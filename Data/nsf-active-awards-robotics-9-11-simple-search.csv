"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1839371","TRIPODS+X:RES: Safe Imitation Learning for Robotics","DMS","TRIPODS Transdisciplinary Rese, OFFICE OF MULTIDISCIPLINARY AC, IIS SPECIAL PROJECTS","10/01/2018","09/10/2018","Zaid Harchaoui","WA","University of Washington","Standard Grant","Nandini Kannan","09/30/2021","$600,000.00","Maryam Fazel, Sham Kakade, Siddhartha Srinivasa","zaid@uw.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","MPS","041Y, 1253, 7484","047Z, 062Z","$0.00","Learning algorithms are now pervasively deployed in robotic systems. However, safe learning procedures with high-probability theoretical guarantees on the acceptability of the predictions have been far less studied, especially for robotic systems trained with data collected from experts and making decisions sequentially. The PIs shall bring together ideas and techniques from statistics, machine learning, and mathematical optimization, to design the next generation of imitation learning approaches with provable safety guarantees for several classes of modern robots that interact with humans.   <br/><br/>The project aims to: (1) develop new formulations of safe imitation learning; (2) design fast learning algorithms with theoretical guarantees on safety; (3) explore trust-building processes for beneficial human-machine interaction. The research approaches will be evaluated in several robotic problem domains, including robotic manipulation and wheeled mobile robot navigation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734190","NRI: INT: COLLAB: Integrated Modeling and Learning for Robust Grasping and Dexterous Manipulation with Adaptive Hands","IIS","National Robotics Initiative","09/01/2017","07/27/2017","Aaron Dollar","CT","Yale University","Standard Grant","James Donlon","08/31/2021","$632,500.00","","aaron.dollar@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","CSE","8013","8086","$0.00","Robots need to effectively interact with a large variety of objects<br/>that appear in warehouses and factories as well as homes and offices.<br/>This requires robust grasping and dexterous manipulation of everyday<br/>objects through low cost robots and low complexity solutions.<br/>Traditionally, robots use rigid hands and analytical models for such<br/>tasks, which often fail in the presence of even small errors. New<br/>compliant hands promise improved performance, while minimizing<br/>complexity, and increased robustness. Nevertheless, they are<br/>inherently difficult to sense and model. This project combines ideas<br/>from different robotics sub-fields to address this limitation. It<br/>utilizes progress in machine learning and builds on a strong tradition<br/>in robot modeling. The objective is to provide adaptive, compliant<br/>robots that are better in grasping objects in the presence of multiple<br/>unknown contact points and sliding or rolling objects in-hand. The<br/>broader impact will be strengthened by the open release of new or<br/>modified robot hand designs, improved control algorithms and software,<br/>as well as corresponding data sets. Furthermore, academic<br/>dissemination will be accompanied by educational outreach to<br/>undergraduate and high school students.<br/><br/>Towards the above objective, the first step will be the definition of<br/>new hybrid models appropriate for adaptive, compliant hands.  This<br/>will happen by improving analytical solutions and extending them to<br/>allow adaptation based on data via novel, time-efficient learning<br/>methods. The objective is to capture model uncertainty inherent in<br/>real-world interactions; a process that suffers from data scarcity.<br/>In order to reduce the amount of data required for learning, different<br/>models will be tailored to specific tasks through an automated<br/>discovery of these tasks and of underlying motion primitives for each<br/>one of them. This task identification process will operate iteratively<br/>with learning and utilize improved models to discover new tasks. It<br/>can also provide feedback for improved hand design. Once these<br/>learning-based and task-focused models are available, they will be<br/>used to learn and synthesize controllers for grasping and in-hand<br/>manipulation. To learn controllers, this work will consider a<br/>model-based, reinforcement learning approach, which will be evaluated<br/>against alternatives. For controller synthesis, existing tools for<br/>this purpose will be integrated with task planning primitives and<br/>extended through learning processes to identify the preconditions<br/>under which different controllers can be chained together. The project<br/>involves extensive evaluation on a variety of novel adaptive hands and<br/>robotic arms designed in the PIs' labs. Modern vision-based solutions<br/>will be used to track grasped objects and provide feedback for<br/>learning and closed-loop control.  The evaluation will measure whether<br/>the developed hybrid models can significantly improve robustness of<br/>grasping and the effectiveness of dexterous manipulation."
"1724392","S&AS: FND: Long-Term Planning and Robust Plan Execution for Multi-Robot Systems","IIS","S&AS - Smart & Autonomous Syst","09/01/2017","07/27/2017","Sven Koenig","CA","University of Southern California","Standard Grant","James Donlon","08/31/2020","$599,999.00","Nora Ayanian","skoenig@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","039Y","046Z, 9102","$0.00","How can multi-robot teams maneuver in tight and cluttered environments when ""no plan survives contact"" with reality?  Traditional approaches plan for idealized situations and must patch up maneuvers when sensors or actuators are imprecise, making them neither robust nor safe.  This project, a collaboration of PIs from artificial intelligence and robotics, will investigate fundamental research to capture and use timing and uncertainty constraints in  large robot navigation and coordination problems.  The target applications are just-in-time manufacturing and automated warehousing, but the results will extend beyond to many applications of smart and autonomous systems that need reliable and safe planning.  <br/><br/>The project will study Multi-Agent Path Finding (MAPF), which is an NP-hard planning problem that belongs to a class of important planning problems, namely multi-agent navigation problems with temporal and spatial constraints.  The research will relax simplifying assumptions typically made by MAPF solvers, namely that plan execution is perfect and stops once all robots have reached their goal locations.  Many AI planning methods that have been developed are not used on robots, since planning/scheduling uses idealized models of the environment and plan execution is never perfect, and there is often insufficient time for re-planning if execution deviates from the plan. This project will develop well-founded planning and plan-execution methods, based on probabilistic and temporal reasoning, that fuse ideas from robotics and artificial intelligence.  In particular, the PIs will combine advances in planning algorithms from the AI community, namely Simple Temporal Networks (STN), and adapt them to the robotics domain by adding timely execution constraints, as well as sensor, actuator, and model uncertainties.   They will make project results (such as papers, videos and code) available on their web pages, present tutorials on their research results to the artificial intelligence and robotics research communities, develop teaching material for multi-robot planning, and integrate undergraduate students into their research activities."
"1730126","CI-P: Physical robotic manipulation test facility","CNS","SPECIAL PROJECTS - CISE, COMPUTING RES INFRASTRUCTURE","09/01/2017","04/18/2018","Cindy Grimm","OR","Oregon State University","Standard Grant","James Donlon","11/30/2018","$115,699.00","Ravi Balasubramanian","grimmc@onid.orst.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","1714, 7359","7359, 9251","$0.00","The robotics community has a rich history of research and development in teaching and training robots to pick up and manipulate objects. However, it has proven to be very difficult to transition this research from structured laboratory settings to real world settings, such as homes, small-scale industrial settings, and search and rescue domains. The development of large-scale, standardized testing and benchmarking of robotic manipulation approaches is necessary to move robotic manipulation from the research lab to the real world. Placing the burden of conducting these tests on every individual robotics researcher is inefficient, at best. Cleaning the captured data to make it available to other researchers requires additional work for the producers of the data - and even more work on potential users. All of this impedes progress for the community as a whole, and makes it difficult to bring to bear recent developments in deep learning. This project addresses this problem by setting the groundwork for a dedicated physical robotic grasping and manipulation testbed infrastructure that can be remotely accessed and operated by anyone doing research in this area.  <br/><br/>This testbed will provide several critical components that the robotics grasping and manipulation community needs: (i) ""Test suites"" that enable repeated testing and controlled manipulation of several variables that have confounded robotic grasping and manipulation research.  Variables include object and gripper material properties, compliance, force/torque of physical interaction, mass of manipulator elements and the objects, surface texture, low-level control algorithms, and higher-level planning techniques. (ii) Extensive instrumentation to capture (nearly) all aspects of the physical interaction, such as the forces, kinematics of movement, and three-dimensional geometry.  (iii) A modular and customizable human-robot interface for enabling robotic physical interaction.  Users will be able to directly control the robot using low-level interfaces, such as the knobs that control the movements of individual joints, or use  higher-level interfaces that encapsulate robot-object interactions, such as close the fingers until they contact the object.  (iv) Data collection, where the data will be made publicly available in a standardized form. The focus of this planning activity is to develop the necessary technological elements to prove the feasibility of such a test facility (automated object return in a fully instrumented space, a fully instrumented ""door"" to evaluate opening and closing doors) and to evaluate the community's needs in this area."
"1830282","NRI: INT: COLLAB: Collaborative Task Planning and Learning through Language Communication in a Human-Robot Team.","IIS","National Robotics Initiative","10/01/2018","09/10/2018","Julie Shah","MA","Massachusetts Institute of Technology","Standard Grant","Reid Simmons","09/30/2022","$731,590.00","","arnoldj@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","8013","063Z, 8086","$0.00","When deployed in the field, robots will often encounter new situations or new tasks they don't have any knowledge or experience about. Even given sufficient knowledge, designing planners that can generate high quality plans and perform efficiently across various domains remains an open challenge. To address these issues, this project aims to empower robots to harness human expertise to acquire new knowledge and to engage humans in the loop of plan generation so that humans and robots can collectively arrive at a joint plan. The results will lead to principles and computational models for enabling effective human-robot teams that can adapt to new and changing environments and tasks, which will benefit many applications such as manufacturing, service, assistive technology, and search and rescue. This project will also provide new exciting training and education opportunities for students through research mentoring and curriculum development. <br/><br/>This project investigates how humans and robots strive to mediate goals, world models, and plans to establish common ground for joint tasks.  It will develop a computational framework that tightly links language and dialogue processing with the robot's underlying planning system to support collaborative task planning and learning in a human-robot team. It further will evaluate collaborative model acquisition and plan generation in terms of consistency of shared understanding, plan quality, and situational awareness. The research will transform planning in a human-robot team by integrating human expertise and knowledge in a collaborative process to improve planning and task performance. It will endow the robot with an ability to explain its internal states, goals and plans, and to continuously learn new states, actions, and plans through language communication with human partners.  It will also advance language and dialogue research by providing a rich context for studying grounded semantics of language.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1838799","SCH: INT: Collaborative Research: Aging In Place Through Enhanced Mobility and Social Connectedness: An Integrated Robot and Wearable Sensor Approach","IIS","National Robotics Initiative, Smart and Connected Health","01/15/2019","09/10/2018","Yi Guo","NJ","Stevens Institute of Technology","Standard Grant","Wendy Nilsen","12/31/2022","$927,247.00","Damiano Zanotto, Ashley Lytle","yguo1@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","CSE","8013, 8018","063Z, 8018, 8086","$0.00","The concept of ""aging in place"", using advanced technology to improve the health and well-being of older adults at home, has become popular as away to reduce costs and allow older adults the dignity of living their final years in the community. This project will use an integrated autonomous system that consists of a mobile robot and smart insole sensors to assist older adults to independently live in their own homes and interact with their communities.  The system will have two initial goals: supporting exercise and enhancing social connections. The target exercise is walking, the most preferred and accessible exercise modality among older adults. Regular walking exercises may result in enhanced balance, increased muscle strength, and reduced risk of falling.  The system guides individuals in regular walking exercises, autonomously assesses gait states, and provides real-time personalized feedback to engage older adults into the exercise. The robot will also be used to connect older adults with family and friends through a virtual connection. The project team will evaluate the system at a senior center in New York City using objective and subjective performance criteria measuring older adults' experiences with the system. This project serves the national interest because the integrated social assistive robot and wearable sensor system enhances mobility and social connectedness of older adults thus should improve their health and well-being. The project will involve an educational component that provides engineering and research method training to graduate and undergraduate students, as well as STEM outreach to middle and high-school students. Additional efforts will be made to attract and retain women and underrepresented minorities into careers in science and engineering.<br/><br/>This research investigates human-robot-sensor interaction, and aims to enhance mobility and social connectedness of older adults through the use of an assistive service robot. Methods to be developed include autonomous gait analysis combining sensing capability of robot onboard image sensors and the smart insoles through parametric and learning-based calibration models. The use of inverse reinforcement learning to explore cost function representation for robot motion planning. The use of dynamic recurrent neural networks and vibrotactile rhythmic stimuli for collaborative human-robot walking tasks. The project also examines the use of autonomous task scheduling to increase social contacts through telepresence robotic techniques. Finally, the implementation and experimental testing of the integrated system will be conducted in a senior center using objective and subjective performance criteria. The project fills a gap in aging-in-place research by providing an integrated robot and wearable sensor solution for enhancement of mobility and social connectedness. The developed methods will be implemented on open-source platforms, and the experimental and evaluation data will be made available for public use.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1838725","SCH:INT:Collaborative Research: Aging In Place Through Enhanced Mobility and Social Connectedness-An Integrated Robot and Wearable Sensor Approach","IIS","Smart and Connected Health","01/15/2019","09/10/2018","Ashwini Rao","NY","Columbia University","Standard Grant","Wendy Nilsen","12/31/2022","$272,047.00","","akr7@cumc.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","8018","063Z, 8018, 8062, 8086","$0.00","The concept of ""aging in place"", using advanced technology to improve the health and well-being of older adults at home, has become popular as away to reduce costs and allow older adults the dignity of living their final years in the community. This project will use an integrated autonomous system that consists of a mobile robot and smart insole sensors to assist older adults to independently live in their own homes and interact with their communities.  The system will have two initial goals: supporting exercise and enhancing social connections. The target exercise is walking, the most preferred and accessible exercise modality among older adults. Regular walking exercises may result in enhanced balance, increased muscle strength, and reduced risk of falling.  The system guides individuals in regular walking exercises, autonomously assesses gait states, and provides real-time personalized feedback to engage older adults into the exercise. The robot will also be used to connect older adults with family and friends through a virtual connection. The project team will evaluate the system at a senior center in New York City using objective and subjective performance criteria measuring older adults' experiences with the system. This project serves the national interest because the integrated social assistive robot and wearable sensor system enhances mobility and social connectedness of older adults thus should improve their health and well-being. The project will involve an educational component that provides engineering and research method training to graduate and undergraduate students, as well as STEM outreach to middle and high-school students. Additional efforts will be made to attract and retain women and underrepresented minorities into careers in science and engineering.<br/><br/>This research investigates human-robot-sensor interaction, and aims to enhance mobility and social connectedness of older adults through the use of an assistive service robot. Methods to be developed include autonomous gait analysis combining sensing capability of robot onboard image sensors and the smart insoles through parametric and learning-based calibration models. The use of inverse reinforcement learning to explore cost function representation for robot motion planning. The use of dynamic recurrent neural networks and vibrotactile rhythmic stimuli for collaborative human-robot walking tasks. The project also examines the use of autonomous task scheduling to increase social contacts through telepresence robotic techniques. Finally, the implementation and experimental testing of the integrated system will be conducted in a senior center using objective and subjective performance criteria. The project fills a gap in aging-in-place research by providing an integrated robot and wearable sensor solution for enhancement of mobility and social connectedness. The developed methods will be implemented on open-source platforms, and the experimental and evaluation data will be made available for public use.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830414","NRI: INT: Balancing Collaboration and Autonomy for Multi-Robot Multi-Human Search and Rescue","CNS","National Robotics Initiative","10/01/2018","09/09/2018","Ryan Williams","VA","Virginia Polytechnic Institute and State University","Standard Grant","Ralph Wachter","09/30/2022","$1,474,719.00","James McClure, Nicole Abaid, Nathan Lau","rywilli1@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","8013","063Z, 8086","$0.00","Each year, thousands of people go missing in the United States. Coordinated search and rescue (SAR) operations provide the best chance to locate a missing individual alive. However, challenging terrain and other search constraints represent a barrier to human searchers. This project therefore seeks to enable collaboration between human searchers and unmanned aerial vehicles (UAVs) to improve searches while reducing human effort. Specifically, this project asks: How do we select and assign search tasks that ensure long-term human-robot collaboration, while deploying robots to complement human searchers in real-time? This project aims to answer this question through optimization, behavioral modeling, human-robot interaction, and computation, with evaluation in large-scale prototypes supported by the SAR community. Finally, impacts beyond SAR include: (1) education focused on co-robots; (2) theory for human-robot interaction in collaborative settings; (3) portable, low-cost, low-power computational infrastructure suitable for a wide range of applications; (4) technologies that foster economic opportunity around co-robots; and (5) field experiences for students from groups underrepresented in engineering.<br/><br/>This project focuses on new theory and technologies for: (1) a minimally invasive, adaptive, multi-UAV control system leveraging risk-aware multi-robot planning for human-in-the-loop (HITL) control; (2) distributed computing that opportunistically exploits and balances multi-robot interaction, communication, computation, and decision-making; and (3) an interface between human searchers and UAVs that allows control from complete autonomy to manual operation, including testable interfaces for exploration vs. exploitation strategies. This project addresses fundamental challenges critical to the scalability of multi-robot multi-human teams: (1) planning and control systems for UAVs that can autonomously gather information in a cooperative and distributed way while adapting to uncertain human plans; (2) interfaces for human-robot interactions that allows collaboration that appropriately balances exploration with exploitation; and (3) real-time support to analyze, store, and share data subject to the power and connectivity constraints typical of real-world deployments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830896","EFRI C3 SoRo: Textile Robotics: Integrative Design, Modeling, Manufacture, and Control of Soft Human-Interactive Apparel","EFMA","EFRI RESEARCH PROJECTS","09/15/2018","09/10/2018","Conor Walsh","MA","Harvard University","Continuing grant","Garie Fordyce","08/31/2022","$1,900,000.00","Joey Mead, Ramaswamy Nagarajan, Katia Bertoldi, Scott Kuindersma","walsh@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","ENG","7633","7633","$0.00","This project seeks to leverage textile materials to create soft and compliant wearable robots that are lightweight and nonrestrictive, and can deliver valuable levels of assistance. This will be achieved by studying how to model, manufacture and control textile-based robotic systems. The outcomes from this project will highlight the benefits of textiles as a materials platform for new components that enable wearable robot systems that can be worn like clothing. When people suffer neurologic and musculoskeletal injuries, they often cannot perform even the simplest activities of daily life. The innovative new devices and systems that result from this project will offer the potential to provide additional strength by applying forces to a wearer's limb to mitigate disability and augment the natural abilities of the human body. This will simultaneously open avenues for independence, societal participation, and return-to-work, while reducing healthcare costs. This project will also promote interdisciplinary research and teaching, and facilitate interactions between roboticists, applied mathematicians, computer scientists, biomedical engineers, material scientists, and functional apparel designers. <br/> <br/>This project will create, analyze, and evaluate a new class of textile-based, conformal, and compliant wearable robots in the form of garments. Embedded textile strain and pressure sensors will monitor the state of the actuators and the underlying limb, while integrated air-impermeable and conductive pathways for fluid power and data transfer will enable manipulation of the limb through simultaneous online estimation and control. This transformative, interdisciplinary research program will address fundamental questions aimed at increasing our understanding of how to leverage the mechanical and electrical properties of advanced textile materials to achieve flexible and distributed actuation, sensing, and information/power transfer for textile-based robots. The project will develop new computational and analytical modeling tools that account for the inherent material and geometric nonlinearities to guide the parametric design of both individual actuators, sensors and their distributions on a limb; model-based and data-driven control and estimation algorithms that account for the nonlinear actuator properties and inherent uncertainty in positioning a textile-based robot on a limb and finally novel material constructions and their manufacturing processes spanning the nanoscale to wearable garments. This project will integrate the activities at all stages of the research through highly collaborative interactions and demonstrate and validate the benefits of this approach through multiple experimental testbeds.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1427872","MRI Development: Enabling Research in Natural Communication with Virtual Tutors, Therapists, and Robotic Companions","CNS","MAJOR RESEARCH INSTRUMENTATION, INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, Cyber-Human Systems (CHS), ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2014","05/11/2017","Mohammad Mahoor","CO","University of Denver","Standard Grant","Rita V. Rodriguez","08/31/2019","$1,348,000.00","Ronald Cole, Wayne Ward, Juan Wachs","mmahoor@du.edu","2199 S. University Blvd.","Denver","CO","802104711","3038712000","CSE","1189, 1640, 1714, 7367, 7495, 8013","1189, 8086, 9251","$0.00","This project, developing SocioBot-SDS (SocioBot-Spoken Dialog System), an instrument in the form of a robotic character with an emotional response, is expected to advance research involving next generation human-machine interactions. The robotic instrument will be used for therapeutic and educational purposes. Its development will specifically contribute to the research area of perceived speech and visual behaviors. The components of the instrument integrate a unique level of programmability and robustness to the display of human- and non-human-like emotive gestures with conventional orientation control through an articulated neck. The work is expected to accelerate research and development of social robots that can accurately model the dynamics of face-to-face communication with a sensitive and effective human tutor, clinician, or caregiver to a degree unachievable with current instrumentation. The robotic agent builds on advances in computer vision, spoken dialogue systems, character animation and effective computing to conduct dialogues that establish rapport with users producing rich, emotive facial gestures synchronized with prosodic speech generations in response to users' speech and emotions. The instrument represents a new level of integration of emotive capabilities that enable researchers to study socially emotive/robots/agents that can understand spoken language and show emotions and interact, speak, and communicate effectively with people in a natural way (as humans do).<br/><br/>The instrument provides an exciting platform for research and training supporting cross-discipline technology. Since the research community would have access to the instrument, research in how to optimize communication among people and avatars might be accelerated through the perception of speech patterns and visual behaviors of those interacting. The instrument represents a new level of integration of emotive capabilities and serves as a platform for designing a new generation of more immersive and effective intelligent tutoring and therapy systems, and robot-assisted therapeutic treatments for human disabilities that include infants at risk for sensory, attention and language delays, as well as adults with mental disabilities.  From an educational perspective, the proposed activities will enhance inter-disciplinary education by involving students at all levels, during and beyond the development of the instrument. The resulting instrument will be freely distributed for researchers to investigate robotic behaviors that lead to immersive and effective applications across a variety of task domains such as teaching students to read, tutoring students in science, conducting speech and language therapy sessions, or providing companionship to elderly individuals in their homes. Moreover, the activities initiated by this development enhance interdisciplinary education, involving students at the undergraduate and graduate levels, during and beyond the development of the instrument."
"1501828","Advanced Technological Education in Robotics and Automated Manufacturing Program (ATE-RAMP)","DUE","ADVANCED TECH EDUCATION PROG","09/15/2015","09/09/2015","Richard Murphy","SC","Orangeburg-Calhoun Technical College","Standard Grant","Heather Watson","08/31/2019","$644,220.00","James Payne","murphycr@octech.edu","3250 Saint Matthews Road","Orangeburg","SC","291158222","8035360311","EHR","7412","1032, 9150, 9178, SMET","$0.00","Orangeburg-Calhoun Technical College (OCtech) will implement the ""Advanced Technological Education in Robotics and Automated Manufacturing Program"" (ATE-RAMP) with the overarching goal of increasing awareness of opportunities in science, technology, engineering, and mathematics (STEM) disciplines for women and underrepresented minorities.  To achieve this goal, the project team will implement a three-step plan focused on awareness, preparation, and career-readiness.  Within the region served by OCtech, interest in STEM careers and student achievement in STEM subjects lags behind the nation and behind many areas within the state of South Carolina. The five counties being targeted for this project are in the top six of South Carolina's forty-six (46) counties with the highest unemployment rates.  Efforts are being made to shore up the lagging economy in the area by recruiting a variety of high tech industries. These employers will need workers with knowledge and skills in STEM subjects, namely robotics and automated manufacturing (AM). Without a skilled workforce to offer, this region of South Carolina will fail to fulfill its potential role as a home to these much needed industries. In partnership with local industry and school districts, ATE-RAMP will help meet current and future workforce needs by attracting and engaging students from poor, rural communities who are not typically exposed to robotics, AM, and STEM career opportunities.  The partnering school districts have significant minority and female student populations.<br/><br/>The objectives of the project are to: (1) introduce opportunities for underrepresented groups to have access to programs involving robotics and AM; (2) provide dual credit courses in robotics and AM for high school students; and (3) expand the course offerings in the computer engineering curriculum at OCtech to include robotics and AM and share developed resources with other colleges.  These objectives will be met through activities including, but not limited to, hosting Vex Robotics teams, competitions, and summer camps for rural K-12 students, deploying traveling robotics and AM demonstrations, adding dual credit courses to the STEM Academy of the Middle College at OCtech, expanding capacity of existing courses to facilitate better hands-on experiences for students, and revising the Associate in Applied Science (AAS) in Engineering Technology to ensure that it produces technicians with marketable skills necessary to work in fields related to robotics and AM.  Achievement of desired goals will be determined by employing mixed methods that assess affective and cognitive outcomes using both quantitative and qualitative data.  The results will help build the knowledge base on promising practices for engaging students from underrepresented groups who live in poor, rural communities in STEM activities, technician programs, and in the workforce."
"1830516","NRI: FND: Hybrid Active-Passive Actuation for Safety and Performance in Physical Human-Robot Collaboration and Rehabilitation","CMMI","National Robotics Initiative","09/15/2018","09/07/2018","Peter Adamczyk","WI","University of Wisconsin-Madison","Standard Grant","Atul G. Kelkar","08/31/2021","$749,704.00","Michael Zinn, Kreg Gruben","peter.adamczyk@wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","ENG","8013","030E, 034E, 063Z, 8024, 8086","$0.00","Physical cooperation between a person and a robot requires a range of performance characteristics that is difficult for traditional robots to meet. Sometimes a robot must have high stiffness to support an object for a person to work with or to perform a precise task of its own, but at other times it must have low stiffness to ensure the safety of a person who makes contact with it. Sometimes a robot must control the interaction force between itself and a person, but at other times it must move along a precise path regardless of the force applied to it. Existing actuators such as electric, pneumatic or hydraulic motors cannot achieve this performance combination, so a new approach to robotic actuators is required. This National Robotics Initiative (NRI) research project will study the design and control of robots that use a combination of active components (motors) and passive components (brakes) to meet these opposing demands. This actuation approach, referred to as Balanced Active-Passive Hybrid Actuation, will provide high power capabilities while possessing the unique characteristics required for human-robot physical collaboration. This research will enable new capabilities for cooperation between people and robots and will open unserved application areas such as cooperative high-power manufacturing robots, high-power rehabilitation robots, and high-performance exoskeletons. One important application is rehabilitation robotics for retraining intentional movement after neural injury such as stroke. The hybrid active-passive actuators developed in this research will be applied to create a strong and accurate, yet also safe, rehabilitation robot for the legs, which will be used to test leg force and movement control and develop rehabilitation methods for stroke survivors. <br/><br/>The goal of this project is to develop design principles and control approaches for hybrid active-passive actuators capable of providing high power and high force-control bandwidth. The research will combine a series-elastic electric motor for low-bandwidth force control, a parallel direct-drive electric motor for high-bandwidth force control, and a parallel brake for efficient very high-bandwidth support against applied external forces. A physical test actuator will be built according to these design principles and used to develop and test a bandwidth-partitioning controller for coordinating the multiple actuators. The resulting design and control techniques will be used to build a two-axis parallel linkage manipulator for applying arbitrary planar force fields to the foot of a human user. The system will be tested for its ability to haptically render virtual mechanical environments such as viscous curl fields. These curl fields will be used to study motor control of the leg, with the goal of developing rehabilitative tasks for stroke survivors to promote the recovery of coordinated movement and postural control.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830244","NRI: INT: COLLAB: Collaborative Task Planning and Learning through Language Communication in a Human-Robot Team","IIS","National Robotics Initiative","10/01/2018","09/10/2018","Joyce Chai","MI","Michigan State University","Standard Grant","Reid Simmons","09/30/2022","$768,410.00","","jchai@cse.msu.edu","Office of Sponsored Programs","East Lansing","MI","488242600","5173555040","CSE","8013","063Z, 8086","$0.00","When deployed in the field, robots will often encounter new situations or new tasks they don't have any knowledge or experience about. Even given sufficient knowledge, designing planners that can generate high quality plans and perform efficiently across various domains remains an open challenge. To address these issues, this project aims to empower robots to harness human expertise to acquire new knowledge and to engage humans in the loop of plan generation so that humans and robots can collectively arrive at a joint plan. The results will lead to principles and computational models for enabling effective human-robot teams that can adapt to new and changing environments and tasks, which will benefit many applications such as manufacturing, service, assistive technology, and search and rescue. This project will also provide new exciting training and education opportunities for students through research mentoring and curriculum development. <br/><br/>This project investigates how humans and robots strive to mediate goals, world models, and plans to establish common ground for joint tasks.  It will develop a computational framework that tightly links language and dialogue processing with the robot's underlying planning system to support collaborative task planning and learning in a human-robot team. It further will evaluate collaborative model acquisition and plan generation in terms of consistency of shared understanding, plan quality, and situational awareness. The research will transform planning in a human-robot team by integrating human expertise and knowledge in a collaborative process to improve planning and task performance. It will endow the robot with an ability to explain its internal states, goals and plans, and to continuously learn new states, actions, and plans through language communication with human partners.  It will also advance language and dialogue research by providing a rich context for studying grounded semantics of language.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1837212","CPS: Medium: LEAR-CPS: Low-Energy computing for Autonomous mobile Robotic CPS via Co-Design of Algorithms and Integrated Circuits","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2018","09/10/2018","Sertac Karaman","MA","Massachusetts Institute of Technology","Standard Grant","Jonathan Sprinkle","09/30/2021","$1,000,000.00","Vivienne Sze","sertac@MIT.EDU","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7918","7924","$0.00","The goal of this research is to enable a new era of low-energy mobile robotic Cyber-Physical Systems (CPS). The approach is the simultaneous design of the computing hardware with the computer algorithms, with input from the physics of the system. Applications include, but are not limited to, insect-size robotic bees for artificial pollination, robotic water striders for environmental monitoring, miniature underwater autonomous vehicles for inspection, orally-administered medical robotic vehicles that can intelligently navigate the digestive system, robotic gliders that can operate in the air or underwater for months at a time, and many more. The results will enable low-power computing for artificial intelligence and autonomy to complement the existing low-energy, miniature actuation and sensing systems that have already been developed. This will enable  low-energy, miniature mobile robotic CPSs that can still provide provable guarantees on completeness, optimality, robustness and safety. <br/><br/>This project will focus on the development of novel algorithms and novel computing hardware for miniature, energy-efficient mobile robotic CPS. The proposed research will enable low-energy computation for full autonomy by way of minimizing energy consumption during design time and run time, by simultaneously designing the algorithms and the computing hardware. Decision making algorithms will minimize computing energy during run time, for instance, by considering motions that may not require heavy computation for perception and planning. The project will demonstrate the new methods by constructing the smallest fully-autonomous aerial robotic vehicle ever built. We believe the proposed foundational research and the proposed demonstration will kickstart a new cyber-physical systems subfield at the intersection of the mobile robotics literature and the computing hardware (circuits) literature.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839194","EXP: Inclusive Design for Engaging All Learners (IDEAL): Designing Technology for Cultural Brokering","IIS","Cyberlearn & Future Learn Tech","01/01/2018","06/21/2018","Yanghee Kim","IL","Northern Illinois University","Standard Grant","Tatiana D. Korelsky","12/31/2019","$436,025.00","","ykim9@niu.edu","301 Lowden Hall","De Kalb","IL","601152828","8157531581","CSE","8020","8045, 8841, 9150","$0.00","In the United States today, children whose home language is not English make up about 21% of the current K-12 school-age population. These children often enter school already behind academically because they have to learn English as well as the subject being taught. Academic struggles can result in children having negative perceptions about education and high dropout rates. There is an urgent need to break this cycle and foster children's confidence so that they view themselves as valuable contributors to the classroom. This project explores the creation of an effective program for all children that recognizes cultural and linguistic diversity as an asset. The project seeks to understand how sociable, humanoid robots can be designed to guide collaborative interactions among children who come from culturally and linguistically diverse backgrounds. Through this understanding, the project addresses urgent societal needs for better integration of minority students into U.S. classrooms. Appreciating diversity is a life skill that is essential for all Americans living in an ever more diverse society. Taking advantage of social robotics, the project intends to create this mindset from an early age.<br/> <br/>The project research is carried out in the context of developing and refining a set of robot-mediated interaction activities for kindergarten-aged, English-speaking and Spanish-speaking children. Grounded in socio-cultural theories, the robot (acting as a playmate) is designed to mediate interactions among children to create an inclusive learning community. The research questions include i) What does it take to design robot-mediated collaborative interactions to support children's development? ii) How do the children's identities and learning develop as they participate in the collaboration? Spanning two years, the project uses design-based research methodology by which the interaction activities are designed, tested, and refined in an iterative cycle. Data collection is done using the Wizard of Oz method, where a hidden person controls the robot to assist children's interactions as they learn and play together. A representative corpus of social interactions between the children and the person allows the researchers to determine the needed robot capabilities for the ultimate implementation using a real robot. Ethnographic, participatory observations of children's interactions and interviews with the children, teachers, and parents are also conducted. The project team consists of researchers from the fields of learning sciences, literacy, and computer science, public school personnel, and a three-member advisory board. The project outcomes will be disseminated through multiple channels that target academic and professional communities."
"1760247","NRI: FND: COLLAB: An Open-Source Robotic Leg Platform that Lowers the Barrier for Advanced Prosthetics Research","CMMI","National Robotics Initiative","10/01/2017","11/17/2017","Elliott Rouse","MI","University of Michigan Ann Arbor","Standard Grant","Irina Dolinskaya","09/30/2020","$341,817.00","","ejrouse@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","8013","030E, 034E, 8024, 8086","$0.00","The objective of this project is to provide researchers with access to a fully capable and standardized open-source robotic leg research platform, without the immense burden of developing each component from scratch. The outcome will be a robust and inexpensive test bed that can be easily manufactured, assembled, and controlled. One of the greatest challenges to the design and commercialization of robotic prosthetic legs is the control strategy -- that is, the computerized instruction set that specifies the effort level and timing for each component of the mechanism. Challenges in developing control strategies stem from the many different functions that an active robotic limb must accomplish. One important function is to detect the amputee's intention to perform different mobility activities, such as walking on a level surface versus ascending or descending stairs. Another important function is to coordinate the pattern of effort and movement of the prosthetic limb in order to emulate the healthy human body. There are many researchers working independently on better control algorithms to address challenges such as these. To be of value, these algorithms must be tested and validated experimentally. Research groups around the world have created a variety of specialized robotic leg designs for this purpose, representing a significant investment of time and effort. The resources required to obtain a suitable research platform represent a substantial obstacle for new researchers to overcome. Furthermore, the vast difference in designs used by established researchers hinders the comparison of new control strategies across research groups. The accessible, standardized leg platform resulting from this project will lower barriers to entry, allowing new researchers to study the control of robotic legs, to unambiguously compare different control approaches, and to generally advance the field. Finally, the improved prosthetic leg designs arising in the long term from this project will benefit the lives of amputees.<br/> <br/>The overall research goals of this project are 1) to identify an electromechanical design for a low cost, high performance, open-source robotic knee and ankle system; 2) to understand how separate prosthesis control strategies can be combined to benefit amputee gait, and 3) to evaluate and compare resulting controllers in amputee experiments. The approach utilizes a novel design methodology employing selectable series elasticity and high-torque motor technology to achieve high performance at low cost. Interchangeable control modules in the open-source architecture allow researchers to investigate new control methods at low, mid, and high levels of the system, that is, motor drive, joint control, and human intent recognition, respectively. In particular, a reflex-based approach and a phase-based approach will be implemented as mid-level control modules and a high-level intent recognition module will enable the robotic leg to automatically switch between different user activities. In all cases, having the new robot leg available together with these algorithms will enable testing in real-world scenarios, rather than being confined to the laboratory. The results of this project will lower the barrier for conducting research and enable fair comparison across different control approaches with standardized leg hardware. Finally, the work will impact students and the community through training, outreach, and dissemination."
"1824660","Data-based Iterative Control using Complex-Kernel Regression for Precision SEA Robots","CMMI","SPECIAL INITIATIVES","09/15/2018","09/06/2018","Santosh Devasia","WA","University of Washington","Standard Grant","Irina Dolinskaya","08/31/2021","$379,250.00","","devasia@u.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","ENG","1642","030E, 034E, 8024","$0.00","This grant will support research that will contribute new knowledge related to increased automation in high-demand, low-volume manufacturing sectors, such as aerospace. In contrast to full automation, there is a need for growing-convergence research on semi-autonomous approaches for low-volume manufacturing, which exploit the combination of human adaptability and machine precision and speed, to be cost effective. Robots with series-elastic actuators (SEA) have soft joints, which enables precision control over the forces applied to the environment and are therefore, considered to be inherently safe for human-robot collaboration. This inherent safety facilitates easy adoption by workers who can directly program the robots by physical demonstrations, which in turn reduces the amount of training needed for new workers.  Nevertheless, this increased control over forces comes at the cost of lower positioning precision, which limits their use in manufacturing, where precision is important. The results from this research will increase the precision of such inherently-safe robots, and enable their use by relatively-novice workers. Moreover, the use of robotic solutions for manufacturing in confined spaces, rather than a human crawling inside, can lead to thinner, lighter and more efficient aircraft wings, with lower operating costs. Thus, the work will directly impact US competitiveness in the aerospace manufacturing sector with a substantial number of high-paying jobs. This research involves the integration of control theory and advanced robotics in manufacturing. Due to substantial and growing interest in manufacturing and robotics, the efforts will help to increase participation by underrepresented groups in research, and strengthen engineering education.<br/><br/>Relatively-soft, series elastic actuators along with low-impedance control improves control authority over the force exerted by such robots on the environment, and has the potential to enable human-robot collaboration in the manufacturing environment. Nevertheless, a central issue is that the flexural systems in such robots result in non-minimum phase dynamics and high gains (for improved precision) can lead to instability. Moreover, accurate modeling for increased precision can be challenging due to substantial friction nonlinearities, backlash, and contact-related effects in series elastic actuators robots. This research will fill the knowledge-gap on data-based iterative machine learning approaches to improve the precision of such systems. The research will use uncertainty estimates from the kernel-based learning approach to develop conditions on the size of the iteration gain for guaranteed convergence.  The approach will be experimentally evaluated with a confined-space manufacturing testbed.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830575","NRI:FND:COLLAB: M3SoRo - Mobility and Morphing using Modular Soft Robots","ECCS","National Robotics Initiative","09/15/2018","09/06/2018","Barry Trimmer","MA","Tufts University","Standard Grant","Radhakisan S. Baheti","08/31/2021","$199,342.00","","barry.trimmer@tufts.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","ENG","8013","092E, 8086, 9150","$0.00","The main objective of this National Robotics Initiative (NRI) award is to develop collaborative Modular Soft Robots (MSoRos) that can move in complex terrestrial and climbing environments and change size and shape. A swarm of MSoRos could be used in disaster relief (search and rescue operations), space exploration and precision agriculture. For example, search and rescue scenarios require small robots to autonomously navigate holes and to crawl through narrow cracks/spaces. The collaborative MSoRos will be composed of soft individual units that can deform to penetrate these spaces without prior programming. In agriculture, where the environment is complex, unstructured (soil) and adverse (changes include heat-cold and rain), these robotic modular devices will be capable of multiple behaviors to match their tasks. For example, individual modules could crawl around locally to monitor soil-health and then re-configure as a three-dimensional ball to roll to a centralized station after the task is complete. The ability to form different structures in this way can minimize locomotion costs. Furthermore, this research is easy to disseminate among high-school and undergraduate students as soft robots are cheap, safe to operate and intriguing. The MSoRos will excite young minds by connecting popular robot icons such as Transformers or Big Hero 6, with real-life morphing soft robots. Simultaneously, it will introduce them to futuristic robotics and mechatronics technologies with applications to wearable robotics, collaborative robotics and robots-in-homes, and encourage them to pursue career in STEM and robotics.<br/>This combination of morphing and modularity can dramatically increase the adaptability of a robot. The proposed research will: a) learn principles for robot mobility in complex environments. This is analogous to building reduced-order models (ROMs). Environment-specific ROMs for a highly deformable, soft, continuum robot will be reverse-engineered by learning factors that dominate robot-environment interactions; b) design open-source, untethered MSoRos that will increase the versatility, robustness and cost effectiveness of traditional modular robots; c) establish that environment awareness is a powerful strategy for controlling deformable robots. MSoRos will use their interaction with the environment to learn and deploy appropriate behaviors. This will lead to the development of hybrid robots that will combine environment-centric exploratory learning (this research) with existing model-centric strategies, to carryout complex autonomous tasks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830432","NRI:FND:COLLAB: M3SoRo - Mobility and Morphing using Modular Soft Robots","ECCS","National Robotics Initiative","09/15/2018","09/06/2018","Vishesh Vikas","AL","University of Alabama Tuscaloosa","Standard Grant","Radhakisan S. Baheti","08/31/2021","$382,192.00","","vvikas@eng.ua.edu","801 University Blvd.","Tuscaloosa","AL","354870005","2053485152","ENG","8013","092E, 8086, 9150","$0.00","The main objective of this National Robotics Initiative (NRI) award is to develop collaborative Modular Soft Robots (MSoRos) that can move in complex terrestrial and climbing environments and change size and shape. A swarm of MSoRos could be used in disaster relief (search and rescue operations), space exploration and precision agriculture. For example, search and rescue scenarios require small robots to autonomously navigate holes and to crawl through narrow cracks/spaces. The collaborative MSoRos will be composed of soft individual units that can deform to penetrate these spaces without prior programming. In agriculture, where the environment is complex, unstructured (soil) and adverse (changes include heat-cold and rain), these robotic modular devices will be capable of multiple behaviors to match their tasks. For example, individual modules could crawl around locally to monitor soil-health and then re-configure as a three-dimensional ball to roll to a centralized station after the task is complete. The ability to form different structures in this way can minimize locomotion costs. Furthermore, this research is easy to disseminate among high-school and undergraduate students as soft robots are cheap, safe to operate and intriguing. The MSoRos will excite young minds by connecting popular robot icons such as Transformers or Big Hero 6, with real-life morphing soft robots. Simultaneously, it will introduce them to futuristic robotics and mechatronics technologies with applications to wearable robotics, collaborative robotics and robots-in-homes, and encourage them to pursue career in STEM and robotics.<br/>This combination of morphing and modularity can dramatically increase the adaptability of a robot. The proposed research will: a) learn principles for robot mobility in complex environments. This is analogous to building reduced-order models (ROMs). Environment-specific ROMs for a highly deformable, soft, continuum robot will be reverse-engineered by learning factors that dominate robot-environment interactions; b) design open-source, untethered MSoRos that will increase the versatility, robustness and cost effectiveness of traditional modular robots; c) establish that environment awareness is a powerful strategy for controlling deformable robots. MSoRos will use their interaction with the environment to learn and deploy appropriate behaviors. This will lead to the development of hybrid robots that will combine environment-centric exploratory learning (this research) with existing model-centric strategies, to carryout complex autonomous tasks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734266","NRI: FND: Scene Understanding and Predictive Monitoring for Safe Human-Robot Collaboration in Unstructured and Dynamic Construction Environments","IIS","National Robotics Initiative","09/01/2017","07/27/2017","SangHyun Lee","MI","University of Michigan Ann Arbor","Standard Grant","Jie Yang","08/31/2020","$750,000.00","Vineet Kamat, Jia Deng","shdpm@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","8013","8086","$0.00","The construction industry has the highest number of fatalities and injuries due to hazardous working conditions. The introduction of robots on construction sites has the potential to relieve human workers from dangerous and repetitive tasks by making machines intelligent and autonomous. However, robotic solutions for construction face significant challenges. This project will develop technologies of automated monitoring and intervention through computer vision to provide a means to dramatically improve the perception of construction safety in the presence of co-robots. The new methods developed in this project will impact computer vision, machine learning, and effective human-robot collaboration in unstructured environments, while significantly contributing to safety. Further, the developed methodologies can be broadly applicable in situations where robots are deployed in human-centered environments (hospitals, airports, shipyards, etc.) and have other priorities such as productivity and efficiency as their objective. This project will engage a diverse group of individuals by training graduate and undergraduate students (including women and underrepresented minorities), reaching out to K-12 students, and interacting with industry professionals for broad dissemination of the research results.<br/><br/>This research will investigate new computer vision based methods that can be coupled with other sensing modalities for holistic understanding and predictive analysis of jobsite safety on co-robotic construction sites. The project will consist of two main research thrusts. First, holistic scene understanding will be pursued on construction sites using graphical models to enable joint reasoning of various scene components. This holistic understanding in turn will help evaluate compliance with established safety rules expressed as formal statements. Second, predictive analysis will be investigated by exploiting the fact that, for safety intervention, the complex dynamics of a construction scene make it necessary to simulate what will happen next. In particular, Recurrent Neural Networks will be leveraged to predict future events and prevent impending accidents. Finally, an integrated demonstration system will be built and tested on real construction sites."
"1526367","NRI: Collaborative Research: Task Dependent Semantic Modeling for Robot Perception","IIS","National Robotics Initiative","09/01/2015","08/12/2015","Alexander Berg","NC","University of North Carolina at Chapel Hill","Standard Grant","Jie Yang","08/31/2019","$269,480.00","","aberg@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","8013","8086","$0.00","The research in this project enables robots to better deal with the complex cluttered environments around us, ranging from open scenes to cluttered table-top settings and to perform the basic mapping, navigation, object search so as to enable fetch and delivery tasks most commonly required in service co-robotics applications.  The key contribution of the project is to develop visual perception systems for robots that can understand the semantic labels of the visual world at multiple levels of specificity as required by particular robot tasks or human-robot interaction.  In addition, the project enables robot perception systems to better understand new, previously unseen, environments through automatically adapting existing learned models, and by actively choosing how to best explore and recognize novel visual spaces and objects.  The datasets and benchmarks, as well as the developed models, form basis for more rapid progress on semantic visual perception for robotics.<br/><br/>The development of methodologies for learning compositional representations which enable active learning and efficient inference is a long standing problem in computer vision and robot perception. Guided by the constraints of indoors and outdoors environments, we plan to exploit large amounts of data, strong geometric and semantic priors and develop novel representations of objects and scenes. The developed representations are captured by compositional structured probabilistic models including deep convolutional networks. Doing this rapidly is required to support active visual exploration to improve semantic parsing of a space.  Furthermore the project team collects and disseminates a large dataset of densely sampled RGBD imagery to support offline evaluation and benchmarking of active vision for semantic parsing.  The project can result in advances in active hierarchical semantic vision for robot tasks including exploration, search, manipulation, programming by example, and generally for human-robot interaction."
"1662233","Stability and Optimality Properties of Sequential Action Control for Nonlinear and Hybrid Systems","CMMI","Dynamics, Control and System D","08/01/2017","06/12/2017","Todd Murphey","IL","Northwestern University","Standard Grant","Robert Landers","07/31/2020","$375,000.00","","t-murphey@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","ENG","7569","030E, 034E, 8024","$0.00","This project will greatly extend a powerful new method for control of robots and vehicles, called sequential action control (SAC). One widely used approach to controlling complicated systems is to solve a real-time numerical optimization problem for the magnitude of the next few control pulses, where the all the pulses have a constant width. However even with powerful processors it can be difficult to compute these values fast enough. SAC addresses this challenge by instead computing the optimal width and relative start time of the next control pulse. For many problems of interest, this change in control strategy greatly simplifies computation, to the point that infeasible control problems become tractable. SAC allows analytical solutions to some problems, and speeds computations by up to eight orders of magnitude for others. SAC is naturally compatible with common features of modern control design, including hybrid systems that switch discretely between a collection of continuous dynamic behaviors; quantized systems where inputs, states, and outputs may take only a finite set of constant values; and systems with nonlinear dynamics. SAC can be shown to recover the globally optimal control signal in a number of analytically solvable cases. In other representative test cases, the computed SAC input provides performance that is numerically indistinguishable from the optimum. Optimal or near-optimal input signals are of no value if small disturbances cause the system to rapidly diverge from the desired behavior. Therefore practical controllers must also ensure that small disturbances to the controlled system cause only small deviations in the system response -- a property known as stability. This project seeks to rigorously derive SAC performance guarantees for a broad class of systems, as well as to show conditions under which SAC ensures stability. The Darwin humanoid robot will be used as a high-dimensional, nonlinear, hybrid testbed for this research. Control of the Darwin robot may be implemented in the open-source Robot Operating System (ROS), allowing a robust and verifiable SAC distribution for dissemination. The results of this project will enable greatly improved and verifiable control over systems such as rehabilitation robots, assistive devices, rotor vehicles, and driverless cars, using widely available and low-cost computing platforms such as mobile phones. Benefits to society from this project include enhanced safety and performance of these automated infrastructure systems. The project also includes classroom innovation, international collaboration, outreach activities through the Museum of Science and Industry in Chicago, and dissemination of open-source software.<br/><br/>The twofold purpose of this project is to develop sequential action control (SAC) into an actionable, near-universal method for synthesizing embedded real-time control as well as to provide foundational results on optimality, stability, and geometry. The method is computationally efficient and scales to high dimensional problems. Moreover, SAC extends naturally to Lie groups, common in applications such as robotics and automation. The project will address three fundamental questions. First, it will identify conditions under which SAC can be applied directly or iteratively to achieve optimal control. Second, it will derive conditions for stability. Third, it will adapt SAC to systems evolving on Lie groups, to achieve global performance for multibody mechanical systems. The broader impacts for this work include outreach, technology transfer to rehabilitation, the development of online courses in dynamics and analysis, and international collaboration. The PI is currently working with the Museum of Science and Industry, and as part of the project the PI, and graduate and undergraduates involved in the PI's laboratory, will participate in a National Robotics Week exhibit in the main rotunda of the museum with an estimated viewership of over ten thousand on-site visitors."
"1527016","NRI: Collaborative Research: Dynamic Robot Guides for Emergency Evacuations","CMMI","National Robotics Initiative","09/01/2015","08/03/2015","Yi Guo","NJ","Stevens Institute of Technology","Standard Grant","Irina Dolinskaya","08/31/2019","$315,274.00","","yguo1@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","ENG","8013","030E, 6840, 8024, 8086, 9102","$0.00","Crowd stampede is one of the most harmful collective human behaviors. In incidents throughout history, panic due, for example, to the outbreak of fire or the unexpected discharge of firearms has been a greater hazard than the original triggering events. This project supports fundamental research on the influence of human-robot interaction on crowd dynamics, towards the design of dynamic robot control algorithms to assist humans and prevent panic in emergency situations. The ultimate goal of this research will be reconfigurable robot guides that can respond to a variety of needs. These include different types of emergency evacuation, as well as non-emergency situations involving mass movement of crowds, such as at parades, concerts, or other large public events. The project integrates research with educational activities through robot-centric education and short course development. To engage the younger generation with science and technology, the project will partner with a university educational center and a community college for various outreach activities.<br/><br/>The objective of the project is to investigate human-robot interaction in crowd dynamics, develop optimal feedback control to regulate human flow distribution, and design robot-assisted emergency evacuation algorithms. The research will advance the state-of-the-art in human-robot interaction, and fill a gap in robotics research by experimentally validating and measuring the interaction forces governing human-robot interaction in crowd dynamics. The proposed robot motion primitive design leads to new approaches for learning-based robot motion planning to efficiently engage humans. The project validates the use of dynamic robot guides in real human-robot interaction experiments in indoor environments. Simulation validation in benchmark environments such as shopping-malls and campus buildings will also be performed, and the efficiency of alternative robot-assisted evacuation strategies will be evaluated. While primarily for intelligent robots, the research results are anticipated to be cross-cutting and applicable to other areas such as transportation, communication, and control."
"1748541","EAGER:   Uncertainty-aware Planning for Robot Navigation in Human Environments","IIS","S&AS - Smart & Autonomous Syst, ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2017","08/04/2017","Stephen Guy","MN","University of Minnesota-Twin Cities","Standard Grant","David Miller","08/31/2019","$170,303.00","","sjguy@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","039Y, 7495, 8013","7495, 7916","$0.00","Robots are increasingly being integrated into society, from service robots to autonomous cars.  To be both safe and efficient, however, they need to better understand how people navigate in unstructured environments and plan paths that take people's own paths into consideration.  The planning methods developed in this project will generate robot paths that satisfy the dual goals of minimizing the robot's risks of collision with people while simultaneously minimizing its expected task completion time. Unique to this work, the robot dynamically estimates how predictable pedestrians are behaving at any point in time and adapts its plans accordingly, automatically taking safer, more conservative, paths when in less predictable situations, and emphasizing efficiency when the situation is more predictable.  The ability for robots to autonomously plan and execute safe, efficient paths in human environments will improve their ability to operate in collaboration with humans, especially in crowded situations, such as in factories, schools, hospitals, or malls.<br/><br/>The navigation method developed follows a sense-plan-predict-act loop where robot plans are computed by finding medium-to-long term trajectories that avoid collision with an expected future distribution of likely obstacle states. The goals of this work split into two tasks: The first improves existing pedestrian path-modeling techniques by augmenting the predictions with estimates of uncertainty.  This is accomplished through an iterative maximum-likelihood framework. The second task finds robot trajectories that minimize a path-cost function, accounting for both control and collision costs, while respecting robot dynamics. This is done using an iterative, gradient-based trajectory optimization approach.  The resulting navigation approach is evaluated in both simulation and on real pedestrian data."
"1752195","CAREER: Modular Origami in Soft Robotic Systems","CMMI","Dynamics, Control and System D","08/01/2018","03/12/2018","Cagdas Onal","MA","Worcester Polytechnic Institute","Standard Grant","Robert Landers","07/31/2023","$500,000.00","","cdonal@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","ENG","7569","030E, 034E, 1045, 8024","$0.00","This Faculty Early Career Development Program (CAREER) project studies new ways to engineer specified mechanical properties into soft robots. Soft robots are intelligent machines with a highly compliant physical structure -- that is, the body of the soft robot will bend when relatively small forces are applied to it. High compliance makes soft robots much safer around people than traditional rigid robots, and also allows soft robots to attain a variety of shapes and to move in many more ways than robots with only a small number of discrete joints. Because structures that are easy to bend cannot carry large loads, a major challenge in soft robotics is to create variable-stiffness structures that are compliant only in certain directions, or only at specific times. This project presents a new approach to engineering variable-stiffness soft robots, inspired by the art and science of ""origami,"" or paper folding. Origami-inspired soft robots use thin sheets of relatively stiff materials that are made bendable along designated fold lines; the folding pattern can be used to create very precise and complex equivalent mechanical properties. This engineered flexibility contrasts with soft robot structures made of materials such as rubbers and foams, which are limited in their achievable strength by the intrinsic softness of the material itself. In this project, origami-inspired folding patterns are used to create modules with a specified compliant behavior. Larger and more capable robots can then be built up by combining many such modules. Examples of the potential of modular origami-inspired robots include soft tentacle-like manipulation in confined spaces, whole-body and passive conformal grasping, and controllable shape change. The results of the project will advance the national health and prosperity, by enabling origami-inspired soft robots to be used in homes, hospitals, and manufacturing sites, as care-givers, co-workers, and self-morphing structures. Educational activities integrated with this project will use origami-inspired robots as teaching tools for students of all ages through outreach activities, high-school internships, and undergraduate projects. <br/><br/>This project will establish modular and scalable design and fabrication methods, characterize and model mechanical properties, and test control algorithms for lightweight origami-inspired modular continuum soft robots to intelligently perform manipulation, grasping, and shape-change tasks. A comprehensive integrated research and education plan will address (1) modular origami design, fabrication, and modeling, to study the mapping between mechanical properties of origami-inspired modules and their design/fabrication parameters, electrically addressable actuation using distributed tendons, distributed soft sensing of 3-D deformation and external forces, and computationally efficient clothoid formulation of continuum section deformations under external loads for dynamic modeling; (2) Control methods that endow soft robots with intelligence, to enable safe force/position interaction with the environment, synergistically combining motion planning and control at the state space, and hyper-redundancy of large scale modular systems to morph into desired shapes with minimal actuation and sensing requirements. Results will be evaluated through validation case studies in continuum arm manipulation, whole-body wrapping and utilizing conformal contact for grasping, and shape change and stiffness control by very large degree-of-freedom origami actuation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1454139","CAREER: Cooperative Control and Decision-Making for Human-Agent Collaborative Teams","CMMI","Dynamics, Control and System D","02/01/2015","01/12/2015","Yue Wang","SC","Clemson University","Standard Grant","Robert Landers","01/31/2020","$500,000.00","","yue6@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","ENG","7569","030E, 034E, 1045, 9102, 9150","$0.00","This Faculty Early Career Development (CAREER) Program grant addresses control and decision-making for human-robot collaborative teams. The project has two main research thrusts. The first thrust examines a team consisting of a skilled human with knowledge of a certain manufacturing or sensing task, and a partially trained robot assistant that is capable of endless repetition without boredom or fatigue. The workload balance between the human and robot is governed by the trust that the human has for the robot, which is modeled mathematically as a function of the rate of improvement in performance and the rate of decrease in number of mistakes. Innovative trust-based algorithms will provide a balanced human experience and guaranteed team performance. The second research thrust will create novel planning strategies incorporating mathematical models of regret, an emotion central to human rational decision-making. Regret-based automatic decision-making aids will provide more human-like decisions for more natural human-robot interaction. Results from both thrusts of the project will ultimately enable transformative human-robot interaction technologies benefitting the U.S. economy and quality of life. The educational initiatives of this project will broaden participation of underrepresented groups in manufacturing and robotics research.<br/><br/>The technical approach entails the integration of trust into cooperative control and regret into decision-making for human-agent collaborative teams. To explore new fundamental understanding of trust and realize effective control allocation, the first thrust will develop new dynamic trust models based on qualitative results from human factors research, and novel trust-based control strategies for human-agent collaborative teams modeled by switched systems. Non-conservative multiple Lyapunov functions based analysis will be developed to provide state-dependent switching control of the manual and autonomous modes. The second thrust features the development of a regret-based Bayesian sequential decision-making framework that selects between the manual and autonomous mode in a way such that suboptimal decisions will be made to avoid the possible regret of making a wrong decision. Both thrusts include experimental validations using a heterogeneous multi-robot test bed and a humanoid manufacturing robot with human-in-the-loop. Results from this research will foster a new interface between control theory and human factors."
"1562911","A Geometric Control Framework for Enabling Behavior-Based Planning and Locomotion of Undulatory Robots","CMMI","Dynamics, Control and System D","06/01/2016","05/01/2017","Patricio Vela","GA","Georgia Tech Research Corporation","Standard Grant","Robert Landers","05/31/2019","$315,867.00","","pvela@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","7569","030E, 031E, 032E, 033E, 034E, 035E, 116E, 8024, 9102, 9178, 9231, 9251","$0.00","Equipped with a slender and over-actuated body, snake-like robots have the ability to maneuver through complex environments. These platforms have been heralded for their locomotive advantages when navigating through rubble, tight spaces, and other areas hard to reach with standard robots. Yet, without a reliably systematic feedback control framework, snake-like robots cannot make the transition from teleoperation to full autonomy. This award will support advances in the dynamic modeling of snake locomotion from fundamental mechanical principles. These models are important for controlling robotic snakes, and other undulatory systems, and will remove a key obstacle to autonomy. The award will also support fundamental research into the role that scales play in snake locomotion, including the creation of robotic snake skin that will enable snake-like robots to realize the locomotive advantages of actual snake scales. The end goal of the project is to demonstrate autonomous snake operation through an unknown environment. Doing so will bring robotic snakes significantly closer to being deployable for search and rescue, inspection, and operation in hazardous environments. The research findings will also apply to similar biologically-inspired robots, such as swimming and flapping-wing flying robots. The popularity of robotics will be leveraged to create engaging educational and outreach activities in promotion of engineering mathematics.<br/><br/>Snake-like robots are high-dimensional, articulated limbless robots that exploit control over a continuous morphological feature to achieve locomotion in a variety of ways. Science has exposed the physical principles underlying locomotion, while engineers have reproduced the fundamental mechanisms and can teleoperate these robots. However the creation of actionable feedback control policies is not fully resolved. What is missing is the physical and mathematical formulation that bridges the gap from achievement of undulatory gaits to the controlled execution of motion along a planned path. To address the gap, this project will design, and demonstrate the performance benefits of, biologically inspired scale fabrication for robotic snakes. The designed scales will reproduce the structural and anistropic friction properties of snake scales. Further, the research will use spatio-temporal averaging to derive reduced control equations for undulatory robotic systems where the body's internal degrees of freedom are modeled in the continuum. Achieving these two objectives will resolve a long-standing achievement gap between biologically inspired, undulatory robots and traditionally engineered robots."
"1544741","CPS: Synergy: Collaborative Research: Learning control sharing strategies for assistive cyber-physical systems","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2015","09/14/2015","Brenna Argall","IL","Rehabilitation Institute of Chicago","Standard Grant","Wendy Nilsen","09/30/2019","$363,937.00","","brenna.argall@northwestern.edu","345 East Superior Street","Chicago","IL","606112654","3122384534","CSE","7918","7918, 8235","$0.00","CPS: Synergy: Collaborative Research: Learning control sharing strategies for assistive cyber-physical systems<br/><br/>Assistive machines - like powered wheelchairs, myoelectric prostheses and robotic arms - promote independence and ability in those with severe motor impairments. As the state- of-the-art in these assistive Cyber-Physical Systems (CPSs) advances, more dexterous and capable machines hold the promise to revolutionize ways in which those with motor impairments can interact within society and with their loved ones, and to care for themselves with independence. However, as these machines become more capable, they often also become more complex. Which raises the question: how to control this added complexity? A new paradigm is proposed for controlling complex assistive Cyber-Physical Systems (CPSs), like robotic arms mounted on wheelchairs, via simple low-dimensional control interfaces that are accessible to persons with severe motor impairments, like 2-D joysticks or 1-D Sip-N-Puff interfaces. Traditional interfaces cover only a portion of the control space, and during teleoperation it is necessary to switch between different control modes to access the full control space. Robotics automation may be leveraged to anticipate when to switch between different control modes. This approach is a departure from the majority of control sharing approaches within assistive domains, which either partition the control space and allocate different portions to the robot and human, or augment the human's control signals to bridge the dimensionality gap. How to best share control within assistive domains remains an open question, and an appealing characteristic of this approach is that the user is kept maximally in control since their signals are not altered or augmented. The public health impact is significant, by increasing the independence of those with severe motor impairments and/or paralysis. Multiple efforts will facilitate large-scale deployment of our results, including a collaboration with Kinova, a manufacturer of assistive robotic arms, and a partnership with Rehabilitation Institute of Chicago. <br/><br/>The proposal introduces a formalism for assistive mode-switching that is grounded in hybrid dynamical systems theory, and aims to ease the burden of teleoperating high-dimensional assistive robots. By modeling this CPS as a hybrid dynamical system, assistance can be modeled as optimization over a desired cost function. The system's uncertainty over the user's goals can be modeled via a Partially Observable Markov Decision Processes. This model provides the natural scaffolding for learning user preferences. Through user studies, this project aims to address the following research questions: (Q1)  Expense: How expensive is mode-switching? (Q2)  Customization Need: Do we need to learn mode-switching from specific users? (Q3)  Learning Assistance: How can we learn mode-switching paradigms from a user? (Q4)  Goal Uncertainty: How should the assistance act under goal uncertainty? How will users respond? The proposal leverages the teams shared expertise in manipulation, algorithm development, and deploying real-world robotic systems. The proposal also leverages the teams complementary strengths on deploying advanced manipulation platforms, robotic motion planning and manipulation, and human-robot comanipulation, and on robot learning from human demonstration, control policy adaptation, and human rehabilitation. The proposed work targets the easier operation of robotic arms by severely paralyzed users. The need to control many degrees of freedom (DoF) gives rise to mode-switching during teleoperation. The switching itself can be cumbersome even with 2- and 3-axis joysticks, and becomes prohibitively so with more limited (1-D) interfaces. Easing the operation of switching not only lowers this burden on those already able to operate robotic arms, but may open use to populations to whom assistive robotic arms are currently inaccessible. This work is clearly synergistic: at the intersection of robotic manipulation, human rehabilitation, control theory, machine learning, human-robot interaction and clinical studies. The project addresses the science of CPS by developing new models of the interaction dynamics between the system and the user, the technology of CPS by developing new interfaces and interaction modalities with strong theoretical foundations, and the engineering of CPS by deploying our algorithms on real robot hardware and extensive studies with able-bodied and users with sprinal cord injuries."
"1526667","NRI: Collaborative Research: Co-Exploration using Science Hypothesis Maps","IIS","National Robotics Initiative","09/01/2015","08/07/2015","David Wettergreen","PA","Carnegie-Mellon University","Standard Grant","Jie Yang","08/31/2019","$857,917.00","","dsw@ri.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","8013","8086","$0.00","This project studies a new approach to exploration. In this approach, the explorer's description of where to go is not prescribed by a path, but instead by a model of what the explorer believes. In the context of a human scientist and robotic explorer working together, this approach transforms the co-robotic relationship into a collaboration in which the human and robot work together to fill in gaps in knowledge to make discoveries. The science hypothesis map is the structure in which human scientists initially describe their belief about the world and in which the belief state evolves as the robotic explorer collects information. <br/><br/>This project addresses a pressing and understudied area of human/robot interaction: it directly tackles the challenges of human scientist interaction with remote robotic explorer by crafting a representation of the environment that is expressive and intuitive for the human while quantifying information to enable meaningful robotic decisions. The hypothesis map formulation is a novel and radical departure from our prior work which has focused on human goal selection and robotic autonomy. It has the potential to revolutionize exploration robotics by changing the nature of the relationship between human and robot from supervisory control to shared information discovery."
"1328722","NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","IIS","National Robotics Initiative","10/01/2013","07/07/2015","Stergios Roumeliotis","MN","University of Minnesota-Twin Cities","Continuing grant","Jie Yang","09/30/2019","$1,499,987.00","Demoz Gebre-Egziabher","stergios@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","8013","7298, 7925, 8086","$0.00","Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation.  The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br/><br/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM."
"1762924","Collaborative Research: Single-Input Control of Large Microrobot Swarms using Serial Addressing for Microassembly and Biomedical Applications","CMMI","Dynamics, Control and System D","06/01/2018","05/16/2018","Igor Paprotny","IL","University of Illinois at Chicago","Standard Grant","Robert Landers","05/31/2021","$366,792.00","Milos Zefran","paprotny@uic.edu","809 S. Marshfield Avenue","CHICAGO","IL","606124305","3129962862","ENG","7569","030E, 034E, 8024","$0.00","This collaborative research project will create a practical control scheme for large swarms of microrobots. These robots are typically no more than a few millimeters in length, and rely on an external power source and control signal. Currently, it is possible to steer the swarm as a whole to a single destination (or perhaps, to a desired average location). However, realizing the full potential benefits of microrobot swarms will require the ability to simultaneously send independent commands, either to individual robots or to small subgroups.  Device designs have previously been explored that respond to different command amplitudes, however this approach quickly becomes impractical as the number of independently addressable robots grows. This scalability problem can be overcome using serial addressing schemes. Here, there are only a few distinct values for the control signal. Each independently addressable subset of robots is associated with a unique sequence of signal values, and will change its behavior only if the control signal contains that specific sequence. This project considers two fundamental issues that arise in implementing such a scheme. First is the need for on-board computation and memory allowing the robots to recognize the unique sequence and to change the robots state based on the detection of such sequence. Second is the need for a propulsive mechanism that couples to the robot state to allow differential guidance towards a target configuration. This project will advance two innovative engineering platforms that meet both needs. The first is electrostatically actuated, operates on a planar substrate, and is suitable for structured tasks such as microassembly. The second is magnetically actuated, operates in a liquid volume, and is suitable for biomedical applications such as drug delivery. The technical aspects of the project are complimented by outreach activities, including an annual microrobotics mobility competition to be held at the IEEE International Conference on Robotics and Automation -- a premier robotics conference for academia and industry. The results from this project will enhance the national health, by enabling new diagnostic and therapeutic uses for microrobot swarms. They will also promote the national prosperity, by enabling new classes of microassembly robots.<br/><br/>This project aims to develop a practical control scheme to simultaneously control large numbers of microrobots. This will be achieved by using microelectromechanical systems (MEMS) to electromechanically and magnetically decode a sequence embedded in the single global control signal, and couple the reconfiguration of such sequence to the modification of the individual microrobot trajectories. This on-board sequence decoding will be accomplished through sets of on-board physics-based finite state machines (PFSM) that can accept a control sequence embedded in the control signal and change the behavior of the microrobots accordingly. The project will use both electrostatic and magnetic approaches to implement PFSMs, and to couple their ""accept"" state to the propulsion mechanism to modulate individual trajectories. Sets of stress-engineered electrostatic switches, which will latch in response to a pre-programmed control voltage sequence, will be used to implement PFSM on the electrostatic platform. Electro-permanent magnetic circuits, which change their magnetic moment in response to a sequence of global magnetic field, will be used to implement PFSM on the magnetic platform. The project will develop the theory for PFSM-based multi-microrobot control, construct both electrostatic and magnetic microrobotic PFSM platforms, and validate the concept by implementing the PFSM-based control on swarms of electrostatically and magnetically powered microrobots. The developed theory and approach will pave way for control of large microrobot swarms for numerous biomedical and microassembly applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1745561","CPS: Synergy: Collaborative Research: Learning control sharing strategies for assistive cyber-physical systems","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","06/01/2017","09/15/2017","Siddhartha Srinivasa","WA","University of Washington","Standard Grant","Wendy Nilsen","09/30/2019","$366,453.00","","siddhartha.srinivasa@gmail.com","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","7918","7918, 8235","$0.00","CPS: Synergy: Collaborative Research: Learning control sharing strategies for assistive cyber-physical systems<br/><br/>Assistive machines - like powered wheelchairs, myoelectric prostheses and robotic arms - promote independence and ability in those with severe motor impairments. As the state- of-the-art in these assistive Cyber-Physical Systems (CPSs) advances, more dexterous and capable machines hold the promise to revolutionize ways in which those with motor impairments can interact within society and with their loved ones, and to care for themselves with independence. However, as these machines become more capable, they often also become more complex. Which raises the question: how to control this added complexity? A new paradigm is proposed for controlling complex assistive Cyber-Physical Systems (CPSs), like robotic arms mounted on wheelchairs, via simple low-dimensional control interfaces that are accessible to persons with severe motor impairments, like 2-D joysticks or 1-D Sip-N-Puff interfaces. Traditional interfaces cover only a portion of the control space, and during teleoperation it is necessary to switch between different control modes to access the full control space. Robotics automation may be leveraged to anticipate when to switch between different control modes. This approach is a departure from the majority of control sharing approaches within assistive domains, which either partition the control space and allocate different portions to the robot and human, or augment the human's control signals to bridge the dimensionality gap. How to best share control within assistive domains remains an open question, and an appealing characteristic of this approach is that the user is kept maximally in control since their signals are not altered or augmented. The public health impact is significant, by increasing the independence of those with severe motor impairments and/or paralysis. Multiple efforts will facilitate large-scale deployment of our results, including a collaboration with Kinova, a manufacturer of assistive robotic arms, and a partnership with Rehabilitation Institute of Chicago. <br/><br/>The proposal introduces a formalism for assistive mode-switching that is grounded in hybrid dynamical systems theory, and aims to ease the burden of teleoperating high-dimensional assistive robots. By modeling this CPS as a hybrid dynamical system, assistance can be modeled as optimization over a desired cost function. The system's uncertainty over the user's goals can be modeled via a Partially Observable Markov Decision Processes. This model provides the natural scaffolding for learning user preferences. Through user studies, this project aims to address the following research questions: (Q1)  Expense: How expensive is mode-switching? (Q2)  Customization Need: Do we need to learn mode-switching from specific users? (Q3)  Learning Assistance: How can we learn mode-switching paradigms from a user? (Q4)  Goal Uncertainty: How should the assistance act under goal uncertainty? How will users respond? The proposal leverages the teams shared expertise in manipulation, algorithm development, and deploying real-world robotic systems. The proposal also leverages the teams complementary strengths on deploying advanced manipulation platforms, robotic motion planning and manipulation, and human-robot comanipulation, and on robot learning from human demonstration, control policy adaptation, and human rehabilitation. The proposed work targets the easier operation of robotic arms by severely paralyzed users. The need to control many degrees of freedom (DoF) gives rise to mode-switching during teleoperation. The switching itself can be cumbersome even with 2- and 3-axis joysticks, and becomes prohibitively so with more limited (1-D) interfaces. Easing the operation of switching not only lowers this burden on those already able to operate robotic arms, but may open use to populations to whom assistive robotic arms are currently inaccessible. This work is clearly synergistic: at the intersection of robotic manipulation, human rehabilitation, control theory, machine learning, human-robot interaction and clinical studies. The project addresses the science of CPS by developing new models of the interaction dynamics between the system and the user, the technology of CPS by developing new interfaces and interaction modalities with strong theoretical foundations, and the engineering of CPS by deploying our algorithms on real robot hardware and extensive studies with able-bodied and users with sprinal cord injuries."
"1426968","NRI: Collaborative Research: Human-Supervised Perception and Grasping in Clutter","IIS","COLLABORATIVE RESEARCH, Cyber-Human Systems (CHS), IIS SPECIAL PROJECTS, National Robotics Initiative","08/15/2014","06/28/2017","Holly Yanco","MA","University of Massachusetts Lowell","Standard Grant","Ephraim P. Glinert","01/31/2019","$577,607.00","","holly@cs.uml.edu","600 Suffolk Street","Lowell","MA","018543643","9789344170","CSE","7298, 7367, 7484, 8013","5948, 8086, 9251","$0.00","One of the basic building blocks in semi-autonomous manipulation is the ability for a robot to grasp an object that a human operator indicates.  There are many tasks where the natural way for a human and robot to work together is for the human to point out the approximate locations of objects to be grasped and for the robot to generate the precise motions necessary to achieve the grasp.  This core ""auto-grasp"" functionality is critical to providing assistive manipulation for the disabled and elderly, as well as for a variety of military, police, space, or underwater applications. But implementing auto-grasp capability can be challenging in situations where the environment is cluttered, or when it is difficult to determine the grasp intention of the human.  In this collaborative project that combines expertise from two institutions, the PIs will tackle situations where it is necessary for the robot to actively explore or ""interrogate"" the environment in order to figure out what the human intends to grasp and how the robot should do it.  To these ends, the PIs will investigate a modified approach to planning under uncertainty known as belief space planning.  Belief space planning is well-suited to active localization for grasping, because it is a single framework in which the algorithm can reason about perception-oriented and goal-orientation parts of the task.  The PIs will use belief space planning to localize graspable geometries in the environment, known as grasp affordances, in a region indicated by the user.  They will also explore different ways in which a human can interact with the system in order to control the grasping.  The application focus of the work will be in assistive manipulation, where a person who is elderly or disabled operates an assistive robot arm mounted on an electric wheelchair or scooter.  User studies will determine the best methods for the target population to operate the system.  The project will contribute to the opportunities available for undergraduates and high school students in the PIs' institutions, and it will also be integrated as appropriate into the curricula of the courses they teach.<br/><br/>This research contains two key innovations that the PIs expect will make robot grasping more robust.  The first is to incorporate ideas from belief space planning into the reach and grasp planning process.  Because belief space planning can reason about how the robot's own ""state of information"" is expected to change in the future, it is capable of producing plans that acquire task-relevant information in the course of performing a task.  The second innovation is a new approach to perception-for-grasping that localizes grasp affordance geometries in the neighborhoods of objects of potential interest.  Not only is this grasp affordance approach helpful to the belief space planner, but the PIs' preliminary work indicates that this approach can be accurate and very fast (10Hz).  Finally, the connection between the user interface and uncertainty in the location of the grasp target will also be explored, the plan being to model human behavior as an uncertain system where hidden variables describe user intention."
"1657186","CRII: RI: Practical Algorithms for Robust Feedback Motion Planning Through Contact","IIS","CRII CISE Research Initiation","09/01/2017","02/28/2017","Scott Kuindersma","MA","Harvard University","Standard Grant","David Miller","08/31/2019","$175,000.00","","scottk@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","026Y","7495, 8228","$0.00","Despite significant progress in robot motion planning and control, modern robots still struggle to operate robustly in the presence of unplanned disturbances, state uncertainty, and model errors. Indeed, the recent DARPA Robotics Challenge dramatically demonstrated that some of the world's most advanced robots still minimize contact with their environments and fail often in realistic operating scenarios. This creates a significant barrier to unleashing robots into critical disaster response, exploration, and industrial applications. Algorithms that explicitly reason about robustness require a coupling of motion planning and feedback design, in which the system's closed-loop response to disturbance sources is optimized. Due to the often heavy computational demands of solving such problems, their application to modern field robots has so far been limited.<br/><br/>The research objective of this proposal is to address the theoretical, computational, and applied challenges of robust motion planning for robots with nonlinear dynamics and state and input constraints, including constraints arising from frictional contact. The algorithms under consideration in this research will build on direct trajectory optimization methods to simultaneously 1) support complex state constraints and rigid-body contacts and 2) exploit mathematical structure in disturbance and feedback controller sets to construct computationally-efficient algorithms. The ability of these algorithms to improve stability in tasks of broad interest, such as bipedal walking, will be investigated. Algorithms will be evaluated against state-of-the-art methods in locomotion and manipulation experiments on physical robots."
"1637809","Understanding the Influence of a Teachable Robot on STEM Skills and Attitudes","IIS","ITEST","10/01/2016","09/06/2018","Erin Walker","AZ","Arizona State University","Standard Grant","David Haury","09/30/2019","$156,074.00","","Erin.A.Walker@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7227","8086, 9251","$0.00","This National Robotics Initiative project will develop a robotic learning environment for middle school geometry students where students who are novices in geometry will learn new concepts by tutoring a humanoid robot to manipulate its gestures and spoken prompts in response to student utterances and problem-solving actions.  The project is based on the principle that the act of tutoring can lead to motivational benefits such as student engagement, positive attitudes toward the subject being studied, and increased confidence.  In this application, the robot is simultaneously a tool that students can program and a social actor that intelligently responds.  This research project will engage a broadly diverse population and is aimed at increasing the participation and retention of underrepresented groups in fields of science, technology, engineering, and mathematics (STEM). There are three components to the broader impacts of this project: 1) Scientific understanding of how robotic learning companions affect STEM attitudes and confidence, 2) Learning among students from traditionally underrepresented groups in the research process, and 3) Creation of a human-robot interaction platform for education and experimentation. The principles discovered through this project are expected to promote increased  participation of women and other underrepresented populations in STEM educational activities and STEM-related careers.<br/><br/>The goals of this research are to link robot behaviors to mediating motivational factors and STEM outcomes with the ultimate goal of understanding how to manipulate robot behaviors to improve a learning interaction. The proposed research will make contributions to understanding of how robotic learning environments can be designed to have a transformative impact on STEM learning.  The research is guided by two questions:  1) How do robot behaviors influence students' mediating motivational factors and affect STEM skills and attitudes?  And 2) What is the impact of adapting robot behaviors to student behaviors on mediating variables and STEM skills and outcomes?  To find answers to these questions, the project will undertake three initiatives: 1) Further development of NaoTAG (Nao Tangible Activities for Geometry) to serve as a platform for experimenting with how different aspects of robot behaviors influence student-robot interactions within the teachable agent context; 2) Understand how student and robot behaviors influence the mediating factors that have identified, and STEM skills and outcomes; and 3) Modeling student-robot interactions."
"1562612","Designing Certified Controllers to Prevent Falls for Legged Robots","CMMI","Dynamics, Control and System D","07/01/2016","07/10/2016","Ramanarayan Vasudevan","MI","University of Michigan Ann Arbor","Standard Grant","Robert Landers","06/30/2019","$375,000.00","C. David Remy","ramv@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","7569","030E, 031E, 032E, 033E, 034E, 035E, 039E, 040E, 099E, 1059, 7234, 8024","$0.00","This project will investigate controllers for legged robots that work reliably despite lacking full information about operating conditions, including uncertainty about terrain and robot properties. The approach differs from previous approaches in that the focus is entirely on maintaining balance. There are three integrated research tasks. First is creation of a feasible algorithm to determine starting positions of a legged robot from which falling can be avoided. Second is pre-computation of a so-called ""safe set"" of control inputs that is guaranteed to avoid falling. Both these tasks embed the hybrid, nonlinear dynamics of walking into a linear partial differential equation, which is propagated backwards in time from a set of acceptable final states to incorporate the effects of uncertainty. The third task is experimental evaluation of the results using a reconfigurable legged robot platform. As part of the third task, a human operator will be allowed to give arbitrary commands to a legged robot. A command filter will modify the user input so that it lies within the safe set. Thus the operator will be able to give any command without the robot falling. Legged robotic systems are an ideal candidate for search and rescue missions or nuclear power plant repair or disassembly. However successful teleoperation of such systems is challenging. Thus guaranteed safe operation will make these systems a viable means of keeping first responders out of harm's way. The techniques under study can be extended to other fields of robotics, such as active prostheses or exoskeletons, thereby benefitting the lives of those suffering from loss of mobility.<br/><br/>This project will construct a novel optimization scheme for automated control synthesis to provide deterministic guarantees on the safety of a legged robotic system in the presence of model uncertainty. Rather than rely upon linearizations or assume arbitrary control authority, the approach considered in this project will address the following three aims: First, a new convex optimization tool to efficiently compute the set of states of a legged robotic system that have less than a user specified probability of avoiding falls in spite of uncertainty in the continuous and contact dynamics. Second, a novel control synthesis tool to pre-compute the set of controls that prevent falls for the set of states that can avoid falling. Finally, an interactive real-world setup wherein users can apply arbitrary inputs to a legged robot which are then modified to ensure safe operation across a variety of terrains; this setup will validate the robust synthesis method while allowing modelers to confidently explore configurations of a legged robot that have been rarely considered to date due to the limitations of existing control design techniques."
"1536035","Design, Control and Optimization of Robotic Systems with Energy Regeneration","CMMI","ENGINEERING DESIGN AND INNOVAT, Dynamics, Control and System D","09/01/2015","08/30/2015","Hanz Richter","OH","Cleveland State University","Standard Grant","Robert Landers","08/31/2019","$202,467.00","","h.richter@csuohio.edu","2121 Euclid Avenue","Cleveland","OH","441152214","2166873630","ENG","1464, 7569","030E, 031E, 032E, 033E, 034E, 035E, 067E, 068E, 073E, 1464, 7569, 8024, 9102","$0.00","Many industrial, consumer and medical products involve masses in motion. These motions are powered from energy sources, and always involve cycles of acceleration and deceleration. Conventional braking is a very inefficient method of deceleration because the object's energy is wasted as heat. In contrast, regeneration involves surplus energy capture and storage into the power supply. Regeneration engineering is advanced and visible in electric and hybrid vehicles, but its understanding and optimal utilization in mobile and industrial robotics remains a challenging area of research. The outcomes of this research have the potential for significant energy savings in industrial installations where many robots are in use. Mobile biomedical devices powered from electric energy sources such as wheelchairs, prostheses and exoskeletons are another target application of this research. Optimal energy utilization in these devices will translate into lighter units with a reduced need for frequent recharging. Impaired people wearing advanced regenerative prostheses will be able to extend the range of their daily activities, improving their quality of life.<br/><br/>This research will introduce a systematic treatment of general motion control problems with explicit consideration of bidirectional energy flow. The intellectual significance of the project is centered in its generality and broad applicability, which contrasts with the mostly case-oriented current literature on regenerative systems. The project focuses on the use of ultracapacitors as key elements of advanced regenerative systems. In comparison to batteries, ultracapacitors have very high power densities. This means that energy extraction and return can be achieved at fast rates. This feature affords great flexibility to alter a robot's dynamic behavior by means of control, in particular its mechanical impedance. Moreover, recent advances in graphene-based ultracapacitors have resulted in devices with energy densities approaching those of lithium-ion batteries. These advances have the potential for the elimination of batteries in certain mobile robotic systems, particularly in medical assistive devices. The project will establish a framework to design, control and optimize such systems. The project has three goals: 1. development of new approaches for modeling, control and design of robotic systems with advanced regenerative hardware such as ultracapacitors; 2. formulation and solution of fundamental energy-motion multi-objective optimization problems for the same; 3. bridging of theory and practice with a custom-built study robot."
"1526327","NRI: Instructional Materials for Soft Co-Robot Design to Improve Motivation and Learning in STEM Classrooms","IIS","ITEST","09/01/2015","08/11/2015","Conor Walsh","MA","Harvard University","Standard Grant","David Haury","08/31/2019","$398,503.00","Donal Holland","walsh@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","7227","8086","$0.00","This National Robotics Initiative (NRI) project conducted at the School of Engineering and Applied Sciences, Wyss Institute for Biologically Inspired Engineering, Harvard University will develop a set of instructional materials and related design competitions focused on the design of soft, co-robotic devices, and to evaluate their impact upon students' attitudes towards and understanding of engineering and science subjects through online instruments for large-scale data collection.  Introductory robotics teaching and outreach typically focuses on task-based applications in which robots are isolated from humans, rather than closely cooperating with them. Combining soft robotic technology with applications involving human interaction and the use of social and people-centric applications is expected to attract a more diverse population to the study of STEM (science, technology, mathematics, and engineering) subjects.  The proposed research incorporates a substantial mechanical design component with the aim of engaging students interested in this topic, who are not served by education and outreach programs that typically emphasize the software and electronic aspects of robotics design. <br/><br/>This project will expose learners to subjects typically neglected in introductory robotic design experiences, such as material selection and manufacturing, and encourage participation by students with a broader range of interests and aptitudes. To evaluate the impact of the proposed instructional materials and design competitions, this research will include an emphasis on instruments for data collection and evaluation by drawing on best practice in evaluation and combining tools that have been developed, tested, and validated in the literature into a single online platform that will be shared publicly with educators and researchers.  The proposed research will contribute to an improved understanding of the factors influencing high school and undergraduate students' motivation to pursue STEM careers, and in particular the influence of application areas on students' perception of science and technology.  The compilation of a set of data collection and evaluation instruments will result in a platform for quantifying the impact of this research as well as other approaches to robotics education and outreach."
"1830950","EFRI C3 SoRo: Strong Soft Robots--Multiscale Burrowing and Inverse Design","EFMA","SPECIAL INITIATIVES, EFRI RESEARCH PROJECTS","09/15/2018","09/05/2018","Timothy Kowalewski","MN","University of Minnesota-Twin Cities","Standard Grant","Jordan Berg","08/31/2022","$1,977,501.00","Sridhar Kota, Emmanuel Detournay, James Van de Ven, Chris Ellison","timk@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","ENG","1642, 7633","7633","$0.00","This project directly addresses major challenges facing the emerging field of soft robotics. Soft robots are made of inherently compliant materials that are soft, flexible, and move gracefully in three dimensions without requiring discrete joints. However, these highly compliant soft bodies may prove too weak to exert sufficiently large forces to accomplish desired tasks. Additionally, there is a general lack of understanding of how to best navigate the bewildering spectrum of materials, configurations, and designs available to soft robotics. This project explores the properties of 3D-printable polyurethane polymers that can be customized to provide different mechanical properties. This project will create mathematical models of highly deformable structures, and computational tools to solve the ""inverse problem"" of finding the material parameters and 3D printing pattern that achieve a specified structural behavior. The project will consider two currently infeasible tasks at greatly different length scales. Task 1 is a millimeter-scale patient-specific soft robot catheter for neurovascular and cardiovascular applications, where the robots can gently move through blood vessels without requiring risky surgery, blocking blood flow, or injuring the patient. Task 2 is a meter-scale robot that intelligently burrows underground, with force levels much higher than previously attained by soft robots. Soft robots in the vascular application can inform potential breakthroughs for the treatment of heart disease and stroke. Large burrowing robots could prove beneficial for inspecting underground civil infrastructure or laying new fiber optic cable, irrigation, or power lines. This project is also designed to engage high school students, and inspire them to pursue STEM careers, including future roboticists.<br/><br/>This project will establish and validate a mathematical framework for the inverse design of universal soft robots that: 1) provide sophisticated 3-D kinematics by further generalizing fiber-reinforced elastomeric enclosures with beam elements and arbitrary shapes along with exceptional force and power densities that match well-known McKibben actuators; 2) achieve arbitrarily-specified tasks and performance requirements including novel multiscale burrowing behavior; and 3) dictate a new means of robotic, automated manufacturing via 3D printed materials exploiting highly anisotropic elastomers, inextensible fibers, and beam elements and their interfacial chemistries.  This mathematical formalism generalizes traditional robot kinematics via a full body mapping incorporating dynamic, arbitrary shape sequences specified by an arbitrary desired task. The coupled innovation in polyurethane chemistry and manufacturing will enable soft robots that exceed the capabilities of existing soft robots and overcome fundamental limitations in their capacity to exert useful force, modulate stiffness, and achieve previously-impossible tasks. This project includes validation experiments on two specific testbeds: (1) millimeter-scale soft robot catheters that locomote through vascular networks, and (2) meter-scale burrowing robots in soils, capable of inferring soil properties to adapt their morphology and motion to suit conditions in naturally occurring, highly heterogeneous, soil deposits.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830388","NRI: INT: COLLAB: Soft Active Contact Pads with Tunable Stiffness and Adhesion for Customizable Robotic Grasping","CMMI","National Robotics Initiative","09/15/2018","09/04/2018","Wanliang Shan","NV","Board of Regents, NSHE, obo University of Nevada, Reno","Standard Grant","Atul G. Kelkar","08/31/2021","$340,879.00","","wshan@unr.edu","1664 North Virginia Street","Reno","NV","895570001","7757844040","ENG","8013","030E, 034E, 063Z, 8024, 8086","$0.00","As robots have a greater presence in our personal, public, and working environments, they must be equipped for a broad range of manipulation tasks and physical encounters.  For many of these activities, such robots must be able to grasp a wide variety of everyday objects or be capable of physical interactions with humans or other robots. While there are robotic grippers (""end effectors"") well-suited for specific tasks, progress in cooperative robotics has been limited by a lack of ""universal"" gripping systems that can handle a diverse set of objects. Universal gripping systems have the potential to dramatically improve robot performance and reduce costs by decreasing the number of end effectors that a robot needs for general purpose functionality. This National Robotics Initiative (NRI) project will address this critical need by creating new material architectures that enable universal robotic grasping. This will be accomplished by using materials that are capable of changing their mechanical properties such as stiffness and adhesion, and incorporating these materials into contact pads that the robot will use for gripping. This work will promote domestic economic growth and well-being by impacting multiple sectors in which cooperative robots will have an important role, including manufacturing, aerospace, agriculture, elderly care, and rehabilitation. This project will also contribute to educational outreach through middle/high school student workshops and science events that will inspire students to learn more about the role of materials in soft and human-friendly robotics. <br/><br/>The ultimate goal of this project is to realize a customizable robotic gripper that can operate in a broad range of contexts. To achieve this, the research team will pursue the following three interrelated research objectives.  The first is to investigate the interplay between material stiffness, surface geometry, and the loading conditions that typically arise during robotic manipulation. This will include the development of adhesion-controlled robotic grasping approaches that exploit materials and structures with tunable stiffness and adhesion.  The second objective is to engineer active contact pads that allow for high adhesive gripping forces and also high adhesion tunability. These pads will exploit a careful understanding of how material properties influence the distribution of mechanical stresses between contacting surfaces.  The third objective is to integrate the soft contact pads into robotic end-effectors or the fingertips of a robotic hand. As part of this effort, the team will demonstrate enhancements in gripping performance and versatility through a comparative study involving objects with a broad range of shapes, sizes, weights, and mechanical properties.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830901","EFRI C3 SoRo: Soft, Strong, and Safe Configurable Robots for Diverse Manipulation Tasks","EFMA","EFRI RESEARCH PROJECTS, ","09/01/2018","08/16/2018","Daniela Rus","MA","Massachusetts Institute of Technology","Standard Grant","Jordan Berg","08/31/2022","$2,000,000.00","Lakshminarayana Mahadevan, Robert Wood, Russell Tedrake","rus@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","ENG","7633, R277","7633","$0.00","This project seeks to extend our understanding of the principles underlying the design and control of effective soft robots. Soft robots and muscle-like soft actuators coupled with agile control strategies will enable new manipulation and locomotion capabilities currently only found in nature, and allow robots and humans to safely collaborate. Today's industrial manipulators enable rapid and precise assembly, but these robots are physically isolated, to ensure the safety of any humans nearby. In contrast, the bodies of soft robots are made of intrinsically soft and/or extensible materials, such as silicone rubbers or fabrics, and are therefore safe for interaction with humans and animals. Soft robots have a continuously deformable structure with muscle-like actuation that emulates key features of biological systems and provides them with a relatively large number of degrees of freedom as compared to their hard-bodied counterparts. Soft robots have capabilities beyond what is possible with today's rigid-bodied robots. For example, soft-bodied robots can move in more natural ways that include complex bending and twisting curvatures that are not restricted to the traditional rigid body kinematics of existing robotic manipulators. Their bodies can deform in a continuous way, providing theoretically infinite degrees of freedom and allowing them to adapt their shape to their task, for example, conforming to natural terrain or forming enveloping grasps. Soft robots have also been shown to be capable of rapid agile maneuvers and can change their stiffness to achieve a task- or environment-specific impedance. Current research on device-level and algorithmic aspects of soft robots has resulted in a range of novel soft devices. This project will derive a systematic mathematical framework to model and control soft robots and will use the resulting algorithms to perform manipulation tasks with a wide variety of delicacy and strength requirements. The results will have potential uses in manufacturing, warehouse and supply chain automation, and everyday home activities such as cooking and cleaning. These soft, strong, and safe robots will have potential application in assisted care for the elderly or disabled, and for physical therapy. This project uses the unique features of soft robots to continue the Principal Investigators' track record of outreach and educational activities that excite young students about STEM careers.<br/><br/>In the recent past, the soft robotics community has explored many different component hardware technologies, however fundamental algorithmic obstacles to their practical use remain challenging. Currently there is an artificial divide between control strategies for rigid and soft robots; rigid robots use high-bandwidth control of contact forces and contact geometry, while soft robots rely almost entirely on open-loop interactions, mediated by material properties, to govern the resulting forces and configurations. This project will bridge this gap by developing optimization-based control for soft robots, via approximate dynamic models of the soft interface, based on representations with a fidelity customized to the task. The proposed class of soft, strong, and safe robots will be designed, fabricated, and controlled by co-developing muscle-like actuation along with internal and contact models and associated planning and control strategies. An innovative new artificial muscle design allows customization of actuators to specific tasks, through systematic modular design. The modeling effort will focus on contact-rich behaviors of the soft robot with the environment, both for delicate touch and manipulation, and for high-force power grasps. Such a combination of soft and strong has not been fully addressed in the soft robotics community and will allow soft robots to interact safely and effectively with people in unprecedented applications.<br/><br/>This project is jointly sponsored by the National Science Foundation, Office of Emerging Frontiers and Multidisciplinary Activities (EFMA) and the US Air Force Office of Scientific Research (AFOSR).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1808051","Combining Optimization, Machine Learning, and Model Structure to Improve the Robustness and Agility of Modern Bipedal Machines","ECCS","ENERGY,POWER,ADAPTIVE SYS, National Robotics Initiative","08/15/2018","08/15/2018","Jessy Grizzle","MI","University of Michigan Ann Arbor","Standard Grant","Radhakisan S. Baheti","07/31/2021","$400,000.00","","grizzle@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","7607, 8013","092E, 8013","$0.00","Bipedal robots are being built to aid in search and rescue, provide last mile delivery of packages, and to assist people in their homes. Lower-limb exoskeletons are being designed to help patients recover the ability to walk after strokes or even severe injuries resulting in paralysis. While the feedback control algorithms required to allow a bipedal robot to walk and a patient to safely operate a lower-limb exoskeleton are not identical, they share enough common elements that pursing their investigation in tandem is insightful and important. This project combines recent advances in the ability to quickly compute energy optimal solutions of bipedal dynamical systems with the mathematics of machine learning and geometric control theory to achieve unprecedented performance and safety in bipedal walking. The proposed research will greatly expand the class of robots for which feedback controllers can be designed with provable stability and it will significantly enhance the safety than can be achieved with exoskeletons that allow a paraplegic to walk without the use of crutches. One of the many technical challenges to be overcome in this research is the complexity of the mathematical models that describe the movement these legged machines. For example, printing out the symbolic model for the exoskeleton studied here would take thousands of pages. If a human ever opened the files to examine them, they would be incomprehensible. Yet, the PI and his students provide concrete means for designing feedback controllers for these machines and say deep things about how the closed-loop system will behave. This is the beauty of feedback control theory when it is married with modern computational tools. In addition, each year, the PI and his students share the excitement of engineering by giving tours of his robotics lab to hundreds of students, from grade school through high school, sharing the excitement and personal fulfillment of careers in STEM fields. Presidents of major universities and management teams of corporations visit his lab for the pure pleasure of seeing a robot doing something amazing and yet at the same time, almost ordinary: walking roughly like a human. The PI works with the media to share with the general public the excitement of cutting-edge engineering research and how it benefits society. <br/><br/>The project seeks major advances in the theoretical conception and practical synthesis of feedback controllers for bipedal robots and lower-limb exoskeletons. The theory will be carefully tested on a Cassie-series bipedal robot and an exoskeleton. The theoretical thrust of the proposal aims to mitigate obstructions imposed by high-dimensional bipedal models (dimension 30 or more), without resorting to simplified pendulum models that are all too common in the robotics literature. The research seeks to work directly with the full model of the robot, making it possible to generate motions that exploit its full capabilities while respecting actuator limitations, ground contact forces, and terrain variability.  The process begins with trajectory optimization to design an open-loop periodic walking motion of the high-dimensional model, and then adding to this solution, a carefully selected set of additional open-loop trajectories of the model that steer toward the nominal motion. Supervised Machine Learning is used to extract from the open-loop behavior (i.e., the collection of input and state trajectories) a low-dimensional state-variable realization (i.e., a low-dimensional manifold and associated vector field). The special structure of mechanical models of bipedal robots is used to embed the low-dimensional model in the original model in such a manner that it is both invariant and locally exponentially attractive, and show that this locally exponentially stabilizes the desired walking motion in the full state space of the robot. Transitions among periodic orbits will also be addressed.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1724399","S&AS: FND: COLLAB: Planning and Control of Heterogeneous Robot Teams for Ocean Monitoring","IIS","S&AS - Smart & Autonomous Syst","09/01/2017","08/21/2017","Nora Ayanian","CA","University of Southern California","Standard Grant","Jie Yang","08/31/2020","$353,063.00","","ayanian@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","039Y","046Z, 9102","$0.00","Robots in marine and littoral environments are envisioned for commerce, scientific exploration, search and rescue, and many other tasks. However, robots in such environments face significant challenges. Vehicles must act and effect change in environments with large inertial effects and disturbances, with only near-field perception. Coupled with our limited understanding of ocean dynamics and the lack of accessible and high-quality ocean flow data, these obstacles make the use of robotics technology in these varied applications extremely difficult. This project realizes an integrated, heterogeneous robotic approach towards large-scale ocean monitoring for environmental mitigation and search and rescue operations. It enables data-driven tracking and mapping of various physical, chemical, and/or biological processes of interest in marine environments, such as tracking contaminant dispersion or missing aircraft. This project significantly improves the state of the art in ocean search and monitoring technology, helping us understand and harness ocean currents, and improve the health of the world's oceans. Results from the project are integrated into education, through the PIs' courses, mentoring students on research, and expanding an existing K-12 outreach relationship. <br/> <br/>The project creates fundamental knowledge about new ways that robots can better monitor, sense, and operate in dynamic and uncertain environments. The project develops new methods for heterogeneous teams of monitoring robots to improve their environment model through current interactions with the environment; concurrently collect data, process and assimilate it into the existing model, and plan on that model; accept high-level instruction and translate goal-oriented directives such as environmental monitoring into a suitable plan for sensing, reasoning, communicating, and acting through the underlying system architecture; and monitor their actions, optimize, and reconfigure autonomously. The heterogeneous team of robots proposed includes surface vehicles providing samples at the air-sea interface and aerial robots creating flow models and acting as intermediaries within the team. The hierarchical structure of the approach takes advantage of the natural boundaries defined by Lagrangian coherent structures in the creation of a distributed sensing framework."
"1454472","CAREER: Soft Robotics for Upper Extremity Rehabilitation","CBET","Disability & Rehab Engineering, COLLABORATIVE RESEARCH","05/01/2015","12/22/2017","Conor Walsh","MA","Harvard University","Standard Grant","Aleksandr Simonian","04/30/2020","$509,677.00","","walsh@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","ENG","5342, 7298","010E, 082P, 1045, 5921, 5978","$0.00","CAREER: Soft Robotics for Upper Extremity Rehabilitation<br/><br/>In terms of upper extremity disabilities, the Americans with Disabilities 2010 report found that 6.7 million people reported difficulty grasping objects like a glass or pencil. These disabilities are a result of a wide variety of conditions (e.g. traumatic injury, stroke, cerebral palsy, burns and arthritis) and in nearly all cases rehabilitation therapy is desirable in order to improve motor function. This CAREER Award proposes to develop a soft wearable robot that can be used for hand rehabilitation. Compared to conventional therapy, this technology will enable more controlled and automated therapy by allowing precise control over the motions and forces that are applied to the fingers and thumb. The use of soft robotics offers advantages over traditional robotics and this work focuses on the development of a soft wearable actuated glove and embedded sensor system, which addresses some of the known challenges in implementing such a system with traditional rigid robotic components (i.e. alignment, weight). Additionally, the sensors embedded in the device will enable control over the assistance applied to the wearer and additionally, monitoring of the activities for the therapist. Present occupational and therapy is inherently expensive and the dosage (or number of visits) for patients is limited. With effective wearable robotic systems that can be used in the clinic and home, more frequent but shorter and more focused therapy may increase the speed of patient recovery and positively impact the productivity of therapists.<br/><br/>This CAREER Award proposes to shift the paradigm of rehabilitation from one where the therapist manipulates the fingers and thumb through some range of motion, to one where a lightweight, comfortable and soft robotic glove can provide high dose rehabilitation in either a continuous passive motion mode or in a functional assistance mode. This will be achieved through new soft actuators with integrated sensors that can comfortably apply forces to the wearer and integrated functional prototypes that will be evaluated on patients in collaboration with clinical partners. This work will advance soft actuator designs that are mechanically programmed to match the complex motions of the human fingers and thumb. This will be achieved by creating anisotropy in the bulk material properties enabling combinations of contraction, extension, bending and twisting to be achieved. These actuators are of interest to the community because they are lightweight, inexpensive, and capable of complex functionality. Low-level closed-loop controllers will be implemented on individual actuators to control their position and the force they apply and in addition different control strategies for intuitive human-robot interaction will be explored. Patients and therapists will be involved at all stages of the project and pilot studies on patients will be performed to demonstrate the potential of this technology."
"1830362","NRI: INT: COLLAB: Soft Active Contact Pads with Tunable Stiffness and Adhesion for Customizable Robotic Grasping","CMMI","National Robotics Initiative","09/15/2018","09/04/2018","Carmel Majidi","PA","Carnegie-Mellon University","Standard Grant","Atul G. Kelkar","08/31/2021","$369,849.00","","cmajidi@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","8013","030E, 034E, 063Z, 8024, 8086","$0.00","As robots have a greater presence in our personal, public, and working environments, they must be equipped for a broad range of manipulation tasks and physical encounters.  For many of these activities, such robots must be able to grasp a wide variety of everyday objects or be capable of physical interactions with humans or other robots. While there are robotic grippers (""end effectors"") well-suited for specific tasks, progress in cooperative robotics has been limited by a lack of ""universal"" gripping systems that can handle a diverse set of objects. Universal gripping systems have the potential to dramatically improve robot performance and reduce costs by decreasing the number of end effectors that a robot needs for general purpose functionality. This National Robotics Initiative (NRI) project will address this critical need by creating new material architectures that enable universal robotic grasping. This will be accomplished by using materials that are capable of changing their mechanical properties such as stiffness and adhesion, and incorporating these materials into contact pads that the robot will use for gripping. This work will promote domestic economic growth and well-being by impacting multiple sectors in which cooperative robots will have an important role, including manufacturing, aerospace, agriculture, elderly care, and rehabilitation. This project will also contribute to educational outreach through middle/high school student workshops and science events that will inspire students to learn more about the role of materials in soft and human-friendly robotics. <br/><br/>The ultimate goal of this project is to realize a customizable robotic gripper that can operate in a broad range of contexts. To achieve this, the research team will pursue the following three interrelated research objectives.  The first is to investigate the interplay between material stiffness, surface geometry, and the loading conditions that typically arise during robotic manipulation. This will include the development of adhesion-controlled robotic grasping approaches that exploit materials and structures with tunable stiffness and adhesion.  The second objective is to engineer active contact pads that allow for high adhesive gripping forces and also high adhesion tunability. These pads will exploit a careful understanding of how material properties influence the distribution of mechanical stresses between contacting surfaces.  The third objective is to integrate the soft contact pads into robotic end-effectors or the fingertips of a robotic hand. As part of this effort, the team will demonstrate enhancements in gripping performance and versatility through a comparative study involving objects with a broad range of shapes, sizes, weights, and mechanical properties.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1750489","CAREER: Towards General-Purpose Manipulation of Deformable Objects through Control and Motion Planning with Distance Constraints","IIS","ROBUST INTELLIGENCE","04/01/2018","03/22/2018","Dmitry Berenson","MI","University of Michigan Ann Arbor","Continuing grant","Reid Simmons","03/31/2023","$102,036.00","","berenson@eecs.umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","7495","1045, 7495","$0.00","This project seeks to advance the capabilities of autonomous robots in environments such as factories, hospitals, and homes. To be effective in such settings, robots need to manipulate many kinds of deformable objects, such as cloth, string or wires, and plant or animal tissue.  Giving robots the ability to manipulate such objects has the potential to revolutionize the use of robots in several application domains: In manufacturing, allowing robots to pack boxes and handle food and fabric; in medicine, allowing robots to perform tedious tasks in surgery and make hospital beds; and in service, allowing robots to handle clothes and prepare food. However, such tasks are beyond the current state-of-the-art, largely because deformable objects are difficult to model and control.  This project will develop new theory, validated with extensive experimentation, that aims to model deformable objects in ways that are amenable to both planning and control. This project will also use manipulation of deformable objects as a motivating problem for students studying robotics at the undergraduate and graduate levels, and in K-12 outreach.<br/><br/>This project investigates the fundamentals of modeling, control, and motion planning for deformable objects. This problem is challenging because deformable objects have large state spaces, are extremely-underactuated, and motion planning for these objects requires numerical simulation, which can be computationally expensive and inaccurate. The main hypothesis of this project is that these challenges can be overcome by representing the object and task in terms of distance constraints, which represent allowable distances between parts of the deformable object as well as between the object and parts of the environment, and formulating control and planning methods based on this representation. The expected outcome of this research is an enhanced ability of robots to perform useful tasks, based on a better understanding of deformable object manipulation and a set of broadly-applicable experimentally-verified controllers, planning building-blocks, and planning algorithms.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1605635","Soft-Robotic Glove for Cerebral Palsy Hand Rehabilitation (REHAB Glove)","CBET","Disability & Rehab Engineering","09/01/2016","12/15/2017","Rita Patterson","TX","University of North Texas Health Science Center at Fort Worth","Standard Grant","Aleksandr Simonian","08/31/2019","$315,993.00","Nicoleta Bugnariu, Muthu Wijesundara, Wei Carrigan, Mahdi Haghshenas-Jaryani","rita.patterson@unthsc.edu","3500 Camp Bowie Blvd.","Fort Worth","TX","761072699","8177355073","ENG","5342","9102, 9251","$0.00","Cerebral Palsy (CP) is a birth related brain injury affecting functional activities of persons throughout the life span. Many children with CP have some form of upper extremity limitations. Reduced function of the hands hinder dressing, personal hygiene, and use of assistive devices, resulting in greater dependency, restricted social participation, and a decreased quality of life. Recent investigations have indicated that the brain is capable of reorganizing itself through targeted use. Functional recovery requires repeated practice, however traditional therapy sessions are inadequate in duration and intensity. Soft robotic devices show promise as a therapy extender needed for motor learning. No device has shown comprehensive capabilities to address this need in children, particularly a device that can provide continuous measurements and data monitoring, characterize the spastic resistance, and accommodate growth as needed. The soft-&#8208;robotic glove, REHAB Glove, developed in this project will fill an important gap to improve independence and to reduce burden of care. The capabilities of this glove will not only address the therapy need of CP children but will also act as an important tool for data gathering for the development of dosage based therapy regimes for better outcomes. The proposed research will also serve as a training ground for medical and engineering students to become competent researchers as they will have the opportunity to join the project team for internships, mentorships, job shadowing, enrichment programs or summer academy.<br/><br/>Current hand rehabilitation devices, based on end-&#8208;effector and hard exoskeleton structures, are complex, have limited degrees of freedom, and are mostly applicable to only four fingers of the hand. All of these factors limit their capacity to support complex hand rehabilitation. Furthermore, the widespread usage of these systems in home environments is hindered by their mechanical complexity, cost, and potential safety concerns. Recent advances in soft robotics using flexible structures and actuators are being explored to reduce the complexity of these devices and improve human-&#8208;robotic interaction. In this work, a sensorized soft robotic glove will be developed using novel soft-&#8208;and-&#8208;rigid hybrid actuators alongside an advanced control unit with closed-&#8208;loop control. The PIs postulate that using a sensorized therapeutic glove capable of monitoring and assisting patient hand motion will enable children with CP to complete repetitive motions, and that children and parents can accept the robotic glove as a tool to optimize their rehabilitation. This device will help reduce the complexity, size, and cost associated with current state-of-the-art care as well as enable the development of dosage based therapy studies. The soft robotic glove is made of compliant elastomeric material, which provides a safe user-device interaction and allows customized fitting onto hands with different conditions and sizes. Sensor integration will provide the capability to monitor and record hand motion and thus evaluate the rehabilitation progress and facilitate clinical research of the hand. With an associated control unit, the device can be portable and used at home or in the hospital. This project leverages a unique collaboration that brings cutting-edge engineering, therapy, and clinical knowledge to the development of an efficacious assistive technology that can be used to facilitate recovery of hand function. The goals of this project will be accomplished by executing the following aims: 1) Develop a soft robotic glove for children with integrated sensors that measure finger trajectory and force; 2) Develop a control algorithm to assist hand motion in different operation modes; 3) Test and validate the system's ability to measure finger motion parameters; 4) Obtain feedback from children, parents, rehabilitation physicians and therapists regarding the ease of use of the REHAB Glove, and their desire to use the tool in their daily rehab practice and exercise."
"1605228","A Shared Autonomy Approach to Robotic Arm Assistance with Daily Activities","CBET","Disability & Rehab Engineering","09/01/2016","08/23/2016","Patricio Vela","GA","Georgia Tech Research Corporation","Standard Grant","Aleksandr Simonian","08/31/2019","$298,503.00","Maysam Ghovanloo","pvela@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","5342","","$0.00","Persons with high-level paralysis rely on the care of others and the modification of their environment for accomplishing the activities of daily living (ADL). Due to the degree of support required, paralysis is costly to provide care for. Recovering the ability to manipulate through technological means would lead to significant improvements to the quality of life for the user, and would reduce the long-term economic impact of paralysis and contribute to society by freeing up caregiver time and labor (usually a family-member or friend). To that end, the project proposes to design and validate a wheelchair-mounted robotic-arm with an augmented reality interface for enabling non-tactile human-robot interaction. Importantly, the design will involve a multi-modal interface approach, which includes a recently developed tongue drive interface, a head orientation sensor, and a speech recognition system. User-centric and participatory design methods will ensure that the engineered system will be seen favorably by persons with tetraplegia. The award also supports fundamental research into the design of collaborative human-robot assistive devices, including the interface design and the underlying robot vision and planning algorithms. The research contribution includes improved understanding on how to effectively coordinate the higher level reasoning and thought processes of humans with the autonomous operation capabilities and limitations of current robotic arms. The social significance of the robotics application will be capitalized to create engaging educational and outreach activities in promotion of engineering mathematics.<br/><br/>The long-term goal is to transform the lives of wheelchair bound persons with limited to no manipulation abilities by enabling them to independently perform the activities of daily living (ADL) irrespective of their environment. Technology meeting the varied needs of the ADL tends to have high control complexity, which impedes adoption. It is essential for these technologies to request high-level (guiding) commands rather than low-level control signals, and to request feedback in a manner compatible with the user's conception of the world. The research goal is to engineer and validate a wheelchair-fitted robotic-arm with an augmented reality interface and a multi-modal user interface for coupling the human command and intent control loop with the robotic-arm decision and control loop.  The novelty of the proposed system is that it is a shared control and a shared sensing assistive technology. The coupled system requires human input to overcome the perceptual limitations of robot vision, and employs robotic planning and manipulation to overcome the physical limitations of the user. By involving the human for scene interpretation and by providing ego-centric information to the robot arm, the coupled system minimizes and simplifies user input during complex manipulation tasks. The associated research objectives are to (I) engineer a human-robot augmented reality interface system with coupled feedback to the two systems (human and robot) for communicating intent and requesting high-level user feedback for complex manipulation tasks, (II) identify the manipulation assistance needs and user interface design through a participatory design process, (III) evaluate the user interface with respect to the desired command and control objectives, and (IV) assess the impact of the operational system with respect to task performance and cognitive burden. Engineering the unique shared control and shared sensing system and achieving the proposed research objectives would transform the way that assistive robotic technologies couple the user to technology. Incorporating the research into existing education and outreach activities would promote engineering and robotics to students and prepare them for participation in an increasingly automated world."
"1638163","NRI: A Variable Stiffness Artificial Muscle Material for Dexterous Manipulation","CMMI","National Robotics Initiative","09/01/2016","08/10/2016","Qibing Pei","CA","University of California-Los Angeles","Standard Grant","Irina Dolinskaya","08/31/2019","$474,501.00","","qpei@seas.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","ENG","8013","8086","$0.00","The goal of this project is creation of a material combining innovative actuation with integrated sensing. The actuation principle is based on a bistable electroactive polymer. This comprises an electrically insulating polymer sheet sandwiched between two flexible conductive layers. The polymer sheet exhibits a phase transition, with a large increase in compliance as temperature exceeds a transition value. In order to actuate the material, it is first heated above transition, then a potential is applied across the polymer. Electrostatic forces pull the conductive layers together, increasing the area of the sheet, possibly by several hundred percent. These high strains, combined with boundary constraints, cause large displacements of the actuator. Then the material is allowed to cool and transition back to the stiff form, locking in the new actuator position and allowing the electric potential to be removed. Thin film sensors measuring pressure or touch are integrated with the actuator sheets. The resulting high-strain, variable-compliance, self-sensing, device is well-suited for robotic manipulators with muscle-like dexterity. Such manipulators would have application to a wide variety of robotic systems, including prosthetic hands, patient rehabilitative equipment, compliant surgical instruments, artificial organs, and humanoid robots for assisted living. This project will provide summer research intern opportunities for minority high school students. Undergraduate and graduate students will also participate in the project, to gain hands-on research experience, and analytical, communication, and inter-personal skills.<br/><br/>This project investigates an artificial muscle material combining variable stiffness, large-strain actuation and sensing, and explores the application of the material for dexterous manipulation that is critically needed in a wide range of robotic applications. It differs from traditional robotics in that the manipulation is object-centered. The objects can have various different shapes, stiffness, surface texture, and weight. Artificial muscles combining sensing, actuation, and variable stiffness are desired to produce dexterous manipulations from gentle touch to firm gripping, with local controllability. Electroactive polymers have shown promise for reproducing both the active and structural properties of human muscles. Among these ""artificial muscle"" materials, dielectric elastomers exhibit low stiffness, high actuation strain and force output. Bistable electroactive polymers have stiffness variable up to 1000 times. In the softened state, the bistable polymer behaves like an elastomer and can be actuated like a dielectric elastomer. The combination of variable stiffness and large strain actuation will enable a new generation of artificial muscles for bioinspired robotic applications. A 6-finger manipulator will be demonstrated to grip and lift a variety of objects including eggs, golf balls, smartphones, and to squeeze a specified length of toothpaste out of the tube."
"1522904","NRI: Collaborative Research: RobotSLANG: Simultaneous Localization, Mapping, and Language Acquisition","IIS","National Robotics Initiative","09/01/2015","08/06/2015","Jason Corso","MI","University of Michigan Ann Arbor","Standard Grant","Ephraim P. Glinert","08/31/2019","$649,999.00","","jjcorso@eecs.umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","8013","8086","$0.00","Humans and robots alike have a critical need to navigate through new environments to carry out everyday tasks.  A parent and child may be touring a college campus; a robot may be searching for survivors after a building has collapsed.  In this collaboration by faculty at two institutions, the PIs envision human and robotic partners sharing common perceptual-linguistic experiences and cooperating in mundane tasks like janitorial work and home care as well as in critical tasks like emergency response or search-and-rescue.  But while mapping and navigation are now commonplace for mobile robots, when considering human-robot collaboration for even simple tasks one is confronted by a critical barrier: robots and people do not share a common language.  Human language is rich in linguistic elements for describing our spatial environment, the objects and places within it, and navigable paths through it (e.g., ""go down the hallway and enter the third door on the right."").  Robots, on the other hand, inhabit a metric world of occupied and unoccupied discretized grid cells, wherein most objects are devoid of meaning (semantics).  The PIs' goal in this project is to overcome this limitation by conjoining the well understood problem of simultaneous localization and mapping (SLAM) with that of language acquisition, in order to enable robots to learn to communicate with people in English about navigation tasks.  The PIs will spur interest in this novel research area within the scientific community by means of an Amazing Race challenge problem modeled after the reality television show of the same name, which will place robots and human-robot teams in unknown environments and charge them with completing a specific task as quickly as possible.  Other outreach activities will include visits to K-12 schools with demonstrations.  <br/><br/>This work will focus on simultaneous localization, mapping, and language acquisition, a field of inquiry that remains untouched.  The crucial principles are that semantics are formulated as a cost function, which in turn specifies a joint distribution over many variables including those capturing sensory input, language, the environment map, and robot motor control.  The cost function and joint distribution support standard inference of many forms, such as command following.  More importantly, they support multidirectional inference over multiple variable sets jointly, such as simultaneous mapping and language interpretation.  Within this innovative multivariate optimization-based framework, the PIs plan a thorough experimental regimen including both synthetic and real-world datasets of challenging environments, grounding the semantics of natural language in spatial maps of the realistic visual world and robot motor control, while navigating along particular paths or to arrive at particular destinations in (possibly novel) environments that are mapped not only in a geometric sense but also with linguistic underpinning to these particular paths and destinations.  The language approach is compositional and uses spatially-grounded representations of nouns (objects/places) and prepositions (relations between them).  These spatially-grounded representations will be modeled in the context of mapping.  Furthermore, the PIs will consider realistic environments and adapt visual models thereof according to the joint model.  The PIs are aware of no other work that jointly models mapping, vision, and language acquisition."
"1614085","Promoting Robotic Design and Entrepreneurship Experiences among Students and Teachers","DRL","ITEST","09/01/2016","05/11/2018","Vikram Kapila","NY","New York University","Standard Grant","Robert Russell","08/31/2019","$1,039,315.00","Catherine Milne, Oded Nov, Jin Montclare, Jennifer Listman, Sheila Borges Rajguru","vkapila@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","EHR","7227","","$0.00","The project will develop, implement, and assess an initiative to promote robotic design and entrepreneurship experiences among students and teachers. Each year, 16 teachers and 32 students from 8 high schools located in all 5 boroughs of New York will attend a 4-week summer institute consisting of a 2-week guided training and a 2-week collaborative robotic-product development. The participants will come primarily from schools in underserved neighborhoods with socially, economically, racially, and ethnically diverse student bodies; approximately half of the participants will be female. During the academic year, each school's two teachers will conduct a robotics course for at least 25 students. Classroom adoption will be facilitated through a professional learning community (PLC). In the annual grand finale, school teams will compete in a robot product design and business idea contest, modeled after the Inno/Vention contest coordinated by the Incubator Initiatives of NYU Tandon School of Engineering. Over the 3-year project duration, 48 teachers and 96 students from 24 high schools will participate in the summer institute with 160 contact hours. Through the academic year elective, teachers will engage 1,200 students during the project funding period. The project has formed an interdisciplinary team including experts in robotics, entrepreneurship, K-12 curriculum design, and assessment to support project design and implementation. <br/><br/>The project design adapts features from research on project-based learning (PBL), robotics and entrepreneurship in K-12 STEM education, social cognitive career theory, and teacher professional development embedded in a PLC. Formulating robotics activities in a PBL framework will help participants learn content, develop planning and problem-solving skills, and foster their higher-order cognitive skills. Integration of PBL with entrepreneurship activities will address participant fear of failure, lack of confidence, and creativity and communication skills. The design of the teacher professional development will support transfer of training through content-immersion, allow modeling and rehearsing of desired skills, and involve teachers for a sufficient duration to support the cognitive demands of new learning. The project will research the broad overarching question: Do robotics design and entrepreneurship activities, experienced through PBL, positively influence teacher practices and student outcomes? The project will investigate if participation (1) builds teacher capacity to effectively utilize PBL, contextualized in robotics and entrepreneurship, to promote STEM learning and (2) positively impacts students self-efficacy, outcome expectations, goals, and interest in STEM studies and careers. This project is funded by the Innovative Technology Experiences for Students and Teachers (ITEST) program that supports projects that build understandings of best practices, program elements, contexts and processes contributing to engaging students in learning and developing interest in STEM, information and communications technology (ICT), computer science, and related STEM content and careers."
"1637031","AitF: Collaborative Research: A Distributed and Stochastic Algorithmic Framework for Active Matter","CCF","ALGORITHMIC FOUNDATIONS","09/01/2016","08/12/2016","Dana Randall","GA","Georgia Tech Research Corporation","Standard Grant","Tracy J. Kimbrel","08/31/2019","$200,000.00","Daniel Goldman","randall@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7796","","$0.00","Swarm robotics explores how groups of robots can work towards a singular goal. Such a goal is typically achieved by equipping each robot with sensory capabilities, basic computing power, and actuation. The sensors detect something about the environment, this information is used to make a decision about the next action, and some resulting actuation is performed. Swarm robotics has made many advances in recent years, but it is still in its infancy.  The PIs will take a ""task-oriented"" approach and start from a desired macroscopic emergent collective behavior to develop the distributed and stochastic algorithmic underpinnings that the robots will run (at the microscopic level) in order to converge to the desired macroscopic behavior; as part of the process, they will also provide the understanding for yet unexplored  collective and emergent systems. The robots envisioned are small in scale, ranging in size from millimeters to centimeters, so that when deployed in crowded (i.e., dense) environments, they will behave as active matter, more specifically as macroscopic programmable active matter.  The emergent behaviors of interest for simulations include clustering (forming a tight-knit community that is mostly well-connected), compression (maintaining coherence of a connected community while minimizing perimeter), flocking (determining an agreed upon direction of orientation), and locomotion (collectively moving while maintaining cohesiveness). Many of these have interesting converse problems which are also equally worthwhile, such as exploration (maintaining a connected population, but exploring maximal area) and desegregation (preventing separation in a binary mixture of particles).<br/><br/>The PIs have strong records for interdisciplinary research, including initiating interdisciplinary areas, e.g., robo-physics (Goldman), self-organizing particle systems (Richa), and the fusion of statistical physics and randomized algorithms (Randall). The PIs also have a strong commitment toward supporting minorities, women, and undergraduate research (e.g., through NSF S-STEM programs at ASU; ADVANCE and S.U.R.E. programs at Georgia Tech).  This project will bring together techniques from multiple disciplines, and new research approaches and findings will be incorporated into graduate courses. Findings (including open source code) will be published in the various disciplines, and will be made available on the web and ArXiv.<br/><br/>The specific goals of this project are to work toward developing a theoretical framework for task-oriented active matter, informed by models of simple physical systems, that can realize and test the algorithms. The swarm robotics systems that biophysicists build to understand nature can be modified to perform the tasks these new algorithms require. The physical models will allow refinements to the theories under additional constraints, such as gravity and limited energy. It also will allow the PIs to test their algorithms for robustness, as physical systems admit some error.  The fundamentals of swarm robotics will be studied from a physics standpoint, by viewing the ensemble as active matter composed of programmable elements at the micro-level. Thus, a (macro-)task oriented approach will be followed in order to design a distributed, stochastic algorithmic framework to construct and evaluate algorithms at the micro-level that yield the targeted emergent macro-behavior."
"1638047","NRI: Collaborative Research: Sketching Geometry and Physics Informed Inference for Mobile Robot Manipulation in Cluttered Scenes","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2016","08/10/2016","Odest Jenkins","MI","University of Michigan Ann Arbor","Standard Grant","Reid Simmons","08/31/2019","$400,857.00","","ocj@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","7495, 8013","7495, 8086","$0.00","The goal of this project is to improve the ability of robots to manipulate and interact with objects, such as when assisting people to support their daily activities.  The key idea is that people can provide robots with important information about their environment and the objects within their environment. In particular, people can use their cognitive skills to name objects, provide an understanding of the geometrical structure of objects, and describe an object's behavior in relation to other objects. Specifically, the project will develop a natural user interface that enables people to provide such information by drawing and sketching on top of the robot's view of the world.  Physical simulation will then be used to fill in the missing gaps needed for a robot to complete autonomous manipulation tasks. Thus, the project aims to combine object sketching and physical simulation to better support mobile manipulation tasks as well as learn to perform new manipulation tasks when encountered.  The project will support a ""Put That There"" task, where a user can simply give high-level manipulation commands, with the robot filling in the details necessary to complete the task in a cluttered environment.<br/><br/>This project aims to improve goal-directed dexterous robotic manipulation in cluttered and unstructured environments through sketching and physical simulation. Robots operating in human environments face considerable uncertainty in perception due to physical contact and occlusions between objects. This project will address such perceptual uncertainty by combining methods for probabilistic inference with natural sketch-based interfaces to extract, label, and automatically infer the geometry, pose, and behavior of objects in complicated scenes.  From a human usability perspective, the project addresses how to best create a sketching language and interfaces for intuitive human-in-the-loop extraction of object geometries and behavior from robot sensing.  The planned exploration into sketching methods will also explore what underlying representations, raw point clouds, RGB images and video, or RGBD images will be most conducive to supporting accurate geometry extraction and grasp location identification.  Given sketched objects, the project will develop probabilistic physically plausible methods for scene estimation that will enable perception for manipulation in cluttered environments.  These methods build upon advances in physical simulation to constrain scene estimates to only plausible configurations to both improve estimation accuracy and enable computational tractability.  The project will also develop a ""Put That There"" testbed using a tablet-based web application to support exploration of these concepts as well as act as user studies to evaluate geometry extraction accuracy and the robustness of physics-based scene estimation algorithms."
"1524363","NRI: Collaborative Research: Human-Supervised Manipulation of Deformable Objects","CMMI","Disability & Rehab Engineering, National Robotics Initiative","08/01/2015","05/03/2018","M. Cenk Cavusoglu","OH","Case Western Reserve University","Standard Grant","Irina Dolinskaya","07/31/2019","$445,191.00","","mcc14@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","ENG","5342, 8013","116E, 8086, 9178, 9231, 9251","$0.00","The goal of the proposed work is to develop algorithms that enable human-supervised robotic manipulation of deformable objects under significant uncertainty. Manipulation of deformable objects is essential in surgery, which involves complex manipulations of delicate and highly deformable tissue under substantial uncertainty, and in manufacturing, where many assembly tasks involve flexible parts and materials (e.g. cables, textiles, and composites). Recent advances in robot hardware (e.g. the da Vinci and Baxter robots) have made robotic manipulation of deformable objects physically possible but robots still lack the algorithms necessary to perform practical tasks in this domain when there is significant model uncertainty. This project will have broad societal impact through its applications in surgical and manufacturing robotics. The ability to robustly manipulate deformable structures is an important precursor technology towards realizing intelligent robotic surgical assistants. Robotics and its medical applications have the potential to inspire children to pursue careers in STEM fields and meet the needs of America's growing health-care and manufacturing robotics industry. Integration of the research activities with education will emphasize actively involving undergraduates in research activities and introducing new lecture material and projects into undergraduate and graduate courses. Also, special emphasis will be given to recruit qualified students from under-represented groups.<br/><br/>The purpose of the proposed research is to develop algorithms that enable human-supervised robotic manipulation of deformable objects under substantial uncertainty. Specifically, the research will focus on developing adaptive complexity models for modeling deformable object dynamics and associated uncertainty, planning algorithms for integrated exploration and task execution, control algorithms for robust manipulation of deformable objects under uncertainty, and algorithms for effective human supervision of robotic manipulation of deformable objects. The intellectual merit of the project comes from its fundamental contributions to robotic modeling, planning, and control algorithms for manipulation of deformable objects. The research will have impact in the fields of robotic manipulation, motion planning under uncertainty, and compliant manipulation control."
"1835279","NCS-FO: Spatial Intelligence for Swarms Based on Hippocampal Dynamics","IIS","IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/05/2018","Kechen Zhang","MD","Johns Hopkins University","Standard Grant","Kenneth C. Whang","09/30/2020","$997,996.00","Grace Hwang, Marvin Carr, Kevin Schultz, Robert Chalmers","kzhang4@jhmi.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","8624","8089, 8091, 8551","$0.00","This project brings together theories of brain functions and principles of robotic swarm control to develop smarter swarms and to better understand the neural processes underlying spatial representations, navigation, and planning. Our world is constantly changing, and mammals have evolved the cognitive ability to plan new paths or new strategies as needed. By contrast, autonomous robots are less robust, and often have difficulty operating in complex, changing environments. This research project is grounded in the idea that individual robots in a group can be thought of analogously to neurons in an animal's brain, which interact with one another to form dynamic patterns that collectively signal locations in space and time relative to brain rhythms. This distribution of information across space and time will enable a new paradigm of swarm control, in which swarms automatically adapt to changes in the world in the same way that a rat knows which detour to take around an unexpected obstacle. Unmanned robots are rapidly becoming a crucial technology for commercial, military, and scientific endeavors throughout the nation and across the globe. Critical future applications such as disaster relief and search & rescue will require intelligent spatial coordination among many robots spread over large geographical areas. This project will advance neural swarming as a control paradigm for this next generation of technological development. Additionally, this project will drive an extensive science, technology, engineering, and mathematics education program to bring the concepts of spatial intelligence, hippocampal information processing, and swarm control to high school students to improve literacy in neuroscience and robotics.<br/><br/>The project's goal is to build a unified framework for self-organized, bottom-up control of spatial task planning that synergistically advances theoretical neuroscience and swarm control paradigms. In the project's brain-to-swarm metaphor, neurons are autonomous agents, spikes are agent-based phase signals, and emergent circuit activity is emergent swarm behavior. The approach targets neural computations in hippocampal circuits and related systems that may contribute to online dynamic replanning. The research thrusts comprise data-driven dynamical network and point-process models of neural activity sequences, mathematical analysis of swarming dynamics using matrix manifolds, and autonomous systems simulations in realistic virtual environments. The project will advance understanding of emergent hippocampal dynamics and autonomous methods for dynamic replanning, motivating new research in distributed control. The project's framework may enable mass-scalability for large, agile swarms of simple robotic agents.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830338","NRI: FND: COLLAB: Optimal Design of Robust Compliant Actuators for Ubiquitous Co-Robots","CMMI","National Robotics Initiative","09/15/2018","09/04/2018","Elliott Rouse","MI","University of Michigan Ann Arbor","Standard Grant","Atul G. Kelkar","08/31/2021","$318,701.00","","ejrouse@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","8013","030E, 034E, 063Z, 8024, 8086","$0.00","Motion of robotic devices is achieved by enabling the movement of its joints by devices called actuators.  This National Robotics Initiative (NRI) project seeks to understand how to design compliant actuators  for human-interactive robots that are energy-efficient and safe across a wide variety of tasks and situations. Unlike rigid actuators, compliant actuators can store and release mechanical energy for greater efficiency and absorb shocks for greater safety, which has made them especially popular in wearable robots (i.e., prostheses and exoskeletons). However, the compliant element of the actuator (e.g., a spring between the motor and the robot joint) must be carefully chosen to achieve these benefits, which has restricted previous implementations to specific use cases. The mathematical framework in this project will enable design of compliant actuators that change their physical properties to guarantee safety and efficiency as interactions vary from gentle to forceful. Compliant actuators that are robust to a wide range of conditions can be used for many applications, allowing mass production at lower cost. The energy efficiency of these actuators will increase the battery range of mobile co-robots and allow the use of smaller, lighter batteries in wearable robots. This work is significant to the ubiquity of compliant actuator technology for safe, energy-efficient interactions between robots and humans in uncertain real-world situations outside the laboratory.<br/><br/>This project will establish a robust convex optimization framework for designing series elastic actuators (SEAs) that globally minimize electrical energy consumption while satisfying actuator/safety constraints. When designing an SEA, a parametric representation of the elastic element (e.g., the stiffness of a linear spring) is typically optimized for a single task (trajectory and load). However, this paradigm has two key limitations: 1) solutions are only optimal within the given space of parameters, and 2) the benefits of the elasticity (i.e., efficiency and compliance) can be entirely lost outside of specific operating conditions. A nonlinear series elastic element can potentially solve these problems by providing different stiffness characteristics at different operating points, but the ideal parameterization of the spring is unknown. A non-parametric, robust optimization framework is therefore needed to develop SEA technology that can achieve a variety of tasks in a variety of situations (customizability) for ubiquitous interaction with humans (scalability). Tools exist to solve convex optimization problems with uncertainty in their parameters, but the design of SEAs is not currently known to be a convex problem. The overall goals of this project are then to 1) understand the convexity of SEA energy consumption as a function of stiffness characteristics, 2) understand how to design nonlinear series elastic elements to achieve maximal efficiency while satisfying constraints, and 3) understand how to design SEAs that are robust to uncertainties.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1832993","RII Track-4: EASE - Functional Electrical Stimulation and Mechanical Actuation of Soft Exoskeletons","OIA","EPSCoR Research Infrastructure","09/01/2018","08/20/2018","Vishesh Vikas","AL","University of Alabama Tuscaloosa","Standard Grant","Chinonye Whitley","08/31/2020","$250,956.00","","vvikas@eng.ua.edu","801 University Blvd.","Tuscaloosa","AL","354870005","2053485152","O/D","7217","9150","$0.00","Non-Technical Description<br/>Soft material robotics is envisioned to be the future of robotics that combines the concepts of the Internet of Things (IoTs), wearable sensors, material science and artificial intelligence to fabricate robots that can assist and collaborate with humans. This field is of special interest to roboticists and engineers as it has multiple fundamental challenges and there are tremendous benefits for applications to fields such as agriculture, disaster robotics to assistive rehabilitation. This project will enable researchers from the University of Alabama to enhance their capabilities to develop next-generation soft material exoskeletons (exosuits) stimulated by mechano-neuromuscular actuators through a collaboration with researchers at the University of Pittsburgh. Mechanically and electrically actuated soft exosuits are envisioned to have an impact on the fields of assistive robotics, rehabilitation robotics, and elder care. The research will result in the development of design and control principles for mechano-neuromuscular actuated soft wearable exosuits, thus greatly enhancing life and reducing rehabilitation cost for individuals who suffer from paralysis, stroke, and spinal cord injuries. The applied nature of this research will play an instrumental role in attracting students to STEM fields that include computer science, electrical engineering, mechanical engineering and biomedical engineering.<br/><br/>Technical Description<br/>The proposed project will integrate learning with research to develop design methodologies and control principles for composite fiber-reinforced soft exosuits.  These exosuits will integrate electro-mechanical actuation (motor-tendons) with the functional electrical stimulation (FES) of muscles to provide ease of movement by assistance and rehabilitation. This research will advance the University of Alabama's (UA) rehabilitation research through the development of design methodologies for motor-tendon driven soft exosuits by adapting principles from fields of compliant mechanisms and composite materials for soft structures. The resulting multi-layer soft material composite exosuits, with reinforced fibers, will address stress concentration and distribution problems specific to electromechanical actuators. This will include addressing anchor-point stress concentration and efficient transfer of actuator forces between components. Nonlinear controllers will be developed to integrate electromechanical and neuromuscular actuation in soft exosuits to effect ease of movement. The proposed research will contribute towards the understanding of design principles for soft wearable materials, which are tough to model, and how their behavior and/or interaction varies with the environment of contact. Furthermore, the research will contribute towards the development of next-generation actuation technologies for mechano-neuromuscular actuators. The research will result in hybrid control principles for mechano-neuromuscular actuators that provide wearable soft exosuits with less stiffness. Given the medical resources and interdisciplinary faculty at UA, this proposal will help in building capacity for a wearable robotics and rehabilitation research program in the state of Alabama.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1812319","S&AS: FND: COLLAB: Planning and Control of Heterogeneous Robot Teams for Ocean Monitoring","IIS","S&AS - Smart & Autonomous Syst","09/01/2017","12/01/2017","M. Ani Hsieh","PA","University of Pennsylvania","Standard Grant","Jie Yang","08/31/2020","$346,929.00","","m.hsieh@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","039Y","046Z","$0.00","Robots in marine and littoral environments are envisioned for commerce, scientific exploration, search and rescue, and many other tasks. However, robots in such environments face significant challenges. Vehicles must act and effect change in environments with large inertial effects and disturbances, with only near-field perception. Coupled with our limited understanding of ocean dynamics and the lack of accessible and high-quality ocean flow data, these obstacles make the use of robotics technology in these varied applications extremely difficult. This project realizes an integrated, heterogeneous robotic approach towards large-scale ocean monitoring for environmental mitigation and search and rescue operations. It enables data-driven tracking and mapping of various physical, chemical, and/or biological processes of interest in marine environments, such as tracking contaminant dispersion or missing aircraft. This project significantly improves the state of the art in ocean search and monitoring technology, helping us understand and harness ocean currents, and improve the health of the world's oceans. Results from the project are integrated into education, through the PIs' courses, mentoring students on research, and expanding an existing K-12 outreach relationship. <br/> <br/>The project creates fundamental knowledge about new ways that robots can better monitor, sense, and operate in dynamic and uncertain environments. The project develops new methods for heterogeneous teams of monitoring robots to improve their environment model through current interactions with the environment; concurrently collect data, process and assimilate it into the existing model, and plan on that model; accept high-level instruction and translate goal-oriented directives such as environmental monitoring into a suitable plan for sensing, reasoning, communicating, and acting through the underlying system architecture; and monitor their actions, optimize, and reconfigure autonomously. The heterogeneous team of robots proposed includes surface vehicles providing samples at the air-sea interface and aerial robots creating flow models and acting as intermediaries within the team. The hierarchical structure of the approach takes advantage of the natural boundaries defined by Lagrangian coherent structures in the creation of a distributed sensing framework."
"1746448","Workshop on Human-Friendly Robots","CBET","Disability & Rehab Engineering","01/01/2018","01/05/2018","Amir Jafari","TX","University of Texas at San Antonio","Standard Grant","Aleksandr Simonian","12/31/2018","$10,000.00","","Amir.Jafari@utsa.edu","One UTSA Circle","San Antonio","TX","782491644","2104584340","ENG","5342","7556","$0.00","Assistive robotics are increasingly an area of societal interest as the population ages and individuals with disabilities seek to maintain as much independence as possible.  However, robotic systems were initially designed to replace humans in hazardous situations, not interact with them.  Assistive robotics, by design, will interact with humans, and this poses new challenges that must be addressed related to the user interface and safety.  In order to insure the safety of users and encourage average citizens to use of assistive robots, research is needed into how to develop, manufacture, and control robots that are designed to interact with individuals on a daily basis and in a home environment.  This conference award will provide support for the 2018 Workshop on Human-Friendly Robotics at the University of Texas, San Antonio in September 2018.  This is the first time that this workshop, held annually in Europe since 2008, will be held in the United States.  The focus of the workshop is on identifying the scientific and technological challenges that exist related to safely and effectively integrating robots into our daily lives, particularly in the area of rehabilitation and assistive technology.  <br/><br/>This award will provide financial support for nine invited speakers, internationally renowned, to attend the workshop and lead the discussions.  The discussions will be focused on identifying the current state of the art and the key unresolved problems and challenges that need to be addressed through research.  The presentations and follow-on discussions will be archived and made available to the public.  A second goal of the workshop is to catalyze collaborations among researchers, both within the US and with international partners, to further advance this area of engineering.  Finally, by hosting the workshop on the campus of a minority-serving institution, the organizers hope to include many underrepresented students in the workshop and use the results of the workshop to excite K12 students regarding opportunities in STEM."
"1726524","MRI: Acquisition of a Mobile Manipulation Robot Platform for Research and Education","CNS","INFORMATION TECHNOLOGY RESEARC","10/01/2017","09/20/2017","Yu Zheng","MI","University of Michigan Ann Arbor","Standard Grant","Rita V. Rodriguez","09/30/2020","$250,000.00","Yubao Chen, Alex Y. Yi, Samir Rawashdeh, Stanley Baek","yuuzheng@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","1640","1189","$0.00","This project, acquiring a mobile manipulation robot platform, aims to address several major challenges of robotics technologies needed to boost robot functionality and applications by integrating manipulation and locomotion capabilities, such that a robot can operate and make changes in a broader environment without territorial restrictions. Specifically, the project specifies enabling:<br/>- Vision-based mobile robot navigation;<br/>- Vision-guided autonomous object manipulation and application to assembly;<br/>- Unified motion generation and control for locomotion and manipulation; and<br/>- Robot-human interaction and collaborations.<br/>This work addresses applications in many areas, such as manufacturing, agriculture health care, homeland security, public service, and entertainment.<br/><br/>Current robots, particularly in manufacturing, have mainly been designed to be bolted on a production line and only execute a pre-defined action with high accuracy and repeatability with limited sensing and no autonomy or intelligence, which significantly restricts their further applications. To enhance the functionality of robots and extend their application scopes, an essential element is not often present: integration of manipulation and locomotion capabilities so that the robot can operate and make changes in a broader environment without territorial restrictions. Moreover, robots need to be equipped with a certain level of autonomy and intelligence so they can decide on their own what to do and how to do it.   The proponents aim to maximize the usage of the robot platform by providing this integration.<br/><br/>Broader Impacts:<br/>The outcomes of the proposed research should significantly enhance the university's research and education infrastructure and facilitate close interaction and collaboration between local industries, nearby institutions, and the university. The enthusiasm and expectations for robots to further promote human science and technological level open up a large demand for new developments on technologies and education, as well as in training qualified researchers and engineers in robotics and related fields. The outcomes of this work offer not only needed results but also educational experience. Research problems will be adapted as senior design projects and thesis topics for undergraduates and graduate programs. Some of this work will be integrated into core courses as special lectures and lab projects. Furthermore, industrial involvement from Omron and General Motors will strengthen existing university-industry relations and create collaborative opportunities."
"1548502","EAGER: Studying the Dynamics of In Home Adoption of Socially Assistive Robot Companions for the Elderly","CBET","EFRI RESEARCH PROJECTS","09/01/2015","08/14/2015","Maja Mataric","CA","University of Southern California","Standard Grant","Aleksandr Simonian","08/31/2019","$250,000.00","Elizabeth Zelinski, Shinyi Wu","mataric@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","ENG","7633","010E, 7916, 8089","$0.00","1548502(Mataric)<br/><br/>The number of adults over the age of 65 is predicted to reach 83.7 million by 2050. There is accordingly a growing need for technologies for the elderly to complement human care in addressing the fast-growing needs of the elderly population.  This project takes a novel approach to developing and evaluating an assistive technology for the elderly: it views the family unit as a team, and focuses on developing a robots as a team member (rather than individual assistant) designed to aid in the achievement of team/family goals. In the project, these goals are focused on the wellbeing of the elderly family member, and include daily social connectedness with others in the family, regular physical and cognitive activity, and medication adherence. These goals are part of the family dynamic and involve the interaction of various team members, pairwise, in subgroups, or all together. The project will develop a hardware and software infrastructure for deploying a socially assistive robot in the home and methods for enabling the robot to adapt to the family members in order to aid in facilitating team dynamics and aiding family goal achievement.  The project brings together leading experts in socially assistive robotics, gerontology, and social work, who will spend two years in a tightly knit process of technology development combined with in home system evaluation with participating families. <br/><br/>This project is focused on engineering team interactions and dynamics, with the robot as a member of the team, embedded in a real-world environment and interacting with other team members in real time. The engineering goal is to develop data-driven robot control algorithms and the associated hardware and software infrastructure for enabling robots to serve as team members in the context of family-supported eldercare. The control algorithms, combined with the hardware and software infrastructure, will enable the robot system to perceive and understand the relevant aspects of the family interaction dynamics, be a participant/component in those team dynamics, and influence/streer those team dynamics toward desired family team goals. The project will enable and then iteratively probe the effects of the robot as team member in different interaction contexts (user-family, user-caregiver, family-caregiver). Furthermore, the project tackles three fundamental components in team goal achievement: evaluation of team performance, coordination of actions across multiple team members, and team member role assignment. It also investigates the application of unsupervised, supervised, and reinforcement learning techniques to the domain of elderly care. The research is complemented with a K-12 STEM outreach program consisting of annual free interactive workshops for students in secondary education (grades 6-12; up to 30 students per workshop). Simple robot programming and demonstrations of the hardware and software being developed in the project will be used to discuss how assistive robots could play a role in society, starting with the students' families."
"1527208","NRI: Collaborative Research: Task Dependent Semantic Modeling for Robot Perception","IIS","National Robotics Initiative","09/01/2015","08/12/2015","Jana Kosecka","VA","George Mason University","Standard Grant","Jie Yang","08/31/2019","$267,486.00","","kosecka@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","8013","8086","$0.00","The research in this project enables robots to better deal with the complex cluttered environments around us, ranging from open scenes to cluttered table-top settings and to perform the basic mapping, navigation, object search so as to enable fetch and delivery tasks most commonly required in service co-robotics applications.  The key contribution of the project is to develop visual perception systems for robots that can understand the semantic labels of the visual world at multiple levels of specificity as required by particular robot tasks or human-robot interaction.  In addition, the project enables robot perception systems to better understand new, previously unseen, environments through automatically adapting existing learned models, and by actively choosing how to best explore and recognize novel visual spaces and objects.  The datasets and benchmarks, as well as the developed models, form basis for more rapid progress on semantic visual perception for robotics.<br/><br/>The development of methodologies for learning compositional representations which enable active learning and efficient inference is a long standing problem in computer vision and robot perception. Guided by the constraints of indoors and outdoors environments, we plan to exploit large amounts of data, strong geometric and semantic priors and develop novel representations of objects and scenes. The developed representations are captured by compositional structured probabilistic models including deep convolutional networks. Doing this rapidly is required to support active visual exploration to improve semantic parsing of a space.  Furthermore the project team collects and disseminates a large dataset of densely sampled RGBD imagery to support offline evaluation and benchmarking of active vision for semantic parsing.  The project can result in advances in active hierarchical semantic vision for robot tasks including exploration, search, manipulation, programming by example, and generally for human-robot interaction."
"1537023","NRI: Collaborative Research: A Dynamic Bayesian Approach to Real-Time Estimation and Filtering in Grasp Acquisition and other Contact Tasks (Continuation)","IIS","National Robotics Initiative","09/01/2015","06/19/2017","Barbara Cutler","NY","Rensselaer Polytechnic Institute","Standard Grant","Ephraim P. Glinert","08/31/2019","$374,039.00","","cutler@cs.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","8013","8086, 9251","$0.00","A current weakness of robots is their inability to quickly and reliably perform contact tasks in unstructured environments.  The goal of this project, which represents a collaboration between faculty at two partner institutions, is to alleviate this shortcoming by developing techniques that will afford robots accurate real-time perception in tasks exhibiting intermittent contact.  Project outcomes will have a strong impact in manipulation tasks, as robots become more capable and autonomous.  The PIs also expect successful applications in other areas, for instance to drive real-time haptic displays in augmented reality systems, to extract human manipulation strategies from observed kinesthetic demonstrations, and to identify model parameters to improve simulation accuracy, not to mention in advancing the level of autonomy for space and undersea exploration.  Additional applications outside of robotics are anticipated in situations where a system experiences abrupt state transitions and the goal is either state estimation or real-time feedback control (e.g., chemical, financial, and geological systems).  The PIs' labs have a track record of supporting women and under-represented minorities, and the research will be integrated into a variety of pedagogical activities at the graduate and undergraduate level on both campuses.<br/><br/>In previous work the team proposed the DBC-SLAM framework, in which continuous states (i.e., poses, velocities and contact impulses), and discrete contact states (i.e., contact-noncontact and stick-slip) of the manipulated objects, are tracked and important model parameters are estimated.  In this research, they will extend that work significantly in two directions.  First, they will design new parallel, anytime complementarity problem (CP) solvers in order to attain real-time performance.  Second, they will enhance the dynamic Bayesian models in DBC-SLAM to allow the use of point-cloud observations and more complex geometric models of the objects, robot links, and environment.  The intellectual merit of the project lies in three main activities: first, the creative, yet rigorous, technical process of designing perception algorithms based on fundamental first principles of nonsmooth mechanics and Bayesian estimation in a way that can utilize point-cloud data; second, achieving real-time performance by exploiting the mathematical structure and properties of both the nonsmooth multibody dynamics and CPU/GPU computing systems; and third, pursuing the first two activities in a way that sheds light on the trade-offs between estimation accuracy and speed."
"1525006","NRI: Collaborative Research: Unified Feedback Control and Mechanical Design for Robotic, Prosthetic, and Exoskeleton Locomotion","ECCS","National Robotics Initiative","09/01/2015","08/31/2015","Jessy Grizzle","MI","University of Michigan Ann Arbor","Standard Grant","Radhakisan S. Baheti","08/31/2019","$300,022.00","","grizzle@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","8013","092E, 8086","$0.00","There is a pressing need for wearable robots, e.g., prostheses and exoskeletons, which improve the quality of life for individuals with limited mobility - devices that work symbiotically with human users to achieve stable, safe and efficient locomotion.  At present, approximately 4.7 million people in the United States would benefit from an active lower-limb exoskeleton due to the effects of stroke, polio, multiple sclerosis, spinal cord injury, and cerebral palsy, and by 2050 an estimated 1.5 million people in the United States will be living with a major lower-limb amputation.  Yet current wearable robotic devices do not address this growing population's needs since they are bulky, heavy, noisy, and require large batteries for even short duration use, while implementing predominately hierarchical control algorithms.  Impeding innovation in this domain is the expensive and slow traditional design-build-test approach that ignores the tight coupling between hardware specifications and control algorithm performance.  The vision of this work is to provide a methodology---inspired by advancements in robotic locomotion---that allows lower-limb prostheses and exoskeletons to meet real-world requirements through the co-design of the electromechanical and feedback systems.  The transformative nature of this work, therefore, stems from its ability to realize wearable robots that synergize with humans to achieve increased mobility, providing a template for the growing robotic assistive device industry and potentially improving the quality of life of millions.  <br/><br/>To realize the vision of this work, the overarching research goal is to create a new unified control and design framework that will allow for the efficient and stable locomotion of robots, prostheses, and exoskeletons.  A key aspect of this control methodology is the ability to continuously mediate between different objectives enforcing stability and safety in an efficient manner through force-based interactions among (wearable) robotic devices, their environment and the user. The resulting framework will be utilized via control-in-the-loop mechanical design of prostheses and exoskeletons with stringent design requirements, tested experimentally on a novel humanoid robot, and clinically evaluated through human subject trials.  This work is, therefore, guided by the following specific goals:  (1) develop a unified online optimization-based control framework for (wearable) robotic locomotion that efficiently mediates stability, safety and force constraints, (2) create a feedback loop between formal control synthesis and the mechanical design of wearable robots that satisfy stringent performance requirements,  (3) accelerate clinical testing by translating controllers formally and experimentally from bipedal humanoid robots to prostheses and exoskeletons.  As a result of these research goals, this work has the potential to create the next generation of robotic systems that enable stable, safe and efficient human mobility."
"1830360","NRI: FND: COLLAB: Optimal Design of Robust Compliant Actuators for Ubiquitous Co-Robots","CMMI","National Robotics Initiative","09/15/2018","09/04/2018","Robert Gregg","TX","University of Texas at Dallas","Standard Grant","Atul G. Kelkar","08/31/2021","$431,244.00","Siavash Rezazadeh","rgregg@utdallas.edu","800 W. Campbell Rd., AD15","Richardson","TX","750803021","9728832313","ENG","8013","030E, 034E, 063Z, 8024, 8086","$0.00","Motion of robotic devices is achieved by enabling the movement of its joints by devices called actuators.  This National Robotics Initiative (NRI) project seeks to understand how to design compliant actuators  for human-interactive robots that are energy-efficient and safe across a wide variety of tasks and situations. Unlike rigid actuators, compliant actuators can store and release mechanical energy for greater efficiency and absorb shocks for greater safety, which has made them especially popular in wearable robots (i.e., prostheses and exoskeletons). However, the compliant element of the actuator (e.g., a spring between the motor and the robot joint) must be carefully chosen to achieve these benefits, which has restricted previous implementations to specific use cases. The mathematical framework in this project will enable design of compliant actuators that change their physical properties to guarantee safety and efficiency as interactions vary from gentle to forceful. Compliant actuators that are robust to a wide range of conditions can be used for many applications, allowing mass production at lower cost. The energy efficiency of these actuators will increase the battery range of mobile co-robots and allow the use of smaller, lighter batteries in wearable robots. This work is significant to the ubiquity of compliant actuator technology for safe, energy-efficient interactions between robots and humans in uncertain real-world situations outside the laboratory.<br/><br/>This project will establish a robust convex optimization framework for designing series elastic actuators (SEAs) that globally minimize electrical energy consumption while satisfying actuator/safety constraints. When designing an SEA, a parametric representation of the elastic element (e.g., the stiffness of a linear spring) is typically optimized for a single task (trajectory and load). However, this paradigm has two key limitations: 1) solutions are only optimal within the given space of parameters, and 2) the benefits of the elasticity (i.e., efficiency and compliance) can be entirely lost outside of specific operating conditions. A nonlinear series elastic element can potentially solve these problems by providing different stiffness characteristics at different operating points, but the ideal parameterization of the spring is unknown. A non-parametric, robust optimization framework is therefore needed to develop SEA technology that can achieve a variety of tasks in a variety of situations (customizability) for ubiquitous interaction with humans (scalability). Tools exist to solve convex optimization problems with uncertainty in their parameters, but the design of SEAs is not currently known to be a convex problem. The overall goals of this project are then to 1) understand the convexity of SEA energy consumption as a function of stiffness characteristics, 2) understand how to design nonlinear series elastic elements to achieve maximal efficiency while satisfying constraints, and 3) understand how to design SEAs that are robust to uncertainties.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830475","NRI: INT: COLLAB: Soft Active Contact Pads with Tunable Stiffness and Adhesion for Customizable Robotic Grasping","CMMI","National Robotics Initiative","09/15/2018","09/04/2018","Kevin Turner","PA","University of Pennsylvania","Standard Grant","Atul G. Kelkar","08/31/2021","$372,036.00","","kturner@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","ENG","8013","030E, 034E, 063Z, 8024, 8086","$0.00","As robots have a greater presence in our personal, public, and working environments, they must be equipped for a broad range of manipulation tasks and physical encounters.  For many of these activities, such robots must be able to grasp a wide variety of everyday objects or be capable of physical interactions with humans or other robots. While there are robotic grippers (""end effectors"") well-suited for specific tasks, progress in cooperative robotics has been limited by a lack of ""universal"" gripping systems that can handle a diverse set of objects. Universal gripping systems have the potential to dramatically improve robot performance and reduce costs by decreasing the number of end effectors that a robot needs for general purpose functionality. This National Robotics Initiative (NRI) project will address this critical need by creating new material architectures that enable universal robotic grasping. This will be accomplished by using materials that are capable of changing their mechanical properties such as stiffness and adhesion, and incorporating these materials into contact pads that the robot will use for gripping. This work will promote domestic economic growth and well-being by impacting multiple sectors in which cooperative robots will have an important role, including manufacturing, aerospace, agriculture, elderly care, and rehabilitation. This project will also contribute to educational outreach through middle/high school student workshops and science events that will inspire students to learn more about the role of materials in soft and human-friendly robotics. <br/><br/>The ultimate goal of this project is to realize a customizable robotic gripper that can operate in a broad range of contexts. To achieve this, the research team will pursue the following three interrelated research objectives.  The first is to investigate the interplay between material stiffness, surface geometry, and the loading conditions that typically arise during robotic manipulation. This will include the development of adhesion-controlled robotic grasping approaches that exploit materials and structures with tunable stiffness and adhesion.  The second objective is to engineer active contact pads that allow for high adhesive gripping forces and also high adhesion tunability. These pads will exploit a careful understanding of how material properties influence the distribution of mechanical stresses between contacting surfaces.  The third objective is to integrate the soft contact pads into robotic end-effectors or the fingertips of a robotic hand. As part of this effort, the team will demonstrate enhancements in gripping performance and versatility through a comparative study involving objects with a broad range of shapes, sizes, weights, and mechanical properties.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830218","NRI: FND: Contact-aware Control of Dynamic Manipulation","CMMI","National Robotics Initiative","09/15/2018","09/04/2018","Michael Posa","PA","University of Pennsylvania","Standard Grant","Atul G. Kelkar","08/31/2021","$504,880.00","","posa@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","ENG","8013","030E, 034E, 063Z, 8024, 8086","$0.00","Working independently and in coordination with humans and other devices, intelligent robots have the potential for profound positive impact on society. To achieve this promise, robots must be fast, capable, and safe as they interact in complex, highly uncertain environments. In this context, the fundamental tasks of grasping and dexterous manipulation are critical: when robots touch their surroundings, they typically operate slowly and cautiously to avoid any accidental contact or damage. This National Robotics Initiative (NRI) research project will develop multi-purpose algorithms for dynamic grasping and manipulation to achieve human-like speed and effectiveness for a broad range of applications. For in-home assistive robots, for example, safety and speed are both important when manipulating either objects or people.  Prosthetic devices would also benefit from reliable and dynamic semi-autonomy: too often the control burden is placed on the user, who has limited sensing and actuation through the prosthetic interface. Additionally, both small and advanced manufacturing industries that require interaction with multiple tools and parts may benefit from this research. Outcomes of this research may also benefit robotic use in safety-critical applications, such as in disaster relief efforts.<br/><br/>A fundamental challenge in dexterous manipulation lies in the complexity of the contact between robot and object. Frictional contact introduces mathematical challenges to the governing equations of motion, particularly discontinuities which result in a combinatorial number of hybrid modes. This combinatorial complexity frustrates standard algorithmic methods, typically limiting manipulation schemes to a strict sequencing of contacts, defined a priori. This research has two central hypotheses. First, that formal, optimization-based numerical methods can discover and verify simple (non-combinatoric) control approaches that will be both dynamic and robust for unstructured manipulation tasks. This simplicity parallels human control of finger forces. Second, by explicitly considering the dynamics of manipulation, this research will lead to more robust and capable approaches than purely static or quasi-static methods. The algorithms will be implemented and tested on a physical, multi-link arm and gripper and in a simulated environment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830345","NRI: INT: COLLAB: Shared Autonomy for Unstructured Underwater Environments through Vision and Language","IIS","National Robotics Initiative","09/01/2018","08/31/2018","Matthew Johnson-Roberson","MI","University of Michigan Ann Arbor","Standard Grant","David Miller","08/31/2021","$348,407.00","","mattjr@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","8013","063Z, 8086","$0.00","Existing underwater robotic systems typically provide one of two operating modes---full teleoperation or full autonomy. Teleoperation is by far the most common, particularly for tasks involving interaction with the environment, such as grasping and manipulation. Autonomy is restricted to non-contact survey missions and to controlled laboratory settings. The ability to operate between teleoperation and autonomy will improve the efficiency and effectiveness of tasks performed in underwater environments. This research will develop and evaluate a novel shared autonomy framework. The research leverages the different nature of humans and robots. This work will reduce the need for multiple, highly trained operators. It has the potential to drastically reduce the cost of underwater missions. The contributions of this research will impact the way in which humans work together with robots within a wide variety of applications, including space exploration, disaster relief, and assistive robotics.<br/><br/>As robotic systems play an ever-larger role as our surrogates for marine science and exploration, the ability to leverage the complementary nature of humans and robots becomes critical for scientific discovery. This research will develop new models and algorithms that exploit multiple non-commensurate sensing and control modalities to realize intelligent shared autonomy in complex unstructured environments. Novel to this research is the use of natural language and vision as complementary forms of weak supervision to enable robots to learn human-collaborative sensorimotor manipulation policies opportunistically from narrated human demonstrations. Fundamental to these methods is their ability to then refine these policies in situ based upon interaction with a human operator. Together, these models and algorithms will enhance the efficiency and effectiveness of underwater scientific exploration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830615","NRI: FND: Connected and Continuous Multi-Policy Decision Making","IIS","National Robotics Initiative","09/01/2018","08/23/2018","Edwin Olson","MI","University of Michigan Ann Arbor","Standard Grant","James Donlon","08/31/2021","$654,807.00","","ebolson@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","8013","063Z, 8086","$0.00","The goal of this project is to create methods that allow robots to move and communicate in close proximity to other robots or humans. In these settings, a robot must understand how its behavior is likely to influence and change the behavior of other robots and people nearby.  The basic idea of this project is to allow the robot to select between several different strategies, picking the one that is most likely to work well in a given situation. For example, a robot might decide to veer towards the right because it predicts that an approaching wheelchair requires more room than a typical pedestrian. This project will also investigate how robots can coordinate with each other, deciding what information should be transmitted to teammate robots. This type of research is important in order to build robots that can safely and comfortably interact with regular people in everyday environments like their homes, schools, and hospitals. <br/><br/>The technical approach of this project is to extend a planning algorithm known as Multi-Policy Decision Making (MPDM).  Using an on-line forward roll-out process, candidate policies are evaluated from a ""library"" of options. The core tension in MPDM type systems is that larger libraries allow more flexible behaviors, but require greater computational resources. This project achieves expressivity in a different way than previous MPDM approaches: it allows policies to have one or more continuous parameters, and then efficiently computes good values of those continuous parameters. For example, whereas earlier MPDM work might have had several policies representing different nominal speeds of travel, this work allows robot designers to explicitly parameterize velocity. This continuous-valued parameter can be tuned using backpropagation methods similar to those used in deep learning networks.  The key advantage of this approach is that a single policy can generate a wider range of behaviors, which reduces the number of policies that must be explicitly considered. In turn, this reduces the computational complexity of the planning process.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1804053","Semi-Passive Robots for Stroke Rehabilitation","CBET","Disability & Rehab Engineering","07/01/2018","06/04/2018","Chandramouli Krishnan","MI","University of Michigan Ann Arbor","Standard Grant","Aleksandr Simonian","06/30/2021","$400,000.00","C. David Remy","mouli@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","5342","","$0.00","Individuals with stroke often experience substantial muscle weakness that greatly reduces their quality of life and leads to additional long-term health problems. Rehabilitation using robotic devices is a promising approach to intensify therapy and to expedite the recovery process after stroke. However, there still exist many barriers that limit the usability of robotic devices in the clinic or the patient's home. Key barriers include the high cost of these devices, their size, and their weight. Furthermore, safety can be a concern, especially when the devices are operated without the supervision of a therapist. Consequently, most clinics and patients still rely primarily on simple devices, such as weights, pulleys, and elastic bands, for performing functional exercises to regain muscle strength and movement control during rehabilitation. This project seeks to investigate a new class of robotic devices that has the potential to be inexpensive, small, and inherently safe such that robotic therapy can be translated into small clinics and even patients' homes. The key innovation is the use of computer controllable brakes, instead of motors, to generate programmed forces to resist or gently guide the user's motion during training. Compared with motors, brakes are lighter, smaller, cheaper, and most importantly, inherently safer because they can only remove energy. Thus, brakes will never hurt a patient, even in the case of a malfunction. At the same time, the devices will maintain many of the advantages of motorized robotic systems, such as the ability to guide the patient's movements along desired paths, to track progress and scale training intensity for adequate progression during rehabilitation, and to enable interactive ""game""-like activities. These features could substantially increase the amount of therapy that patients can receive while making training fun and engaging.  This project will establish the basic design and control principles for such robots, develop two prototype robots, and then validate the clinical potential of these novel devices in healthy subjects and stroke survivors.  The project will advance the field of rehabilitation robotics by creating the scientific foundation for a new type of rehabilitation robot that will bridge the gap between fully assistive motorized robots and traditional exercise equipment. Project outcomes may not only impact the lives of millions of stroke survivors, but also others with a wide range of neurological or orthopaedic conditions, such as spinal cord injury, cerebral palsy, and joint surgeries. Additionally, the research will train students and scholars and foster outreach activities through educational opportunities for underrepresented individuals in Science, Technology, Engineering, and Math.<br/><br/>This project focuses on investigating the potential of a new class of semi-passive rehabilitation robots that will bridge the gap between current effective robotic devices that are too expensive and bulky for in-home rehabilitation and less effective, inexpensive, and  totally-passive devices such as weights and elastic bands.  The system will use controllable brakes instead of motors to generate forces to resist or gently guide the user's motion during training, which makes the device cost-effective, portable, and inherently safe for in-home use.  The Research Plan is organized under three tasks. The first task is to systematically investigate how to design and control semi-passive rehabilitation robots. The primary challenges to overcome are that such robots cannot produce arbitrary forces, but can only create forces that remove energy from the device, and that energy dissipation is in the joints of the robot, not in the robot's end-effector. Thus task activities include: 1) systematically investigating different robot structures and other design choices that influence how the motion of the end-effector handle is translated to the joints and brakes and 2) developing controllers that allow the generation of  force-fields, virtual walls, other haptic elements and closed-loop steering in trajectory tracking tasks. The second task is to conduct a thorough evaluation of the proposed device's capabilities. Task activities include: 1) developing hardware and software for prototype robots and 2) conducting tests that range from physical assessments to experiments with healthy human subjects, e.g., measuring how different types of resistance affect muscle activation of healthy subjects and implementing resistive and assistive capabilities of the robot in a version of a computer game--Pac-Man--to demonstrate how interactive elements can be used in a rehabilitation setting. The third task is to evaluate the clinical potential of the proposed device in stroke survivors. Task activities include: 1) testing how different types of resistance affect muscle activation in stroke survivors, 2) evaluating the extent to which closed-loop controllers improve performance of line-drawing tasks and 3) assessing the device's ability to break dysfunctional synergies and how training with the device affects movement kinematics, muscle coordination, and motor cortical plasticity during a simple reaching task.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1351520","CAREER: Biologically-Inspired Actuation and Control of Robotic Above-Knee Prostheses","CBET","Disability & Rehab Engineering","02/15/2014","04/16/2015","Xiangrong Shen","AL","University of Alabama Tuscaloosa","Standard Grant","Aleksandr Simonian","01/31/2019","$431,837.00","","xshen@eng.ua.edu","801 University Blvd.","Tuscaloosa","AL","354870005","2053485152","ENG","5342","010E, 1045, 9150, 9251","$0.00","Shen<br/>1351520<br/><br/>Overview: The research in this CAREER proposal addresses two fundamental issues in the emerging powered above-knee (AK) prosthetics area -- Actuation and Control -- with innovative biologically-inspired robotic approaches. The objective is to provide sufficient power output, long duration of operation, and reliable volitional control capability for powered AK prostheses to enable their use in the amputee users- daily life. By addressing these fundamental issues, this project will lay a solid foundation for the PI's long-term research goal of creating powered prosthetic devices with comparable functionality and appearance as biological limbs, so that amputee patients can enjoy life like healthy persons. The educational activities in this proposal aim to generate a synergistic impact with a series of activities under a common theme of ""Using Robotics to Help Persons with Disabilities!"" These activities will build a basis for the PI's long-term education goal of creating a comprehensive robotics education program that integrates education and research on multiple levels (graduate, undergraduate, and K-12), with the emphasis on recruiting, retaining, and mentoring students with disabilities.<br/>Intellectual Merit: Despite recent technological advances, the majority of state-of-the-art AK prostheses are still unpowered. Biomechanical studies show that these devices are unable to restore the normal locomotive functions. The research in this project aims at bringing powered AK prostheses to reality with a novel chemo-fluidic sleeve muscle actuation system, which provides a significant advantage relative to the traditional battery-DC motor system. The actuator in this new system, sleeve muscle actuator, provides a superior power density compared with DC motor (at least 10 times higher). It also enables the use of an innovative design philosophy - integrating joint actuator with load bearing structure -- and thus can potentially generate a highly compact AK prosthesis suitable for daily use. The new system also incorporates a new energy-storing medium, namely monopropellant, to provide ample energy supply for the AK prosthesis. As a unique class of liquid fuel, monopropellant releases energy through catalytic reaction (instead of combustion). The safe reaction products, oxygen and water steam, can be used directly as the high-pressure working fluid to drive the sleeve muscle actuator. As such, monopropellant can form the basis of a highly compact pneumatic supply to support the desired long duration of operation for powered AK prostheses.  The new actuation system will be complemented with a novel prosthesis control approach, namely fault-tolerant EMG direct control. This new approach enables volitional (i.e., according-to-the-intent) control of the prosthesis through the neural interface provided by electromyography (EMG).  Furthermore, to address the reliability issue of EMG interface, a fault-tolerant control structure will be created, which reconfigures the controller in the event of EMG failure.  As such, this novel approach is anticipated to allow the user to control the prosthesis according to his or her intention while avoiding the hazards from a complete controller failure, such as falling and the resulting injuries.<br/>Broader Impacts: Currently, there are more than 400,000 AK amputees in the U.S., and this number is expected to double by 2050. The proposed research has the potential to benefit society by significantly improving these amputees' mobility and quality of life. Furthermore, based on the PI's ongoing educational efforts, new education activities will be conducted in this project by integrating research into education. These activities include: (1) Establish a comprehensive plan for the recruitment, retention, and mentoring of students with disabilities; (2) Contribute to graduate education in both engineering and prosthetics & orthotics with the efforts towards bridging the gap between biomedical engineering research and clinical practice; (3) Promote undergraduate research with a multi-year research project aiming at developing a robotic arm exhibit for a science museum; (4) Outreach into K-12 education system to promote science and engineering with robotics-themed activities, collaborating with the first STEAM-accredited elementary school in the world."
"1656101","NRI: Collaborative Research: Human-Supervised Manipulation of Deformable Objects","IIS","National Robotics Initiative","07/01/2016","08/24/2016","Dmitry Berenson","MI","University of Michigan Ann Arbor","Standard Grant","Irina Dolinskaya","07/31/2019","$322,319.00","","berenson@eecs.umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","8013","8086","$0.00","The goal of the proposed work is to develop algorithms that enable human-supervised robotic manipulation of deformable objects under significant uncertainty. Manipulation of deformable objects is essential in surgery, which involves complex manipulations of delicate and highly deformable tissue under substantial uncertainty, and in manufacturing, where many assembly tasks involve flexible parts and materials (e.g. cables, textiles, and composites). Recent advances in robot hardware (e.g. the da Vinci and Baxter robots) have made robotic manipulation of deformable objects physically possible but robots still lack the algorithms necessary to perform practical tasks in this domain when there is significant model uncertainty. This project will have broad societal impact through its applications in surgical and manufacturing robotics. The ability to robustly manipulate deformable structures is an important precursor technology towards realizing intelligent robotic surgical assistants. Robotics and its medical applications have the potential to inspire children to pursue careers in STEM fields and meet the needs of America's growing health-care and manufacturing robotics industry. Integration of the research activities with education will emphasize actively involving undergraduates in research activities and introducing new lecture material and projects into undergraduate and graduate courses. Also, special emphasis will be given to recruit qualified students from under-represented groups. <br/><br/>The purpose of the proposed research is to develop algorithms that enable human-supervised robotic manipulation of deformable objects under substantial uncertainty. Specifically, the research will focus on developing adaptive complexity models for modeling deformable object dynamics and associated uncertainty, planning algorithms for integrated exploration and task execution, control algorithms for robust manipulation of deformable objects under uncertainty, and algorithms for effective human supervision of robotic manipulation of deformable objects. The intellectual merit of the project comes from its fundamental contributions to robotic modeling, planning, and control algorithms for manipulation of deformable objects. The research will have impact in the fields of robotic manipulation, motion planning under uncertainty, and compliant manipulation control."
"1733680","AiTF: Collaborative Research: Distributed and Stochastic Algorithms for Active Matter: Theory and Practice","CCF","Algorithms in the Field, ALGORITHMIC FOUNDATIONS","01/01/2018","05/15/2018","Andrea Richa","AZ","Arizona State University","Standard Grant","Rahul Shah","12/31/2020","$216,000.00","","aricha@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7239, 7796","7934, 9102, 9251","$0.00","Swarm robotics explores how groups of robots can work towards a singular goal, which is typically achieved by equipping each robot with sensory capabilities, basic computing power, and movement. The sensors detect and use information about the environment to decide on the next action. Swarm robotics has made many advances in recent years, but is still in its infancy. This project proposes to explore swarm robotics systems in a non-standard way as  physical systems. The PIs take a ""task-oriented"" approach to develop the distributed algorithmic rules that the robots will run (at the microscopic level) in order to converge to the desired collective behavior (at the macroscopic level).  This will provide understanding of the minimal requirements for individuals to accomplish the desired behavior, for both algorithmic and physical realizations, and will provide a more principled approach for studying swarm robotics. The robots envisioned are small in scale, ranging in size from millimeters to centimeters, so that when deployed in dense environments, they will behave as programmable active matter.<br/><br/>The PIs have strong records for interdisciplinary research, including initiating interdisciplinary areas (e.g., robo-physics, self-organizing particle systems, and the fusion of statistical physics and randomized algorithms). They have a strong commitment toward supporting minorities, women, and undergrad research (e.g., through NSF REUs, including through this project, NSF S-STEM programs at ASU; ADVANCE and S.U.R.E. programs at Georgia Tech).  Any breakthrough in this combination of swarm and active matter systems will require employing analyses and techniques from stochastic systems, condensed matter physics, swarm systems, robotics, and distributed algorithms to understand and achieve the desired group dynamics, and hence will bring together and educate researchers from different disciplines and specialties.  New research approaches and findings will be incorporated into multiple graduate courses and workshops will provide tutorials for bridging multiple disciplines, making material accessible to young researchers and helping to widely disseminate results. Findings (including open source code) will be published in the various disciplines, and will be be made available on our web pages and ArXiv.   <br/> <br/>The project explores the fundamentals of swarm robotics from a physics standpoint, by viewing the ensemble as active matter composed of programmable elements at the micro-level.  The project will follow a (macro-)task oriented approach, and design a distributed stochastic algorithmic framework to design and evaluate algorithms at the micro-level that will yield the targeted emergent macroscopic behavior.  The emergent behaviors it addresses include compression (maintaining coherence of a connected community while minimizing perimeter), bridging (connecting two or more locations in the most efficient manner), alignment (determining an agreed upon direction of orientation), jamming (obstruction of movement by increased collective flow), and locomotion (collectively moving while maintaining cohesiveness). Many of these have interesting converse problems which are also equally worthwhile, such as exploration (maintaining a connected population, but exploring maximal area) and non-alignment (representing a disordered ensemble). In some cases the collective behavior acts like a physical system changing between a liquid (disordered) and a solid (ordered) state, as determined by phase transitions in the systems. The project will explore stochastic and distributed algorithms for rigorously achieving these goals."
"1637393","AitF: Collaborative Research: A Distributed and Stochastic Algorithmic Framework for Active Matter","CCF","ALGORITHMIC FOUNDATIONS","09/01/2016","08/12/2016","Andrea Richa","AZ","Arizona State University","Standard Grant","Tracy J. Kimbrel","08/31/2019","$100,000.00","","aricha@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7796","","$0.00","Swarm robotics explores how groups of robots can work towards a singular goal. Such a goal is typically achieved by equipping each robot with sensory capabilities, basic computing power, and actuation. The sensors detect something about the environment, this information is used to make a decision about the next action, and some resulting actuation is performed. Swarm robotics has made many advances in recent years, but it is still in its infancy.  The PIs will take a ""task-oriented"" approach and start from a desired macroscopic emergent collective behavior to develop the distributed and stochastic algorithmic underpinnings that the robots will run (at the microscopic level) in order to converge to the desired macroscopic behavior; as part of the process, they will also provide the understanding for yet unexplored  collective and emergent systems. The robots envisioned are small in scale, ranging in size from millimeters to centimeters, so that when deployed in crowded (i.e., dense) environments, they will behave as active matter, more specifically as macroscopic programmable active matter.  The emergent behaviors of interest for simulations include clustering (forming a tight-knit community that is mostly well-connected), compression (maintaining coherence of a connected community while minimizing perimeter), flocking (determining an agreed upon direction of orientation), and locomotion (collectively moving while maintaining cohesiveness). Many of these have interesting converse problems which are also equally worthwhile, such as exploration (maintaining a connected population, but exploring maximal area) and desegregation (preventing separation in a binary mixture of particles).<br/><br/>The PIs have strong records for interdisciplinary research, including initiating interdisciplinary areas, e.g., robo-physics (Goldman), self-organizing particle systems (Richa), and the fusion of statistical physics and randomized algorithms (Randall). The PIs also have a strong commitment toward supporting minorities, women, and undergraduate research (e.g., through NSF S-STEM programs at ASU; ADVANCE and S.U.R.E. programs at Georgia Tech).  This project will bring together techniques from multiple disciplines, and new research approaches and findings will be incorporated into graduate courses. Findings (including open source code) will be published in the various disciplines, and will be made available on the web and ArXiv.<br/><br/>The specific goals of this project are to work toward developing a theoretical framework for task-oriented active matter, informed by models of simple physical systems, that can realize and test the algorithms. The swarm robotics systems that biophysicists build to understand nature can be modified to perform the tasks these new algorithms require. The physical models will allow refinements to the theories under additional constraints, such as gravity and limited energy. It also will allow the PIs to test their algorithms for robustness, as physical systems admit some error.  The fundamentals of swarm robotics will be studied from a physics standpoint, by viewing the ensemble as active matter composed of programmable elements at the micro-level. Thus, a (macro-)task oriented approach will be followed in order to design a distributed, stochastic algorithmic framework to construct and evaluate algorithms at the micro-level that yield the targeted emergent macro-behavior."
"1830419","NRI: FND: COLLAB: Distributed, Semantically-Aware Tracking and Planning for Fleets of Robots","IIS","National Robotics Initiative","10/01/2018","08/31/2018","Philip Dames","PA","Temple University","Standard Grant","Ralph Wachter","09/30/2021","$281,370.00","","pdames@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","CSE","8013","063Z, 8086","$0.00","The ability to track, predict and reason about pedestrians and vehicles in a fast-paced dense urban environment is crucial to ensuring that autonomous vehicles can operate safely and dependably.  This project focuses on providing that capability to fleets of autonomous cars and delivery drones, allowing these autonomous systems to realize their promised societal benefits, such as the potential for greater mobility of people and goods while reducing traffic congestion and increasing safety.  This technology can moreover be customized for other applications such as large manufacturing operations and even small household robotic applications.  The methods and results from this project will be included in course curricula and in used outreach programs and events.<br/><br/>The project approaches this challenge in several ways: (i) combine classification algorithms from machine vision with the motion tracking of the objects from multi-target Bayesian filters into a new filtering architecture; (ii) generate new online, distributed tessellation algorithms, using tools from Voronoi-based distributed coverage control, to dynamically partition the surrounding environment in a way that leverages the innate parallelism of teams of multi-robots; (iii) use this partition to create a distributed memory architecture that has bandwidth-efficient updates and ensures data integrity in the face of system errors and malicious agents; (iv) develop semantically-aware path planning algorithms for fast, online optimization of robot motion that account for the range of possible reactionary behaviors of other objects; and (v) design an app-based interface that facilitates two-way information exchange between a human operator and the multi-robot team.  A prototype system based on these advances will be tested and evaluated in a highly instrumented laboratory environment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830660","NRI: INT: COLLAB: Shared Autonomy for Unstructured Underwater Environments through Vision and Language","IIS","National Robotics Initiative","09/01/2018","08/31/2018","Matthew Walter","IL","Toyota Technological Institute at Chicago","Standard Grant","David Miller","08/31/2021","$313,303.00","","mwalter@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372803","7738340409","CSE","8013","063Z, 8086","$0.00","Existing underwater robotic systems typically provide one of two operating modes---full teleoperation or full autonomy. Teleoperation is by far the most common, particularly for tasks involving interaction with the environment, such as grasping and manipulation. Autonomy is restricted to non-contact survey missions and to controlled laboratory settings. The ability to operate between teleoperation and autonomy will improve the efficiency and effectiveness of tasks performed in underwater environments. This research will develop and evaluate a novel shared autonomy framework. The research leverages the different nature of humans and robots. This work will reduce the need for multiple, highly trained operators. It has the potential to drastically reduce the cost of underwater missions. The contributions of this research will impact the way in which humans work together with robots within a wide variety of applications, including space exploration, disaster relief, and assistive robotics.<br/><br/>As robotic systems play an ever-larger role as our surrogates for marine science and exploration, the ability to leverage the complementary nature of humans and robots becomes critical for scientific discovery. This research will develop new models and algorithms that exploit multiple non-commensurate sensing and control modalities to realize intelligent shared autonomy in complex unstructured environments. Novel to this research is the use of natural language and vision as complementary forms of weak supervision to enable robots to learn human-collaborative sensorimotor manipulation policies opportunistically from narrated human demonstrations. Fundamental to these methods is their ability to then refine these policies in situ based upon interaction with a human operator. Together, these models and algorithms will enhance the efficiency and effectiveness of underwater scientific exploration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813550","AF: SHF: Small: Algorithmic and Architectural Foundation for Next-Generation Collective DNA Robots","CCF","SPECIAL PROJECTS - CCF, COMPUTATIONAL BIOLOGY","10/01/2018","08/31/2018","Lulu Qian","CA","California Institute of Technology","Standard Grant","Mitra Basu","09/30/2021","$425,000.00","","luluqian@caltech.edu","1200 E California Blvd","PASADENA","CA","911250600","6263956219","CSE","2878, 7931","7923, 7931, 7946, 9102","$0.00","A molecular robot is an important type of artificial molecular machine that automatically carry out nanomechanical tasks. DNA is an excellent material for building molecular robots, because their geometric, thermodynamic and kinetic properties are well understood and highly programmable. There exist no systematic approaches for translating high-level mechanical tasks to low-level molecular implementations nor software tools that enable researchers with diverse backgrounds to build DNA robots with new functions. To accomplish that, more simple algorithms and more modular building blocks are needed to create a wider range of collective behaviors, until there is enough understanding for the development of a molecular robotics programming language that will work in practice. This project will provide better answers to the following questions: To what extent can simple algorithms allow increasingly complex nanomechanical tasks to be programmed and carried out by DNA molecules? Does cooperation in DNA robots allow more complex tasks to be accomplished with less time and less energy? What composability issues arise when new building blocks are added to the toolbox for general-purpose DNA robots? What design principles can allow DNA robots to function well in increasingly complex and diverse operating environments? The scientific understanding will be incorporate into public online software tools to assist the design and construction of molecular robots, which will be introduced into the classroom. Course materials will be shared among multiple educational institutions. Public engagement will be promoted through public talks, lab tours, podcasts, news stories, YouTube videos and artwork.<br/><br/>The project involves three main goals: developing a new building block for leaving pheromone-like signals to mark where a robot has been, demonstrating how the new building block can be used to construct DNA robots that find and modify a direct path from the entrance to the exit in an arbitrary maze, and developing software tools that automatically convert user-specified robotics systems to design diagrams, simulations, DNA sequences and experimental protocols. DNA origami technique will be used to build testing grounds for DNA robots, while DNA strand displacement mechanism will be used to program the behavior of DNA robots. Fluorescence spectroscopy and atomic force microscopy will be used to quantitatively analyze the behavior of DNA robots, in bulk and at the single-molecule level. The team of investigators will study the mechanisms for tuning the behavior of DNA robots, if it is qualitatively but not quantitatively as designed, and understand how the behavior of DNA robots depends on the specific configuration of their operating environment. The new building block expands the toolbox for general-purpose DNA robots and allows tasks that involve surveying and marking an unknown environment. The maze-solving robots could be used to perform efficient molecular transportation where a group of leader robots mark a direct path in a complex environment using very little energy and a group of follower robots walk on marked path only to transport molecular cargos without spending any time on indirect routes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1724191","S&AS: FND: COLLAB: Learning Manipulation Skills Using Deep Reinforcement Learning with Domain Transfer","IIS","S&AS - Smart & Autonomous Syst","09/01/2017","08/16/2017","Robert Platt","MA","Northeastern University","Standard Grant","Jie Yang","08/31/2020","$300,000.00","","r.platt@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","039Y","046Z","$0.00","This project develops new methods of using deep reinforcement learning to solve real world robotics problems. The project focuses on robotic manipulation tasks such as grasping, opening doors, helping out in the home, performing repairs aboard Navy ships, etc. The key operation in all of the above is the ability for the robot to reliably manipulate objects, parts, or tools with its hands in order to perform a task. The project leverages deep reinforcement learning: a new approach to robotic learning that is capable of learning both perceptual features and control policies simultaneously. This project could have important benefits for a variety of practical applications including: explosive ordnance disposal for our military, materials handling aboard Navy ships, dexterous robotic assistants for NASA astronauts in space, assistive technologies that could help seniors age in place longer, better capabilities for handling radioactive materials during nuclear cleanup, assistance for ergonomically challenging tasks in manufacturing, and general assistance in the office and the home.<br/><br/>This research investigates novel deep reinforcement learning approaches for robotic grasping and manipulation that work well in previously unseen, unstructured environments and compose end-to-end tasks from simpler sub-task controllers. The research is built on two main results from research team's recent work, the deep learning approach to grasping and domain adaptation methods for deep neural networks. The research is guided by the following three key ideas: 1) learning in simulation and then using domain transfer techniques to adapt the solutions to reality; 2) simplifying learning for visuomotor control by using planning to estimate the value function; and 3) using symbolic task and motion planning to perform end-to-end tasks by sequencing learned controllers and planned arm/hand motions. The research team performs extensive evaluations to ensure that the system is able to perform novel instances of a task, e.g., those in a context that the robot has not seen before."
"1830450","NRI:FND:COLLAB: Girls Immersed in Robotics Learning Simulations (GIRLS)","IIS","ITEST","09/01/2018","08/31/2018","Florence Sullivan","MA","University of Massachusetts Amherst","Standard Grant","David Haury","08/31/2021","$382,303.00","","fsullivan@educ.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","7227","063Z, 8086","$0.00","This project aims to promote interest and learning about robotics, computer science, and other fields of science, technology, engineering, and mathematics (STEM) among middle school girls. The project will engage students who are attending summer camps or out-of-school programs during vacation weeks in immersive simulations of how ubiquitous, collaborative robots can be used to provide relief to people impacted by natural disasters, such as hurricanes. A collaborative robot, or co-robot, is a robot intended to physically interact with humans in a shared environment or workspace.  The students will create and take part in an immersive simulation of a co-robotics enhanced emergency response to assist first responders and other recovery workers by using wheeled robots and flying, programmable drones.  Students will also discuss the social, economic, ethical, and legal implications of using ubiquitous co-robots in these settings.  <br/><br/>Girls and students from populations underrepresented in STEM fields generally have less exposure, access, and experience with important domains of learning due to social barriers. This mixed-methods study is guided by the hypothesis that girls will positively respond to role-playing in immersive simulations of helping residents in a town recover from a natural disaster, and as a result, will exhibit greater engagement and interest in robotics as a field and possible career choice. Students will be separated into two groups: a) An experimental group that will receive a co-robotics curriculum contextualized by a real-world immersive simulation narrative of an emergency response to the recent Puerto Rico hurricane or a similar natural disaster, and b) A comparison group that will receive just the co-robotics curriculum. The goals of the project are: (1) Test the effectiveness of an immersive simulation educational strategy as an introduction to co-robotics; (2) Design, implement, and test the innovative middle school co-robotics curricula and assessments, including the social, economic, ethical, and legal implications of co-robotics as they are used in first responder situations; (3) Broaden participation in robotics, computer science, and STEM fields by engaging traditionally underrepresented populations, specifically Latinx girls, through an immersive simulation of disaster recovery where co-robotics technology is used to help people; and (4) Increase student self-efficacy, interest, awareness, and participation in co-robotics activities that could lead to future robotics, computer science and STEM careers. Student interest, and awareness will be assessed through pre-post self-efficacy, interest, and career awareness surveys.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637737","NRI: Workers, Firms, and Industries in Robotic Regions","IIS","National Robotics Initiative","09/01/2016","05/08/2018","Nancey Green Leigh","GA","Georgia Tech Research Corporation","Standard Grant","Frederick M Kronz","08/31/2019","$784,887.00","Henrik Christensen","ngleigh@gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","8086","$0.00","This research project focuses on the U.S. robotics industry and the economic impacts of robotics technology. The researchers will generate new data and then analyze it. The goal of the project is to assess the impacts of robotics on work and the economy following a significant leap in robotic capabilities that has enabled robot-human collaboration. It will build on previous work of the research team, which characterized the U.S. robotics industry and identified regions that host relatively intense research, development, and commerce relating to robotics. The researchers will use a mixed methods approach that situates robot use and diffusion in a regional context. They will survey manufacturers about their robot use and associated employment patterns, and they survey of systems integrators; their prior research has determined that systems integrators are as a group crucial to the U.S. robotics industry. They will also analyze novel labor market data to assess robot-related employment supply and demand, and they will conduct a cross-case comparison of two robotic regions that have significant robotics-related employment. This research will enable current and future policy makers, workers, and corporate leaders to make more informed decisions in anticipation of-and in response to-the diffusion of robots throughout the economy. It will shed light on evolving employment structures, the changing nature of work, firm strategies, and regional economic evolution as robots diffuse. Professional and trade associations, regional planning, workforce and economic development agencies, and popular media will be targeted for dissemination efforts. <br/><br/>The proposed research will advance understanding of the relationship between 21st century technology and work, meeting a need to assess robots as more than just advanced manufacturing technology, given the rise of collaborative robots in manufacturing and expected diffusion into the service sector. It employs a comprehensive approach to assessing technological change by combining theoretical perspectives and empirical analysis of regional economic development with engineering approaches to robot development and adoption in production. The research team is multidisciplinary, including professors of economic development planning and robotics engineering. The proposed research extends the team's preliminary research, which indicates that distinct robotic regions have emerged within the US. It overcomes the significant deficit of actual data on robot use and diffusion at the national and subnational levels through the use of industry survey and case study methodologies, and through an analysis of real time labor market data made possible through advances in big data collection. By identifying regional factors that lead to innovations in robotics technologies and influence local firm decisions to use robots, this research will equip local policy makers with knowledge to foster competitive and resilient places in the context of rapid technological change."
"1638060","NRI: Collaborative Research: Sketching Geometry and Physics Informed Inference for Mobile Robot Manipulation in Cluttered Scenes","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2016","08/10/2016","Joseph LaViola","FL","University of Central Florida","Standard Grant","Reid Simmons","08/31/2019","$286,434.00","","jjl@cs.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","CSE","7495, 8013","8086","$0.00","The goal of this project is to improve the ability of robots to manipulate and interact with objects, such as when assisting people to support their daily activities.  The key idea is that people can provide robots with important information about their environment and the objects within their environment. In particular, people can use their cognitive skills to name objects, provide an understanding of the geometrical structure of objects, and describe an object's behavior in relation to other objects. Specifically, the project will develop a natural user interface that enables people to provide such information by drawing and sketching on top of the robot's view of the world.  Physical simulation will then be used to fill in the missing gaps needed for a robot to complete autonomous manipulation tasks. Thus, the project aims to combine object sketching and physical simulation to better support mobile manipulation tasks as well as learn to perform new manipulation tasks when encountered.  The project will support a ""Put That There"" task, where a user can simply give high-level manipulation commands, with the robot filling in the details necessary to complete the task in a cluttered environment.<br/><br/>This project aims to improve goal-directed dexterous robotic manipulation in cluttered and unstructured environments through sketching and physical simulation. Robots operating in human environments face considerable uncertainty in perception due to physical contact and occlusions between objects. This project will address such perceptual uncertainty by combining methods for probabilistic inference with natural sketch-based interfaces to extract, label, and automatically infer the geometry, pose, and behavior of objects in complicated scenes.  From a human usability perspective, the project addresses how to best create a sketching language and interfaces for intuitive human-in-the-loop extraction of object geometries and behavior from robot sensing.  The planned exploration into sketching methods will also explore what underlying representations, raw point clouds, RGB images and video, or RGBD images will be most conducive to supporting accurate geometry extraction and grasp location identification.  Given sketched objects, the project will develop probabilistic physically plausible methods for scene estimation that will enable perception for manipulation in cluttered environments.  These methods build upon advances in physical simulation to constrain scene estimates to only plausible configurations to both improve estimation accuracy and enable computational tractability.  The project will also develop a ""Put That There"" testbed using a tablet-based web application to support exploration of these concepts as well as act as user studies to evaluate geometry extraction accuracy and the robustness of physics-based scene estimation algorithms."
"1830500","NRI: INT: COLLAB: Shared Autonomy for Unstructured Underwater Environments through Vision and Language","IIS","National Robotics Initiative","09/01/2018","08/31/2018","Richard Camilli","MA","Woods Hole Oceanographic Institution","Standard Grant","David Miller","08/31/2021","$511,549.00","","rcamilli@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","CSE","8013","063Z, 8086","$0.00","Existing underwater robotic systems typically provide one of two operating modes---full teleoperation or full autonomy. Teleoperation is by far the most common, particularly for tasks involving interaction with the environment, such as grasping and manipulation. Autonomy is restricted to non-contact survey missions and to controlled laboratory settings. The ability to operate between teleoperation and autonomy will improve the efficiency and effectiveness of tasks performed in underwater environments. This research will develop and evaluate a novel shared autonomy framework. The research leverages the different nature of humans and robots. This work will reduce the need for multiple, highly trained operators. It has the potential to drastically reduce the cost of underwater missions. The contributions of this research will impact the way in which humans work together with robots within a wide variety of applications, including space exploration, disaster relief, and assistive robotics.<br/><br/>As robotic systems play an ever-larger role as our surrogates for marine science and exploration, the ability to leverage the complementary nature of humans and robots becomes critical for scientific discovery. This research will develop new models and algorithms that exploit multiple non-commensurate sensing and control modalities to realize intelligent shared autonomy in complex unstructured environments. Novel to this research is the use of natural language and vision as complementary forms of weak supervision to enable robots to learn human-collaborative sensorimotor manipulation policies opportunistically from narrated human demonstrations. Fundamental to these methods is their ability to then refine these policies in situ based upon interaction with a human operator. Together, these models and algorithms will enhance the efficiency and effectiveness of underwater scientific exploration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1626505","MRI: Acquisition of robotic tools for studying brain, behavior and embodied cognition","BCS","MAJOR RESEARCH INSTRUMENTATION","09/01/2016","09/06/2016","Ramesh Balasubramaniam","CA","University of California - Merced","Standard Grant","John E. Yellen","08/31/2019","$182,806.00","Michael Spivey, Stefano Carpin","ramesh@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2097566405","SBE","1189","1189","$0.00","This project will make a new robotic exoskeleton arm with integrated virtual reality and eye-tracking facilities available to researchers for the study of human embodied and situated cognition at UC Merced, the tenth and newest campus of the University of California system. The equipment would enable cutting-edge research in the study of human cognition using tools from robotics benefitting a range of Faculty and students across various departments including Cognitive & Information Sciences, Electrical Engineering & Computer Science, Mechanical Engineering and Digital Humanities. The equipment will catalyze research in several directions including 1) Human Motor Control & Action Dynamics with applications for physical rehabilitation 2) Embodied Cognition and Action 3) Brain-behavior interactions 4) Fundamental human-inspired robotics research 5) Human-machine interactions 6) Language, Communication & Gesture. The robotic arm will provide a sophisticated platform to monitor and manipulate the upper limb, providing a broad range of hand and joint-based kinesthetic information and gaze information. With built in virtual/augmented reality, the robot arm system will allow for altering visual information to be presented to human participants while manipulating their arm movements. The work will help build institutional capacity in an area of strategic focus at UC Merced and will result in direct collaborations between scientists and students across various departments on campus. The impact of the training resulting from the equipment is expected to be particularly broad at UC Merced due to its exceptionally diverse student body and the large number of programs focused on increasing the participation of underrepresented minorities.<br/><br/>Researchers including the PI: Balasubramaniam and Co-PIs Spivey and Carpin also plan on perturbing neural activity using techniques such as Transcranial Magnetic Stimulation (TMS) and recording brain activity during the perturbation of arm movements using the robotic device. The transformative aspect of this research comes from its ability to observe and manipulate brain activity and complex motor behavior simultaneously."
"1632259","NSF/SBE-BSF:Integration of kinesthetic and tactile information in perception, action, and learning","BCS","CROSS-DIRECTORATE  ACTIV PROGR, Disability & Rehab Engineering, Engineering of Biomed Systems, PERCEPTION, ACTION & COGNITION, EFRI RESEARCH PROJECTS, IntgStrat Undst Neurl&Cogn Sys","09/15/2016","09/09/2017","Ferdinando Mussa-Ivaldi","IL","Rehabilitation Institute of Chicago","Continuing grant","Betty H. Tuller","08/31/2019","$479,212.00","","sandro@northwestern.edu","345 East Superior Street","Chicago","IL","606112654","3122384534","SBE","1397, 5342, 5345, 7252, 7633, 8624","014Z, 1397, 7252, 8089, 8091","$0.00","Simple acts such as opening a jar or lighting a match depend on the ability to grasp objects with different shapes and to apply well-regulated forces and movements in different directions. When we hold a glass of water, the forces applied by the fingers are directed against the surface of the glass, and our brain coordinates these forces to prevent slippage and maintain the orientation of the glass. The planned studies will combine computational methods derived from control engineering and robotics with techniques and theories from neuroscience to understand how the brain controls grip forces when lifting and manipulating objects and how it estimates an object's mechanical properties. The investigations will consider how grasping an object is affected by uncertainties about the object properties (e.g., it's hardness, slipperiness, texture, etc) and how fundamental manipulation skills may be enhanced by artificially augmenting tactile information. The outcomes of these studies will influence several domains including (1) neuroscience (understanding our ability to  control and manipulate objects with our hands); (2) technology (for presenting force information to users of robotic devices such as teleoperation and robot-assisted surgery); and (3) neurorehabilitation (for developing intelligent robotic prostheses and new exercises to promote the recovery of lost manual skills). These studies will establish a collaborative interaction between scientists in the United States and Israel having a range of expertise that includes robotics, control, motor systems neuroscience and neurorehabilitation.<br/><br/>Getting the fingers to cooperate during dexterous manipulation requires the integration of different types of information. The fingers have a rich array of tactile sensors that generate signals related to the interaction with the object. However, for the brain to know the magnitude and direction of these forces, it must also know the orientation of the fingers in space. This information is obtained by other sources that form the basis for the sense of position of the body in space. The control of grasp can also be informed by kinesthetic force sensors in the muscles that in turn are integrated with the sense of the joint's configuration in space. This project takes advantage of a new technology that allows applying controlled stretches to the skin of the fingers. Skin stretch devices mounted on a robotic manipulator will be used to apply a variety of controlled perturbations while subjects are performing manipulation tasks. Perturbations will be applied to increase or decrease the consistency between tactile and kinesthetic feedback, and to investigate how the brain adapts the ability to maintain a stable grasp during both unpredictable and predictable forces. The approach will combine theory and experiments to tackle the integration of multiple information sources in perception and in controlling manipulation and grip forces.<br/><br/>This project is being supported by a partnership between the National Science Foundation and the U.S.-Israel Binational Science Foundation."
"1734981","NCS-FO: Collaborative Research: Understanding the neural basis for sensorimotor control loops using whisker-based robotic hardware platforms","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/07/2017","Mitra Hartmann","IL","Northwestern University","Standard Grant","Betty H. Tuller","08/31/2020","$666,298.00","L. Brinson","m-hartmann@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","SBE","8624","8089, 8091, 8551, 9251","$0.00","This project will construct robots in order to understand how animals gather information through the sense of touch and how animals use touch information to perform complex behaviors. The results will be important to both neuroscience and engineering. On the neuroscience side, the results will address how the brain combines information about movement and touch, thereby improving our understanding of stroke and brain injury. On the engineering side, the work will develop novel robots and sensors that use touch to sense object location, shape, and texture, to track fluid wakes in water, and to sense the direction of airflow. These capabilities will improve the ability of robots to work in challenging environments; for example, robots could explore dark areas more easily or provide surgeons with a better sense of touch during surgery. To train the next generation of scientists and engineers, both undergraduate and graduate students will help construct the robots and will explore industry- and government-related applications of whisker-based touch sensing. The research team will investigate technology transfer opportunities in robotics and medicine, flow sensing, instrument placement, corrosion detection, three-dimensional tactile profilometry, and compliance sensing. <br/><br/>The fundamental scientific rationale for the work is that understanding how animal nervous systems process complex sensory and motor information necessarily requires quantification of the input. However, it is currently impossible for neuroscientists to record from all primary sensory neurons involved in a particular sensorimotor behavior. The three stages of this project exploit the whisker system of mammals in an endeavor to completely quantify whisker-based input and early neural processing in the rat (Rattus norvegicus) and the harbor seal (Phoca vitulina). The first stage of work will focus on the development of modular, reconfigurable, artificial whiskers that can sense both touch and fluid flow. The materials, manufacturing, and sensor designs necessary for whiskers at multiple length scales will be investigated and signals from the whiskers will be represented based on known coding properties of primary whisker-sensitive neurons in the trigeminal ganglion (TG). The second stage of work will involve the construction of whisker arrays that anatomically match those of the rat and the seal. These arrays will be used to develop combined hardware and software models of the responses of the entire population of TG neurons. Finally, in the third stage of work, the whisker arrays will be mounted on robotic platforms, and the robots will be put through the same head movements as real animals during natural behavior. This process will allow us to simulate the entire TG neuron population response during complex, natural behaviors. Overall, the project will help unlock the basis by which low-level but powerful neural circuits confer animals with flexibility and resourcefulness in sensing and movement. This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a mulitdisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1830402","NRI: FND: COLLAB:  Distributed Semantically-Aware Tracking and Planning for Fleets of Robots","IIS","National Robotics Initiative","10/01/2018","08/31/2018","Mac Schwager","CA","Stanford University","Standard Grant","Ralph Wachter","09/30/2021","$467,989.00","","schwager@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","8013","063Z, 8086","$0.00","The ability to track, predict and reason about pedestrians and vehicles in a fast-paced dense urban environment is crucial to ensuring that autonomous vehicles can operate safely and dependably.  This project focuses on providing that capability to fleets of autonomous cars and delivery drones, allowing these autonomous systems to realize their promised societal benefits, such as the potential for greater mobility of people and goods while reducing traffic congestion and increasing safety.  This technology can moreover be customized for other applications such as large manufacturing operations and even small household robotic applications.  The methods and results from this project will be included in course curricula and in used outreach programs and events.<br/><br/>The project approaches this challenge in several ways: (i) combine classification algorithms from machine vision with the motion tracking of the objects from multi-target Bayesian filters into a new filtering architecture; (ii) generate new online, distributed tessellation algorithms, using tools from Voronoi-based distributed coverage control, to dynamically partition the surrounding environment in a way that leverages the innate parallelism of teams of multi-robots; (iii) use this partition to create a distributed memory architecture that has bandwidth-efficient updates and ensures data integrity in the face of system errors and malicious agents; (iv) develop semantically-aware path planning algorithms for fast, online optimization of robot motion that account for the range of possible reactionary behaviors of other objects; and (v) design an app-based interface that facilitates two-way information exchange between a human operator and the multi-robot team.  A prototype system based on these advances will be tested and evaluated in a highly instrumented laboratory environment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830179","NRI:FND:COLLAB: Girls Immersed in Robotics Learning Simulations (GIRLS)","IIS","ITEST","09/01/2018","08/31/2018","Beryl Hoffman","MA","College of Our Lady of the Elms","Standard Grant","David Haury","08/31/2021","$188,394.00","","hoffmanb@elms.edu","291 Springfield Street","Chicopee","MA","010132837","4132652298","CSE","7227","063Z, 8086","$0.00","This project aims to promote interest and learning about robotics, computer science, and other fields of science, technology, engineering, and mathematics (STEM) among middle school girls. The project will engage students who are attending summer camps or out-of-school programs during vacation weeks in immersive simulations of how ubiquitous, collaborative robots can be used to provide relief to people impacted by natural disasters, such as hurricanes. A collaborative robot, or co-robot, is a robot intended to physically interact with humans in a shared environment or workspace.  The students will create and take part in an immersive simulation of a co-robotics enhanced emergency response to assist first responders and other recovery workers by using wheeled robots and flying, programmable drones.  Students will also discuss the social, economic, ethical, and legal implications of using ubiquitous co-robots in these settings.  <br/><br/>Girls and students from populations underrepresented in STEM fields generally have less exposure, access, and experience with important domains of learning due to social barriers. This mixed-methods study is guided by the hypothesis that girls will positively respond to role-playing in immersive simulations of helping residents in a town recover from a natural disaster, and as a result, will exhibit greater engagement and interest in robotics as a field and possible career choice. Students will be separated into two groups: a) An experimental group that will receive a co-robotics curriculum contextualized by a real-world immersive simulation narrative of an emergency response to the recent Puerto Rico hurricane or a similar natural disaster, and b) A comparison group that will receive just the co-robotics curriculum. The goals of the project are: (1) Test the effectiveness of an immersive simulation educational strategy as an introduction to co-robotics; (2) Design, implement, and test the innovative middle school co-robotics curricula and assessments, including the social, economic, ethical, and legal implications of co-robotics as they are used in first responder situations; (3) Broaden participation in robotics, computer science, and STEM fields by engaging traditionally underrepresented populations, specifically Latinx girls, through an immersive simulation of disaster recovery where co-robotics technology is used to help people; and (4) Increase student self-efficacy, interest, awareness, and participation in co-robotics activities that could lead to future robotics, computer science and STEM careers. Student interest, and awareness will be assessed through pre-post self-efficacy, interest, and career awareness surveys.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1752902","Workshop to Explore US/Korean Collaboration in Human-Friendly Co-Robotic Technologies","IIS","ROBUST INTELLIGENCE","09/01/2017","08/19/2017","Richard Voyles","IN","Purdue University","Standard Grant","David Miller","08/31/2019","$14,980.00","Byung-Cheol Min","rvoyles@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7495","7495, 7556","$0.00","This proposal supports a workshop on U.S. and South Korean collaboration in the area of robotics, specifically humanoid robots that collaborate with people.  International collaboration is important for keeping U.S. researchers abreast of the latest technological developments around the world, which have impact on our quality of life, quality of work, and quality of education.  The workshop will be held in conjunction with the International Conference on Intelligent Robots and Systems (IROS), in Vancouver, Canada, September 2017.  The focus of the workshop is to keep abreast of latest developments in robotics research, communicate the benefits of the U.S. environment supporting leading edge innovation, and begin a ?match-making? process to connect U.S. and South Korean robotics researchers.  The goal is to develop a sustainable model for international collaboration, where the benefits exceed the added administrative burdens typical of such collaborations.  Innovative approaches both during and after the workshop will be employed in order to develop and nurture nascent research collaborations."
"1734557","NRI: FND: Scalable Multimodal Tactile Sensing for Robotic Manipulators in Manufacturing","CMMI","National Robotics Initiative","09/01/2017","07/27/2017","Matei Ciocarlie","NY","Columbia University","Standard Grant","Bruce M. Kramer","08/31/2020","$750,000.00","Ioannis Kymissis, Peter Allen","mtc2103@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","ENG","8013","030E, 082E, 087E, 8013, 8086","$0.00","The research focuses on sensors and software to enable robots to have an artificial sense of touch. Current robot hands and grippers rarely have the ability to sense their environments; they operate by precisely repeating pre-programmed motions. This prevents the use of robots in applications where the state of the world is unknowable in advance, since such use requires a robot to sense and react to unexpected events. The project will design novel and sophisticated touch sensors and equip robot hands with them.  The sensors will include multiple types of touch sensors and integrate them to detect different types and characteristics of contacts: fast versus slow, transitory versus maintained, etc.  These data will be interpreted by software algorithms that learn how to make use of the newly acquired touch data. This approach takes its inspiration from the human hand, which is also equipped with multiple types of tactile sensing elements relaying information to the nervous system. The proximate goal of the work is to build tools for material handling in cluttered environments, a task that can enable e-commerce and supply chains to run more efficiently, help manufacturers become more efficient and competitive, and reduce injuries to workers by assisting with repetitive tasks that are known to cause injuries.<br/><br/>Novel sensor design, computation and planning will be integrated to endow robots with a sense of touch, thereby enabling manipulation in cluttered environments. At the hardware level, the sensors will combine piezoelectric and resistive strain sensing to capture both transient, high-frequency responses and absolute strain measurements. Sensor sheets will be stacked in multiple sensing layers to provide a rich signal set that departs from the ""one location, one taxel"" approach that is normally taken and maximum use will be made of the rich data by combining model-based and data-driven approaches to define motor control primitives.  These will be combined to implement algorithms for motor control and planning that use the tactile data in a target task: bin-picking and kitting in manufacturing. The overall goal is a compact, multi-modal, scalable tactile sensing system for robotic manipulators, along with the low-level motor skills and high level planning algorithms that use tactile data for manipulating in clutter."
"1638107","NRI: Collaborative Research: Scalable Robot Autonomy through Remote Operator Assistance and Lifelong Learning","IIS","National Robotics Initiative","09/01/2016","07/27/2016","Scott Niekum","TX","University of Texas at Austin","Standard Grant","Tatiana D. Korelsky","08/31/2019","$486,276.00","Andrea Thomaz","sniekum@cs.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","8013","8086","$0.00","One of the most significant barriers to the wider adoption of autonomous robotic systems in commercial applications is the challenge of achieving 100% reliable autonomy in unconstrained human environments. One path toward more robust autonomy is to spend more time in research labs improving robot capabilities, delaying deployment until autonomy is entirely robust.  Instead, it may be valuable to deploy robots out in the wild and adapt their behavior based on the rare examples, corner cases, and contingencies encountered after deployment in order to achieve near-term, fully reliable autonomy. This approach is specifically motivated by the call center model, in which robots are deployed at end-user sites and contact a remote human operator for assistance whenever an error is encountered.  This project develops a system that enables robots to perform lifelong, incremental improvement from remote human assistance with the long-term goal of achieving full autonomy. This research program has significant broader impacts, making personal robots more accessible to everyday people, while also providing opportunities for human-robot interaction that are ideal for educational K-12 programs, as well as undergraduate and graduate education. <br/><br/><br/>Towards these goals, novel algorithms, interfaces, and user studies are being developed to advance the state of the art in three key areas related to the call center model: (1) Robust, Multi-Sensory Task Outcome Detection: multimodal techniques for identifying conditions under which to seek assistance or deploy recovery behaviors; (2) Transparency Devices for Situated Awareness: visual and language interface modalities for increasing the situational awareness of the remote operator and allowing for intuitive interaction, leading to more efficient and correct recovery procedures; (3) Low-Level and High-Level Task Model Refinement: lifelong learning techniques for incorporating corrections and recovery procedures into existing task models, as well as active learning methods to collect more targeted data.  The proposed approach is being evaluated on a variety of mobile manipulation tasks that a hotel concierge robot might perform, such as delivery tasks or preparing for and cleaning up after a conference banquet."
"1528036","NRI: Collaborative Research: ASPIRE: Automation Supporting Prolonged Independent Residence for the Elderly","IIS","National Robotics Initiative","09/01/2015","08/18/2015","Naira Hovakimyan","IL","University of Illinois at Urbana-Champaign","Standard Grant","Irina Dolinskaya","08/31/2019","$1,295,917.00","Amy LaViers, Alex Kirlik, Ranxiao Wang, Dusan Stipanovic","nhovakim@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","8013","010E, 8086","$0.00","Because of the graying of the population, there is a growing need for new assistive technologies to aid the elderly in their daily living.  Based on figures provided by the U.S. Census Bureau, and due largely to the aging of the ""baby boomer"" generation, the population of U.S. adults who are 65 and older is projected to be twice as large in 2030 as it was in 2000, increasing from 35 million to 71.5 million and representing nearly 20 percent of the total U.S. population. This trend is placing enormous burdens on health care costs and causing disruptive changes to how individuals and families manage key late-in-life decisions, including residence. A recent (2015) report by the U.S. Department of Housing and Urban Development concluded that most seniors would prefer to age in place, and a 2010 survey found that 88% of respondents over 65 preferred to remain in their homes as long as possible. It is important to note that these residential preferences must typically be viewed in light of alternatives that are likely to be much more expensive and/or more socially taxing, such as older adults living instead in hospitals, assistive living facilities or with family members. While estimates of the costs associated with these trends vary greatly, it is almost certain that extending the portions of older adults' life spans in which they can live safely and independently through technological means could have enormous positive societal impact. In order to assist in successful aging in place, assistive robots have been developed in the past few decades. However, very few of them have become commercially available, and their use in domesticated environments remains highly limited. The major cause of the problem is that assistive robots typically take the form of full-size humanoid devices or something equally as cumbersome, expensive, and limited in movement and function. We propose a novel assistive robotic system that provides: (i) flexibility, allowing  the designed system  to be personalized based on users' needs without demanding any home modification upon installation; (ii) safety, ensuring that the system development process accounts for perceived safety by the user, and that the underlying  theoretical framework  guarantees  collision avoidance; (iii) usability, consisting of a minimal and intuitive user interface  to provide acceptable controls; (iv) reduced costs, with respect to currently available solutions on the market. The idea behind this research project is the development of a general framework that enables a team of unmanned ground vehicles and small multirotor unmanned aerial vehicles to safely cooperate with the elderly in a home environment. Equipped with appropriate human-machine interfaces, the co-robots will be able to accomplish a number of tasks as demanded by the users. <br/><br/>The project addresses fundamental problems in the domain of multi-agent cooperative systems, comprised of humans and co-robots interacting in shared, highly constrained spaces. In order to assist humans, the co-robots have to be trusted by humans, implying that their behaviors be predictable and consistent with principles of human spatial perception, and their appearance must foster a high level of comfort and not create high cognitive demands on the user. Inspired by these challenges, this proposal focuses on the design and control of co-robots, which can adapt to unstructured and rapidly changing environments in a manner consistent with human perception and cognition, thus enhancing safety and robustness. The key focus areas include the design and acceptance of mobile ground and aerial robots that coexist in environments inhabited by humans and the development of a multi-objective control framework to allow intuitive user control over an ensemble of co-robots, which includes the design of both low-level controllers (LLC) and a supervisory, high-level controller (HLC). To demonstrate the benefits of the framework and to engage student groups from various, diverse populations, the following scenario will be considered as a test case: multirotor unmanned aerial vehicles and ground robots acting as domestic assistive devices for healthy older adults in a research laboratory. These co-robots will safely navigate the shared space and accomplish domestic tasks requested by humans while displaying behaviors and appearances that are perceived as safe and trusted. Humans will use an intuitively designed interface for both controlling and monitoring co-robots on a tablet or a smartphone device. A motion capture system and virtual reality Cube at the Beckman Institute will provide the context for data collection, iterative testing and validation."
"1637656","NRI: Shape Morphing Arm Robotic (SMART) Manipulators for Simultaneous Safe Human-Robot Interaction and High Performance in Manufacturing","CMMI","National Robotics Initiative","09/01/2016","06/21/2018","Hai-Jun Su","OH","Ohio State University","Standard Grant","Bruce M. Kramer","08/31/2019","$995,778.00","Marcelo Dapino, Junmin Wang","su.298@osu.edu","Office of Sponsored Programs","Columbus","OH","432101016","6146888735","ENG","8013","082E, 116E, 6840, 7632, 8086, 9178, 9231, 9251, MANU","$0.00","Co-robots are robotic devices that work in collaboration with human partners. The current solutions for human-safe co-robots fail to offer the safety required in many manufacturing tasks. The shape morphing robotic manipulators are designed to be inherently safe by making the links flexible during robot motion. The upper and lower arms of the manipulators can change their stiffness in real-time by simple smart material actuators. The arms are relatively stiff at low speeds for maximum performance and highly flexible at high speeds for maximum safety. When a collision occurs, the flexible link deflects to limit the impact to the human operator. At low speeds, the flexible link is morphed to the high stiffness mode for maximum positioning accuracy. This research will significantly improve the design of safe co-robotic systems, which can benefit numerous fields, including the health care, automotive, construction and military sectors. It will help to reduce injuries in manufacturing industries and home/hospital nursing and improve efficiency of housekeeping. <br/><br/>Safety concerns with industrial robots present a serious technical barrier to practical co-robot applications.  To address these safety challenges, this research offers a comprehensive solution by integrating complementary expertise in three areas: (i) shape morphing and design optimization of compliant mechanisms, (ii) electrically-controlled stiffness modulation with smart materials and (iii) performance maximization by optimal motion control.  The shape morphing robotic manipulators can adapt their stiffness to the traveling speed by morphing their shape. They are designed for safe operation while maintaining their performance via shape morphing control and trajectory motion control. The shape morphing robotic manipulator offers several advantages over existing techniques in co-robots. It has the potential to create a paradigm shift towards ""safe by design, performance by control"" for human-safe co-robots."
"1734117","NRI: FND: Smart Material Composites and Design of Internal Structural Geometry for Tunably Compliant Soft Robots","CMMI","National Robotics Initiative","09/01/2017","08/25/2017","John Swensen","WA","Washington State University","Standard Grant","Irina Dolinskaya","08/31/2020","$288,660.00","","john.swensen@wsu.edu","280 Lighty","PULLMAN","WA","991641060","5093359661","ENG","8013","030E, 034E, 8024, 8086","$0.00","This project will demonstrate soft robots that can radically modulate their stiffness in a manner comparable to biological systems. This ability will enable robots that can safely collaborate with human co-workers in the service and manufacturing industries. The creation of intrinsically flexible robots using materials such as soft rubbers and foams is a stark contrast to the traditional paradigm of large, heavy, rapidly moving robotics in isolated environments, and has played an important role towards moving robots from the factory floor to the home, clinic, and office. However the intrinsic compliance that makes soft materials safe also makes them unable to exert large forces or to maintain their shape when acted upon by outside forces. In many biological systems, animals are able to change the magnitude and directionality of their soft tissue stiffness through muscle contractions and modification of internal fluid pressures. This project will show researchers how to use controllable compliance in robotic components to obtain the benefits of soft materials -- adaptability, fault tolerance, and safety -- while also providing greater force and manipulation capabilities. The results will find application in a wide range of applications, including home health care, medical interventions, factory automation, and disaster response. The simplicity and safety of experimental exploration with soft robotics also provides an ideal platform for high schools students and undergraduate students to get involved in the emerging field of soft robotics.<br/><br/>The central hypothesis of this research is that the development of tunable compliance - with respect to location, magnitude, and directionality - will provide greater dexterity and control and allow soft robotic designs to exert larger and more precise forces on their environment. This work will research the effects of compositing smart materials with existing soft robotic components to identify the fundamental principles of geometric design of the smart material aggregate. The intention is to imbue soft robots with the ability to dynamically adjust the magnitude, spatial location, and directionality of their compliance. These three aspects of tunable compliance will require new methods of modeling kinematics and dynamics as a function of the control of the smart material stimuli, in conjunction with other traditional actuation schemes such as tendons and pneumatics. Another primary result of the project will be quantitative metrics to objectively describe the capabilities of the resulting tunably compliant robots, in order to formally optimize the geometry of the smart material aggregate."
"1450153","NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","IIS","National Robotics Initiative","07/01/2014","05/10/2016","Paul Oh","NV","University of Nevada Las Vegas","Standard Grant","Jie Yang","09/30/2019","$307,998.00","","paul.oh@unlv.edu","4505 MARYLAND PARKWAY","Las Vegas","NV","891541055","7028951357","CSE","8013","7298, 7925, 8086, 9251","$0.00","Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation.  The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br/><br/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM."
"1637947","Understanding the Influence of a Teachable Robot on STEM Skills and Attitudes","IIS","ITEST","10/01/2016","09/14/2016","Heather Pon-Barry","MA","Mount Holyoke College","Standard Grant","David Haury","09/30/2019","$71,169.00","","ponbarry@mtholyoke.edu","50 College Street","South Hadley","MA","010756456","4135382000","CSE","7227","8086","$0.00","This National Robotics Initiative project will develop a robotic learning environment for middle school geometry students where students who are novices in geometry will learn new concepts by tutoring a humanoid robot to manipulate its gestures and spoken prompts in response to student utterances and problem-solving actions.  The project is based on the principle that the act of tutoring can lead to motivational benefits such as student engagement, positive attitudes toward the subject being studied, and increased confidence.  In this application, the robot is simultaneously a tool that students can program and a social actor that intelligently responds.  This research project will engage a broadly diverse population and is aimed at increasing the participation and retention of underrepresented groups in fields of science, technology, engineering, and mathematics (STEM). There are three components to the broader impacts of this project: 1) Scientific understanding of how robotic learning companions affect STEM attitudes and confidence, 2) Learning among students from traditionally underrepresented groups in the research process, and 3) Creation of a human-robot interaction platform for education and experimentation. The principles discovered through this project are expected to promote increased  participation of women and other underrepresented populations in STEM educational activities and STEM-related careers.<br/><br/>The goals of this research are to link robot behaviors to mediating motivational factors and STEM outcomes with the ultimate goal of understanding how to manipulate robot behaviors to improve a learning interaction. The proposed research will make contributions to understanding of how robotic learning environments can be designed to have a transformative impact on STEM learning.  The research is guided by two questions:  1) How do robot behaviors influence students' mediating motivational factors and affect STEM skills and attitudes?  And 2) What is the impact of adapting robot behaviors to student behaviors on mediating variables and STEM skills and outcomes?  To find answers to these questions, the project will undertake three initiatives: 1) Further development of NaoTAG (Nao Tangible Activities for Geometry) to serve as a platform for experimenting with how different aspects of robot behaviors influence student-robot interactions within the teachable agent context; 2) Understand how student and robot behaviors influence the mediating factors that have identified, and STEM skills and outcomes; and 3) Modeling student-robot interactions."
"1253146","CAREER: A Rigidity Theory for Multi-Robot Formations","IIS","CAREER: FACULTY EARLY CAR DEV, IIS SPECIAL PROJECTS, ROBUST INTELLIGENCE","10/01/2013","09/12/2013","Audrey St. John","MA","Mount Holyoke College","Standard Grant","Reid Simmons","09/30/2019","$411,531.00","","astjohn@mtholyoke.edu","50 College Street","South Hadley","MA","010756456","4135382000","CSE","1045, 7484, 7495","1045, 7484, 7495, 9229","$0.00","This proposal connects foundational research for multi-robot formations with the development of empowering experiences for women undergraduates in the classroom and beyond. The theoretical nature of the research is complemented by a firm grounding in hardware and computer vision fundamentals, integrated throughout a comprehensive education plan. The PI will develop an understanding of geometric formations of multi-robot systems, such as swarms in both 2- and 3-dimensions. Sensor and communication costs will be integral to modeling and algorithmic considerations, as minimizing power consumption is increasingly important for the design of lightweight and agile robot platforms. The PI will establish mathematical foundations and develop algorithms in three fundamental directions: (1) understanding a formation's structural properties, (2) producing optimal control architectures, and (3) predicting a formation?s internal motions. Developing a unifying theory from both theoretical and applied perspectives will produce a wealth of new directions, such as actuating a formation as if it were a single traditional robot.<br/><br/>The research contributions have the potential to significantly impact cutting-edge technology for the control and coordination of multi-robot systems. The PI is junior faculty at Mount Holyoke College, a liberal arts college for women, where a recent growth in enrollments has led to an average of 15 computer science majors a year (surpassing the peak of 2002). She will engage this vibrant community of budding computer scientists through her proposed education plan. Two courses will be developed, designed to simultaneously educate undergraduates through core computer science principles and expose them to exciting research problems challenging the field. Students will have additional opportunities for experiences outside the classroom through highly visible robotics and computer vision projects on campus, producing role models for generations to come. By working closely with the student-run CS Club, the PI will establish a supportive environment that fosters growing interest in technology from traditionally under-represented groups. She will also actively involve students in research by supervising two undergraduates each summer through a compelling research experience."
"1830642","NRI: FND: The Urban Design and Policy Implications of Ubiquitous Robots and Navigation Safety","SES","SCIENCE, TECH & SOCIETY, National Robotics Initiative","08/15/2018","08/28/2018","Matthew Spenko","IL","Illinois Institute of Technology","Standard Grant","Frederick M Kronz","07/31/2021","$750,000.00","Ronald Henderson, Boris Pervan","mspenko@iit.edu","10 West 35th Street","Chicago","IL","606163717","3125673035","SBE","7603, 8013","063Z, 8086, 9179","$0.00","This research project will investigate how to reshape 20th-century transportation infrastructure (such as highways, intersections, roads, and sidewalks) for the 21st-century so that it may accommodate autonomous vehicles while addressing the needs of the entire community. To do so, it will explore trade-offs between three key elements: safety, usability, and aesthetics. It will then propose a suitable balance between these elements by developing a framework for reshaping the existing infrastructure. The resulting framework will serve to inform city planners, architects, and landscape architects how to plan and design cities in which autonomous vehicles safely interact with humans, and it will serve to educate roboticists on how to ensure that the technology they are developing has a positive societal impact.<br/><br/>This project will investigate the critical link between the urban landscape and navigation safety of mobile co-robots, from self-driving cars to delivery drones, or any mobile co-robot that operates on city streets and sidewalks. It will address fundamental questions of safety and trust in operating ubiquitous robots in dense urban environments by determining what changes to the urban infrastructure can simultaneously ensure safety, usability, and environmental sustainability. It will bring to light opportunities enabled by ubiquitous co-robots, and more to the point it will show how to leverage that technology to make changes in the transportation infrastructure that lead to positive changes for society.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1605275","Development of spirally coiling, force-sensing soft-robot for safe and accurate cochlear electrode implantation","CBET","Disability & Rehab Engineering","09/01/2016","08/19/2016","Jaeyoun Kim","IA","Iowa State University","Standard Grant","Aleksandr Simonian","08/31/2019","$300,317.00","In Ho Cho","plasmon@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","ENG","5342","","$0.00","Cochlear implant (CI) is fast becoming the main rehabilitation aid for those who suffer from hair cell-related hearing impairments. The nation's current demography suggests that the CI adoption will increase at an accelerated pace for the foreseeable future, calling for more innovations in the CI technology. Of particular urgency is the need for safe and accurate schemes for CI electrode array insertion which is very challenging due to its stringent requirements on insertion depth, electrode-to-wall proximity, and tissue safety. The 3D-spiraling human cochlear anatomy further complicates the task. Many shape-controllable electrodes have been devised to meet the requirements but they still suffer from issues related to limited shape control, slow operation, and potential hazards of electrical actuation. This project focuses on achieving safe and accurate CI electrode insertion through joint utilization of pneumatic soft-robotic micro-tentacles and optical force sensors monolithically integrated with them. Both of them are made of soft elastomers, which greatly facilitates non-intrusive, safe insertion of the CI electrode. The high-level maneuverability of the bio-inspired micro-tentacle will also widen the scope of achievable motion and improve accuracy of the insertion process. Above all, the fusion of agile shape control and integrated sensing will eventually lead to ""adaptive insertion"" which has been incessantly pursued in CI. All of these will be achieved via the collaboration of two researchers with very different specialty areas, electrical engineering and structural engineering, which will contribute to the convergence in science and technology. This project also aims to strengthen cross-disciplinary training in academia through co-advising of graduate and undergraduate students in seemingly unrelated, yet highly synergistic topics such as optics, MEMS, structural engineering, and computational mechanics. It includes outreach plans to the underrepresented in based on K12 science and technology demonstrations and extra-curricular activities.  <br/><br/>This project's ultimate goal of safe and accurate insertion of CI electrode arrays through soft-robotic, sensor-integrated micro-tentacle. Accordingly, the following objectives have been lined up: (1) Development of soft-robotic tentacle capable of performing 3-dimensionally spiraling motion. This task will be carried out as a parallel effort encompassing the microfabrication and testing work by the PI and the computational design, optimization, and analysis by the co-PI. (2) Development of elastomer-based optical force sensors. The key issues of the task include the accomplishment of totally non-intrusive sensing for tissue safety and monolithic, clinically safe integration with the soft-robotic main body. (3) Development of the schemes to fix the shape of the soft-robot upon completion of the insertion process. The key issue is again achieving the goal in a clinically safe fashion. The impact of this unique collaboration will go beyond CI eventually. The importance of micro-robots and soft-robots in rehabilitation and assistive technologies has been in continuous increase in recent years. This project will expedite their fusion and add momentum to the fledgling field of ""microscale soft-robotics."" The plan to monolithically integrate the shape-control and force-sensing function blocks with the soft-actuator will also contribute to the field of human-friendly robotics which is attracting intense research interests from the robotics community. The resulting additive fabrication and shape-control techniques will enrich the arsenal of additive manufacturing and microscale medical robotics, respectively."
"1545857","PIRE: Advanced Artificial Muscles for International and Globally Competitive Research and Education in Soft Robotics","OISE","PIRE, EPSCoR Co-Funding","10/01/2015","08/15/2018","Kwang Kim","NV","University of Nevada Las Vegas","Continuing grant","Cassandra M. Dudka","09/30/2020","$3,598,857.00","Paul Oh, Chulsung Bae, Maurizio Porfiri, Kam Leang","kwang.kim@unlv.edu","4505 MARYLAND PARKWAY","Las Vegas","NV","891541055","7028951357","O/D","7742, 9150","5921, 5942, 5978, 7566, 7742, 9150","$0.00","This international project addresses a technologically important issue ?soft robotics. Soft robotics is an important emerging field in robotics, mechatronics, and automation.  Soft robotic components and systems offer new features and advances over conventional robotic devices.  This project focuses on the creation of advanced multifunctional artificial muscles (AM) based on new polymer-metal composites which can be used in soft robotic applications. Artificial muscles can be transformative for millions of people with disabilities.  The development of AM will benefit biomimetic soft robotics, medical diagnostics and tools, and invasive surgical systems.  The potential market for reliable, cost-effective and easily scalable Ionic Polymer-Metal Composites (IPMCs)-based AM technology is substantial.  If successful and cost effective, the impact on people?s lives and on economies could be very significant.  The international partners are from the Department of Mechanical Engineering and Graduate School of Ocean Systems Engineering at the Korea Advanced Institute of Science and Technology (KAIST) and the Hybrid Actuator Group, Inorganic Functional Material Research Institute at the National Institute of Advanced Industrial Science and Technology (AIST) in Japan. The international team has strong expertise in manufacture engineering and has the necessary computational and experimental resources. The strength of soft robotics research in Japan and very active industry efforts in Korea are especially valuable.  <br/><br/>Owing to their soft and flexible structure and ability to emulate the motion of biological muscles, IPMCs are considered excellent candidates for future AM technology in soft robotic systems.  The main challenges with IPMC materials include:  relatively high fabrication costs associated with the use of fluorinated ionic polymers, low actuation force, and limited control accuracy. This project will bring together experts from around the world to address these challenges toward developing effective IPMC-based AMs for soft robotic applications."
"1830146","NRI: FND: COLLAB: Intuitive, Wearable Haptic Devices for Communication with Ubiquitous Robots","CMMI","National Robotics Initiative","09/01/2018","08/27/2018","Marcia O'Malley","TX","William Marsh Rice University","Standard Grant","Irina Dolinskaya","08/31/2021","$327,242.00","","omalleym@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","ENG","8013","8086, 9102","$0.00","This National Robotics Initiative (NRI) project will promote the progress of science and beneficially impact human health and quality of life by developing wearable soft robotic devices with distributed tactile stimulation that enable new forms of communication. Human-robot interactions will be commonplace in the near future.  In applications such as self-driving cars and physically assistive devices, interaction will require effective and intuitive bidirectional communication.  Transferring information through vision and sound can be slow and inappropriate in many circumstances.  This project focuses on haptic (touch-based) robotics to enable communication in a salient but private manner that alleviates demands on other sensory channels. This project serves the national interest by advancing knowledge in the fields of human perception, psychology and neuroscience, while developing novel, convergent technology that integrates concepts across the fields of robotics, haptics, and control engineering. Project results will be disseminated through tactile haptic devices for education and publicly available software and data. The project aims to broaden participation of underrepresented groups in engineering through outreach programs, public lab tours, and the mentoring of female and minority graduate students, undergraduates, and high school students.<br/><br/>Wearable haptic systems have the potential to enable private, salient communication between humans and intelligent systems through an underutilized sensory channel (somatosensation). In this research, information will be transmitted through the haptic channel via wearable, ubiquitous, soft robotic devices that provide both passive and active touch interactions with the human user. This research is comprised of four main objectives. First, a characterization of human perception of the forearm will set the requirements for the frequency, amplitude, directions, spacing, and temporal actuation patterns for a two-dimensional array of haptic stimulators that are able to convey a range of haptic cues. Second, the project will develop a wearable, soft, haptic device able to stimulate the skin of one forearm, while also providing mechanical stimuli that are intended to be explored by the fingertips of the other hand. Third, the project will develop rendering algorithms for the haptic device that take into consideration human perceptual abilities for passive stimulation of the arm and active exploration by the fingertips. Fourth, the project team will create application scenarios to evaluate and refine the system. Wearable haptic systems have potential to improve human health and well-being through a variety of applications including: physical cueing for rehabilitation/movement therapy; explosive ordnance defusing; feedback from assistive devices including mobile robots in the home; tactile communication to enable design and e-commerce; immersion in virtual worlds for education; and the facilitation of remote interaction between people.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1634431","NRI: A Proactive Approach to Managing Contingencies during Human Robot Collaboration in Manufacturing","CMMI","National Robotics Initiative","08/01/2016","05/02/2016","Satyandra Gupta","CA","University of Southern California","Standard Grant","Bruce M. Kramer","11/30/2019","$639,076.00","","guptask@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","ENG","8013","030E, 071E, 082E, 6840, 8086","$0.00","Recent advances in human-safe industrial robots present an opportunity for creating hybrid work cells, where humans and robots can collaborate in close physical proximities. This capability enables realizing systems that utilize complementary strengths of humans and robots. Several new low-cost robots have been introduced in the market over the last few years, making them attractive in many new manufacturing applications. This makes the idea of hybrid cells economically viable for small and medium manufacturers, which represent a very important segment of the manufacturing sector in the United States. Both humans and robots can make errors in a hybrid cell, hence creating contingency situations. Unless handled promptly, a contingency situation may lead to significant operational inefficiencies. Hence, hybrid cells are not likely to cost-effective unless contingency situations are proactively detected and managed. This National Robotics Initiative (NRI) award supports fundamental research to enable proactive management of contingencies arising during human-robot collaboration in hybrid work cells in small production volume manufacturing operations. Results from this research will enable introduction of industrial robots in small production volume operations and are expected to make US manufacturing industry cost competitive in the global market. The integration of the research with graduate and undergraduate courses will enhance the robotics and manufacturing curricula and enrich learning experiences of the participating students. Outreach activities will educate and inform K-12 students about career opportunities in robotics and manufacturing.   <br/><br/>Fundamental advances are needed in automated planning, cell monitoring, replanning, and human-robot interaction to endow hybrid cells with effective contingency handling capabilities. This research will investigate computational foundations for the design of task planning and resource allocation algorithms that explicitly account for managing contingencies. Algorithms will be developed for real-time monitoring of the task progress to ensure that tasks are completed in a safe and efficient manner. Real-time replanning algorithms will be designed to handle contingencies and refine plans based on the observed task execution performance. This research will also explore and characterize methods for effective information exchange between humans and robots to deal with contingencies."
"1830163","NRI: FND: COLLAB: Intuitive, Wearable Haptic Devices for Communication with Ubiquitous Robots","CMMI","National Robotics Initiative","09/01/2018","08/27/2018","Allison Okamura","CA","Stanford University","Standard Grant","Irina Dolinskaya","08/31/2021","$356,817.00","","aokamura@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","ENG","8013","8086, 9102","$0.00","This National Robotics Initiative (NRI) project will promote the progress of science and beneficially impact human health and quality of life by developing wearable soft robotic devices with distributed tactile stimulation that enable new forms of communication. Human-robot interactions will be commonplace in the near future.  In applications such as self-driving cars and physically assistive devices, interaction will require effective and intuitive bidirectional communication.  Transferring information through vision and sound can be slow and inappropriate in many circumstances.  This project focuses on haptic (touch-based) robotics to enable communication in a salient but private manner that alleviates demands on other sensory channels. This project serves the national interest by advancing knowledge in the fields of human perception, psychology and neuroscience, while developing novel, convergent technology that integrates concepts across the fields of robotics, haptics, and control engineering. Project results will be disseminated through tactile haptic devices for education and publicly available software and data. The project aims to broaden participation of underrepresented groups in engineering through outreach programs, public lab tours, and the mentoring of female and minority graduate students, undergraduates, and high school students.<br/><br/>Wearable haptic systems have the potential to enable private, salient communication between humans and intelligent systems through an underutilized sensory channel (somatosensation). In this research, information will be transmitted through the haptic channel via wearable, ubiquitous, soft robotic devices that provide both passive and active touch interactions with the human user. This research is comprised of four main objectives. First, a characterization of human perception of the forearm will set the requirements for the frequency, amplitude, directions, spacing, and temporal actuation patterns for a two-dimensional array of haptic stimulators that are able to convey a range of haptic cues. Second, the project will develop a wearable, soft, haptic device able to stimulate the skin of one forearm, while also providing mechanical stimuli that are intended to be explored by the fingertips of the other hand. Third, the project will develop rendering algorithms for the haptic device that take into consideration human perceptual abilities for passive stimulation of the arm and active exploration by the fingertips. Fourth, the project team will create application scenarios to evaluate and refine the system. Wearable haptic systems have potential to improve human health and well-being through a variety of applications including: physical cueing for rehabilitation/movement therapy; explosive ordnance defusing; feedback from assistive devices including mobile robots in the home; tactile communication to enable design and e-commerce; immersion in virtual worlds for education; and the facilitation of remote interaction between people.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734443","NRI: INT: COLLAB: Development, Deployment and Evaluation of Personalized Learning Companion Robots for Early Literacy and Language Learning","IIS","ITEST, National Robotics Initiative","09/01/2017","08/16/2017","Cynthia Breazeal","MA","Massachusetts Institute of Technology","Standard Grant","David Haury","08/31/2021","$882,935.00","Regina Barzilay","cynthiab@media.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7227, 8013","8086","$0.00","This National Robotics Initiative project willdevelop, deploy and evaluate personalized companion robots to assist kindergarten-age children in learning language and vocabulary skills. The aim is to accelerate the impacts of social robots for early education in schools and at home.  The four-year project will advance knowledge in three key areas: (1) automatic speech recognition models for young children; (2) multi-modal student assessment algorithms for early language and literacy skills; and (3) personalization of activities, content, and dialogic question generation to boost learning outcomes. The project will generate new insights for how to develop expressive, socially responsive robots that provide more effective, engaging, and empathetic educational experiences for young children. To evaluate the impacts of long-term interactions on educational outcomes, the project team will conduct a 4-month study with Kindergarten classrooms, as well as a 3-month at-home study.  The project will engage teachers and parents to develop key guidelines for best practices for use of social robots in classroom and home settings, and participating undergraduate and graduate students will be trained in the multidisciplinary aspects of social robotics, speech recognition and understanding, human participation studies, interactive machine learning for automatic assessment and personalization tools, and early education research.<br/><br/>This research and development project will be implemented in two phases:  An initial phase consisting of short pilot deployments to train and continually iterate development of project technologies and systems, followed by longer term deployment of the robot to examine autonomous interactions with social robots in school and home educational settings.  During the development stage of individual components (automatic reading and language assessment tools, automatic question-generation algorithm, automatic speech recognition and spoken language understanding system models, and activities with the autonomous social robot learning companion) the project team will collect and analyze data with practical and performance measures, and refine and iterate each component of the system being developed.  After development of the individual components, the autonomous social robot storytelling companion will be developed through repeated iterations with children.  In the final year of the project, two 4-month studies will be conducted in six Kindergarten classrooms with 15 to 20 students each.  This project is expected to result in five key contributions: (1) Development of Automatic Speech Recognition and Spoken Language Understanding systems for young children's speech, (2) Multi-modal automatic assessment algorithms for Kindergarten age children's spoken language and early reading skills; (3) Automatic personalization algorithms for story content customization and dialogic question generation in the context of young children's verbal storytelling; (4) Development of a fully autonomous, collaborative, peer-like social robot system with effective educational activities; and (5) Long-term studies with deployed social robots in schools and homes spanning several months and demonstrating sustained engagement and positive learning outcomes."
"1516562","Robotics and E-Textiles Backpacks for Family Learning","DRL","AISL","09/15/2015","09/12/2017","Carrie Tzou","WA","University of Washington","Continuing grant","Catherine Eberbach","08/31/2019","$2,473,438.00","Megan Bang, Eve Klein, Philip Bell","tzouct@u.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","EHR","7259","8244","$0.00","Libraries serve vital roles in communities not only for access to print media but also family programming and access to the internet. Because of their widespread local presence in communities and the diverse communities served, libraries are well-positioned to address inequalities in access to technology, family programming, and spaces for collaboration. Science centers, universities, and community centers represent resources that can partner with libraries to create science and technology-related content for delivery to diverse communities. Research has firmly established the link between parent engagement and a broad range of student academic outcomes, including higher student attendance, achievement and graduation rates.  A growing body of research in out-of-school science learning is focusing on the rich and varied ways in which families learn science outside of school, including habits of mind, motivation, and identities as scientists. Pilot work showed that backpacks have the potential for youth and parents to take on new roles relative to STEM work, with parents or older siblings taking on roles of lab partners, translators, and even teachers. The Robotics and E-Textiles project will support increased capacity within libraries and community centers to hold robotics workshops for families in their own communities.  Libraries and community centers will serve as vehicles through which families engage with robotics and e-textiles, resulting in wider access to Next Generation Science Standards' engineering practices to more people. This Innovations in Development project is funded by the Advancing Informal STEM Learning (AISL) program which seeks to advance new approaches to, and evidence-based understanding of, the design and development of STEM learning in informal environments.<br/><br/>Librarians and community engagement leaders will participate in professional experiences to develop science and technology content and facilitation skills. University researchers in collaboration with project partners will use a design-based research methodology to iteratively design the professional development and backpack programs and to investigate learning processes and outcomes. The Cultural Learning Pathways theoretical model will guide the study of how engagement with robotics/e-textiles experiences can lead to changes in practice, identity, and deeper participation in communities of practice on the part of librarians, youth, and families. <br/><br/>Although collaborations between public libraries and informal science providers are becoming increasingly common, this project will document the process of developing such collaborations and draw insights that may be applied to other contexts. By bringing together traditional and non-traditional community organizations to develop and facilitate STEM learning experiences, this project has the potential for resulting in a new model for a decentralized system of informal STEM education and broadening participation in STEM. Over the life of the project, the number of partner libraries will expand from one to four, and it is anticipated to reach more than 550 families. It is being conducted through a partnership between the University of Washington, the Pacific Science Center, the Seattle Public Libraries, and Red Eagle Soaring, a Native American community youth program."
"1830215","NRI: FND: Robotic Human Enhancement Enabled through Wearable Hip Exoskeletons Capable of Community Ambulation","IIS","National Robotics Initiative","09/01/2018","08/23/2018","Aaron Young","GA","Georgia Tech Research Corporation","Standard Grant","Wendy Nilsen","08/31/2021","$702,440.00","","aaron.young@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","063Z, 8086","$0.00","The increased metabolic and biomechanical demands of ambulation limit community mobility in persons with lower limb disability due to neurological damage or advanced age. Robotic exoskeletons have the potential to assist these individuals to increase community mobility to improve quality of life. Current technology does not support dynamic movements, such as transitioning between different gaits and supporting a wide variety of walking speeds. This project proposes to meet this challenge by exploring an innovative myoelectric controller that brings together information across multiple muscles to assist the exoskeleton in a range of tasks for mobility. Of interest is how to extract information about the human user's intent, such as what speed the user wants to walk at or if they want to take a step up a stair. Recognizing intent will allow the device to give appropriate assistance over a wide range of activities. For this research project, the investigators will use a new type of robotic hip exoskeleton to augment the human hip during tasks such as walking at different speed, ramps and stairs. This project seeks to advance the state of the science in man-machine exoskeleton interfaces through new types of control techniques. This will help the team's long-term research goal of creating robotic assistive devices that benefit individuals with serious lower limb disabilities by improving mobility and, thus, overall independence. This NSF project will also include a significant outreach to the local Atlanta community. Local project partners will bring underserved minority students in the Atlanta area to Georgia Tech to participate in this educational program. These high school students will interact with the human assistive robotics in the lab and design, build, and program their own assistive robots through hands on education. This project will facilitate the training of an interdisciplinary group of students including graduate and undergraduate biomedical, electrical, and mechanical engineers, GT graduate students training to be clinical practitioners in prosthetics and orthotics, and physical therapists in training in Emory's DPT program. This interdisciplinary group of students will work together to fully integrate all aspects of the project and facilitate learning.<br/><br/>This research project will advance the knowledge of myoelectric (EMG) control for enabling humans to have dynamic movement assistance using lower limb robotic exoskeletons. Existing technologies of exoskeleton systems have limited high-level understanding of user intent, thus precluding adaptation to a proper range of daily tasks of living. Sensing modalities used in such systems do not provide sufficient information regarding key physiological parameters such as muscle activity. Conventional control algorithms relate a single modality of sensors to exoskeleton assistance and are thus incapable of fusing broader sets of varying sensor information. These technological gaps have impeded the translation of such systems beyond lab settings to clinical use where they can impact important health needs such as assistive rehabilitation. This proposal will address these gaps in assistive robotic technology by pursuing research organized in three key objectives: Objective 1) Determine the most effective strategy of providing exoskeleton hip assistance for reducing metabolic cost using a novel myoelectric controller. Objective 2) Compare the metabolic and biomechanical effects of a novel controller driven by myoelectric inputs vs a standard controller driven by kinematic inputs. Objective 3) Determine the contributions of high-level intent recognition using myoelectric information to improve control of a powered hip exoskeleton over simulated community terrain. Relatively simple mobility tasks like standing from a seated position or walking represent the primary outcome measures that determine independence in rehabilitation. Thus, the wearable exoskeleton system described in this grant proposal has the potential to make a measurable impact on enhancing the functional performance capabilities of individuals with lower limb deficits by increasing their quality of life, independence and well-being.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830597","NRI: FND: Robust Learning of Sequential Motion from Human Demonstrations to Enable Robot-Guided Exercise Training","IIS","National Robotics Initiative","01/01/2019","08/23/2018","Momotaz Begum","NH","University of New Hampshire","Standard Grant","James Donlon","12/31/2021","$749,999.00","Dain LaRoche, Sajay Arthanat","mbegum@cs.unh.edu","51 COLLEGE RD SERVICE BLDG 107","Durham","NH","038243585","6038622172","CSE","8013","063Z, 8086, 9150","$0.00","Therapeutic exercises are crucial for healthy living and effective recovery from injury, surgery, disease, or frailty. Physical or occupational therapists are typically responsible for directing therapeutic exercises. There is currently a mismatch between supply and demand for these services. There is a predicted shortage of 26,600 physical therapists nationally by year 2025 and 50,000 occupational therapists by year 2030. Technology-based home programs are rapidly emerging as a way to combat this skilled labor shortage. Technology assisted exercise programs that promote highly structured practice and provide real-time feedback are believed to improve well-being but have yet to be conceived. This project bridges that gap through designing intelligent robots that can take the role of a therapist during therapeutic exercise training. The idea is that a clinician will teach a robot any structured exercise through demonstrations and the robot will then take the role of a coach to teach users and provide quantitative evaluation of performance. For a robot to do that, we need an intelligent algorithm that will allow the therapists to teach a robot any new exercise without actually programming the robot and enable the robot to learn from therapists' demonstrations. This project will develop a novel Learning from demonstration (LfD) framework to realize exercise trainer robots.   <br/><br/>The core technical challenges of designing a LfD framework for a exercise trainer robot are i) robustly learning sequence of human movements from lay users' demonstrations while accommodating inter- and intra-personal variations and ii) offers a quantitative metric to explain the deviation of a user's trajectory from the demonstrated sequence in a contextually meaningful way. Solving these challenges requires major changes in the way we currently learn motion trajectories (low-level policy learning) and model the relations among trajectories for learning sequential tasks (high-level policy learning). Accordingly, this research will design the entire pipeline of LfD based only on the kinematic and kinetic variables of motion. The core of this LfD framework is a phase space model (PSM) for learning task trajectories. The PSM leverages dynamic system theories to analyze motion variables to segment a task trajectory and build a parametric representation that is robust against spatio-temporal variations. The compact parameter set that PSM generates are used by a graphical model to learn the high-level policy underlying the demonstrated task while leveraging the typical anatomical constraints of human limbs. The same parameter set is used to design a quantitative metric to evaluate the learning outcome. The project will evaluate the fidelity of a co-robot exercise trainer powered by this LfD framework to teach upper extremity exercises in a series of user studies. An ABB YuMi robot will be used as the test platform. The demonstration data will be collected from inertial measurement units (IMUs) worn by student-therapists on the hand, forearm, upper arm and torso. The robot will demonstrate learned exercises to older adult participants (OA), who then will perform the exercises by mirroring the robot. During the training phase, the OAs will also be wearing IMUs so that their performance can be assessed with respect to the original demonstration from the therapist. The fidelity of movement transmission will be tested from the therapist, to the robot, to the patient with a high-speed, 3D motion capture video system which is the gold standard for kinematic analysis.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1351677","CAREER: Generalizations in Obstacle Avoidance Theory","IIS","COLLABORATIVE RESEARCH, IIS SPECIAL PROJECTS, ROBUST INTELLIGENCE","03/15/2014","05/04/2018","Animesh Chakravarthy","KS","Wichita State University","Continuing grant","Reid Simmons","02/28/2019","$457,999.00","","animesh.chakravarthy@wichita.edu","1845 Fairmount","Wichita","KS","672600007","3169783285","CSE","7298, 7484, 7495","1045, 5946, 7495, 8086, 9150, 9251","$0.00","This project develops a theoretical framework that enables an analytical characterization of guidance laws for obstacle avoidance, accompanied by an experimental validation of these laws.  This has significant implications since the obstacle avoidance problem is an important component of the path planning problem, which appears in several diverse fields including robotics, autonomous air, ground and underwater vehicles, computer animation, molecular motion, autonomous wheelchairs, spacecraft avoiding space debris, robotic surgery, assistance aids for the blind, etc.  The guidance laws designed are particularly applicable for real-time implementation of precise path planning in cluttered dynamic environments such as those containing robot manipulators, humanoid robots, vehicles flying in formation and other high-dimensional spaces wherein the agents have no a priori information about their environment.  A robustness analysis of the designed guidance laws to various uncertainties such as sensor noise, data delays and data dropouts is performed, followed by an experimental validation wherein the guidance laws are coded on microcontroller platforms in a resource-efficient manner and implemented on small-scale robotic ground and air vehicles.  The expected results include guidance laws suitable for collision avoidance of obstacles of various, possibly time-varying, shapes moving in high-dimensional stochastic environments, along with a postulation of the safety guarantees of these guidance laws.  This project also performs multiple outreach activities and introduces new curriculum that promote the education and applications of robotics, and these activities are conducted in levels starting from K-12 all the way through undergraduate and graduate level engineering education."
"1839686","Collaborative Research: FW-HTF: Integrating Cognitive Science and Intelligent Systems to Enhance Geoscience Practice","DUE","FW-HTF: Advancing Cognitive an","10/01/2018","08/22/2018","M. Ani Hsieh","PA","University of Pennsylvania","Standard Grant","Stephanie August","09/30/2021","$500,000.00","","m.hsieh@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","EHR","082Y","063Z","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim. <br/><br/>This project will make a significant contribution toward the support of future workers in geology. Understanding how geologists reason, plan to collect new data, consider three-dimensional spatial relations, and evaluate uncertainty are critically important for supporting scientists working on applied problems, such as natural resource exploration. This project will enhance existing efforts in geology to collect data using robot drones.  Drones allow access to important areas of the world too dangerous to access in person and not visible from satellite or plane.  The project will use machine learning to incorporate expert knowledge into drone flights to support effective autonomous data collection.  The data will yield improved geological understanding of an important fault system. Findings from the project will improve understanding of uncertainty in volumes and thus improve our understanding of earthquakes and the analyses of petroleum workers.  Understanding how expert geologists reason will support new exploration and mapping strategies for human-robot teams working in natural environments. The collaborative efforts of the interdisciplinary team will advance the fields of cognitive science, geology, and machine learning. The integration of cognitive science, robotics, and geology will develop new approaches to field work with human-autonomous systems teams that are faster and more effective than any either human or autonomous system would be acting alone. <br/><br/>The project will characterize expert spatial reasoning about 3D relations and uncertainty as geologists collect data to develop a 3D understanding of a new field area, make predictions about future observations, and construct geological models.  Errors in reasoning about 3D structures will be used to develop quantitative models of expert uncertainty. These models will be used to help explicitly visualize uncertainty for the experts and to construct cost functions for the robot navigation. The cost functions will include metrics that capture scientific value. The project will develop new approaches to drone exploration and mapping, including machine learning of features of interest to geologists. Drones will autonomously explore and map natural rock formations in canyon environments to support and speed up the data collection and interpretation efforts of field geologists.  The project will study the structural geology of the Mecca Hills area of California, a well exposed portion of the San Andreas fault system.  Robot drones will collect data about surface features to develop maps of subsurface structures. The cognitive science-infused robot design will employ successful expert strategies and focus on areas where experts are likely to make errors to prioritize exploration of those areas in navigation plans. The proposed strategies will enable 3D surface reconstruction of canyon surfaces. They will also enable better understanding of how to enhance planning and on-the-fly decision making of experts for collecting scientifically important data.   The project's foundational work aims to develop an interdisciplinary understanding of how geologists build a scientific understanding of a region over time. It also aims to design autonomous exploration strategies for human-robot teams, and test new ways to support the sequential decisions about where to collect data to maximize scientific impact.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839971","FW-HTF: Collaborative Research: Pre-Skilling Workers, Understanding Labor Force Implications and Designing Future Factory Human-Robot Workflows Using a Physical Simulation Platform","DUE","FW-HTF: Advancing Cognitive an","10/01/2018","08/22/2018","Karthik Ramani","IN","Purdue University","Standard Grant","Alexandra Medina-Borja","09/30/2022","$1,839,998.00","Thomas Redick, Shimon Nof, Alexander Quinn","ramani@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","EHR","082Y","063Z","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim.<br/><br/>This collaborative project between Purdue University, Indiana University and the Massachusetts Institute of Technology is based on the rationale that today's manufacturers, especially small and medium enterprises may struggle to keep pace with rapid changes in manufacturing. To help manufacturers thrive in a rapidly changing industry, this project aims to develop a Physical-Simulation Platform that will realistically simulate interactions between workers, robots, and machines in future factories, and at the same time, improve factory agility and productivity. This project will provide new insights into workers' spatial, multitasking, and predictive task abilities in manufacturing, and their performance in shared and smooth workflows. Those insights can then be used to shape the augmented manufacturing environment of the future by amplifying cognitive capacity and transferring some cognitive burden to artificial intelligence and smart automation.  Such changes can improve both productivity and worker experience. The project will explore the economic impact on different types of workers as well as the benefits of artificial intelligence-based augmentation technologies on human labor, factory productivity and agility. In addition, the project will contribute to workforce development by creating educational plans and outreach to prepare workers for the manufacturing workplace of the future. The researchers will directly engage underserved young people by introducing them to new toolkits and curriculum developed as part of this project.  These materials can then be adapted by educators across the country. Strong industry collaborations are present to facilitate testing and adoption of this approach. <br/><br/>The research team of mechanical and electrical engineers, psychologists, computer scientists, education researchers, and economists will work toward accomplishing five goals: (1) use Mixed Reality to capture interactions, shared workflows, and collaborative tasks as close as possible to a real manufacturing environment; (2) develop and demonstrate new types of authoring platform to program robots, internet-of-things-based machines, and humans interacting with them, with augmented reality, artificial intelligence to substantially reduce cognitive loads and enhance worker and factory overall capabilities and productivities; (3) discover, design and develop flexible representations of collaborative intelligence workflows and metrics to simulate and evaluate Humans-Robots-Machines shared work; (4) evaluate shared work economics and labor market implications of augmenting humans with robotics, augmented reality, and artificial intelligence; and (5) pre-skill the workforce and increase engagement towards the future of work at the human-technology interface.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839921","FW-HTF: Collaborative Research: Pre-Skilling Workers, Understanding Labor Force Implications and Designing Future Factory Human-Robot Workflows Using a Physical Simulation Platform","DUE","FW-HTF: Advancing Cognitive an","10/01/2018","08/22/2018","Daron Acemoglu","MA","Massachusetts Institute of Technology","Standard Grant","Alexandra Medina-Borja","09/30/2022","$360,000.00","","daron@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","EHR","082Y","063Z","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim.<br/><br/>This collaborative project between Purdue University, Indiana University and the Massachusetts Institute of Technology is based on the rationale that today's manufacturers, especially small and medium enterprises may struggle to keep pace with rapid changes in manufacturing. To help manufacturers thrive in a rapidly changing industry, this project aims to develop a Physical-Simulation Platform that will realistically simulate interactions between workers, robots, and machines in future factories, and at the same time, improve factory agility and productivity. This project will provide new insights into workers' spatial, multitasking, and predictive task abilities in manufacturing, and their performance in shared and smooth workflows. Those insights can then be used to shape the augmented manufacturing environment of the future by amplifying cognitive capacity and transferring some cognitive burden to artificial intelligence and smart automation.  Such changes can improve both productivity and worker experience. The project will explore the economic impact on different types of workers as well as the benefits of artificial intelligence-based augmentation technologies on human labor, factory productivity and agility. In addition, the project will contribute to workforce development by creating educational plans and outreach to prepare workers for the manufacturing workplace of the future. The researchers will directly engage underserved young people by introducing them to new toolkits and curriculum developed as part of this project.  These materials can then be adapted by educators across the country. Strong industry collaborations are present to facilitate testing and adoption of this approach. <br/><br/>The research team of mechanical and electrical engineers, psychologists, computer scientists, education researchers, and economists will work toward accomplishing five goals: (1) use Mixed Reality to capture interactions, shared workflows, and collaborative tasks as close as possible to a real manufacturing environment; (2) develop and demonstrate new types of authoring platform to program robots, internet-of-things-based machines, and humans interacting with them, with augmented reality, artificial intelligence to substantially reduce cognitive loads and enhance worker and factory overall capabilities and productivities; (3) discover, design and develop flexible representations of collaborative intelligence workflows and metrics to simulate and evaluate Humans-Robots-Machines shared work; (4) evaluate shared work economics and labor market implications of augmenting humans with robotics, augmented reality, and artificial intelligence; and (5) pre-skill the workforce and increase engagement towards the future of work at the human-technology interface.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839730","Collaborative Research: FW-HTF: Integrating Cognitive Science and Intelligent Systems to Enhance Geoscience Practice","DUE","FW-HTF: Advancing Cognitive an","10/01/2018","08/22/2018","Basil Tikoff","WI","University of Wisconsin-Madison","Standard Grant","Stephanie August","09/30/2021","$499,992.00","","basil@geology.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","EHR","082Y","063Z","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim. <br/><br/>This project will make a significant contribution toward the support of future workers in geology. Understanding how geologists reason, plan to collect new data, consider three-dimensional spatial relations, and evaluate uncertainty are critically important for supporting scientists working on applied problems, such as natural resource exploration. This project will enhance existing efforts in geology to collect data using robot drones.  Drones allow access to important areas of the world too dangerous to access in person and not visible from satellite or plane.  The project will use machine learning to incorporate expert knowledge into drone flights to support effective autonomous data collection.  The data will yield improved geological understanding of an important fault system. Findings from the project will improve understanding of uncertainty in volumes and thus improve our understanding of earthquakes and the analyses of petroleum workers.  Understanding how expert geologists reason will support new exploration and mapping strategies for human-robot teams working in natural environments. The collaborative efforts of the interdisciplinary team will advance the fields of cognitive science, geology, and machine learning. The integration of cognitive science, robotics, and geology will develop new approaches to field work with human-autonomous systems teams that are faster and more effective than any either human or autonomous system would be acting alone. <br/><br/>The project will characterize expert spatial reasoning about 3D relations and uncertainty as geologists collect data to develop a 3D understanding of a new field area, make predictions about future observations, and construct geological models.  Errors in reasoning about 3D structures will be used to develop quantitative models of expert uncertainty. These models will be used to help explicitly visualize uncertainty for the experts and to construct cost functions for the robot navigation. The cost functions will include metrics that capture scientific value. The project will develop new approaches to drone exploration and mapping, including machine learning of features of interest to geologists. Drones will autonomously explore and map natural rock formations in canyon environments to support and speed up the data collection and interpretation efforts of field geologists.  The project will study the structural geology of the Mecca Hills area of California, a well exposed portion of the San Andreas fault system.  Robot drones will collect data about surface features to develop maps of subsurface structures. The cognitive science-infused robot design will employ successful expert strategies and focus on areas where experts are likely to make errors to prioritize exploration of those areas in navigation plans. The proposed strategies will enable 3D surface reconstruction of canyon surfaces. They will also enable better understanding of how to enhance planning and on-the-fly decision making of experts for collecting scientifically important data.   The project's foundational work aims to develop an interdisciplinary understanding of how geologists build a scientific understanding of a region over time. It also aims to design autonomous exploration strategies for human-robot teams, and test new ways to support the sequential decisions about where to collect data to maximize scientific impact.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839705","Collaborative Research: FW-HTF: Integrating Cognitive Science and Intelligent Systems to Enhance Geoscience Practice","DUE","FW-HTF: Advancing Cognitive an, IUSE","10/01/2018","08/22/2018","Thomas Shipley","PA","Temple University","Standard Grant","Stephanie August","09/30/2021","$499,852.00","Alexandra Davatzes","TSHIPLEY@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","EHR","082Y, 1998","063Z, 9178","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim. <br/><br/>This project will make a significant contribution toward the support of future workers in geology. Understanding how geologists reason, plan to collect new data, consider three-dimensional spatial relations, and evaluate uncertainty are critically important for supporting scientists working on applied problems, such as natural resource exploration. This project will enhance existing efforts in geology to collect data using robot drones.  Drones allow access to important areas of the world too dangerous to access in person and not visible from satellite or plane.  The project will use machine learning to incorporate expert knowledge into drone flights to support effective autonomous data collection.  The data will yield improved geological understanding of an important fault system. Findings from the project will improve understanding of uncertainty in volumes and thus improve our understanding of earthquakes and the analyses of petroleum workers.  Understanding how expert geologists reason will support new exploration and mapping strategies for human-robot teams working in natural environments. The collaborative efforts of the interdisciplinary team will advance the fields of cognitive science, geology, and machine learning. The integration of cognitive science, robotics, and geology will develop new approaches to field work with human-autonomous systems teams that are faster and more effective than any either human or autonomous system would be acting alone. <br/><br/>The project will characterize expert spatial reasoning about 3D relations and uncertainty as geologists collect data to develop a 3D understanding of a new field area, make predictions about future observations, and construct geological models.  Errors in reasoning about 3D structures will be used to develop quantitative models of expert uncertainty. These models will be used to help explicitly visualize uncertainty for the experts and to construct cost functions for the robot navigation. The cost functions will include metrics that capture scientific value. The project will develop new approaches to drone exploration and mapping, including machine learning of features of interest to geologists. Drones will autonomously explore and map natural rock formations in canyon environments to support and speed up the data collection and interpretation efforts of field geologists.  The project will study the structural geology of the Mecca Hills area of California, a well exposed portion of the San Andreas fault system.  Robot drones will collect data about surface features to develop maps of subsurface structures. The cognitive science-infused robot design will employ successful expert strategies and focus on areas where experts are likely to make errors to prioritize exploration of those areas in navigation plans. The proposed strategies will enable 3D surface reconstruction of canyon surfaces. They will also enable better understanding of how to enhance planning and on-the-fly decision making of experts for collecting scientifically important data.   The project's foundational work aims to develop an interdisciplinary understanding of how geologists build a scientific understanding of a region over time. It also aims to design autonomous exploration strategies for human-robot teams, and test new ways to support the sequential decisions about where to collect data to maximize scientific impact.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839896","FW-HTF: Collaborative Research: Pre-Skilling Workers, Understanding Labor Force Implications and Designing Future Factory Human-Robot Workflows Using a Physical Simulation Platform","DUE","FW-HTF: Advancing Cognitive an","10/01/2018","08/22/2018","Kylie Peppler","IN","Indiana University","Standard Grant","Alexandra Medina-Borja","09/30/2022","$300,002.00","","kpeppler@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","EHR","082Y","063Z","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim.<br/><br/>This collaborative project between Purdue University, Indiana University and the Massachusetts Institute of Technology is based on the rationale that today's manufacturers, especially small and medium enterprises, may struggle to keep pace with rapid changes in manufacturing. To help manufacturers thrive in a rapidly changing industry, this project aims to develop a Physical-Simulation Platform that will realistically simulate interactions between workers, robots, and machines in future factories, and at the same time, improve factory agility and productivity. This project will provide new insights into workers' spatial, multitasking, and predictive task abilities in manufacturing, and their performance in shared and smooth workflows. Those insights can then be used to shape the augmented manufacturing environment of the future by amplifying cognitive capacity and transferring some cognitive burden to artificial intelligence and smart automation.  Such changes can improve both productivity and worker experience. The project will explore the economic impact on different types of workers as well as the benefits of artificial intelligence-based augmentation technologies on human labor, factory productivity and agility. In addition, the project will contribute to workforce development by creating educational plans and outreach to prepare workers for the manufacturing workplace of the future. The researchers will directly engage underserved young people by introducing them to new toolkits and curriculum developed as part of this project.  These materials can then be adapted by educators across the country. Strong industry collaborations are present to facilitate testing and adoption of this approach. <br/><br/>The research team of mechanical and electrical engineers, psychologists, computer scientists, education researchers, and economists will work toward accomplishing five goals: (1) use Mixed Reality to capture interactions, shared workflows, and collaborative tasks as close as possible to a real manufacturing environment; (2) develop and demonstrate new types of authoring platform to program robots, internet-of-things-based machines, and humans interacting with them, with augmented reality, artificial intelligence to substantially reduce cognitive loads and enhance worker and factory overall capabilities and productivities; (3) discover, design and develop flexible representations of collaborative intelligence workflows and metrics to simulate and evaluate Humans-Robots-Machines shared work; (4) evaluate shared work economics and labor market implications of augmenting humans with robotics, augmented reality, and artificial intelligence; and (5) pre-skill the workforce and increase engagement towards the future of work at the human-technology interface.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1039741","MRI: Development of a Video-Based Robotic Instrument for Behavioral Analysis and Diagnosis of At-Risk Children","CNS","MAJOR RESEARCH INSTRUMENTATION, INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, INDUSTRY/UNIV COOP RES CENTERS","10/01/2010","08/22/2018","Nikolaos Papanikolopoulos","MN","University of Minnesota-Twin Cities","Standard Grant","Rita V. Rodriguez","09/30/2019","$1,725,730.00","Kelvin Lim, Guillermo Sapiro","npapas@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","1189, 1640, 1714, 5761","1189, 5761, 9178, 9251","$0.00","Abstract <br/>Proposal #: 10-39741 <br/>PI(s): Papanikolopoulos, Nikolaos; Lim, Kelvin; Guillermo Sapiro <br/>Institution: University of Minnesota <br/>Title: MRI/Dev.: Video-Based Robotic Instrument for Behavioral Analysis and Diagnosis of At-Risk Children <br/><br/>Project Proposed: <br/>The proposed set of tools constitutes a video-based robotic instrument which targets the domain of early diagnosis for children at risk of developing psychiatric disorders. As such, this proposal is at the disciplinary boundaries between computer science, psychology and psychiatry, and medicine. Proposed is the development of a robotic instrument that could observe and automatically analyze abnormalities in children, thus introducing a novel technology which can help identifying children at risk.  Specific activities include: <br/>- Development and clinical verification of instrumentation and clinical protocols to quantify mental disorders in children; <br/>- Development and usage of computer vision and machine learning methodologies in the instrument; <br/>- Development of statistical models to evaluate the available related data sets; <br/>- Usage of a wide array of passive and active sensors and state-of-the-art 3D camera systems to collect and analyze the monitored data; <br/>- Usage of robots and robot pets as a means to detect and treat mental disorders; and, <br/>- Practical validation of the instrument at the Medical School. <br/><br/>Broader Impacts: <br/>The recent usage of computer vision methodologies/hardware and robotics for detection of mental disorders in children, in itself, constitutes strong broader impacts. Planned are also educational programs (workshops, tutorials, etc.) that will enable training gathering of physicians and psychologists to the aforementioned methods/procedures, which would otherwise not be possible. Moreover, significant planned curriculum development at the participating institutions revolves around the instrument. In addition, outreach activities for middle-school students from underrepresented groups will take place, and so will outreach to various pertinent patient groups. This truly interdisciplinary project also plans to include international partners."
"1433414","Collaborative Research: ITEST-Strategies: Human-Centered Robotics Experiences for Exploring Engineering, Computer Science, and Society","DRL","ITEST","09/01/2014","08/27/2015","Selma Sabanovic","IN","Indiana University","Standard Grant","Celestine Pea","08/31/2019","$407,163.00","Cindy Hmelo-Silver","selmas@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","EHR","7227","9251","$0.00","Involving more students from urban and rural areas in STEM fields and careers has been at the forefront of national STEM education reform efforts for decades. Research shows that engaging these students in STEM activities relevant to their everyday lives is critical to increasing their motivation, interest, learning, and participation in STEM. This project will address this need through engineering and computer science activities aimed at helping 400 middle and high school students grasp the intricacies of scientific principles and technology design. The goal is to inspire and prepare a greater number of students from the targeted population to understand how these principles and design strategies contribute to a stronger educational and technological society. To do this, the project will use a teaching and learning model that will integrate human-centered robotics and telepresence theme-based activities in a problem-based learning and systems thinking environment. In this project, human-centered robotics will involve the development of robotics technologies and applications for everyday use while telepresence robots will enable better communication, operation, and exploration across enormous distances. This dual strategy makes the proposed technological approach highly relevant to the daily needs of students in Alaska.<br/><br/>The project will be conducted by an interdisciplinary team of students and faculty mentors from the Electrical Engineering and Computer Science Departments at the University of Alaska at Fairbanks and from the School of Informatics and Computing and the Center for Research on Learning and Technology at Indiana University at Bloomington. Through this partner-effort, the research team will develop a curriculum that addresses the technical and societal aspects of the human-centered robotics and telepresence that underlie the engineering and computer science concepts students will learn about. Each year, students will actively engage in a 9-month problem-based learning strategy using two basic open-architecture platforms based on the Arduino microcontroller. Students will be able to customize these platforms through design variations and with the addition of new sensors, actuators, program parts, and other technology-related functions. User-friendly software will help teachers and mentors assist students with their designs and redesigns. Through this approach, students will gain STEM knowledge and skills that will be useful to their own individual lives and for sharing with other students, who might be chronically ill, reside in remote places, live in the lower 48 states, or even internationally via ties established through prior NSF-supported efforts. Hence, this project will help student develop technology-based products adaptable to peoples' daily environments, needs, and practices in some meaningful way, which in turn, could increase student's motivation and interest in STEM and STEM careers."
"1763878","CHS: Medium: Collaborative Research: Manipulation Assistance for Activities of Daily Living in Everyday Environments","IIS","Cyber-Human Systems (CHS)","08/01/2018","08/23/2018","Robert Platt","MA","Northeastern University","Continuing grant","Ephraim P. Glinert","07/31/2022","$389,825.00","","r.platt@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","7367","7367, 7924","$0.00","While many people with disabilities need help with activities of daily living (ADLs) in their homes or at other locations, they care deeply about maintaining their sense of independence, which implies limiting the tasks that professional or family caregivers are asked to provide. There is the potential for robots to have a huge impact here, by enabling people to live independently for longer. The goal of this research is to develop a robotic wheelchair-manipulator system (RoWMan) consisting of a power wheelchair with a robotic arm mounted on it, that will help its user perform ADLs either as an assistive device or by performing manipulation tasks autonomously. In assistive mode, the user would ride in the wheelchair, with the RoWMan system manipulating items as requested. Whereas in autonomous mode, the user could ask RoWMan to navigate on its own through the house, retrieve items, and place them as directed. This project will necessitate the development of new user interfaces as well as an array of new machine learning and robotics techniques that will enable successful autonomous robotic navigation and manipulation in unstructured environments. To ensure broad impact, project outcomes will be evaluated with a user population at Crotched Mountain Rehabilitation Center.<br/><br/>In recent focus groups it was found that users want a number of capabilities, including the ability to pick up something from the floor, the ability to unlock and open a door, the ability to manipulate items on a tightly packed shelf, etc. RoWMan will be designed so as to enable users to perform these sorts of tasks, by focusing on two areas: robotic manipulation and human-robot interaction. The manipulation work will develop new algorithms that perform well with novel objects in unstructured environments. Traditionally, manipulation planners assume that the shapes of the objects involved are known in advance or can be estimated on the fly, but these assumptions often cause problems in practice. The focus here will be to develop new algorithms based on deep reinforcement learning that can perform manipulation tasks reliably even when the geometry of the world is unknown in advance. The project will also support research into a new class of human-robot interaction based on laser pointers. Recent work suggests that laser pointing can be very effective for the target user community because it enables users to point directly in the environment rather than on a screen which induces additional cognitive load. This project will develop new ways of communicating sophisticated intent using a combination of environmental context, laser pointing, and laser gestures.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1356406","Support Through Robotics for Underserved Talented Students (STRUTS)","DUE","S-STEM:SCHLR SCI TECH ENG&MATH","07/01/2014","08/22/2018","Natalie Candela","MI","Kettering University","Standard Grant","Talitha Washington","06/30/2019","$597,955.00","Robert Nichols, Samantha Klaskow, Natalie Candela","ncandela@kettering.edu","1700 University Ave","Flint","MI","485046214","8107629677","EHR","1536","9178, SMET","$0.00","The need to increase the number and quality of STEM graduates in the workforce both nationally and in Michigan is well documented.  A 2010 state-level analysis study by the Georgetown University Center on Education and the Workforce (http://cew.georgetown.edu/jobs2018/states) projects that by 2018  45 percent of STEM jobs in Michigan will be in Engineering and Technicians Occupations and 94 percent of these jobs require postsecondary education.<br/><br/>Kettering University, Support Through Robotics for Underserved Talented Students (STRUTS) enrolls full-time, 10 academically talented but financially disadvantaged students in their pursuit to become leaders in a high quality scientific and technical workforce.  The number of scholars is optimal for creating camaraderie within a cohort which is large enough to be diverse but not too large to marginalize students.  Kettering University attracts students interested in computer and technical fields who have financial need. STRUTS funding bridges the gap between available financial support and the cost of tuition so removing financial barriers which result in attrition of students with financial need.  Academic support through experiential learning, leadership opportunities, FIRST Robotics, multi-level mentorship, and rigorous academics ensures the success of scholars and is centered around Kettering's new FIRST Community Center (FCC), which houses high school FIRST Robotics teams on campus.  Scholars receive targeted academic support, have a strong cohort  and a cadre of peer mentors who have completed a class in mentoring.  In addition they are provided with challenging paid co-op work assignments to prepare them for professional success and workplace leadership.  STRUTS Scholars acquire essential leadership skills when they mentor the FIRST Robotics participants working in the FCC. Simultaneously, STRUTS Scholars are mentored by an extensive pool of committed Kettering faculty from a variety of disciplines. A required research-based thesis is focused on professional practice with an interdisciplinary focus which provides an opportunity to apply academic and co-op experience with research to solve a real problem at a pre-selected organization. <br/><br/>A comprehensive, culturally responsive assessment plan for continuous improvement and overall success will be implemented.  At least 90% of STRUTS Scholars are retained and graduate. Programmatic successes are documented to insure sustainability at Kettering and replication at other elite technology schools.  Results are disseminated to enhance the benefit of need-based support, FIRST Robotics, and mentorship on STEM higher education. The STRUTS project  is a showcase to potential donors with a view to sustaining matriculation and graduation of talented students who have financial need."
"1830403","NRI: FND: COLLAB: A Foundational Approach to Muscle Actuators that Lowers Barriers to Muscle-Powered Robotics Research","CMMI","National Robotics Initiative","09/01/2018","08/21/2018","Michael Yip","CA","University of California-San Diego","Standard Grant","Irina Dolinskaya","08/31/2021","$389,174.00","","yip@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","ENG","8013","030E, 034E, 8024, 8086","$0.00","This National Robotics Initiative (NRI) project will promote the progress of science and advance the national prosperity by developing a foundational approach towards muscle-powered machines that move using biomimetic muscle actuators. Biomimetic muscle actuators, or robot muscles, are actuators that closely mimic the properties of biological muscles in nature. A common set of challenges in actuator selection and design, and modeling and controlling behaviors and properties emerge among different muscle actuators. This award supports identifying and unifying modeling, control, and design strategies that would lower the barrier to muscle-powered robotics research.  A significant effort to de-risk robot muscles for designers is the creation a robot muscles toolkit, an accessible software and hardware toolkit for designing muscle-powered machines and for democratizing the development and proliferation of these technologies at a broad scale. Design challenges and competitions will spur the interests and community building for those interested in robot muscles across all ages and experiences, from K-12 to college students and researchers.  Local arrangements for outreach in the San Diego and Greater Boston Area communities are planned for stirring interest in robotics for underrepresented minorities.<br/><br/>A novel, data-driven process and structure for parameterizing a common set of biomimetic features that define muscle actuation will be developed in order to anchor modeling, control, and design strategies across a so-called performance and configuration space. These methods can be employed across muscle types and generalize beyond currently available muscle actuators. There is a strategy for muscle selection over multi-dimensional performance criteria that incorporates both empirical data and physics models. Design strategies for muscle configurations for amplification along these performance dimensions, generalizable across muscles, will be investigated. New technologies will be able to be easily added into this framework to perform quantitative comparison studies without replication of gold standard actuators.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830291","NRI: FND: COLLAB: A Foundational Approach to Muscle Actuators that Lowers Barriers to Muscle-Powered Robotics Research","CMMI","National Robotics Initiative","09/01/2018","08/21/2018","Robert Wood","MA","Harvard University","Standard Grant","Irina Dolinskaya","08/31/2021","$360,826.00","","rjwood@eecs.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","ENG","8013","030E, 034E, 8024, 8086","$0.00","This National Robotics Initiative (NRI) project will promote the progress of science and advance the national prosperity by developing a foundational approach towards muscle-powered machines that move using biomimetic muscle actuators. Biomimetic muscle actuators, or robot muscles, are actuators that closely mimic the properties of biological muscles in nature. A common set of challenges in actuator selection and design, and modeling and controlling behaviors and properties emerge among different muscle actuators. This award supports identifying and unifying modeling, control, and design strategies that would lower the barrier to muscle-powered robotics research.  A significant effort to de-risk robot muscles for designers is the creation of a robot muscles toolkit, an accessible software and hardware toolkit for designing muscle-powered machines and for democratizing the development and proliferation of these technologies at a broad scale. Design challenges and competitions will spur the interests and community building for those interested in robot muscles across all ages and experiences, from K-12 to college students and researchers.  Local arrangements for outreach in the San Diego and Greater Boston Area communities are planned for stirring interest in robotics for underrepresented minorities.<br/><br/>A novel, data-driven process and structure for parameterizing a common set of biomimetic features that define muscle actuation will be developed in order to anchor modeling, control, and design strategies across a so-called performance and configuration space. These methods can be employed across muscle types and generalize beyond currently available muscle actuators. There is a strategy for muscle selection over multi-dimensional performance criteria that incorporates both empirical data and physics models. Design strategies for muscle configurations for amplification along these performance dimensions, generalizable across muscles, will be investigated. New technologies will be able to be easily added into this framework to perform quantitative comparison studies without replication of gold standard actuators.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1316934","NRI: Small: Multirobot-Human Coordination for Visual Scene Understanding","IIS","COLLABORATIVE RESEARCH, IIS SPECIAL PROJECTS, National Robotics Initiative","09/01/2013","07/17/2018","Amit Roy Chowdhury","CA","University of California-Riverside","Standard Grant","Reid Simmons","03/31/2019","$821,934.00","Anastasios Mourikis, Jay Farrell","amitrc@ece.ucr.edu","Research & Economic Development","RIVERSIDE","CA","925210217","9518275535","CSE","7298, 7484, 8013","5920, 7923, 8086","$0.00","The objective of this research is to enable the development of teams of robots, equipped with vision and other sensors, capable of working alongside humans in critical missions, such as search and rescue. Key requirements are situational awareness and coordinated action. The approach is to develop mathematical frameworks and algorithms to enable such a team of robots to coordinate their paths, share and analyze their sensor data, maintain communications, and interact effectively and safely with humans. The project brings together experts in computer vision, robotics, estimation theory and controls.<br/><br/>Intellectual Merit. Realizing the above goals will require advances in several inter-related domains. Specifically, the sensing, estimation, and trajectory control tasks must seamlessly integrate visual analysis with navigation and control strategies, as well as inputs from humans. Novel distributed estimation strategies must be developed to accommodate difficult and dynamic environments. Efficient human-robot coordination necessitates methodologies for joint exploration and mapping, identifying important visual information, and robots? operation at different levels of autonomy.<br/><br/>Broader Impact. The success of this project will be a major step towards the deployment of teams of robots to assist humans in dangerous and complex tasks like disaster response. Search-and-rescue experts will advise the team in developing a prototype system, and evaluating it in situations that mimic operational conditions. The developed software tools will be disseminated to other researchers so they can build on the results. Undergraduates from UCR's highly diverse student population will gain valuable experience working alongside graduate student researchers."
"1734100","NRI:  INT:   Design and Development of a Social Robot for Gathering Ecological Momentary Stress Data from Teens","SES","National Robotics Initiative","09/01/2017","04/24/2018","Elin Bjorling","WA","University of Washington","Standard Grant","Frederick M Kronz","08/31/2020","$1,075,001.00","Maya Cakmak, Emma Rose","bjorling@uw.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","SBE","8013","8086, 9179, 9251","$0.00","This award supports project EMAR (Ecological Momentary Assessment Robot), a timely interdisciplinary project that will research, develop, and deploy a user-friendly social robot that gathers teen mental health data in a public high school setting. Existing research only provides evidence for the benefits of human-robot-interaction among young children and adults; investigating the interactions between teens and robots has been largely overlooked. Such an investigation is needed since adolescents are very likely to have long-lasting relationships with robots in the future at work, in the classroom, and at home. It also needed especially since adolescents constitute a vulnerable population that is negatively affected by stress and mental health issues, and since there are well-established difficulties in gathering accurate, useful, mental health data from teens in their natural environment with digital surveys and experience sampling using static data collection tools including computers, tablets, and smart phones. The success of this project will contribute to the development of ubiquitous social robots that serve as tools for on-site, real time data collection. Such tools would improve research methodology and facilitate evidence-based decisions in real time. In addition, this interdisciplinary, community-based project will serve to achieve societally relevant outcomes by broadening participation and engaging both undergraduate and high school students, including those who are traditionally underrepresented in STEM. The results of this project will be disseminated widely using pertinent means for reaching researchers, practitioners, community partners, and schools.<br/><br/>The project has two key objectives: To design and develop an engaging social robot to capture real-time stress and mood data from teens, and to successfully deploy and evaluate the social robot in an urban, high school setting. As school populations increase, and mental health services decrease, gathering valid, real-time data via engaging technology may be an essential tool for assessing student health. Using a human-centered design approach, the project employs participatory methods to engage local teens directly in the design and testing of the robot. The project will utilize interdisciplinary investigations of teen-robot interactions, teen-centric iterative design, and the social impact of deployment; in doing so, it will acquire valuable and much needed information to understand the relationship between teens and robots as well as the potential impact of a social robot as a data gathering device. It will also facilitate assessing the feasibility of using a robot to gather real-time data for aggregation into visual data that would serve to inform decision-making and evaluation of interventions; such an ability would be especially useful in school environments where teens need more support. The results of this study will contribute and serve to advance the field of robotics as well as the fields of adolescent health and research methodology. They will also contribute to understanding the specific relationship between teens and robots, which is an imperative for this generation's future success."
"1744637","Workshop on the Dynamic Interaction of Embodied Human and Machine Intelligence; Marconi State Historic Park, Marshall, California; June 2018","CMMI","M3X - Mind, Machine, and Motor, PERCEPTION, ACTION & COGNITION","08/01/2017","07/19/2017","Ramesh Balasubramaniam","CA","University of California - Merced","Standard Grant","Robert Scheidt","07/31/2019","$49,995.00","","ramesh@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2097566405","ENG","058Y, 7252","030E, 034E, 063Z, 7252, 7556, 8024","$0.00","This award will support an interdisciplinary workshop to study how humans and intelligent machines, such as robots, may behave while physically interacting with each other, in contrast to situations where they only exchange information. These questions will become increasingly important as humans begin to come into frequent physical contact with intelligent machines, such as when navigating shared spaces, riding in or walking near autonomous vehicles, or interacting with caregiving or physical therapy robots.<br/><br/>This workshop will gather experts from cognitive neuroscience, behavioral science, dynamics and control, robotics, optimization, and computer science to define key challenges in analyzing the dynamic behavior of systems of embodied human and machine intelligences. Due to rapidly developing capabilities in machine learning, and wide scale deployment of autonomous and intelligent robotic systems, humans in the near future will regularly find themselves physically interacting with intelligent technology. Such intelligent technology might include home assistance robots, physical therapy robots, autonomous vehicles, and smart buildings. The dynamics of physically coupled of humans and intelligent machines have so far received little study, despite the potential for unexpected behavior."
"1526986","NRI: Simulation Guided Design To Optimize the Performance of Robotic Lower Limb Prostheses","IIS","National Robotics Initiative","09/01/2015","08/12/2015","Frank Sup IV","MA","University of Massachusetts Amherst","Standard Grant","Reid Simmons","08/31/2019","$630,331.00","Brian Umberger","sup@umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","8013","8086","$0.00","The goal of this project is to use sophisticated computer models of the human body to help design the next generation of robotic prosthetic technologies that maximize mobility for lower-limb amputees. The major outcome of this project will be an improved approach for designing prosthetic devices that reduce loading on the body and make walking easier. The success of this project will improve the quality of life for lower limb amputees by increasing their mobility and their ability to participate in the activities of daily life. The proposed research is especially relevant for older amputees whose residual limbs cannot tolerate significant loading. This award will also support the training of the next generation of engineers and scientists and the development of an innovative STEM robotics program targeted toward middle and high school teachers and their students.<br/><br/>This project is focused on creating a new design process for assistive robotic devices that aid people with mobility impairments. Using modeling and simulation, optimal robot forms and controls will be identified. The case study for this project is the development of prostheses for below-knee amputees. The guiding principle of the project is to consider the complete and altered anatomy of the person and develop solutions that are not limited to anthropomorphic mimicry. Detailed musculoskeletal models and optimal control simulations will be used to guide the robotic prosthesis development process towards optimized loading conditions while minimizing metabolic energy consumption. In this process, the optimal prosthesis form and specifications are initially unknown and are generated through predictive simulations. The results will then be reverse-engineered to develop robotic ankle prostheses that enable these optimal gait patterns for below-knee amputees. This approach will later be extended to maximize the performance of other co-robot systems such as exoskeletons and other rehabilitation robots."
"1833005","RII Track-4: A Reflective Learning and Association Control Framework based on Adaptive Dynamic Programming: Architecture and Applications in Robotics","OIA","EPSCoR Research Infrastructure","10/01/2018","08/20/2018","Zhen Ni","SD","South Dakota State University","Standard Grant","John-David Swanson","09/30/2020","$261,503.00","","Zhen.Ni@sdstate.edu","1015 Campanile Ave","Brookings","SD","570070001","6056886696","O/D","7217","9150","$0.00","Nontechnical description: <br/>Data efficiency and learning speed are two of the major bottlenecks for applying biologically-inspired control methods in many domains. The project's goal is to address these fundamental challenges by introducing a new adaptive dynamic programming-based learning control framework and integrate it into space robot navigation and scouting applications such as the Mars Rover. The scientific contribution of this project will promote interdisciplinary research in computational intelligence, machine learning, control and robotics. In addition to space applications, the proposed structure can also be applied to robot-assisted pedestrian evacuation application and cyber-physical power systems and is expected to impact general systems beyond this project period. Due to geographic isolation, South Dakota doesn't have a National Aeronautics and Space Administration (NASA) research center, and research collaboration opportunities on space technology is very limited. This project will expand the principle investigator (PI)'s research capacity through an extended visit and collaboration with NASA Ames Research Center located in San Jose, CA, and transform the PI's career path from theoretical algorithm/architecture development towards a new direction in complex space applications. Meanwhile, the outcomes of this project align well with the South Dakota's and South Dakota State University's strategic plans. The collaboration fits well with NASA's mission to Mars and technology roadmaps.<br/><br/><br/>Technical description: <br/>The proposed project will fundamentally advance the learning and association of biologically-inspired control methods. Three major contributions to the scientific field are expected. First, a new experience network is proposed and systematically integrated into a model-free adaptive dynamic programming-based learning control framework. The PI will design an experience replay tuple (i.e., state-action-reward pair) based on backward temporal difference information from historical data. This design can avoid the model network/prediction noted in existing literature and significantly save computation resources. Second, instead of a uniform sampling method, the PI proposes a prioritized sampling method based on the Bellman's estimation error. This new method is expected to enhance the controller's reflective learning performance with useful long-short term memory. The stability and convergence properties will also be analyzed. Third, this project is closely tied with NASA on robot and optimal control for space program. This new learning control structure will be integrated for robot navigation, exploration and scouting in unknown spaces. The PI and the collaborator will use both a virtual reality platform and a real Rover facility to analyze the control performance of the proposed algorithm at NASA Ames. The PI's outreach and dissemination plans will cultivate the scientific curiosity of K-12 students and motivate their interest in STEM programs. Moreover, the integration of the project's cutting-edge research results into the PI's new courses will aid retention of current STEM students. Specific plans include a workshop for a local middle school, a distance course for demographically diverse institutions, and development of new courses.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637961","NRI: Towards Dexterous Micromanipulation and Assembly","IIS","National Robotics Initiative","09/01/2016","07/27/2016","David Cappelleri","IN","Purdue University","Standard Grant","Reid Simmons","08/31/2019","$1,000,000.00","Song Zhang, Karthik Ramani","dcappell@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","8013","8086","$0.00","Robots that people are familiar with are large, roughly, human-sized.  The theory and design tools for developing such macro-scale robots is well developed.  By contrast, the theory and design tools applicable to tiny, or micro-scale, robots is nearly non-existent.  The goal of this project is to enable the transition of robot manipulation technology from macro-scale robots to micro-scale robots.  The expected project outcomes are: i.) controlled and predictable environments for micro-robotic manipulation and assembly; ii.) a new class of 3D vision-based micro-force sensors and a 3D multi-resolution vision system; and iii.) the identification of dexterous micro-manipulation primitives via human micro-teleoperation with new novel haptic probes.  These results will enable the assembly of micro-scale systems that are currently not possible.  Such systems are applicable across a wide range of domains, such as cm-to-mm scale robots, micro-sensors, steerable catheters, micro-fluidic, and energy harvesting devices.  <br/><br/>At the micro-scale, surface forces dominate the interactions causing unpredictable forces.  This project aims to lay the foundations for tools, such as simulators, motion planners, controllers, etc., to be developed for this unique micro-scale environment.  The research approach is to reduce the uncertainty in forces present in the micro-world to enable dexterous micro-manipulation and assembly.  A new class of manipulation substrates, fixtures, micro-parts, and manipulation tools to control and overcome the levels of adhesion forces present in the micro-world will be created.  To enable force control, 3D vision-based micro-force sensing probes along with a multi-resolution 3D vision system to detect the micro-forces in real-time will be developed.  Dexterous micro-manipulation primitives will be identified from a human tele-operating a multi-probe micro-manipulation system with micro-force feedback in an augmented reality system.  How much and what types of micro-force feedback information is needed for the human to perform different tasks will be studied.  These motion primitives together with physics-based simulators can reduce uncertainty in motion planners.  The insights gained here will dictate the force-control algorithms implemented in future automated systems."
"1426828","NRI: Collaborative Research: Minimally Invasive Robotic Non-Destructive Evaluation and Rehabilitation for Bridge Decks (Bridge-MINDER)","IIS","COLLABORATIVE RESEARCH, IIS SPECIAL PROJECTS, National Robotics Initiative","08/01/2014","08/03/2018","Jingang Yi","NJ","Rutgers University New Brunswick","Standard Grant","Reid Simmons","12/31/2018","$628,499.00","Nenad Gucunski, Hung La","jgyi@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","7298, 7484, 8013","5936, 8086","$0.00","Bridges are critical components of modern transportation infrastructure. Bridges deteriorate over time as a result of material aging, excessive use and overloading, environmental conditions, inadequate maintenance, and deficiencies in inspection and evaluation. Building on the recent advances in robotics and automation technologies, the objective of this project is to develop a novel Minimally Invasive robotic Non-Destructive Evaluation and Rehabilitation for bridge decks.  <br/><br/>The project develops new robotic system, algorithms and control schemes for sustainable civil infrastructure, including (1) development of a novel robotics-assisted in-traffic system for highly-efficient, safety-guaranteed bridge deck inspection and diagnosis; (2) development of a new robotic rehabilitation system for delivering fast, cost-effective, minimally invasive repair and maintenance for bridge decks; (3) a human-in-the-loop robotic coordination for minimally traffic interference; and (4) experimental platforms and field performance evaluation for the proposed system. The project also provides insights to advance real time scene understanding, multiple robot coordination, and human-robot collaboration in complex robotic systems. If successful, this project can drastically reduce bridge maintenance cost and mitigate negative impact caused by closing the bridge traffic flow under traditional bridge inspection and repair. The project outcomes, including source code, datasets, and publications, are to be shared among research community and the general public. The project also includes a number of integrated research and education programs to attract students from underrepresented groups into engineering and involve students into robotics research."
"1552427","CAREER: End-User Programming of General-Purpose Robots","IIS","Cyber-Human Systems (CHS)","05/15/2016","08/20/2018","Maya Cakmak","WA","University of Washington","Continuing grant","Ephraim P. Glinert","04/30/2021","$301,336.00","","mcakmak@cs.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","7367","1045, 7367","$0.00","Robots that can assist humans in everyday tasks have the potential to improve people's quality of life and bring independence to persons with disabilities.  A key challenge in realizing such robots is programming them to meet the unique and changing needs of users and to robustly function in their unique environments.  Most research in robotics targets this challenge by attempting to develop universal or adaptive robotic capabilities.  This approach has had limited success because it is extremely difficult to anticipate all possible scenarios and use-cases for general-purpose robots.  Instead, this research aims to develop robots that can be programmed in-context and by end-users after they are deployed.  The PI's approach is to apply and extend methods from the broad research area of end-user programming, which has previously been limited to personal computers, smart phones, and Web applications, to programming robots.  Project outcomes will have long-term societal and economic impacts, particularly on individuals with varying levels of motor impairments.  To further broaden the impacts of this research, the project will involve several outreach and educational activities focused on broadening participation of women and individuals with disabilities in computer science education, research, and careers.  These activities will directly integrate tools developed in the project, within three educational outreach modules for K-12 students and one undergraduate course.  Outreach modules will target three venues with different time scales; a week-long summer camp for students with disabilities organized by the UW DO-IT center, a three-hour exercise for a ""Girls who Code"" field trip, and one-hour exercise for an ""Hour of Code"" event.  The Robotics Capstone course developed by the PI will be updated to integrate tools developed in this project and to focus on projects within assistive robotics with the involvement of an actual customer.  All tools will be implemented on a state-of-the-art mobile manipulator robot, PR2, and will be released as open-source projects.  A truly unique aspect of this research is that developed tools will be deployed on two privately-owned in-home PR2 robots, leading to first insights from real-world evaluations.<br/><br/>To achieve her goal the PI will address challenges related to distinct characteristics of robots including situatedness, ability to influence the environment, mobility, distributed concurrent processing, and overall complexity.  This research will produce a suite of new methods and tools within three programming paradigms: (i) ""situated programming"" which involves programming through direct interactions with the robot and its environment, (ii) ""simplified programming"" which involves actual programming but with highly simplified languages, and (iii) ""abstracted programming"" which involves manipulating abstractions of program entities for which programs are synthesized automatically.  All methods will be instantiated as tools for programming robots at multiple levels, including programming of new knowledge, skills, tasks, and rules.  The main objectives of the projects are to make these tools (i) expressive enough to capture useful real-world tasks, (ii) usable by people with no technical background, and (iii) accessible to people with diverse abilities.  The first objective will be evaluated through systematic experiments with a comprehensive user-centered benchmark for domestic assistive robots, including programming of tasks such as fetching, organizing, or preparing, and skills such as opening or closing cabinets, drawers, appliances, and faucets in different homes.  The second and third objectives will be evaluated through user studies with both able-bodied and motor-impaired individuals."
"1545287","NRT: Accessibility, Rehabilitation, and Movement Science (ARMS): An Interdisciplinary Traineeship Program in Human-Centered Robotics","DGE","IGERT FULL PROPOSALS, RES IN DISABILITIES ED, NSF Research Traineeship (NRT)","09/01/2015","08/13/2015","Ayanna Howard","GA","Georgia Tech Research Corporation","Standard Grant","Laura Regassa","08/31/2020","$2,908,825.00","Lena Ting, Charles Kemp, Randy Trumbower","ah260@gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","EHR","1335, 1545, 1997","1545, 7433, 8212, 9179, SMET","$0.00","NRT: Accessibility, Rehabilitation and Movement Science (ARMS): An Interdisciplinary Traineeship Program in Health-Centered Robotics<br/><br/>The world's demographics are changing. People continue to live longer and the U.S. population is becoming older and more racially and ethnically diverse. There is also an increase in younger individuals living with a life-long disability, such as veterans who sustain catastrophic injuries, persons suffering from neurodegenerative diseases, and children growing up with developmental disorders or delays.  With this changing population profile comes an increasing demand for advanced healthcare technologies and a need to train a new generation of engineers able to develop these new technologies. This National Science Foundation Research Traineeship award to the Georgia Institute of Technology will address this demand by training graduate master's and doctoral students in the interdisciplinary field of healthcare robotics. The traineeship anticipates providing a unique and comprehensive training opportunity for one hundred and fifty-five (155) students, including thirty (30) funded trainees, by combining disciplines in robotics, studies in health sciences, interactions with clinical partners, hands-on rehabilitation research, and a culture of innovation and translational research. <br/><br/>Trainees will have unique exposure to a variety of approaches developed in Robotics, Physiology, Neuroscience, Rehabilitation, and Psychology. The traineeship will bridge the gap between healthcare and robotics by addressing two major barriers:  a) the lack of a formalized framework to enable interdisciplinary collaborations between robotics engineers and health professionals; b) the tendency for students in robotics to be unprepared to address problems in healthcare, including a lack of appreciation for the challenges encountered by clinicians, caregivers, and people with disabilities.  Through close interactions with various partners, the traineeship will expand student horizons beyond a technology-first mentality to consider challenges in developing robotic solutions that address the needs of clinicians, caregivers, and people with disabilities.  The goal is to develop an interdisciplinary curriculum based upon the concept of participatory design, problem-based learning, and an immersive research experience that blends techniques from multiple disciplines to solve problems posed in healthcare.  A second major goal of the traineeship is to increase the participation of women, underrepresented minorities, and students with disabilities in robotics and related engineering fields. The project will develop a new M.S. degree program in healthcare robotics and a new PhD concentration area in healthcare robotics as well as curricular materials and best-practices to allow other institutions to develop similar programs.<br/><br/>The NSF Research Traineeship (NRT) Program is designed to encourage the development and implementation of bold, new, potentially transformative, and scalable models for STEM graduate education training.  The Traineeship Track is dedicated to effective training of STEM graduate students in high priority interdisciplinary research areas, through the comprehensive traineeship model that is innovative, evidence-based, and aligned with changing workforce and research needs.<br/><br/>This award is supported, in part, by the EHR Core Research (ECR) program, specifically the ECR Research in Disabilities Education (RDE) area of special interest.  ECR emphasizes fundamental STEM education research that generates foundational knowledge in the field.  Investments are made in critical areas that are essential, broad and enduring: STEM learning and STEM learning environments, broadening participation in STEM, and STEM workforce development."
"1734419","NRI: FND: Collaborative Multi-Robot Systems with Provable Availability, Safety, and Optimality Guarantees","IIS","SPECIAL PROJECTS - CISE, National Robotics Initiative","09/01/2017","05/04/2018","Jingjin Yu","NJ","Rutgers University New Brunswick","Standard Grant","Ralph Wachter","08/31/2020","$548,060.00","","jingjin.yu@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","1714, 8013","8086, 9251","$0.00","In recent years, collaborative multi-robot systems have had great initial success in industrial applications. Notable examples include the deployment of automated straddle carriers at container shipping ports (e.g., Brisbane, Rotterdam, Los Angeles) and the use of mobile robots at order fulfillment centers of online retailers (e.g., Amazon). Operational efficiency plays a pivotal role in the viability of these multi-robot systems, the underlying structure of which is yet to be fully understood. A thorough investigation of large-scale collaborative multi-robot systems will lead to solutions for the effective routing of many robots in dynamic and dense settings with provable availability, safety, and optimality guarantees, which will help lower the barrier of entry for industrial multi-robot applications and contribute to productivity increases of the US labor force.<br/><br/>Algorithmic issues rising from the domain possess unique features that distinguish them from well-studied problems. On one hand, classical pickup and delivery problems (PDP) do not model the non-trivial geometry of physical robots and the possible collisions among multiple robots sharing a limited workspace. On the other, multi-robot path and motion planning research has yet to systematically address the coordination of hundreds to thousands of robots for the continuous execution of dynamic and stochastic tasks. The proposed study intends to fill this gap between research and application through the modeling and subsequent algorithmic resolution of the problem, which we call the dynamic multi-robot dispatching problem (DMD). Depending on the specific application domain, DMD may be subdivided into unlabeled (e.g., container unloading from ships) and labeled (e.g., order fulfillment) variants, providing rich grounds for structural exploration. Despite the fact that optimal multi-robot coordination is a computationally intractable problem, preliminary efforts indicate that approximately optimal solutions could be computed in polynomial time, through the careful integration of the state-of-the-art multi-robot motion planners and the global coordination of robot flows. Following this route, the proposed research will develop algorithmic solutions for DMD with provable availability and optimality guarantees under stringent safety assurances for human co-workers. Working with collaborators, the research will also seek to maximize its applicability to industrial setups."
"1719031","PFI:BIC: iWork, a Modular Multi-Sensing Adaptive Robot-Based Service for Vocational Assessment, Personalized Worker Training and Rehabilitation.","IIP","PARTNRSHIPS FOR INNOVATION-PFI, IIS SPECIAL PROJECTS","09/01/2017","06/14/2018","Fillia Makedon","TX","University of Texas at Arlington","Standard Grant","Jesus Soriano Molla","08/31/2020","$999,638.00","Morris Bell, Nicolette Hass, Vassilis Athitsos","makedon@cse.uta.edu","701 S Nedderman Dr, Box 19145","Arlington","TX","760190145","8172722105","ENG","1662, 7484","1662","$0.00","Automation, foreign competition, and the increasing use of robots replacing human jobs, stress the need for a major shift in vocational training practices to training for intelligent manufacturing environments, so-called ""Industry 4.0"".  In particular, vocational safety training using the latest robot and other technologies is imperative, as thousands of workers lose their job or die on the job each year due to accidents, unforeseen injuries, and lack of appropriate assessment and training.  The objective of this Partnerships for Innovation: Building Innovation Capacity (PFI:BIC) project is to develop iWork, a smart robot-based vocational assessment and intervention system to assess the physical, cognitive and collaboration skills of an industry worker while he/she performs a manufacturing tasks in a simulated industry setting and collaborating with a robot to do the task. The aim is to transform traditional vocational training and rehabilitation practices to an evidence-based and personalized system that can be used to (re)train, retain, and prepare workers for robotic factories of the future. The need for personalized vocational training, rehabilitation and accurate job-matching is essential to ensuring a strong manufacturing sector, vital to America's economic development and ability to innovate. The iWork service is ""smart"" because it can adjust and adapt to the individual's abilities as it assesses him/her and help decide on the type of tasks needed to test and train, based on the job's complexity, difficulty or familiarity to the worker.  The iWork system integrates human expert knowledge to overcome or compensate for detected worker constraints. <br/>Research has shown that robot trainers can increase motivation and sustain interest, increase compliance and learning, and provide training for specific and individual needs. The iWork system aims to assess and train both the human and the work-assistive robot, as they collaborate on a manufacturing job.  The projected outcome is low-cost vocational training solutions that can have substantial economic and societal benefits to diverse economic sectors. Most importantly, if successful, projected outcomes could impact how millions of persons seeking a manufacturing job are trained, including those facing a type of learning, physical or aging disability. The system's mobile, low cost methods accelerate recognizing a worker's specific needs and improve the ability of the vocational expert to make correlations between cognitive and physical assessments, thus empowering traditional practices with user-centric targeted training methods. In addition, the project's robot-based emphasis on safety and risk assessment, can reduce liability costs and productivity setbacks faced by industry, due to manufacturing accidents. <br/>The iWork system uses computational methods in reinforcement (machine) learning, data mining, collaborative filtering and human robot interaction to collect and analyze multi-sensing worker data during a manufacturing human-robot collaboration simulation. Data collected and analyzed come from sensors, wearables, and explicit user feedback measuring worker movements, eye gazes, errors made, performance delays, human-robot interactions, physiological metrics, and others, depending on the task. The system has a closed loop architecture composed of four phases: assessment, recommendation, intervention (or adjustment), and evaluation, with a human expert in the loop. The system generates recommendations for personalized interventions to the expert, at different loop intervals. Use of the latest developments in sensing technologies, robotics and intelligent communications, assess the ability to enhance the intelligence of a robot co-worker with more human-like learning and collaboration abilities to support the human in achieving a task.  The system is modular and customizable to a particular manufacturing task, domain or worker robot. Two types of robots are used, socially assistive robots that provide non-contact user assistance through feedback and physically assistive robots that provide cognitive, physical and collaboration skill training. To predict risks of injury due to inattention, age, vision, or physical and mental issues, motion analysis and kinematics experiments are conducted to determine the type of safety training needed, to assess how well a human interacts with a collaborative robot, and how best to train the robot to help the human overcome identified physical and other deficiencies in performing a given task. The project integrates three main areas of expertise, engineered service system design, where assistive robots interact with and train each other to collaborate; computing, sensing, and information technologies, where machine learning, data mining and recommender algorithms are used to identify behavioral patterns of interest, and recommend targeted interventions; and human factors and cognitive engineering that deploy methods from the team's expertise in workplace assessment, personalized psychiatric intervention, and evaluation methods of vocational satisfaction, work habits, work quality, etc., as they relate to job preparation and retention.<br/>The project has an interdisciplinary team of experts from two collaborating universities, University of Texas Arlington (UTA) and Yale University, representing several fields, including human factors, psychology, computing, and industrial organization. The project deploys two primary industry partners, SoftBank Robotics (San Francisco, CA) manufacturer of humanoid service robots, and InteraXon (Canada), producing mobile EEG devices, who provides hardware, software and know-how to enhance iWork's functionality in cognitive activity monitoring. The broader context partners include, C8Sciences (USA), Assistive Technology Resources (USA), Barrett Technologies Inc. (USA), and the Dallas Veteran Affairs Research Corp. (USA)."
"1830471","NRI:INT: Ad-Hoc Collaborative Human-Robot Swarms","IIS","National Robotics Initiative","09/01/2018","08/18/2018","Hadas Kress Gazit","NY","Cornell University","Standard Grant","James Donlon","08/31/2022","$1,490,568.00","Guy Hoffman, Kirstin Petersen","hadaskg@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","8013","063Z, 8086","$0.00","This project addresses the challenge of creating ad-hoc collaborative teams (swarms) of robots and people, where the people are not robotics experts and are interacting with the robots to accomplish an ad-hoc task such as emergency evacuation. The project investigates what the robots should look like, how they should behave, and how they should interact with people without prior experience with robots, to make sure the overall task is accomplished. The scientific insights of this project can apply to different tasks such as crowd control and large scale search missions. Here the research is grounded in a series of room and building evacuation scenarios where robots work autonomously, provide information and guidance, and respond to people's requests and behaviors. This project will impact three graduate classes taught by the researchers, will support undergraduate and masters projects and the results will be incorporated into activities targeted at increasing the participation of groups traditionally underrepresented in engineering.    <br/><br/>This project advances knowledge in three subfields of robotics and especially at their intersection; swarm design, autonomy, and human-swarm interaction. The challenge includes development of hardware platforms that can traverse and modify their environment and permit safe human-robot interaction, while remaining inexpensive, robust, and low maintenance. Specifically, this will involve blimps to facilitate and provide broad situational awareness by projecting images on the ground, and ground robots with inflatable, interactive bladders. For autonomy, this project considers a top-down approach where individual robot control is synthesized from a high-level task. In addition, algorithms will be developed that enable robots to automatically modify their behavior and provide intuitive feedback based on interactions with humans, the humans' behaviors, and the observed environments. This project will contribute to the field of Human-Robot Interaction by designing and evaluating distributed interactions where the role of the human fluidly changes between being a leader providing instructions to the robots, a cooperative swarm member guided by the robots, an uncooperative member who acts in opposition to the swarm guidance, and a passive member who needs to be physically assisted. Evaluating the human-swarm behavior using established metrics in a variety of increasingly complex environments will provide unique insights into the opportunities and challenges of creating ad-hoc human-robot swarms.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830497","NRI: FND: Probabilistic Hypothesis-Driven Adaptive Human-Robot Teams","IIS","National Robotics Initiative","09/01/2018","08/18/2018","Mark Campbell","NY","Cornell University","Standard Grant","James Donlon","08/31/2021","$663,869.00","","mc288@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","8013","063Z, 8086","$0.00","Teams of humans and robots working together have the potential to transform search and rescue operations, given the maturation of robotic technology and the ability to task each (human or robot) individually and collaboratively. Example applications include locating survivors or gas leaks after earthquakes or fires, where the safe access for first responders is limited, and locating a chemical/biological release in an urban environment. The disaster response example offers a broad motivational challenge, given the potentially hazardous situations for humans, trapped survivors, fast changing conditions, and communication uncertainties. The key challenge in developing truly efficient and high performing human-robot teams is enabling the team to intelligently reason and act together.  This research project will address this challenge by developing hypothesis-based methods to communicate between humans and robots to enable their collective perception about the environment, and to develop sub-teams and tasks to address the search problem as it evolves. Broader educational impacts include having undergraduate and high school students collaborate with the research team to perform experiments and data collection. Outcomes include open source algorithms and data logs for researchers in the community, and for robotics and controls classes; dissemination through publications, conferences, workshops and NRI meetings; and the inclusion of undergrad and high school students and diversity programs collaborating in the interdisciplinary area of human-robot teaming.<br/><br/>The goal of this research project is to develop foundational theory and validated algorithms for human-robot teams which can uniquely operate in, and adapt to, a complex and changing environment, particularly as knowledge of the environment/tasks evolves over time. The technical approach uses a probabilistic hypothesis formulation as a basis to formulate both the Process Inference and Team Forming problems. Formal modeling methods will connect human's natural language to hypotheses of the perception and teaming tasks, thereby allowing humans and robots to communicate efficiently and collaboratively. Hypotheses will be evaluated by the robots for information content using physical and data driven models to capture the processes and sensing. Importantly, both the inference and teaming will evolve as the complex processes evolve. The hypothesis-based approaches and team adaptation will be validated in a series of human-robot search experiments, and scaling will be validated via large scale simulations. The approach also enables the perception and planning to evolve as the scene evolves. This project aims to advance cooperative robot collaboration via human-robot information exchange; the scalability of cooperative robot teams where the team itself adapts over time as information is collected and knowledge is formed; and demonstrate the role for physical embodiment of intelligent systems as human-robot teams address complex applicable models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1823219","CRI: CI-P: Planning a Sustainable Infrastructure for the Robot Operating System","CNS","COMPUTING RES INFRASTRUCTURE","09/01/2018","08/18/2018","William Smart","OR","Oregon State University","Standard Grant","David Miller","02/29/2020","$100,000.00","","smartw@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7359","7359","$0.00","The Robot Operating System (ROS) is a large collection of open-source software for robotics that has, over the past decade, allowed more rapid progress in the field than was possible in the past.  The ROS software includes all of the low-level ""plumbing"" that roboticists used to write for themselves to make motors turn, to get data from their sensors, and to implement basic competences like moving around the world.  It supports a wide array of robot hardware, and is increasingly being used by companies across the country.  ROS is written and maintained by a large collection of volunteers from around the world and, like any large open-source project, has some management challenges.  Under this award, we will identify these challenges, and come up with concrete solutions for them, to ensure that ROS remains as useful over the coming decade as it was in the past.<br/><br/>This planning award will survey the ROS community to identify the areas of the ecosystem and management best practices that need improvement, with the goal of writing a Community Research Infrastructure proposal to implement these changes.  We will deploy on-line surveys to the community, and hold focused workshops at both the ROS Developers Conference and more general robotics conferences.  We will analyze the data from these surveys and workshops, alongside more concrete data from the existing infrastructure (wiki, Q&A site, etc) to determine what the most pressing community needs are, and then propose strategies to directly address them in a sustainable manner that continues to engage the community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830421","NRI: FND: Robust Inverse Learning for Human-Robot Collaboration","IIS","National Robotics Initiative","09/01/2018","08/18/2018","Prashant Doshi","GA","University of Georgia Research Foundation Inc","Standard Grant","James Donlon","08/31/2021","$644,182.00","Yi Hong, Kenneth Bogert","pdoshi@cs.uga.edu","310 East Campus Rd","ATHENS","GA","306021589","7065425939","CSE","8013","063Z, 8086","$0.00","Collaborative robots are robots that share with humans their work and personal spaces. These robots are expected to work with humans on a variety of tasks in various situations with few changes to their software and hardware. To do this, the robot must understand what is it that the human or other robot is doing, how is the human or robot performing the task, and then personalize its interaction. Currently, robots are programmed with much manual effort to perform specific tasks in controlled environments. This research is studying ways that will substantially advance a robot's capabilities in all these aspects, to enable a collaboration that is as automatic and seamless as possible. It is building methods, which allow the robot to observe the human or robot perform the task, understand the human's preferences and intent in the task, and then spontaneously collaborate with the human on the task. This approach relies on the insight that observing a human or robot perform the task provides information and facilitates learning the task. An application considered in this project is an agricultural robot that will observe and autonomously collaborate with a human in grading and packing onions in postharvest processing sheds. This has the potential to augment scarce human labor in our nation's farms in performing this repetitive task. <br/><br/>Inverse reinforcement learning (IRL) refers to both the problem and method by which an agent learns the goals and preferences of another agent that explain the latter's observed behavior. The technical approach to this research is first identifying the challenges that IRL is facing in its use toward inferring the goals and preferences of the observed agent, human or robot, in real-world contexts. The research is tractably generalizing IRL to meet key unmet challenges. It is developing new methods that will make IRL robust to real-world uncertainties involving hidden variables, occlusions, and imperfect observations by the robot. Typically, IRL is one sided and the reward is learned with the aim of imitating the observed behavior. This research will go a step further and investigate how the dynamics and learned preferences can be revised and incorporated in the robot's collaborative decision making and planning, to enable the robot to spontaneously collaborate with the previously observed agent on the task. Consequently, the focus is on domains where the subject robot can observe an agent performing well-defined tasks that benefit from teamwork. The research plan is expected to yield a portfolio of algorithms that take key steps toward enabling robots to autonomously learn how to perform tasks and deploy this knowledge toward optimally collaborating with others on the task. Being able to learn tasks simply from passive demonstrations provides greater appeal to this research as it minimizes costly human interventions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830686","NRI: FND: Life-Long Learning for Motion Planning by Robots in Human Populated Environments","IIS","National Robotics Initiative","09/01/2018","08/18/2018","Bradley Hayes","CO","University of Colorado at Boulder","Standard Grant","James Donlon","08/31/2021","$749,094.00","Christoffer Heckman","bradley.hayes@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","8013","063Z, 8086","$0.00","Long-term, safe interaction in human-populated environments is essential to the widespread adoption and continued deployment of robotics. Accordingly, an important aspect of behaving safely is the ability to use one's observations and past experiences to set realistic expectations about others' behaviors, operating in such a way that minimizes the risk of failure or causing harm. Just as humans are capable of adapting their behavior to changing circumstances and understanding possible failures, robots must similarly understand risks and adapt their behaviors to safely complete tasks in densely populated or dynamic environments. To enable these capabilities, this project will develop methods to provide mobile robots with the ability to build their own models of activity-based risk and human behaviors, using them to mitigate dangerous or risk-prone scenarios in the presence of uncertainty. These methods are broadly applicable across service robots, manufacturing robots, and close-quarters collaborative robots, enabling the effective and safe integration of such systems into human environments that have otherwise been inaccessible for enhancement or improvement through robotic automation. By contributing toward making such applications possible, results from this research will benefit the U.S. economy and society at large, while simultaneously contributing to the competitiveness of U.S. manufacturing on grounds of safety and efficiency through advanced and flexible automation. This work involves contributions from many complementary areas of research, including robotics, human factors, manufacturing, and computer science through both academic and industry collaborations. <br/><br/>To address challenges in safe, life-long learning as applied to long-term robot operation, this research focuses on the development of novel algorithms for self-supervised human-aware motion planning and context-aware trajectory optimization. Advancing the state-of-the-art in self-supervised learning through self-determined curriculum development and learning through experiences collected during live deployments, the work will additionally develop new transfer learning techniques to generalize experiences and behavioral models across contexts. Robots incorporating these research products will be able to learn to anticipate and mitigate risks and potential failure modes during task execution in uncertain environments by leveraging their own self-collected knowledge. This award targets fundamental advances in social navigation and task execution by integrating human motion modeling and robot motion planning with contextual understanding, achieving applicable and real-world grounded results through long-term mobile robot deployments in public spaces.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830366","NRI: INT: Customizing Semi-Autonomous Nursing Robots Using Human Expertise","IIS","National Robotics Initiative","09/01/2018","08/18/2018","Kris Hauser","NC","Duke University","Standard Grant","Wendy Nilsen","08/31/2021","$962,572.00","Ryan Shaw","kris.hauser@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","8013","063Z, 8086","$0.00","Remote-controlled robots have the potential to allow humans to perform useful tasks without putting themselves in danger, or without travelling long distances. This project explores how humans can control nursing robots that can communicate with patients, collect vital signs, and perform routine cleaning tasks in quarantine environments. The use of these robots has the potential to protect nurses from infection during disease outbreaks, and to protect patients with weakened immune system. A significant challenge in this effort is to make the user interface to the robot easy enough for nurses to use without significant training. Because engineers are not experts in nursing, the research will let nurses customize the user interface by teaching the robot about objects, places, and tasks that are typically used in nursing. After training, artificial intelligence algorithms will then automatically estimate which actions the nurse wants to perform, and these will be presented in a simple user interface that allows the nurse to select those actions quickly. <br/><br/>This project will continue an interdisciplinary collaboration between Duke's School of Engineering and School of Nursing. Research will be conducted in three thrust areas: 1) smart human operator interfaces for supervised autonomy that learn mappings between multimodal sensor input streams to provide simple, interpretable task options and status feedback; 2) hierarchical task learning algorithms for helping human experts train novel composite tasks; and 3) real world evaluation of human-robot system speed, reliability, operator workload, and operator learning curve using registered nurses and nursing students performing simulated clinical tasks in training environments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830242","NRI: FND: Communicating Physical Interactions","IIS","National Robotics Initiative","09/01/2018","08/17/2018","Michael Gleicher","WI","University of Wisconsin-Madison","Standard Grant","Reid Simmons","08/31/2021","$749,986.00","Michael Zinn, Bilge Mutlu","gleicher@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","8013","063Z, 8086","$0.00","For robots to become ubiquitous collaborators, they must interact physically with objects in unstructured human environments. Robots must adeptly grasp, push, squeeze, snap, balance, stabilize and hand-off objects, and must effectively communicate about these actions with their human collaborators. People must not only be able to specify to a robot what to do and how to do it, they must also be able to interpret what a robot intends to do (and how).  Effective communication about physical interactions will be essential if robots are going to perform such tasks as delivering care to older adults, responsively helping technicians in performing repairs, or being trained by non-experts to perform repetitive assembly tasks.  This project will enable a new generation of robot applications, and advance the vision of ubiquitous, collaborative robots by developing better methods for robots to more effectively communicate with people. <br/><br/>The project will address key challenges in communication about physical interactions: conveying invisible and unfamiliar quantities (e.g., forces and compliances), communicating plans and contingencies, and communicating about what did not (or should not) happen.  The project will involve three key challenges: specification, interpretation, and monitoring.  To address these challenges, the project will 1) perform formative studies to gain insight into how people communicate about physical interactions and interpret displays; 2) develop methods for specifying physical actions based on the idea of augmented demonstrations, methods for interpreting physical actions based on the idea of interpretable representations, and methods for monitoring physical actions based on multimodal communication; and 3) deploy these ideas in prototype systems for contextualized scenarios for evaluation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1848912","I-Corps: Wheelchair Mounted Robotic Assistive Arm","IIP","I-Corps","09/15/2018","08/16/2018","Mohammad Rahman","WI","University of Wisconsin-Milwaukee","Standard Grant","Cindy WalkerPeach","02/28/2019","$50,000.00","","rahmanmh@uwm.edu","P O BOX 340","Milwaukee","WI","532010340","4142294853","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project is to identify the customer needs and develop a minimum viable robotic assistive device that will enable disabled individuals to care for themselves, improve their mobility, independence and quality of life while reducing the burden on their families and communities. There is opportunity for launching a homecare equipment market through the adaptive sports clubs and the clinical facilities. The elderly and disabled assistive devices global market was valued at $14 billion in 2015 and is expected to surpass $26 billion by 2024. The outcome of the project will further help researchers, educators, and clinicians to discover new approaches/technology to satisfy unmet needs of customers. This I-Corps project will provide hands on training and experience for an engineering undergraduate student (co-entrepreneurial lead) and graduate student (entrepreneurial lead) on the customer discovery process. The PI will also gain exposure to the customer discovery process, and will incorporate the learnings from this course in ongoing and future projects within his research lab and engineering senior design classes. The project activities are intimately linked to educational activities that will teach students at various levels about the customer discovery process, entrepreneurship, hypothesis testing, etc. <br/><br/>This I-Corps project will advance understanding of the problems and needs of disabled individuals with upper/lower extremity impairments from different conditions. The intellectual merit of the project lies in the development of a sustainable business model canvas around the proposed technology and in the novel design and development of the proposed robotic assistive arm (R2A). The R2A that we envision is a 7 degrees of freedom anthropomorphic robotic hand that can be mounted on a wheelchair or any mobile platform. It can be controlled either by hand/foot/mouth control depending on the patient?s needs. This will allow the patient, regardless of the disability, to control the robot. The fundamental research conducted so far includes development of an upper-extremity robotic exoskeleton to provide arm movement therapy. This I-Corps project will find the gaps between the customer unmet needs and the approaches/technology currently being used to satisfy their needs. The project activities will unite different customers? problems, needs, and existing solutions; and form a symbiotic relationship to overcome the critical barrier to advancing the field of assistive robotics. Overall, the proposed project will significantly advance the knowledge of how robotic devices can meaningfully and effectively be used in caregiving and rehabilitation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1831161","SBIR Phase II: Orchestration of Multiple Robotic Subsystems into a Commercially Viable Robotic Strawberry Harvesting System","IIP","SMALL BUSINESS PHASE II","08/15/2018","08/16/2018","Robert Pitzer","FL","Harvest CROO, LLC","Standard Grant","Muralidharan S. Nair","07/31/2020","$749,720.00","","bob@harvestcroorobotics.com","100 Stearns St.","Plant City","FL","335635045","8133447855","ENG","5373","5373, 6840, 8034, 8035","$0.00","The broader impact/commercial potential of this project includes development of berry post-picking screening and handling that will provide a safe and efficient way to remove contaminated berries from the processing stream of an automated harvester. The project will advance machine vision technology for robotic harvesting and will be a key enabling technology leading to acceptance of automated harvesting as safe and effective. The market sector addressed by this project is strawberry farmers, though the technology will be applicable to other types of fruit and vegetable farming as well. The automated harvesting technology advanced by this project will alleviate chronic and worsening labor shortages faced by strawberry farmers and will ensure that strawberries remain affordable and available to consumers. Filling the need created by farming labor shortages is a $1 billion business opportunity.<br/><br/>This Small Business Innovation Research (SBIR) Phase II project will develop new vision processing and inspection methods vital to enabling use of an automated, robotic strawberry harvester. Acceptance of automated harvesting technology by strawberry farmers hinges on the ability of the harvester to remove bad berries from the plant without allowing the undesirable berries from entering the harvester packaging stream and potentially contaminating large quantities of berries. To achieve this, it will be necessary for the harvester to identify and eliminate diseased, rotten, damaged, or infested berries at multiple stages in the stream from automated picking to final packaging. The classification method that identifies the berries to be eliminated will be extremely accurate, with a very high detection rate and a low false alarm rate. The methods developed will be suitable for installation on a farming machine that is subject to a harsh outdoor environment as well as the shock and vibration environment found on a robotic harvesting device. New handling processes will be developed that will allow automated inspection of the entire berry without damaging the fruit or creating a risk of cross contamination from infected berries, significantly advancing the state of the art for automated strawberry processing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830460","NRI: INT: COLLAB: Anthropomorphic Robotic Ankle Prosthesis with Programmable Materials","IIS","National Robotics Initiative","09/01/2018","08/17/2018","Mo Rastgaar","MI","Michigan Technological University","Standard Grant","Wendy Nilsen","08/31/2022","$680,182.00","Kenton Kaufman","rastgaar@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","CSE","8013","063Z, 8086","$0.00","There are currently 2 million Americans living with an amputation; the majority of those amputations are of the lower limbs. Leg amputation is a significant life-altering event that has an overwhelmingly negative effect on many aspects of life, even years after the injury. Leg amputation can cost in excess of $1.8 million per individual. Most available prostheses are designed to replicate some aspects of normal ankle function during level-ground walking. These prostheses allow many individuals with below-knee amputation to return to basic daily activities. However, these devices are best suited for level-ground walking and many users experience difficulties during other important tasks, such as walking on slopes, stairs, or different terrains. Therefore, the general aim of this project is to address this gap in the design of existing powered ankle-foot prostheses by enabling new prosthetics that adapt to different environmental conditions commonly found in daily life. The proposed ankle-foot mechanism significantly enhances the customizability of lower leg-powered prostheses by introducing a new design approach. This project will study how the human ankle stiffness changes during different walking scenarios. The research team will use this information to design a powered ankle-foot prosthesis with properties more similar to the human ankle. In order to do so, a lightweight and modular prosthesis that uses programmable material will be developed. The modular mechanical design and control approach generates human-like characteristics and enables a larger set of users with different lengths of amputated legs to use this prosthesis. Moreover, the prosthesis' performance will be evaluated during real-world activities in dynamic environments. The focus of this project is on amputees' well-being. The resulting agile ankle foot prosthesis will help amputees improve their physical function, ability to work, and recreation, thus helping individuals return to the activities and quality of life they had prior to injury. The research findings from this project can also be applied to advance functions of exoskeletons, orthotics, and rehabilitation robots. In addition to advancing research, undergraduate and graduate students will be involved in research activities and will receive interdisciplinary education/innovation/outreach experiences. Outreach activities will allow the project team to engage diverse middle and high school students in science and engineering, especially those from underrepresented groups and low-income families. <br/><br/>This project plans a new class of customizable agile ankle-foot prosthesis that is modular in design and has its impedance modulation decoupled from its torque control. This will be achieved by equipping a novel and recently developed powered 2-degrees of freedom (DOF) ankle-foot prosthesis with an augmented mechanism built from soft programmable material. The primary outcomes of this project will be a comprehensive understanding of how to 1) reduce the complexity of the control of ankle-foot prostheses, as observed in clinical trials, and 2) enhance prosthesis performance in real-world activities, such as walking and running on surfaces with different profiles, stiffness, and lateral inclinations. The planned work aims to address customizability issues of robotic ankle foot prostheses and address societal impact by improving amputees' quality of life and work. The main goal of this study is to consolidate the impedance control of the ankle to a mechanical module comprised of programmable material to follow the 2-D human ankle impedance. The effort will further integrate the impedance modulation with 2-DOF torque control of the ankle to provide the customizability required for tailoring an agile prosthesis to each user's need in parallel to the torque control tuning. The project researchers hypothesize that real-time control of the two-dimensional ankle impedance in a robotic ankle-foot prosthesis can improve the performance and the agility of the user during walking on surfaces with different profiles, stiffness, and inclinations. The interconnected research thrusts will provide the opportunity to offer a new solution through 1) modeling the ankle dynamics in different gait scenarios, 2) equipping a 2-DOF robotic ankle-foot prosthesis with a programmable material module, and 3) performing extensive evaluation experiments with amputees. Understanding the effect of the control and adaptation of the 2-D ankle impedance during walking with a lower extremity prosthesis will be significantly beneficial for the field of assistive robotics because it can provide guidelines for the design and control of powered prostheses, exoskeletons, and rehabilitation devices. In addition to advancing research, undergraduate and graduate students will be involved in research activities and will receive interdisciplinary education/innovation/outreach experiences. Outreach activities will allow the project team to engage diverse middle and high school students, especially those from underrepresented groups and low-income families. The findings from this project will be disseminated through publications, software sharing, and technology commercialization.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1700468","Robotics Awake: Promoting the Diffusion of Innovation through Curriculum Development and a Technician Training Community College Extension Model","DUE","ADVANCED TECH EDUCATION PROG","07/01/2017","07/03/2017","Michael Moore","NC","Wake Technical Community College","Standard Grant","Heather Watson","06/30/2020","$575,277.00","James Reaves","memoore1@waketech.edu","9101 Fayetteville Road","Raleigh","NC","276035655","9193351200","EHR","7412","1032, 9178, SMET","$0.00","Wake Technical Community College (Wake Tech) will collaborate with industry partners to develop curricula for training technicians in the operation, utilization, and programming of light industrial robots in advanced manufacturing applications.  This model enables the use of technician training as a basis for community college extension work to promote the diffusion of innovations likely to contribute to regional economic development. The project will impact the region through modernization and improved competitiveness of local manufacturers as well as by recruiting diverse students to learn advanced manufacturing skills.  The overarching goals of this ATE project will be achieved by: (a) building collaborations with industry partners, (b) developing and disseminating robotics education in advanced manufacturing curricula, (c) improving student learning, performance and industrial skill acquisition, and (d) developing a model for industrial extension through technician education. To achieve the goals of this project, Wake Tech will leverage relationships with over 70 local manufacturing companies, North Carolina State University, North Carolina Works, and employment agencies.  This program is designed to recruit and serve 120 students over the three year duration of the project. <br/><br/>Project activities include (a) the creation of an industry partnership group focused on integration of co-robots in local manufacturing plants, (b) professional development for faculty from Wake Tech and three neighboring community colleges, (c) developing industrial extension partnerships, (d) development and implementation of two courses and certificates, (d) establishing equipment to support hands-on curricula, (e) recruiting diverse students though outreach efforts, and (f) developing and evaluating a model for future community college extension work. The project team and independent evaluator will conduct a case study of Wake Tech's role as a knowledge hub in the diffusion of the innovation of technician education in light industrial robots. This project will produce broader impacts through new curricula for students and collaboration with regional industry. The project will provide local and regional benefits by assisting local small to mid-size manufacturing businesses in increasing productivity and competitiveness with multiplier effects in the surrounding communities and nearby community colleges."
"1556058","SBIR Phase II:  Robotic System for the Sorting of Recyclable Waste","IIP","SMALL BUSINESS PHASE II","04/15/2016","08/17/2018","Matanya Horowitz","CO","Cognitive Robotics","Standard Grant","Muralidharan S. Nair","09/30/2020","$1,410,690.00","","mhorowit@caltech.edu","17795 W 59th Dr","Golden","CO","804031103","7204700812","ENG","5373","116E, 165E, 169E, 5373, 6840, 8035, 8240, 9139, 9231, 9251, HPCC","$0.00","The broader impact/commercial potential of this project will be to change the fundamental economics of the recycling process. Although it is estimated that up to 95% of the waste stream could be recycled, only a third of the 250 million tons of municipal solid waste that are generated each year in the United States is currently diverted. Greater diversion would provide immense savings in landfill and processing costs, and benefit the environment as well. Tens of millions of pounds of greenhouse gas emissions from virgin material mining may be eliminated, and pollution from landfill waste reduced. The existing sorting process is expensive and unprofitable, requiring human workers to manually sort debris, an extremely dull, dirty, and dangerous profession. This innovation has the potential to eliminate these trade-offs between cost and environmental damage. <br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project will create a scalable, integrated robotic system that autonomously sorts material for recycling. This advance in autonomous systems is made possible by a series of innovations in robotics: (1) tremendous improvements in both computer vision and robotic manipulation, allowing for the system to be deployed with virtually zero retrofitting in existing facilities; (2) new motion planning techniques that allow for trajectories to be generated in real time, customized for the characteristics of the waste, safety, and any uncertainty in individual objects? position;&#8232; and (3) modern machine learning techniques that allow the system to classify waste at levels approaching human performance, with a continual training signal obtained via human supervision. These innovations pave the way for a new era in recycling, where waste is sorted cheaply, safely, and reliably on a universal scale."
"1524544","NRI: Robotic Tool-Use for Cleaning","IIS","National Robotics Initiative","09/01/2015","07/16/2015","Maya Cakmak","WA","University of Washington","Standard Grant","Tatiana D. Korelsky","08/31/2019","$400,063.00","","mcakmak@cs.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","8013","8086","$0.00","Cleaning is as one of the most desired capabilities for personal robots, according to reported surveys and interviews conducted with potential users. However, successful solutions to robotic cleaning have so far been special-purpose robots designed for particular cleaning tasks, as with the vacuuming or mopping robots. Instead, this project aims to make general-purpose mobile manipulators perform a much wider range of cleaning tasks, including dusting, wiping, scrubbing, sweeping, or mopping, by enabling them to use human tools.  Cleaning is a key activity of daily living and an important task in the maintenance of one's quality of life. Many older adults lose their independence when they can no longer carry out cleaning tasks. Similarly, many mobility-impaired individuals rely on others for cleaning. Robots taking on these tasks could therefore positively impact millions of individuals. General-purpose cleaning robots could also have significant economic impact, similar to those of special-purpose ones like the Roomba. Cleanliness is critical in many commercial facilities, such as hotels or department stores, which involve large surfaces that need to be regularly cleaned in specific ways that programmable cleaning robots developed in this project could handle.<br/><br/>General-purpose cleaning robots need to be able to use many different cleaning tools, in many different environments, based on many different user preferences. The diversity of possible situations makes it difficult to develop universal controllers or planners for arbitrary cleaning tasks. Furthermore, it is impossible to know the users' preferences in advance. To address these challenges, this project develops a Learning from Demonstration (LfD) technique that allows a robot to learn cleaning actions from human demonstrations. This technique exploits the common structure of cleaning tasks: they all involve moving a cleaning tool relative to a target surface with a certain pattern while applying a certain force on the surface. Although many LfD approaches already exist, none of them allow learning cleaning actions that generalize to arbitrary surfaces with arbitrary cleaning patterns. This project contributes new representations and learning algorithms that enables a mobile manipulator to clean surfaces of arbitrary size, shape, curvature, dirt distribution, and clutter, using different types of cleaning tools. The methods developed in the project are evaluated with real cleaning tasks through systematic experiments and user studies in the lab, as well as, in the real world through an identical robot deployed in a private home."
"1837662","EAGER: Modeling the Interaction Physics between Soft-structures and Granular Materials","CMMI","Dynamics, Control and System D","08/15/2018","08/16/2018","Nicholas Gravish","CA","University of California-San Diego","Standard Grant","Irina Dolinskaya","07/31/2019","$124,622.00","Michael Tolley","ngravish@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","ENG","7569","030E, 034E, 7916, 8024","$0.00","This EArly-concept Grant for Exploratory Research (EAGER) project explores the interaction between soft robots and commonly occurring granular media, like sand, soil, or gravel. Soft robots constructed from compliant materials like rubber or cloth are much safer than rigid robots for use with and around people. Soft robots are also remarkable for their ability to use intrinsic structural compliance to passively adapt to unknown and unexpected obstacles and terrain. Yet analyzing the movements of a robot that makes intermittent contact with the ground is difficult even for rigid robots moving on hard surfaces, and much more so when both the robot structure and the terrain may deform in poorly understood ways. Thus, in order to fully realize the potential of soft robots operating reliably and predictably in unknown natural terrain, it is critical to construct a systematic framework for modeling the forces and movements of soft structures moving in or on granular media. This EAGER project creates such a framework in two parts. First is a sequence of tests that measure the forces and deformations associated with a set of standard objects moving in pre-defined patterns through a granular medium. Next, mathematical models are used to capture the essential features of the interaction, which may then be extended to more general motions and geometries. Soft robotics is rapidly emerging as a new field, with the potential to transform applications such as health care, search and rescue, scientific exploration, and orthotics and prosthetics, much as rigid robots revolutionized manufacturing. The results of this project will help advance the national prosperity and welfare, and secure the national defense, for example, by enabling the creation of soft robots that can move reliably through uncertain terrain for search-and-rescue, exploration, environmental monitoring, or construction. The project also supports providing a research experience to undergraduate students through the UC San Diego Summer Training Academy for research Success (STARS) program.<br/><br/>The primary goals of this project are to, 1) develop an experimental system to study the forces and deformation of soft intruders in laboratory granular materials, and 2) develop discrete element method (DEM) and resistive force theory (RFT) models of the interaction between granular material and soft robot appendages. Locomotion of mobile robots is challenged by complex, natural substrates such as sand, leaf-litter, brush, and slopes. Effective movement and control of mobile robots over real-world environments requires study of the failure modes of a model natural substrate granular material. A recent study demonstrated that empirically verified granular models can be used to design and control legged robots for effective locomotion on unstructured terrain. However, this approach has only been demonstrated for rigid intruders. Robots with soft bodies and appendages present new opportunities for robot functionality, including resilience, passive adaptation, and safe interaction. Mobile soft robots have the potential to control the local interactions between complex substrates and soft appendages, and to enable sensing and feedback control of foot stiffness and shape when moving across complex substrates. However, this potential will not be realized without accurate models of the interactions between soft robot appendages and complex, natural substrates. The overarching goal of this one-year project is to enable predictive understanding of how soft intruders interact with granular material to inform soft robot design and control in future applications. These efforts will enable the design and control of future soft robots. Additionally, this work will be of interest to scientists and engineers interested in the flow and failure of granular materials.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1427345","NRI: Considerate Co-robot Intelligence through Ubiquitous Human State Awareness","IIS","National Robotics Initiative","09/01/2014","06/20/2016","Weihua Sheng","OK","Oklahoma State University","Continuing grant","Reid Simmons","05/31/2019","$725,000.00","Guoliang Fan","weihua.sheng@okstate.edu","101 WHITEHURST HALL","Stillwater","OK","740781011","4057449995","CSE","8013","8086, 9150","$0.00","This project develops a new type of social intelligence for robot companions in assisted living environments.  This new intelligence allows a robot to learn a person's daily activity and location without constantly following him or her.  Such a human-aware capability frees the robot to do its daily routine work, while being able to attend the human more proactively and effectively.  A large population can benefit from the outcome of this project, especially the elderly and patients who need assistance and companionship in their homes.  In addition, people in their work places can also benefit from this project, since robot co-workers can provide routine service and emergency assistance with such human-awareness.  The proposed educational activities will raise more awareness of robot research through curriculum enrichments in a series of undergraduate and graduate courses.  Through the outreach activities, it will stimulate prospective and current college students to pursue degrees and careers in science and engineering. <br/><br/>The objective of this project is to develop the new theoretical/algorithmic framework and the open hardware/software platform for this type of considerate co-robot intelligence.  The proposed method is based on ubiquitous human awareness-a robot capability of knowing a person's activity and location in an indoor environment without using onboard sensors. This capability is realized through wearable sensing and computing from a human-based perspective. The major research efforts consist of four parts: co-robot 3D semantic mapping; human activity and location inference; activity prediction and behavioral anomaly detection; experimental evaluation using open hardware/software platforms. A case study will be conducted to evaluate the effectiveness of the proposed considerate co-robot intelligence in elderly fall prevention, detection and intervention."
"1830256","NRI: INT: COLLAB: Anthropomorphic Robotic Ankle Prosthesis with Programmable Materials","IIS","National Robotics Initiative","09/01/2018","08/17/2018","Panagiotis Polygerinos","AZ","Arizona State University","Standard Grant","Wendy Nilsen","08/31/2022","$800,000.00","Panagiotis Artemiadis","Polygerinos@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","8013","063Z, 8086","$0.00","There are currently 2 million Americans living with an amputation; the majority of those amputations are of the lower limbs. Leg amputation is a significant life-altering event that has an overwhelmingly negative effect on many aspects of life, even years after the injury. Leg amputation can cost in excess of $1.8 million per individual. Most available prostheses are designed to replicate some aspects of normal ankle function during level-ground walking. These prostheses allow many individuals with below-knee amputation to return to basic daily activities. However, these devices are best suited for level-ground walking and many users experience difficulties during other important tasks, such as walking on slopes, stairs, or different terrains. Therefore, the general aim of this project is to address this gap in the design of existing powered ankle-foot prostheses by enabling new prosthetics that adapt to different environmental conditions commonly found in daily life. The proposed ankle-foot mechanism significantly enhances the customizability of lower leg-powered prostheses by introducing a new design approach. This project will study how the human ankle stiffness changes during different walking scenarios. The research team will use this information to design a powered ankle-foot prosthesis with properties more similar to the human ankle. In order to do so, a lightweight and modular prosthesis that uses programmable material will be developed. The modular mechanical design and control approach generates human-like characteristics and enables a larger set of users with different lengths of amputated legs to use this prosthesis. Moreover, the prosthesis' performance will be evaluated during real-world activities in dynamic environments. The focus of this project is on amputees' well-being. The resulting agile ankle foot prosthesis will help amputees improve their physical function, ability to work, and recreation, thus helping individuals return to the activities and quality of life they had prior to injury. The research findings from this project can also be applied to advance functions of exoskeletons, orthotics, and rehabilitation robots. In addition to advancing research, undergraduate and graduate students will be involved in research activities and will receive interdisciplinary education/innovation/outreach experiences. Outreach activities will allow the project team to engage diverse middle and high school students in science and engineering, especially those from underrepresented groups and low-income families. <br/><br/>This project plans a new class of customizable agile ankle-foot prosthesis that is modular in design and has its impedance modulation decoupled from its torque control. This will be achieved by equipping a novel and recently developed powered 2-degrees of freedom (DOF) ankle-foot prosthesis with an augmented mechanism built from soft programmable material. The primary outcomes of this project will be a comprehensive understanding of how to 1) reduce the complexity of the control of ankle-foot prostheses, as observed in clinical trials, and 2) enhance prosthesis performance in real-world activities, such as walking and running on surfaces with different profiles, stiffness, and lateral inclinations. The planned work aims to address customizability issues of robotic ankle foot prostheses and address societal impact by improving amputees' quality of life and work. The main goal of this study is to consolidate the impedance control of the ankle to a mechanical module comprised of programmable material to follow the 2-D human ankle impedance. The effort will further integrate the impedance modulation with 2-DOF torque control of the ankle to provide the customizability required for tailoring an agile prosthesis to each user's need in parallel to the torque control tuning. The project researchers hypothesize that real-time control of the two-dimensional ankle impedance in a robotic ankle-foot prosthesis can improve the performance and the agility of the user during walking on surfaces with different profiles, stiffness, and inclinations. The interconnected research thrusts will provide the opportunity to offer a new solution through 1) modeling the ankle dynamics in different gait scenarios, 2) equipping a 2-DOF robotic ankle-foot prosthesis with a programmable material module, and 3) performing extensive evaluation experiments with amputees. Understanding the effect of the control and adaptation of the 2-D ankle impedance during walking with a lower extremity prosthesis will be significantly beneficial for the field of assistive robotics because it can provide guidelines for the design and control of powered prostheses, exoskeletons, and rehabilitation devices. In addition to advancing research, undergraduate and graduate students will be involved in research activities and will receive interdisciplinary education/innovation/outreach experiences. Outreach activities will allow the project team to engage diverse middle and high school students, especially those from underrepresented groups and low-income families. The findings from this project will be disseminated through publications, software sharing, and technology commercialization.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1328805","NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","IIS","National Robotics Initiative","10/01/2013","05/26/2017","R. Vijay Kumar","PA","University of Pennsylvania","Standard Grant","Jie Yang","09/30/2019","$708,000.00","Daniel Lee, Katherine Kuchenbecker","Kumar@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","8013","7298, 7925, 8086, 9251","$0.00","Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation.  The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br/><br/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM."
"1662641","Collaborative Research: Processing and Performance of Chained Magnetic Particle Composites for Soft Robotics","CMMI","Materials Eng. & Processing","04/01/2017","03/16/2017","Benjamin Evans","NC","Elon University","Standard Grant","Mary M. Toney","03/31/2020","$108,182.00","","bevans7@elon.edu","2620 Campus Box","Elon","NC","272449423","3362786603","ENG","8092","085E, 7237, 8021, 8025, 8037","$0.00","Soft robotics is a rapidly growing field in which soft materials, such as polymers, are formed into devices whose mechanical response can be triggered by physical or chemical stimuli. Magnetically responsive polymer composites containing embedded magnetic particles are especially attractive for soft robotics, because they allow for non-contact actuation with electromagnets or permanent magnets. Furthermore, chaining the magnetic particles within the polymer imparts an enhanced, directional response. This award supports fundamental experimental and theoretical research to investigate the processing and performance of chained magnetic particle composites for soft robotics. Soft robotic devices based on chained magnetic particle composites developed in this research will be immediately useful in practical applications, including non-contact peristaltic pumps and remotely actuated microfluidic valves and mixers for next-generation medical diagnostic devices. Theoretical tools developed in this research will also drive innovation by providing easily accessible metrics to inform the design and evaluate the performance of chained magnetic particle actuators. Themes and results from this research will be integrated into education and outreach activities designed to inspire and recruit the next generation of scientists and engineers.<br/><br/>While there have been many reports of magnetoactive elastomers for soft robotics, the design of these materials is usually empirical rather than guided by a predictive model, resulting in missed opportunities to optimize their design and performance, such as with chained-particle formulations. This research aims to develop a framework and figures of merit for predicting the behavior of magnetoactive elastomer actuators and to employ them for designing useful devices with enhanced capabilities. Using these tools, the torque in chained-particle magnetoactive elastomers generated in applied magnetic fields will be maximized, elasticity of the polymer and elastic instabilities will be incorporated in device function, and shape memory polymers will enable realization of magnetoactive elastomer materials and devices that are reconfigurable and selectively addressable. This research will advance the field of chained-particle magnetoactive elastomers by developing tools to guide their design for applications in soft robotics and by demonstrating the capabilities of these materials and devices."
"1427050","NRI: Collaborative Research: Efficient Algorithms for Contact-Aware State Estimation","IIS","National Robotics Initiative","08/15/2014","08/11/2014","Russell Tedrake","MA","Massachusetts Institute of Technology","Standard Grant","Jie Yang","07/31/2019","$874,928.00","Alberto Rodriguez Garcia","russt@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","8013","8086","$0.00","This project addresses the difficult theoretical, computational, and applied challenges required to exploit a deep mathematical relationship between recent advances in machine perception/estimation algorithms and recent advances in algorithms for planning/controlling systems undergoing frictional contact.  It explores the immediate applications of these algorithms to perception, robotic object manipulation and parts assembly, and humanoid robots performing complex, multi-contact, whole-body maneuvers. In order to showcase the generality of approach, and simultaneously reach out to the important under-represented minority population, the research team employs a new hands-on short-course curriculum in which students apply the proposed algorithms to predict the outcome of games using visual tracking. The course is being developed in partnership with the MIT Office of Minority Education (OME).<br/><br/>The project brings together expertise in simultaneous localization and mapping (SLAM), robot manipulation, robotic automation, legged robots, and optimization and nonlinear control, leading to a cross-fertilization of ideas and techniques.  The research team exploits sparsity in the complementarity formulations of contact in Lagrangian dynamics.  The project explores a new algebraic approach to nonlinear estimator design. The project produces new theorems, new algorithms, and experimental results on real robots.  The project also represents a new partnership with our industrial collaborator, ABB Robotics. The developed algorithms facilitate a broad range of new applications in which perception and control systems monitor and manipulate physical interactions with the world.  From palm-sized smart devices to environmental monitoring, sensors are becoming ubiquitous; to reach their full potential these sensor networks must be able to reason about contact - the basic building block of physical interaction."
"1842642","Workshops for the Future of Mechatronic and Robotic Education","EEC","ENGINEERING EDUCATION","08/15/2018","08/15/2018","Nima Lotfi Yagin","IL","Southern Illinois University at Edwardsville","Standard Grant","Julie Martin","07/31/2019","$49,957.00","Michael Gennert, James Mynderse, Vikram Kapila","nlotfiy@siue.edu","Campus Box 1046","Edwardsville","IL","620250001","6186503010","ENG","1340","110E, 1340, 7556","$0.00","Mechatronics and Robotics Engineering is a new engineering discipline that is experiencing tremendous, dynamic growth. Mechatronics and Robotics Engineering professionals are shaping the world by designing smart and autonomous systems and processes that will improve human life and welfare. This requires an interdisciplinary knowledge of mechanical, electrical, computer, software, and systems engineering to oversee the entire design and development process. There have been many educational efforts around Mechatronics and Robotics Engineering in higher education such as courses, minors, and degree programs, but they have not been well integrated or widely adopted. The educators in this nascent community continue to re-invent content modules, courses, and curricula instead of adopting and improving existing content. With the rapid increase in demand for robotics and automation engineers, now is the time for Mechatronics and Robotics Engineering to coalesce as a distinct and identifiable engineering discipline. This project consists of a series workshops on the future of Mechatronics and Robotics Engineering education at the bachelor's degree and postgraduate levels. <br/><br/>The workshop series serve to solidify the emerging community of current and future educators, promote diversity and inclusivity within the community, gather community input, and identify thought leaders for future community activities. Participants will include a wide range of educators teaching courses such as mechatronics, robotics, dynamics, controls. PhD students seeking academic careers in mechatronics and robotics, and industry professionals desiring to shape the future workforce. As a result of these workshops, the will begin standardization of educational components such as frameworks, curricula, course outlines, experiments, and assignments. Furthermore, the workshops will be stepping stones towards building a diverse and inclusive community of educators and professionals from a broad range of colleges, universities, and industries with the ultimate goal of shaping the future of Mechatronics and Robotics Engineering Education and increasing its widespread adoption.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1848653","EAGER: CNS: Misdirection in Robot Teams: Exploiting Organizational Principles for Operational Advantage","IIS","National Robotics Initiative","10/01/2018","08/15/2018","Ronald Arkin","GA","Georgia Tech Research Corporation","Standard Grant","Ralph Wachter","03/31/2020","$271,867.00","","arkin@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","063Z, 7916, 8086","$0.00","Trust, dependability, cohesion, and capability are integral to an effective team.  These attributes are the same for teams of collaborating robots and humans as well as all-robot teams.  For a team to remain effective in the presence of faults, failures, and errors from nature or intent, team members must have sufficient perception and understanding of the problem and possible solutions to make appropriate adjustments in their operations.  When multiple teams with competing incentives are tasked, a strategy, if available, may be to weaken, influence or sway the attributes of other teams and limit their understanding of their full range of options.  Such strategies are widely found, for example, in nature, sporting contests, and military operations, where strategies such as feints and misdirection often appear.  This project focuses on one class of higher-level strategies for multi-robots: namely, to misdirect and where feasible to counter misdirection.  As multi-robot systems become more autonomous, distributed, networked, numerous, and with more capability to make critical decisions, the prospect for intentional and unintentional misdirection must be anticipated.  This project will support robust multi-robotic operations in important strategic domains such as security and military operations.<br/> <br/>The project studies strategies to enable co-robots, multi-robots and teams of multi-robots to model, generate, and cope with misdirection in various situations.  This research direction in robotic control offers a novel approach to resilience in and among these teams to these forms of possible disruption. Computational models, drawn particularly from studies of human endeavors and group behaviors, provide a general framework for understanding, producing, and countering misdirection in robotic systems. A framework of computational models will be designed using recursive schema-theoretic models of behaviors at the individual and team levels, building on decentralized methods of control and communication, to provide robustness in the presence of noisy and chaotic environments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1849417","NRI: FND: Scalable, Customizable Sensory Solutions for Dexterous Robotic Hands","IIS","National Robotics Initiative","09/01/2018","08/15/2018","Nitish Thakor","MD","Johns Hopkins University","Standard Grant","Reid Simmons","08/31/2021","$421,727.00","Rahul Kaliki","nthakor@bme.jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","8013","063Z, 8086","$0.00","This project aims to enhance the sense of touch for robotic hands. The main goal is to develop prosthetic hands with a sense of touch. The touch sensor's primary application is for upper limb amputees. The research team plans both fundamental research and its application. The types of applications of this kind of sensor include: humanoid robots for assistive work and elder-care, surgical robotics, underwater robotic manipulators and spacesuits. Additionally, educational initiatives including internships, training of under-represented minority, and research experiences and summer modules for high school students are planned through the Johns Hopkins Center for Talented Youth. <br/><br/>The technical goal of the project is to build a highly scalable sensor design mimicking different tactile receptors in human skins and encode information from the sensors in a manner analogous to the neural activity of the tactile receptors. The sensor will encode the tactile information at multiple scales, firstly based on different receptor properties, and secondly based on neuron-like encoding of the sensor signals. This technique of encoding the neural activity, known as neuromorphic encoding, converts the sensor activity as an event stream, and from that data obtains finer features. The receptor based sensing along with the various neural network algorithms, for the first time, will provide an approach to texture and shape recognition and, as such, can also be useful for intelligent palpation and tactile perception by dexterous robotic hands.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1823736","I-Corps: A Design Driven Educational Robotics Framework","IIP","I-Corps","04/01/2018","03/07/2018","Anurag Purwar","NY","SUNY at Stony Brook","Standard Grant","Cindy WalkerPeach","09/30/2019","$50,000.00","","anurag.purwar@stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project is in providing a design-driven robotics framework encompassing a low-cost, modular robot hardware kit, a software app for motion design, and a web-based Computer-Aided Design (CAD) environment to enable students, makers, hobbyists, and industry practitioners to innovate and invent robots and machines. The framework brings together computational thinking, design process, and programming to meet STEM imperatives and provide compelling value propositions for both the education and prototyping industry. The proposed robotics framework has the potential to fill 2.5 million unfilled jobs in STEM and positively impact the U.S. educational robotics market, which is expected to grow to $2.7 billion by 2021.<br/><br/>This I-Corps project leverages the latest research in mechanism synthesis area to create novel algorithms for designing motions of planar linkage mechanisms. Planar linkage mechanisms are rigid bodies connected to one another using rotating or sliding joints and their special configurations give rise to desired motion. Their implementation in a mobile app provides users an ability to synthesize and simulate mechanisms for robots and machines. While, the robot hardware kit employs inexpensively produced novel planar and compliant pieces to create a new method of interconnection to realize three-dimensional geometry and mechanisms of robots and structures, the web-based CAD tool would allow users to design customized robot parts. The flexibility of the design allows for the use of any programming platform and any readily available sensors and actuators thereby dramatically broadening the inventions design capabilities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1638007","NRI: Goal-Oriented, subject-Adaptive, robot-assisted Locomotor Learning (GOALL)","CBET","SPECIAL INITIATIVES, Disability & Rehab Engineering, National Robotics Initiative","09/01/2016","06/21/2018","Fabrizio Sergi","DE","University of Delaware","Standard Grant","Christina Payne","08/31/2019","$587,903.00","Jill Higginson","fabs@udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","ENG","1642, 5342, 8013","8086, 9150, 9251","$0.00","1638007<br/>Sergi, Fabrizio<br/><br/>Demand for technology to support gait training after neurological injury is increasing due to population aging. Due to recent advances in sensing, actuation, and computation, robots are ideal tools to deliver gait training, but their potential in gait neurorehabilitation has not yet been fully realized. In this context, crucial difficulties are identified in the employed control schemes, which are required to accommodate inter-individual gait variations, while promoting stable and energetically efficient gait patterns. The proposed project combines experiments with a lower limb exoskeleton with biomechanical modeling to determine subject-specific assistance strategies that enable a new approach to robot-aided gait neurorehabilitation, named GOALL (Goal-Oriented, subject Adaptive, robot-assisted Locomotor Learning). The conducted research activities have relevant applications both in rehabilitation and in human augmentation, while improving our basic understanding of gait biomechanics. The planned education and outreach components will be targeted to engage a community of graduate, undergraduate and K-12 students in topics at the intersection of robotics and biomechanics. The dissemination of the research methods and results in an open source format will benefit the robotics and biomechanics communities.<br/><br/>The proposed project formalizes new control methods to modulate discrete kinematic variables of gait, achieving controllability of such variables without fully constraining the gait cycle kinematics, thus promoting inter-individual variability in gait kinematics. To this aim, we pursue a systematic approach to the design of gait assistance primitives, i.e. multi-joint coordination patterns capable of modulating a chosen gait parameter, at different gait speeds. The proposed approach is based on inverse dynamics and pulsed torque approximation, and is followed by human-in-the-loop experiments to test the efficacy of assistance primitives to modulate a selected gait parameter during motor adaptation. The experimental investigation is paralleled by neuromechanical modeling of the response to robotic intervention, with the ultimate goal of generalizing the results to other gait parameters of interest for various patient populations."
"1734109","NRI: FND: Safe and Efficient Robot Collaboration System (SERoCS) for Next Generation Intelligent Industrial Co-Robots","CMMI","National Robotics Initiative","09/01/2017","08/17/2017","Masayoshi Tomizuka","CA","University of California-Berkeley","Standard Grant","Bruce M. Kramer","08/31/2020","$750,000.00","","tomizuka@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","ENG","8013","030E, 082E, 7632, 8013, 8086","$0.00","In current automated factories, humans and robots typically work separately, partly for safety reasons and partly because full robotic automation has been a goal. In recent years, however, it has been recognized that there are tremendous opportunities when robots are brought out of their cages and allowed to collaborate with human workers in a shared workspace.  Such collaboration takes advantage of both the intelligence, adaptability and flexibility of humans and the endurance, strength and reliability of robots. In any collaboration between humans and robots, i.e. co-robots, it is important to consider and ensure both the safety of the humans and the best performance of the robots. This project aims to establish a set of design principles for a safe and efficient robot collaboration system (SERoCS).  Outside of factories, SERoCS may be applied in other settings, such as with mobility assistance of humans by robots and automated driving situations where human-driven vehicles and autonomous vehicles share the same road.<br/><br/>SERoCS consists of three parts: (1) robust cognition algorithms for environment monitoring, (2) optimal task planning algorithms for safe human-robot collaboration, and (3) safe motion planning and control algorithms for safe human-robot interactions (HRI).  Research on cognition environment monitoring algorithms involves the construction of a cognition model library and the implementation of an algorithm for online prediction and adaptation of human behavior. In addition, task planning algorithms for safe human-robot collaboration require the construction of a motion skill library learned from human demonstrations and its association with an algorithm for online task planning and objective generation using learned skills. The two-layer structure that will be employed for safe motion planning and control algorithms comprises a long-term, efficiency-oriented planning layer and a short-term, safety-oriented control layer for safe HRIs. The SERoCS will signicantly expand the skill sets of the co-robots and prevent and minimize occurrences of human-robot collision and robot-robot collision during operation."
"1844524","EAGER: Reconciling Model Discrepancies in Human-Robot Teams","IIS","National Robotics Initiative","09/01/2018","08/13/2018","Yu Zhang","AZ","Arizona State University","Standard Grant","Reid Simmons","08/31/2020","$249,929.00","","Yu.Zhang.442@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","8013","063Z, 7916, 8086","$0.00","Robots greatly complement human capabilities in many domains, but having them function as teammates has often proven to be challenging. This is due in part to a lack of understanding of robots, which often leads humans to find that their expectations of robotic teammates are not met in reality.  The proposed research addresses this by having robots reason about the models people have of them and using those models to either behave in ways that meet the expectations more closely or explain the perceived differences.  The work can have a significant impact on critical domains that involve human-in-the-loop AI systems, such as decision support, automated manufacturing, eldercare, and medical robotics. <br/><br/>To become reliable teammates, robots must understand the expectations of their human partners regarding the robots' tasks and abilities, and be able to seek reconciliation between the expected and actual models. In this project, reconciliation will be achieved either by 1) biasing the robot's behavior to implicitly accommodate model differences; or 2) communicating to explicitly reduce the differences. The first approach, termed model reconciliation planning, will be formulated as an optimization problem that generates a plan for the robot to execute while minimizing its distance to the expected plan that the human envisions. Heuristic search methods will be developed to accommodate this approach. The second approach will generate explanations to update the human's model of the robot in such a way that the robot's plan more closely matches that of the human's expectation in the updated model.  In addition, machine learning will be used to approximate the model of human expectation when not provided explicitly, and methods for model reconciliation with these learned and incomplete models will be developed.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830613","NRI: FND: Soft Wearable Robots for Injury Prevention and Performance Augmentation","IIS","National Robotics Initiative","09/01/2018","08/13/2018","Hao Su","NY","CUNY City College","Standard Grant","Wendy Nilsen","08/31/2021","$249,978.00","YingLi Tian, Alessandra Carriero","hao.su@ccny.cuny.edu","Convent Ave at 138th St","New York","NY","100319101","2126505418","CSE","8013","063Z, 8086","$0.00","Musculoskeletal disorders are a leading cause of injury among workers who are exposed to physical workloads, with overexertion in lifting causing over one-third of these injuries. Every year approximately $56 billion is lost due to lift related injuries. The emerging technologies of exoskeletons hold promising potential to reduce biomechanical loads, thereby preventing worker injury. The obstacles to widespread adoption of this technology, however, arise from discomfort due to excessive weight, restricted range of motion, and high-pressure concentration. This project seeks to explore a new design for wearable robots as ubiquitous co-robots to address these challenges. The proposed bio-inspired, soft, back-support exoskeletons will provide joint moment assistance, while being lightweight and unobtrusive. Our soft back-support exoskeleton consists of 1) a soft exoskeleton that is lightweight as its design architecture (bio-inspired, cable-driven mechanism) and actuation (high-torque density actuators) overcome the limitations of rigid exoskeletons (heavy, limit range of motion) and textile-based soft exosuits (medium weight, exert high pressure concentration on tissue); and 2) wearable sensors and its on-site estimation algorithms of biological joint moment to characterize and prevent injuries. The proposed exoskeleton presents a promising solution in assisting injury prevention and performance augmentation. In terms of its societal impact, it will improve the quality of life and work as well as address the social and economic impact of robots on our workers. Thus, it will have a direct massive gain to the economy, health, and welfare of our society.<br/><br/>The goal of this project is to explore new research and design of soft wearable collaborative robots to minimize injuries of workers prone to fatigue and musculoskeletal disorders. The project will focus on 1) designing bio-inspired soft back-support exoskeletons which are hybrid wearable robots that combine the advantages of rigid exoskeletons and soft exosuits while minimizing their respective limitations; 2) exploring on-site estimation algorithms using wearable sensors to characterize the biological joint moments to detect fatigue onset; and 3) evaluating the performance of the exoskeletons and its effectiveness for injury prevention. <br/>The contributions of this research entail both engineering innovations including new design methodology and enabling technologies for soft robots, as well as scientific foundation and tools to understand human-robot interaction and biomechanics. 1) Advances in robotics. Soft exoskeleton design architecture will enable a new type of wearable robot design that is comfortable, powerful, and versatile. High torque density actuators will significantly reduce the weight and increase the transparency of exoskeletons. 2) Understanding of human-robot interaction. The investigation into lifting biomechanics and assistive control strategy will shed light on human-robot interactions and improve human and robot performances.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1844325","EAGER: Hierarchical Contrastive Explanations for Robot-Human Communication","IIS","National Robotics Initiative","09/01/2018","08/11/2018","Siddharth Srivastava","AZ","Arizona State University","Standard Grant","Reid Simmons","08/31/2020","$274,581.00","Subbarao Kambhampati","siddharths@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","8013","063Z, 7916, 8086","$0.00","Intelligent assistive robots have the potential to improve our society in many walks of life: they could help us take care of the elderly and the sick, act as first responders in emergencies, and kickstart extra-planetary exploration.  However, today's robots require highly trained experts for their customization, configuration, and repair. This not only makes it difficult to realize the potential benefits of assistive robots in society, but also creates large uncertainties in the future of employment for millions in the workforce.  To help address such issues, this project develops new ways for robots to explain their actions to humans, considering the proficiency of the users.  Thus, robots will be able to tailor their explanations to what someone already understands about the robots' capabilities and limitations.<br/><br/>The project focuses on automatically explaining unexpected robot behavior to users with potentially imprecise knowledge about the underlying task and/or the robot. This can be used to efficiently diagnose specification problems and customize robots towards desired behaviors. The proposed approach formalizes three general principles: 1) customizing explanations according to the audience; 2) treating explanation as an interactive process; and 3) using the questions asked of a robot to estimate the user's level of expertise. In this framework, a user may present a foil, or a counterfactual proposal of alternative robot behavior, that s/he finds more natural. The proposed approach estimates the user's proficiency using a lattice of abstract models and computes reasons why the proposed alternatives would not work using minimal additional detail. In this way, the system can produce explanations that are contrastive and aligned with the proficiency of the user.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637704","NRI: Decentralized Feedback Control Design for Cooperative Robotic Walking with Application to Powered Prosthetic Legs","CMMI","National Robotics Initiative","09/01/2016","08/08/2016","Kaveh Akbari Hamed","CA","San Diego State University Foundation","Standard Grant","Irina Dolinskaya","08/31/2019","$612,213.00","Robert Gregg","kavehakbarihamed@vt.edu","5250 Campanile Drive","San Diego","CA","921822190","6195945731","ENG","8013","8086","$0.00","This project addresses the creation of innovative decentralized controllers for legged locomotion. Decentralized controllers require only local information to accomplish their function. In the case of legged locomotion, decentralization is desirable for several reasons. For prosthetics, where the purpose is to replace a lost natural limb, it is impractical to wire the user with a profusion of sensors. Therefore the prosthetic device must primarily rely on its own built-in measurements. Another advantage of decentralization is the management of complexity. As robots become more sophisticated, the number of variables that must be monitored for a complete description of the system status becomes so large that top-down controllers are costly or infeasible to implement. The challenge of decentralized control is made substantially more difficult because walking and running are hybrid dynamic behaviors, that is, the dynamics follow a completely different set of rules when, for example, a foot is planted on the ground, compared to when it is swinging in the air. This project will address the substantial analytical difficulties caused by these features. This project will advance the state of the art in advanced lower limb prosthetics, as well as in locomotion for the next generation of legged robots. <br/><br/>This project will investigate the systematic design of decentralized feedback controllers that coordinate low-dimensional subsystems to achieve robust legged locomotion, overcoming the curse of dimensionality in legged robots and enabling cooperative human-machine walking with powered prosthetic legs. The project draws upon robotics, optimization, and feedback control theory to advance two key innovations: (1) creating algorithms to systematically design robust stabilizing decentralized controllers for cooperative subsystems; and (2) transferring the decentralized control framework into practice with an experimental quadruped and a powered prosthetic leg. The problem of creating decentralized nonlinear controllers for robust dynamic walking with interconnected subsystems, coordinated only by a common gait cycle phasing variable, will be formulated in the context linear and bilinear matrix inequalities. The theoretical significance of these algorithms include: (1) they are powerful tools for the design of general nonlinear decentralized feedback control schemes; (2) they explicitly account for underactuation to account for walking motions that are not flat-footed; (3) they provide cooperation between subsystems of complex walking models with high dimensionality and strong interactions; and (4) they provably stabilize full-dimensional hybrid dynamical models of walking robots rather than simplified models. This decentralized control framework is technologically significant because it can be readily transferred into practical high-DOF legged robots, as well as wearable robots for physical rehabilitation."
"1834557","NRI: Collaborative Research: Unified Feedback Control and Mechanical Design for Robotic, Prosthetic, and Exoskeleton Locomotion","IIS","National Robotics Initiative","01/01/2018","05/22/2018","Koushil Sreenath","CA","University of California-Berkeley","Standard Grant","Radhakisan S. Baheti","08/31/2019","$182,057.00","","koushils@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","8013","092E, 8086","$0.00","There is a pressing need for wearable robots, e.g., prostheses and exoskeletons, which improve the quality of life for individuals with limited mobility - devices that work symbiotically with human users to achieve stable, safe and efficient locomotion.  At present, approximately 4.7 million people in the United States would benefit from an active lower-limb exoskeleton due to the effects of stroke, polio, multiple sclerosis, spinal cord injury, and cerebral palsy, and by 2050 an estimated 1.5 million people in the United States will be living with a major lower-limb amputation.  Yet current wearable robotic devices do not address this growing population's needs since they are bulky, heavy, noisy, and require large batteries for even short duration use, while implementing predominately hierarchical control algorithms.  Impeding innovation in this domain is the expensive and slow traditional design-build-test approach that ignores the tight coupling between hardware specifications and control algorithm performance.  The vision of this work is to provide a methodology---inspired by advancements in robotic locomotion---that allows lower-limb prostheses and exoskeletons to meet real-world requirements through the co-design of the electromechanical and feedback systems.  The transformative nature of this work, therefore, stems from its ability to realize wearable robots that synergize with humans to achieve increased mobility, providing a template for the growing robotic assistive device industry and potentially improving the quality of life of millions.  <br/><br/>To realize the vision of this work, the overarching research goal is to create a new unified control and design framework that will allow for the efficient and stable locomotion of robots, prostheses, and exoskeletons.  A key aspect of this control methodology is the ability to continuously mediate between different objectives enforcing stability and safety in an efficient manner through force-based interactions among (wearable) robotic devices, their environment and the user. The resulting framework will be utilized via control-in-the-loop mechanical design of prostheses and exoskeletons with stringent design requirements, tested experimentally on a novel humanoid robot, and clinically evaluated through human subject trials.  This work is, therefore, guided by the following specific goals:  (1) develop a unified online optimization-based control framework for (wearable) robotic locomotion that efficiently mediates stability, safety and force constraints, (2) create a feedback loop between formal control synthesis and the mechanical design of wearable robots that satisfy stringent performance requirements,  (3) accelerate clinical testing by translating controllers formally and experimentally from bipedal humanoid robots to prostheses and exoskeletons.  As a result of these research goals, this work has the potential to create the next generation of robotic systems that enable stable, safe and efficient human mobility."
"1749783","CAREER: Preventive Robotics:  Learning and Adaptation for Predictive Human Robot Symbiosis","IIS","Cyber-Human Systems (CHS)","08/01/2018","03/23/2018","Heni Ben Amor","AZ","Arizona State University","Continuing grant","Ephraim P. Glinert","07/31/2023","$140,412.00","","hbenamor@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7367","1045, 7367","$0.00","Deploying assistive technologies that intelligently minimize the risk of musculoskeletal injury during physical tasks could improve user safety and significantly reduce the healthcare costs associated with the treatment of long-term disabilities such as chronic pain.  With that goal in mind, this CAREER project will contribute key innovations that allow robots to reason about the biomechanical safety of actions performed jointly with a human partner.  The research will focus on the concept of Preventive Robotics, a novel approach to human-machine collaboration that incorporates the biomechanical well-being of the human user into robot control and decision-making.  In contrast to Rehabilitation Robotics, which focuses on therapeutic procedures after an injury occurs, Preventive Robotics seeks to proactively reduce the risk of injury.  A critical knowledge gap in this regard is the absence of a theoretical foundation that supports human-machine symbiosis - healthy, physical, and bi-directional interactions between human and machine which can be comfortably sustained over very long periods of time.  The main objective of Preventive Robotics is to generate assistive robot actions that (a) seamlessly blend with actions of the human partner to achieve the intended function, while (b) minimizing biomechanical stress on the human body.  Coalescing these two goals will unlock new potential for robotics to drastically improve public and occupational health.  The project will also involve transition of innovations to a commercial partner developing intelligent lower-leg prostheses.  The research integrates with an education program targeting K-12 students, undergraduate and graduate students, and students from underrepresented groups.  <br/><br/>To these ends, the project will develop a unified Bayesian framework for modeling symbiotic dynamics among multiple agents using a compact probabilistic and data-driven methodology. The framework will bridge the divide between predictive modeling of humans and predictive control of symbiotic human-robot systems. A Bayesian representation will be used to derive algorithms for learning and adaptation which include the future biomechanical state of a human user. In addition, new symbiotic control algorithms will be introduced that utilize predicted biomechanical variables to steer the human-robot interaction towards biomechanically safe movement regimes. These control methods will provide new insights about strongly-coupled systems with reciprocal dependencies, in which only one system can be actively controlled (e.g., an assistive device or prosthesis). The new approach will be implemented on a powered-ankle prosthesis in order to anticipate joint loads and proactively avoid high stresses. The resulting prosthesis will have the potential to significantly lower the risk of musculoskeletal diseases such as osteoarthritis.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637915","NRI: Coordinated Detection and Tracking of Hazardous Agents with Aerial and Aquatic Robots to Inform Emergency Responders","IIS","National Robotics Initiative","10/01/2016","08/10/2016","Pratap Tokekar","VA","Virginia Polytechnic Institute and State University","Standard Grant","Reid Simmons","09/30/2019","$900,835.00","David Schmale","tokekar@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","8013","8086","$0.00","New tools and technology are needed to rapidly assess hazardous agents in the environment and inform emergency responders. Unmanned surface vehicles (USVs) have been used to monitor pollutant plumes in aquatic environments. However, USVs can only provide a close-up view of the plumes. Unmanned aerial systems (UASs) can survey large areas, but only from a distance. This project addresses the challenges in tracking flows of pollutants using a team of UASs and USVs. UASs are used as scouts to direct USVs to efficiently sample the water for testing. The results will provide emergency responders with technology that can provide rapid, actionable information on the dispersal of hazardous agents. This technology will be of immediate value in the development of early-warning systems for airborne hazards such as chemicals and radioactive particles. In an effort to encourage careers in robotics and emergency response, this project delivers a unique interdisciplinary robotics unit for 75 high school students. <br/><br/>Efficient coordination algorithms are required to fully exploit heterogeneity in sensing of teams of autonomous surface and aerial vehicles. When moving through the water, a plume of hazardous agents may bifurcate into different flow regimes, complicating the sampling and control scenario. This project: (1) develops approximation algorithms for multi-resolution, informative trajectory planning to track spatio-temporal plumes with UAS teams; (2) develops an autonomous USV to sample and characterize a surrogate hazardous agent in the water and air; (3) conducts field sampling campaigns with emergency responders (Virginia Tech Rescue Squad, a unique group of stakeholders consisting of >50 student members) to find and localize sources of a surrogate hazardous agent; and (4) develops a unique interdisciplinary robotics unit for 75 high school students representing a range of ages, ethnicities, and socioeconomic classes."
"1525889","NRI: Collaborative Research: Versatile Locomotion: From Walking to Dexterous Climbing with a Human-Scale Robot","IIS","National Robotics Initiative","09/01/2015","08/06/2015","Mark Cutkosky","CA","Stanford University","Standard Grant","Reid Simmons","08/31/2019","$450,000.00","","cutkosky@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","8013","8086","$0.00","The project aims to give legged robots the skills to navigate a wide variety of terrain.  This capability is needed to employ robots in applications such as search-and-rescue, construction, and exploration of remote environments on Earth and other planets. The multidisciplinary team, composed of researchers at Duke, Stanford, UC Santa Barbara, JPL, and Motiv Robotics, will develop a robot to climb a variety of surfaces ranging from flat ground to overhanging cliffs. Using an array of sensors, unique hands, and sophisticated algorithms, the robot will dynamically adopt walking, crawling, climbing, and swinging strategies to traverse wildly varied terrain. During the course of this research, the team hopes to achieve the milestone of the first demonstration of a human-scale rock climbing robot. The research is also expected to lead to insights into cognitive and biomechanical processes in human and animal locomotion.<br/><br/>Although rock climbing serves as an ideal proving ground for the work, this project conducts basic research to address more a general-purpose goal; namely, to provide the physical and cognitive skills for robots to adaptively navigate varied terrain. It takes a dexterous climbing approach, which uses non-gaited, coordinated sequences of contact to move the body, much as dexterous manipulation uses contact with the fingers and palm to move an object.  It will apply principles from optimization, machine learning, bioinspiration, and control theory to make intellectual contributions in several domains, such as robot hand design, planning algorithms, balance strategies, and locomotion performance measurement.  Novel grippers, sensor-based planning strategies, reactive maneuvers, and locomotion metrics will be developed during the course of this research."
"1760479","RAPID: Human-Robotic Interactions During Harvey Recovery Operations","CNS","Hurricane Harvey 2017","10/01/2017","09/20/2017","Ranjana Mehta","TX","Texas A&M University Main Campus","Standard Grant","David Corman","09/30/2018","$117,579.00","Robin Murphy, S. Camille Peres","rmehta@tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","CSE","071Y","7914, 9102","$0.00","Effective and efficient disaster recovery is necessary for individuals, the community and businesses to return to normal functioning from large-scale disasters, like hurricanes Harvey and Irma. In recent years, unmanned robots have been used to facilitate rescue, response, and recovery and have been found invaluable in these efforts as they can go where humans cannot. Although these robots do not have someone on the vehicle itself, they do require humans to operate them, and little is known about the demands of this technological work environment on the humans during disaster recovery. What is known is that the pilots often work: in high work demand stressful environments; outside (often in the heat, as hurricanes happen in the summer); require ambulation or prolonged standing in awkward postures for extended periods of time; and sometimes these operators live in the affected area themselves and thus maybe experiencing psycho-social stressors due to the disaster. Given the finite number of trained operators, the availability of different types of robots, and the increasing areas of the country needing assessment of damages using robots due to large-scale disasters, there is a critical need to examine naturalistic human/robotic interactions during recovery operations in affected regions. The study will create a fundamental, principled understanding of attributes of collaborations between human and robot teams that are resilient during disaster recovery operations to minimize costly errors and improve effectiveness of future disaster robotics response and recovery operations.<br/><br/>This RAPID award will provide critical and timely information on human/robotic interactions during robot-assisted Harvey recovery operations in the Texas Gulf Coast and surrounding locations impacted by flooding. The study will examine recovery operations that focus on inspections of critical infrastructure affected by the flooding and to assist with economic recovery across different types of structures (homes, factories, neighborhoods, etc.). The objectives of this study are to 1) document the relationships between the human (e.g., pilot) and the robot (e.g., unmanned aerial vehicle) to achieve specific recovery tasks (surveillance and inspections) in dynamically changing and unstable environments (e.g., flood-damaged infrastructure); and 2) determine the key contributors of poor human/robotic interactions to provide heuristics/guidelines for improved human/robotic interactions. Both qualitative and quantitative data collection and analyses techniques will be used: video observations to document the gamut of human/robot interactions during recovery operations, perceptions of workload/fatigue, trust in robots, usability, communication, and training gaps through surveys and interviews from the human teams, types and functions of robots used, operator physiological responses, and task productivity metrics. Findings obtained from this study will be rapidly disseminated to appropriate stakeholders (industry, government, public safety) for developing effective best practices in disaster recovery operations."
"1463960","NRI-Small: Context-Driven Haptic Inquiry of Objects Based on Task Requirements for Artificial Grasp and Manipulation","CBET","National Robotics Initiative","07/01/2014","10/14/2014","Veronica Santos","CA","University of California-Los Angeles","Standard Grant","Christina Payne","09/30/2018","$454,632.00","","vjsantos@ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","ENG","8013","7923, 8086","$0.00","PI: Santos, Veronica<br/>Proposal Number: 1208519<br/><br/>Intellectual Merit: Human-like dexterous manipulation is featured prominently as a grand challenge in the 2009 Roadmap for U.S. Robotics' report. Human dexterity relies heavily on tactile sensation and is influenced by proprioceptive and visual feedback. The proposed work aims to advance artificial manipulators by integrating a new class of multimodal tactile sensors with anthropomorphic artificial hands and developing generalizable routines for context-driven haptic inquiry of objects based on task requirements for artificial grasp and manipulation. A primary goal is the development of capabilities for a robot hand to efficiently learn about objects in its unstructured environment through touch, specifically for cases where computer vision would fail to provide critical information about the physical hand-object interactions. While computer vision provides preliminary information about an object and its environment, vision alone cannot provide all essential information necessary for successful physical hand-object interactions. This is especially true when digits are occluded by the grasped object, and when the hand-object interaction is completely out of view. Inspiration for the haptic inquiry framework will be drawn from a suite of human haptic exploration procedures. In contrast to haptic exploration, haptic inquiry will require that the order and time spent on each exploratory procedure depend on task goals. The order and type of questions to be asked haptically will be context-dependent and designed to yield high-level, task-directed information at a low cost of inquiry. The weight given to each mode of tactile sensing (force, vibration, temperature) will also be tuned according to the context of the task.<br/>This proposal aims to strengthen the robustness of co-robot systems by developing a framework for context-driven, task-directed haptic inquiry that integrates multi-digit tactile and proprioception data in a task-appropriate manner. The framework will be developed and deployed on an anthropomorphic robot hand outfitted with a new class of commercially-available multimodal tactile sensors. The work is transformative because it will enable co-robot systems to remain functional even in the absence of visual feedback, which is typically the primary form of feedback for robotic systems. The long-term research objective of this proposal is to reduce the cognitive burden on the user of an artificial manipulator. <br/><br/>Broader Impacts: The proposed translational research could enhance the functional capabilities of co-robot systems in which humans use artificial manipulators to work in unstructured, unsafe, or limited access environments (prosthetic, rehabilitative, assistive, space, underwater, military, rescue, surgery).  The proposed work could benefit the human user of a co-robot system by empowering the robot with the ability to control low-level perception-action loops autonomously without burdening the human. The ROS operating system may be used to simulate and control an anthropomorphic robot hand outfitted with commercially-available tactile sensors using commercially-available actuators. Custom source code (C, MATLAB, ROS) and an open source haptic library for a commercially-available tactile sensor (suitable for data mining) will be made publicly available for the benefit and advancement of the robotics community."
"1813651","CHS: Small: Watch One, Do One, Teach One: An Integrated Robot Architecture for Skill Transfer","IIS","Cyber-Human Systems (CHS)","08/15/2018","08/08/2018","Brian Scassellati","CT","Yale University","Standard Grant","Ephraim P. Glinert","07/31/2021","$500,000.00","","brian.scassellati@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","CSE","7367","075Z, 7367, 7923","$0.00","In the last several years, robotics research has transitioned from being concerned exclusively with building fully autonomous and capable robots to include building partially-capable robots that collaborate with human partners, allowing the robot to do what robots do best and the human to do what humans do best.  This transition has been fueled by a renaissance of safe, interactive systems designed to enhance the efforts of small- and medium-scale manufacturing, and has been accompanied by a change in the way we think robots should be trained.   Learning mechanisms in which the robot operates in isolation, learning from passive observation of people performing tasks, are being replaced by mechanisms where the robot learns through collaboration with a human partner as they accomplish tasks together.  This project will seek to develop a robot architecture that allows for new skills to be taught to a robot by an expert human instructor, for the robot to then become a skilled collaborator that operates side-by-side with a human partner, and finally for the robot to teach that learned skill to a novice human student.  To achieve this goal, popular but opaque learning mechanisms will need to be abandoned in favor of novel representations that allow for rapid learning while remaining transparent to explanation during collaboration and teaching, in conjunction with a serious consideration of the mental state (the knowledge, goals, and intentions) of the human partner.  A fundamental outcome of this work will be a unified representation linking the existing literature in learning from demonstration to collaborative scenarios and scenarios involving the robot as an instructor. Thus, project outcomes will have broad impact in application domains such as collaborative manufacturing, while also enhancing our substantial investment in education and training (especially research offerings for graduate and undergraduate investigators), and will furthermore enrich the efforts to broaden participation in computing.<br/><br/>This effort will build upon research in three subfields and extend the state-of-the-art to address deficiencies in each:<br/><br/>1 - Robot as Student.  Building on work from Learning from Demonstration, the team will construct robots that learn task models from humans.   However, to be useful to the other thrust areas, these models must not be opaque as many current learning techniques are.   Instead, a transparent model will allow the robot to provide and ask feedback about its performance, explain what it has learned, and to proactively ask questions that speed up learning.<br/><br/>2 - Robot as Collaborator.  The relatively new field of Human-Robot Collaboration struggles with synchronizing task execution between human and robot partners.   By linking to models of learned task behavior and models of user intention and understanding, the team will construct systems that become proficient in negotiating task allocation, accommodating user preferences, and restoring/updating internal representations in case of errors or change of plans.<br/><br/>3 - Robot as Teacher.  Fields including Intelligent Tutoring Systems build models of user knowledge, typically modeled using Bayesian knowledge tracing.  These models, however, simply show knowledge as known, unknown, or forgotten, and only for factual knowledge.   By linking with concrete representations of task and intent, the team will create robots that can detect, extend, or repair the mental model of a student for real-world tasks.<br/><br/>A set of milestones across three years will culminate in a demonstration of a robot that can learn a new task, collaborate on that task, and then teach that task to others.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830498","NRI: FND: Rapid Operator Awareness via Mobile Robotics (ROAMR), Customizable Human Safety using Mobile and Wearable Co-Robots","IIS","National Robotics Initiative","09/01/2018","08/08/2018","Anirban Mazumdar","GA","Georgia Tech Research Corporation","Standard Grant","Reid Simmons","08/31/2021","$489,964.00","Aaron Young","anirban.mazumdar@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","063Z, 8086","$0.00","Human operators in construction sites, disaster zones, and other rapidly changing environments risk injury from collisions with moving machinery and falling components.  The risk of collisions can reduce human performance by forcing them to work very slowly and keep track of multiple situations simultaneously.  This project aims to explore how teams of co-robots can improve human safety by detecting potential collisions that the humans may not be aware of, alerting them to the danger, and helping them move away from the danger.  The project will develop methods for communicating potential threats to human operators via a human-worn exoskeleton, which can also assist the people in moving to safety as rapidly as possible.<br/><br/>The approach will augment human awareness, performance, and safety in unstructured, outdoor, and varying environments, where dynamic objects pose threats of imminent, unnoticed collision.  Specifically, the project will develop a new safety architecture where mobile systems rapidly detect collisions and plan a safe response, a wearable exoskeleton communicates the situation to the human, and the exoskeleton helps to achieve a safe response.  The project will focus on 1) developing and characterizing a physical ""language"" for wearable co-robots to provide situational awareness based on visual displays, audio guidance, vibro-tactile sensations, and physical signals from the exoskeleton actuators; 2) investigating how wearable sensing can infer human motions using machine learning to predict human behavior by accounting for automated obstacle avoidance plans, human motion strategies, and measurements of joint kinematics, ground contact forces, and muscle activation; and 3) researching how a wearable exoskeleton can accelerate safe responses in real-time by using targeted exoskeleton torques to enhance propulsive forces and increase speed of response by reducing the apparent inertia of the limbs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734355","NRI: INT: COLLAB: Co-Robotic Systems for GeoSciences Field Research","ECCS","National Robotics Initiative","09/01/2017","08/05/2017","Daniel Koditschek","PA","University of Pennsylvania","Standard Grant","Radhakisan S. Baheti","08/31/2020","$1,076,122.00","Douglas Jerolmack","kod@ese.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","ENG","8013","8013, 8086","$0.00","Sand and dust storms are a growing worldwide menace, soil instability and erosion threatens agriculture, and fine sediment compromises ecosystem health of rivers and oceans, all impacting large human populations on nearly every continent. The cumulative effects of these disturbed environments also threaten human well-being through damage of habitation and disruption of transportation. An interdisciplinary collaboration of geoscience, cognitive science, and robotics researchers aims to accelerate and deepen the collection of data about the fluid and materials properties associated with such unstable soils by endowing legged robots with the instrumentation and scientific agenda of agile, novice field assistants. These new robots are capable of general field mobility and are being programmed to think like assistant field geologists in order to develop research strategies in rugged natural environments where measurements are lacking. Overcoming the specific locomotion challenges presented by these environments and developing algorithms and software sufficient to interpret and act on human research needs will greatly advance the field of robotics. The resulting new information about wind, water and materials processes will have bearing on the management of infrastructure and agriculture, and also the response of landscapes to environmental changes.<br/><br/>The project focus is to use the geosciences field research setting to test a chain of hypotheses reaching from the formal representation of scientific knowledge to the properties of provably correct algorithms for human-machine pursuit of scientific data. The geoscientific goal is to produce the first comprehensive, time varying maps of soil strength with co-located soil moisture composition and size over the course of rainfall events in a natural landscape. The cognitive science goal is to develop a formalized representation of the cognitive processes underlying field data collection and interpretation that is simultaneously suitable to underlie robotic field assistance algorithms while at the same time advancing the study of human perceptual interpolation and reasoning. The robotics goal is to achieve a provably correct architecture for generating from formalized human task specification a chain of safe, stable online automated legged gait transitions on complex broken terrain that subserve the geoscientist data collection objectives. Two different families of legged robots with a variety of perceptual and geoscientific instrumentation suites will be deployed over natural hillsides under investigation by human geoscientists. Field performance of the resulting human-robot teams will be evaluated according to criteria assessing the degree of robotic mobility and autonomy, the quality and reliability of the resulting geoscientific measurements, and the impact of the collection process on the sampled environment. Advances in legged robot mechanics and intelligent control have brought the field to a threshold where the next major challenges for autonomous mobility can only be formulated and engaged with respect to suites of abstract but formal tasks relative to unstructured environments against which the appropriateness and success of autonomously generated, goal-directed motor behaviors can be precisely measured.<br/>Robots endowed with even the rudiments of understanding what measurements are needed where and when by scientists, in order to test their hypotheses, would deepen our insight into the structure of human cognition. They would also open the way toward collecting massive amounts of data at presently unachievably fine spatiotemporal scales, potentially transforming the theoretical and empirical foundations of geoscience."
"1542301","RET SITE: Robotics Research Experiences for Middle School Teachers","CNS","RES EXP FOR TEACHERS(RET)-SITE","05/01/2016","08/19/2015","Daniel Koditschek","PA","University of Pennsylvania","Standard Grant","Harriet G. Taylor","04/30/2019","$569,655.00","DANIEL UEDA","kod@ese.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","1359","1359","$0.00","This funding establishes a new Research Experience for Teachers (RET) Site at the University of Pennsylvania. The primary objective of this RET site is to involve middle school teachers in the School District of Philadelphia in summer research experiences that emphasize robotics.  The teachers will spend six weeks in the summer participating in research experiences and developing classroom modules and materials which will be implemented in their classrooms during the academic year. The project is led by the General Robotics, Automation, Sensing, and Perception (GRASP) Laboratory at the University of Pennsylvania.  The GRASP Lab is known not only as a leader in robotics research but also for its significant outreach and impact on K-12 education.  The RET Site project involves a partnership between the university, the school district, the Mayor's Office of Education, and industrial associates.  The teachers will continue to receive classroom support for related activities in their classrooms during the academic year including establishing FIRST LEGO League clubs in the schools. This RET Site project will develop a community of teachers who are passionate about robotics and who can translate this excitement to their students through engaging, high-quality inquiry learning experiences.  <br/><br/>The project is anchored by a research area this is compelling and exciting for teachers and middle school students and by a faculty team that has demonstrated expertise in both research and education.  The goals of the project are to: provide a quality research experience for middle school teachers in the field of robotics and automation; increase understanding of science and robotics; increase teachers' abilities to apply scientific and engineering methods to problems; increase the opportunities in underserved Philadelphia schools to prepare students for the engineering and scientific workforce; and develop teachers into STEM leaders.  The site features projects that are teacher accessible as well as connected to current research and practice.  The RET site includes sound evaluation and dissemination plans that will provide models for integrating robotics concepts into the middle school curricula.   Teachers will develop and hone their research, communication, and presentation skills, all of which are essential to their professional growth and success. The project will build the technical capacity of teachers so they are capable of developing and implementing new, exciting robotics learning activities at their schools. The project team will disseminate the project materials through the TeachEngineering digital library and a GRASP's engagement web site that will be shared with a wider audience of teachers at annual workshops and conferences."
"1531039","US Ignite: Collaborative Research: Track 1: Industrial Cloud Robotics across Software Defined Networks","CNS","CISE RESEARCH RESOURCES","09/01/2015","08/24/2015","Andrea Fumagalli","TX","University of Texas at Dallas","Standard Grant","Bruce M. Kramer","08/31/2019","$175,000.00","Miguel Razo, Donald Hicks, Marco Tacca","andreaf@utdallas.edu","800 W. Campbell Rd., AD15","Richardson","TX","750803021","9728832313","CSE","2890","015Z, 082E, 6840, 9102","$0.00","Currently, industrial robots are cost-effective for repetitive and high-volume tasks such as welding and painting, but not for lower-volume, mixed-part production.  The need for robotic part handling for unstructured industrial applications is diverse. In manufactured-goods distribution centers, where multiple bins are presented to an operator, a human is required to handle a range of parts that must be boxed and shipped. In the reclamation and recycling industry, humans sort waste streams of mixed products on conveyor belts. Assembly and kitting operations in manufacturing are termed ?robotic opportunities? but they require a solution for handling many part types in the same work-cell. This project will research and integrate technologies to enable the use of industrial robots for low-volume mixed-part production tasks. The proposed solution will include 3D image sensors and high-speed flexible networking, cloud computing, and industrial robots. The inclusion of cutting-edge new software such as the Robot-Operating System Industrial (ROS-I) and Cloud Computing platforms offer excellent educational opportunities for both undergraduate and graduate students. The software developed in this project will be widely distributed to enable further innovations by other teams.<br/><br/>The project objective is to develop cloud robotics applications that leverage high-performance computing and high-speed software-defined networks (SDN). Specifically, the target applications combine big-data analytics of sensor data (of the type collected from factory floors) with the control of industrial robots for low-volume, mixed-part production tasks. Cloud computers located at a remote facility relative to the factory floor on which industrial robots operate can be used for compute-intensive applications such as object identification from 3D sensor data, and grasp planning for the robots to perform object manipulation.  The project methods will consist of (i) integrating ROS-I components and developing new software as required to transmit the 3D sensor data to remote computers, running the object identification and grasp planning applications, and returning robot instructions to the original site, (ii) running this software on geographically distributed compute clouds, (iii) collecting measurements and enhancing the software to meet real-time delay requirements. The technical challenge lies in meeting these stringent real-time requirements. For example, high-speed networks with the flexibility to connect arbitrary factory floors and datacenters are needed to transfer the 3D sensor data quickly to the remote cloud computers and to deliver the computed robot instructions(hence, SDN)."
"1501335","University, Community College and Industry Partnership: Revamping Robotics Education to Meet 21st Century Workforce  Needs","DUE","S-STEM:SCHLR SCI TECH ENG&MATH, ADVANCED TECH EDUCATION PROG","06/01/2015","04/28/2015","Aleksandr Sergeyev","MI","Michigan Technological University","Standard Grant","Heather Watson","05/31/2019","$702,324.00","Scott Kuhl, Mark Highum, Abdulnasser Alaraje, Mark Kinney","avsergue@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","EHR","1536, 7412","1032, 9178, SMET","$0.00","This proposal led by Michigan Technological University in cooperation with Bay de noc Community College intends to improve STEM education by capitalizing on the appeal of robotics.  It also supports industry demand for well-trained specialists capable of programming, maintaining, and troubleshooting modern robots.  Development of an advanced, industry-driven, hands-on educational curriculum in robotic automation will improve the quality of STEM education for electrical engineering technology students at two- and four-year institutions.  The software that is being developed will be freely available for adaptation, which will allow robotics to be taught even when the purchase of industrial robots is not feasible.  Faculty development will include extensive training and industrial certification in robotics and automation.  Partnership with a leading robotics manufacturer creates an important ongoing link between academia and industry ensuring the curriculum is regularly updated to meet emerging needs. K-12 teacher seminars will introduce advances in technology to those who play a pivotal role in inspiring future generations of engineering technologists. New robotics courses and equipment obtained in the project will attract interest of K-12 teachers and students, while simultaneously advancing undergraduate learning. As a result of the project, engineering technologists will enter the workforce prepared to adapt to the complex and changing demands of a high-tech workplace. <br/><br/>Robotics is a valuable learning tool that can enhance overall STEM comprehension and critical thinking.  The interdisciplinary construction of robots makes it a useful pedagogical tool for all STEM areas.  The novelty of robotics is instrumental in attracting and recruiting diverse STEM students.  In the classroom, a robotics platform advances students' understanding of both scientific and mathematical principles, develops and enhances problem-solving techniques, and promotes cooperative learning.  There is also a strong need for industrial certification programs in robotics automation.   The curriculum includes courses developed with the goal of providing students the occasion to configure and execute real-life, industry comparable, robotic scenarios with opportunity for certification.  An external evaluator will contact industrial partners to verify that the curriculum effectively addresses industry needs.  Student learning is being assessed using pre-test/post-test embedded testing methods.  Evaluation methods focus on determining the effectiveness of course materials and instructional methods for the different student populations involved.  Formative evaluation occurring during the course development and pilot stages is anticipated to inform adjustments for subsequent course offerings. Summative evaluation is anticipated to help determine how the project meets its objectives and document results for dissemination.  The outreach portion of the project also entails evaluation when K-12 teachers, student camp participants and those involved at participating schools are surveyed to gauge impact.  Project dissemination plans include a 2-day workshop for up to 12 faculty members. The goal of the workshop is to take the knowledge gained from curriculum development and the technical information gained from lab development, and combine it with robotics training to produce practical curriculum planning and strategies for developing courses similar to those piloted in this project."
"1427014","NRI: Collaborative Research: Robotics 2.0 for Disaster Response and Relief Operations","IIS","National Robotics Initiative","08/15/2014","05/04/2018","Nikolaos Papanikolopoulos","MN","University of Minnesota-Twin Cities","Standard Grant","Jie Yang","07/31/2019","$1,024,000.00","Miki Hondzo, Ibrahim Isler, Jiarong Hong","npapas@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","8013","8086, 9251","$0.00","The project develops and tests novel compressive sensing and sensor locating techniques that are adaptable to a myriad of different mobile robot designs while operable on today's wireless communication infrastructures. Unique in-situ laboratory and field experiments provide tangible results to scientists and other stakeholders that can be leveraged to advance these systems into future real-world hazard management scenarios. The research team develops new technological approaches that results in mobilizing more intelligent, automated ""eyes and ears on the ground."" Outreach efforts include: (i) integration of the activities with practitioners; (ii) Seminars/webcasts to audiences like environmental engineers and first responders; (iii) Annual technology day camps to attract middle-schoolers from under-represented groups to engineering; (iv) Demonstrations to local K-12 institutions; (v) Inclusion of the project themes to the regular curricula; and (vi) International collaborations.<br/><br/>This project introduces Robotics 2.0; a framework that targets autonomous robots that are co-workers and co-protectors, adapting to and working with humans. The research team develops a Cyber-Control Network (CCN) to allow multiple fixed and mobile robotic environmental sensing and measurements to adapt quickly to the changing environment by dynamically linking sub-networks of actuation, sensing, and control together. The design of such CCN ControlWare, and compressive sensing architectures, could be adapted to other large-scale problems beyond disaster response, mitigation, and management, such as power grid monitoring and reconfiguration, or regional urban traffic operations to respond to traffic congestion and incidents. The robotic sensing platforms do not require a-priori knowledge of the hazardous and dynamically changing environments they are monitoring. The Robotics 2.0 framework allows to swiftly respond, to prepare, and to manage various types of disasters."
"1822872","ROBO-VI: A Virtual-Internship-Based Hybrid Learning Technology to Prepare Traditional and Non-Traditional Students to Work with Collaborative Robots","IIS","Cyberlearn & Future Learn Tech","08/15/2018","08/03/2018","Bilge Mutlu","WI","University of Wisconsin-Madison","Standard Grant","Chia Shen","07/31/2021","$499,123.00","Andrew Ruis, David Shaffer","bilge@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","8020","063Z, 8045","$0.00","Collaborative robots are emerging as a new family of advanced technologies that are designed to work side-by-side with people in industrial settings. These robots can improve the productivity and flexibility in manufacturing and logistics industries, while also assisting workers in repetitive, and unhealthy or unsafe work conditions. Unlike traditional factory robots that are programmed and configured by engineers to function independently for long periods of time, collaborative robots require human workers to frequently interact with the robot, including training the robot, making the necessary changes in the environment for the robot to function, and supervising the robot's work to ensure its successful operation. The integration of collaborative robots into and operation within existing industrial settings require expert skills that many workers lack, and that current educational programs do not cover, highlighting a skills mismatch from the demands of an increasingly automated future of work. This project will develop an understanding of what skills workers will need to perform these tasks effectively and to design a hybrid digital-physical educational technology that will support worker education and training in these skills in classrooms and industrial-training facilities. The research team will evaluate the effects of the technology on skill development among trainees and make recommendations for future job-training programs. <br/><br/>The new hybrid technology will include an expert system computer program that will provide learners with explanations, visualizations, and simulations of key concepts and a robotic assistant that will provide physical demonstrations. This hybrid physical-digital learning environment will be used in expert-led instruction of traditional and non-traditional students in collaborative robotics. The research team will (1) develop an empirical model of expertise in working with collaborative robots through observations of and interviews with experts and analyses of expert-training programs and (2) iteratively design, build, and test a digital-physical hybrid learning environment, integrating an Expert-View Dashboard (EVD), to support expert-led instruction in educational and industrial-training settings. The resulting educational technology will provide educators and trainers with a powerful educational tool that will supplement the development of expertise in working with autonomous, intelligent, and collaborative technologies to meet the demands of an increasingly automated jobs landscape.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1638034","NRI: Operating in the Abyss: Bringing Together Humans and Bio-Inpsired Autonomous Vehicles for Maritime Applications","IIS","National Robotics Initiative","09/01/2016","08/29/2016","Kamran Mohseni","FL","University of Florida","Standard Grant","Ralph Wachter","08/31/2019","$599,981.00","","mohseni@ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","8013","8086","$0.00","The ocean covers about two-thirds of the planet's surface, drives weather, regulates temperature, produces about half of the oxygen in the atmosphere, absorbs most carbons from the atmosphere, and ultimately supports all living organisms on Earth.  Furthermore, the ocean has been essential to humans for commerce, transport, food, and sustenance.  Nevertheless, 95% of the ocean remains unexplored, and the long term impact of natural or man-made changes on the health of the planet and its occupants are far from understood.  This investigation is aimed at addressing some of the challenges in the design and operation of a sustained networked robotic system for monitoring and exploring the vast ocean in cooperation with or in replacement for humans.  This project proposes research that will fill the knowledge gap in underwater hybrid robotics, effective navigation and coordination of a team of robots with significant constraints and limited resources, and path planning for a team of robots in harsh mediums and with restricted resources.<br/><br/>The proposed hybrid robotic system takes inspiration from marine animals, with a healthy balance between migratory capabilities and accurate maneuvering in proximity of obstacles. The robot will be outfitted with a distributed pressure and surface velocity sensors to provide total hydrodynamic forces for vehicle control and vortex street identification for obstacle detection. Novel underwater robotic actuators are also proposed and will be employed in the design and operation of a hybrid class of underwater robot with efficient high speed cruising and precise low speed maneuvering capabilities required in many marine applications. These new sensing and actuation capabilities facilitate safe co-operation of robots with humans in the ocean and in proximity of obstacles, humans, and other robots.  Availability of such new sensory information and actuation capabilities will also result in a paradigm shift in our approach to vehicle control, path planning, and cooperation.  To this end new algorithms will be developed and tested in simulations and experiments in a well-equipped underwater laboratory.  The system capability to maximize its contribution as human assistants or replacements in existing and emerging marine applications will be explored."
"1830549","NRI: FND: Robotic Collaboration through Scalable Reactive Synthesis","IIS","National Robotics Initiative","09/01/2018","08/04/2018","Lydia Kavraki","TX","William Marsh Rice University","Standard Grant","James Donlon","08/31/2021","$749,291.00","Moshe Vardi","kavraki@cs.rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","CSE","8013","063Z, 8086","$0.00","As human-robot collaboration is scaled up to more and more complex tasks, there is an increased need for formally modeling the system formed by human and robotic agents. Such modeling enables reasoning about reliability, safety, correctness, and scalability of the system. The modeling, however, presents a daunting task. This research aspires to formally model scenarios where the robot and the human can have varying roles. The intent is to develop scalable methodologies that will endow the robot with the ability to adapt to human actions and preferences without changes to its underlying software or hardware. An assembly scenario will be used to mimic manufacturing settings where a robot and a human may work together and where the actions of the robot can improve the quality and safety of the work of the human. The project is a critical step towards making robots collaborative with and responsive to humans while allowing the human to be in control. <br/><br/>This research will develop a framework for human-robot collaboration that integrates reactive synthesis from formal methods with robotic planning methods. By tightly combining the development of synthesis methods with robotics, it will pursue the development of a framework that is intuitive and scalable. The focus is on task-level collaboration as opposed to physical interaction with a human. The framework takes as input a task specification defined in a novel formal language interpreted over finite traces: a language suitable for robotics problems. It produces a policy for a robotic agent to assist a human agent regardless of which subtask or execution order for this subtask that the human agent chooses. The policy includes both high-level actions for the robotic agent as well as corresponding low-level motions that can be directly executed by the actual robot. One key novel component of the approach is the automated construction of abstractions for robotic manipulation that can be used by synthesis methods. The scalability of the proposed work will be investigated along different dimensions: the extent to which symbolic reasoning can be applied, the development of new synthesis algorithms, and the proper use of abstractions including their automatic refinement and the construction of factored abstractions. The trade-offs in using a combination of partial policies and replanning will be investigated as well as how to account for incomplete information due to incomplete observations. The theoretical contributions will be implemented on real robot hardware and demonstrated in experiments that are analogous to real-world assembly tasks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734272","NRI: FND: A Framework for Human-Team-Supervised Autonomy with Application to Underwater Search and Rescue","IIS","National Robotics Initiative","08/15/2017","07/27/2017","Vaibhav Srivastava","MI","Michigan State University","Standard Grant","Jie Yang","07/31/2020","$749,997.00","Xiaobo Tan","vaibhav@egr.msu.edu","Office of Sponsored Programs","East Lansing","MI","488242600","5173555040","CSE","8013","8086","$0.00","Advances in computing and manufacturing have led to rapid developments in autonomous robots. For sophisticated tasks such as search and rescue, it is often critical to integrate human knowledge and perception skills with the capabilities offered by robots. Taking underwater search and rescue as a motivating context, this project focuses on developing a principled design framework for optimizing the performance of a mixed human-robot team comprised of multiple human operators and heterogeneous robots. By enabling efficient and reliable human-robot interactions, this work will facilitate the use of robots in hazard response, environmental monitoring, mobility of goods and humans, healthcare, manufacturing, and many other applications of societal impact. The project will provide training opportunities for graduate and undergrad students, including those from underrepresented groups. It will also provide research training to high school students and K-12 teachers. An open-source robotic fish educational kit and demos of EEG-mediated human-robot interactions will be developed to pique the interest of K-12 students in science and engineering. The project will further produce an underwater robotics testbed available for use by the broader robotics and control community.<br/><br/>This research will develop a generalizable framework for rigorous and systematic design of autonomy supervised by a team of interacting human operators, which will enable the leveraging of human operators' adaptivity in complex scenarios while mitigating performance deterioration due to loss of situational awareness. The framework will consist of two tightly coupled modules. The first module will involve optimal task allocation and scheduling for event-triggered human team supervision, which will be formulated as a semi-Markov decision process (SMDP) for a complex queueing network capturing task processing by a team of human operators with different skill sets. Human cognitive dynamics will be incorporated via practical models, and efficient algorithms for solving the SMDP are examined while uncertainties introduced by stochasticity in cognitive processes and variability among human operators are accommodated. The second module of the framework will deal with informative path planning for autonomous robots that optimally balances the explore-exploit trade-off in their search for targets of interest, by solving a multi-armed bandit problem that incorporates mobility constraints of the robots. The framework will be experimentally evaluated in field trials emulating underwater search and rescue, which will involve a group of gliding robotic fish and remotely operated vehicles (ROVs), supervised by a team of two human operators."
"1632460","SBIR Phase II:  Versatile Robot Hands for Warehouse Automation","IIP","STTR PHASE II","09/01/2016","08/22/2016","Lael Odhner","MA","RightHand Robotics, LLC","Standard Grant","Muralidharan S. Nair","12/31/2018","$750,000.00","","lael@righthandrobotics.com","21 Wendell St Apt 20","Cambridge","MA","021381850","6175010085","ENG","1591","1591, 6840, 8035, 9139, HPCC","$0.00","The broader impact/commercial potential of this project affects one of the fastest-growing sectors of the US economy. E-commerce sales in 2015 accounted for 7.4% of total U.S. retail and are expected to rapidly rise. The potential for the commercial impact of general each-picking systems is high, as current manual labor methods are pain points for distribution centers; human picking is unpleasant, expensive and inefficient due to high absenteeism, high turnover and human error. The success of the proposed technology will also contribute to American competitiveness in the robotics industry. Of the top 20 distribution system integrators, only three are currently based in the U.S. Robotics is going to be the key driver of progress in this area, where each-picking, our core product capability, is a key component of future automated distribution systems. Beyond warehousing logistics, applications that our technology can benefit include: broad applications of industrial automation and manufacturing; military applications (e.g., IED disposal, where robots can perform tasks that are dangerous for humans to perform); and assistive healthcare (e.g., where robots must be compliant enough to be safe around humans while interacting successfully with unknown environments).<br/><br/>This Small Business Innovation Research Phase II project will focus on the development of a state-of-the-art each-picking robotic system and its deployment, initially targeted at the order fulfillment industry. To date, robotic systems have enabled significant progress on transporting inventory on shelves or in totes. However, there has not yet been a deployed system that can perform the task of picking individual items from inventory bins and placing them in boxes for shipment. During Phase I of this project, RightHand Robotics developed a picking system far in advance of the research literature on robotic grasping, picking tens of thousands of items previously unseen objects, with error rates of less than 0.1%. During Phase II, the project will focus on advancing the state of the art in data-driven refinement of grasp planning using machine learning techniques, and will develop methods for box-packing that exploit the company?s advanced compliant grippers. These improvements will result in an average pick-and-place time of 6 seconds or less and an undetected placement failure rate of fewer one in ten thousand."
"1523767","NRI: Learning to Plan for New Robot Manipulation Tasks","IIS","National Robotics Initiative","09/01/2015","09/17/2015","Tomas Lozano-Perez","MA","Massachusetts Institute of Technology","Continuing grant","James Donlon","08/31/2019","$900,000.00","Leslie Kaelbling","tlp@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","8013","8086","$0.00","Robots have great potential societal benefits, especially working with humans in tasks such as manufacturing, disaster relief and elder care. Robots are however very difficult to program to perform new tasks: non-programmers can teach relatively stereotyped action sequences and expert programmers can generate more elaborate action strategies through long programming and debugging processes. Part of the difficulty stems from trying to teach the robot at the level of actions, since the actions to achieve a desired effect depend strongly on details of the environment.  Instead, this project focuses on teaching the robot models of the environment.  The robot can then use these models to plan its actions automatically.  This approach leads to more adaptable behavior.  Models are also easier to extend and re-use than action sequences, thereby reducing the burden for teaching subsequent tasks. The project involves a thorough integration of research and education. Graduate and undergraduate students are involved in all aspects of the research. Furthermore, the research in this project will become part of an undergraduate subject on robot algorithms at MIT.<br/><br/>This project will develop techniques to teach a robot to perform long-horizon tasks in complex, uncertain domains, in a way that equips the robot with knowledge it can re-use and re-combine with previous knowledge to solve not just the task it was taught, but a broad array of additional tasks.  Furthermore, the robot will be aware of its own knowledge and lack of knowledge, and will be able to plan to take actions, including performing experiments and asking humans for further information, to improve its own knowledge about how to behave in its environment.  The project will develop a set of machine learning tools that will allow humans to, relatively quickly and straightforwardly, teach the basic ideas of a new domain to the robot, and then enable to robot to continue to improve its knowledge as it gains experience in the domain. This project will build on a new hierarchical framework for integrating robot motion planning, symbolic planning, purposive perception and decision-theoretic reasoning.  The framework, as it stands, supports planning and execution to achieve pick-and-place tasks in complex domains that may require moving objects out of the way, using real, noisy, robot perception and actuation.  However, it requires a specification of the domain it is to operate in.  In our existing implementation, the domain description was written by hand, by experts, through a long period of trial-and-error. The concrete objective of the project is to develop methods enabling a robot to learn to perform high-level tasks in new domains by acquiring new domain models through human-provided examples and advice.  These methods will be evaluated in three domains using a Willow Garage PR2 mobile manipulation robot.  The overriding objective will be to develop methods that apply broadly and can be used to instruct robots to perform a wide variety of tasks."
"1816540","RI: Small: Exploiting Global Structure in Robot Decision Problems","IIS","ROBUST INTELLIGENCE","08/15/2018","08/03/2018","Kris Hauser","NC","Duke University","Standard Grant","Reid Simmons","07/31/2021","$348,774.00","","kris.hauser@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495","7495, 7923","$0.00","Some decision problems, like loading a dishwasher or assembling furniture, require explicit planning about a sequence of steps, while others, like grasping an object or swerving to avoid a stopped car, can be performed largely through learned reflexes. In robotics, it is still poorly understood why some problems require planning and why others can be solved via reflex. This project explores how techniques from topology, a branch of mathematics, can be applied to study the fundamental nature of robot decision problems. By developing algorithms that apply topology to optimize, analyze, and visualize large datasets of robot motions, the researchers hope to better understand the gray area between planning and learning. Ultimately, this better understanding could help other engineers develop more responsive, capable, and robust robot behaviors. <br/><br/>The technical goal of this research is to analyze the mathematical relation connecting robot decision problems to their solutions in order to shed light on fundamental questions surrounding the connection between motion planning and control learning. Breaking from the classical planning paradigm of developing an algorithm that solves individual problem queries, the project studies the global topological characteristics of continuous variations of related problem instances. Specifically, it investigates how certain features of topological complexity relate to the performance of learning and planning algorithms. Based on this understanding, new algorithms, topological metrics, and visualization techniques are developed to help exploit topological structure for faster planning and more accurate learning. The proposed methods are evaluated on benchmark problems in redundant inverse kinematics, legged robots, and agile autonomous vehicles.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734365","NRI: INT: COLLAB: Co-Robotic Systems for GeoSciences Field Research","ECCS","National Robotics Initiative","09/01/2017","08/05/2017","Thomas Shipley","PA","Temple University","Standard Grant","Radhakisan S. Baheti","08/31/2020","$423,878.00","","TSHIPLEY@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","ENG","8013","8013, 8086","$0.00","Sand and dust storms are a growing worldwide menace, soil instability and erosion threatens agriculture, and fine sediment compromises ecosystem health of rivers and oceans, all impacting large human populations on nearly every continent. The cumulative effects of these disturbed environments also threaten human well-being through damage of habitation and disruption of transportation. An interdisciplinary collaboration of geoscience, cognitive science, and robotics researchers aims to accelerate and deepen the collection of data about the fluid and materials properties associated with such unstable soils by endowing legged robots with the instrumentation and scientific agenda of agile, novice field assistants. These new robots are capable of general field mobility and are being programmed to think like assistant field geologists in order to develop research strategies in rugged natural environments where measurements are lacking. Overcoming the specific locomotion challenges presented by these environments and developing algorithms and software sufficient to interpret and act on human research needs will greatly advance the field of robotics. The resulting new information about wind, water and materials processes will have bearing on the management of infrastructure and agriculture, and also the response of landscapes to environmental changes.<br/><br/>The project focus is to use the geosciences field research setting to test a chain of hypotheses reaching from the formal representation of scientific knowledge to the properties of provably correct algorithms for human-machine pursuit of scientific data. The geoscientific goal is to produce the first comprehensive, time varying maps of soil strength with co-located soil moisture composition and size over the course of rainfall events in a natural landscape. The cognitive science goal is to develop a formalized representation of the cognitive processes underlying field data collection and interpretation that is simultaneously suitable to underlie robotic field assistance algorithms while at the same time advancing the study of human perceptual interpolation and reasoning. The robotics goal is to achieve a provably correct architecture for generating from formalized human task specification a chain of safe, stable online automated legged gait transitions on complex broken terrain that subserve the geoscientist data collection objectives. Two different families of legged robots with a variety of perceptual and geoscientific instrumentation suites will be deployed over natural hillsides under investigation by human geoscientists. Field performance of the resulting human-robot teams will be evaluated according to criteria assessing the degree of robotic mobility and autonomy, the quality and reliability of the resulting geoscientific measurements, and the impact of the collection process on the sampled environment. Advances in legged robot mechanics and intelligent control have brought the field to a threshold where the next major challenges for autonomous mobility can only be formulated and engaged with respect to suites of abstract but formal tasks relative to unstructured environments against which the appropriateness and success of autonomously generated, goal-directed motor behaviors can be precisely measured. Robots endowed with even the rudiments of understanding what measurements are needed where and when by scientists, in order to test their hypotheses, would deepen our insight into the structure of human cognition. They would also open the way toward collecting massive amounts of data at presently unachievably fine spatiotemporal scales, potentially transforming the theoretical and empirical foundations of geoscience."
"1637764","NRI: Task-Based Assistance for Software-Enabled Biomedical Devices","CBET","National Robotics Initiative","09/01/2016","08/26/2016","Todd Murphey","IL","Northwestern University","Standard Grant","Christina Payne","08/31/2019","$429,782.00","","t-murphey@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","ENG","8013","8086","$0.00","1637764 - Murphey<br/><br/>Robotic assistive devices help people execute and learn physical tasks. Sometimes these tasks are relatively simple, sometimes they are in a particular context, and sometimes they are highly dynamic and very task specific. This work will create algorithms that enable the delivered assistance to take into account algorithmic descriptions of the underlying task. As an example, walking is a highly structured task that simultaneously requires efficiency and stability during motion and must take into account terrain characteristics. The work takes advantage of task knowledge to either modify a person's motion or exert forces that help the person complete the task. This capability is relevant to rehabilitation and physical therapy, where one may wish to only minimally help a person in order to improve therapy outcomes. This work will therefore impact the development of software that supports people engaged in robot-assisted physical therapy, including people recovering from various forms of injury. The key to this work is that knowledge of a task is combined with knowledge of a person's capabilities to synthesize software decisions that ensure safety while also maximizing a person's agency during motion. Broader impact of this work includes technology transfer to rehabilitation, outreach through the Museum of Science and Industry in Chicago, classroom innovation, and industry collaboration.<br/><br/>The proposed work will create software-enabled, task-specific support for assistive biomedical devices. Dynamic tasks require that a combination of the robot and the assisted person be both effective and safe, and the proposed research will create algorithms and software that ensure efficacy and safety while leaving the user free to both move and exert effort. The latter is important in contexts like physical therapy, where effort is important to therapeutic impact. The proposed work will leverage recent results in real-time nonlinear optimal control techniques for human-in-the-loop systems. Specifically, sequential action control (SAC) will be used to both filter and assist human subject dynamic behavior, using a method called the Maxwell's Demon Algorithm. The work will additionally develop formal methodologies for establishing stability and performance guarantees for the proposed algorithms. Lastly, the proposed work will develop compact representations of the controlled assistance algorithms appropriate for computationally minimal embedded systems. All the work will be developed in the Robot Operating System (ROS), making the developed tools widely available to both researchers and companies. The algorithms will be tested on haptic devices and an exoskeleton. The broader impacts for this work will include outreach, technology transfer to rehabilitation, the development of courses in dynamics and analysis, and industrial collaboration. The PI is currently working with the Museum of Science and Industry, and as part of the proposed work the PI and supported students will participate in a National Robotics Week exhibit in the main rotunda of the museum with an estimated viewership of over ten thousand on-site visitors. The PI is involved in significant classroom innovations, and the proposed work will include development of courses in analysis and dynamics. Lastly, the project will include a collaboration with Ekso Bionics, leveraging and impacting their unparalleled expertise in exoskeleton development."
"1525251","NRI: Rich Task Perception for Programming by Demonstration","IIS","National Robotics Initiative","09/01/2015","08/17/2015","Dieter Fox","WA","University of Washington","Standard Grant","Jie Yang","08/31/2019","$1,200,000.00","Luke Zettlemoyer, Maya Cakmak","fox@cs.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","8013","8086","$0.00","Robots that can work alongside humans and take on repetitive, time-consuming tasks could greatly improve productivity and reliability in task-oriented environments such as laboratories, manufacturing facilities, or commercial kitchens. One of the key challenges in realizing this vision is that every combination of environment, user, and task presents unique requirements for the robot's behavior and it is impractical to employ traditional approaches for programming these robots. Instead, the PIs envision robots that are programmable by their end-users in their particular operation environment and for the particular tasks they are needed for. To overcome limitations of existing approaches, the PIs propose to develop a framework for rich task perception, which is able to extract detailed task descriptions from intuitive human demonstrations. Building on recent advances in depth camera sensing, GPU-optimized visual processing, and language understanding, the proposed framework will track all objects and people in a scene, recognize their goals and task context, and parse speech to extract higher-level task structure from a demonstration. The PIs will also introduce new programming by demonstration techniques that take full advantage of such rich task information and enable users to program robots by demonstrating their desired behavior. The proposed research has the potential to advance national health, prosperity and welfare by developing research and commercial robotic systems for use in factories, laboratories, and households. It will be an enabling technology for a new generation of highly flexible robots that can be programmed on-the-job to increase the productivity of task environments, such as laboratories or manufacturing facilities. The proposed work will also promote the progress of science by enabling reliable documentation and replication of experiments performed in scientific  research wet-labs. Through a new undergraduate capstone course, this project will educate students to develop and program this next generation of robots. To motivate participation in STEM careers, the PIs will demonstrate their work at yearly public outreach events at the University of Washington, and will organize a summer camp for K-16 students through the UW DawgBytes program.<br/><br/>Co-robots that can take on repetitive, time-consuming tasks could greatly improve productivity and reliability in task-oriented environments currently occupied by human workers; such as laboratories, manufacturing facilities, or commercial kitchens. One of the key challenges in realizing this vision is that every combination of environment, user, and task presents unique requirements for the co-robot's behavior and it is impractical to employ traditional approaches for programming these robots. Instead, the PIs envision co-robots that are programmable by their end-users in their particular operation environment and for the particular tasks they are needed for. A popular end-user programming approach in robotics is Programming by Demonstration (PbD), which enables users to program robots by demonstrating their desired behavior. While state-of-the-art PbD techniques have generated impressive robotic behaviors, current approaches have limitations that prevent them from becoming practical and widely adopted. Many of these limitations are specifically related to perception, preventing robots from understanding the detailed context of human demonstrations. To overcome these limitations, The PIs propose to develop a framework for rich task perception, which is able to extract detailed task descriptions from intuitive human demonstrations. Building on recent advances in RGB-D camera sensing, GPU-optimized visual processing, and language grounding, the proposed framework will track all objects and people in a scene at a very fi ne granularity, and parse speech to extract higher-level task structure from a demonstration. The PIs will also introduce new PbD techniques that better take advantage of such rich task information both in the programming and execution of tasks."
"1734360","NRI: INT: MANUFACTURING USA: COLLAB: In-Situ Collaborative Robotics in Confined Spaces","CMMI","National Robotics Initiative","09/01/2017","05/11/2018","Howard Choset","PA","Carnegie-Mellon University","Standard Grant","Bruce M. Kramer","08/31/2021","$757,230.00","","choset@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","8013","030E, 082E, 116E, 8013, 8086, 9178, 9231, 9251","$0.00","Many manufacturing operations require workers to perform operations in confined spaces, subjecting them to possible fatigue and injury from performing tedious tasks in non-ergonomic postures. Intelligent robotic assistants can facilitate safe and ergonomic reach into such spaces, while allowing human workers to remain physically present and in full control over delicate operations. The project will investigate the use of highly reconfigurable, in-situ, collaborative robots (ISCRs) with the enhanced perception and support-autonomy needed to allow a worker and a robot to safely share a common space and collaborate through physical interaction. Conventional robots cannot be used as ISCRs because they are bulky, special-purpose and difficult to program. This project's ISCRs are expected to reduce worker fatigue and musculoskeletal injuries, which are responsible for more than 34 percent of lost work days in the United States, and increase worker productivity. Their added intelligence is also expected to make the robots easier to use, by offering a human-friendly means of interaction. The research has potential applications in the aerospace industry, including the manufacture and service of the fuselage and wings, inspection and repair of hydraulic lines or fuel tanks and pipes, caulking, welding of structural joints and deburring.<br/><br/>This work to support effective human-robot collaboration in confined spaces makes three main technical contributions: 1) design and control strategies for ISCRs, 2) contact detection and location estimation and 3) simultaneous contact-force and navigation (SCAN) planning, so that a robot can use bracing to maneuver deep into a confined space. The ISCRs allow compliance and robustness to geometric uncertainty, reduced inertia, contact sensing and regulated force of interaction with the environment. This new design enables the exploration of real-time estimation for contact state detection, a screw-theoretic approach for constraint identification, and stiffness modeling. The research will also develop planners to achieve SCAN within a semi-structured environment with uncertainty and will use intentional contact to allow enable the robot to reach deep into confined spaces."
"1637446","NRI: Vine Robots: Achieving Locomotion and Construction by Growth","CMMI","National Robotics Initiative","08/01/2016","07/24/2017","Allison Okamura","CA","Stanford University","Standard Grant","Irina Dolinskaya","07/31/2019","$1,757,999.00","Jonathan Fan, Sean Follmer","aokamura@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","ENG","8013","116E, 8086, 9102, 9178, 9231, 9251","$0.00","In contrast to legged robots inspired by locomotion in animals, this project explores robotic locomotion inspired by plant growth. Specifically, the project creates the foundation for classes of robotic systems that grow in a manner similar to vines. Within its accessible region, a vine robot provides not only sensing, but also a physical conduit -- such as a water hose that grows to a fire, or an oxygen tube that grows to a trapped disaster victim. The project will demonstrate vine-like robots able to configure or weave themselves into three-dimensional objects and structures such as ladders, antennae for communication, and shelters. These novel co-robots aim to improve human safety, health, and well-being at a lower cost than conventional robots achieving similar outcomes. Because of their low cost, vine robots offer exceptional educational opportunities; the project will include creation and testing of inexpensive educational modules for K-12 students.<br/><br/>This work broadens the concept of bio-inspired robots from animals to plants, the concept of locomotion from point-to-point movement to growth. In contrast to traditional terrestrial moving robots that tend to be based on the animal modality of repeated intermittent contacts with a surface, the vine modality begins with a root, harboring power and logic, and extends using growth, increasing permanent contacts throughout the process. This project will demonstrate a soft robot capable of growing over 100 times in length, withstanding being stepped on, extending through gaps a quarter of its height, climbing stairs and vertical walls, and navigating over rough, slippery, sticky and aquatic terrain. The design adopts a bio-inspired strategy of moving material through the core to the tip, allowing the established part of the robotic vine to remain stationary with respect to the environment. A thin-walled tube fills with air as it grows, allowing the vine robot to be initially stored in a small volume at its base, and to extend very large distances when controllably deployed.  Mechanical modeling and new design tools will enable the development of task-specific vine robots for search and rescue, reconfigurable communication antennas, and construction. The paradigm of achieving movement and construction through growth will produce new technologies for integrated actuation, sensing, planning, and control; novel principles and software tools for robot design; and humanitarian applications that push the boundaries of collaborative robotics."
"1734416","NRI: INT: COLLAB: Accelerating Large-Scale Adoption of Robotic Lower-Limb Prostheses through Personalized Prosthesis Controller Adaptation","ECCS","National Robotics Initiative","09/01/2017","03/22/2018","Young-Hui Chang","GA","Georgia Tech Research Corporation","Standard Grant","Radhakisan S. Baheti","08/31/2021","$599,684.00","Walter Childers, Kinsey Herrin","yh.chang@ap.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","8013","8013, 8086, 9150","$0.00","Experiencing a lower limb amputation is a life-changing event.  A person with lower-limb amputation relies heavily on a leg prosthesis to support himself/herself and stay mobile.  However, most leg prostheses in current use are unpowered, which can cause great inconvenience.  For example, these unpowered prostheses cannot propel the amputee users forward in walking, and cannot push them up while standing up or climbing stairs.  With the advances in medical robotic technologies, powered robotic leg prostheses are starting to become more common.  These powered prostheses can help amputees to walk more easily and naturally, and also provide power to support activities previously unattainable or extremely difficult with existing unpowered prostheses (such as standing up and stair climbing).  On the other hand, these robotic prostheses are much more complex than the existing unpowered prostheses, so tuning such a prosthesis to fit an individual user is very challenging and time-consuming, requiring numerous office visits with a clinician over a long period of time.  This is one of the main reasons why powered leg prostheses have not gained extensive use among the amputee users.<br/><br/>In this project, the research team will help to solve this problem by developing a new method to automate the prosthesis tuning process.  The main idea is to use a pendant-like wearable sensor to measure upper body motion, which provides rich information about how well the prosthesis is being controlled to help the user to walk and perform other basic tasks of daily life.  The new method will use such information and gradually tune the controller parameters over time without the need for constant clinical supervision.  To develop this method, the researchers will study how an experienced prosthetist tunes the prosthesis parameters and develop an algorithm to mimic this process.  Furthermore, the upper body motion will be used to infer the amputee user's intention more precisely, so the prosthesis can reliably understand what the user intends to do even if he/she changes the motion pattern while learning to use the robotic prosthesis.<br/><br/>By conducting research in this project, the researchers aim to develop a complete Personalized Prosthesis Controller Adaptation (PPCA) system, which provides personalized controller adaption on two levels: 1) automatic motion controller tuning, and 2) automatic intent recognizer adaptation.  The researchers anticipate to make significant contributions to the related scientific areas, including: 1) a novel wearable sensor that incorporates an inertial measurement unit (IMU), capacitive sensing (for sensor-torso relative motion), and advanced signal processing to provide reliable trunk motion information; 2) fundamental understanding of robotic prosthesis-assisted amputee locomotion, and how human expertise-based tuning optimizes its gait quality; 3) a novel quasi-supervised adaptation of classifier-based intent recognizer, which provides the advantages of the traditional supervised learning while avoiding its major weakness (highly effective in adapting to changing human conditions, and no repeated training sessions or human-conducted data labeling required).  Impacts of this project will also be generated by its various education activities, including the introduction of robotic technologies to the future prosthetic clinicians through a renowned prosthetics and orthotics education program, and the creation of hands-on robotic projects in undergraduate research, which can also serve as important tools in the K-12 outreach to attract children at different age groups to the science and engineering fields."
"1446785","CPS: Synergy: Collaborative Research: Designing semi-autonomous networks of miniature robots for inspection of bridges and other large infrastructures","ECCS","ENERGY,POWER,ADAPTIVE SYS, CYBER-PHYSICAL SYSTEMS (CPS), National Robotics Initiative","11/01/2014","08/18/2016","Nuno Miguel Martins","MD","University of Maryland College Park","Standard Grant","Radhakisan S. Baheti","10/31/2019","$855,500.00","Richard La, Sarah Bergbreiter","nmartins@isr.umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","ENG","7607, 7918, 8013","092E, 7918, 8235, 9251","$0.00","Designing semi-autonomous networks of miniature robots for inspection of bridges and other large civil infrastructure<br/><br/>According to the U.S. Department of Transportation, the United States has 605102 bridges of which 64% are 30 years or older and 11% are structurally deficient. Visual inspection is a standard procedure to identify structural flaws and possibly predict the imminent collapse of a bridge and determine effective precautionary measures and repairs. Experts who carry out this difficult task must travel to the location of the bridge and spend many hours assessing the integrity of the structure.  <br/><br/>The proposal is to establish (i) new design and performance analysis principles and (ii) technologies for creating a self-organizing network of small robots to aid visual inspection of bridges and other large civilian infrastructure. The main idea is to use such a network to aid the experts in remotely and routinely inspecting complex structures, such as the typical girder assemblage that supports the decks of a suspension bridge. The robots will use wireless information exchange to autonomously coordinate and cooperate in the inspection of pre-specified portions of a bridge. At the end of the task, or whenever possible, they will report images as well as other key measurements back to the experts for further evaluation. <br/><br/>Common systems to aid visual inspection rely either on stationary cameras with restricted field of view, or tethered ground vehicles. Unmanned aerial vehicles cannot access constricted spaces and must be tethered due to power requirements and the need for uninterrupted communication to support the continual safety critical supervision by one or more operators.  In contrast, the system proposed here would be able to access tight spaces, operate under any weather, and execute tasks autonomously over long periods of time. <br/><br/>The fact that the proposed framework allows remote expert supervision will reduce cost and time between inspections. The added flexibility as well as the increased regularity and longevity of the deployments will improve the detection and diagnosis of problems, which will increase safety and support effective preventive maintenance. <br/><br/>This project will be carried out by a multidisciplinary team specialized in diverse areas of cyber-physical systems and robotics, such as locomotion, network science, modeling, control systems, hardware sensor design and optimization. It involves collaboration between faculty from the University of Maryland (UMD) and Resensys, which specializes in remote bridge monitoring. The proposed system will be tested in collaboration with the Maryland State Highway Administration, which will also provide feedback and expertise throughout the project.<br/><br/>This project includes concrete plans to involve undergraduate students throughout its duration. The investigators, who have an established record of STEM outreach and education, will also leverage on exiting programs and resources at the Maryland Robotics Center to support this initiative and carry out outreach activities. In order to make student participation more productive and educational, the structure of the proposed system conforms to a hardware architecture adopted at UMD and many other schools for the teaching of undergraduate courses relevant to cyber-physical systems and robotics. <br/><br/>This grant will support research on fundamental principles and design of robotic and cyber-physical systems. It will focus on algorithm design for control and coordination, network science, performance evaluation, microfabrication and system integration to address the following challenges: (i) Devise new locomotion and adhesion principles to support mobility within steel and concrete girder structures. (ii) Investigate the design of location estimators, omniscience and coordination algorithms that are provably optimal, subject to power and computational constraints. (iii) Methods to design and analyze the performance of energy-efficient communication protocols to support robot coordination and localization in the presence of the severe propagation barriers caused by metal and concrete structures of a bridge."
"1651792","EAGER:  Dexterous Robotic Cutting","IIS","SPECIAL PROJECTS - CISE, National Robotics Initiative","10/01/2016","06/06/2017","Yan-Bin Jia","IA","Iowa State University","Standard Grant","Ralph Wachter","09/30/2019","$308,828.00","","jia@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","CSE","1714, 8013","7916, 8086, 9251","$0.00","This research will form a theory of robotic cutting and manipulation of soft and irregularly shaped objects. Applications of the results are leading to more skillful dexterous robots geared for a range of industrial applications, improving safety risks, and increasing reliability and consistency. <br/><br/>The technical goal of this project is to understand in depth about manipulation of delicate, flexible, and slippery items, handling of tools with skills, coordination among robotic arms and hands, and motion planning and control based on multi-modality sensing and deformable modeling. The project consists of two phases. The first phase develops strategies for basic maneuvers of cutting devices, tackling issues that include vision-guided hand placements, large deformable modeling in real time, pickup and stabilization, and dexterous grasping and re-grasping. The second phase investigates coordination of two robotic arm-hand pairs to carry out cutting, and synthesizes trajectories and controls to implement different cutting skills. Technical issues to address in this phase include material viscoelasticity, contact detection, cut planning and execution on the fly, arm and hand trajectory planning, and fusion of visual and force data."
"1734461","NRI: INT: MANUFACTURING USA: COLLAB: In-Situ Collaborative Robotics in Confined Spaces","CMMI","National Robotics Initiative","09/01/2017","08/01/2017","Nabil Simaan","TN","Vanderbilt University","Standard Grant","Bruce M. Kramer","08/31/2021","$750,000.00","","nabil.simaan@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","ENG","8013","030E, 082E, 8013, 8086","$0.00","Many manufacturing operations require workers to perform operations in confined spaces, subjecting them to possible fatigue and injury from performing tedious tasks in non-ergonomic postures. Intelligent robotic assistants can facilitate safe and ergonomic reach into such spaces, while allowing human workers to remain physically present and in full control over delicate operations. The project will investigate the use of highly reconfigurable, in-situ, collaborative robots (ISCRs) with the enhanced perception and support-autonomy needed to allow a worker and a robot to safely share a common space and collaborate through physical interaction. Conventional robots cannot be used as ISCRs because they are bulky, special-purpose and difficult to program. This project's ISCRs are expected to reduce worker fatigue and musculoskeletal injuries, which are responsible for more than 34 percent of lost work days in the United States, and increase worker productivity. Their added intelligence is also expected to make the robots easier to use, by offering a human-friendly means of interaction. The research has potential applications in the aerospace industry, including the manufacture and service of the fuselage and wings, inspection and repair of hydraulic lines or fuel tanks and pipes, caulking, welding of structural joints and deburring.<br/><br/>This work to support effective human-robot collaboration in confined spaces makes three main technical contributions: 1) design and control strategies for ISCRs, 2) contact detection and location estimation and 3) simultaneous contact-force and navigation (SCAN) planning, so that a robot can use bracing to maneuver deep into a confined space. The ISCRs allow compliance and robustness to geometric uncertainty, reduced inertia, contact sensing and regulated force of interaction with the environment. This new design enables the exploration of real-time estimation for contact state detection, a screw-theoretic approach for constraint identification, and stiffness modeling. The research will also develop planners to achieve SCAN within a semi-structured environment with uncertainty and will use intentional contact to allow enable the robot to reach deep into confined spaces."
"1723381","S&AS:INT: Integrated Reasoning, Planning and Acting for Household Robots","IIS","S&AS - Smart & Autonomous Syst","08/15/2017","07/27/2017","Leslie Kaelbling","MA","Massachusetts Institute of Technology","Standard Grant","Reid Simmons","07/31/2021","$800,000.00","Tomas Lozano-Perez","lpk@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","039Y","046Z","$0.00","Robots have the potential for enormous beneficial impact on society in fields such as cleaning, tidying, and cooking in households and hospitals, and supporting the elderly to age in place. To achieve many of these benefits, however, these systems will need to be smart enough so that they can be easily told what to do and act sensibly over long periods without needing constant supervision.  The proposed research aims to develop fundamental algorithms that will enable robots to operate autonomously in complex domains, characterized by substantial uncertainty, complex interacting goals, and interaction with multiple people and many objects.  Graduate and undergraduate students are involved in all aspects of the research, and the research in this project will become part of a new ""AI in Robotics"" project course at MIT (also available on-line).<br/><br/>The fundamental approach in this proposal is decision-theoretic: (a) the system's uncertainty about its physical environment (such as location, shape, type, mass, etc. of objects) as well as mental states of other agents (such as intentions and desires) is modeled probabilistically; (b) design objectives for the system are articulated in terms of utility; and (c) the robot chooses actions according to the principle of rationality, that is, it should do things expected to gain high utility.  While finding optimal solutions in complex domains is highly computationally intractable; the project will develop principled approximate solutions that are tractable, based on principles of hierarchical abstraction in space and time, planning in advance for only the most likely outcomes, and factoring complex processes into nearly-independent subprocesses.<br/>"
"1734633","NRI: INT: SCHooL: Scalable Collaborative Human-Robot Learning","IIS","National Robotics Initiative","09/01/2017","08/18/2017","Ken Goldberg","CA","University of California-Berkeley","Standard Grant","Reid Simmons","08/31/2020","$1,374,893.00","Stuart Russell, Pieter Abbeel, Anca Dragan","goldberg@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","8013","8086","$0.00","To be useful in warehouses, homes, and other environments from schools to retail stores, robots will need to learn how to robustly manipulate a wide variety of objects.  For instance, to enhance the productivity of human workers, service and factory robots could keep specified surfaces clear by identifying, grasping, and relocating objects to appropriate locations.  Pre-programming robots to perform such complex manipulation tasks is not feasible; instead this project will investigate scalable robot manipulation, where multiple robots collaboratively learn from multiple humans.  The project will contribute new models, algorithms, software, and experimental data to advance the state-of-the-art in deep learning, human-robot interaction, and cloud robotics.  To broadly convey the results of this research to students and the public, the project will create a book and video with the Lawrence Hall of Science and the African Robotics Network.<br/> <br/>Two primary gaps in current understanding of co-robotic Learning from Demonstration (LfD) are: 1) the absence of a theoretical framework that encompasses humans and robots to produce cooperative learning behaviors as optimal solutions; and 2) the lack of research linking LfD with deep learning, hierarchical planning, and human-robot interaction. The project addresses those gaps with a unified theoretical framework based on Inverse Reinforcement Learning and game-theoretic models of communication between humans and robots, treating LfD as a scalable co-robotic process in which multiple humans and multiple networked robots work in a distributed set of environments to maximize a collective set of reward functions and humans learn how to become more effective demonstrators for robots. The research can be applied to almost any context where robots can learn from human demonstrations and will be evaluated in ""surface decluttering"" benchmarks of increasing complexity over the course of the project."
"1711554","Resilient Control of Human Controlled Robotic Networks","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/01/2017","07/25/2017","Nikhil Chopra","MD","University of Maryland College Park","Standard Grant","Radhakisan S. Baheti","07/31/2020","$380,000.00","","nchopra@umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","ENG","7607","092E","$0.00","The research objective of this proposal is to investigate resilience of human controlled robotic networks to cyber attacks. These systems extend the human capability to manipulate objects remotely with the help of robotic systems and communication networks. Several application areas such as operations in hazardous environments, undersea exploration, robotic surgery, drilling, etc. are significantly impacted by this technology.  However, the use of communication networks can lead to man-in-the-middle or malware attacks that can severely compromise the safety and performance of these systems. Motivated by these observations, this proposal is aimed at investigating algorithms, tools, and implementations that lead to secure and resilient human controlled robotic networks. From a fundamental standpoint, the proposed work will broadly impact the field of cyber security in control systems and robotics. From an applications perspective, the proposed research will impact the field of telesurgery, space robotics, and other semiautonomous telemanipulation systems. One graduate student will directly benefit from the proposed research, and it is expected that several hundred undergraduate and graduate students will benefit from the enriched interdisciplinary education in control theory, robotics, and cyber security.<br/>  <br/>The proposed three-year research effort is expected to significantly impact the manner in which secure and resilient semiautonomous systems are designed and controlled. This will be realized by investigating distributed and computationally light algorithms for edge and node attack detection in human controlled robotic systems. Additionally, utilizing and refining the computation of fundamental bounds to colluding attackers in these systems will aid in understanding achievable resilience to the aforementioned attacks. Specific objectives of the proposed work include investigating analysis tools and physics based encryption techniques for edge and node attack detection and identification, developing resilience in human controlled robotic networks by utilizing mixed physical-virtual robot teams, and experimental studies on a test bed consisting of heterogeneous robotic systems to achieve an understanding of implementation vulnerabilities."
"1657469","CRII: RI: Joint Models of Language and Context for Robotic Language Acquisition","IIS","CRII CISE Research Initiation","08/01/2017","07/20/2017","Cynthia Matuszek","MD","University of Maryland Baltimore County","Standard Grant","Tatiana D. Korelsky","07/31/2019","$163,057.00","","cmat@umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","026Y","7495, 8228","$0.00","As robots become smaller, less expensive, and more capable, they are able to perform an increasing variety of tasks, leading to revolutionary improvements in domains such as automobile safety and manufacturing. However, their inflexibility makes them hard to deploy in human-centric environments such as homes and schools, where their tasks and environments are constantly changing. Meanwhile, learning to understand language about the physical world is a growing research area in both robotics and natural language processing. The core problem is how the meanings of words are grounded in the noisy, perceptual world in which a robot operates. This project explores how robots can learn about the world from natural language in order to take instructions and learn about their environment naturally and intuitively from people. The ability to follow directions reduces the adoption barrier for robots in domains such as assistive technology, education, and caretaking, where interactions with non-specialists are crucial. Such robots have the potential to ultimately improve autonomy and independence for populations such as aging-in-place elders; for example, a manipulator arm that can learn from a user?s explanation how to handle food or open novel containers would directly affect the independence of persons with dexterity concerns such as advanced arthritis. <br/><br/>This is an exploratory investigation of how linguistic and perceptual models can be expanded during interaction, allowing robots to understand novel language about unanticipated domains. In particular, the focus is on developing new learning approaches that correctly induce joint models of language and perception, building data-driven language models that add new semantic representations over time. The work combines semantic parser learning, which provides a distribution over possible interpretations of language, with perceptual representations of the underlying world. New concepts are added on the fly as new words and new perceptual data are encountered, and a semantically meaningful model can be trained by maximizing the expected likelihood of language and visual components. This integrated approach allows for effective model updates with no explicit labeling of words or percepts. This approach will be combined with experiments on improving learning efficiency by incorporating active learning, leveraging a robot's ability to ask questions about objects in the world."
"1810402","Spatially resolve three-dimensional tactile sensing using functionally graded piezoresistive pillar arrays","ECCS","ELECT, PHOTONICS, & MAG DEVICE","08/01/2018","07/31/2018","Burak Aksak","TX","Texas Tech University","Standard Grant","Usha Varshney","07/31/2021","$287,659.00","Richard Gale","burak.aksak@ttu.edu","349 Administration Bldg","Lubbock","TX","794091035","8067423884","ENG","1517","8028","$0.00","Despite much advancement in materials, computation power, actuators, sensors, and design, robots drastically lag in their ability to match humans in dexterous manipulation. Studies that show success in robotic manipulation suffer from complex sensing schemes and extensive post processing steps because they utilize tactile sensors that are not capable of human-like high spatial resolution or contact force magnitude and direction detection. Artificial skin-like flexible tactile sensors that can resemble the tactile sensing capabilities of their biological analogue are bound to revolutionize robotics, providing unprecedented control and dexterity, and support the recent advancements in artificial intelligence and humanoid robotics. This work addresses the pressing need for skin-like distributed tactile sensors and proposes a novel tactile sensor of flexible construction, which can resolve dynamic contact forces with fingertip-like high spatial resolution. The proposed work is transformative in its ability to equip robotic manipulators with tactile feedback comparable to that of humans, paving the way to human-like dexterity in robotics. This innovative technology has the potential to be a significant step toward the realization of corobots living and working with humans. This project complements the educational activities in biomimetic engineering and entrepreneurial awareness, giving undergraduate and graduate students the opportunity to be involved in cutting-edge research and gain skills in innovative thinking and entrepreneurship. Educational outreach activities to introduce and promote engineering to K-12 students and underrepresented groups will be an integral part of this project.   <br/><br/>The goal of this work is to enable spatially resolve three-dimensional contact force imaging and provide skin-like touch sensing capabilities (namely, local three-dimensional dynamic force sensing) to robotic platforms and facilitate human-like dexterous manipulation in robotic manipulators. The PI will achieve this goal by fabricating a novel array-type tactile sensor comprising a fibrillar polymeric contact layer which amplifies contact forces at the integrated piezoresistive base sensing layer and a flexible substrate with integrated electrodes. Preliminary experiments have demonstrated composite piezoresistors with pressure sensitivity close to that of a human fingertip. The objectives of the proposed work are to  (i) design a composite microfibrillar sensor array, based on piezoresistive sensing, which would be flexible, cheap, and durable; (ii) develop repeatable and scalable fabrication techniques; (iii) study the underlying physics for composite fiber sensing using micro-and-mesoscale characterization techniques; and (iv) study and demonstrate friction characterization, slip detection, and slip prevention using custom characterization tools.  The long-term scientific goal is to understand and quantify the relationship between three dimensional spatio-temporal contact force images and manipulation to advance robotics as well as its medical and biological applications. If successful, this project, in addition to providing unprecedented control and dexterity in robots, will support the recent advancements in other important areas of robotics, for example in artificial intelligence and humanoid robotics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1748582","NRI: Collaborative Research: Learning Deep Sensorimotor Policies for Shared Autonomy","IIS","National Robotics Initiative","06/01/2017","09/15/2017","Siddhartha Srinivasa","WA","University of Washington","Standard Grant","James Donlon","08/31/2019","$453,379.00","","siddhartha.srinivasa@gmail.com","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","8013","7495, 8086","$0.00","Assistive robots have the potential to transform the lives of persons with upper extremity disabilities, by helping them perform basic daily activities, such as manipulating objects and feeding. However, human control of assistive robots presents substantial challenges. The high dimensionality of robotic arms means that joystick-like interfaces are unnatural hard to use intuitively, and motions resulting from direct teleoperation are often slow, imprecise, and severely limited in their dexterity. This research address these challenges by developing learning algorithms for shared autonomy, where the robot anticipates the user's intent and provides a degree of assistive autonomy to ensure fluid and successful motions. This research will also pave the way for future research that can bootstrap from teleoperation and build towards full robot autonomy. <br/><br/>The research proposes a hierarchical and multi-phased approach to shared autonomy, using techniques from deep learning and reinforcement learning. The system begins by using deep inverse reinforcement learning to quickly ascertain the user's high-level goal, such as whether the user wants to grasp a particular object or operate an appliance, from raw sensory inputs. This goal inference layer supplies objectives to the lower control layer, which consists of deep neural network control policies that can directly process raw sensory input about the environment and the user to make decisions. These policies choose low-level controls to satisfy the high-level objective while minimizing disagreement with the user's commands. The algorithms will be deployed and tested on a wheelchair-mounted robot arm with the potential to assist users with upper extremity disabilities to perform activities of daily living."
"1514395","RI: Medium: Collaborative Research: Novel microLIDAR Design and Sensing Algorithms for Flapping-Wing Micro-Aerial Vehicles","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","08/01/2015","05/01/2018","Karthik Dantu","NY","SUNY at Buffalo","Continuing grant","Reid Simmons","07/31/2019","$372,655.00","","kdantu@buffalo.edu","520 Lee Entrance","Amherst","NY","142282567","7166452634","CSE","7495, 8013","7495, 7924, 8086, 9232, 9251","$0.00","This project makes it possible for a tiny robotic bee to sense its distance to any nearby object. Such depth sensing for a small robot insect pushes the limits of sensor and algorithm design in terms size, weight, computing, and power. The key idea is joint design; every part of the robotic insect is optimized together, from wing design and optics to intelligent algorithms and efficient computation. This is possible by inter-disciplinary work across scientists and engineers from diverse backgrounds. The lessons learned through this project can be applied to transform other applications that involve small devices including medical sensors and endoscope imaging, smart homes and the internet of things, agricultural and industrial monitoring systems, and mobile vision for search and rescue.<br/><br/>Lidar sensing has enabled large robotic cars to navigate complex environments. This proposal introduces designs for ""micro-lidar"" that can be used on insect-scale aerial robots. Making micro-lidar work on small platforms involves four intertwined research thrusts. The first thrust uses MEMS mirrors and wide-angle optics to sense and modulate the laser pulses. The second thrust is adapting signal processing algorithms to estimate range data at this scale. The third thrust is developing novel perception and navigation algorithms to map the indoor environments using a micro-aerial vehicle. The fourth thrust is to improve robotic insect flight to allow novel manipulations that require knowledge of the surrounding range map. The utility of these sensors will be demonstrated on the robobee for novel maneuvers and building topo-feature maps of indoor environments."
"1531065","US Ignite: Collaborative Research: Track 1: Industrial Cloud Robotics across Software Defined Networks","CNS","CISE RESEARCH RESOURCES","09/01/2015","08/24/2015","Malathi Veeraraghavan","VA","University of Virginia Main Campus","Standard Grant","Bruce M. Kramer","08/31/2019","$424,261.00","Shaun Edwards","mv5g@virginia.edu","P.O.  BOX 400195","CHARLOTTESVILLE","VA","229044195","4349244270","CSE","2890","015Z, 082E, 6840","$0.00","Currently, industrial robots are cost-effective for repetitive and high-volume tasks such as welding and painting, but not for lower-volume, mixed-part production.  The need for robotic part handling for unstructured industrial applications is diverse. In manufactured-goods distribution centers, where multiple bins are presented to an operator, a human is required to handle a range of parts that must be boxed and shipped. In the reclamation and recycling industry, humans sort waste streams of mixed products on conveyor belts. Assembly and kitting operations in manufacturing are termed robotic opportunities but they require a solution for handling many part types in the same work-cell. This project will research and integrate technologies to enable the use of industrial robots for low-volume mixed-part production tasks. The proposed solution will include 3D image sensors and high-speed flexible networking, cloud computing, and industrial robots. The inclusion of cutting-edge new software such as the Robot-Operating System Industrial (ROS-I) and Cloud Computing platforms offer excellent educational opportunities for both undergraduate and graduate students. The software developed in this project will be widely distributed to enable further innovations by other teams.<br/><br/>The project objective is to develop cloud robotics applications that leverage high-performance computing and high-speed software-defined networks (SDN). Specifically, the target applications combine big-data analytics of sensor data (of the type collected from factory floors) with the control of industrial robots for low-volume, mixed-part production tasks. Cloud computers located at a remote facility relative to the factory floor on which industrial robots operate can be used for compute-intensive applications such as object identification from 3D sensor data, and grasp planning for the robots to perform object manipulation.  The project methods will consist of (i) integrating ROS-I components and developing new software as required to transmit the 3D sensor data to remote computers, running the object identification and grasp planning applications, and returning robot instructions to the original site, (ii) running this software on geographically distributed compute clouds, (iii) collecting measurements and enhancing the software to meet real-time delay requirements. The technical challenge lies in meeting these stringent real-time requirements. For example, high-speed networks with the flexibility to connect arbitrary factory floors and datacenters are needed to transfer the 3D sensor data quickly to the remote cloud computers and to deliver the computed robot instructions(hence, SDN)."
"1763469","CHS: Medium: Collaborative Research: Manipulation Assistance for Activities of Daily Living in Everyday Environments","IIS","Cyber-Human Systems (CHS)","08/01/2018","07/30/2018","Holly Yanco","MA","University of Massachusetts Lowell","Continuing grant","Ephraim P. Glinert","07/31/2022","$170,269.00","","holly@cs.uml.edu","600 Suffolk Street","Lowell","MA","018543643","9789344170","CSE","7367","7367, 7924","$0.00","While many people with disabilities need help with activities of daily living (ADLs) in their homes or at other locations, they care deeply about maintaining their sense of independence, which implies limiting the tasks that professional or family caregivers are asked to provide. There is the potential for robots to have a huge impact here, by enabling people to live independently for longer. The goal of this research is to develop a robotic wheelchair-manipulator system (RoWMan) consisting of a power wheelchair with a robotic arm mounted on it, that will help its user perform ADLs either as an assistive device or by performing manipulation tasks autonomously. In assistive mode, the user would ride in the wheelchair, with the RoWMan system manipulating items as requested. Whereas in autonomous mode, the user could ask RoWMan to navigate on its own through the house, retrieve items, and place them as directed. This project will necessitate the development of new user interfaces as well as an array of new machine learning and robotics techniques that will enable successful autonomous robotic navigation and manipulation in unstructured environments. To ensure broad impact, project outcomes will be evaluated with a user population at Crotched Mountain Rehabilitation Center.<br/><br/>In recent focus groups it was found that users want a number of capabilities, including the ability to pick up something from the floor, the ability to unlock and open a door, the ability to manipulate items on a tightly packed shelf, etc. RoWMan will be designed so as to enable users to perform these sorts of tasks, by focusing on two areas: robotic manipulation and human-robot interaction. The manipulation work will develop new algorithms that perform well with novel objects in unstructured environments. Traditionally, manipulation planners assume that the shapes of the objects involved are known in advance or can be estimated on the fly, but these assumptions often cause problems in practice. The focus here will be to develop new algorithms based on deep reinforcement learning that can perform manipulation tasks reliably even when the geometry of the world is unknown in advance. The project will also support research into a new class of human-robot interaction based on laser pointers. Recent work suggests that laser pointing can be very effective for the target user community because it enables users to point directly in the environment rather than on a screen which induces additional cognitive load. This project will develop new ways of communicating sophisticated intent using a combination of environmental context, laser pointing, and laser gestures.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734454","NRI: INT: COLLAB: Robust, Scalable, Distributed Semantic Mapping for Search-and-Rescue and Manufacturing Co-Robots","IIS","National Robotics Initiative","09/01/2017","08/03/2017","Roberto Tron","MA","Trustees of Boston University","Standard Grant","James Donlon","08/31/2020","$395,035.00","","tronroberto@gmail.com","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","8013","8086","$0.00","The goal of this project is to enable multiple co-robots to map and understand the environment they are in to efficiently collaborate among themselves and with human operators in education, medical assistance, agriculture, and manufacturing applications. The first distinctive characteristic of this project is that the environment will be modeled semantically, that is, it will contain human-interpretable labels (e.g., object category names) in addition to geometric data. This will be achieved through a novel, robust integration of methods from both computer vision and robotics, allowing easier communications between robots and humans in the field. The second distinctive characteristic of this project is that the increased computation load due to the addition of human-interpretable information will be handled by judiciously approximating and spreading the computations across the entire network. The novel developed methods will be evaluated by emulating real-world scenarios in manufacturing and for search-and-rescue operations, leading to potential benefits for large segments of the society. The project will include opportunities for training students at the high-school, undergraduate, and graduate levels by promoting the development of marketable skills.<br/><br/>The project will advance the state of the art in robust semantic mapping from multiple robots by 1) developing a new optimization framework that can handle large, dynamic, uncertain environments under significant measurement errors, 2) explicitly allowing and studying interactions and information exchanges with humans with an hybrid discrete-continuous extension of the optimization framework, and 3) allowing an intelligent use and sharing of the limited computational resources possessed by the network of co-robots as a whole by enabling approximations and balancing of the computations. These developments will be driven by two particular case studies: a job-shop (small factory) scenario, where robots and fixed cameras are used to track and assist human workers during production and assembly of parts; and a classic search-and-rescue scenario, where operators use an heterogeneous team of robots to quickly assess damages and to discover survivors. These two applications, when considered together, highlight all the limitations of the currently prevalent geometric mapping solutions, and will be used as benchmarks for the project's results."
"1427250","NRI: Multi-Digit Coordination by Compliant Connections in an Anthropomorphic Hand","IIS","National Robotics Initiative","08/01/2014","08/23/2016","Joshua Schultz","OK","University of Tulsa","Standard Grant","Ephraim P. Glinert","07/31/2019","$443,583.00","Yuri Lansinger, Gavin O'Mahony","joshua-schultz@utulsa.edu","800 S. Tucker Drive","Tulsa","OK","741049700","9186312192","CSE","8013","8086, 9150","$0.00","Robust, soft, lightweight, dexterous hands will be a crucial component of the next generation of robots that physically interact with human co-workers.  To date, under-actuated robot hands (where one motor moves multiple joints) that grasp objects reliably have been created largely by designer ingenuity using ""tricks of the trade"" without fully capitalizing on the wealth of mathematical grasping and manipulation theory.  Moreover, anatomical studies of the human hand and robotic hands that do useful work have largely evolved separately, leading to similar conclusions expressed in a different way.  This collaborative effort between engineering and medical faculty will help bridge these gaps.  Engineering graduate students and medical residents will interact regularly; this will serve to translate knowledge and experience across the boundaries of these two disciplines, thereby fostering the ability to solve complex, multi-faceted bioengineering problems.  A key contribution of this project will be a theoretical description of an elastic drive train that maps individual actuator motions to key movements in tasks of daily living.  The robotic hand produced as another outcome of this work will serve as a robust platform for future experimentation (for example, in studies on gesturing, communication for the hearing impaired, and tactile exploration), and it will also be useful for evaluating and visualizing the effect of potential surgical interventions ex vivo.  An important educational and research tool in the PI's institution, this hand will be used to educate and interest university and K-12 students in robotics.  The PI team will coordinate with student groups and Native American community organizations, to recruit qualified underrepresented minorities to participate in the project.<br/><br/>Moving from single- to multi-actuator multi-fingered dexterous robot hand design is not straightforward and has frustrated researchers for several years; it will require a principled formal treatment.  In single-actuator hands, adding a spring to the drive train improves the hand; the exact spring characteristics are not critical.  In the general case of multi-actuator compliant hands simply adding a spring is not enough; a multidimensional spring of specific characteristic is needed.  Concepts from multiport circuit theory, mechanics of materials, linear algebra and elements of general multi-fingered grasping theory will be used to understand the behavior of such a multi-dimensional spring.  The PI's approach is to break this problem into sub-problems, greatly simplifying the analysis.  There is also the matter of which actions an under-actuated hand should be able to perform; the PI argues that complete finger individuation is not necessary, rather coupled finger movements should correspond to those used by humans to perform tasks.  Anatomical analysis of both normal humans and those that have undergone surgical intervention will be used to prioritize basic human motion primitives.  Combined with the novel compliant grasping theory, under-actuated hand synthesis will be formulated as a parameter fitting problem.  Detailed evaluation of the effects of surgical intervention on the human hand, the study of human anatomy, multi-port circuit models, and consideration of compliant mechanisms and the fundamental subspaces of linear algebra will all be blended.  Taken together, this will result in a method to synthesize an elastic drive train that maps actuator contributions to useful, coordinated motions of the fingers.  Implications of the compliant actuation theory will be examined in the mechanism synthesis and grasp stability contexts, and these will be evaluated experimentally.  The investigators will pursue this line of reasoning all the way to implementation in a functioning anthropomorphic hand capable of performing the most common tasks of everyday life."
"1427030","NRI: Collaborative Research: Modeling and Verification of Language-based Interaction","IIS","National Robotics Initiative","08/15/2014","08/18/2014","Mark Campbell","NY","Cornell University","Standard Grant","Reid Simmons","07/31/2019","$700,000.00","Hadas Kress Gazit","mc288@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","8013","8086","$0.00","Many autonomous systems today, such as personal or service robots, are designed primarily to perform tasks independently and in isolation. Integrating these robots with human partners can often result in poor performance, as the robot does not know how to interpret human interaction, and cannot merge information from this  interaction with a model that guarantees robot performance.  This research brings together key elements that are just now reaching a sufficient level of maturity for integration: firstly, natural language processing and probabilistic modeling to capture human input, and secondly probabilistic synthesis and verification of the combined human-robot systems to ensure correct performance. The outcome will be theory and software to enable correct, effective and natural interactions between robots and humans to be realized. This research will impact most future autonomous systems which require interactions with humans, including service, personal and planetary robots. <br/><br/>The goal of this research is to develop models and algorithms for synthesizing and verifying an integrated human-plus-robot system based on natural language interaction. Algorithms are being developed for probabilistic modeling and inference of natural language, including the grounding of the constituents of the language into the physical world and the human's expectations. These models will enable the development of a distribution over specifications for control synthesis, which will in turn enable the development and verification of correct-by-construction controllers to a particular level of probability. The out years will consider interactive human-robot dialogue to resolve conflicts, and ""open world"" scenarios to enable on-line learning of new models over time. It is expected that this research will enable high reliability and performance in many autonomous systems because of the inherent interaction with humans.  Outcomes include open source data and software; community workshops; and undergraduate and graduate student education in the unique area of language, modeling and verification for robotics."
"1734497","NRI: FND: COLLAB: Coordinating Human-Robot Teams in Uncertain Environments","IIS","National Robotics Initiative","09/01/2017","08/23/2017","Christopher Amato","MA","Northeastern University","Standard Grant","James Donlon","08/31/2020","$374,939.00","","c.amato@northeastern.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","8013","8086","$0.00","The decreasing cost and increasing sophistication of robot hardware is creating new opportunities for teams of robots to be deployed in combination with skilled humans to support and augment labor-intensive and/or dangerous manual work. The vision is for robots to free up time of skilled workers so they can focus on the tasks that they are skilled at (complex problem solving, dextrous manipulation, customer service, etc.) and robots can help with the distracting and frustrating parts of working, such as delivering materials or fetching supplies. This vision is being realized across many sectors of the US economy and abroad, such as in warehouse management, assembly manufacturing, and disaster response. However, progress in this area is being stymied by current methods that are rigid and inflexible, and rely on unrealistic models of human-robot interaction. This project seeks to overcome these problems by proposing new models and methods for teams robots to coordinate with teams humans to complete complex problems. <br/><br/>In particular, this project will create and solve realistic models for coordinating teams of humans and robots in uncertain environments. The PIs will investigate innovative approaches to this research area, and will make the following contributions: 1) Enable a transformative re-conceptualization of multi-human multi-robot teamwork the accurately reflects the strengths and limitations of the team, as situated within a temporally dynamic, stochastic environment, 2) develop realistic and general models of human-robot teamwork that consider uncertainty and partial observability, and 3) Contribute innovative and scalable techniques for planning and learning in these models. This research will build off of methods that have been successful in single-robot problems under uncertainty and partially observability: partially observable Markov decision processes (POMDPs). POMDPs model robots and environments, but not humans. However, explicitly including people in these models will be critical in almost all real-world applications.  By extending POMDPs to multiple robots interacting with teams of humans, complex and realistic problems with mixed human and robot teams can be represented. The solution methods developed in this project will allow the robots to reason about the uncertainty about the domain and their human teammates, while optimizing their behavior. The methods are broadly applicable to human-robot collaboration domains, but they will be evaluated in an emergency department, an environment with a large amount of uncertainty and many delivery and supply tasks during high-volume times. A team of robots can assist in these tasks. Experiments will take place in simulation and in the UC San Diego Simulation and Training Center with various numbers of humans and robots. The results of this project have the potential to transform the way human-robot coordination is performed."
"1427081","NRI: Collaborative Research: Human-Supervised Perception and Grasping in  Clutter","IIS","COLLABORATIVE RESEARCH, IIS SPECIAL PROJECTS, National Robotics Initiative","08/15/2014","06/05/2015","Robert Platt","MA","Northeastern University","Standard Grant","Ephraim P. Glinert","07/31/2019","$807,978.00","","r.platt@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","7298, 7484, 8013","5947, 8086, 9251","$0.00","One of the basic building blocks in semi-autonomous manipulation is the ability for a robot to grasp an object that a human operator indicates.  There are many tasks where the natural way for a human and robot to work together is for the human to point out the approximate locations of objects to be grasped and for the robot to generate the precise motions necessary to achieve the grasp.  This core ""auto-grasp"" functionality is critical to providing assistive manipulation for the disabled and elderly, as well as for a variety of military, police, space, or underwater applications. But implementing auto-grasp capability can be challenging in situations where the environment is cluttered, or when it is difficult to determine the grasp intention of the human.  In this collaborative project that combines expertise from two institutions, the PIs will tackle situations where it is necessary for the robot to actively explore or ""interrogate"" the environment in order to figure out what the human intends to grasp and how the robot should do it.  To these ends, the PIs will investigate a modified approach to planning under uncertainty known as belief space planning.  Belief space planning is well-suited to active localization for grasping, because it is a single framework in which the algorithm can reason about perception-oriented and goal-orientation parts of the task.  The PIs will use belief space planning to localize graspable geometries in the environment, known as grasp affordances, in a region indicated by the user.  They will also explore different ways in which a human can interact with the system in order to control the grasping.  The application focus of the work will be in assistive manipulation, where a person who is elderly or disabled operates an assistive robot arm mounted on an electric wheelchair or scooter.  User studies will determine the best methods for the target population to operate the system.  The project will contribute to the opportunities available for undergraduates and high school students in the PIs' institutions, and it will also be integrated as appropriate into the curricula of the courses they teach.<br/><br/>This research contains two key innovations that the PIs expect will make robot grasping more robust.  The first is to incorporate ideas from belief space planning into the reach and grasp planning process.  Because belief space planning can reason about how the robot's own ""state of information"" is expected to change in the future, it is capable of producing plans that acquire task-relevant information in the course of performing a task.  The second innovation is a new approach to perception-for-grasping that localizes grasp affordance geometries in the neighborhoods of objects of potential interest.  Not only is this grasp affordance approach helpful to the belief space planner, but the PIs' preliminary work indicates that this approach can be accurate and very fast (10Hz).  Finally, the connection between the user interface and uncertainty in the location of the grasp target will also be explored, the plan being to model human behavior as an uncertain system where hidden variables describe user intention."
"1427300","NRI: Representing and Anticipating Actions in Human-Robot Collaborative Assembly Tasks","IIS","INFORMATION TECHNOLOGY RESEARC, National Robotics Initiative","08/01/2014","07/27/2016","Aaron Bobick","GA","Georgia Tech Research Corporation","Continuing grant","Reid Simmons","07/31/2019","$849,999.00","Irfan Essa, Henrik Christensen, Michael Stilman","afb@wustl.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","1640, 8013","8086","$0.00","For robots to effectively collaborate with humans on a variety of tasks, they must go beyond responding to human actions to anticipating them.   This is especially true in the domain of collaborative assembly tasks where the robot assists a human worker by providing tools or parts as required.  In this project, a method for formally specifying collaborative assembly tasks is being developed that allows a robot both to understand the action of the human as well as to determine which action the robot has to perform and when. <br/><br/>This project is making fundamental advances to enable task specification to be compiled or converted into a grammar-like description of the human activity.  Given this description, a probabilistic inference method that integrates sensory information to analyze the actions of a human and predict which actions the human will take and when. The system learns the necessary perceptual detection information for human actions will be learned from small amounts of training examples of individual actions.  By integrating these perceptual observations within a structured representation of the task derived from the specification, the robot can make effective predictions about the timing of human action and can thus anticipate when it will need to provide assistance and of what type.  Given these probabilistic predictions the robot makes a plan of action that optimizes a collaboration measure such as how idle time of the human or overall task completion time.  The broader impact of this project is along two dimensions.  The first is within the small to medium enterprise manufacturing and assembly industry.  Successful development of the technologies described is critical for human-robot collaboration in a variety of structured tasks in these domains.  Second, the ability to successfully anticipate human behavior is essential for the general integration of assistive robotics into society."
"1659514","REU Site: Applied Computational Robotics","IIS","RSCH EXPER FOR UNDERGRAD SITES","02/15/2017","02/13/2017","Jason O'Kane","SC","University of South Carolina at Columbia","Standard Grant","Wendy Nilsen","01/31/2020","$359,982.00","Jenay Beer","jokane@cse.sc.edu","Sponsored Awards Management","COLUMBIA","SC","292080001","8037777093","CSE","1139","9150, 9250","$0.00","This Research Experiences for Undergraduates (REU) Site will support a diverse group of computing majors in a mentored research experience in computational robotics, including components emphasizing professional and academic skills development and community building. The primary population of target students will be sophomores and juniors from undergraduate-serving institutions in the southeast. The project will encourage these students toward graduate study and research-oriented industry positions, and provide essential preparation for these career paths. It will be an excellent opportunity for ten undergraduates to participate in research projects each year. The emphasis on applications of computing in robotics is supportive of the growing social need for such expertise. The selection process for these students will promote the inclusion of underrepresented groups through targeted publicity and outreach efforts.<br/><br/>Research conducted by the students will lead to more effective approaches to robot perception, control, and interaction. The research also includes projects rooted in areas such as software engineering, security, and automated reasoning that are often overlooked by the contemporary robotics community, but crucially important for the deployment of reliable, trustworthy robotic systems. The research projects will be organized around the observation that ""Robots Change Everything."" That is, every aspect of a computer system, from the design and engineering of its software, to its interactions with humans, to its core functions of perception and movement, is deeply impacted by the way robots must interact with the physical world."
"1527747","NRI: Collaborative Research: Multimodal Brain Computer Interface for Human-Robot Interaction","IIS","National Robotics Initiative","05/15/2016","05/27/2016","Peter Allen","NY","Columbia University","Standard Grant","Kenneth C. Whang","04/30/2019","$736,552.00","Paul Sajda","allen@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","8013","8086, 8089","$0.00","Human Robot Interaction (HRI) is research that is a key component in making robots part of our everyday life. Current interface modalities such as video, keyboard, tactile, audio, and speech can all contribute to an HRI interface. However, an emerging area is the use of Brain-Computer Interfaces (BCI) for communication and information exchange between humans and robots. BCIs can provide another channel of communication with more direct access to physiological changes in the brain. BCIs vary widely in their capabilities, particularly with respect to spatial resolution, temporal resolution and noise. This project is aimed at exploring the use of multimodal BCIs for HRI. Multimodal BCIs, also referred to as hybrid BCIs (hBCI), have been shown to improve performance over single modality interfaces. This project is focused on using a novel suite of sensors (Electroencephalography (EEG), eye-tracking, pupillary size, computer vision, and functional Near Infrared Spectroscopy (fNIRS)) to improve current HRI systems. Each of these sensing modalities can reinforce and complement each other, and when used together, can address a major shortcoming of current BCIs which is the determination of the user state or situational awareness (SA). SA is a necessary component of any complex interaction between agents, as each agent has its own expectations and assumptions about the environment. Traditional BCI systems have difficulty recognizing state and context, and accordingly can become confusing and unreliable. This project will develop techniques to recognize state from multiple modalities, and will also allow the robot and human to learn about each other's state and expectations using the hBCI we are developing. The goal is to build a usable hBCI for real physical robot environments, with noise, real-time constraints, and added complexity.<br/><br/>The technical contributions of this project include:<br/>1. Characterization of a novel hBCI interface for visual recognition and labeling tasks with real physical data and environments.<br/>2. Integration of fNIRS sensing with EEG and other modalities in human robot interaction tasks. We will test our ability in the temporal domain to determine at what timescale we can correctly classify movement components that would predict a correct (rewarding) trial or non-rewarding/incorrect movement.<br/>3. Analysis and validation of the hBCI in complex robotic tele-operation tasks with human subject operators such as open door, grasp object on table, pick up item off floor etc.<br/>4. Use of hBCI to characterize human/robot state and create a learning method to recognize state over time.<br/>5. Use of augmented reality for HRI decision making.<br/>6. Further develop hBCI for tracking cognitive states related to reward, motivation, attention and value.<br/>A new class of HRI interfaces will be developed that can expand the ability of humans to work with robots; promote the use and acceptance of robot agent systems in everyday life; expand the use of hBCIs in areas other than robotics for human-machine interaction; further the development of hBCIs as our system will be tapping into reward modulated activity that will be used via reinforcement learning to autonomously update the learning machinery; and bridge the educational divide between Engineering/Computer Science and Neuroscience."
"1208153","NRI-Small: Collaborative Research: Assistive Robotics for Grasping and Manipulation using Novel Brain Computer Interfaces","IIS","Disability & Rehab Engineering, National Robotics Initiative","10/01/2012","06/20/2016","Peter Allen","NY","Columbia University","Standard Grant","Irina Dolinskaya","09/30/2018","$800,498.00","Joel Stein","allen@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","5342, 8013","7923, 8086, 9251","$0.00","This is a collaborative proposal (with UC Davis) which is aimed at making concrete some of the major goals of Assistive Robotics. A team of experts has been brought together from the fields of signal processing and control, robotic grasping, and rehabilitative medicine to create a field-deployable assistive robotic system that will allow severely disabled patients to control a robot arm/hand system to perform complex grasping and manipulation tasks using novel Brain Muscle Computer Interfaces (BMCI). Further, the intent of this effort is not just technology-driven, but is also driven by clear and necessary clinical needs, and will be evaluated on how well it meets these clinical requirements.  Validation will be performed at the Department of Regenerative and Rehabilitation Medicine at Columbia University on a diverse set of disabled users who will provide important feedback on the technology being developed, and this feedback will be used to iterate on the system design and implementation.<br/><br/>Intellectual Merit: The intellectual merit of this proposal includes:<br/>o Novel research in Human Machine Interfaces that has the potential to be transformative in eliciting rich, multi-degree-of-freedom signal content from simple and non-invasive surface electromyographic (sEMG) sensors.<br/>o Development of smart adaptive software that employs machine learning algorithms that can continually monitor user performance, and then automatically calibrate and tune system parameters based on system performance.<br/>o Data driven methods for real-time grasp planning algorithms that can be used with both known and unknown objects.<br/>o Methods for finding pose-robust grasps that are tolerant of errors in sensing.<br/>o Evaluation of an underactuated hand as a grasping device for certain application tasks.<br/>o Integration of 3D vision with real-time grasp planning.<br/>o Scientific evaluation at the clinical level of the impact of these new technologies on the disabled population.<br/><br/>Broader Impacts: The broader impacts of this proposal include:<br/>o Development of a complete system to aid the severely disabled population with tetraplegia.<br/>o Extensions of this technlogy to others lacking motor control function including multiple sclerosis, stroke, amyotrophic lateral sclerosis (ALS or Lou Gehrig disease), cerebral palsy, and muscular dystrophy.<br/>o New technology that can extend the reach and impact of the field of Assistive Robotics.<br/>o Major extensions to the open-source GraspIt! software system that will allow many other researchers to leverage the results of this project.<br/>o Educational thrusts that will bring together engineering students, clinicians and the disabled population to extend the reach and scope of Assistive Robotics.<br/>o New directions in Human Machine Interfaces that can extend beyond the disabled population and into a variety of other applications."
"1818602","NRI: Small: Rapid exploration of robotic ankle exoskeleton control strategies","CMMI","National Robotics Initiative","09/01/2017","01/29/2018","Steve Collins","CA","Stanford University","Standard Grant","Irina Dolinskaya","08/31/2019","$97,801.00","","stevecollins@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","ENG","8013","7923, 8086","$0.00","This project compares different techniques for assisting individuals with stroke-related mobility impairments using a robotic ankle orthosis. Several promising assistance techniques have been developed for robotic prostheses and rehabilitation platforms, which have been extended to exoskeletons - worn at the ankle joint, and adapted for individuals with stroke. An ankle exoskeleton test bed is used to emulate each assistance technique, allowing comparisons of efficiency and effectiveness within the same platform. Each technique is first programmed and verified in pilot tests with this emulator, followed by multi-dimensional parameter studies, conducted first on subjects without neurological impairment and then on subjects with hemiparesis following stroke. The results for each technique are used to identify ideal parameters and their settings, which facilitates across-technique comparisons and development of a standardized set of quantitative performance metrics, including measures of effort, preferred speed, and stability. These studies will contribute to a scientific foundation for the design and prescription of robotic ankle-foot orthoses that will benefit the millions of impaired individuals."
"1734449","NRI: INT: Individualized Co-Robotics","CMMI","National Robotics Initiative","09/01/2017","05/09/2018","Christopher Atkeson","PA","Carnegie-Mellon University","Standard Grant","Irina Dolinskaya","08/31/2020","$1,500,000.00","Steve Collins","cga@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","8013","030E, 034E, 8024, 8086","$0.00","This project explores new ways to meet the needs of individual patients and users with customized active artificial limbs, motorized ankle and knee supports, and other forms of assistive robots. The effectiveness of such devices depends on accommodating person-to-person differences, such as in body types, walking gaits, and impairments. A preliminary study investigated the degree to which an individually adapted sequence of control patterns for a powered ankle exoskeleton -- modified as the subject used the device -- could reduce the metabolic cost of walking. This outcome showed that optimizing the assistive control pattern separately for each subject greatly increased the average benefits compared to the non-optimized device, and outperformed any previously documented approach. This project builds upon those preliminary results to find better and more robust customization methods for a wide range of assistive technology in diverse circumstances.  This approach to ""human-in-the-loop"" optimization of human-collaborative robots could have a wide impact on improved assistive and therapeutic devices and environments that reduce the risk of falls in older adults; help mitigate developmental disorders in children; and assist workers, soldiers, and first responders with physical tasks. Ultimately these customization methods could improve performance of everyday items like shoes and exercise equipment.<br/><br/>The scientific goal of the project is to find optimization approaches to robustly improve co-robotic interaction with users, facilitating physical collaboration. Scaling up to support a variety of devices, joints, behaviors, tasks, environments, and users is also a key goal. The project will explore how long a set of optimized parameters stay valid, how to optimize device behavior during actual use without reducing task performance or device acceptance, and how to assist a variety of behaviors where the user determines when and how a behavior is engaged. In terms of scope, the project will initially focus on how the parameterization of robot behavior, the choice of optimization algorithm, and enhancement of human learning by interaction with a co-robot can all play an important role in achieving this goal.  In terms of methods, the project will use both laboratory-based exoskeleton emulators as well as portable exoskeleton devices that can go outdoors to develop and test ideas and approaches, as well as psychophysical studies that will improve understanding of how muscle is controlled.  Co-optimization involves both the co-robot and the user optimizing their interface policies simultaneously, and thus presenting time-varying targets for each other's optimization.  The project will improve theoretical understanding of co-optimization in the context of physical co-robotics. The project will also add new molecular phenomenon to current muscle models, to provide a physiological basis and understanding of human-robot physical interaction.  The intellectual significance of this work includes better understanding of how humans work, how to most effectively assist humans, and how to best customize assistance for an individual.  A long term goal is to build a library of customized interaction policies for an individual performing a variety of tasks, and tune the library online as the user does desired tasks."
"1718075","RI:  Small:  Collaborative Research:  A Modular Approach to Robot Systems Incorporating Compliant and Soft Elements","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2017","08/13/2017","Ian Walker","SC","Clemson University","Standard Grant","Reid Simmons","08/31/2020","$210,000.00","","iwalker@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","CSE","7495, 8013","7495, 7923, 8086, 9150","$0.00","Biological systems can demonstrate impressive energy efficient manipulation, from picking up fragile objects to lifting heavy weights.  To do so, they rely on building blocks of varying stiffness, such as bones and muscles.  Inspired by these biological systems, this project is investigating the combination of ""stiff"" and ""soft"" robotic components, creating novel ""hybrids"" that exploit the advantages, and conceal the inherent weaknesses, of the individual technologies. Such ""hybrids"" aim to bring safe and practical soft robotics to previously inaccessible domains and applications, including urban search/rescue, disaster relief, and assistance for the elderly and people with disabilities.  The project will also promote robotics among underrepresented groups at both DePaul and Clemson.<br/><br/>The project is collaboratively designing, modeling, creating, and demonstrating a series of innovative soft, modular robots. The modules are exploiting the hard/soft component interaction and constrained actuator arrangement to control stiffness independently from bending. Exploiting modularity, these robots can reassemble, or ""evolve"", into different manipulators and locomotors. The project is developing a unified design and optimization framework to optimize, per user specifications, the composition of hard/soft modules and optimal sensor placement. Resulting modules are fabricated and assembled into a variety of robotic configurations to demonstrate the importance of stiffness modulation in dealing with unforeseen circumstances. Using these modules, the project is also creating a sophisticated physical platform for providing new theoretical insights and innovative operational modes for soft modular robots, as well as demonstrating the fundamentals of morphological computation. Morphological computation utilizes physical body properties (e.g., stiffness and bending shape) as a computational resource that can share the burden of control to optimize stability and locomotion efficiency in real-time. This thrust is exploiting the intrinsic resonant motions of modular systems, via stiffness and shape modulation, to minimize energy loss and improve stability."
"1527165","RI: Small: Vine-Like Continuum Robots","IIS","ROBUST INTELLIGENCE","09/01/2015","08/07/2015","Ian Walker","SC","Clemson University","Standard Grant","Reid Simmons","08/31/2019","$450,000.00","Karl Niklas","iwalker@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","CSE","7495","7495, 7923, 9150","$0.00","The investigators are conducting fundamental research focused on the synthesis of a series of novel ""vine-like"" robots. Vines are found throughout the natural (and human-made) world. They have unique capabilities allowing them to adapt to congested spaces and/or irregular terrain, significant voids, and unpredictable dynamic environmental interactions. Robots emulating the capabilities of vines can extend the reach (literally and figuratively) of robotics into previously inaccessible domains and applications. This offers new and useful solutions across a wide range of endeavors important to society, including persistent environmental monitoring, field archaeology, medical procedures, and urban disaster relief.<br/><br/>Exploiting their combined expertise in continuum robots and biological vines, the PIs are collaboratively designing, modeling, creating, and demonstrating a series of innovative vine-like continuum robots. Coordinated basic research in the laboratory at Clemson and the greenhouse at Cornell is providing inspiration from biology for the vine-like robots, and returning insight from engineering to biology regarding open questions on mechanisms governing biological vines. The key innovations in robot hardware, representing a significant new direction in continuum robotics, are enabling unprecedented workspace reach via augmentation with passive and active appendages (artificial thorns/tendrils), and creating the ability to ""branch"" into new continuum ""growth"". The novel navigation and manipulation capabilities enabled by these hardware innovations are providing both new theoretical insight and innovative operational modes for robots. The overall results are pushing the range of access of robots to a new level, currently beyond the reach of the field."
"1426961","NRI: Autonomous Synthesis of Haptic Languages","IIS","National Robotics Initiative","08/01/2014","08/04/2014","Todd Murphey","IL","Northwestern University","Standard Grant","Reid Simmons","07/31/2019","$585,217.00","J. Edward Colgate","t-murphey@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","8013","8086","$0.00","This project develops algorithms that enable a robot to physically explore its environment using touch and to construct a language that it can use to describe that environment.  The steps include exploring an environment while actively seeking information and then detecting potential elements of a language to describe what was touched.  A secondary phase involves taking the set of language elements and compressing the language itself so that sensing, storage, and communication are all more efficient and more robust.  The work will use a robot equipped with a robotic arm, hand, and fingertip sensors to describe objects and surfaces it encounters, all without any information about the objects provided beforehand. The importance of the work stems from the need for robots to operate in environments where touch is the only reliable sensory source.  For instance, underwater applications often have limited visibility and dexterous manipulation can suffer from visual occlusion due to the hand itself.  This research will enable robots to be more responsive to touch and more reliable in vision-impoverished environments.<br/><br/>A key technical tool used in this work is ergodic control, a computational technique that finds exploration strategies matching desired statistics.  Symbol detection involves finding definitions of dynamic sensor evolution that minimize measures of variability.  Language minimization depends on computing the entropy of a language, and finding the minimal language that has the same level of expressiveness.  These three mathematical and algorithmic components need to be used in parallel during language creation, and they each have to respect physical limitations on the part of the robot (e.g., computational limitations and physical limitations).  Software will be shared through the Robot Operating System (ROS) and TREP (physical simulation and optimal control software).<br/>"
"1734600","NRI: FND: COLLAB: An Open-Source Robotic Leg Platform that Lowers the Barrier for Advanced Prosthetics Research","CMMI","National Robotics Initiative","10/01/2017","08/16/2017","Robert Gregg","TX","University of Texas at Dallas","Standard Grant","Irina Dolinskaya","09/30/2020","$193,000.00","","rgregg@utdallas.edu","800 W. Campbell Rd., AD15","Richardson","TX","750803021","9728832313","ENG","8013","030E, 034E, 8024, 8086","$0.00","The objective of this project is to provide researchers with access to a fully capable and standardized open-source robotic leg research platform, without the immense burden of developing each component from scratch. The outcome will be a robust and inexpensive test bed that can be easily manufactured, assembled, and controlled. One of the greatest challenges to the design and commercialization of robotic prosthetic legs is the control strategy -- that is, the computerized instruction set that specifies the effort level and timing for each component of the mechanism. Challenges in developing control strategies stem from the many different functions that an active robotic limb must accomplish. One important function is to detect the amputee's intention to perform different mobility activities, such as walking on a level surface versus ascending or descending stairs. Another important function is to coordinate the pattern of effort and movement of the prosthetic limb in order to emulate the healthy human body. There are many researchers working independently on better control algorithms to address challenges such as these. To be of value, these algorithms must be tested and validated experimentally. Research groups around the world have created a variety of specialized robotic leg designs for this purpose, representing a significant investment of time and effort. The resources required to obtain a suitable research platform represent a substantial obstacle for new researchers to overcome. Furthermore, the vast difference in designs used by established researchers hinders the comparison of new control strategies across research groups. The accessible, standardized leg platform resulting from this project will lower barriers to entry, allowing new researchers to study the control of robotic legs, to unambiguously compare different control approaches, and to generally advance the field. Finally, the improved prosthetic leg designs arising in the long term from this project will benefit the lives of amputees.<br/> <br/>The overall research goals of this project are 1) to identify an electromechanical design for a low cost, high performance, open-source robotic knee and ankle system; 2) to understand how separate prosthesis control strategies can be combined to benefit amputee gait, and 3) to evaluate and compare resulting controllers in amputee experiments. The approach utilizes a novel design methodology employing selectable series elasticity and high-torque motor technology to achieve high performance at low cost. Interchangeable control modules in the open-source architecture allow researchers to investigate new control methods at low, mid, and high levels of the system, that is, motor drive, joint control, and human intent recognition, respectively. In particular, a reflex-based approach and a phase-based approach will be implemented as mid-level control modules and a high-level intent recognition module will enable the robotic leg to automatically switch between different user activities. In all cases, having the new robot leg available together with these algorithms will enable testing in real-world scenarios, rather than being confined to the laboratory. The results of this project will lower the barrier for conducting research and enable fair comparison across different control approaches with standardized leg hardware. Finally, the proposed work will impact students and the community through training, outreach, and dissemination."
"1842051","Doctoral Consortium at the 2018 International Symposium on Experimental Robotics (ISER 2018)","IIS","ROBUST INTELLIGENCE","08/01/2018","07/25/2018","Jing Xiao","MA","Worcester Polytechnic Institute","Standard Grant","David Miller","07/31/2019","$15,000.00","","jxiao2@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","7495","7495, 7556","$0.00","This project will provide travel funds for 15-20 US-based students to attend the 2018 International Symposium on Experimental Robotics (ISER) in Buenos Aires, Nov 5-8, 2018, and participate in the doctoral consortium. The symposium features both invited and selected research presentations that focus on robotics research that has been validated through experimental results. This unique conference presents the latest advances across various fields of robotics, with ideas that are not only conceived conceptually but also explored experimentally. It has a high visibility in the international robotics research community as well as a high relevance to applications due to its emphasis on experimental validation. ISER 2018 will provide excellent opportunities for students to learn about the latest advances across a wide spectrum of robotics research, development, and applications and to network with seasoned researchers and practitioners in the worldwide robotics community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1719291","NRI: Collaborative Goal and Policy Learning from Human Operators of Construction Co-Robots","IIS","National Robotics Initiative","08/01/2016","09/14/2017","Girish Chowdhary","IL","University of Illinois at Urbana-Champaign","Standard Grant","Reid Simmons","07/31/2019","$703,235.00","","girishc@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","8013","8086","$0.00","The overall goal of this research is to investigate and significantly advance the science of collaborative interaction between human operators and co-robots. This includes the development of algorithms that can be used to train co-robots from skilled human operators to efficiently perform complex tasks in the face of real-world uncertainty, and to guide novice operators in performing such tasks. The primary targeted application is the construction and farming equipment industry that includes complex co-robots such as excavators, wheel loaders, tractors, forage harvesters where there is a significant need to understand and improve human-robot collaborative learning.<br/><br/>There are significant scientific challenges in developing efficient algorithms for co-robots that can actively learn from skilled human operators by observing and posing appropriate queries to close the feedback loop between the co-robot and the human operator. This project addresses these challenges by systematically formulating and investigating focused problems to create efficient algorithms that can enhance collaborative human-robot learning. To achieve the goal, algorithms are designed to collaboratively learn latent subgoal structures from ill-defined complex tasks, real-time path planning and control algorithms are developed for co-robots to achieve the learned subgoals, and techniques are developed to provide operator skill specific task decomposition and motion execution guidance. In addition, the developed algorithms are corroborated by simulators, hardware experimentation on laboratory and field co-robots, and theoretical analysis.<br/>"
"1328018","NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","IIS","National Robotics Initiative","10/01/2013","09/25/2013","Steven Lavalle","IL","University of Illinois at Urbana-Champaign","Standard Grant","Jie Yang","09/30/2018","$300,000.00","","lavalle@cs.uiuc.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","8013","7298, 7925, 8086","$0.00","Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation.  The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br/><br/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM."
"1464737","NRI: Human Cognition Assisted Control of Industrial Robots for Manufacturing","CMMI","National Robotics Initiative","12/01/2014","06/22/2018","T. Kesavadas","IL","University of Illinois at Urbana-Champaign","Standard Grant","Bruce M. Kramer","07/31/2019","$558,527.00","","kesh@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","8013","087E, 092E, 6840, 8086, 8091, MANU","$0.00","Advanced manufacturing, driven by industrial robots, is playing an increasing role in US economy. Robots are being used to carry out assembly, welding, material handling and fabrication. Even as such interactions are becoming more common in every phase of manufacturing, a perfect symbiotic relationship between machines and human beings is still very far away. Because of this, a majority of the robotic applications in manufacturing are currently limited to areas where a relatively low level of skill is required. This has restricted the full potential of robotics to augment human operators and improve productivity and quality of life. With recent advances in cognitive neuroscience and brain interface technologies, connecting the human cognitive thought process directly to robots and machines is possible, resulting in direct control of real world applications. By collecting the brain signals using sensors and analyzing the thought processes, many activities that take place inside the brain when humans take specific actions or think of actions can be identified and matched to known signals using fast computation. This new human-robot communication paradigm will be demonstrated by developing three manufacturing scenarios. The project will also have broad applicability in the design of robotic systems in fields outside manufacturing, including telesurgery, rehabilitation and space exploration. Results from this multidisciplinary research, which combines manufacturing, computer science and robotics, have the potential to improve the productivity of future manufacturing plants and can lead to new commercial ventures, which will help the US maintain global leadership in robotics and manufacturing, broaden participation of underrepresented groups in research, and positively impact engineering education.<br/><br/>Significant future challenges in the development of a new human-robot communication system, which allows operators to perform complex high skilled tasks, will be addressed. The postulated paradigm will be explored by meeting the following intellectual challenges: (i) researching a novel methodology for communicating motion commands to a robot by imagining simple actions using a grammar called ""actemes,"" (ii) new brain-computer mode and algorithms to classify these actemes and, (iii) an intent-based system that auto-completes robotic actions based on most likely sequence of events that human operators are planning to complete. Three robotic manufacturing scenarios will be explored to demonstrate the human cognition based interactions in manufacturing environment: assembly, direct control, and quality control through object recognition. Finally, by using a non-invasive brain-computer interface a wide range of day-to-day applications of robotics will be demonstrated."
"1734456","NRI: FND: Human-Robot Collaboration with Distributed and Embodied Intelligence","SES","SCIENCE, TECH & SOCIETY, National Robotics Initiative","08/01/2017","08/04/2017","John Zimmerman","PA","Carnegie-Mellon University","Standard Grant","Frederick M Kronz","07/31/2020","$699,540.00","Aaron Steinfeld","johnz@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","SBE","7603, 8013","8086, 9179","$0.00","This award supports research on the issue of intelligence re-embodiment in robots. The fundamental question to be addressed is whether robots should be designed so that different synthetic intelligences can take over. A smart phone can be repurposed to serve different users by swapping chips. Should robots with much higher functionality be designed so that they operate in a suitably similar way? The goal of this project is to answer this question along with a number of related questions including the following. Should robots be designed so different intelligences can take over? Where does the locus of intelligence sit? How does the user understand where it is and who or what is in control? How does re-embodiment impact issues of privacy? To answer these questions, this research effort will adopt a mixed-methods approach including surveys, fieldwork, simulations, and on-site testing of a robot operating system module. The findings of this work are expected to have direct value to robot developers and other researchers. Other impacts include interdisciplinary training of PhD students, and creating research opportunities for undergraduates. Team members plan to use the results of this research to enrich courses on human-robot interactions, and in outreach activities to engage non-academic audiences.<br/><br/>This research project uses a variety of methods to study the issue of intelligence re-embodiment in robots. Team members will conduct online surveys to systematically assess factors related to re-embodiment. They will engage in fieldwork to investigate current practices of people working and living in environments with several intelligent systems. These findings will in turn be used to inform a user enactment study that will create simulations of real-world contexts and test participants' reactions to different robot behaviors. Team members will also extract and evaluate a set of generalized interaction principles using a second online study. In addition, they will develop a robot operating system (ROS) module to enable re-embodiment of robots by a cloud-based intelligence; the module will be used to assess reactions of business owners and other stakeholders interacting with these systems. The results of these research components will advance knowledge on how people understand re-embodiment. They will serve to map out a set of design recommendations, design features, and the corresponding interaction patterns that do not yet exist around robot behavior in different contexts. They will also lead to the production of software components that support re-embodiment by remote intelligences. More generally, they will help achieve a vision of fully collaborative, ubiquitous, interconnected co-robot systems."
"1734558","NRI: INT: Learning-Enabled Robot Support of Daily Activities for Successful Activity Completion","IIS","National Robotics Initiative","09/01/2017","03/26/2018","Diane Cook","WA","Washington State University","Standard Grant","Wendy Nilsen","08/31/2021","$999,999.00","Matthew Taylor, Maureen Schmitter-Edgecombe, Diane Cook","cook@eecs.wsu.edu","280 Lighty","PULLMAN","WA","991641060","5093359661","CSE","8013","8086","$0.00","The population is aging - the estimated number of individuals over the age of 85 will triple by 2050. Even in our current population an estimated 9% of adults age 65+ and 50% of adults age 85+ need assistance with everyday activities, and the annual cost for the United States is roughly $2 trillion. Given the economic and quality of life costs, there is a critical need to better use smart technologies so that individuals can live independently in their own homes, helping both individuals and society as a whole. This proposed work will create a novel multi-agent robot system, called Robotic Activity Support (RAS), that provides in-home activity support for older adults and others that need assistance to independently perform common activities of daily living. The system will rely on cooperation between a smart home and a mobile robot to learn activity routines for an individual. RAS will use this information to provide activity interventions that help smart home residents initiate and successfully complete important daily activities and improve functional independence. <br/><br/>Rather than explore co-robot systems with multiple identical platforms, the system will represent a collaboration between a mobile robot, a smart home agent with multiple heterogeneous sensors and multiple humans with distinct roles. For this collaboration, the project team will employ a custom robot that will partner with the team's CASAS smart home architecture.  RAS will incorporate caregiver-in-the-loop active learning to improve its models. the team will use an iterative user-centered development process to enhance the mobile robotic platform design. The RAS system will use active learning from both the resident and caregiver to learn common activities and how it can support such activities. For example, the robot may prompt a resident to eat breakfast if she does not initiate the task at the normal time, remind the resident where the cereal is, and notify a nearby caregiver if help is needed that is beyond the robot's capabilities. The team will evaluate RAS on historic smart home data (from their more than 100 deployments), in their on-campus smart home, and in a home with a healthy older adult caregiver, as well as an older adult exhibiting cognitive limitations."
"1637853","NRI: Design and Fabrication of Robot Hands for Dexterous Tasks","IIS","National Robotics Initiative","08/01/2016","08/01/2016","Nancy Pollard","PA","Carnegie-Mellon University","Standard Grant","James Donlon","07/31/2019","$769,906.00","Stelian Coros","nsp@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","8013","8086","$0.00","Dexterous manipulation is a Grand Challenge in robotics today.   Dexterity is required for robots working in the home, in space, for medical applications, disaster scenarios, and flexible manufacturing.    Robots in these environments must be able to maneuver, lift, and handle objects, use them as tools, and competently transfer objects from one secure hold to another in a wide variety of uncertain situations.   Such operations are very difficult for robots and present a barrier to their wider adoption.    Recent advances in rapid prototyping and digital manufacturing have made it possible to design, manufacture, and test custom robot manipulators at a very rapid pace.    One aim of this project is to explore and understand how these new technologies may be used to design a radically different type of robot manipulator that is customized for dexterous maneuvers.  A second aim of the project is to increase our fundamental understanding of dexterity itself.   The end goal is to enable robots to live up to their potential. In so doing, robots will begin to play an increasingly important role in our daily lives, and will inspire young students to prepare for, and pursue STEM careers.<br/><br/>The key research goal of this project is to formalize novel mathematical models and computational approaches to co-design mechanical structures and control policies for dexterous robotic manipulation tasks.   Through this approach, control policies can be made significantly simpler, and mechanical features such as joint stops and compliance can passively improve the robustness of the manipulation tasks while reducing sensing and actuation requirements. Grasp nets, which capture specific families of manipulation capabilities observed in human performances, focus the efforts of this project and guide the design processes that are developed."
"1344227","INSPIRE Track 1: Is Evolvability Driven By Emergent Modularity? Biomimetic robots, gene inspired information structures, and the evolvability of intelligent agents","DEB","INFORMATION TECHNOLOGY RESEARC, CROSS-EF ACTIVITIES, INFO INTEGRATION & INFORMATICS, EVOLUTIONARY GENETICS, ANIMAL BEHAVIOR, INSPIRE","01/01/2014","07/16/2014","Kenneth Livingston","NY","Vassar College","Continuing grant","George W. Gilchrist","09/30/2019","$999,314.00","Jodi Schwarz, John Long, Marc Smith, Joshua Bongard","livingst@vassar.edu","124 Raymond Avenue","Poughkeepsie","NY","126040657","8454377092","BIO","1640, 7275, 7364, 7378, 7659, 8078","1640, 7275, 7364, 7378, 7659, 8653, 8750","$0.00","This INSPIRE award is partially funded by the Evolutionary Processes program in the Division of Environmental Biology in the Directorate for Biological Sciences, the Behavioral Systems program in the Division of Integrative Organismal Systems in the Directorate for Biological Sciences, and the Information Integration and Informatics program in the Division of Information & Intelligent Systems in the Directorate for Computer & Information Science & Engineering.<br/><br/>For millennia, humans have bred organisms to produce better food, clothes, and companionship. Recently, scientists have learned how to breed robots, evolving simulated creatures in virtual worlds, or physical robots in the real world.  By combining the evolutionary process with robotic engineering, more complex and novel designs should be possible compared to traditional methods.  In spite of the promise, so far evolved robots only do simple things like walk, navigate, or pick up objects. What limits progress is a lack of understanding of ""evolvability,"" the capacity of organisms (or robots) to change and become more complex.  Understanding evolvability is the main goal of this project: researchers will borrow ideas from modern genetics so their robots mutate and develop in ways that are similar to how biological creatures do. In theory, this could produce simple robots that evolve into ever more complex, capable and useful robots.<br/><br/>Understanding how complexity evolves is central to the study of life, and may enable even non-specialists to automatically and continuously produce diverse kinds of machines.  By linking complexity, genetics, and evolution, this project seeks to discover new principles that can be applied in science and industry.  To help convert scientific principles into innovation drivers, online software will be created to show how to evolve virtual or physical robots; this will help students learn about engineering, biology, and how to apply both to technology.  Finally, evolutionary robotics can be used to solve complex problems in robotic control that defy logical programming solutions, so this research can help companies that manufacture robots."
"1637838","NRI: Achieving Selective Kinematics and Stiffness in Flexible Robotics","CMMI","National Robotics Initiative","12/01/2016","08/20/2016","Robert Howe","MA","Harvard University","Standard Grant","Irina Dolinskaya","11/30/2019","$547,508.00","Katia Bertoldi","howe@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","ENG","8013","8086","$0.00","This research project will employ an effect called laminar jamming to create robotic structures that controllably transition between highly compliant and nearly rigid. Precise position control typically requires rigidity, while safe and comfortable interactions with humans requires compliance. The need to incorporate both characteristics arises, for example, in assistive applications such as tremor suppression in Parkinson's disease. It is also necessary for robots working collaboratively with humans in manufacturing settings. Laminar jamming structures are composed of multiple parallel layers that ordinarily slide easily over each other. However, when the laminar structure is squeezed the layers become locked together by friction forces. This project will derive computationally tractable models of laminar structures under external forcing, to enable parametric design and real-time control. Fabrication of laminar jamming devices is simple and inexpensive, lowering barriers to widespread use, both in commercial applications and in educational settings. To ensure dissemination of the results, reference designs, configurations of jamming elements, application prototypes, and testing and performance data will be posted on a popular soft robotics website.<br/><br/>The combination of laminar jamming and soft robotics opens an entirely new range of robot designs and behaviors. Because the bending stiffness of a beam is proportional to the third power of its thickness, even a few laminae can produce dramatic increases in stiffness when jammed. The goal of this project is to define the capabilities of the technology and derive and validate the fundamental underlying principles. The project consists of three research subtasks: actuator design and testing, computational and analytical modeling, and implementation of key applications. The results of the project will provide a rich set of building blocks for robots that combine the advantageous features of both soft and rigid robots."
"1637758","NRI: Collaborative Research: Accelerating Robotic Manipulation with Data-Enhanced Contact Mechanics","IIS","National Robotics Initiative","09/01/2016","07/27/2016","Byron Boots","GA","Georgia Tech Research Corporation","Standard Grant","Jie Yang","08/31/2019","$452,219.00","","bboots@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","8086","$0.00","Robotic manipulation depends upon mechanical contact between robot and object.  A better understanding of mechanical contact enables a wider range of more flexible manipulation techniques, which in turn enables the applications of greatest societal benefit such as eldercare, disaster response, or surgery.   This project is developing a broader and more accurate understanding of frictional contact, using a fusion of physics and data.  The project combines recent advances in a physics-based understanding of frictional contact with new machine learning techniques applied to a large corpus of experimental data.  One operation of great interest is manipulation of an object held in the robot gripper, even when the gripper is very simple.  Other operations of interest are handling objects in clutter, and manipulation of flexible objects, such as clothing.<br/><br/>The project is attacking several central challenges: modeling frictional contact, modeling deformation, measuring small motions and interaction forces, gathering large amounts of data, and developing techniques for learning in a closed-loop system.  Parametric and semi-parametric models enable the project to apply engineering models enhanced with observation data, for both planning and control.  New machine learning techniques such as predictive state representations (PSRs) enable identification and modeling of previously hidden state, as well as learning in closed-loop systems.  New infrastructure enables gathering of relevant, precise data, on a large scale.  The project is developing and employing a Robotic Manipulation Arena, with a unique combination of manipulation resources and instrumentation to provide high volumes of high quality experimental data.  The primary outcomes are robust and practical contact models, so that robots can work more dexterously and opportunistically."
"1659746","REU Site: Robots in the Real World","IIS","RSCH EXPER FOR UNDERGRAD SITES, ROBUST INTELLIGENCE","02/15/2017","02/13/2017","Cindy Grimm","OR","Oregon State University","Standard Grant","Wendy Nilsen","01/31/2020","$360,000.00","William Smart","grimmc@onid.orst.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","1139, 7495","9250","$0.00","This Research Experiences for Undergraduates (REU) Site will inspire students with the possibilities inherent in multi-disciplinary research in robotics. They will complete the program excited about continuing to do research in robotics, having the necessary tools to successfully transition to graduate-level research, and achieve further academic progress and research at their home institutions.  Robotics is a multi-disciplinary field ranging from mechanical design, to understanding physical systems, to exploring human-robot interaction. This array of skills makes it both a challenging and exciting field of study for many undergraduates, but exploiting that appeal can be challenging for a small institution because of the inherent infrastructure cost. This site is particularly targeted at academic institutions that do not have extensive robotics infrastructure, and to enable students at those institutions to both successfully compete for graduate positions and bring back robotics culture to their home institutions. <br/><br/>The design of this REU site contains a number of programmatic elements designed to teach undergraduates how to approach research, what life as a graduate student is like, and how to write solid graduate applications. Broadly speaking, the research in robotics focuses on physical robots operating in the real world, and the challenges inherent in designing, building, controlling, and interacting with them in complex environments. One intangible but important benefit to a summer REU program is networking - meeting students with similar interests who, potentially, will go on to graduate school in related areas, and even, long-term, into faculty positions. This site has several mechanisms to support the creation of these networks, from peer-to-peer mentoring and shared activities through longer-term social networking tools. These long-term relationships will help to form multi-disciplinary bridges in the next generation of researchers in robotics."
"1637908","NRI: Collaborative Research: Accelerating Robotic Manipulation with Data-Enhanced Contact Mechanics","IIS","National Robotics Initiative","09/01/2016","07/27/2016","Matthew Mason","PA","Carnegie-Mellon University","Standard Grant","Jie Yang","08/31/2019","$422,050.00","","matt.mason@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","8013","8086","$0.00","Robotic manipulation depends upon mechanical contact between robot and object.  A better understanding of mechanical contact enables a wider range of more flexible manipulation techniques, which in turn enables the applications of greatest societal benefit such as eldercare, disaster response, or surgery.   This project is developing a broader and more accurate understanding of frictional contact, using a fusion of physics and data.  The project combines recent advances in a physics-based understanding of frictional contact with new machine learning techniques applied to a large corpus of experimental data.  One operation of great interest is manipulation of an object held in the robot gripper, even when the gripper is very simple.  Other operations of interest are handling objects in clutter, and manipulation of flexible objects, such as clothing.<br/><br/>The project is attacking several central challenges: modeling frictional contact, modeling deformation, measuring small motions and interaction forces, gathering large amounts of data, and developing techniques for learning in a closed-loop system.  Parametric and semi-parametric models enable the project to apply engineering models enhanced with observation data, for both planning and control.  New machine learning techniques such as predictive state representations (PSRs) enable identification and modeling of previously hidden state, as well as learning in closed-loop systems.  New infrastructure enables gathering of relevant, precise data, on a large scale.  The project is developing and employing a Robotic Manipulation Arena, with a unique combination of manipulation resources and instrumentation to provide high volumes of high quality experimental data.  The primary outcomes are robust and practical contact models, so that robots can work more dexterously and opportunistically."
"1619278","RI: Small: Collaborative Research: Micro-Assembly Exploiting SofT RObotics (MAESTRO)","IIS","ROBUST INTELLIGENCE, Unallocated Program Costs","07/01/2016","06/20/2017","Aaron Becker","TX","University of Houston","Continuing grant","Reid Simmons","06/30/2019","$209,308.00","","atbecker@uh.edu","4800 Calhoun Boulevard","Houston","TX","772042015","7137435773","CSE","7495, 9199","7495, 7923, 9251","$0.00","The MAESTRO project will develop a new type of manufacturing by combining soft robotics and swarm control to construct assemblies in 2D and 3D from individual artificial cells made of hydrogels. MAESTRO will design rules for building tiny factories so that, like a conductor?s baton, global control signals will organize artificial cells into complex configurations. These artificial cells can contain living cells and be assembled into tissue for artificial organs, or contain inorganic particles to assemble into micro-scale tools. <br/><br/>MAESTRO will ferry desired components in artificial cells constructed from polysaccharide-based hydrogels. Current approaches use engineered structures or live bacteria as micro-scale actuators to push or pull desired objects into place. The proposed approach uses the soft robots themselves as building blocks for desired patterns. The artificial cells excel at encapsulating a wide range of micro and nano-sized particles, for example living cells and magnetic nanoparticles. Furthermore, artificial cells can be triggered to efficiently release their payloads. Novel swarm control algorithms using obstacle-based particle computation will steer the cells. In traditional robotics, simultaneous control of multiple robots is based on individual motion control that requires heterogeneity among robots or the ability to deliver multiple input signals; both approaches are currently impractical in small-scale systems.  However, these challenges can be overcome by parallel motion planning in obstacle-filled workspaces. This obstacle-based positional control makes the position of microrobots fully controllable using just a single control input. Actuation of these stimuli-responsive artificial cells in micro-fluidic, obstacle-laden environments presents a paradigm shift in fabrication technology.<br/>"
"1825993","Risk-Aware Planning and Control of Robot Motion Including Intermittent Physical Contact","CMMI","Dynamics, Control and System D","09/01/2018","07/24/2018","Ludovic Righetti","NY","New York University","Standard Grant","Irina Dolinskaya","08/31/2021","$348,106.00","","lr114@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","ENG","7569","030E, 034E, 8024","$0.00","This project considers the problem of planning and controlling motions that involve intermittent physical contact. These motions include such tasks as walking across unexplored terrain, or manipulating an object with poorly known weight, shape, or surface roughness. The project approaches this problem in two ways. The first builds upon findings that humans respond to uncertainty by varying the effective springiness of their limbs. The project will formulate a corresponding approach to robot control by finding the robot limb stiffness that minimizes a probabilistic measure of risk under uncertain initial conditions. That is, the first part of the project will find the best possible outcome of a movement, while taking into account a spread of possible starting points. The second part of the project addresses the challenge of considering all the ways in which small changes to intermittent contacts -- such as when a foot hits the ground, or where a finger touches a tool -- can propagate through a larger task. There are efficient methods to handle such variability when the problem being study has a property called ""convexity,"" which allows for efficient partitioning and search of the space of solutions. Contact problems do not have this desirable property, however the project will explore ways to approximate the true problem by a sequence of convex problems. Walking and grasping robots will increasingly help human co-workers in manufacturing settings, and assist elderly and disabled citizens in everyday tasks. This project will promote the national health and prosperity by improving the performance and reliability of robotic walking and grasping. The results are not limited to robotics and will also be beneficial in bio-mechanics and human motor control research, where they could suggest an explanatory framework for analyzing human behavior.<br/><br/>The project will characterize the optimal mechanical impedance modulation for robust contact interactions and provide a methodology to compute motions that are open-loop robust despite environmental uncertainties. It will leverage recent results in risk-sensitive optimal control and robust optimization to explicitly consider uncertainty about the environment while ensuring low computational complexity. The last but key objective of the project is to conduct extensive robotic experiments with a one-legged jumping robot, a manipulator grasping unknown objects, a quadruped walking and jumping and a humanoid robot climbing up high steps using its arms and legs therefore demonstrating the general applicability of the methodology in realistic and diverse robotic scenarios. The experiments seek to clarify the influence of external disturbances and environmental uncertainty on optimal impedance modulation and robust movements. Additionally, they will shed light on the important factors enabling robust execution of complex tasks in unknown environments. The project will also compare the optimal leg impedance predicted by the established modeling methodology with human walking data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637736","NRI: Robots that Learn to Communicate through Natural Human Dialog","IIS","National Robotics Initiative","09/01/2016","08/01/2016","Raymond Mooney","TX","University of Texas at Austin","Standard Grant","Tatiana D. Korelsky","08/31/2019","$936,906.00","Peter Stone","mooney@cs.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","8013","8086","$0.00","Robots are increasingly capable and are on the threshold of becoming a ubiquitous technology. For robots to be truly useful, people must be able to effectively communicate their needs in everyday human language. Although there is a growing body of research on natural-language processing for human-robot interaction, it typically requires some form of explicit supervision provided by an engineering expert and involves unnatural, laborious training to obtain robustness and coverage. This project involves the development of human-robot dialog systems that learn to communicate with users through natural dialog, learning from repeated normal user interactions to become more robust and capable. The project supports the education of students in the areas of natural-language processing, human-robot interaction, and machine learning, where there is significant demand for educated personnel.  It is integrated with the university's  Freshman Research Initiative, which gets undergraduate students involved in research in their first year.<br/><br/>In order to develop human-robot dialog systems that learn to improve their communication skills through normal user interactions, the project integrates and adapts learning techniques from three currently disparate technical areas: semantic parsing, spoken dialog management, and perceptual language grounding.  The project adapts and integrates techniques for semantic-parser learning using combinatory categorial grammar (CCG), dialog management using Partially Observable Markov Decision Processes (POMDPs), and multi-modal language grounding using both visual and haptic sensors, in order to develop a dialog system for communicating with robots that comprise the Building Wide Intelligence (BWI) system being developed at the University of Texas at Austin. The research integrates the PI's expertise in semantic parsing and language grounding with the co-PI's expertise in robotics and reinforcement learning, forming a unique interdisciplinary team for developing novel and effective systems for human-robot interaction. The project includes rigorous evaluations using controlled experiments on a range of tasks using both on-line simulations with crowdsourced users, and natural user interaction with a mobile robot platform consisting of a wheeled Segway base and a Kinova robot arm being developed for the BWI system."
"1764092","CHS: Medium: Data-Mediated Communication with Proximal Robots for Emergency Response","IIS","Cyber-Human Systems (CHS)","09/01/2018","07/23/2018","Daniel Szafir","CO","University of Colorado at Boulder","Continuing grant","Dan Cosley","08/31/2021","$420,977.00","Danielle Szafir, Christoffer Heckman","daniel.szafir@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","7367","7367, 7924","$0.00","Robots may augment emergency response teams by collecting information in environments that may be dangerous or inaccessible for human responders, such as in wildfire fighting, search and rescue, or hurricane response. For example, robots might collect critical visual, mapping, and environmental data to inform responders of conditions ahead that could improve their awareness of the operational environment. These data would assist in planning and re-planning courses of action and enhance in-the-field decision making. However, response teams currently have little ability to directly access robot-collected information in the field, despite its value for rapidly responding to local conditions, because current systems typically route the data through a central command post. This project's goal is to design systems that support more direct access and analysis for first responders while not imposing additional distractions or operational risks through using faulty data. Through collaboration with several local response groups, the project team will develop better understandings of responders' needs and concerns around robot-collected data, algorithms and visualizations that meet those needs using augmented reality technologies, and systems that integrate well with responders' actual work practices. The project will also develop a series of demonstrations, outreach activities, and technology challenges based on the project goals aimed at increasing public interest in science, including among high school students and underrepresented groups in computer science. <br/><br/>Overall, this research will develop fundamental knowledge in robotics and visualization, leading to new methods and tools that enable responders to take advantage of robot-collected data while in the field. In particular, this project will explore how see-through augmented reality head-mounted displays (ARHMDs) might offer an intuitive and powerful medium for in situ analysis of robot-collected data through developing an ARHMD system that allows emergency responders to interact with robot-collected information in the contexts of where, when, and how that data was obtained. The team will conduct empirical studies to guide the design of system components that allow responders to actively analyze available data through interactive visualization, passively view digital traces and ""data drops"" left by robots as they collect information about the environment, and query specific information such as camera feeds on-demand. The team will also develop novel algorithms for 3D scene reconstruction and simultaneous location and mapping that will be useful for a broad variety of applications. Overall, the project will contribute empirical knowledge of how different factors of ARHMD visualizations influence data interpretation, novel algorithms for estimating, correcting, and sharing maps between intermittently-networked agents in the field, and information regarding how data from collocated robots can mediate human-robot interactions, particularly within the context of emergency response.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1526424","NRI: Collaborative Research: Versatile Locomotion: From Walking to Dexterous Climbing With a Human-Scale Robot","IIS","National Robotics Initiative","09/01/2015","08/06/2015","Katie Byl","CA","University of California-Santa Barbara","Standard Grant","Reid Simmons","08/31/2019","$454,868.00","","katiebyl@ece.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","CSE","8013","8086","$0.00","The project aims to give legged robots the skills to navigate a wide variety of terrain.  This capability is needed to employ robots in applications such as search-and-rescue, construction, and exploration of remote environments on Earth and other planets. The multidisciplinary team, composed of researchers at Duke, Stanford, UC Santa Barbara, JPL, and Motiv Robotics, will develop a robot to climb a variety of surfaces ranging from flat ground to overhanging cliffs. Using an array of sensors, unique hands, and sophisticated algorithms, the robot will dynamically adopt walking, crawling, climbing, and swinging strategies to traverse wildly varied terrain. During the course of this research, the team hopes to achieve the milestone of the first demonstration of a human-scale rock climbing robot. The research is also expected to lead to insights into cognitive and biomechanical processes in human and animal locomotion.<br/><br/>Although rock climbing serves as an ideal proving ground for the work, this project conducts basic research to address more a general-purpose goal; namely, to provide the physical and cognitive skills for robots to adaptively navigate varied terrain. It takes a dexterous climbing approach, which uses non-gaited, coordinated sequences of contact to move the body, much as dexterous manipulation uses contact with the fingers and palm to move an object.  It will apply principles from optimization, machine learning, bioinspiration, and control theory to make intellectual contributions in several domains, such as robot hand design, planning algorithms, balance strategies, and locomotion performance measurement.  Novel grippers, sensor-based planning strategies, reactive maneuvers, and locomotion metrics will be developed during the course of this research."
"1718801","PFI:BIC Affordable Flexible Robotic Technology to Enhance Work Performance of Farmers with Mobility Restrictions","IIP","PARTNRSHIPS FOR INNOVATION-PFI, Disability & Rehab Engineering, IIS SPECIAL PROJECTS","07/15/2017","07/21/2018","Alexander Leonessa","VA","Virginia Polytechnic Institute and State University","Standard Grant","Jesus Soriano Molla","06/30/2020","$1,014,677.00","Donatus Ohanehi, Alan Asbeck, Robert Grisso, Kimberly Niewolny, Divya Srinivasan","leonessa@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","ENG","1662, 5342, 7484","116E, 1662, 8019, 9251","$0.00","A growing elderly population is creating a crisis in the farming industry. With the lack of alternative solutions available, robotics could become a welcomed approach for assisting farmers and farm workers with mobility limitations and strength deficits. This award leverages an interdisciplinary academe-industry partnership to jointly develop flexible robotic systems that are designed to be wear by farmers with mobility limitations to assist them in performing activities of daily living. The research team's goal is not only to adapt state-of-the-art flexible robotics technology to the needs of farmers with mobility limitations, but also to educate stakeholders regarding the availability and role of assistive technology to augment their performance at work and improve their quality of life. In particular, the funded effort consists of a combination of 1) technology development in order to take out-of-the-box flexible robotics technology and make it suitable to this particular population; 2) development of a test bed which will allow for technology testing in typical daily activities; 3) coordination of a service delivery system to provide education, health-based agricultural resources, and community-based services  addressing  life and farm-based goals of farm workers and farm families. <br/><br/>The research team aims at demonstrating a new use of flexible robotics for the care of farmers and farm workers while performing their daily activities. The investigators will advance knowledge on the actual design of wearable robots (both hardware and software) that can perform a set of tasks to facilitate farmer's mobility and decrease the possibility of secondary injuries. Specifically, the researchers will develop modules to support the back, knee, and hand and assist with motion of these joints. The research plan includes understanding the motions and activities typically performed by farmers, designing the robotic modules to be comfortable and compatible with being worn daily; understanding the user inputs and adapting control algorithms that will enable the robotic modules to best assist with their wearers' mobility; add and study the impact of flex-sensors and force sensors into the structure of some modules. Additionally, motion information collected by the system will help create a data-driven health monitoring system whereby health service providers could understand how a patient's mobility is changing over time.  Undergraduate students will be involved in supplementing graduate student work, in interactions with client farming communities, and in ground-level activities aimed at educating the public in innovative, assistive technologies for people with disabilities. The PFI project plan for educational outreach includes several activities such as summer camps, senior design capstone design experiences, and service learning opportunities for engineering and agriculture students.<br/><br/>The lead institution is Virginia Tech with faculty from Mechanical Engineering, Agricultural Leadership, and Community Education, Industrial and Systems Engineering, Engineering Education and the Virginia Cooperative Extension.  The primary industrial partners are TORC Robotics (small business, Blacksburg, VA), and Total Motion Physical Therapy (small business, Blacksburg, VA) together with two nonprofit broader context partners, AgrAbility Virginia (nonprofit, Salem, VA) and Easter Seals UCP (United Cerebral Palsy, Salem, VA). It is expected that this partnership will have broader impacts across the National AgrAbility community where engineers, service providers, and industry professionals collaborate to assist injured or disabled farmers in their respective states. In addition, AgrAbility Virginia will provide the means for education, evaluation, and farmer participation in the system design. The synergy of all the institutions involved in this project will facilitate the translation of research and education outcomes to the broad community of farmers."
"1742127","Designing Biomimetic Robots:  Researching the impact of an interdisciplinary bio-engineering-computational design curriculum on middle school engineering and science education","DRL","STEM + Computing (STEM+C) Part","08/01/2017","07/28/2017","Debra Bernstein","MA","TERC Inc","Standard Grant","Amy Baylor","07/31/2020","$1,198,780.00","Gillian Puttick, Ethan Danahy, Kristen Wendell","debra_bernstein@terc.edu","2067 Massachusetts Avenue","Cambridge","MA","021401339","6178739600","EHR","005Y","","$0.00","The project is funded by the STEM+Computing program, which seeks to advance applied research on the integration of computational thinking and computing activities within the disciplines of science, technology, engineering, and mathematics (STEM) in early childhood education through high school (preK-12). In most middle schools, learning is segregated by discipline - science is taught in one class, and engineering or computing are taught in another, if at all.  Yet today discovery and innovation are interdisciplinary and students need to use skills and practices from multiple subject areas to solve problems.  The Designing Biomimetic Robots project will develop and study an education program that integrates science, engineering, and computing by engaging students in biomimicry design challenges to support students in developing computational thinking and scientific reasoning, as well as engineering design practices, while practicing interdisciplinary problem solving skills. Students will study the natural world to learn how animals and plants accomplish different tasks and then engineer a robot that is inspired by what they learned.  For example, they may use what they learn about how different animals pick up objects to design a robot that can assist wheelchair-bound people in picking up dropped items.  In addition, the project will demonstrate how teachers can foster interdisciplinary learning, and can broaden participation in science, engineering and computing among middle school students in diverse settings.<br/><br/>The project will develop an innovative intervention to support the development of interdisciplinary STEM knowledge and practices through a series of biomimetic design challenges.  The program will include: a) a 4-week modular and flexible curriculum that integrates bio-inspired engineering design, robotics, and computer programming content and practices into middle school STEM classrooms, b) a teacher professional development program, and c) web resources to support integration of biomimetic robotics into middle schools.  The goal is for all participating students to develop knowledge, practices, and skills consistent with engineering and science standards, and computational thinking principles, and demonstrate an understanding that computing enhances STEM practice and knowledge development.  Participating teachers will learn how to enact interdisciplinary instruction through integrating STEM and computing, and how to create task structures and discursive practices that support the participation of all students.  The project will contribute to theory about interdisciplinary and participatory learning environments that can foster students' learning about the intersections of computation, engineering, and biomimicry. The project will work with 24 middle school teachers and approximately 3,200 students in urban, suburban, and rural districts in Massachusetts, Maryland, and Maine that have diverse student demographics."
"1563705","CHS: Medium: Improving Distributed Teamwork Through Mobile Robotic Telepresence Systems","IIS","Cyber-Human Systems (CHS)","07/01/2016","05/04/2018","Susan Fussell","NY","Cornell University","Continuing grant","William Bainbridge","06/30/2019","$1,248,000.00","Francois Guimbretiere, Malte Jung, Drew Margolin, Ross Knepper","sfussell@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7924, 9251","$0.00","This research systematically investigates the impact of specific Mobile Robotic Presence (MRP) system features on formal and informal collaboration across different levels of analysis, including teamwork, informal communication, and the social network structure of an organization.  MRP systems are audio and video conferencing systems mounted on a mobile base, operated by someone a distance away from the location, and often serving as a surrogate for people who cannot travel there, for any of a number of reasons.  Geographically distributed teams and organizations have been shown to suffer in comparison to those that are collocated, in part because conventional computer-mediated communication tools fail to support both formal meetings and informal interactions during activities like walking the hallway or waiting for the elevator that help build work relationships and provide valuable information about the organizational.  MRP systems are a promising new technology for distributed teamwork because they can support both formal and informal workplace interactions.  The project will develop new tools and knowledge for communication across geographic distance that will be made widely available to the research community and general public. It will also enhance education through graduate student training and the development of new classroom tools, curriculum, and diversity outreach efforts.  <br/><br/>Specifically, the project aims to: (a) develop a systematic understanding of the effects of telepresence robots on formal and informal workplace communication through a series of lab and field studies; (b) develop and evaluate a set of interface and control techniques that improve informal and formal communication; (c) examine how the introduction of MRPs into an organization influences the structure of its social network using social network analysis; and (d) integrate the techniques and findings at the interface, team and organizational levels through a set of field studies.  The research will contribute to the fields of computer-mediated communication and computer-supported cooperative work by developing new theories and understandings of how people interact via telepresence robots in both formal group meetings and informal interactions. It will contribute to human-computer interaction, robotics, and related fields through the development of new techniques and tools for interacting with and through telepresence robots. It will contribute to theories of how distance affects organizational structure by exploring the network-level effects of working remotely via MRPs vs. conventional computer-mediated communication tools. Finally, the project will help build new understandings of the relationships among individual features of MRP technology, the usefulness of that technology for distributed collaboration, and its effects on organizational structure."
"1317849","NRI: Small: Collaborative Research: Rethinking Motion Generation for Robots Operating in Human Workspaces","IIS","National Robotics Initiative","09/01/2013","07/17/2018","Lydia Kavraki","TX","William Marsh Rice University","Standard Grant","Reid Simmons","08/31/2019","$923,140.00","Mark Moll","kavraki@cs.rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","CSE","8013","7923, 8086, 9251","$0.00","This proposal develops a new motion planning paradigm for enabling robots to work in the presence of humans or cooperatively with humans as co-workers. The paradigm is intended to be fast, reactive, and responsive to the requirements that arise from human-robot interaction. It involves the definition and subsequent implementation of constraints that encode properties of human-aware paths and can be translated to cost functions characterizing path quality. New motion planners are proposed. The operation of these planners is guided by constraints and their corresponding cost functions. The planners produce paths compatible with a given set of constraints. A mechanism to incorporate user feedback on the relative importance of constraints is provided and semi-autonomous operation of the robots is considered. Importantly, the planners are embedded in a novel hybrid-systems framework that allows a robot to automatically switch among planners, and hence behaviors, in order to take into account different constraints and user preferences that arise in the context of semi-autonomous operation. Besides the actual implementation of the planners on specific platforms, this project also disseminates all developed libraries and planners. Compatibility will the Robot Operating System (ROS) is provided for wide adoption, while tutorials at major conferences are planned. The training of graduate students and female undergraduate students are a central focus of this proposal."
"1533844","XPS: FULL: DSD: Parallel Motion Planning for Cloud-connected Robots","CCF","Exploiting Parallel&Scalabilty","09/01/2015","08/17/2015","Ron Alterovitz","NC","University of North Carolina at Chapel Hill","Standard Grant","M. Mimi McClure","08/31/2019","$670,536.00","Jan Prins","ron@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","8283","","$0.00","Robots are entering new domains, from self-driving vehicles on real-world streets, to autonomous aerial vehicles for package delivery, to assistive robots helping people with disabilities in their homes with daily activities. Autonomous robots in these domains often need extensive computational resources for motion planning, which involves computing a safe motion for a robot through an environment that avoids obstacles and accomplishes the task. To enable low-power mobile robots to achieve their full potential, new algorithms and software frameworks are needed that fully leverage parallel computation and the warehouse-scale computing available via the cloud.   This project aims to develop a new software framework for motion planning for cloud-connected robots that effectively parallelizes motion planning and distributes the computation across the robot's embedded multicore processor and multiple cloud-based compute servers. <br/><br/>This research combines ideas from multiple areas of computer science and engineering, including robotics, parallel algorithms, high-performance computing, motion planning, and cloud computing. Locally on the robot, the project parallelizes traditional motion planners to fully leverage low-power, embedded multicore processors. Simultaneously, the project enables the robot to request computation time from cloud-based resources to significantly increase the computing power available for the motion planning task, and thus increase the responsiveness and quality of motion plans. The new algorithms and software aim to enable robots to autonomously complete tasks in new domains where the challenge of motion planning is currently prohibitive, broadening the applicability of robots to new societally-relevant domains. <br/><br/>The concepts and software developed in this project are being integrated into undergraduate and graduate courses taught across topics ranging from robotics to high-performance computing. Another goal of the project is to create fun, hands-on, interactive demonstrations using cloud-connected robots to inspire children to consider STEM fields."
"1734399","NRI: FND: Collaborative Control for Wearable Robots","IIS","National Robotics Initiative","09/01/2017","08/17/2017","Guy Hoffman","NY","Cornell University","Standard Grant","Reid Simmons","08/31/2020","$472,209.00","","hoffman@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","8013","8086","$0.00","There are many applications, including manufacturing, assembly, health care, and construction, where workers may be hampered by not having enough hands to do their job effectively.  While one approach is to have a mobile robot assist the human, our project instead focuses on the augmenting human capabilities by developing a wearable robotic arm. Such augmentation of the human body can enhance a person's power, efficiency, safety, and quality of work. The project aims to make these wearable robots act as collaborative teammates, rather than directly controlled passive tools, making them both intuitive for novices and adaptable to expert users. This will significantly improve the efficiency and acceptance of such robots, and positively affect the work conditions of people interacting with them. The robot arm will be tested with human users performing tasks for which a third arm is useful. <br/><br/>Whereas wearable robotics is a maturing field, there is almost no research on the human-robot interaction (HRI) aspects of such robots. This project investigates collaborative HRI for wearable robots, in four phases: 1) Collecting wearable collaboration data with a human and a tele-operated robot arm; 2) using this data to design an anticipatory Conditional Random Field (CRF) model for the collaboration; 3) developing a Partially Observable Markov Decision Process (POMDP) controller for the robot; and 4) evaluating the controller in human-robot interaction experiments with a physical wearable robotic arm, using metrics of efficiency, fluency, and usability. By doing so, the project contributes to the state-of-the-art in computational HRI by developing new probabilistic models for human-wearable robotic collaboration. The project also contributes new empirical data on how people interact with wearable co-robots through two human-subject studies. The collected data set on human-wearable-robotic interaction will be released to serve the research community. <br/>"
"1762530","Advanced Integrated Design Optimization Method to Realize Ultrasonic-Phase-Change Actuated Soft Materials","CMMI","EDSE-Engineering Design and Sy","08/01/2018","07/19/2018","Kenneth Loh","CA","University of California-San Diego","Standard Grant","Richard Malak","07/31/2021","$556,149.00","Hyunsun Kim","kenloh@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","ENG","072Y","024E, 067E, 073E","$0.00","The goal of this project is to enable the optimal design and fabrication of a material for soft robotic applications. Soft robots have potential for functionality, versatility, adaptability, and safety exceeding that of traditional robotic systems. However, it is challenging to create materials capable of supplying the forces and motion required for soft robotics. This research will create a new method for optimally designing and fabricating advanced shape-changing materials that can be used in soft robotic applications. Like in biological systems, shape change will be encoded within the architecture of the material system. The design technique to be pioneered in this research will establish this encoding in a manner tailored to the specific robotic system problem. Outcomes of this study will enable more advanced soft robotic systems with capabilities beyond what is possible with current technology. This research will enable to novel technologies such as micro-robotic vehicles, bio-inspired soft robots, and micro-propulsion devices. The project will prepare students for careers designing and optimizing advanced soft robotic systems. It also will yield new educational modules to promote training in this area.<br/><br/>The objective of this research is to create an optimization method to enable a tailored design of soft material and soft robotic systems based on a novel actuation modality. The research approach is to formulate multi-scale topology optimization for designing a soft material system with different sizes and geometries of embedded fluid cavities that change phase when certain cavities undergo local resonances induced by propagating narrowband ultrasonic waves. Five primary research tasks will be investigated. First, this project will begin with multi-physics modeling to characterize the constitutive relationship that governs ultrasonic wave excitation with phase-change actuation, considering different geometries and material properties of the soft structure, cavities, and in-fill liquid. Second, multi-scale topology optimization will be formulated, and coupled with the finite element model from the first task, for designing the material architecture to optimize for desired shape change. Third, additive manufacturing coupled with liquid infill during prototyping will enable the realization of these optimized multi-scale structures. This will then be experimentally validated for shape change by ultrasonic-phase-change. Having demonstrated proof-of-concept and fourth, multi-objective topology optimization will output solutions that will enable the entire structure to attain multiple states of motions (i.e., displacement positions, such as various degrees and angles of bending of a long, slender structure). The final task integrates the advances from all previous tasks to fabricate optimized, multi-phase, soft prototypes that can be actuated to achieve different motions. This project will lead to the first multi-scale topology optimization for smart material-structural systems, linking directly the actuation material design to achieve the desired motion at the structural scale.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734627","NRI: FND: Bioinspired Design and Shared Autonomy for Underwater Robots with Soft Limbs","IIS","National Robotics Initiative","08/15/2017","04/13/2018","Yigit Menguc","OR","Oregon State University","Standard Grant","Reid Simmons","07/31/2020","$694,583.00","Camille Palmer, Geoffrey Hollinger","yigit.menguc@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","8013","8086, 9251","$0.00","Currently, delicate and challenging underwater manipulation tasks are performed only by human divers when it is safe for them to enter the environment. Robots can help address this issue by distancing human operators from dangerous environments, while still leveraging their skills in planning complex manipulation tasks. Rigid robotic manipulators, however, are typically not suitable for delicate manipulation tasks.  To address this limitation, this project explores the design and control of soft robotic arms inspired by the octopus.  Soft robots can perform delicate tasks of scientific interest in underwater environments, such as retrieving biological samples or delicate artifacts, without harming them.  Such soft robots can also be safer when operating alongside humans. The results of the research will be integrated into hands-on courses as part of the Oregon State University PhD in Robotics and into K-12 outreach via the OSU Robotics Club and Oregon FIRST Robotics competitions.<br/><br/>The objective of this research is to establish a framework for underwater manipulation, combining shared autonomy between human operators and robots with mechanically-directed soft actuation and sensing. The proposed work will examine new actuator morphologies, alternative fabrications techniques, and the use of stretchable integrated liquid metal sensors. To control the soft grippers, this project develops a planning and control interface that utilizes machine learning techniques to leverage human operators' skills at quickly identifying stable grasps. The physical attributes of the soft grippers will be designed in tandem with algorithms, which will provide improved understanding of underwater interaction and shared autonomy.  Dexterity and compliance of the soft manipulators will be evaluated for large contact-area, multi-point gripping, which is particularly advantageous for grasping delicate objects underwater.  Testing will be done in a benchtop underwater test bed, using kinematic motion capture and interaction forces to evaluate performance.<br/>"
"1426945","NRI: Information-Theoretic Trajectory Optimization for Motion Planning and Control with Applications to Space Proximity Operations","IIS","National Robotics Initiative","09/01/2014","05/19/2017","Panagiotis Tsiotras","GA","Georgia Tech Research Corporation","Standard Grant","Radhakisan S. Baheti","08/31/2019","$708,000.00","Evangelos Theodorou","p.tsiotras@ae.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","8086, 9251","$0.00","Robotic operations in space are indispensable for many missions both in Earth orbit and beyond.  Satellite servicing and refueling, space station resupply with consumables, removal of space debris, spacecraft structural integrity inspection, crew assistance, as well as support for deep space missions to Mars and other planets and comets, all require the assistance of highly accurate, reliable and autonomous (or semi-autonomous) space robots. To date, most robotic operations in space are performed in a closely supervised mode by a human operator. This limits both the flexibility and the type of missions that can be performed (for example, the time for light to travel to and from Mars takes about 15 minutes, making ""real-time"" remote control impossible). This research aims at developing the necessary theory and algorithms to be able to utilize active exploration using robust, reliable sensing and planning of a free-flying space robots in the vicinity of another body, in order to perform proximity operations (including autonomous rendezvous and docking in space). One of the challenges in these types of problems is the uncertainty in understanding the surroundings in order to plan suitable control actions. In order to handle these challenges we utilize novel tools and methodologies from the field of stochastic optimal control along with new advances describing the spacecraft attitude dynamics and kinematics of spacecraft in orbit.  In order to ensure that the algorithms we develop perform in real-life as expected, the theoretical results will be experimentally validated on a high-fidelity 5-dof spacecraft simulator facility. This work will have an immediate impact on the US capabilities to perform monitoring and servicing of satellites in space routinely, by advancing the state-of-the-art in perception and path-planning of orbiting spacecraft in the vicinity of another body, man-made or natural. Although the emphasis of this work is primarily on space robotic applications, the same techniques can be used in all similar problems where an intelligent agent needs to navigate autonomously in an uncertain and dynamic environment.<br/><br/>The proposed research tackles a fundamental problem in autonomous/robotic systems, namely, the integrated sensing and planning under uncertainty. The current paradigm in the literature utilizes perceptual cues (especially those based solely on visual information) essentially as surrogates of full-state feedback estimators, thus enforcing an artificial separation of perception and control action. This dichotomy between sensory data acquisition/processing, and control/actuation strategies - deeply rooted in the community from its wide applicability to the stabilization of linear systems subject to additive noise (?separation principle?) - is unsuitable for this problem, where information gathering (perception/sensing) is tightly coupled with motion (control). To overcome the aforementioned limitations, in this work it is proposed to use tools from stochastic optimal control in order to extract actionable information from raw sensory inputs. A key ingredient of the proposed approach is to keep track of the first and second order statistics of the estimation error and treat them as the state, so that control actions depend on both of them. The result is a new, computationally more efficient, methodology to maximize information gathering during the exploration phase and to optimize over distributions of trajectories during the execution phase."
"1527826","NRI: Collaborative Research: Versatile Locomotion: From Walking to Dexterous Climbing with a Human-Scale Robot","IIS","National Robotics Initiative","09/01/2015","05/05/2017","Kris Hauser","NC","Duke University","Standard Grant","Reid Simmons","08/31/2019","$486,512.00","","kris.hauser@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","8013","8086, 9251","$0.00","The project aims to give legged robots the skills to navigate a wide variety of terrain.  This capability is needed to employ robots in applications such as search-and-rescue, construction, and exploration of remote environments on Earth and other planets. The multidisciplinary team, composed of researchers at Duke, Stanford, UC Santa Barbara, JPL, and Motiv Robotics, will develop a robot to climb a variety of surfaces ranging from flat ground to overhanging cliffs. Using an array of sensors, unique hands, and sophisticated algorithms, the robot will dynamically adopt walking, crawling, climbing, and swinging strategies to traverse wildly varied terrain. During the course of this research, the team hopes to achieve the milestone of the first demonstration of a human-scale rock climbing robot. The research is also expected to lead to insights into cognitive and biomechanical processes in human and animal locomotion.<br/><br/>Although rock climbing serves as an ideal proving ground for the work, this project conducts basic research to address more a general-purpose goal; namely, to provide the physical and cognitive skills for robots to adaptively navigate varied terrain. It takes a dexterous climbing approach, which uses non-gaited, coordinated sequences of contact to move the body, much as dexterous manipulation uses contact with the fingers and palm to move an object.  It will apply principles from optimization, machine learning, bioinspiration, and control theory to make intellectual contributions in several domains, such as robot hand design, planning algorithms, balance strategies, and locomotion performance measurement.  Novel grippers, sensor-based planning strategies, reactive maneuvers, and locomotion metrics will be developed during the course of this research."
"1637876","NRI: Enhancing Mapping Capabilities of Underwater Caves using Robotic Assistive Technology","IIS","National Robotics Initiative, EPSCoR Co-Funding","11/01/2016","08/25/2016","Ioannis Rekleitis","SC","University of South Carolina at Columbia","Standard Grant","Jie Yang","10/31/2019","$526,405.00","","yiannisr@cse.sc.edu","Sponsored Awards Management","COLUMBIA","SC","292080001","8037777093","CSE","8013, 9150","8086, 9150","$0.00","This project develops robotic assistive technologies to improve mapping capabilities of underwater caves. The project enables the practical construction of accurate volumetric models for water-filled caves. The technology of this robotic system can also be deployed on underwater vehicles enabling the autonomous exploration of caves and other underwater structures. The developed techniques can also be used in some applications of aerial and ground vehicles. Collected data from field deployments of the developed sensor are made available to the wider robotic, geological, and speleological research community through public-domain releases in order to further innovation. Furthermore, the data and software, released under an open-source license, enable researchers to test algorithms on computer vision, state estimation, and sensor fusion, in challenging environments. The project integrates research and education through training graduate and undergraduate students and enhancing several graduate and undergraduate courses at the University of South Carolina. The project also engages undergraduate students from Benedict College, a Historically Black College or University (HBCU). The collected data are used in outreach activities to recruit high-school students of the greater Columbia area in STEM education, engaging students and educators, particularly in underserved communities.<br/><br/>This research develops 3D reconstruction algorithms utilizing the environmental characteristic of a cave system. The research team studies robotic technologies for sensor fusion of multiple data streams in a single unit and validates experimentally the developed system via extensive testing in underwater cave explorations in collaboration with expert cave divers. The project introduces robotic technology to the underwater cave explorer community by capitalizing on existing practices in three steps: (a) deploying stereo cameras to be used in conjunction with structured light carried by the divers, (b) developing a bearing-only Cooperative Localization system for accurately recording the skeleton of explored caves; (c) developing a sensor suite that seamlessly integrates inertial measurement unit, sonar, depth, and visual data with state estimation algorithms for the volumetric mapping of the cave. The project enhances underwater cave mapping abilities by increasing: 1) the scale of the area mapped, 2) the safety of the divers by reducing their cognitive load during exploration and 3) the quality of the produced maps."
"1657235","CRII: RI: Distributed, Stable and Robust Topology Control:  New Methods for Asymmetrically Interacting Multi-Robot Teams","IIS","CRII CISE Research Initiation","04/01/2017","03/24/2017","Ryan Williams","VA","Virginia Polytechnic Institute and State University","Standard Grant","Reid Simmons","03/31/2019","$174,333.00","","rywilli1@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","026Y","7495, 8228","$0.00","Recent years have seen a rapid increase of autonomous robotics in critical segments of research and industry.  However, autonomy in teams of robots remains somewhat in its infancy.  This project therefore aims to eliminate three assumptions that currently limit the autonomous control of multi-robot teams:  (1) that complete system information is available to all robots at all times; (2) that robot-to-robot interactions are symmetric among team members (i.e., I see you and you see me); and (3) that interactions among robots provide enough information to guarantee predictable and safe robot motion.  This project will tackle such restrictions by developing new methods for explicitly controlling robot-to-robot interaction when the above assumptions are absent, with validation in field experiments using commercial off-the-shelf robotic and Internet of Things (IoT) sensor platforms.  The project outcomes will find broad relevance in applications spanning intelligent transportation, precision agriculture, autonomous construction, and defense, while allowing for deeper experimentation outside of laboratories.  Finally, the project includes a comprehensive outreach plan consisting of:  (1) K-12 academic experiences for underrepresented students;  (2) graduate curriculum; and (3) open-source contributions to the robotics community.<br/><br/>Towards the above goals, this project will intersect novel techniques from control and graph theory to derive stability guarantees for a new class of asymmetric topology control laws.  The theoretical approaches will enable guaranteed coordination for a large class of distributed multi-robot systems.  Specifically, this project will focus on the following objectives of developing:  (1) nonlinear motion controllers that guarantee stable multi-robot coordination for an identified class of asymmetric robot interactions; (2) distributed algorithms for determining stable transitions in asymmetric communication and sensing topologies; (3) extensions for hardware safe control inputs and robustness to external disturbance; and (4) field experiments with aerial and ground robots, and an IoT sensor network in a target tracking regime."
"1514258","RI: Medium: Robotic Assistance with Dressing using Simulation-Based Optimization","IIS","Cyber-Human Systems (CHS), ROBUST INTELLIGENCE","07/01/2015","07/08/2015","C. Karen Liu","GA","Georgia Tech Research Corporation","Standard Grant","Reid Simmons","06/30/2019","$1,199,987.00","Greg Turk, Charles Kemp","ckarenliu@gmail.com","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367, 7495","7367, 7495, 7924","$0.00","The aging population, rising healthcare costs, and shortage of healthcare workers in the United States create a pressing need for affordable and effective personalized care. Physical disabilities due to illness, injury, or aging can result in people having difficulty dressing themselves, and the healthcare community has found that dressing is an important task for independent living.  The goal of this research is to develop techniques that enable robots to assist people with putting on clothing, which is a challenging task for robots due to the complexities of cloth, the human body, and robots. A key aspect of this research is that robots will discover how they can help people by quickly trying out many options in a computer simulation.  Success in this research would make progress towards robots capable of giving millions of people greater independence and a higher quality of life. In addition to healthcare applications, this research will result in better computer tools for fruitful collaborations between robots and humans in other scenarios.<br/><br/>This research uses efficient physics simulation and optimization tools to substantially automate the design of assistive robots for dressing. The approach considers the robot to be an assistive device that a human learns to use. The system optimizes the assistive robot based on what a particular human with impairments is capable of doing comfortably, rather than what he/she typically does. This approach automatically optimizes personalized assistive controllers for a particular user and article of clothing via simulation. Due to frequent line-of-sight occlusion and the importance of controlling forces applied to the user's body, controllers that use data-driven haptic perception are trained using simulation-generated data. These capabilities critically depend on advancements in the efficient physical simulation of cloth, robots, and humans, as well as the discovery of appropriate human motions for a given assistive robot. This work advances the state of the art in assistive robotics, haptic perception, human modeling, optimization and efficient physical simulation. Evaluation of the system is in simulation and in the real world with test rigs that model aspects of dressing, a PR2 robot dressing a humanoid robot, and a PR2 dressing able-bodied participants with restricted motion."
"1747189","SBIR Phase I:  Shape-shifting robots for Disaster Rescue, Monitoring, and Education","IIP","SMALL BUSINESS PHASE I","01/01/2018","12/26/2017","Alice Agogino","CA","Squishy Robotics","Standard Grant","Muralidharan S. Nair","12/31/2018","$225,000.00","","agogino@berkeley.edu","2150 Shattuck Avenue, SkyDeck, P","Berkeley","CA","947042527","5106846685","ENG","5371","5371, 8034","$0.00","The broader impact/ commercial potential of this project is to commercialize previous research in tensegrity robots for new markets in disaster rescue, surveillance, scientific monitoring, and STEM (Science, Technology, Engineering and Math) education. Future deaths by both victims and first responders in disaster rescue in unchartered risky environments could be prevented by utilizing semi-autonomous technology to explore the regions of disasters, provide surveillance to inform first responders, and assist in the rescue of victims until human first responders can arrive. Current autonomous vehicles can be ineffective in navigating surface obstacles and climbing steep slopes to reach areas of interest. Aerial operations may be limited to dropping supplies, which may not be beneficial if victims are immobile or unconscious. The goal is to drop the proposed shape-shifting robots from aerial vehicles, so that these mobile robots can reach previously difficult areas for effective emergency response. This proposed technology will have broader impact in use for scientific monitoring and surveillance as well. A secondary market will be for K-12 students, teachers, parents and roboticists with the potential to have large impact in STEM education.  Robot kits will be developed for educational applications that will meet new Next Generation Science Standards.<br/><br/>The Small Business Innovation Research (SBIR) Phase I project will focus on de-risking prior research in the development of spherical tensegrity structures as a robotic platform for the proposed target applications. To meet market needs, the specifications need to include impact testing from a drop from an aerial vehicle along with ground travel requirements of slope, rubble and speed. New hardware and software will be designed to meet these specifications. The following three control algorithms and actuation schemes will be developed and evaluated for target specifications and tested in simulation and in hardware for locomotion (1) Multi-cable rolling motion on inclined surfaces, (2) Dynamic rolling using Model Predictive Control (MPC), and (3) Deep reinforcement learning. For applications where the terrain has been mapped, a (4) Generative path-planning algorithm will be developed. (5) Control mechanisms for the internal sphere of the robot will be developed so that the tensegrity robot will be able to manipulate and orient a payload of sensing equipment (e.g., camera, ultrasound, infrared, laser, spectrometer) while traveling on rough terrain. (6) Associated sensor validation, fusion and estimation techniques will be developed to meet the specifications. The results will be a proof-of-concept prototype that meets the target specifications."
"1643989","PFI:BIC - Adaptive Robotic Nursing Assistants for Physical Tasks in Hospital Environments","IIP","PARTNRSHIPS FOR INNOVATION-PFI, SPECIAL PROJECTS - CISE, IIS SPECIAL PROJECTS","06/01/2016","06/02/2017","Dan Popa","KY","University of Louisville Research Foundation Inc","Standard Grant","Jesus Soriano Molla","07/31/2019","$880,776.00","","dan.popa@louisville.edu","The Nucleus","Louisville","KY","402021959","5028523788","ENG","1662, 1714, 7484","116E, 1662, 9251","$0.00","This Partnerships for Innovation: Building Innovation Capacity (PFI:BIC) project aims to provide next-generation assistive robots to support the activities of hospital-based registered nurses (RNs). There are nearly three million registered nurses employed in the United States, making them the largest pool of healthcare providers in the country. Technology that affects the performance of this large labor pool cannot fail to have impact. Due to advancements in robotics and computer technology, access to intelligent communication, sensing, and computing hardware is on the cusp of becoming common--not only for healthcare professionals, but also for patients themselves. The project led by The University of Kentucky at Louisville in collaboration with the University of Texas at Arlington will focus on the creation of new design tools that can configure the hardware and software of adaptive robotic nursing assistants (ARNA). ARNA will be specifically designed to assist nurses in healthcare facilities with simple tasks such as, lift assistance, delivery of everyday lightweight objects (medicine, medical wearable equipment), and some physical assistance with movement of heavier objects, such as furniture, gurneys, and the patients themselves. The design and engineering innovations resulting from insights gained in this project may have great value deployed as products in broader consumer markets in addition to hospitals. Examples include in-home service and assistive robots, robots for assistance in public venues, and co-Robot manufacturing where humans are in close proximity to robot workers. The improved understanding of human-robot and nurse-robot interaction could represent enabling technology that will facilitate research breakthroughs and increase productivity and social acceptance of robotics. The research will also advance the understanding of the perceptual effects of robot design aesthetics and interfaces.<br/><br/>The proposed Adaptive Robotic Nurse Assistants will navigate cluttered hospitals, while equipped with multi-modal skin sensors that can anticipate nurse intent, automate mundane low-level tasks, but keep nurses in the decision loop. Modular and strong hardware will be deployed in reconfigurable platforms specially designed for nurse physical assistance. Adaptive human-machine interfaces will play a key role in this project, as these interfaces directly impact the ability of robots to help nurses in a dynamic, unstructured environment. Rather than pre-programming robot behaviors,  learning algorithms will be used so that robots adapt to human preferences. Two leading applications are envisioned for feasibility evaluation by quantitative and qualitative metrics, including patient sitters and walkers. The sitter robot will take vital sign measurements, evaluate risk from patient movement and pose, and provide continuous observation of patients and feedback to and from nurses. The walker robot will assist nurses and patients by providing partial balance support, navigating cluttered environments, and assisting with medical equipment transportation.<br/><br/>The lead institution is the University of Kentucky at Louisville in collaboration with the University of Texas at Arlington with its multidisciplinary departments including the College of Engineering, College of Nursing, and the University of Texas at Arlington Research Institute (UTARI). Primary industrial partners include QinetiQ-North America (Waltham, MA), a large corporation specializing in unmanned systems, and RE2 (Pittsburgh, PA),  a small business specializing in modular robotic manipulators that will contribute unique battle-tested hardware and systems engineering. In-hospital testing and evaluation of the proposed robots will be carried out by nurse researchers at the University of Texas at Arlington College of Nursing and Texas Health Resources (Dallas-Fort Worth, TX), a large healthcare provider."
"1720713","CHS: Small: Collaborative Research: Modeling Social Context to Improve Human-Robot Interaction","IIS","Cyber-Human Systems (CHS)","09/16/2016","07/13/2017","Laurel Riek","CA","University of California-San Diego","Standard Grant","Ephraim P. Glinert","08/31/2019","$161,250.00","","lriek@eng.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","CSE","7367","7367, 7923","$0.00","For robots to be truly useful to people, it is critical that they be able to understand and operate independently in human social environments (HSEs).  Decades of research into this problem by many investigators have to date failed to yield a solution.  The PIs on this collaborative project that spans two partner institutions argue that a fundamental paradigm shift is necessary to enable progress, and that this shift can be ignited through a contextually driven approach to mobile robotics.  Thus, the goal of this proposal is to create and evaluate new models of social context in order to enable mobile robots to interact appropriately with people in HSEs.  Project outcomes will help give all ""things that think"", from social robots to smart homes, a better understanding of human social context and a greater capability to operate effectively in real-world human spaces.  By contributing new theoretical models, techniques, and open source implementations that will accelerate the development and adoption of machines that operate in HSEs, the PIs anticipate this work will have a transformative impact on many fields within computer and information science, including robotics, human-machine interaction, and ubiquitous computing.  The PIs also will make their context models available to other researchers.  <br/><br/>The PIs' approach to context is unique in that, rather than being techno-centric and entirely representational, it fully adopts Dourish's approach to an interactional model of context inspired by the social sciences - relational, dynamic, occasioned, and arising from activity - i.e., fluid.  The key contribution of the approach is that it ties real-time sensor data to models of situational context, which then inform a robot of the social affordances of the environment.  The PIs will engage in two primary research activities.  First, they will create a situational context processing capability that can accept a multimodal, social scene snapshot from a robot and return back a situational context frame (SCF) that contains an estimate of the scene's salient objects, social activities, and situational context.  Then, they will contribute algorithmic techniques that enable a robot to leverage the SCF to perform guided exploration to refine its model, and ultimately, goal-driven task execution adapted to conform to social norms.  The PIs' research emphasis on using solely naturalistic, real-world, multimodal data, will enable them to make unique contributions for increasing robustness in multimodal processing."
"1316809","NRI: Small: Collaborative Research: Don't Read my Face: Tackling the Challenges of Facial Masking in Parkinson's Disease Rehabilitation through Co-Robot Mediators","IIS","National Robotics Initiative","09/15/2013","09/02/2013","Matthias Scheutz","MA","Tufts University","Standard Grant","David Miller","08/31/2019","$949,924.00","Linda Tickle-Degnen","matthias.scheutz@tufts.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","CSE","8013","7923, 8086","$0.00","The overarching scientific goal of this project is two-fold: (1) to develop a robotic architecture endowed with moral emotional control mechanisms, abstract moral reasoning, and a theory of mind that allow corobots to be sensitive to human affective and ethical demands, and (2) to develop a specific instance of the architecture for a co-robot mediator between people with ""facial masking"" due to Parkinson's disease (PD) that reduces their ability to signal emotion, pain, personality and intentions to their family caregivers, and health care providers who often misinterpret the lack of emotional expressions as disinterest and an inability to adhere to treatment regimen, resulting in stigmatization. To tackle these problems, the project brings together two roboticists with extensive prior experience in robot ethics and modeling emotions as well as implementing them in integrated autonomous robotic systems. The robotics expertise is combined with that of an expert in early PD rehabilitation and daily social life. The project will build on extensive software, hardware and data set resources, including complex robotic control architectures with ethical control mechanisms, personality and emotion models, and affect and natural language capabilities.<br/><br/>The general expected outcome of the project is an architecture for co-robots that can be adapted to a great variety of health care scenarios in an effort to enrich and dignify already stressed and stigmatized relationships between humans. The project also includes novel educational efforts such as a course in occupational therapy robotics as well as significant K?12 outreach through the Tufts Centers for STEM Diversity and for Engineering Education and Outreach, as well as various important community and public activities such as presentations on health care robotics to focus and patient groups."
"1528145","NRI: Robust and Low-Cost Smart Skin with Active Sensing Network for Enhancing Human-Robot Interaction","IIS","National Robotics Initiative","10/01/2015","08/27/2015","Fu-Kuo Chang","CA","Stanford University","Standard Grant","Reid Simmons","06/30/2019","$900,000.00","Marco Pavone","fkchang@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","8013","8086","$0.00","Tactile sensing is ubiquitous in nature - arguably even more essential than vision. Most animals have thousands of cutaneous sensors over their bodies for touch, temperature, etc. But even the most sophisticated robots have relatively few tactile sensors and, after 30 years of research, tactile sensing lags behind computer vision. This project aims at the development of a novel artificial skin mimicking the human skin that can be fitted into any robotic hand providing information-rich ""sense of touch."" This technology leads to the development of extremely sensitive robotic skins with unprecedented tactile sensing capabilities. As such, this work enables a plethora of robotic applications where tactile sensing is of utmost importance, ranging from robotic caregivers to medical robotics and autonomous exploration. The methodology in this project may revolutionize the way future robots are designed enabling their broad applicability. This effort represents a major milestone in endowing robots with the sensory information required to carry out tasks in human-centered environments.<br/><br/>The advent of microprocessors for touch sensing, spurred by the smart phone industry, has helped to address the wiring problem with local processing of information and communication. However, there remain the critical problems of fabricating a multi-functional artificial skin that can conformally cover arbitrary surfaces, diagnosing in real-time, the contact state, and gathering a large amount of data for high-resolution tactile sensing, while minimizing power consumption. Overall, this effort addresses tactile sensing from a system-level point of view. The approach involves the development of advanced manufacturing technologies from leveraging nonstandard CMOS/MEMS/NEMS fabrication processes to produce a low-cost and robust artificial skin outfitted with multi-modal micro-sensors. The tactile sense of touch is achieved via an innovative micro-contact sensing technique based on ultrasound waves generated from embedded sensors to identify local contact/slip conditions. Finally, the validation and performance evaluation is demonstrated through a series of graded tactile sensing experiments."
"1426824","NRI/Collaborative Research: Models and Instruments for Integrating Effective Human-Robot Teams into Manufacturing","CMMI","National Robotics Initiative","09/01/2014","08/01/2014","Bilge Mutlu","WI","University of Wisconsin-Madison","Standard Grant","Bruce M. Kramer","08/31/2019","$589,959.00","","bilge@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","ENG","8013","082E, 092E, 1786, 8086, MANU","$0.00","Robots for application in collaborative manufacturing must perform manual work side-by-side with people. Such robots offer the flexibility to work on many different tasks and promise to transform manufacturing by improving the quality and efficiency of manual processes in small shops and in facilitates that manufacture highly customized products. However, in order to meet this promise, robots must be effectively integrated into existing manufacturing teams and practices. To enable this integration, this National Robotics Initiative (NRI) award supports fundamental research on the methods and instruments that manufacturing engineers will need to form effective human-robot teams based on task requirements and worker skills. These methods will also enable robots to adapt to changes in workflow to maximize safety and efficiency. The effective integration of collaborative robots into manufacturing promises improvements in many industries that have not yet benefited from robotic technology. Therefore, results from this research will contribute to the competitiveness of U.S. manufacturing and benefit the U.S. economy and society. The research will involve contributions from multiple disciplines, including robotics, human factors, computer science, and manufacturing, and by academic and industry collaborators. These collaborations will help the dissemination of research results into manufacturing organizations and the integration of research into undergraduate and graduate curriculum in engineering.<br/><br/>Advancements in robotics promise the use of collaborative robots that perform interdependent work with people in order to improve quality, efficiency, and safety in industrial manufacturing. However, integrating collaborative robots into these processes and ensuring their efficient operation pose significant research challenges, including the optimal allocation of work based on task requirements and constraints, the formation of human-robot teams, and the dynamic adaptation of teamwork to workflow changes. This research will address these research challenges, enabling the seamless integration of collaborative robots into these processes and achieving efficient and safe collaboration between human and robot workers. The research team will create novel methods for optimal allocation of tasks to human and robot workers based on task constraints and worker skills, design new tools that utilize these methods to facilitate workflow design for human-robot teams, and develop novel mechanisms that enable robots to more efficiently and safely collaborate with human workers in the planned manufacturing operations. These methods and instruments will be validated in real-world manufacturing operations and disseminated through industry workshops, engineering curricula, and a public outreach program."
"1426338","NRI/Collaborative Research: Improving the Safety and Agility of Robotic Flight with Bat-Inspired Flexible-Winged Robots","CMMI","National Robotics Initiative","08/01/2014","05/17/2016","Kenneth Breuer","RI","Brown University","Standard Grant","Atul G. Kelkar","07/31/2019","$708,000.00","Sharon Swartz","kbreuer@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","ENG","8013","116E, 8086, 9150, 9178, 9231, 9251","$0.00","Bat flight, perhaps the most advanced and efficient form of animal flight, has long been a source of inspiration for roboticists and biologists alike. This National Robotics Initiative (NRI) collaborative research award supports research aimed at understanding and reproducing the unparalleled agility and resilience of bat flight. Biological studies of bats (their structure, muscle movement, and flight dynamics) will drive the engineering development of mathematical models of robotic flight and the eventual design and implementation of a prototype 30-80cm bat-like robot.  The physical flight capabilities of the robot will be augmented with perception and reasoning abilities, with the aim of providing support for construction site activities such as site monitoring, inspection, and general surveillance of the work site to provide image data to enhance situational awareness of human workers. The research involves several disciplines, including biology, aerodynamics, robotics, control systems engineering, and construction engineering.<br/><br/>Aerial robots have nowhere near the agility and efficiency of animal flight, especially in complex, constrained environments. This is not surprising since even the simplest winged robots have complex flight dynamics that pose significant challenges for modeling, design, and control. In the case of bat-inspired robots, these difficulties are exacerbated by the use of under-actuated mechanisms driving wings constructed from flexible membranes. This project will combine biological and engineering research to address these problems. Biological research on the kinematics of bats and their flight will provide a basis for mechanical designs. To control the robot, agile motion planning and flight control algorithms will employ motion primitives that are derived from biological investigation of the dynamics of bat flight. Conversely, models obtained from biological studies will be validated by experimental investigations using the prototype robot, enabling iterative refinement of reduced-order models and control algorithms.  Ultimately, the robots will be equipped with sensing systems and planning algorithms, to facilitate localization, mapping, inspection and surveillance at construction sites."
"1637444","NRI: Collaborative Research: Software Framework for Research in Semi-Autonomous Teleoperation","IIS","National Robotics Initiative","10/01/2016","08/18/2016","Blake Hannaford","WA","University of Washington","Standard Grant","Reid Simmons","09/30/2019","$479,998.00","","blake@ee.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","8013","8086","$0.00","Telemanipulation systems consist of a human interacting with a mechanical device on the master side to operate a robot at the remote side. They provide natural opportunities for research in intelligent human/robot collaboration, but existing commercial systems, used in areas such as telesurgery, are not intelligent and therefore only replicate the actions of the human operator. These systems are also proprietary, expensive, and not available for modification by researchers. The goal of this NRI project is to provide an open-source software infrastructure that is designed to work with a broad range of hardware and simulated devices to enable a larger community to pursue research and education in intelligent telemanipulation at a lower cost.<br/><br/>The increasing pace of robotics research can be attributed, at least in part, to the increasing availability of software infrastructure, such as Robot Operating System (ROS), and open hardware platforms. This NRI project focuses on providing a software infrastructure for research in intelligent telemanipulation, leveraging infrastructure developed for the Raven II robot and the da Vinci Research Kit (dVRK) and continuing to extend it to other systems, including simulated robots. The three main tasks are to: (1) engage the community to guide development, (2) develop and implement a common API for the diverse hardware platforms, and (3) provide a set of high-level, platform-independent software modules. The goal is to support research towards semi-autonomous telerobotic systems that can more effectively combine the knowledge, reasoning, and decision-making capabilities of a human with the sensing and manipulation capabilities of a robot."
"1703267","SCH: EXP: Home+, An Intelligent and Interoperable Suite of Robotic Furnishings, Learning and Evolving with Their Users","IIS","Smart and Connected Health","10/01/2016","10/27/2016","Keith Green","NY","Cornell University","Standard Grant","Wendy Nilsen","09/30/2019","$593,218.00","","keg95@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","8018","8018, 8061","$0.00","The number of older persons in the United States is substantially increasing, as is the cost of health care. Accompanying these trends is a growing scarcity of caretakers, care deliverers, and care facilities to attend to our growing elder population. Technology supporting health for older adults tends to be limited to computerized monitoring systems and, potentially someday in the future, as assistive 'humanoid' robots that look and function something like us. Our homes and their many furnishings, meanwhile, remain conventional, low-tech, and maladaptive to life changes. To promote independent living, this research team from architectural design, robotics, and human factors explores how our homes can be outfitted with furnishings of advanced functionality. This project, home+, is a collection of robotic home furnishings that fits easily into any conventional home to increase the quality of life of individuals with impaired mobility and cognitive functioning by enabling routine domestic activities. This research project will: (1) establish the needs and wants of older people wishing to age in place, identifying those aspects of the home+ concept that best promise to support independent living; (2) design robotic furnishings, accordingly; (3) test these furnishing to determine how well they interact with each other and with the people that use them; (4) define the choreography by which these furnishings and their users interact; and (5) evaluate how well home+ supports typical users performing ten routine home tasks that define a capacity for independent living. The team will gain insights not only from the targeted populations and healthcare professions who may benefit most by home+, but also from a wider audience. This outreach aspect of the home+ project will culminate in a workshop that seeks marketplace and practice support for advancing the prototype. <br/><br/>The majority of seniors want to age in place in their homes. To realize this goal, this project will: (1) conduct a needs assessment of older adults; (2) iteratively co-design and usability test robotic furnishings that recognize, communicate with, and partly remember each other in interaction with human users (interoperability); (3) define the pattern language of interactions for this cyber-human system; and (4) evaluate the efficacy of home+ by comparing performance on 10 routine home tasks defining a capacity for independent living for individuals with and without home+. Drawing on research and formalism in distributed robotics, the team will focus efforts on implementing and evaluating three software environments for home+: (1) a centralized architecture, with all sensory information, processing, command and control at a single source; (2) a distributed architecture, with localized sensing, processing, and control, and minimal interactions between elements; and (3), a combination of the first two, with a dedicated interface layer between the high-level strategies of (1) and the reactive behaviors of (2). Intellectually, this approach can be viewed as establishing a bridge between traditional robotics and smart, robotically enhanced, physical built environments."
"1526813","RI: Small: Reinforcement Learning in Partially Observable Multi-Agent Tasks","IIS","ROBUST INTELLIGENCE","09/01/2015","06/01/2016","Bikramjit Banerjee","MS","University of Southern Mississippi","Continuing grant","James Donlon","08/31/2019","$247,664.00","","Bikramjit.Banerjee@usm.edu","2609 WEST 4TH ST","Hattiesburg","MS","394015876","6012664119","CSE","7495","7495, 7923, 9150","$0.00","The goal of this project is to develop new techniques for the design of robot controllers (programs that drive individual autonomous robots) for multi-robot tasks, i.e., tasks involving a collaborative team of robots. Existing techniques that have sound decision and game theoretic properties address simple multi-agent systems. In practice, robot controllers are still largely designed manually. Little is known about the decision theoretic optimality of such controllers, especially in multi-robot settings. This project aims to change that by bridging the gap between multi-agent decision theory and multi-robot control, via three main thrusts. Two of these thrusts seek to modify the ways by which multi-agent decision theory describes and computes these controllers, so as to be applicable to multi-robot tasks. The third thrust seeks to make the new computational approach scale to large robot teams. The project has mixed (theoretical and applied) scope, and will lay the foundation for more principled design of future multi-robot systems. The project will also have  broad educational impact. The research will be conducted in collaboration with a graduate and an undergraduate student, and involve hands-on robotics experience for students, as well as generate material for a new undergraduate course on robotics. Any theory and algorithms developed will be shared publicly.<br/><br/>More specifically, the first main thrust of this project will investigate the expression and game theoretic optimization of behavior based controllers---a popular controller language in the robotics community. Non-linear programming techniques will be used for optimization of modular behaviors, that will be integrated in a hirerchical fashion from simpler to complex tasks. The second main thrust will utilize multi-agent reinforcement learning for the agents/robots to compute their own controllers via joint exploration in task simulations, exploiting inductive knowledge transfer to bootstrap the learning of complex behaviors from simpler, related ones. The third main thrust will develop a new paradigm of multi-agent reinforcement learning---Reinforcement Learning as a Rehearsal (RLaR). Agents will learn in a supervised setting with hidden as well as observable information to reduce sample complexity, but marginalize out the hidden features to yield controllers usable in partially observable settings. <br/>"
"1637479","NRI: Collaborative Research: Experiential Learning for Robots: From Physics to Actions to Tasks","IIS","National Robotics Initiative","10/01/2016","05/15/2018","Dieter Fox","WA","University of Washington","Standard Grant","James Donlon","09/30/2019","$760,000.00","Ali Farhadi","fox@cs.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","8013","8086, 9251","$0.00","Recent advances in machine learning coupled with unprecedented archives of labeled data are advancing machine perception at a remarkable rate. However, applying these advances to robotics has not advanced as quickly because learning for robotics requires both active interaction with the physical world, and the ability to generalize over a variety of task contexts. This project addresses this knowledge gap through the development of new learning methods to produce experience-based models of physics. In this approach, an object or category specific model of physics is learned directly from perceptual data rather than deploying general-purpose physical simulation methods. These physical models will support both direct control of action - for example pouring a liquid into a container, and the learning of the physical effects of sequences of actions - for example planning to handle fluids in a laboratory. More generally, these methods will provide a means for robots to learn how to handle fluids, soft materials, and other complex physical phenomena.<br/><br/>The proposed experiential learning framework will build on recent advances in deep neural networks. The key problem is to learn the mappings between raw perceptual and control data via a low-dimensional implicit physics space representing a perception-based physical model of how an object acts in the environment. Three directions will be investigated: 1) the development of experiential physics models for object interaction and fluid flow that have strong predictive capabilities, 2) creating mappings directly from experiential models to control of actions such as pouring or moving an object, 3) the assembly of local experience-based controllers into complex tasks from interactive demonstration. Additionally, the project will develop unique data sets that include physical models, simulations, data components, and learned components that other groups can access and build on to enable comparative research similar to what has emerged in machine perception."
"1712088","RI: Small: Collaborative Research: Micro-Assembly Exploiting SofT RObotics (MAESTRO)","IIS","ROBUST INTELLIGENCE","09/01/2016","05/15/2018","MinJun Kim","TX","Southern Methodist University","Continuing grant","Reid Simmons","06/30/2019","$314,692.00","","mjkim@lyle.smu.edu","6425 BOAZ","Dallas","TX","752750302","2147682030","CSE","7495","7495, 7923, 9251","$0.00","The MAESTRO project will develop a new type of manufacturing by combining soft robotics and swarm control to construct assemblies in 2D and 3D from individual artificial cells made of hydrogels. MAESTRO will design rules for building tiny factories so that, like a conductor's baton, global control signals will organize artificial cells into complex configurations. These artificial cells can contain living cells and be assembled into tissue for artificial organs, or contain inorganic particles to assemble into micro-scale tools. <br/><br/>MAESTRO will ferry desired components in artificial cells constructed from polysaccharide-based hydrogels. Current approaches use engineered structures or live bacteria as micro-scale actuators to push or pull desired objects into place. The proposed approach uses the soft robots themselves as building blocks for desired patterns. The artificial cells excel at encapsulating a wide range of micro and nano-sized particles, for example living cells and magnetic nano-particles. Furthermore, artificial cells can be triggered to efficiently release their payloads. Novel swarm control algorithms using obstacle-based particle computation will steer the cells. In traditional robotics, simultaneous control of multiple robots is based on individual motion control that requires heterogeneity among robots or the ability to deliver multiple input signals; both approaches are currently impractical in small-scale systems.  However, these challenges can be overcome by parallel motion planning in obstacle-filled workspaces. This obstacle-based positional control makes the position of micro-robots fully controllable using just a single control input. Actuation of these stimuli-responsive artificial cells in micro-fluidic, obstacle-laden environments presents a paradigm shift in fabrication technology."
"1564080","CHS: Medium: Leveraging Human Interaction to Efficiently Learn and Use Multimodal Object Affordances","IIS","Cyber-Human Systems (CHS)","06/15/2016","08/02/2016","Sonia Chernova","GA","Georgia Tech Research Corporation","Standard Grant","Ephraim P. Glinert","05/31/2020","$1,199,831.00","Andrea Thomaz","chernova@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","7367, 7924","$0.00","The goal of this research is to enable robots to effectively identify, reason about and predict the affordances of common objects found in everyday human environments.  When a robot enters a new environment, it should not need to learn all domain knowledge from scratch.  Instead, it should be able to leverage general commonsense knowledge about the objects it sees, as well as domain-specific knowledge it acquires through situated interaction, to reason effectively about the attributes and affordances of objects in the surrounding environment.  The PIs' ultimate objective is to make robots more accessible to everyday people.  Project outcomes will contribute research infrastructure and novel data sources for the research community, as well as create an opportunity for broadening participation and STEM educational outreach.  Undergraduate and graduate education will be impacted because the research will supplement the material and projects covered in the PIs' AI, robotics and HRI courses.  The PIs have a track record of including undergraduate research assistants in their labs, and PI Thomaz serves as faculty advisor to the undergraduate AI Club.  Both PIs have an extensive history of mentoring and promoting women in science and technology.  And they will continue their tradition of open source software development in this project; all data deriving from this research will be made publicly available.<br/><br/>This project encompasses an end-to-end research agenda that explores how a domain-specific affordance knowledge base, which the PIs call a Situated Affordance Network (SAN), can be represented, acquired, and then used for reasoning about complex tasks.<br/><br/>* SAN Representation: The PIs will use Markov logic networks to establish the SAN knowledge representation, which relates physical object properties to object attributes and affordances.  This representation will serve as the unifying foundation for the remainder of the work.<br/>* SAN construction from semantic knowledge sources: The PIs will develop automated techniques for leveraging existing, general purpose semantic knowledge resources to construct a domain-specific SAN based on object and location observations made by the robot.  The outcome will be a Markov logic network that represents abstract conceptual knowledge about the robot's environment, including categorical labels, object attributes and affordances.<br/>* SAN refinement through situated interaction: Next, the PIs will develop techniques for physically grounding the SAN's abstract affordance concepts in the environment in which the robot exists.   They will develop techniques for learning specific representations of objects, locations, attributes, and the controllers needed to achieve affordances through situated interaction with the environment and with the human user.<br/>* Affordance reasoning using SAN: In the final research thrust, the PIs will develop algorithmic techniques that leverage the unified SAN representation to enable the robot to perform high level task planning, adapt to changes in the environment and generalize domain-independent knowledge across multiple contexts.<br/><br/>At the completion of this work, a robot will be able to enter a novel environment, and 1) use objects that it recognizes in the scene to initialize a domain-specific SAN that contains abstract knowledge about the attributes and affordances of objects in the surrounding environment, 2) incrementally refine the resulting SAN through exploration of the environment and interaction with a human, and 3) leverage the resulting representation to perform complex tasks in the environment, including prediction of the affordances of novel objects, grounding of abstract task plans, and performing plan repair.  The main contribution of this research is not the specific SAN knowledge base that has been generated for a given domain and object set, but rather the domain-independent method by which a robot can construct a SAN for any new environment."
"1427547","NRI: Collaborative Research: Modeling and Verification of Language-based Interaction","IIS","National Robotics Initiative","08/15/2014","03/10/2015","Nicholas Roy","MA","Massachusetts Institute of Technology","Standard Grant","Reid Simmons","07/31/2019","$525,000.00","","nickroy@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","8013","8086","$0.00","Many autonomous systems today, such as personal or service robots, are designed primarily to perform tasks independently and in isolation. Integrating these robots with human partners can often result in poor performance, as the robot does not know how to interpret human interaction, and cannot merge information from this  interaction with a model that guarantees robot performance.  This research brings together key elements that are just now reaching a sufficient level of maturity for integration: firstly, natural language processing and probabilistic modeling to capture human input, and secondly probabilistic synthesis and verification of the combined human-robot systems to ensure correct performance. The outcome will be theory and software to enable correct, effective and natural interactions between robots and humans to be realized. This research will impact most future autonomous systems which require interactions with humans, including service, personal and planetary robots. <br/><br/>The goal of this research is to develop models and algorithms for synthesizing and verifying an integrated human-plus-robot system based on natural language interaction. Algorithms are being developed for probabilistic modeling and inference of natural language, including the grounding of the constituents of the language into the physical world and the human's expectations. These models will enable the development of a distribution over specifications for control synthesis, which will in turn enable the development and verification of correct-by-construction controllers to a particular level of probability. The out years will consider interactive human-robot dialogue to resolve conflicts, and ""open world"" scenarios to enable on-line learning of new models over time. It is expected that this research will enable high reliability and performance in many autonomous systems because of the inherent interaction with humans.  Outcomes include open source data and software; community workshops; and undergraduate and graduate student education in the unique area of language, modeling and verification for robotics."
"1144591","IGERT: Soft Material Robotics","DGE","IGERT FULL PROPOSALS, NSF Research Traineeship (NRT), IGERT Chemistry, IGERT Physics, IGERT Materials Research","07/01/2012","07/20/2016","Barry Trimmer","MA","Tufts University","Continuing grant","Laura Regassa","12/31/2018","$2,709,035.00","David Kaplan","barry.trimmer@tufts.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","EHR","1335, 1997, 8062, 8063, 8064","1335, 9179, SMET","$0.00","IGERT: Soft Material Robotics.<br/><br/>This Integrative Graduate Education and Research Traineeship (IGERT) award creates an interdisciplinary graduate program to  develop advances in the field of soft robotics. These machines, inspired by animals, will be capable of complex tasks that are difficult to achieve with conventional robots, suitable for close interactions with humans, and able to work in environmentally sensitive locations. The research will cross traditional disciplinary boundaries, employing novel biomaterials, exploiting cellular processes and tissue engineering methods, and using control strategies derived from evolutionary principles ? approaches that are comparatively rare in conventional robotics.<br/><br/>Broader Impacts: The development of this new technology provides an exciting opportunity to train inventive and entrepreneurial future science and engineering leaders. IGERT trainees will train in multiple disciplines, including materials science, neuromechanics, mechanical control systems, computer science, artificial intelligence and product design. Novel collaborative training approaches include the formation of mentorship teams and an innovative problem solving-based model of education. IGERT trainees will exploit bioengineering approaches to machine design, fabricate and control new robotic devices to address a wide range of current medical, social and environmental challenges. For example, soft robots could be developed for internal medical diagnosis and delivery of therapeutics, or for search and rescue operations and bioremediation. The international partners, leaders in the emerging field of soft robots, will help trainees form collaborations and affiliations across the world. These students will bridge emerging areas of biology and engineering to create revolutionary new technologies including robots for human assistance and environmentally-friendly biodegradable robots. <br/><br/>IGERT is an NSF-wide program intended to meet the challenges of educating U.S. Ph.D. scientists and engineers with the interdisciplinary background, deep knowledge in a chosen discipline, and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to establish new models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries, and to engage students in understanding the processes by which research is translated to innovations for societal benefit.<br/><br/>"
"1563921","CHS: Medium: Collaborative Research: Novel Optimal Control for Co-Adaptation of Human and Powered Lower Limb Prosthesis","IIS","Cyber-Human Systems (CHS)","07/15/2016","09/15/2017","Jennie Si","AZ","Arizona State University","Continuing grant","Ephraim P. Glinert","06/30/2020","$457,765.00","","si@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7367","7367, 7924","$0.00","Emerging powered lower limb prostheses hold great promise for restoring normative locomotion in amputees.  However, these robotic devices currently lack inter- and intra-wearer adaptability to cope with wearers' physical variations and changes.  Frequent manual and heuristic adjustment in clinics is required, which limits the practical use of these advanced prostheses.  A new generation of prosthesis control that is intelligent, adaptable, and interactive is needed to better support walking function and improve the quality of life of lower limb amputees.  The PIs' long-term research goal is to create bionic legs that can adapt to the individual amputee's physical and cognitive capabilities, coordinate with the wearer's movement and intent, adjust to changing environments, and essentially restore the full function of patients with lower limb impairments.  To this end, the PIs' objective in this project is to create a novel optimal control framework for these prostheses.   They will systematically address the challenge of supporting automatic adaptation to the wearer's physical capability while achieving desired gait performance for the integrated amputee-prosthesis system.  And they will provide a preliminary design and evaluation for an interactive interface that would allow wearers to personalize prosthesis control safely and easily.  Project outcomes will open up a new frontier of wearable robotics and lay the foundation for clinical translations of these innovative devices, which will impact not only the prosthetics and orthotics industry but also the robotics community by providing new knowledge relating to human-robot interaction, the biomechanics and neuromotor control community by elucidating the control mechanism of amputee locomotion, and healthcare in general by providing innovative and cost-effective prosthesis solutions.<br/><br/>The new amputee-prosthesis performance-based framework for control of powered lower limb prostheses which this work will introduce represents a departure from existing approaches that mainly focus on design for the prosthesis (a local machine), in that it adopts a global approach by accounting for co-adaptation between amputees and prostheses in order to provide optimal, personalized assistance based on wearers' physical conditions.  The PIs will use approximate dynamic programming (ADP) to achieve the global control goal.  Such innovative use of ADP will provide an opportunity to demonstrate its optimal adaptive control capability in a new test domain of co-adaptive robotic prosthesis, a unique and significant challenge only seen in human wearable robotics but not in lifeless robots.  The ADP scheme is based on approximation and learning that alleviate problems associated with the requirement of accurately modeling wearers' neuromuscular control and dynamics that is difficult, if not impossible, to achieve.  Additionally, the PIs will conduct an experimental investigation on subjects with transfemoral amputations of the interactions between amputees and prostheses, including evaluations of the compensatory strategies of amputees, and discrepancy assessment between subjective (human) and objective (machine) preferences in prosthesis control."
"1528121","NRI: Socially Aware, Expressive, and Personalized Mobile Remote Presence: Co-Robots as Gateways to Access to K-12 In-School Education","CMMI","National Robotics Initiative","09/01/2015","06/07/2017","Maja Mataric","CA","University of Southern California","Standard Grant","Irina Dolinskaya","08/31/2019","$608,000.00","Gisele Ragusa","mataric@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","ENG","8013","010E, 116E, 8086, 9102, 9178, 9231, 9251","$0.00","Participating in the school environment is essential to children's social, emotional, and cognitive development and learning. It has long been recognized that the quality of a student's school experience is important not only for the academic and achievement outcomes, but for fostering self-esteem, self-confidence, and general psychological well-being. Yet annually 26.6% of America's children have health or behavioral challenges that cause them to miss significant amounts of school, and 13% of all US K-12 public school students receive interventions due to learning disabilities or emotional disturbances.  This project focuses on the problem of using mobile remote presence co-robots as a means to provide numerous K-12 aged children who cannot be present in school access to the curricular and social learning experiences critical to their development and future outcomes. Using mobile remote presence for access to K-12 classrooms for homebound students may be a powerful gateway for minimizing the effects of physical separation from the school environment. This project develops methods that enable the creation of personalizable robots that allow shared autonomy, socially appropriate movement and socially expressive nonverbal communication in dynamic in-class K-12 environments, allowing children to be truly embodied in the classroom, even from a distance. The impact of this NRI project spans K-12 education at large, but also applies to general uses of mobile remote presence systems outside of the classroom setting, for both education and training. In addition, the project connects the research themes with outreach; it engages K-12 students and teachers in co-robot-themed activities and holds annual NRI-themed workshops at large-scale public venues. The broader outreach program is designed to train students in STEM, so they can become not only end users of robotics and other technologies but capable of developing such technologies themselves, thereby contributing to the US STEM workforce. <br/><br/>This proposal focuses on developing control algorithms for mobile remote presence (MRP) co-robot systems that will improve human access to a learning/training environment, focusing on homebound K-12 students, but with general implications to users of all ages and a variety of contexts. Work with MRP systems has identified key missing technical capabilities necessary for facilitating natural remote interaction and learning: 1) simple, socially-appropriate autonomous behavior and context awareness that reduces user cognitive load; 2) expressiveness for conveying the user's affect and communicative intent; and 3) the ability to personalize the way the user interacts through the MRP. This project addresses these challenges with participatory user-informed algorithm development, system integration, and evaluation. Specifically, it first develops an approach to automating and facilitating spatial and social context awareness for the operator and the MRP, and uses it to enable the two research thrusts, social appropriateness and expressiveness, with algorithmic methods for personalizing both. To ground the results in the selected real-world context, iterative design and evaluation is performed in the K-12 in-class setting, involving users across the age and education span, providing a test of the co-robot's relevance, effectiveness, and robustness. The project brings together a pair of interdisciplinary experts with a track record of successful past collaborations and three partners: industry, deployment, and outreach, committed to a project timeline with specific evaluable milestones."
"1822181","2nd Summer School on Cognitive Robotics: Proposed Summer School","IIS","ROBUST INTELLIGENCE","07/01/2018","06/27/2018","Brian Williams","MA","Massachusetts Institute of Technology","Standard Grant","Reid Simmons","06/30/2019","$25,000.00","","williams@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7495, 7556","$0.00","This grant supports a week-long summer school on Cognitive Robotics to be held in Boston, Ma in July 2018. The summer school will be a combination of invited talks and tutorials, which are designed to introduce researchers to issues in planning and execution from perspectives of both Robotics and Cognitive Artificial Intelligence, and daily labs, which are designed to give students hands-on experience with robotic hardware and state-of-the-art software tools for developing robotic behaviors. The summer school will help expose graduate students to cutting-edge ideas at the intersection of Robotics and Cognitive Systems and will help to form a new community of researchers in this interdisciplinary area.  The hands-on experience with, and open-source release of, the Enterprise Executive Architecture will facilitate the formation of this collaborative community.  The summer school concludes with a grand challenge using robot hardware that combines what the students have learned during the week.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1757401","REU Site: Summer Undergraduate Research in Engineering (SURE) - Robotics","EEC","HUMAN RESOURCES DEVELOPMENT","03/01/2018","01/19/2018","Ayanna Howard","GA","Georgia Tech Research Corporation","Standard Grant","Mary Poats","02/28/2021","$287,979.00","Leyla Conrad","ah260@gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","1360","116E, 9178, 9250","$0.00","This three-year Research Experiences for Undergraduates (REU) Site: Summer Undergraduate Research in Engineering (SURE)-Robotics, at Georgia Institute of Technology, will expose participating students to interdisciplinary robotics research, and as a direct consequence, interest them in opportunities available through graduate study.  Due to the universal appeal and the compelling real-world applications that robotics has in society, this program is designed to have direct appeal in attracting minority and female undergraduate students into research. Robotics, as a discipline, is inherently interdisciplinary, combining all aspects of engineering necessary for designing and deploying integrated systems and solutions. As students are exposed to robotics, they begin to see connections among these disciplines and begin to understand how their in-class book knowledge translates into real-world systems that can assist society in positive ways. The push of robotics, as it moves from traditional industrial settings, into public spaces and homes across the world opens up extensive new research opportunities in important economic areas such as healthcare, education, and entertainment. <br/><br/>Annually, Georgia Tech will host eight REU students in an immersive 10-week robotics summer research experience. The program will recruit participants locally and nationwide from institutions that provide no or limited research opportunities. Since it is expected that this theme will be highly advantageous for recruiting, retaining, and motivating students who are currently underrepresented in engineering disciplines, particular emphasis will be placed on recruitment of minority and female students. Students who are paired with both a faculty advisor and a graduate student mentor, will undertake meaningful robotics research projects, visit local industrial labs, attend weekly seminars on emerging research in the robotics field, and participate in weekly academic enrichment and skill development workshops. Students will conclude the program with research presentations to their peers, faculty, and graduate student mentors. Through this immersive research experience, robotics REU students will share in meeting the challenges of this promising new robotics domain and fully reap the rewards of being trained in this interdisciplinary field.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1757929","REU Site: Collaborative Human-Robot Interaction","IIS","RSCH EXPER FOR UNDERGRAD SITES","02/01/2018","01/26/2018","David Feil-Seifer","NV","Board of Regents, NSHE, obo University of Nevada, Reno","Standard Grant","Wendy Nilsen","01/31/2021","$360,000.00","Shamik Sengupta","dave@cse.unr.edu","1664 North Virginia Street","Reno","NV","895570001","7757844040","CSE","1139","9150, 9250","$0.00","Human-Robot Interaction (HRI) has the potential to affect several real world domains such as hospitals, homes, schools, offices, or infrastructure sites where robots are uniquely able to assist a human team member to achieve a common goal. However, there are many challenges for effective human-robot collaboration that impinge on this promise, such as communicating with human partners using natural language, providing information to an operator through a visual interface, or quickly providing information so that a person is able to offer assistance. We propose an HRI direction that provides several closely-related projects for undergraduate research experiences. The project team will mentor 10 undergraduates each summer, pursuing research directly impacting assistive robotics, in the following technical areas: development of autonomous robot capabilities targeted for care environments, such as networked robotics devices cooperating with care professionals to perform complex tasks in support of aging in place; human command-and-control infrastructure for operations that utilize robots for technology support; and connectivity and security for a network of robots, computers, and embedded devices collectively used to mission-critical goals while utilizing unused parts of the wireless spectrum. The goal of this Research Experiences for Undergraduates (REU) site is to develop and evaluate robotic systems whose function is to help bridge the human-robot collaboration gap and achieve the above objectives efficiently and effectively. The summer activities for undergraduates will provide hands-on science and engineering activities related to current research projects, and professional development with training sessions on writing a graduate school application and how to apply for fellowships to support graduate education. <br/><br/>The site will develop new autonomous robot capabilities and supporting network and data science technology to address real-world challenges of operating autonomous systems in hospital, clinic, home, and infrastructure environments. This site will develop solutions for semi-autonomous robot behavior with humans in the loop, wireless network connections in rapidly changing frequency domains, and processing high volumes of real-world data. The proposed site presents five projects related to these computing domains: Empirical Study of Socially-Appropriate Interaction; Language-Based Human-Robot Collaboration; Autonomous Robotic Exploration of Underground Mine Environments; Multi-robot Collaboration and Human in-the-loop for Safe, Accurate and Reliable Inspection; and Network Management of Heterogeneous Robotics Devices in a Wireless Environment. This REU site links these projects together through the common objective of developing assistive technology. Students will develop domain knowledge, mathematical skills, and interdisciplinary competency. The possible intellectual properties resulting from this project will include study on long-term human-robot interaction, wireless networking for challenging signal environments, autonomous robot capabilities for human-robot teaming, and data science tools for processing high volumes of data from real-world systems."
"1657596","CRII: RI: Enabling Manipulation of Object Collections via Self-Supervised Robot Learning","IIS","CRII CISE Research Initiation, ROBUST INTELLIGENCE","03/01/2017","06/27/2018","Tucker Hermans","UT","University of Utah","Standard Grant","David Miller","02/28/2019","$183,000.00","","thermans@cs.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","026Y, 7495","7495, 8228, 9251","$0.00","While manipulation of individual objects in cluttered, real-world settings has received substantial attention, the problem of directly manipulating collections of objects has been left unexplored. This project investigates to what extent robots can autonomously manipulate such object collections. This project facilitates autonomous manipulation methods suitable for use in home robotic assistants. Such assistive robots stand to make a substantial impact in increasing the quality of life of older adults and persons with certain degenerative diseases. Additionally, the robot skills investigated in this project are suitable for manipulation in areas damaged in natural or man-made disasters, where building rubble and other debris need to be cleared. The project supports the development and presentation of an interactive robotics lecture for low-income school children, teaching them fundamentals of computer programming.<br/><br/><br/>The research goal of this project is to enable robots to manipulate and reason about groups of objects en masse. The hypothesis of this project is that treating object collections as single entities enables data-efficient, self-supervised learning of contact locations for pushing and grasping grouped objects. This project investigates a novel neural network architecture for self-supervised manipulation learning. The convolutional neural network model takes as input sensory data and a robot hand configuration. The network learns to predict as output a manipulation quality score for the given inputs. When presented with a novel scene, the robot can perform manipulation inference by evaluating the current sensory data, while directly optimizing the manipulation score predicted by the network over different hand configurations. The project supports the development of experimental protocols and the collection of associated data for dissemination to stimulate research activity in manipulation of object collections."
"1617611","CHS: Small: Applying Intergroup Psychology to Overcome Barriers in Human-Robot Interaction","IIS","Cyber-Human Systems (CHS)","07/15/2016","06/05/2017","Selma Sabanovic","IN","Indiana University","Standard Grant","Ephraim P. Glinert","06/30/2019","$514,905.00","Eliot Smith","selmas@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7367","7367, 7923, 9251","$0.00","Robots are projected to become ubiquitous in homes, hospitals, schools, and other everyday spaces, where they will have to interact not with experts but rather with ordinary people - adults, the elderly, and children, from different cultural backgrounds.  But untrained users may have negative beliefs, emotions, and attitudes about robots, due to lack of familiarity, which present potential challenges to their acceptance.  Furthermore, multiple people will interact with multiple robots.  Interaction between human and robot groups may be especially problematic, because intergroup interactions among humans are generally more negative, uncooperative, and aggressive than interactions between individuals, and human reactions to technological artifacts often resemble their reactions to other humans.  In this project the PI will draw upon research from social psychology that has examined stereotyping, prejudice, and intergroup conflict, and will   apply established and validated theories and methods to develop: (a) measures that can be used to understand the extent, nature, and bases of people's negative reactions to robots; (b) theoretical models of the causes and consequences of these negative reactions; and (c) interventions that demonstrably reduce negative beliefs, attitudes, and behavior in intergroup human-robot interaction (HRI).  Project outcomes will suggest ways to reduce or eliminate crucial barriers to future robotics applications that are due to people's beliefs, attitudes, and emotions. <br/><br/>Nine studies will be conducted over three years.  In Year 1, online and in-person measures will be administered to understand participant attitudes toward robots, and investigate fundamental factors that contribute to negative reactions.  In Year 2, group contact, perspective taking, and long term exposure will be explored as ways to reduce prejudice toward robots.  In Year 3, two more approaches to prejudice reduction in HRI will be tested: recategorization and norm-based intervention.  A final study will evaluate the interaction and design strategies found to be most successful in fostering positive intergroup HRI by implementing them in robots interacting with people in a naturalistic setting.  The studies will involve participants of different ages, socio-economic status, and cultural background (including four studies in Japan).  Because HRI has mostly focused to date on one-on-one interactions between people and robots, this application of psychological theory to HRI in groups has vast transformative potential."
"1263049","REU Site: Summer Undergraduate Research in Engineering (SURE)","EEC","HUMAN RESOURCES DEVELOPMENT, , , ","05/01/2013","02/15/2018","Ayanna Howard","GA","Georgia Tech Research Corporation","Continuing grant","Mary Poats","04/30/2019","$444,298.00","Leyla Conrad","ah260@gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","1360, L644, N532, O266","116E, 7736, 9178, 9250","$0.00","Robotics, as a discipline, is inherently interdisciplinary, combining all aspects of engineering necessary for designing and deploying integrated systems and solutions. As students are exposed to robotics, they begin to see connections among these disciplines and begin to understand how their in-class book knowledge translates into real-world systems that can assist society in positive ways. The push of robotics, as it moves from traditional industrial settings, into public spaces and homes across the world opens up extensive new research opportunities in important economic areas such as healthcare, education, and entertainment. This Research Experience for Undergraduates (REU) award, funded with co-support from the Division of Engineering Education and Centers, will support the involvement of undergraduate students in an immersive 10-weeks robotics research experience, and as a direct consequence, interest them in opportunities available through graduate study. The program will recruit participants locally and nationwide from institutions that provide no or limited research opportunities. Since we expect this theme to be highly advantageous for recruiting, retaining, and motivating students who are currently underrepresented in engineering disciplines, particular emphasis will be placed on recruitment of minority and female students. Participating students, who are paired with both a faculty advisor and a graduate student mentor, will undertake meaningful robotics research projects, visit local industrial labs, attend weekly seminars on emerging research in the robotics field, and participate in weekly academic enrichment and skill development workshops.  Students will conclude the program with research presentations to their peers, faculty, and graduate student mentors. Through this immersive research experience, robotics REU students will share in meeting the challenges of this promising new robotics domain and fully reap the rewards of being trained in this interdisciplinary field.<br/><br/>""The site is co-funded by the Department of Defense in partnership with the NSF REU program."""
"1664554","CRII: CHS: Human-Robot Collaboration in Special Education: A Robot that Learns Service Delivery from Teachers' Demonstrations","IIS","CRII CISE Research Initiation, Cyber-Human Systems (CHS)","09/13/2016","01/23/2017","Momotaz Begum","NH","University of New Hampshire","Continuing grant","Ephraim P. Glinert","05/31/2019","$126,849.00","","mbegum@cs.unh.edu","51 COLLEGE RD SERVICE BLDG 107","Durham","NH","038243585","6038622172","CSE","026Y, 7367","7367, 8228","$0.00","This project focuses on improving the quality of life for children with special needs through the use of robot technologies.  In 2011, 13% of children enrolled in schools in the United States required some form of special education; in 2010, 1 in 68 children in the U.S. was diagnosed with some form of autism spectrum disorder (ASD), a developmental condition that almost always triggers the need for special education.  A significant amount of robotics research over the past decade has indicated that many children with ASD have a strong interest in robotic toys, and suggested that robots are potentially valuable tools in special education for these children.  But the clinical community and educators, who have the authority to approve the use of such devices in special education, remain unconvinced.  One reason for this gap is that the robotics research in this domain has not had a strong focus on effectiveness.  The PI recently completed a preliminary study involving children with ASD that confirmed the clinical feasibility of special education service delivery through human-robot interaction (HRI).  Her goal in the current project is to establish a research program that builds on these findings to develop a framework, including methods and algorithms, for robot-mediated special education service delivery to children with ASD and other disorders of a similar nature.  The PI's vision is to lay the foundations for a future where educators deliver services in collaboration with robots, thereby making a significant impact by increasing the effectiveness of special education services while reducing the burden on the educator during the service delivery process.<br/><br/>This research proposes a ""Learning from Demonstration"" (LfD) approach where the robot learns service delivery from a series of demonstrations by human educators in real special education scenarios.  When the human educator has sufficient confidence in the robot's ability, s/he will initiate a collaborative service delivery scenario in which the robot autonomously delivers some steps of a specific educational service but  asks for the educator's assistances in cases where it has low confidence in its perception and/or planned actions.  A multi-modal activity recognition framework will provide information about the responses and activities of children with special needs as they engage with the robot.  To facilitate educator/robot interaction, a focus group will be organized with educators and clinicians to accommodate their needs and expectations in the design of the control interface for the special education service delivery robot.  An HRI study will test the effectiveness of the proposed framework in real-world settings.  The design and implementation of robots that can deliver special education services in collaboration with a human educator will open up many opportunities to advance the state of the art in robot learning (especially high-level concept learning), robot vision and activity recognition, and HRI."
"1563454","CHS: Medium: Collaborative Research: Novel Optimal Control for Co-Adaptation of Human and Powered Lower Limb Prosthesis","IIS","Cyber-Human Systems (CHS)","07/15/2016","05/01/2018","He Huang","NC","North Carolina State University","Standard Grant","Ephraim P. Glinert","06/30/2020","$765,155.00","","hhuang11@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7367","7367, 7924, 9251","$0.00","Emerging powered lower limb prostheses hold great promise for restoring normative locomotion in amputees.  However, these robotic devices currently lack inter- and intra-wearer adaptability to cope with wearers' physical variations and changes.  Frequent manual and heuristic adjustment in clinics is required, which limits the practical use of these advanced prostheses.  A new generation of prosthesis control that is intelligent, adaptable, and interactive is needed to better support walking function and improve the quality of life of lower limb amputees.  The PIs' long-term research goal is to create bionic legs that can adapt to the individual amputee's physical and cognitive capabilities, coordinate with the wearer's movement and intent, adjust to changing environments, and essentially restore the full function of patients with lower limb impairments.  To this end, the PIs' objective in this project is to create a novel optimal control framework for these prostheses.   They will systematically address the challenge of supporting automatic adaptation to the wearer's physical capability while achieving desired gait performance for the integrated amputee-prosthesis system.  And they will provide a preliminary design and evaluation for an interactive interface that would allow wearers to personalize prosthesis control safely and easily.  Project outcomes will open up a new frontier of wearable robotics and lay the foundation for clinical translations of these innovative devices, which will impact not only the prosthetics and orthotics industry but also the robotics community by providing new knowledge relating to human-robot interaction, the biomechanics and neuromotor control community by elucidating the control mechanism of amputee locomotion, and healthcare in general by providing innovative and cost-effective prosthesis solutions.<br/><br/>The new amputee-prosthesis performance-based framework for control of powered lower limb prostheses which this work will introduce represents a departure from existing approaches that mainly focus on design for the prosthesis (a local machine), in that it adopts a global approach by accounting for co-adaptation between amputees and prostheses in order to provide optimal, personalized assistance based on wearers' physical conditions.  The PIs will use approximate dynamic programming (ADP) to achieve the global control goal.  Such innovative use of ADP will provide an opportunity to demonstrate its optimal adaptive control capability in a new test domain of co-adaptive robotic prosthesis, a unique and significant challenge only seen in human wearable robotics but not in lifeless robots.  The ADP scheme is based on approximation and learning that alleviate problems associated with the requirement of accurately modeling wearers' neuromuscular control and dynamics that is difficult, if not impossible, to achieve.  Additionally, the PIs will conduct an experimental investigation on subjects with transfemoral amputations of the interactions between amputees and prostheses, including evaluations of the compensatory strategies of amputees, and discrepancy assessment between subjective (human) and objective (machine) preferences in prosthesis control."
"1651129","EAGER: Representations and Methods for Verifiable Human-Robot Interactions","IIS","ROBUST INTELLIGENCE","09/01/2016","05/15/2018","Bilge Mutlu","WI","University of Wisconsin-Madison","Standard Grant","Reid Simmons","08/31/2019","$307,877.00","Aws Albarghouthi, Allison Sauppe","bilge@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","7495","7495, 7916, 9251","$0.00","Robotics promises to transform how people work, learn, communicate, and engage in other activities of daily living. To do so, robots must interact with users following conventions and norms that people expect, so that people readily adopt them into their environments. These conventions and norms, however, are highly complex and nuanced, requiring that designers consider an impractical number of scenarios, constraints, and requirements in the design process. This project will build new computational methods to facilitate this process, enabling designers of future robot systems to more easily explore the design space for human-robot interactions and to verify that their solutions satisfy design goals. These methods will help achieve the promise of robotics by improving their safety, effectiveness, and reliability.<br/><br/>The design of robotic technologies for human interaction poses a complex, multifaceted design problem that requires that resulting designs satisfy several constraints. Systematically exploring the solution space for actions and behaviors that meet user expectations, follow norms of human interaction, and ensure safety of nearby humans requires an appropriate computational framework for the evaluation and proactive exploration of the space of possible human-robot interactions. This project will devise a novel framework for computationally representing human-robot interactions and exploring the solution space for robot behaviors and actions that satisfy defined correctness properties. Specifically, the project will develop a set of prototypical interaction scenarios and correctness properties; specify formal representations for interaction states and properties, using a variety of temporal logics; apply and extend existing verification methods to verify correctness; devise methods to translate verification output to design feedback; and validate and demonstrate the applicability of the developed framework.<br/>"
"1317214","NRI: Small: Collaborative Research: Don't Read my Face: Tackling the Challenges of Facial Masking in Parkinson's Disease Rehabilitation through Co-Robot Mediators","IIS","National Robotics Initiative","09/15/2013","05/14/2015","Ronald Arkin","GA","Georgia Tech Research Corporation","Standard Grant","David Miller","08/31/2019","$587,987.00","","arkin@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","7923, 8086, 9251","$0.00","The overarching scientific goal of this project is two-fold: (1) to develop a robotic architecture endowed with moral emotional control mechanisms, abstract moral reasoning, and a theory of mind that allow corobots to be sensitive to human affective and ethical demands, and (2) to develop a specific instance of the architecture for a co-robot mediator between people with ""facial masking"" due to Parkinson's disease (PD) that reduces their ability to signal emotion, pain, personality and intentions to their family caregivers, and health care providers who often misinterpret the lack of emotional expressions as disinterest and an inability to adhere to treatment regimen, resulting in stigmatization. To tackle these problems, the project brings together two roboticists with extensive prior experience in robot ethics and modeling emotions as well as implementing them in integrated autonomous robotic systems. The robotics expertise is combined with that of an expert in early PD rehabilitation and daily social life. The project will build on extensive software, hardware and data set resources, including complex robotic control architectures with ethical control mechanisms, personality and emotion models, and affect and natural language capabilities.<br/><br/>The general expected outcome of the project is an architecture for co-robots that can be adapted to a great variety of health care scenarios in an effort to enrich and dignify already stressed and stigmatized relationships between humans. The project also includes novel educational efforts such as a course in occupational therapy robotics as well as significant K?12 outreach through the Tufts Centers for STEM Diversity and for Engineering Education and Outreach, as well as various important community and public activities such as presentations on health care robotics to focus and patient groups."
"1513175","Soft Robotics to Broaden the STEM Pipeline","DRL","ITEST","08/01/2015","05/11/2018","Nathan Mentzer","IN","Purdue University","Standard Grant","Michael Ford","07/31/2019","$716,301.00","Rebecca Kramer-Bottiglio, Anita Deck, Barry Burke","nmentzer@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","EHR","7227","","$0.00","This project aims to increase female interest in science, technology, engineering and mathematics (STEM) careers through the emerging field of soft robotics. Soft robotics diverge from other robotics in that they leverage materials science (understanding how materials stretch and deform), chemistry (polymer synthesis), and biology (bio-inspired design) to provide aids for human needs. This project will advance efforts of the Innovative Technology Experiences for Students and Teachers (ITEST) program to better understand and promote practices that increase students' motivations and capacities to pursue STEM careers by exploring the inspiration that soft robotics might afford. The focus is a unit within a high school freshman engineering course. Results of this project will include the development and testing of curriculum that has the potential to broaden participation. The International Technology and Engineering Educators Association STEM Center for Teaching and Learning will disseminate it to 50,000 students annually.<br/><br/>This project will test the hypothesis that the implementation of soft robot design experiences improves learning, motivation, engineering self-efficacy and interest in engineering careers as compared to traditional robot design experiences. This development and study is contextualized in a course required of many 9th grade students called Foundations of Technology, which is the freshman-level technology and engineering education course provided by the Engineering by Design core program. It is taught in over 270 school districts across 23 states to about 100,000 students annually. The study will employ a design research framework to develop the 8-hour unit and study its implementation in 11 classrooms with a total of 660 students in the Carroll County Public Schools.  Measures include the Situational Motivation Scale and the Longitudinal Assessment of Engineering Self Efficacy. In Year 3, the project will implement an efficacy study to compare results of the soft robotics unit with the unit implemented traditionally in the Engineering by Design program."
"1544332","CPS: TTP Option: Synergy: Safe and Secure Open-Access Multi-Robot Systems","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2015","02/16/2017","Magnus Egerstedt","GA","Georgia Tech Research Corporation","Standard Grant","Radhakisan S. Baheti","09/30/2019","$999,999.00","Aaron Ames, Raheem Beyah, Eric Feron","magnus@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7918","7918, 8235, 9102","$0.00","This proposal addresses the safety and security issues that arise when giving users remote-access to a multi-robot research test-bed, where mobile robots can coordinate their behaviors in a collaborative manner. Through a public interface, users are able to schedule, and subsequently upload, their own code and run their experiments, while being provided with the scientific data produced through the experiment.  Such an open-access framework has the potential to significantly lowering the barriers to entry in robotics research and education, yet is inherently vulnerable from a safety and security point-of-view. This proposal aims at the development and definition of appropriate cyber-physical security notions, formal verification algorithms, and safety-critical, real-time control code for teams of mobile robots that will ultimately make such a system both useful and safe. On top of the research developments, this proposal contains a Transition to Practice component that will allow the system to become a highly usable, shared test-bed; one that can serve as a model for other open, remote-access test-beds.<br/><br/>Safety is of central importance to the successful realization of any remote-access test-bed and failure to enforce safety could result in injury in local operators and damaged equipment. To guarantee safe operation, while allowing users to test algorithms remotely, new science is required in the domain of safety-critical control.  To address this need, the proposed work follows a three-pronged approach, namely (1) development and use of novel types of barrier certificates in the context of minimally invasive, optimization-based controllers with provable safety properties, (2) formal methods for verification of safety-critical control code for networked cyber-physical systems, and (3) novel methods for protecting against machine-to-machine cyber attacks.  By bringing together ideas from multi-agent robotics, safety-critical control, formal verification, and cyber-security, this project will result in a unified and coherent approach to security in networked cyber-physical systems. <br/><br/>The potential impact of the resulting open-access multi-robot test-bed is significant along the research, education, and general outreach dimensions in that a future generation of roboticists at institutions across the country will have open and remote access to a world-class research facility, and educators at all levels will be able to run experiments on actual robots."
"1801727","RET Site: Cross-disciplinary Research Experiences on Smart Cities for Nevada Teachers: Integrating Big Data into Robotics","EEC","RES EXP FOR TEACHERS(RET)-SITE","09/01/2018","06/22/2018","Kostas Alexis","NV","Board of Regents, NSHE, obo University of Nevada, Reno","Standard Grant","Mary Poats","08/31/2021","$581,073.00","Lei Yang","kalexis@unr.edu","1664 North Virginia Street","Reno","NV","895570001","7757844040","ENG","1359","115E, 9150, 9177","$0.00","This Research Experiences for Teachers (RET) Site at the University of Nevada Reno aims to deliver a unique holistic research experience to K-12 teachers of Nevada in relation to future smart cities and the cutting edge topics of robotics and big data, as well as their intersection. The overarching goal is to enable a critical mass of teachers in Nevada to be able to help their students develop a passion for these domains, strengthen their critical thinking, and broadly nurture an interest to excel in STEM fields. Research in the respective domains is currently of paramount importance in order to address the multitude of open challenges to achieve truly autonomous driving and the realization of smart cities. The relevance and significance of cross-disciplinary research in robotics and big data cannot be overstated in the context of STEM education and its potential is daily growing. This site will attract K-12 teacher participants to STEM education by providing tangible research experiences and appropriately designed knowledge modules, in turn enhancing the STEM education for their students and further designing and deploying transferable research and education tools for the school environment.<br/><br/>This project aims to nurture an interest and passion for robotics and big data research to K-12 teachers of all levels, especially from the perspective of their intersection for smart cities. The RET Site will provide a tangible experience through a) educational activities on the fundamental principles of autonomous driving, machine learning, and big data, b) a custom-designed, miniaturized, and transferable test-bed of smart cities called ""Robocity"", and c) hands-on activities on an instrumented electric bus and a drive-by-wire Lincoln MKZ autonomous car. Through the envisioned activities, it is anticipated that Nevada teachers will be actively engaged and gain knowledge and research experiences in robotic perception and machine learning, control, path planning, big data analytics, and big data system design. To enhance the quality of STEM education in local K-12 schools at all levels, a team with both senior and young faculty has been assembled to support the development of curricular modules and provide a set of mechanisms that allow research to be seamlessly transferred to the school environment. The project will engage a thorough plan for project evaluation and a participant recruitment process that focuses on underrepresented groups and respective student populations. To ensure that the developed skills acquired by teachers are transferred to the classroom, the PI team will engage in follow-up activities with the RET participants to support the installation of Robocity. The PI team will also offer demonstrations and tangible exercises at schools, as well as workshops at the University of Nevada, Reno.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1652588","CAREER: Safe and Transformative Robotic Intervention through Dynamic Elastic Structures (STRIDES)","IIS","ROBUST INTELLIGENCE","09/01/2017","06/19/2018","Daniel Rucker","TN","University of Tennessee Knoxville","Continuing grant","Reid Simmons","08/31/2022","$214,292.00","","drucker6@utk.edu","1 CIRCLE PARK","KNOXVILLE","TN","379960003","8659743466","CSE","7495","1045, 7495","$0.00","Robotic devices are currently being used in medical applications, but their prevalence is hindered by lack of capability.  This project seeks to transform the safety and effectiveness of medical interventions by advancing the capabilities of flexible robots and medical devices.  The project aims to create new mathematical models to better understand the behavior of flexible robots and to develop innovative robotic devices to increase their reach, precision, intelligence, and safety.  In collaboration with medical professionals, the project will use these results to develop robotic systems for minimally invasive surgical removal of colon cancer and upper extremity rehabilitation.  The research is fundamentally linked to an educational plan that includes middle- and high-school engineering outreach, as well as undergraduate research and open courseware development.<br/><br/>This research is organized along three technical thrusts that advance soft and continuum robotics knowledge in modeling, design, and sensing.  First, the project will create a novel computational framework for the dynamics of slender elastic objects that extends and unifies existing models.  The proposed approach is a unique, high-order time-discretized solution method for the hyperbolic partial-differential equations of a Cosserat rod, which has potential for increased accuracy and efficiency. Second, this project will analyze and validate two novel concepts in the design of elastic robotic structures: high-strength, variable-curvature mechanisms, and concentric agonist-antagonist elastic actuation.  These concepts are aimed at addressing the tradeoffs of range-of-motion, strength, and compactness in continuum robot design. Third, new algorithmic approaches for shape-based distributed force sensing and elastic stability assessment for elastic objects are being developed and tested. The research plan culminates in efforts to advance knowledge of robotic medical intervention at the system level for minimally-invasive robotic surgery and robot-assisted rehabilitation."
"1700839","PFI:AIR - TT: Magnetic Resonance Imaging Guided Robotic Cardiac Catheter System","IIP","Accelerating Innovation Rsrch","06/01/2017","04/05/2018","M. Cenk Cavusoglu","OH","Case Western Reserve University","Standard Grant","Jesus Soriano Molla","05/31/2019","$215,870.00","Evren Gurkan-Cavusoglu","mcc14@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","ENG","8019","116E, 8019, 9251","$0.00","This PFI: AIR Technology Translation project focuses on translating magnetic resonance imaging-guided robotics technology to develop a robotic catheter system for treatment of atrial fibrillation ablation.  The developed technology aims to improve treatment of atrial fibrillation, which has an estimated the prevalence of 2.7-6.1 million in the United States, with 200,000 new cases annually.  The developed real-time, magnetic resonance, imaging-guided, robotic catheter technology will significantly improve the accuracy and repeatability of the atrial fibrillation ablation therapy, compared to the state-of-the-art manually controlled catheters.  This technology will also reduce costs by decreasing time in the operating room, reducing the need for repeat procedures due to incomplete treatment, and reducing adverse events and complications.  In this project, the investigators will develop a proof-of-concept prototype of the robotic catheter system that will be used in subsequent early validation studies.<br/><br/>This project addresses the technology gaps in synergistically integrating high-speed magnetic resonance imaging technologies with robotic motion planning and control techniques, to develop a novel co-robotic system.  In the proposed paradigm, the atrial fibrillation ablation will be performed under intra-operative magnetic resonance imaging guidance, and conventional manually controlled intravascular catheters will be replaced with robotic catheters actuated by the magnetic resonance imaging system. The location of the catheter tip and the target tissue will be measured by magnetic resonance imaging in real-time. The robotic control algorithms will then use this information to actively control the catheter tip. Intra-operative availability of magnetic resonance imaging, with its superior tissue discrimination capabilities, would allow real-time evaluation of the substrate depth and lesion created by ablation. <br/><br/>In addition, personnel involved in this project, in particular, one postdoctoral and one graduate student, will receive training in innovation and technology commercialization through participating in technology innovation and entrepreneurship education programs."
"1651843","CAREER: Deep Robotic Learning with Large Datasets: Toward Simple and Reliable Lifelong Learning Frameworks","IIS","ROBUST INTELLIGENCE","07/01/2017","06/19/2018","Sergey Levine","CA","University of California-Berkeley","Continuing grant","Reid Simmons","06/30/2022","$227,311.00","","sergey.levine@gmail.com","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495","1045, 7495","$0.00","Learning robot behaviors from large data sets is an important way to make robots more capable and reliable.  This project will develop algorithms for autonomous robotic skill learning that can easily be used by novice hobbyists with low-cost robots. If deployed widely, such an approach could be used to gather a large number of robotic motions, which can be combined to improve the robot's skills.  Availability of large datasets has proven critical in machine learning application areas, from computer vision to speech recognition, and the ability to collect a large amount of robotic interaction data would substantially increase the capabilities of learning-based robotic systems. Since the approach will be designed for untrained users, it also doubles as an effective tool for robotics education.<br/><br/>Deep learning has emerged as a powerful technique for taming the complexity of the real world. The success of deep learning depends on the availability of large datasets, which traditionally have been difficult to obtain for robotic learning. This project will focus on deep learning algorithms that can be used for effective and reliable robotic skill learning, generating intelligent actions directly from raw sensory input, with an eye towards enabling widespread deployment for large-scale data collection. To that end, the proposed research will aim to: (1) devise reliable and robust real-world robotic learning algorithms that can collect experience without human oversight or intervention; (2) build algorithms centered around transfer learning, whereby experience from prior tasks can be used to inform dramatically faster learning of new skills with potentially different robotic platforms; and (3) devise algorithms that can effectively control heterogeneous, low-cost, imprecise robots, so as to facilitate widespread deployment and the project's educational mission."
"1551631","CAREER: From Grasp Quality to Hand Quality: Analysis and Optimization for Effective Robot Hands","IIS","ROBUST INTELLIGENCE","07/01/2016","06/19/2018","Matei Ciocarlie","NY","Columbia University","Continuing grant","Reid Simmons","06/30/2021","$324,372.00","","mtc2103@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495","1045, 7495","$0.00","Robotic manipulators often exhibit high precision, repeatability, and grip strength, characteristics which have enabled many applications, primarily in industrial settings. However, robot hands still lack versatility: once a manipulation task implies variation, it quickly falls beyond the capabilities of today's robots. This prevents robot manipulators from operating in many environments, from cluttered store rooms and warehouses to typical homes and other human settings. This project aims to develop and demonstrate more versatile robot hands, able to manipulate a wide range of objects and to operate in clutter. Robots equipped with such hands could perform what are otherwise injury-prone tasks like kitting and bin picking (in manufacturing), or order picking and packing (in logistics). In healthcare, more versatile robotic manipulators could assist with activities of daily living, many of which involve contact and manipulation. From an educational perspective, this project aims to encourage interdisciplinary training by combining areas of robotics traditionally spanning multiple engineering disciplines, and to promote diversity in engineering education by inspiring and preparing young students for STEM careers, at both the high school and undergraduate levels.<br/><br/>The key research objective of this project is to find new ways of building and using robot hands, where the high level grasp planning algorithms, the low-level control loops, and the hardware design itself are optimized simultaneously, in a tight loop, and taking each other into account. This represents a departure from the ""build, then program"" approach, where algorithms for performing complex tasks (such as grasping and manipulation) are researched only after the underlying hardware (the hand) has been designed and constructed. By combining these stages, we can jointly optimize algorithms, sensor arrays, control strategies and mechanism structures that fit and complement each other. Both mechanical and algorithmic complexity can then be increased based strictly on provable performance gains."
"1226883","NRI-Large: Collaborative Research: Soft Compliant Robotic Augmentation for Human-Robot Teams","IIS","National Robotics Initiative","10/01/2012","07/02/2014","Daniela Rus","MA","Massachusetts Institute of Technology","Continuing grant","Reid Simmons","09/30/2019","$1,099,650.00","","rus@csail.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","8013","7925, 8086","$0.00","This proposal addresses the hardware, control and planning technologies required to achieve soft robotic systems, in order to offer inherent safety and adaptation to the human-machine systems of the future. The project is motivated by a broad range of aspects of human-robot interaction, including soft augmentation tools for safe compliant manipulation, soft exoskeletons for rehabilitation of neuromuscular disorders, or active clamping systems that can conform to arbitrary surfaces. The proposed research will address the algorithmic and device-level challenges that arise in the design of soft compliant robots capable of pose-invariant and shape-invariant grasping. A combination of algorithmic solutions to modeling, control, planning, and adaptation will lead to new soft compliant manipulators that do not need accurate geometric models for grasping. By designing soft compliant fingers and hands, new approaches to grasp planning and manipulation will be enabled. A novel composable actuation system and supporting planning and control algorithms with features inspired by natural muscle will be developed.<br/><br/>Broader Impacts: Soft robots are inherently low-cost. Affordable soft manipulators will enable in-home assistants for the elderly or incapacitated, but these robots must be able to manipulate the natural world as easily as people do. The next generation robot manipulators will also support new levels of factory automation, in which robots will work synergistically with humans with the ultimate goal of reducing the cost of manufacturing in the USA. The proposed soft devices will provide a new approach to assistive and rehabilitative usage of compliant robotic platforms. Their functional compliant properties will enable them to work side-by-side with human beings or as part of their bodies, to augment and improve human productivity and performance. This new wearable soft robotic technology will not only help workers perform tasks, but also improve the quality of life for many people. In addition, the PIs have a long tradition of integrating research and education by providing research training at all levels, from high-school teachers and students to undergraduate and graduate students, and postdocs. A range of activities to reach out to undergraduate students, high-school communities, women and minorities is planned."
"1838470","I-Corps:  Neuromorphic Target Tracking and Control for Insect-Scale Aerial Vehicles","IIP","I-Corps","07/01/2018","06/18/2018","Silvia Ferrari","NY","Cornell University","Standard Grant","Cindy WalkerPeach","12/31/2018","$50,000.00","","ferrari@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project is to enable a broader range of end users to utilize the capabilities of autonomous robotics and to make advanced autonomous systems more broadly accessible and reliable. Robotics such as micro aerial vehicles (MAVs), self-driving cars, and other ground-based service robots are playing increasingly important roles in the lives of many industries as advances in autonomy enable them to be used safely and reliably in diverse situations. Accurately tracking targets and navigating while avoiding obstacles are important prerequisites to fully autonomous operation for robots. Neuromorphic cameras can more accurately detect motion than traditional cameras while consuming far less power. This project will explore the commercial applications of algorithms which interpret the data from neuromorphic cameras to enable autonomous systems to accurately track motion and navigate in unknown environments. By enabling more accurate sensing with reduced power consumption, these algorithms will increase the safety and reliability of autonomous systems. The proposed techniques will enable autonomous systems to react safely and robustly in real time to unexpected environmental changes without immediate operator intervention.<br/><br/>This I-Corps project will explore the commercialization of neuromorphic sensing and control algorithms that enable accurate environmental sensing from moving robotic platforms. Autonomous navigation requires processing data from exteroceptive sensors for the purposes of obstacle avoidance and target tracking. These tasks must be accomplished in real time with minimal latency to maximize the capabilities and reliability of the autonomous robot. Neuromorphic cameras sense the environment with sub-millisecond latency and, unlike traditional cameras, provide information only about changes in the scene. The algorithms which will be explored by this project efficiently process the data from neuromorphic sensors to detect the presence of moving targets and stationary obstacles to enable efficient autonomous control for high-speed aerial and ground-based robots in uncertain and rapidly changing environments. These algorithms include neuromorphic control techniques which enable autonomous control in the presence of both environmental uncertainties such as disturbances and uncertain variations in the physical parameters of the robot. The proposed techniques have been validated in high-fidelity simulations using benchmark datasets and have been shown to be capable of rapid adaptation to unexpected changes while maintaining control of the autonomous system.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1652561","CAREER: Robots that Help People","IIS","ROBUST INTELLIGENCE","03/15/2017","06/15/2018","Stefanie Tellex","RI","Brown University","Continuing grant","Reid Simmons","02/28/2022","$208,714.00","","stefie10@cs.brown.edu","BOX 1929","Providence","RI","029129002","4018632777","CSE","7495","1045, 7495","$0.00","As robots become more prevalent, it is crucial to develop ways for people to collaborate with them.  This proposal aims to create collaborative robots through a combination of communication, perception, and action.  Existing approaches are typically tailored to specific applications; yet people want to talk to robots about everything they can see and do.  To address such limitations, this project will create a unified framework to enable robots to communicate with people to learn their needs, plan how to achieve them, and then perceive and act in the world in order to meet those needs.  The research will be demonstrated with robots that can assist with household tasks, such as cooking and cleaning, as well as in manufacturing settings, such as collaborative assembly.  The project will expose many people to collaborative robotics through an internship program with local high schools, a regional robotics conference, and the Million Object Challenge.<br/><br/>This project will create a model, the Human-Robot Collaborative Partially Observable Markov Decision Process, that enables robots to 1) automatically acquire object-oriented models of objects in the physical world; 2) communicate with people to understand their needs and how to meet them; and 3) act to change the world in ways that meet people's needs.  Creating a unified framework requires bridging gaps between different aspects of the robotic system.  This project focuses on creating a single probabilistic graphical model to represent the robot's states and actions in a hierarchical framework, allowing the robot to make plans that take into account its own uncertainty and to communicate with a person about everything it can see and everything it can do.  Focusing on collaboration leads to reformulations of traditional problems in computer vision, planning, and natural language understanding enabling the robot to collaborate in new and more natural ways.  <br/>"
"1139161","Collaborative Research: Socially Assistive Robots","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems (CHS), ROBUST INTELLIGENCE, EXPERIMENTAL EXPEDITIONS","04/01/2012","08/10/2017","Pamela Hinds","CA","Stanford University","Continuing grant","Ephraim P. Glinert","03/31/2019","$1,340,840.00","Daniel Schwartz","phinds@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","1640, 7367, 7495, 7723","1640, 7367, 7723, 9251","$0.00","Socially Assistive Robots<br/>Lead PI/Institution: Brian Scassellati, Yale University<br/>This Expedition will develop the fundamental computational techniques that will enable the design, implementation, and evaluation of robots that encourage social, emotional, and cognitive growth in children, including those with social or cognitive deficits.  The need for this technology is driven by critical societal problems that require sustained, personalized support that supplements the efforts of educators, parents, and clinicians.   For example, clinicians and families struggle to provide individualized educational services to children with social and cognitive deficits, whose numbers have quadrupled in the US in the last decade alone.  In many schools, educators struggle to provide language instruction for children raised in homes where a language other than English is spoken (over 20%), the fastest-growing segment of the school-age population.  This Expedition aims to support the individual needs of these children with socially assistive robots that help to guide the children toward long-term behavioral goals, that are customized to the particular needs of each child, and that develop and change as the child does.  <br/>To achieve this vision, this Expedition will advance the state-of-the-art in socially assistive human-robot interaction from short-term interactions in structured environments to long-term interactions that are adaptive, engaging, and effective. This progress will require transformative computing research in three broad and naturally interrelated research areas. First, the Expedition will develop computational models of the dynamics of social interaction, so that robots can automatically detect, analyze, and influence agency, intention, and other social interaction primitives in dynamic environments. Second, the Expedition will develop machine learning algorithms that adapt and personalize interactions to individual physical, social, and cognitive differences, enabling robots to teach and shape behavior in ways that are tailored to the needs, preferences, and capabilities of each individual. Third, the Expedition will develop systems that guide children toward specific learning goals over periods of weeks and months, allowing for truly long-term guidance and support. Research in these three areas will be integrated into socially assistive robots that are deployed in schools and homes for durations of up to one year.  <br/>This Expedition has the potential to substantially impact the effectiveness of education and healthcare for children, and the technological tools developed will serve as the basis for enhancing the lives of children and other groups that require specialized support and intervention. The proposed computing research is tied to a comprehensive student training program, bringing a compelling, engaging, and grounded STEM experience to K-12 students through in-school and after-school activities. It also establishes an annual training summit to provide undergraduates with the multi-disciplinary background to engage in this promising research area in graduate school. Finally, by establishing a brand name for socially assistive robotics, this effort will create a central authority for the distribution of high-quality, peer-reviewed information, providing a coherent focal point for enhancing outreach and education.<br/>For more information visit www.yale.edu/SAR"
"1566612","CRII: CHS: Leveraging Implicit Human Cues to Design Effective Behaviors for Collaborative Robots","IIS","CRII CISE Research Initiation","06/15/2016","06/01/2017","Daniel Szafir","CO","University of Colorado at Boulder","Continuing grant","Ephraim P. Glinert","05/31/2019","$174,300.00","","daniel.szafir@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","026Y","7367, 8228","$0.00","Robots have the potential to significantly benefit society by actively collaborating with people in critical domains including manufacturing, healthcare, and space exploration.  But to provide effective assistance, robots must be able to work with people in a natural, intuitive, and socially adept manner.  Current human-robot collaborations require that people explicitly communicate their goals and desired responses to robotic partners.  As a result, joint human-robot activities bear little resemblance to scenarios involving human-human teamwork, where people are able to understand their partner's implicit cues, such as eye gaze, facial expressions, and intonations, and intuit appropriate responses, such as moving to a certain location, preemptively fetching a tool, or providing a clarification.  The PI's goal in this project is to establish a research program that will explore the design of effective behaviors for collaborative robots by developing computational models that enable them to sense implicit human communicative cues and guide robot responses by inferring cue intent, and to evaluate the effectiveness of the new algorithms in human-robot studies.  The research holds significant promise of benefiting society by helping to achieve a vision of robots acting as key contributors, partners, and assistants in human work, with applications across a range of activities including domestic housework, manufacturing, construction, healthcare, and space exploration.  In addition to disseminating project outcomes to the larger research community, the PI will build on his successful past outreach activities to provide opportunities for K-12 summer programs centered on robotics and computer science education.<br/><br/>To these ends, the PI will address the challenge of designing effective collaborative robots by developing a preliminary framework, process, and set of methods to sense and respond to implicit human communicative behaviors.  His approach will involve (1) observing and classifying implicit cues and responses for human-human teams engaged in an archetypical collaborative task, (2) developing computational models of the relationships between goals, cues, and responses using features and parameters extracted from observed behaviors, (3) integrating implicit cue sensing and response algorithms to guide robot behaviors in specific collaborative use cases, and (4) evaluating the effectiveness of these behaviors on collaborative task outcomes.  This research will produce a set of generalizable design principles for collaborative robots, generate open-source algorithms showcasing practical implementations, and advance knowledge regarding computational understanding of human behaviors.  Overall, the work will lead to robots that are able to work more effectively with people and accelerate the integration of assistive robots into society.  It will synthesize theories of human communication and explore their application to human-robot interaction, as well as advancing knowledge regarding how robots might provide assistance as human collaborators and the types of sensors necessary for robots working closely with human partners.  Implicit sensing and response algorithms that have been empirically validated in HRI experiments will be disseminated as modules for the open-source Robotic Operating System (ROS)."
"1819709","SBIR Phase I:  Drones for Industrial Indoor Robotic Applications","IIP","SMALL BUSINESS PHASE I","06/15/2018","06/13/2018","SK Ganapathi","CA","Vimaan Robotics, Inc.","Standard Grant","Muralidharan S. Nair","01/31/2019","$225,000.00","","kg.ganapathi@vimaanrobotics.com","830 Stewart Drive","Sunnyvale","CA","940854513","6507047714","ENG","5371","5371, 8034","$0.00","The broader impact / commercial potential of this project would be in the ability to deploy drones in industrial and commercial indoor environments as aerial robots.  A key requirement to deploying drones in such indoor environments in the presence of people is to make them safe and non-threatening.  In addition, for drones to function as robots, they need to be made fully autonomous and minimize the need for human operation or intervention.  These attributes are not possible with conventional drone technology today.  The ability to use drones as aerial robots can open up opportunities in large markets such as warehouse inventory scanning, construction, security, and factory automation.  Such robots can enable functions such as scanning and reconstruction of the environment, or also ?pick and place? at high throughput within factories.  The use of drones in industrial indoor environments for these applications can also result in broader societal benefits, including improved worker safety inside industrial indoor environments (by performing tasks that may otherwise require harnesses, forklifts or ladders); reduced environmental impacts (in construction sites by catching discrepancies early and minimizing rework and material wastage) and macroeconomic benefits (enabling automated factories of the future and bringing back US jobs).  <br/><br/>This Small Business Innovation Research (SBIR) Phase I Project has the potential to advance the frontiers of knowledge in design and control systems for use in drones and other applications.  This unique approach redefines the control systems for rotorcraft, and enables a drone with dramatically improved metrics ? as much as 10X -- that are traditionally used to characterize the performance of drones.  In this Phase I project, Vimaan plans to complete the design and modeling of the system, develop the control mechanisms for the system, and integrate, test and demonstrate the application of the innovation to a drone that has the above attributes.  During the project, Vimaan will need to overcome some critical technical challenges in the components and systems design, the control circuitry and controls algorithms and the power budgets, timings and optimizations of the sub-systems for the required performance.  If successful, such an innovation would revolutionize decades old legacy technologies that have been hitherto deployed in rotorcraft, and make possible attributes that have been long sought after by the aerospace industry.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1747193","SBIR Phase I:  Cloud Based Laboratory for Remote Experiential Learning in Robotics","IIP","SMALL BUSINESS PHASE I","01/01/2018","12/26/2017","Raghav Mahalingam","TX","Apptronik","Standard Grant","Rajesh Mehta","12/31/2018","$224,924.00","","rmahalingam@apptronik.com","10705 Metric Blvd Ste 103","Austin","TX","787584522","5123008171","ENG","5371","5371, 8031","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to enable students and trainees to take state-of-the-art robotics laboratory classes from anywhere in the world. The proposed learning system is aimed to be incorporated as online courses, with the potential of being attended by more than a million students. The addressable market represents hundreds of millions of dollars considering online courses, secondary schools and industrial training. Laboratory courses in colleges and high schools require students to be physically present next to the equipment. With the proposed remote robotics laboratory, students and trainees can take laboratory classes just turning on their mobile devices or computers. Most importantly, the students can conduct the laboratory tutorials anywhere across the globe and at any time. This technology can be transformative for accessing expensive laboratory equipment not present in many institutions or companies. The system we provide consists of a robotic device currently being used inside NASA robots. Therefore, students using the remote laboratory will learn the use of real-world, state-of-the-art equipment that can be highly valuable for their job careers in STEM fields.<br/><br/>The proposed project will solve two key problems in online learning. First, no known commercially available laboratory online course exists that provides students remote hands-on experimentation. The second is that the same content is delivered to all students regardless of their current understanding level. Distributed communications, robotic software and web framework technologies will be integrated to provide access to state-of-the-art laboratory equipment. The second key innovation is the delivery of content adaptively tailored to individual needs. The innovation, consists of three key components. A web framework that connects equipment to servers and personal mobile devices, an intelligent content tutoring system, scheduling usage times and student evaluation regarding skill acquisition and assessments. The team anticipates that being remotely located will be slightly less effective than being next to the equipment but superior than learning theory only."
"1745591","I-Corps: Modular throwable robot for inspection and characterization","IIP","I-Corps","07/01/2017","07/12/2017","Herbert Tanner","DE","University of Delaware","Standard Grant","Cindy WalkerPeach","12/31/2018","$50,000.00","","btanner@udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","ENG","8023","9150","$0.00","The broader impact/commercial potential of this I-Corps project lies in offering modular and reconfigurable mobile robotics solutions for deployment in environments that maybe unsafe for humans.  Modularity offers a unique opportunity to address needs in multiple markets with a single solution when coupled with a suite of specific attachment modules.  It is envisioned that the platform will first be adopted by law enforcement.  Other market that will be explored include defense applications, where there seems to be interest in throwable robots.  Robotic assistance for environmental management is another potential market area.<br/><br/>This I-Corps project is based on developments in small mobile robots for applications in search, rescue and reconnaissance.  This modular platform is designed to support efforts in the context of ""robotics science of safety.""  Novel aspects in design provide more advanced mobility characteristics than currently available platforms. The locomotion designs spawns new questions and opportunities for basic research in legged locomotion.  A modular form-factor makes this robot accessible to a larger audience, with an inexpensive baseline model that can be upgraded with sensor and hardware packages as needed by the customers.  Throwable, and miniature sized robots are currently an asset to operations involving reconnaissance, inspection and characterization in dangerous environments.  Driven by customer feedback, the features of this robot can carefully evolve to meet the needs of each customer segment."
"1317989","NRI: Small: Assistive Robots for Blind Travelers","CBET","SPECIAL INITIATIVES, Disability & Rehab Engineering, National Robotics Initiative","09/01/2013","05/23/2017","Mary Dias","PA","Carnegie-Mellon University","Standard Grant","Christina Payne","02/28/2019","$986,571.00","Aaron Steinfeld","mbdias@ri.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","1642, 5342, 8013","010E, 7923, 8086, 9251","$0.00","PI: Dias, M. Bernadine; Steinfeld, Aaron<br/>Proposal Number: 1317989<br/><br/>Summary: As robotics technology evolves to a stage where co-robots become a reality, we need to ensure they are equally capable of interacting with humans with disabilities. The proposed work addresses this challenge by exploring meaningful human-robot interaction in the context of assistive robots for blind travelers. For people with disabilities independent transportation remains a major barrier to employment and quality of life. Furthermore, emergency situations necessitating evacuation is one of the greatest fears they face. The key question we seek to answer in the proposed work is: what role can co-robots play in empowering people with disabilities to safely travel to and navigate unfamiliar environments? We hypothesize that co-robots can enhance the safety and independence of these travelers by assisting them to navigate unfamiliar urban environments effectively and providing support when evacuating. We begin our proposed work with a needs assessment to understand the preferences and challenges of blind travelers. The ultimate objective is to enhance the safety and independence of blind travelers.<br/><br/>Intellectual Merit: The proposed work explores three principal research areas applied to three scenarios relevant to assistive robots for blind travelers: (1) information exchange and object manipulation, (2) assistive localization, and (3) urban navigation and emergency building evacuation. The research areas we plan to explore are accessible interfaces, assistive interaction modalities, and effective cooperation mechanisms. Envisioned scenarios include robots assisting humans to localize within necessary resolution and context using a combination of perception, robot localization, and crowdsourcing, robots assisting humans to retrieve lost or fallen objects or locate objects or people of interest, robots assisting humans to interact with other aspects of the environment such as reading notices, and robots assisting humans during emergency evacuation of buildings. We will also explore means of these travelers ""teaching"" the robots to do tasks of interest to them. The robots will have to reason intelligently about task allocation among themselves and coordinating with humans when needed. Overall, the proposed research will significantly advance the knowledge of how assistive robots can meaningfully and effectively interact with travelers with disabilities. The uniqueness of the proposed research is captured in the accessibility of the interfaces, the richness of the interaction modalities, and the flexibility and range of the cooperation mechanisms.  The combination of these contributions will significantly advance the state of the art in assistive technology as well as human-robot interaction.<br/><br/>Broader Impact: The team has a strong commitment to undergraduate research experience. Over 75% of the students mentored by the Principal Investigator and Co-Principal Investigator have been women, minorities, or people with disabilities. This commitment extends to the team's instructional activities. Team members regularly incorporate research findings into class presentations, guest lectures, and seminars. The team is also committed to community outreach. Both Dias and Steinfeld regularly speak to non-academics and will include aspects of this project in such talks. A final educational outcome will be several planned workshops at our partner organizations and the outcomes from the proposed work are expected to impact operations and methodologies used at these organizations. The assembled team of researchers and partner organizations further enhances the broader impact of this proposal. Principal Investigator Dias is one of the very few female robotics faculty members at the university and in the discipline. She is engaged in many mentoring and leadership activities to encourage and sustain the participation of women in computing and to address the needs of technologically underserved communities. The proposed team of undergraduate students, a graduate student, and a postdoctoral research assistant will also gain significant mentoring and education through their participation in this research. Industry interaction extends beyond regular contact due to faculty involvement in high profile centers. The research and evaluation program is specifically geared towards people with disabilities. Therefore, the contributions of the proposed work will make significant advancements towards realizing the vision of safe and independent travel for people with disabilities. The results of the proposed work will be disseminated broadly through a variety of avenues and all outcomes of the research will be made available in accessible formats to the community partners and their networks."
"1511792","Actualizing STEM Potential in the Mississippi Delta","DRL","ITEST","07/15/2015","07/08/2015","Brenda Brand","VA","Virginia Polytechnic Institute and State University","Standard Grant","Michael Ford","06/30/2019","$1,641,313.00","Daniel Trent, Dr. Qiang He, Takumi Sato","bbrand@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","EHR","7227","","$0.00","This project will advance efforts of the Innovative Technology Experiences for Students and Teachers (ITEST) program to better understand and promote practices that increase students' motivations and capacities to pursue careers in fields of science, technology, engineering, or mathematics (STEM) by investigating the effectiveness of an existing collaborative robotics program. The program will positively influence the engineering self-efficacy and orientation to STEM majors with African American students living in an underserved region of the United States, the Mississippi Delta.  Students in this program are immersed in engineering design activities requiring the application of science and mathematics principles.  The program model includes pre-engineering courses in computer science, computer aided drafting, and electronics. These are designed and facilitated by university faculty. Undergraduate seniors are trained by faculty and then serve as mentors. Engineering design activities, career orientation activities and robotics summer camps for elementary and middle school students are facilitated by high school faculty.  At the beginning of the spring semester, students participate in an international robotics competition.  This robotics program is year-long and occurs after school, and halfway through the year students enter their designs in a robotics competition.  Beginning in the freshmen year, students are allowed to remain in the program throughout their years in high school. An understanding of the components that positively influence the African American students' beliefs about their abilities in STEM disciplines and their perceptions of their identification with STEM could be useful for understanding and decreasing the gap in STEM majors that exists with students from underserved populations in the United States.  <br/><br/>This longitudinal mixed methods research study is designed to investigate the influence of engineering design and career orientation activities implemented in a collaborative robotics/pre-engineering program on African American students' self-efficacy, and scientific identity, to better understand factors influencing their achievement in STEM disciplines and orientation to STEM majors.  This is a four year study, allowing the researchers to follow a group of students from freshman to the end of their senior year, so that key factors influencing the students' learning and achievement in the engineering course activities can be observed and documented during the peak years of decision making for college majors and careers.  This study is unique in terms of its location and population of students, and because it is longitudinal and utilizes a mixed methods approach.   While this study investigates the effectiveness of the program on the engineering self-efficacy, scientific identity and achievement of program objectives for students in this program, the findings of the study could also be valuable for informing initiatives devoted to increasing the numbers of students from other marginalized groups majoring in STEM fields. Quantitatively, this research employs pre and post measures to determine changes in students engineering self-efficacy and scientific identities.   Qualitatively, field notes from classroom observations and interviews with the high school students provide data on specific program elements determined to be effective in positively influencing the African American students' achievement of program objectives and decisions to pursue STEM careers."
"1537257","NRI: Collaborative Research: A Dynamic Bayesian Approach to Real Time Estimation and Filtering in Grasp Acquisition and Other Contact Tasks (Continuation)","IIS","National Robotics Initiative","09/01/2015","08/05/2015","Siwei Lyu","NY","SUNY at Albany","Standard Grant","Ephraim P. Glinert","05/31/2019","$220,997.00","","lsw@cs.albany.edu","1400 WASHINGTON AVE","Albany","NY","122220100","5184374550","CSE","8013","8086","$0.00","A current weakness of robots is their inability to quickly and reliably perform contact tasks in unstructured environments.  The goal of this project, which represents a collaboration between faculty at two partner institutions, is to alleviate this shortcoming by developing techniques that will afford robots accurate real-time perception in tasks exhibiting intermittent contact.  Project outcomes will have a strong impact in manipulation tasks, as robots become more capable and autonomous.  The PIs also expect successful applications in other areas, for instance to drive real-time haptic displays in augmented reality systems, to extract human manipulation strategies from observed kinesthetic demonstrations, and to identify model parameters to improve simulation accuracy, not to mention in advancing the level of autonomy for space and undersea exploration.  Additional applications outside of robotics are anticipated in situations where a system experiences abrupt state transitions and the goal is either state estimation or real-time feedback control (e.g., chemical, financial, and geological systems).  The PIs' labs have a track record of supporting women and under-represented minorities, and the research will be integrated into a variety of pedagogical activities at the graduate and undergraduate level on both campuses.<br/><br/>In previous work the team proposed the DBC-SLAM framework, in which continuous states (i.e., poses, velocities and contact impulses), and discrete contact states (i.e., contact-noncontact and stick-slip) of the manipulated objects, are tracked and important model parameters are estimated.  In this research, they will extend that work significantly in two directions.  First, they will design new parallel, anytime complementarity problem (CP) solvers in order to attain real-time performance.  Second, they will enhance the dynamic Bayesian models in DBC-SLAM to allow the use of point-cloud observations and more complex geometric models of the objects, robot links, and environment.  The intellectual merit of the project lies in three main activities: first, the creative, yet rigorous, technical process of designing perception algorithms based on fundamental first principles of nonsmooth mechanics and Bayesian estimation in a way that can utilize point-cloud data; second, achieving real-time performance by exploiting the mathematical structure and properties of both the nonsmooth multibody dynamics and CPU/GPU computing systems; and third, pursuing the first two activities in a way that sheds light on the trade-offs between estimation accuracy and speed."
"1327566","NRI: Large: Collaborative Research: Complementary Situational Awareness for Human-Robot Partnerships","IIS","National Robotics Initiative","10/01/2013","07/05/2016","Nabil Simaan","TN","Vanderbilt University","Continuing grant","Jie Yang","09/30/2019","$1,279,600.00","","nabil.simaan@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","CSE","8013","7925, 8086, 9150, 9251","$0.00","This work will advance human-robot partnerships by establishing a new concept called complementary situational awareness (CSA), which is the simultaneous perception and use of the environment and operational constraints for task execution. The proposed CSA is transformative because it ushers in a new era of human-robot partnerships where robots act as our partners, not only in manipulation, but in perception and control. This research will establish the foundations for CSA to enable multifaceted human-robot partnerships. Three main research objectives guide this effort: 1) Real-time Sensing during Task Execution: design low-level control algorithms providing wire-actuated or flexible continuum robots with sensory awareness by supporting force sensing, exploration, and modulated force interaction in flexible unstructured environments; 2) Situational Awareness Modeling: prescribe information fusion and simultaneous localization and mapping (SLAM) algorithms suitable for surgical planning and in-vivo surgical plan adaptation; 3) Telemanipulation based on CSA: Design, construct, and integrate robotic testbeds with telemanipulation algorithms that use SLAM and exploration data for online adaptation of assistive telemanipulation virtual fixtures. This research also includes investigation of previously unaddressed questions on how sensory exploration and palpation data can be used to enable online-adaptation of assistive virtual fixtures based on force and stiffness data while also taking into account preoperative data and intraoperative correction of registration parameters.<br/><br/>The proposed work will restore the situational awareness readily available in open surgery to minimally invasive surgery. This will benefit patients by enabling core technologies for effective and safe natural orifice surgery or single port access surgery. The societal impact of the proposed work on these two surgical paradigms is reduced pain for patients, shorter hospital stay, improved cosmesis and patients' self image, and lower costs. We also believe that CSA will impact manufacturing where its future will require people and robots working together in a shared space on collaborative tasks. Also, the same concepts of CSA apply to telemanipulation in constrained and unstructured environments and the proposed research has direct relevance to robot-human partnerships for space exploration. To ensure this broader impact will be achieved, an advisory board has been assembled with experts from medicine, manufacturing and aerospace. Finally, the PIs will facilitate collaboration in the medical robotics research community by making our software and hardware designs available on-line and using commercial-grade hardware available at multiple institutions."
"1753687","EAGER: Microscopic Deployment Algorithms to Achieve Macroscopic Objectives for Spatially Distributed Stochastic Networks of Mobile Agents","CMMI","Dynamics, Control and System D","04/01/2018","02/20/2018","Efstathios Bakolas","TX","University of Texas at Austin","Standard Grant","Irina Dolinskaya","01/31/2020","$125,002.00","","bakolas@austin.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","ENG","7569","030E, 034E, 7916, 8024","$0.00","This EArly-concept Grant for Exploratory Research (EAGER) project will study new ways to control large networks of mobile agents to accomplish a variety of tasks. The first challenge addressed by this project is to account for uncertainty in the position and velocity of each agent. This uncertainty can be caused by inaccurate measurements or imperfect communications. To capture uncertainty, this project uses probability distributions to quantify the collective behavior of all the agents. This is called the macroscopic description of the network. The second challenge addressed by this project is to find control laws that achieve a desired macroscopic behavior of the network, using only distributed algorithms and local information. That is, the project will find rules by which each agent will control its own velocity, based only on knowledge of a few neighboring agents, but in such a way that a desired macroscopic probability distribution is obtained. The local dynamic behavior of the individual agents is called the microscopic description of the network, and the goal of this project is to find rules for microscopic behavior that give rise to a desired macroscopic result. An example is the control of a large group of autonomous mobile robots that pick up and deliver packages across a wide geographic region. The macroscopic goal is that, for each point in the region, the probability density of a delivery robot being available should match the probability density that a package needs to be picked up. For large numbers of robots, it is impractical to achieve this macroscopic goal by controlling every individual robot from a single command center. Instead, to avoid prohibitive requirements for communication bandwidth, information storage, and data processing, the computational task should be distributed among the individual robots -- however, the individual robots can only share data with a few nearby units. The challenge addressed by this project is for the individual robots to plan their movements based only on this limited local exchange, in such a way that the entire network of robots spreads out across the delivery region in a pattern mirroring the customer demand. This project advances the national prosperity and helps to secure the national defense by improving the ability to control large networks of mobile robots for commercial applications such as package delivery, or security applications such as surveillance and interdiction.<br/><br/>The macroscopic deployment problem is approached in three steps. The first step is to define a single fictitious agent that captures the macroscopic state of the multi-agent network. This is done by choosing the mean and the covariance of the individual states of all the constituent agents of the network to be the statistical quantities that determine the probability distribution of the state of the representative agent. Tools from stochastic optimal control theory are then applied to steer the network towards areas of high importance. The second step is to solve the microscopic deployment problem for the constituent agents of the network, by assigning tasks to different agents based on their suitability to accomplish these tasks. The proposed solution approach is based on a divide-and-conquer scheme that is centered around a special class of Voronoi-like spatial partitions (sub-divisions of the workspace of the multi-agent network). The expected outcomes of this effort will include 1) stochastic control algorithms for the solution of the macroscopic control problem, 2) partitioning algorithms for the computation of Voronoi-like subdivisions of the network's workspace, 3) distributed algorithms for the solution of the microscopic control problem that leverage the Voronoi-like partitions and Lloyd's algorithm. The third and final step is to validate the proposed algorithms via a set of experimental demonstrations that will take place at the facilities for robotics research at the PI's home department.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1327597","NRI: Large: Collaborative Research: Complementary Situational Awareness for Human-Robot Partnerships","IIS","National Robotics Initiative","10/01/2013","05/11/2016","Howard Choset","PA","Carnegie-Mellon University","Continuing grant","Jie Yang","09/30/2019","$1,286,883.00","","choset@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","8013","7925, 8086, 9251","$0.00","This work will advance human-robot partnerships by establishing a new concept called complementary situational awareness (CSA), which is the simultaneous perception and use of the environment and operational constraints for task execution. The proposed CSA is transformative because it ushers in a new era of human-robot partnerships where robots act as our partners, not only in manipulation, but in perception and control. This research will establish the foundations for CSA to enable multifaceted human-robot partnerships. Three main research objectives guide this effort: 1) Real-time Sensing during Task Execution: design low-level control algorithms providing wire-actuated or flexible continuum robots with sensory awareness by supporting force sensing, exploration, and modulated force interaction in flexible unstructured environments; 2) Situational Awareness Modeling: prescribe information fusion and simultaneous localization and mapping (SLAM) algorithms suitable for surgical planning and in-vivo surgical plan adaptation; 3) Telemanipulation based on CSA: Design, construct, and integrate robotic testbeds with telemanipulation algorithms that use SLAM and exploration data for online adaptation of assistive telemanipulation virtual fixtures. This research also includes investigation of previously unaddressed questions on how sensory exploration and palpation data can be used to enable online-adaptation of assistive virtual fixtures based on force and stiffness data while also taking into account preoperative data and intraoperative correction of registration parameters.<br/><br/>The proposed work will restore the situational awareness readily available in open surgery to minimally invasive surgery. This will benefit patients by enabling core technologies for effective and safe natural orifice surgery or single port access surgery. The societal impact of the proposed work on these two surgical paradigms is reduced pain for patients, shorter hospital stay, improved cosmesis and patients' self image, and lower costs. We also believe that CSA will impact manufacturing where its future will require people and robots working together in a shared space on collaborative tasks. Also, the same concepts of CSA apply to telemanipulation in constrained and unstructured environments and the proposed research has direct relevance to robot-human partnerships for space exploration. To ensure this broader impact will be achieved, an advisory board has been assembled with experts from medicine, manufacturing and aerospace. Finally, the PIs will facilitate collaboration in the medical robotics research community by making our software and hardware designs available on-line and using commercial-grade hardware available at multiple institutions."
"1637949","NRI: Collaborative Research: Experiential Learning for Robots: From Physics to Actions to Tasks","IIS","National Robotics Initiative","10/01/2016","08/17/2016","Gregory Hager","MD","Johns Hopkins University","Standard Grant","James Donlon","09/30/2019","$648,000.00","Marin Kobilarov","hager@cs.jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","8013","8086","$0.00","Recent advances in machine learning coupled with unprecedented archives of labeled data are advancing machine perception at a remarkable rate. However, applying these advances to robotics has not advanced as quickly because learning for robotics requires both active interaction with the physical world, and the ability to generalize over a variety of task contexts. This project addresses this knowledge gap through the development of new learning methods to produce experience-based models of physics. In this approach, an object or category specific model of physics is learned directly from perceptual data rather than deploying general-purpose physical simulation methods. These physical models will support both direct control of action - for example pouring a liquid into a container, and the learning of the physical effects of sequences of actions - for example planning to handle fluids in a laboratory. More generally, these methods will provide a means for robots to learn how to handle fluids, soft materials, and other complex physical phenomena.<br/><br/>    The proposed experiential learning framework will build on recent advances in deep neural networks. The key problem is to learn the mappings between raw perceptual and control data via a low-dimensional implicit physics space representing a perception-based physical model of how an object acts in the environment. Three directions will be investigated: 1) the development of experiential physics models for object interaction and fluid flow that have strong predictive capabilities, 2) creating mappings directly from experiential models to control of actions such as pouring or moving an object, 3) the assembly of local experience-based controllers into complex tasks from interactive demonstration. Additionally, the project will develop unique data sets that include physical models, simulations, data components, and learned components that other groups can access and build on to enable comparative research similar to what has emerged in machine perception."
"1813940","AF: Small: RUI: Competitive Search, Evacuation and Reconfiguration with Coordinated Mobile Agents","CCF","ALGORITHMIC FOUNDATIONS","06/01/2018","05/21/2018","Sunil Shende","NJ","Rutgers University Camden","Standard Grant","Rahul Shah","05/31/2021","$237,473.00","","shende@camden.rutgers.edu","311 N. 5th Street","Camden","NJ","081021400","8562252949","CSE","7796","7923, 7929, 7934, 9229","$0.00","In recent years, innovations in special-purpose sensor hardware and machine-learning algorithms have led to rapid advances in robotics and autonomous vehicle technology. This project aims to develop and analyze algorithms for an ensemble of mobile agents working in parallel to achieve coordinated, goal-directed motion in simple geometric spaces that are abstractions of complex terrains. The agents cooperate among themselves to efficiently search, explore, synchronize and reconfigure into patterns using distributed algorithms with limited memory, sensing and communication capabilities. The research will contribute to a deeper understanding of coordination protocols to complete navigational tasks, even when some of the agents may be faulty. Results from the research will provide critical insights that can be used in robot-assisted applications such as search-and-rescue in hostile or unknown terrains, or surface exploration needed to develop and maintain future colonies and human outposts on other planets. The study of reconfiguration problems will also provide ideas that can shed light on previously unexplained aspects of flocking phenomena in birds, such as murmurations. The project will involve undergraduate students in theoretical research and will train them to develop and maintain an open-source repository of distributed algorithms for robot coordination problems and their animations. In addition, results from the project will be archived as a permanent online resource for the parallel and distributed computing community at large. Two specific annual initiatives for outreach will be a part of the project: firstly, participation by the investigator and undergraduate research students in the Rutgers Future Scholars program, and secondly, conducting workshops for K-12 teachers to teach basic computational and algorithm design skills.<br/><br/>The project addresses fundamental theoretical problems of efficient, coordinated exploration and reconfiguration by a team of mobile agents as they work together to accomplish a computational task in simple geometric spaces.  Three basic problem settings are considered: (a) the search problem, where an unknown target location, which can only be sensed when reached, has to be found by at least one robot in the team, (b) the evacuation problem, that requires some subset of the robots to reach an unknown exit location in the region after it has been found, and (c) the reconfiguration problem, where the robots must rearrange themselves in a certain desired configuration based on either a given arrangement or on local rules. Within each problem setting, the goal is to develop an algorithm for the robots so that they can attain the desired configuration or complete the task defined by the problem with the minimum amount of resource usage possible, e.g. total distance traveled or time taken. Many interesting variants of the problems will also be studied, such as the peculiarities of the region's geometry, constraints on the communication capabilities of the robots, and handling faulty robots that may be benign or malicious.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1327657","NRI: Large: Collaborative Research: Complementary Situational Awareness for Human-Robot Partnerships","IIS","COLLABORATIVE RESEARCH, IIS SPECIAL PROJECTS, National Robotics Initiative","10/01/2013","04/17/2015","Russell Taylor","MD","Johns Hopkins University","Continuing grant","Wendy Nilsen","09/30/2019","$1,228,609.00","","rht@cs.jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","7298, 7484, 8013","5946, 7925, 8086, 9251","$0.00","This work will advance human-robot partnerships by establishing a new concept called complementary situational awareness (CSA), which is the simultaneous perception and use of the environment and operational constraints for task execution. The proposed CSA is transformative because it ushers in a new era of human-robot partnerships where robots act as our partners, not only in manipulation, but in perception and control. This research will establish the foundations for CSA to enable multifaceted human-robot partnerships. Three main research objectives guide this effort: 1) Real-time Sensing during Task Execution: design low-level control algorithms providing wire-actuated or flexible continuum robots with sensory awareness by supporting force sensing, exploration, and modulated force interaction in flexible unstructured environments; 2) Situational Awareness Modeling: prescribe information fusion and simultaneous localization and mapping (SLAM) algorithms suitable for surgical planning and in-vivo surgical plan adaptation; 3) Telemanipulation based on CSA: Design, construct, and integrate robotic testbeds with telemanipulation algorithms that use SLAM and exploration data for online adaptation of assistive telemanipulation virtual fixtures. This research also includes investigation of previously unaddressed questions on how sensory exploration and palpation data can be used to enable online-adaptation of assistive virtual fixtures based on force and stiffness data while also taking into account preoperative data and intraoperative correction of registration parameters.<br/><br/>The proposed work will restore the situational awareness readily available in open surgery to minimally invasive surgery. This will benefit patients by enabling core technologies for effective and safe natural orifice surgery or single port access surgery. The societal impact of the proposed work on these two surgical paradigms is reduced pain for patients, shorter hospital stay, improved cosmesis and patients' self image, and lower costs. We also believe that CSA will impact manufacturing where its future will require people and robots working together in a shared space on collaborative tasks. Also, the same concepts of CSA apply to telemanipulation in constrained and unstructured environments and the proposed research has direct relevance to robot-human partnerships for space exploration. To ensure this broader impact will be achieved, an advisory board has been assembled with experts from medicine, manufacturing and aerospace. Finally, the PIs will facilitate collaboration in the medical robotics research community by making our software and hardware designs available on-line and using commercial-grade hardware available at multiple institutions."
"1417769","DR K-12: Teaching STEM with Robotics: Design, Development, and Testing of a Research-based Professional Development Program for Teachers","DRL","STEM + Computing (STEM+C) Part, DISCOVERY RESEARCH K-12","09/01/2014","06/30/2017","Vikram Kapila","NY","New York University","Continuing grant","John Cherniavsky","08/31/2019","$2,545,955.00","Jasmine Ma, Magued Iskander, Orit Zaslavsky, Catherine Milne","vkapila@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","EHR","005Y, 7645","8244","$0.00","Offering meaningful and motivating engineering contexts, such as robotics, within science and math courses constitutes a compelling strategy to address the Next Generation Science Standards and the Common Core State Standards for Math while enhancing science and math learning for all students. Using design-based research, with teachers as design partners, the project will create and refine project-based, hands-on curricula such that science and math content inherent in robotics and related engineering design practices are learned. To provide teachers with effective models to capitalize on robotics for elucidating science and math concepts, a design-based Professional Development program will be built using principles of technological, pedagogical, and content knowledge (TPACK). To ensure that teachers are well prepared, research-based practices and features of effective Professional Development will be adopted. Experts in robotics, engineering, education, curriculum design, and assessment--with experience in K-12 education, training, and outreach--have formed an interdisciplinary team to make robotics central to and sustainable in middle school science and math classrooms.<br/><br/>The research questions addressed in this project are qualitative in nature as appropriate for design research questions. The methodologies include teacher needs assessment, teachers' perceptions of robotics, pre and post testing, classroom observations, and surveys. Examples of the research questions are:<br/><br/>What characteristics of robotics  promote effective learning of middle school science and math?<br/><br/>What elements of Professional Development engender teachers' TPACK of robotics and link it with classroom science and math?<br/><br/>What are student prerequisites to effectively use robotics in science and math learning? <br/><br/>What are the gains in students' STEM engagement, interest, persistence, and career awareness? <br/><br/>The robotics curriculum will include physical science used in robot performance expectations and motion stability.  Additionally the curriculum will include the engineering design process consisting of problem definition, solution development, and design improvement. Robotics provides opportunities to support science and engineering practices of the Next Generation Science Standards such as developing and using models, planning and conducting  investigations, designing solutions, and analyzing and interpreting data.  The project will be aimed at middle school students and will provide substantial teacher professional development to implement the new curriculum modules. The partner schools have student bodies drawn from a diverse student population in New York City."
"1526534","NRI: Collaborative Research: Unified Feedback Control and Mechanical Design for Robotic, Prosthetic, and Exoskeleton Locomotion","IIS","National Robotics Initiative","09/01/2015","08/31/2015","Levi Hargrove","IL","Rehabilitation Institute of Chicago","Standard Grant","Radhakisan S. Baheti","08/31/2019","$302,981.00","","lhargrove@sralab.org","345 East Superior Street","Chicago","IL","606112654","3122384534","CSE","8013","092E, 8086","$0.00","There is a pressing need for wearable robots, e.g., prostheses and exoskeletons, which improve the quality of life for individuals with limited mobility - devices that work symbiotically with human users to achieve stable, safe and efficient locomotion.  At present, approximately 4.7 million people in the United States would benefit from an active lower-limb exoskeleton due to the effects of stroke, polio, multiple sclerosis, spinal cord injury, and cerebral palsy, and by 2050 an estimated 1.5 million people in the United States will be living with a major lower-limb amputation.  Yet current wearable robotic devices do not address this growing population's needs since they are bulky, heavy, noisy, and require large batteries for even short duration use, while implementing predominately hierarchical control algorithms.  Impeding innovation in this domain is the expensive and slow traditional design-build-test approach that ignores the tight coupling between hardware specifications and control algorithm performance.  The vision of this work is to provide a methodology---inspired by advancements in robotic locomotion---that allows lower-limb prostheses and exoskeletons to meet real-world requirements through the co-design of the electromechanical and feedback systems.  The transformative nature of this work, therefore, stems from its ability to realize wearable robots that synergize with humans to achieve increased mobility, providing a template for the growing robotic assistive device industry and potentially improving the quality of life of millions.  <br/><br/>To realize the vision of this work, the overarching research goal is to create a new unified control and design framework that will allow for the efficient and stable locomotion of robots, prostheses, and exoskeletons.  A key aspect of this control methodology is the ability to continuously mediate between different objectives enforcing stability and safety in an efficient manner through force-based interactions among (wearable) robotic devices, their environment and the user. The resulting framework will be utilized via control-in-the-loop mechanical design of prostheses and exoskeletons with stringent design requirements, tested experimentally on a novel humanoid robot, and clinically evaluated through human subject trials.  This work is, therefore, guided by the following specific goals:  (1) develop a unified online optimization-based control framework for (wearable) robotic locomotion that efficiently mediates stability, safety and force constraints, (2) create a feedback loop between formal control synthesis and the mechanical design of wearable robots that satisfy stringent performance requirements,  (3) accelerate clinical testing by translating controllers formally and experimentally from bipedal humanoid robots to prostheses and exoskeletons.  As a result of these research goals, this work has the potential to create the next generation of robotic systems that enable stable, safe and efficient human mobility."
"1637854","NRI: Collaborative Research: Towards Robots with Human Dexterity","IIS","National Robotics Initiative","01/01/2017","08/31/2016","Dagmar Sternad","MA","Northeastern University","Standard Grant","Reid Simmons","12/31/2019","$500,000.00","","d.sternad@northeastern.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","8013","8086, 8089","$0.00","Despite vastly slower ""hardware"" and ""wetware,"" human dexterity vastly out-performs modern robots. This project studies apparently-simple tasks - managing the kinematic constraint on hand motion required to open a door; and dealing with the dynamic complexity of liquid sloshing in a cup of coffee - that profoundly challenge robots but humans perform with ease. The key idea is that humans manage skillful physical interaction with these objects by exploiting clever combinations of primitive dynamic actions that do not require continuous intervention. A novel theory to describe the effectiveness of this approach is developed and tested by experiments with human subjects. The theory is applied to transfer comparable skill to robots, despite manifestly different hardware. If successful, these robots will be more capable, more comprehensible, and more collaborative partners with humans.<br/><br/>The central experimental challenge is to determine the essential strategy underlying humans? remarkable competence in physical interaction tasks. Three hypotheses reflecting major themes in contemporary motor neuroscience are tested: Humans 1) develop models of object dynamics sufficient to pre-compute and execute required hand motions (similar to modern robot programming); 2) choose forces and motions to minimize muscular effort (similar to optimizing efficiency); or 3) exploit dynamic primitives to robustly achieve satisficing (good-enough) performance. The theoretical challenge is to formulate a coherent account combining the information-processing of brains (or computers) with the ""energy-processing"" of physical objects and their interactions. Classical equivalent circuit theory is re-purposed to define a neo-classical equivalent network theory, combining dynamic motion primitives with mechanical impedances (interactive dynamics). Mechanical impedances enjoy a key property, compositionality, that overcomes the curse of dimensionality."
"1522954","NRI: Collaborative Research: RobotSLANG: Simultaneous Localization, Mapping, and Language Acquisition","IIS","National Robotics Initiative","09/01/2015","08/06/2015","Jeffrey Siskind","IN","Purdue University","Standard Grant","Ephraim P. Glinert","08/31/2019","$650,000.00","","qobi@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","8013","8086","$0.00","Humans and robots alike have a critical need to navigate through new environments to carry out everyday tasks.  A parent and child may be touring a college campus; a robot may be searching for survivors after a building has collapsed.  In this collaboration by faculty at two institutions, the PIs envision human and robotic partners sharing common perceptual-linguistic experiences and cooperating in mundane tasks like janitorial work and home care as well as in critical tasks like emergency response or search-and-rescue.  But while mapping and navigation are now commonplace for mobile robots, when considering human-robot collaboration for even simple tasks one is confronted by a critical barrier: robots and people do not share a common language.  Human language is rich in linguistic elements for describing our spatial environment, the objects and places within it, and navigable paths through it (e.g., ""go down the hallway and enter the third door on the right."").  Robots, on the other hand, inhabit a metric world of occupied and unoccupied discretized grid cells, wherein most objects are devoid of meaning (semantics).  The PIs' goal in this project is to overcome this limitation by conjoining the well understood problem of simultaneous localization and mapping (SLAM) with that of language acquisition, in order to enable robots to learn to communicate with people in English about navigation tasks.  The PIs will spur interest in this novel research area within the scientific community by means of an Amazing Race challenge problem modeled after the reality television show of the same name, which will place robots and human-robot teams in unknown environments and charge them with completing a specific task as quickly as possible.  Other outreach activities will include visits to K-12 schools with demonstrations.  <br/><br/>This work will focus on simultaneous localization, mapping, and language acquisition, a field of inquiry that remains untouched.  The crucial principles are that semantics are formulated as a cost function, which in turn specifies a joint distribution over many variables including those capturing sensory input, language, the environment map, and robot motor control.  The cost function and joint distribution support standard inference of many forms, such as command following.  More importantly, they support multidirectional inference over multiple variable sets jointly, such as simultaneous mapping and language interpretation.  Within this innovative multivariate optimization-based framework, the PIs plan a thorough experimental regimen including both synthetic and real-world datasets of challenging environments, grounding the semantics of natural language in spatial maps of the realistic visual world and robot motor control, while navigating along particular paths or to arrive at particular destinations in (possibly novel) environments that are mapped not only in a geometric sense but also with linguistic underpinning to these particular paths and destinations.  The language approach is compositional and uses spatially-grounded representations of nouns (objects/places) and prepositions (relations between them).  These spatially-grounded representations will be modeled in the context of mapping.  Furthermore, the PIs will consider realistic environments and adapt visual models thereof according to the joint model.  The PIs are aware of no other work that jointly models mapping, vision, and language acquisition."
"1755766","CRII: RI: Embedded and Continuous Shape Morphing using Twisted-and-Coiled Artificial Muscle","IIS","ROBUST INTELLIGENCE","06/01/2018","05/24/2018","Jianguo Zhao","CO","Colorado State University","Standard Grant","Reid Simmons","05/31/2020","$175,000.00","","Jianguo.Zhao@colostate.edu","601 S Howes St","Fort Collins","CO","805232002","9704916355","CSE","7495","7495, 8228","$0.00","Many animals have the ability to locomote in different environments, such as on land, in the water, and in the air.  Developing biologically inspired robots with similar abilities would open up many new types of applications for robotics. Towards this goal, this research investigates a novel shape morphing scheme that can autonomously modify the shape of a structure, such as by changing legs to flippers. With shape morphing capabilities, robots can leverage varying shapes from the same structure for locomotion in different environments, which can drastically reduce the robot's costs while dramatically improving their performance. The approach can enable a structure to precisely morph into a three-dimensional shape without using bulky external sensors and actuators, making it suitable for various applications such as morphing wings, multimodal robots, programmable matter, foldable robots, etc. The project will also broadly impact STEM students of all ages through outreach to K-12 students, enhancement of existing curriculum with research-inspired projects, and promotion of undergraduate research.<br/><br/>The new shape morphing scheme is accomplished by embedding a novel twisted-and-coiled actuator (TCA) into soft materials, together with a thermoplastic material with temperature-dependent stiffness.  With the proposed scheme, this project aims to accomplish embedded and continuous shape morphing through closed-loop shape control enabled by the TCA's dual actuation and sensing capabilities. To do this, physics-based models will be first established to relate a desired shape of a structure to the embedded TCA's electrical resistance. Then, closed-loop shape control can be accomplished by controlling the TCA's resistance to a desired value. Finally, the proposed shape morphing scheme is applied to a miniature amphibious robot that can swim in water with straight legs and travel on ground by morphing the legs into a curved shape.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1408672","CHS: Medium: The Use of Robots as Intermediaries to Gather Sensitive Information from Children","IIS","Cyber-Human Systems (CHS), Unallocated Program Costs","07/01/2014","09/21/2016","Cindy Bethel","MS","Mississippi State University","Continuing grant","Ephraim P. Glinert","06/30/2019","$1,207,819.00","David May, Deborah Eakin, Melinda Pilkinton","cbethel@cse.msstate.edu","PO Box 6156","MISSISSIPPI STATE","MS","397629662","6623257404","CSE","7367, 9199","7367, 7924, 9150, 9251","$0.00","A recent report entitled ""Child Maltreatment 2011"" issued by the U.S. Department of Health & Human Services Administration for Children and Families estimated that more than 3.7 million children were the subjects of at least one report of maltreatment, and that over 681,000 children were found to be unique victims of child maltreatment in the United States.  This multidisciplinary research will compare the effectiveness of robot vs. human interviewers for gathering sensitive information from children, using situations in which this would commonly occur: cases of child eyewitness memory and child reports of bullying.  The PI argues that the use of a robot as an intermediary during these so-called forensic interviews could reduce or eliminate unintentional cues observed in human interviewers that result in inaccurate reports by children.  To validate her hypothesis the PI and her team will develop a systems architecture, an interactive user interface and an interactive robotic toolkit for interviewers, and perform a series of six studies involving children ages 8-11.  The interdisciplinary research team is comprised of experts in human-computer interaction, human-robot interaction, robotics, psychology, sociology, and social work, and the project will make contributions to each of these domains.  The team further includes a member of the legal profession as a consultant, who will iteratively evaluate the potential for extending the research findings to real-world legal proceedings and investigations.  Preliminary research conducted by the PI has attracted attention from the law enforcement and legal communities, so if successful this project has the potential to transform information gathering for investigative purposes.  The PI and her colleagues have been actively involved in community outreach in local middle schools and Boys and Girls Clubs with respect to the use of robots for eliciting information related to bullying, and this outreach will be extended to elementary school children involved in the current research.  <br/><br/>The research goals for this project will be accomplished through the development of an integrated robotic toolkit based on a novel Interactive Social Engagement Architecture (ISEA) and a unique interactive user interface.  ISEA provides a framework for the autonomous generation of robot behaviors for self-preservation and to convey social intelligence.  The toolkit will be designed to integrate behavior-based robotics, human behavior models, cognitive architectures, and user input to increase social engagement between a human and system (robot, avatar, etc.).  The interactive user interface will provide interviewers with the ability to use the robot as an intermediary for gathering sensitive information.  ISEA has three primary parallel paths for processing robot behaviors: (1) verbal behaviors based on expert user input from the interactive user interface; (2) autonomous self-preservation behaviors if the robot is threatened that consist of both verbal and non-verbal responses; and (3) non-verbal autonomous behaviors generated from sensor data coming from the environment, the current internal state of the robot, user input, and prior knowledge from the knowledge base/long-term memory.  As part of the research, six human studies will be conducted that use typical situations in which gathering sensitive information from children might occur.  Three of these experiments will examine whether child eyewitness memory is more accurate when a robot rather than a human presents misleading information during an interview, while the other three will examine whether children who have been victimized by bullying will be more likely to disclose that victimization to a robot as opposed to a human interviewer.   Some of these experiments will examine the role of gender both for humanoid robots and adult interviewers, using established forensic interview protocols, while others will examine whether interviewers high in social intelligence elicit more accurate child eyewitness memory and reports of bullying than those low in social intelligence (where social intelligence is defined by the use of gestural and facial non-verbal behaviors)."
"1527794","CHS: Small: Empowerment of Disabled Individuals via an Adaptive Framework for Indirect Human-Robot Interaction","IIS","Cyber-Human Systems (CHS)","09/01/2015","06/05/2017","Aman Behal","FL","University of Central Florida","Standard Grant","Ephraim P. Glinert","08/31/2019","$523,932.00","Janan Smither","abehal@mail.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","CSE","7367","7367, 7923, 9251","$0.00","Thanks to advances in autonomy, an increasing variety of robotic devices have emerged over the last few years to assist disabled users with mobility and object manipulation.  However, users often report higher satisfaction from controlling and interacting with a robot, even when an autonomous robot shows better quantitative performance, because they tend to see the robot not merely as an agent for retrieving objects but as a quintessential tool for reasserting their domain of interaction with their environment and engaging their available faculties to the fullest.  Sadly, for these users effective interaction with a robotic device is frequently hindered by the fact that haptic feedback in the normal sense may not be possible, whether due to sensory and/or cognitive disabilities or to limitations imposed by motor disabilities that may prevent proper transfer of user intent in the absence of an appropriate user interface.  Motivated by these considerations, and in the hope of boosting the current low rates of assistive technology adoption by its intended users, the PI will in this project create a software framework that is independent of the robotic system and allows for adaptively compensating the level and type of human-robot interaction to increase user satisfaction based on real-time measurements of user performance.  Project outcomes will foster a new paradigm for the design of assistive technology, which will enable system developers to understand the impact of user preferences and incorporate them in their designs from the start, as opposed to the current inefficient practice of user testing a design after creating an expensive product or prototype.  <br/><br/>This research will push the envelope of human-robot interaction through the creation of models for understanding the underlying intent of users with disabilities, which may adversely affect their environmental perception and response.  By utilizing these empirical models to design an adaptive human-robot interface that can compensate for deficits and variability in user performance, the work will generate a novel framework for effective sharing of control between individuals with disabilities and their robotic assistants.  Furthermore, the control design for physical human-robot interaction that will be developed as part of this work will advance the field of autonomous robotics in general through the creation of new algorithms for physically interacting with users and their environments.  The research tasks include systematic modeling of user performance during human-robot interaction, estimation of user performance parameters within a generalized estimation framework, and design of adaptive Lyapunov-based control strategies to facilitate safe and efficient physical interaction of the robotic end-effector with the user and environmental objects.  The work will be informed by quantitative/qualitative data to be gathered from extensive user studies in the field, by the PI's previous experience in working with this class of users, and by his expertise in assistive robotics."
"1723869","S&AS: FND: Reflective Learning of Stochastic Physical Models for Robust Manipulation","IIS","S&AS - Smart & Autonomous Syst, National Robotics Initiative","09/01/2017","08/17/2017","Abdeslam Boularias","NJ","Rutgers University New Brunswick","Standard Grant","Reid Simmons","08/31/2020","$682,646.00","Mubbasir Kapadia, Kostas Bekris","abdeslam.boularias@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","039Y, 8013","046Z","$0.00","In order for robots to function in everyday life environments, from flexible manufacturing and warehouse domains to households, they need to autonomously grasp and manipulate a wide variety of potentially unknown objects. Currently, autonomous robots are practically unable to work outside highly-controlled environments wherein an accurate model of every object is provided. This limitation is partially due to the lack of robust algorithms for grasping and manipulating objects with unknown geometric or mechanical properties. The proposed project will perform fundamental research into robust robotic manipulation in a way that will enable autonomous robots to interact efficiently with a large variety of everyday physical objects for extended periods of time. The objective is for autonomous robotic manipulators to effectively learn from experience how objects may physically interact with each other and with the robotic arm. The next step is to utilize this experience so as to perform robust manipulation tasks. There are many exemplary robotic tasks that can be benefited from the proposed improvements and which will form the basis of the project's experimentation process. They include the pushing of objects to desired poses, reconfiguration of objects to simplify their picking and the handling of tools. <br/><br/>The project develops three key components: (1) An algorithm for learning inertial, elastic, and friction properties of an unknown object by observing how the object moves when manipulated by a robot. The project will research novel Bayesian optimization techniques for black-box system identification in order to learn probabilistic models of objects. (2) A physically realistic simulator that can provide a stochastic model of an object's motion given the physical parameters learned by the first component. This will be achieved by utilizing online non-parametric learning methods for speeding up physically realistic simulations under uncertainty. (3), A robust planning algorithm that utilizes the simulator for finding  optimal actions to apply on the object given the learned stochastic model. The objective is to converge to increasingly robust solutions as computation time increases and the robot acquires increased experience with objects in an environment. To strengthen the project's broader impact, the PIs will provide implementations of their solutions to the research community as open-source software packages. This will be coupled with the generation of educational material, which will aim to attract undergraduate students early in their studies to STEM. The PIs will also aim to organize academic meetings that will bring together researchers from foundational domains, robotics experts and industry representatives."
"1723972","S&AS: FND: COLLAB: Probabilistic Underactuated Motion Adaptation","IIS","S&AS - Smart & Autonomous Syst","10/01/2017","07/22/2017","Thomas Howard","NY","University of Rochester","Standard Grant","James Donlon","09/30/2020","$274,739.00","","thomas.howard@rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","CSE","039Y","046Z","$0.00","Unconventional, underactuated robots, such as humanoids or legged platforms more broadly, offer the potential to move through and perform work in constrained, three-dimensional environments that are currently inaccessible to existing autonomous agents.  However, this potential has been largely unrealized because it is difficult to reliably adapt the behaviors of these platforms to account for the changing and uncertain task and environmental conditions in the ""real world.""  Although many of the fundamental principles that govern contemporary task and motion planning techniques are applicable across different platforms, the practical implementation of these principles has been largely platform specific.  In contrast, this project will adopt a probabilistic planning framework which learns common structure for the motion patterns of different platforms performing related tasks, then uses this structure to generate generalized, inherently platform independent, motion primitives.  At runtime, the primitives will be grounded and adapted where necessary to specific robot models given local task and environmental conditions.  The primary benefit of this project will be an increase in the utility of autonomous platforms for tasks such as urban search and rescue, industrial inspection, and planetary exploration.  The analytical techniques that will be developed will have further impacts on locomotion science and learning-based approaches to motion coordination.  The PIs will additionally be involved with K-12 outreach involving robot demonstrations at FIRST Robotics Competitions and the Rochester Museum and Science Center.<br/><br/>This project will specifically address fundamental limitations in the tractability of real-time task and motion planning for underactuated robots over diverse objectives and distributions of environmental conditions.  Probabilistic models will be developed to efficiently reason over and adapt the nominal behaviors of different highly-articulated, underactuated robots.  The behavioral inference will make it possible to 1) select appropriate pre-existing behaviors (developed over the course of the project) where relevant, 2) use novel combinations of nominal behaviors to form compound, task-specific behaviors, and 3) leverage similar, but not necessarily the same, kinematic structure across heterogeneous platforms to transfer behaviors between them.  To ensure the success of the practical, online implementation of the developed models, the PIs will develop algorithms that combine probabilistic inference, nonlinear dimensionality reduction, and dynamic movement primitives to produce a novel combination of efficient motion generation and robust online adaptation.  In addition to varying task and environmental conditions, the adaptability of the probabilistic models to changes in the internal kinematics and dynamics of robot platforms, such as those that would arise from degraded motor performance or structural failures of joints or entire limbs, will also be explored.  The models will be trained and validated using a combination of simulation and experimental results on two physical platforms: the Carnegie Mellon Hexapod and the Robotis OP2.   Furthermore, the PIs will develop software tools and release open-source products related to generalizable probabilistic models for motion adaptation of underactuated systems."
"1659838","REU Site: Robotics and Autonomous Systems","IIS","RSCH EXPER FOR UNDERGRAD SITES, ROBUST INTELLIGENCE","04/01/2017","03/14/2017","Nora Ayanian","CA","University of Southern California","Standard Grant","Wendy Nilsen","03/31/2020","$333,627.00","Gaurav Sukhatme","ayanian@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","1139, 7495","9250","$0.00","This Research Experiences for Undergraduates (REU) site will train students in research methodology by engaging them in authentic research projects and using a focused approach to promote a sense of belonging in the research community. The participating faculty mentors span the spectrum of cutting-edge research topics in robotics and are well established in their fields. Students will participate in research projects that cross-cut multiple areas of robotics and autonomous systems, including socially assistive robotics, robot learning, networked robotics, and robotics data processing. They will gain research experience in solving some of the most challenging modern robotics and autonomy problems and get exposure to robotics research beyond the scope of the REU site, through seminars by other University of Southern California faculty and external site visits, to aid in planning their next career steps.  The intended impact is to have a significant proportion of the REU students go on to graduate school.<br/><br/>The goal of this REU site is to incorporate into the professional research community a cohort of undergraduate student participants from three populations: (1) academically talented students from traditionally underserved colleges and universities, (2) women, and (3) underrepresented minorities.  It will use expertise from the USC Viterbi School of Engineering's Center for Engineering Diversity to explicitly promote diversity in the REU student pool. The dual objective is to train carefully selected students in research methodology, and excite them about robotics research by providing a compelling cohort experience. Students will work with faculty mentors and their Ph.D. students, interact with an existing Viterbi School of Engineering Research Experiences for Teachers (RET) site, and engage in three relevant external research visits. A rigorous assessment of outcomes is planned. To facilitate the sense of a research cohort and encourage networks, housing will be provided in on-campus apartments, as will additional social programs."
"1724000","S&AS: FND: COLLAB: Probabilistic Underactuated Motion Adaptation","IIS","S&AS - Smart & Autonomous Syst","10/01/2017","07/22/2017","Matthew Travers","PA","Carnegie-Mellon University","Standard Grant","James Donlon","09/30/2020","$425,000.00","","mtravers@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","039Y","046Z","$0.00","Unconventional, underactuated robots, such as humanoids or legged platforms more broadly, offer the potential to move through and perform work in constrained, three-dimensional environments that are currently inaccessible to existing autonomous agents.  However, this potential has been largely unrealized because it is difficult to reliably adapt the behaviors of these platforms to account for the changing and uncertain task and environmental conditions in the ""real world.""  Although many of the fundamental principles that govern contemporary task and motion planning techniques are applicable across different platforms, the practical implementation of these principles has been largely platform specific.  In contrast, this project will adopt a probabilistic planning framework which learns common structure for the motion patterns of different platforms performing related tasks, then uses this structure to generate generalized, inherently platform independent, motion primitives.  At runtime, the primitives will be grounded and adapted where necessary to specific robot models given local task and environmental conditions.  The primary benefit of this project will be an increase in the utility of autonomous platforms for tasks such as urban search and rescue, industrial inspection, and planetary exploration.  The analytical techniques that will be developed will have further impacts on locomotion science and learning-based approaches to motion coordination.  The PIs will additionally be involved with K-12 outreach involving robot demonstrations at FIRST Robotics Competitions and the Rochester Museum and Science Center.<br/><br/>This project will specifically address fundamental limitations in the tractability of real-time task and motion planning for underactuated robots over diverse objectives and distributions of environmental conditions.  Probabilistic models will be developed to efficiently reason over and adapt the nominal behaviors of different highly-articulated, underactuated robots.  The behavioral inference will make it possible to 1) select appropriate pre-existing behaviors (developed over the course of the project) where relevant, 2) use novel combinations of nominal behaviors to form compound, task-specific behaviors, and 3) leverage similar, but not necessarily the same, kinematic structure across heterogeneous platforms to transfer behaviors between them.  To ensure the success of the practical, online implementation of the developed models, the PIs will develop algorithms that combine probabilistic inference, nonlinear dimensionality reduction, and dynamic movement primitives to produce a novel combination of efficient motion generation and robust online adaptation.  In addition to varying task and environmental conditions, the adaptability of the probabilistic models to changes in the internal kinematics and dynamics of robot platforms, such as those that would arise from degraded motor performance or structural failures of joints or entire limbs, will also be explored.  The models will be trained and validated using a combination of simulation and experimental results on two physical platforms: the Carnegie Mellon Hexapod and the Robotis OP2.   Furthermore, the PIs will develop software tools and release open-source products related to generalizable probabilistic models for motion adaptation of underactuated systems."
"1734559","NRI: FND: COLLAB: An Open-Source Robotic Leg Platform that Lowers the Barrier for Advanced Prosthetics Research","CMMI","National Robotics Initiative","10/01/2017","04/27/2018","Hartmut Geyer","PA","Carnegie-Mellon University","Standard Grant","Irina Dolinskaya","09/30/2020","$222,237.00","","hgeyer@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","8013","030E, 034E, 116E, 8024, 8086, 9178, 9231, 9251","$0.00","The objective of this project is to provide researchers with access to a fully capable and standardized open-source robotic leg research platform, without the immense burden of developing each component from scratch. The outcome will be a robust and inexpensive test bed that can be easily manufactured, assembled, and controlled. One of the greatest challenges to the design and commercialization of robotic prosthetic legs is the control strategy -- that is, the computerized instruction set that specifies the effort level and timing for each component of the mechanism. Challenges in developing control strategies stem from the many different functions that an active robotic limb must accomplish. One important function is to detect the amputee's intention to perform different mobility activities, such as walking on a level surface versus ascending or descending stairs. Another important function is to coordinate the pattern of effort and movement of the prosthetic limb in order to emulate the healthy human body. There are many researchers working independently on better control algorithms to address challenges such as these. To be of value, these algorithms must be tested and validated experimentally. Research groups around the world have created a variety of specialized robotic leg designs for this purpose, representing a significant investment of time and effort. The resources required to obtain a suitable research platform represent a substantial obstacle for new researchers to overcome. Furthermore, the vast difference in designs used by established researchers hinders the comparison of new control strategies across research groups. The accessible, standardized leg platform resulting from this project will lower barriers to entry, allowing new researchers to study the control of robotic legs, to unambiguously compare different control approaches, and to generally advance the field. Finally, the improved prosthetic leg designs arising in the long term from this project will benefit the lives of amputees.<br/> <br/>The overall research goals of this project are 1) to identify an electromechanical design for a low cost, high performance, open-source robotic knee and ankle system; 2) to understand how separate prosthesis control strategies can be combined to benefit amputee gait, and 3) to evaluate and compare resulting controllers in amputee experiments. The approach utilizes a novel design methodology employing selectable series elasticity and high-torque motor technology to achieve high performance at low cost. Interchangeable control modules in the open-source architecture allow researchers to investigate new control methods at low, mid, and high levels of the system, that is, motor drive, joint control, and human intent recognition, respectively. In particular, a reflex-based approach and a phase-based approach will be implemented as mid-level control modules and a high-level intent recognition module will enable the robotic leg to automatically switch between different user activities. In all cases, having the new robot leg available together with these algorithms will enable testing in real-world scenarios, rather than being confined to the laboratory. The results of this project will lower the barrier for conducting research and enable fair comparison across different control approaches with standardized leg hardware. Finally, the proposed work will impact students and the community through training, outreach, and dissemination."
"1537715","Collaborative Research: A Combustion-Powered, Flapping-Wing Micro Air Vehicle","CMMI","Dynamics, Control and System D","11/01/2015","08/23/2015","Robert Wood","MA","Harvard University","Standard Grant","Irina Dolinskaya","10/31/2018","$225,849.00","","rjwood@eecs.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","ENG","7569","030E, 031E, 032E, 033E, 034E, 8024","$0.00","This project will demonstrate an insect-sized flying robot powered by combustion, with a hard exoskeleton and integrated soft actuators. The premise is that structure, propulsion, snd control inspired by the insect musculoskeletal system will produce more efficient and robust microrobots. The analogy becomes even more clear with the realization that, like most animals, insects chemically burn glucose (a hydrocarbon) for muscle actuation. Conservative estimates suggest that the use of combustion to power flying microrobots will allow untethered and autonomous operation for greater than 30 minutes in idealized conditions, enabling vastly more effective application to search and rescue, inspection of infrastructure, and distributed sensor networks. In addition, this project will have broad impacts in education, harnessing children's natural interest in insect biology towards a STEM outcome of understanding robotics.<br/><br/>The combustion of hydrocarbons can have up to fifty times the volumetric energy density of lithium polymer batteries and is a potential power source for untethered robots, even at the scale of insects. This research is to show how combustion-powered actuation of a soft, artificial muscle can generate sufficiently high frequencies and forces to power flapping-wing micro-aerial vehicles. Typical combustion-powered machines require heavy and complex transmission systems to effectively use chemical energy. Instead, this research will develop soft, elastomeric bladders that expand during combustion, and serve as both engine and transmission -- drastically reducing complexity and weight. Flying robots are the target application for this project due to the extreme energetic demands of flight at small scales but the results will be broadly applicable to other power-demanding autonomous systems. Furthermore, the small scale of the envisioned robot will produce innovations in multi-scale multi-material manufacturing. The  work will take place in three tasks: (i) fabrication and testing of a microscale soft engine; (ii) integration of the combustion chamber with a flapping-wing robot platform; (iii) development of additional technologies required for autonomous flight and performing tethered controlled flight experiments."
"1537413","Collaborative Research: A Combustion-Powered, Flapping-Wing Micro Air Vehicle","CMMI","Dynamics, Control and System D","11/01/2015","08/23/2015","Robert Shepherd","NY","Cornell University","Standard Grant","Irina Dolinskaya","10/31/2018","$274,151.00","","rfs247@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","ENG","7569","030E, 031E, 032E, 033E, 034E, 8024","$0.00","This project will demonstrate an insect-sized flying robot powered by combustion, with a hard exoskeleton and integrated soft actuators. The premise is that structure, propulsion, snd control inspired by the insect musculoskeletal system will produce more efficient and robust microrobots. The analogy becomes even more clear with the realization that, like most animals, insects chemically burn glucose (a hydrocarbon) for muscle actuation. Conservative estimates suggest that the use of combustion to power flying microrobots will allow untethered and autonomous operation for greater than 30 minutes in idealized conditions, enabling vastly more effective application to search and rescue, inspection of infrastructure, and distributed sensor networks. In addition, this project will have broad impacts in education, harnessing children's natural interest in insect biology towards a STEM outcome of understanding robotics.<br/><br/>The combustion of hydrocarbons can have up to fifty times the volumetric energy density of lithium polymer batteries and is a potential power source for untethered robots, even at the scale of insects. This research is to show how combustion-powered actuation of a soft, artificial muscle can generate sufficiently high frequencies and forces to power flapping-wing micro-aerial vehicles. Typical combustion-powered machines require heavy and complex transmission systems to effectively use chemical energy. Instead, this research will develop soft, elastomeric bladders that expand during combustion, and serve as both engine and transmission -- drastically reducing complexity and weight. Flying robots are the target application for this project due to the extreme energetic demands of flight at small scales but the results will be broadly applicable to other power-demanding autonomous systems. Furthermore, the small scale of the envisioned robot will produce innovations in multi-scale multi-material manufacturing. The  work will take place in three tasks: (i) fabrication and testing of a microscale soft engine; (ii) integration of the combustion chamber with a flapping-wing robot platform; (iii) development of additional technologies required for autonomous flight and performing tethered controlled flight experiments."
"1762700","Collaborative Research: Single-Input Control of Large Microrobot Swarms using Serial Addressing for Microassembly and Biomedical Applications","CMMI","Dynamics, Control and System D","06/01/2018","05/16/2018","David Arnold","FL","University of Florida","Standard Grant","Irina Dolinskaya","05/31/2021","$295,191.00","","darnold@ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","ENG","7569","030E, 034E, 8024","$0.00","This collaborative research project will create a practical control scheme for large swarms of microrobots. These robots are typically no more than a few millimeters in length, and rely on an external power source and control signal. Currently, it is possible to steer the swarm as a whole to a single destination (or perhaps, to a desired average location). However, realizing the full potential benefits of microrobot swarms will require the ability to simultaneously send independent commands, either to individual robots or to small subgroups.  Device designs have previously been explored that respond to different command amplitudes, however this approach quickly becomes impractical as the number of independently addressable robots grows. This scalability problem can be overcome using serial addressing schemes. Here, there are only a few distinct values for the control signal. Each independently addressable subset of robots is associated with a unique sequence of signal values, and will change its behavior only if the control signal contains that specific sequence. This project considers two fundamental issues that arise in implementing such a scheme. First is the need for on-board computation and memory allowing the robots to recognize the unique sequence and to change the robots state based on the detection of such sequence. Second is the need for a propulsive mechanism that couples to the robot state to allow differential guidance towards a target configuration. This project will advance two innovative engineering platforms that meet both needs. The first is electrostatically actuated, operates on a planar substrate, and is suitable for structured tasks such as microassembly. The second is magnetically actuated, operates in a liquid volume, and is suitable for biomedical applications such as drug delivery. The technical aspects of the project are complimented by outreach activities, including an annual microrobotics mobility competition to be held at the IEEE International Conference on Robotics and Automation -- a premier robotics conference for academia and industry. The results from this project will enhance the national health, by enabling new diagnostic and therapeutic uses for microrobot swarms. They will also promote the national prosperity, by enabling new classes of microassembly robots.<br/><br/>This project aims to develop a practical control scheme to simultaneously control large numbers of microrobots. This will be achieved by using microelectromechanical systems (MEMS) to electromechanically and magnetically decode a sequence embedded in the single global control signal, and couple the reconfiguration of such sequence to the modification of the individual microrobot trajectories. This on-board sequence decoding will be accomplished through sets of on-board physics-based finite state machines (PFSM) that can accept a control sequence embedded in the control signal and change the behavior of the microrobots accordingly. The project will use both electrostatic and magnetic approaches to implement PFSMs, and to couple their ""accept"" state to the propulsion mechanism to modulate individual trajectories. Sets of stress-engineered electrostatic switches, which will latch in response to a pre-programmed control voltage sequence, will be used to implement PFSM on the electrostatic platform. Electro-permanent magnetic circuits, which change their magnetic moment in response to a sequence of global magnetic field, will be used to implement PFSM on the magnetic platform. The project will develop the theory for PFSM-based multi-microrobot control, construct both electrostatic and magnetic microrobotic PFSM platforms, and validate the concept by implementing the PFSM-based control on swarms of electrostatically and magnetically powered microrobots. The developed theory and approach will pave way for control of large microrobot swarms for numerous biomedical and microassembly applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1526835","NRI: Collaborative Research: Dynamic Robot Guides for Emergency Evacuations","CMMI","National Robotics Initiative","09/01/2015","08/03/2015","Haibo He","RI","University of Rhode Island","Standard Grant","Irina Dolinskaya","08/31/2019","$282,112.00","","he@ele.uri.edu","RESEARCH OFFICE","KINGSTON","RI","028811967","4018742635","ENG","8013","030E, 6840, 8024, 8086, 9150","$0.00","Crowd stampede is one of the most harmful collective human behaviors. In incidents throughout history, panic due, for example, to the outbreak of fire or the unexpected discharge of firearms has been a greater hazard than the original triggering events. This project supports fundamental research on the influence of human-robot interaction on crowd dynamics, towards the design of dynamic robot control algorithms to assist humans and prevent panic in emergency situations. The ultimate goal of this research will be reconfigurable robot guides that can respond to a variety of needs. These include different types of emergency evacuation, as well as non-emergency situations involving mass movement of crowds, such as at parades, concerts, or other large public events. The project integrates research with educational activities through robot-centric education and short course development. To engage the younger generation with science and technology, the project will partner with a university educational center and a community college for various outreach activities.<br/><br/>The objective of the project is to investigate human-robot interaction in crowd dynamics, develop optimal feedback control to regulate human flow distribution, and design robot-assisted emergency evacuation algorithms. The research will advance the state-of-the-art in human-robot interaction, and fill a gap in robotics research by experimentally validating and measuring the interaction forces governing human-robot interaction in crowd dynamics. The proposed robot motion primitive design leads to new approaches for learning-based robot motion planning to efficiently engage humans. The project validates the use of dynamic robot guides in real human-robot interaction experiments in indoor environments. Simulation validation in benchmark environments such as shopping-malls and campus buildings will also be performed, and the efficiency of alternative robot-assisted evacuation strategies will be evaluated. While primarily for intelligent robots, the research results are anticipated to be cross-cutting and applicable to other areas such as transportation, communication, and control."
"1427096","NRI: Using Multi-Robot Enabled Dexterous Locomotion to Search for Victims in Disaster Areas","CMMI","National Robotics Initiative","11/01/2014","07/18/2014","Ronald Fearing","CA","University of California-Berkeley","Standard Grant","Irina Dolinskaya","10/31/2018","$1,200,000.00","Avideh Zakhor","ronf@eecs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","ENG","8013","8086","$0.00","After a disaster, such as an earthquake or hurricane, victims are often trapped in voids that are survivable but too difficult or dangerous for rescuers to reach.  Small robots that can crawl through narrow crevices could provide rescuers with valuable information about where to focus their efforts.  Although individual small-scale robots have previously lacked the intelligence and mobility of larger robots, recent breakthroughs in robot locomotion, and compact computers (from cell-phone technology) will enable the development of distributed robotic teams of dozens of very low-cost, small-scale mobile robots coordinating with each other to overcome obstacles while rapidly making a map of an irregular environment.  This National Robotics Initiative (NRI) award supports fundamental research in understanding how to design systems of multiple robots which can cooperate with each other to identify and then move over obstacles, while providing information to, and receiving overall guidance from, human operators.  Success in this research project will bring society closer to having teams of mobile, disposable, search and rescue robots which can robustly locomote through uncertain environments and find survivors in disaster situations while removing risks posed to human and animal rescuers.  In addition to graduate students, undergraduate students will gain firsthand experience in the design and control of millirobotic platforms, and robot designs will be made publically available for construction and simulation. To increase youth interest in science, technology, engineering and math, middle school students will be engaged in robot design and build activities.<br/><br/>This research project aims to understand how to combine enhanced mobility through dynamic robot cooperation with distributed low-cost mapping of irregular environments.  To reduce cost and complexity, millirobots are typically minimally actuated and have limited mobility in complex terrain.  Through dynamic robot cooperation, multiple robots can jointly traverse terrain features which can block single robots.  Algorithms will be developed to flexibly surmount obstacles by combining forces from multiple robots and using robot body surfaces as temporary bridging or stepping elements, which should enable teams of millirobots to cooperatively locomote and explore areas efficiently, for example by finding, or if necessary, creating low-energy ingress paths.  The research team will develop new techniques for joint 3D mapping using multiple small and medium robots size equipped with lightweight sensors. A research challenge is using compact (sub-5 gram) steerable lasers and image sensors to identify reference points, and then using low-bandwidth communication of the most salient features to higher level computation nodes to create a 3D global map.  Exterior surface maps will be fused with interior maps to guide search planning towards the regions with highest probability of unexplored volumes.  Human searchers can carry lightweight mapping gear (on the order of 100 grams) while working on exterior surfaces, and provide information regarding the search regions.  The robot ensemble will be tested at a local urban search and rescue training facility."
"1208186","NRI-Small: Collaborative Research: Assistive Robotics for Grasping and Manipulation using Novel Brain Computer Interfaces","IIS","National Robotics Initiative","10/01/2012","09/06/2012","Sanjay Joshi","CA","University of California-Davis","Standard Grant","Irina Dolinskaya","09/30/2018","$430,000.00","","maejoshi@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","CSE","8013","7923, 8086","$0.00","This is a collaborative proposal (with UC Davis) which is aimed at making concrete some of the major goals of Assistive Robotics. A team of experts has been brought together from the fields of signal processing and control, robotic grasping, and rehabilitative medicine to create a field-deployable assistive robotic system that will allow severely disabled patients to control a robot arm/hand system to perform complex grasping and manipulation tasks using novel Brain Muscle Computer Interfaces (BMCI). Further, the intent of this effort is not just technology-driven, but is also driven by clear and necessary clinical needs, and will be evaluated on how well it meets these clinical requirements.  Validation will be performed at the Department of Regenerative and Rehabilitation Medicine at Columbia University on a diverse set of disabled users who will provide important feedback on the technology being developed, and this feedback will be used to iterate on the system design and implementation.<br/><br/>Intellectual Merit: The intellectual merit of this proposal includes:<br/>o Novel research in Human Machine Interfaces that has the potential to be transformative in eliciting rich, multi-degree-of-freedom signal content from simple and non-invasive surface electromyographic (sEMG) sensors.<br/>o Development of smart adaptive software that employs machine learning algorithms that can continually monitor user performance, and then automatically calibrate and tune system parameters based on system performance.<br/>o Data driven methods for real-time grasp planning algorithms that can be used with both known and unknown objects.<br/>o Methods for finding pose-robust grasps that are tolerant of errors in sensing.<br/>o Evaluation of an underactuated hand as a grasping device for certain application tasks.<br/>o Integration of 3D vision with real-time grasp planning.<br/>o Scientific evaluation at the clinical level of the impact of these new technologies on the disabled population.<br/><br/>Broader Impacts: The broader impacts of this proposal include:<br/>o Development of a complete system to aid the severely disabled population with tetraplegia.<br/>o Extensions of this technlogy to others lacking motor control function including multiple sclerosis, stroke, amyotrophic lateral sclerosis (ALS or Lou Gehrig disease), cerebral palsy, and muscular dystrophy.<br/>o New technology that can extend the reach and impact of the field of Assistive Robotics.<br/>o Major extensions to the open-source GraspIt! software system that will allow many other researchers to leverage the results of this project.<br/>o Educational thrusts that will bring together engineering students, clinicians and the disabled population to extend the reach and scope of Assistive Robotics.<br/>o New directions in Human Machine Interfaces that can extend beyond the disabled population and into a variety of other applications."
"1834932","Inclusion @ Robotics: Science and Systems (RSS) 2018","IIS","ENG DIVERSITY ACTIVITIES, National Robotics Initiative","06/01/2018","05/17/2018","Hadas Kress Gazit","NY","Cornell University","Standard Grant","Reid Simmons","05/31/2019","$24,900.00","","hadaskg@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7680, 8013","7556, 8086","$0.00","This project supports travel for 27 students in robotics from traditionally underrepresented groups, including minorities and people with disabilities. The researchers will participate in the Robotics: Science and Systems (RSS) conference, along with its associated workshops, which runs June 26-30, 2018 in Pittsburgh, PA. The students will be mentored both through being paired with senior PhD students and postdocs and participation in a mentorship breakfast led by the RSS conference chair.  By exposing early career researchers from underrepresented groups to this type of intellectual environment, they will be better able to be situated in the robotics field and get better ideas for the type and quality of research needed to have impact in the field.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1460674","Research Experience for Undergraduates (REU) Site for Computational Sensing and Medical Robotics (CS&MR)","EEC","HUMAN RESOURCES DEVELOPMENT","04/01/2015","03/09/2017","Ralph Etienne-Cummings","MD","Johns Hopkins University","Standard Grant","Mary Poats","03/31/2019","$431,151.00","Suchi Saria","retienne@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","ENG","1360","115E, 116E, 7218, 9177, 9178, 9250","$0.00","BROADER SIGNIFICANCE OF THE PROJECT:<br/><br/>This project will provide undergraduates STEM research experience at the interface of engineering and medicine, aiming to help medical diagnosis and procedures, development of prosthetics, and contribute to technologies that are likely to become a part of the ""future of medicine."" This program addresses a vital national need to improve the delivery of healthcare by developing new tests and medical devices that enhance the ability of doctors to plan and perform procedures. By recruiting from and partnering with minority student societies and programs, minority-serving institutions and community colleges, the investigators will help develop a pipeline of qualified, diverse individuals who will contribute to the STEM workforce, particularly in the multi- and interdisciplinary subjects encountered in biomedical research, healthcare delivery, and basic biological and life sciences. The participants will be well trained in communications and research ethics, which are essential for success in today's biotechnology and bioscience work and market place.<br/><br/>PROJECT DESCRIPTION: <br/><br/>During a ten-week summer session, undergraduate participants from institutions nationwide will engage in exciting and challenging research projects in a wide range of engineering disciplines, e.g. electrical, mechanical and biomedical, computer science, and physics. Each participant will be matched with a current research project in the Laboratory for Computational Sensing and Robotics (LCSR) and will be a part of a collegial research team, including a faculty project supervisor and a graduate student mentor. These research projects relate to medical image registration and fusion, image enhancement and segmentation or the development of new robotic devices to support surgeons in the operating room or to aid patients with disabilities. Participants will receive instruction on technical communication, oral presentation skills, and research ethics and will deliver a final research report and presentation. Additional activities will include tours and trips to other labs at JHU Hospital (JHU/H) and the Applied Physics Laboratory, the opportunity to perform laparoscopic procedures at the JHU/H Minimally Invasive Surgical Training Center, and industry tours of local robotics, biotechnology and engineering companies.<br/><br/>The program is multidisciplinary and offers each participant the ability to conduct research in a variety of fields and develop strong teamwork collaboration skills. Each faculty mentor provides a project description for projects that may be created specifically for the program or designed to carry out a facet of an on-going research. Because the Laboratory for Computational Sensing and Robotics has close ties with the Johns Hopkins Medical Institutions, participants can experience the cutting-edge research that is designed to aid medical diagnosis, interventions, and prosthesis, and contribute to technologies that are likely to become a part of the ""future of medicine."" The investigators plan to leverage on-going research activities and training and mentoring experience, and aim this REU in CS&MR program at broader topics that include more biological inspired and biologically targeted computational sensing, imaging, and robotics systems. An external assessment expert will conduct annual formative and summative evaluations."
"1531195","MRI: Development of the Robotarium: A Shared, Remote Access, Multi-Robot Laboratory","ECCS","MAJOR RESEARCH INSTRUMENTATION","09/01/2015","09/02/2015","Magnus Egerstedt","GA","Georgia Tech Research Corporation","Standard Grant","Anil Pahwa","08/31/2019","$1,050,000.00","Raheem Beyah, Eric Feron, Blair MacIntyre, Steven McLaughlin","magnus@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","1189","1189, 6840","$0.00","In the near future, robot-assisted technologies have the potential to improve individuals' qualify of life in almost every aspect of society. However, in order to realize this future, access to instruments that enable discovery in the area of robotics must be ensured. In this regard, this project develops the Robotarium, a world-class, shared multi-robot research and education facility, remotely and locally accessible to users across different educational institutions and age groups. Through an online, open, public interface, users will be able to schedule and run their experiments, while being provided with both streaming video of the experiment as well as the scientific data produced through the experiment. The expected outcome is a first-of-its-kind multi-robot research platform that can be utilized by researchers, educators, and students, without incurring the prohibitive costs associated with setting up and maintaining a suitably-equipped research facility. Even more importantly, however, the expected outcome goes beyond access. A research instrument like the Robotarium has the potential to build stronger networks of collaborative research, thus making the whole significantly larger than the sum of its parts. As such, the end result has the potential to show how remote access research instruments can be structured in other areas beyond robotics.<br/><br/>The Robotarium is an open, remote access multi-robot testbed that allows researchers and educators to run robotics experiments without having to incur the prohibitive costs associated with setting up and maintaining an actual research facility. In order to achieve this agenda, research instrumentation efforts in this project are pursued along three different dimensions that will come together to produce a first-of-its-kind open, remote access multi-robot research facility. These three dimensions are: (1) A remote access multi-robot laboratory where researchers, educators, and students can test and run their own coordinated control strategies; (2) Low-cost, high-performance mobile robots designed explicitly to support remote-access multi-robot research; and (3) Instrument development that has operational and cybersecurity primitives built-in, which is critical since remote users can literally take control of physical assets. The Robotarium will not only provide local and remote access to a multi-robotics facility, but it will also facilitate research in a number of areas that will directly benefit from the Robotarium research instrument, such as (i) swarm robotics, (ii) visualization and augmented reality, (iii) cybersecurity, (iv) cyber-physical systems, and (v) formal model-checking of real-time software."
"1704436","RI: Medium: Collaborative Research: A Structure-Math-Function Approach for Designing Robustly Intelligent Synthetic Nervous Systems","IIS","ROBUST INTELLIGENCE, IntgStrat Undst Neurl&Cogn Sys","10/01/2017","05/15/2018","Roger Quinn","OH","Case Western Reserve University","Standard Grant","Kenneth C. Whang","09/30/2021","$753,043.00","","rdq@po.cwru.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","CSE","7495, 8624","7495, 7924, 8089, 8091, 9251","$0.00","Robots are becoming integrated into more areas of life, no longer confined to the predictable environment of a factory, performing the same task. Robots that work among humans require greater intelligence and the ability to adapt to changing tasks in an unpredictable environment. This work develops a sophisticated control system for robotics by modeling the control systems in the brain of a remarkably intelligent, capable, and adaptable insect: the praying mantis. This work promises to transform our understanding of intelligence in both robotics and neuroscience. A model of decision-making in the relatively simple brains of insects advances the study of more complex brains. The model will then be used to allow a legged robot to adapt its movement to suit its goals such as assisting humans, or its ""needs"" such as seeking energy or avoiding danger. These advances seek to give robots the autonomy that animals have. Instead of being programmed for every possible situation, a robot could be trained, continue to learn from experience, and improve efficiency even in novel situations. At an after-school robotics program at an inner-city school, students will benefit from hands-on experience creating robots with the unique perspective of bio-inspired design and modeling of nervous systems.  <br/><br/>This work expands the scale and sophistication of a synthetic nervous system (SNS), a continuous time dynamical model of praying mantis nervous system, and applies it to robotic control. Multi-channel neural recording and stimulation techniques are revealing how insects simplify motor control by distributing computation throughout the nervous system. This project leverages these techniques to understand how the capability of the ""higher"" level (the brain, where sensory input is processed) is directly supported by intelligence in the ""lower"" level (ganglia that coordinate the legs). These data will be used to develop and implement an SNS to control the six-legged MantisBot, endowing it with online learning and intelligent autonomy. Neurobiology will inform this work in all three specific aims: 1) Investigate the lower-level intelligence of the mantis nervous system and use the results to increase the intelligence of MantisBot's low-level control networks; 2) Investigate the correlation between descending commands and behavior and use the results to develop a simplified brain (i.e. high-level controller) for MantisBot; and 3) Investigate the effect of conflicting visual inputs (e.g. simultaneous prey and predator) on descending commands, and use these findings to endow MantisBot with robust intelligence distributed throughout its SNS."
"1724982","PFI:BIC: Smart Factories -An Intelligent Material Delivery System to Improve Human-Robot Workflow and Productivity in Assembly Manufacturing","IIP","PARTNRSHIPS FOR INNOVATION-PFI, IIS SPECIAL PROJECTS","01/15/2017","02/28/2017","Laurel Riek","CA","University of California-San Diego","Standard Grant","Jesus Soriano Molla","08/31/2019","$1,000,000.00","","lriek@eng.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","ENG","1662, 7484","1662","$0.00","Manufacturing represents a quarter of all employment in the US. To reshore jobs, improve operations, and recruit, retain, and retrain skilled workers, companies are increasingly using robotics technology. Ideally, robots will not replace humans but team with them to improve productivity. However, most industrial robots are poorly integrated into human workflow, causing expensive work stoppage problems ($1.7M per hour), worker stress, and talent loss.  The research goal of this project is to address this problem by designing novel methods to improve human-robot workflow and productivity in assembly manufacturing through the use of an intelligent material delivery system (IMDS), which will closely integrate with and support the manual work process. This project will investigate innovative, multi-disciplinary approaches to this research area, dramatically advancing the state-of-the art in smart manufacturing and human-centered robotics. <br/><br/>The research team will make the following contributions to human-centered smart service systems: 1) Revolutionize the use of robotics in assembly manufacturing processes to closely support skilled human workers, enabling them to focus on tasks they value (their trade) as opposed to tasks that distract from their talent (material movement). 2) Dramatically improve the productivity and flexibility of factories through nimble, real-time scheduling of an IMDS system that dynamically incorporates real-time models of human workflow. 3) Deeply explore the socio-technical implications of having an IMDS system in the workplace, in terms of human workers' cognition, fatigue, affect, and job satisfaction. The project's approach serves as a direct contrast to industry state-of-the-art, which relies on strict bifurcation of human and robot work, and rigid delivery schedules that fail to take local trim-line variations into account. By closely integrating an IMDS into the manual work process and understanding worker and material status, the project will readily enable flexibility and reconfigurability of a human workforce, an absolute necessity in made-to-order, small-batch manufacturing settings. <br/><br/>This project will help the US manufacturing sector dramatically improve their operations by using automation to directly support a talented, skilled workforce. It has the potential to impact all major US manufacturing sectors, including automotive, construction, healthcare, energy, and goods. It will help US companies reshore operations, as well as create new opportunities for US worker STEM skill acquisition. Furthermore, this project involves a detailed investigation of multiple human worker implications of the transition from traditional to intelligent material delivery using robotics. By understanding reactions to such change, there will be new understanding on how to optimize a system not only for workflow and task efficiency but also for the human experience. Such knowledge is critical to maintaining job satisfaction, safety and health, and long-term well-being of the human workforce.<br/><br/>The lead institution is the University of Notre Dame, Department of Computer Science and Engineering, in collaboration with the Massachusetts Institute of Technology, Department of Aerospace and Aeronautics (Cambridge, MA) and University of Colorado at Boulder, Department of Civil, Environmental, and Architectural Engineering (Boulder, CA). The primary industrial partner is Steelcase, Inc. (Grand Rapids, MI), a large manufacturer that specializes in customizable, made-to-order furniture.<br/><br/>This proposal is co-funded by The Directorate for Computer and Information Science and Engineering (CISE), Divisions of Information and Intelligent Systems (IIS) and Computer and Network Systems (CNS)"
"1351028","CAREER: Apprenticeship Learning for Robotic Manipulation of Deformable Objects","IIS","ROBUST INTELLIGENCE","03/15/2014","03/10/2014","Pieter Abbeel","CA","University of California-Berkeley","Standard Grant","Reid Simmons","02/28/2019","$500,000.00","","pabbeel@cs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495","1045, 7495","$0.00","This project considers the problem of apprenticeship learning, in which a robot first gets access to demonstrations of a task and ought to learn from these demonstrations how to perform that task in new, yet similar, situations.  This line of work has already shown significant promise, including in helicopter control where it enabled autonomous helicopter aerobatics at the level of the best human pilots.  However, fundamental limitations remain, and robotic capabilities to manipulate deformable objects are currently still well below human level. The approach followed builds on, and extends, non-rigid registration algorithms, which can capture how scenes with deformable objects relate to each other.  Such registration is extrapolated to morph a demonstrated manipulation trajectory into a good trajectory for a new scene.  New machine learning algorithms are developed to enable choosing the optimal training demonstration and the optimal morphing objective while accounting for external constraints, such as avoiding collisions and satisfying joint limits. Infrastructure is being built for large-scale data collection of demonstrations and theoretical and empirical characterizations are developed for how much data is needed for a given task.  Concrete challenge tasks considered are knot tying, cloth and fabric manipulation, surgical suturing, and small surgical procedures. Results will be incorporated into the PI's graduate robotics course and the source code will be shared with the robotics community."
"1446285","CPS: TTP Option: Synergy: Collaborative Research: Dependable Multi-Robot Cooperative Tasking in Uncertain and Dynamic Environments","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","01/01/2015","08/27/2014","Kimon Valavanis","CO","University of Denver","Standard Grant","Bruce M. Kramer","12/31/2018","$499,994.00","Nikolaos Vitzilaios, Matthew Rutherford","kvalavan@du.edu","2199 S. University Blvd.","Denver","CO","802104711","3038712000","CSE","7918","1653, 6840, 7496, 8235, 8888","$0.00","Driven by both civilian and military applications, such as coordinated surveillance, search and rescue, underwater or space exploration, manipulation in hazardous environments, and rapid emergency response, cooperative actions by teams of robots has emerged as an important research area. However, the coordination strategies for such robot teams are still developed to a great extent by trial-and-error processes.  Hence, the strategies cannot guarantee mission success. This award supports fundamental research to provide a provably correct formal design theory of multi-robot systems that guarantees mission success.  Furthermore, results from the research can be extended to the design of more general cyber-physical systems (CPSs) consisting of distributed and coordinated subsystems, such as the national power grid, ground/air traffic networks, and manufacturing systems. These CPSs are critical components of the national civil infrastructure that must operate reliably  to ensure public safety. The multidisciplinary approach taken will help broaden participation of underrepresented groups in research and positively impact engineering education.<br/> <br/>Focusing on multi-robot teams, the goal of the research is to build foundations for a provably correct formal design theory for CPSs. This design theory will guarantee a given global performance of multi-robot teams through designing local coordination rules and control laws. The basic idea is to decompose the team mission into individual subtasks such that the design can be reduced to a local synthesis problem for individual robots. Multidisciplinary approaches combining hybrid systems, supervisory control, regular inference and model checking will be utilized to achieve this goal. The developed theory will enable robots in the team to cooperatively learn their individual roles in a mission, and then automatically synthesize local supervisors to fulfill their subtasks. A salient feature of this method lies on its ability to handle environmental uncertainties and unmodeled dynamics, as there is no need for an explicit model of the transition dynamics of each agent/robot and their interactions with the environment. In addition, the design is online and reactive, enabling the robot team to adapt to changing environments and dynamic tasking. The derived theory will be implemented as software tools and will be demonstrated through real robotic systems consisting of unmanned ground and aerial vehicles in unstructured urban/rural areas."
"1544857","CPS: Synergy: Learning to Walk - Optimal Gait Synthesis and Online Learning for Terrain-Aware Legged Locomotion","CNS","SPECIAL PROJECTS - CISE, IIS SPECIAL PROJECTS, CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2015","09/14/2017","Patricio Vela","GA","Georgia Tech Research Corporation","Continuing grant","David Corman","09/30/2019","$799,982.00","Aaron Ames, Erik Verriest, Daniel Goldman","pvela@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","1714, 7484, 7918","7918, 8235","$0.00","Legged robots have captured the imagination of society at large, through<br/>entertainment and through the dissemination of research findings.  Yet,<br/>today's reality of what (bipedal) legged robots can do falls short of<br/>society's vision.  A big part of the reason is that legged robots are<br/>viewed as surrogates for humans, able to go wherever humans can as aids<br/>or as assistants where it might also be too dangerous or risky.  It is<br/>in the expectation of robustness and walking facility that today's<br/>research hits its limits, especially when the terrain has granular<br/>properties.  Impeding progress is the lack of a holistic approach to the<br/>cyber-physical modeling and control of legged robots.  The vision of<br/>this work is to unite experts in granular mechanics, optimal control,<br/>and learning theory in order to define a methodology for advancing<br/>cyber-physical systems (CPS) involving a tight coupling of the physical with<br/>the cyber through dynamic interactions that must be learned online.  The<br/>proposed work will advance the science of cyber-physical systems by more<br/>explicitly tying sensing, perception, and computing to the optimization<br/>and control of physical systems whose properties are variable and<br/>uncertain.  Achieving reliable, adaptive legged locomotion over terrain<br/>with arbitrary granular properties would transform several application<br/>domain areas of robotics; e.g., disaster response, agricultural and<br/>industrial robotics, and planetary robotics.  More broadly, the same<br/>tools would apply to related CPS with regards to terrain aware<br/>exoskeleton and rehabilitation prosthetics for persons with missing,<br/>non-functional, or injured legs, as well as to energy networks with<br/>time-varying, nonlinear dynamics models.<br/><br/><br/>The CPS platform to be studied is that of a bipedal robot locomoting<br/>over granular ground material with uncertain physical properties (sand,<br/>gravel, dirt, etc.).  The proposed work seeks to overcome current<br/>impediments to reliable legged locomotion over uncertain terrain type,<br/>which fundamentally relies on the controlled interaction of the robot's<br/>feet with the physical environment.  The research goal is to improve the<br/>perception and control of legged locomotion over granular media for the<br/>express purpose of achieving robust, adaptive, terrain-aware locomotion.<br/>It revolves around the hypothesis that simple models with decent<br/>predictive performance and low computational overhead are sufficient for<br/>the optimal control formulations as the compute-constrained adaptive<br/>subsystem will both learn and classify the peculiarities of the terrain<br/>online.  The main research objectives will involve: [1] a validated<br/>co-simulation platform for legged robot movement over granular media;<br/>[2] terrain-dependent, stable gait generation and gait transition<br/>strategies via optimal control; [3] online, compute-constrained learning<br/>of granular interactions for adaptation and terrain classification; and<br/>[4] validated contributions using experimental testbeds involving<br/>variable and unknown (to the robot) granular media.  Given the high<br/>value of the robotic platforms and the research with regards to outreach<br/>and participation, they will be used as outreach tools and to create new<br/>educational modules for promotion of STEM fields.  Further, the<br/>multi-disciplinary nature of the work will be highlighted in order to<br/>emphasize its importance.<br/>"
"1426907","NRI: Formal Methods for Motion Planning and Control with Human-in-the-Loop","IIS","National Robotics Initiative","08/01/2014","08/04/2014","Calin Belta","MA","Trustees of Boston University","Standard Grant","Reid Simmons","07/31/2019","$488,644.00","","cbelta@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","8013","8086","$0.00","How much autonomy should a robotic system have in a safety critical application? The proposed project addresses this fundamental question. Consider a disaster relief scenario in which an autonomous aerial vehicle (a robot) is required to monitor some areas of interest, while fighting fires and searching for survivors. The survivors should be provided medical assistance and the fires should be extinguished, with priority given to stabilizing and extracting survivors. During the mission, the aerial vehicle should stay away from areas where explosions are likely, so it can continue to do its job. An emergency medical technician (EMT) and firefighter specify the robot?s mission in a way that can be easily understood by the robot.  During the execution, depending on what is discovered, the robot makes decisions on its own as long as the high-level specification is not violated. If this is not the case (e.g., there is an obstacle blocking the access to a survivor), the system initiates a dialog with the firefighter and EMT, who provide instructions to help the robot safely cope with the unexpected situation.  The research plan of this project is integrated with an education and outreach plan that includes a rich spectrum of robotic-related activities for university and high-school students. <br/><br/>This research project combines ideas and techniques from robot motion planning, formal verification, and control theory to provide a rigorous answer to the question of how much autonomy a robot should be given. A specification language inspired by temporal logics is used to communicate the mission to the robot, whose motions are directed by a hierarchical controller. At the top level, automata game techniques and two discretization schemes, one based on cellular decomposition and the other one on randomized sampling, are used. At the low level, input-output linearization combined with path and vector field following are used to implement the high level plans in quadrotors and differential drive ground vehicles. The human-robot negotiation process is based on the internal representation of temporal logic formulas and their quantitative semantics. While directed at robotics, the project impacts a number of safety critical areas, such as cyber physical systems (construction of correct-by-design systems), air traffic control (design of safe minimum-energy paths for airplanes taking off and landing in a crowded airport), etc."
"1525045","NRI: Collaborative Research: Targeted Observation of Severe Local Storms Using Aerial Robots","IIS","SPECIAL PROJECTS - CISE, National Robotics Initiative","01/01/2016","05/04/2018","Ibrahim Isler","MN","University of Minnesota-Twin Cities","Standard Grant","Ralph Wachter","12/31/2018","$308,000.00","","isler@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","1714, 8013","8086, 9251","$0.00","This project addresses the development of self-deploying aerial robotic systems that will enable new in-situ atmospheric science applications. Fixed-wing aerial robotic technology has advanced to the point where platforms fly persistent sampling missions far from remote operators. Likewise, complex atmospheric phenomena can be simulated in near real-time with increasing levels of fidelity. Furthermore, cloud computing technology enables distributed computation on large, dynamic data sets. Combining autonomous airborne sensors with environmental models dispersed over multiple communication and computation channels enables the collection of information essential for examining the fundamental behavior of atmospheric phenomena. The aerial robotic system proposed here will close significant capability gaps in conventional platform?s abilities to collect the data necessary to answer a wide range of scientific questions. The motivating application for this work is improvement in the accuracy and lead-time of tornado warnings.<br/><br/>The proposed project draws on techniques in the areas of robotics, unmanned systems, networked control, wireless communication, active sensing, and atmospheric science to realize the vision of bringing cloud robotics to the clouds. The autonomous self-deploying aerial robotic systems is comprised of multiple robotic sensors and distributed computing nodes including: multiple fixed-wing unmanned aircraft, deployable Lagrangian drifters, mobile Doppler radar, mobile command and control stations, distributed computation nodes in the field and in the lab, a net-centric middleware connecting the dispersed elements, and an autonomous decision-making architecture that closes the loop between sensing in the field and new online numerical weather prediction tools."
"1560761","EAGER: Characterizing Physical Interaction in Instrument Manipulations","IIS","National Robotics Initiative","03/01/2016","02/25/2016","Yu Sun","FL","University of South Florida","Standard Grant","Reid Simmons","02/28/2019","$299,887.00","","yusun@mail.usf.edu","3702 Spectrum Blvd.","Tampa","FL","336129446","8139742897","CSE","8013","7916, 8086","$0.00","As personal robots become common in our homes, they will perform a broad range of helpful tasks for their owners.  In doing so, all sorts of physical interactions will occur between the robot and the home environment, for example, picking up a mug requires the robot to carefully control contact forces as it secures a grasp. As tasks become more advanced, for example, operating a can opener, the robot will have to ""understand"" how to grasp the can and the can opener, so that it can operate the opener.  The goal of this project is to gather data and develop algorithms that will allow a robot to understand how to grasp tools in a way that facilitates its ability to operate that tool safely and effectively. <br/><br/>This research aims to improve the understanding of the physical interactions between the instruments and the environment in daily manipulation tasks with the goal of developing effective robotic grasp and manipulation planners to facilitate the tasks. The research designs and develops a physical-interaction observation system to observe both the interactive motion and wrench between the instruments and environment in several representative instrumental manipulation tasks by a number of participants. Each manipulation task is characterized with its instrumental motion models and wrench distribution models. Using the models, optimal grasps are generated using the task wrench coverage measure and evaluated using a real robotic arm and hand platform. The data collected in this work enables researchers to fully explore daily living tasks and provide excellent training and testing data sets for other related research.  The optimal manipulation grasping approach equips robot manipulators with the ability to hold instruments with a firm grasp to withstand the disturbance in daily living interactions and perform tasks efficiently."
"1253917","CAREER: A New Paradigm in Control and Coordination of Robot Teams in Geophysical Flows","IIS","ROBUST INTELLIGENCE","02/01/2013","05/08/2017","M. Ani Hsieh","PA","Drexel University","Standard Grant","Reid Simmons","01/31/2019","$270,999.00","","m.hsieh@seas.upenn.edu","1505 Race St, 10th Floor","Philadelphia","PA","191021119","2158955849","CSE","7495","1045, 7495, 9251","$0.00","Little prior work in unmanned underwater vehicles (UUVs) has addressed the tight coupling that is inherent between the fluid dynamics of the body of water and the vehicle itself. In fact, the fluid dynamics of large, open bodies of water can be quite complex and this proposal addresses large coherent structures that naturally occur in the flow structure of these large bodies of water. The goals of this project are to extend the PI's ONR YIP award into the realm of 3-D, expanding the mathematical and control framework for distributed autonomous sensing and tracking of geophysical fluid dynamics and to understand the long-term impact of geophysical fluid dynamics to improve the autonomy of underwater vehicles. The key idea exploits the capability of the team to cover large regions to increase the spatio-temporal sampling resolution of the flow field. The data will then be processed in a distributed fashion to obtain a global description of the flow dynamics that can be maintained and updated in real-time. The specific objectives that expand prior proposals include not only the 3-D modeling, but the development of an energy efficient stochastic pulse controller for tracking the ridges of the coherent structures and expanding the estimation of the structures through stochastic approaches that allow the fusing of larger teams of sensing entities. The intellectual merit of the proposed work stems from the synthesis of nonlinear dynamical systems theory, transport theory, and robotics to develop a modeling, control, and analysis framework for collaborative unmanned systems operating in dynamic and uncertain environments. The information gleaned from the coherent structures will be used to refine motion control and resource allocation strategies to determine minimum-effort stochastic control policies for long-term operation in GFD environments. To the PI's knowledge, this is the first attempt to use robots to track and map unstable coherent structures in the ocean, and to exploit knowledge of them to improve the autonomy of AUVs/ASVs.<br/><br/>Broader Impact: Success of these endeavors will improve the forecast of weather-climate systems, underwater transport dynamics, and the modeling and prediction of various other physical phenomena in geophysical flow environments. Since the proposed methods are very general and developed for continued operation in dynamic and uncertain environments, success of the proposed activities will likely increase the maneuverability and energy-efficiency of existing AUVs/ASVs; enable teams of AUVs/ASVs to continuously adapt to changing environmental conditions as they execute their assigned tasks; and provide greater situational awareness for various scientific, commercial, and military applications in the ocean. In addition, the proposed educational activities include a comprehensive plan to integrate the study of GFD into robotics through online educational modules for general K-12 audiences; an interdisciplinary undergraduate and graduate curriculum; and contributions to the robotics community in the form of open source software and hardware development tools."
"1527558","NRI: Collaborative Research: Multimodal Brain Computer Interface for Human-Robot Interaction","IIS","National Robotics Initiative","05/15/2016","05/27/2016","Joseph Francis","TX","University of Houston","Standard Grant","Kenneth C. Whang","04/30/2019","$308,077.00","","jtfranci@Central.UH.EDU","4800 Calhoun Boulevard","Houston","TX","772042015","7137435773","CSE","8013","8086, 8089","$0.00","Human Robot Interaction (HRI) is research that is a key component in making robots part of our everyday life. Current interface modalities such as video, keyboard, tactile, audio, and speech can all contribute to an HRI interface. However, an emerging area is the use of Brain-Computer Interfaces (BCI) for communication and information exchange between humans and robots. BCIs can provide another channel of communication with more direct access to physiological changes in the brain. BCIs vary widely in their capabilities, particularly with respect to spatial resolution, temporal resolution and noise. This project is aimed at exploring the use of multimodal BCIs for HRI. Multimodal BCIs, also referred to as hybrid BCIs (hBCI), have been shown to improve performance over single modality interfaces. This project is focused on using a novel suite of sensors (Electroencephalography (EEG), eye-tracking, pupillary size, computer vision, and functional Near Infrared Spectroscopy (fNIRS)) to improve current HRI systems. Each of these sensing modalities can reinforce and complement each other, and when used together, can address a major shortcoming of current BCIs which is the determination of the user state or situational awareness (SA). SA is a necessary component of any complex interaction between agents, as each agent has its own expectations and assumptions about the environment. Traditional BCI systems have difficulty recognizing state and context, and accordingly can become confusing and unreliable. This project will develop techniques to recognize state from multiple modalities, and will also allow the robot and human to learn about each other's state and expectations using the hBCI we are developing. The goal is to build a usable hBCI for real physical robot environments, with noise, real-time constraints, and added complexity.<br/><br/>The technical contributions of this project include:<br/>1. Characterization of a novel hBCI interface for visual recognition and labeling tasks with real physical data and environments.<br/>2. Integration of fNIRS sensing with EEG and other modalities in human robot interaction tasks. We will test our ability in the temporal domain to determine at what timescale we can correctly classify movement components that would predict a correct (rewarding) trial or non-rewarding/incorrect movement.<br/>3. Analysis and validation of the hBCI in complex robotic tele-operation tasks with human subject operators such as open door, grasp object on table, pick up item off floor etc.<br/>4. Use of hBCI to characterize human/robot state and create a learning method to recognize state over time.<br/>5. Use of augmented reality for HRI decision making.<br/>6. Further develop hBCI for tracking cognitive states related to reward, motivation, attention and value.<br/>A new class of HRI interfaces will be developed that can expand the ability of humans to work with robots; promote the use and acceptance of robot agent systems in everyday life; expand the use of hBCIs in areas other than robotics for human-machine interaction; further the development of hBCIs as our system will be tapping into reward modulated activity that will be used via reinforcement learning to autonomously update the learning machinery; and bridge the educational divide between Engineering and Neuroscience."
"1646897","RISE: High-Performance Additive Manufacturing of Composite Structures via Development of Reconfigurable Cyber-Physical Robotic (CPR) Systems","HRD","CENTERS FOR RSCH EXCELL IN S&T","01/01/2017","12/20/2016","Tarik Dickens","FL","Florida Agricultural and Mechanical University","Standard Grant","Victor A. Santiago","12/31/2019","$958,673.00","Carl Moore, Hui Wang","tarik.dickens@famu.edu","1700 Lee Hall Drive","Tallahassee","FL","323073200","8505993531","EHR","9131","","$0.00","The Historically Black Colleges and Universities Research Infrastructure for Science and Engineering (HBCU-RISE) activity within the Centers of Research Excellence in Science and Technology (CREST) program supports the development of research capability at HBCUs that offer doctoral degrees in science and engineering disciplines. HBCU-RISE projects have a direct connection to the long-term plans of the host department(s) and the institutional mission, and plans for expanding institutional research capacity as well as increasing the production of doctoral students in science and engineering. With support from the National Science Foundation, Florida Agricultural and Mechanical University (FAMU), the largest land grant institution with a 65% female population, aims to provide integrated research and training, specifically to re-engage the underrepresented female population in the engineering research community. The program will utilize the greater FAMU resources to promote engineering prominence through design-centered projects. The project will develop and offer new training/curriculum modules and workshops to FAMU graduate students and community college instructors/students and should directly impact more than six graduate students and indirectly influence nearly 400 undergraduate and graduate students at FAMU. The project will stimulate FAMU students' interests in manufacturing research by using advanced robotics technologies and cyber technologies, thus increasing PhD student enrollment and overall student retention which is vital to the University's mission to expand engineering. <br/><br/>The proposed research aims to establish methodologies and infrastructures leading to a viable way to create high-performance lightweight composite structures at various size scales. The project will leverage state-of-the-art technologies in advanced robotics and cyber-physical systems to enhance additive manufacturing of composite materials. The research elements in this project include: 1) hybrid composite manufacturing process development, modeling/simulation, and optimization, 2) a cyber-physical system (CPS) for multi-robot collaboration, control, and coordination, and 3) a reconfigurable cyber-physical robotic system for scalable demands. This project will provide the first demonstration in cybernizing composite material production through coordinated and networked manufacturing.  The research will transform the composite structure manufacturing from compression molding to a high-performance CPS production system. The Cyber-Physical Robotic Systems project will support FAMU's long-term goal of establishing a center of excellence for research and education in advanced materials and manufacturing engineering through innovative additive manufacturing research."
"1503177","CAREER: Cooperative Motion Planning for Human-Operated Robots","IIS","CAREER: FACULTY EARLY CAR DEV, ROBUST INTELLIGENCE","08/15/2014","07/06/2016","Kris Hauser","NC","Duke University","Continuing grant","Reid Simmons","09/30/2018","$378,465.00","","kris.hauser@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","1045, 7495","1045, 7495","$0.00","This proposal outlines a research and educational plan to advance decision-making techniques for robots that cooperate with human operators. Because humans far exceed the abilities of state-of-the-art robots in vision, creativity, and adaptability, interest is rapidly growing in a human-centered approach to robotics: combining the strengths of humans with the superior precision and repeatability of robots. And yet, our available motion planning tools, while powerful at computing motions for complex autonomous tasks, are poorly suited for human-centered applications that demand responsive and natural motions. This proposal hypothesizes that a new cooperative motion planning paradigm will support major advances in intuitiveness and task performance of human-operated robots such as intelligent vehicles, tele-surgery systems, search and-rescue robots, and household robots. This hypothesis is echoed in an educational plan that aims to train engineers with cross-disciplinary strengths that bridge both the technical and social dimensions of robotics. Initial human subjects studies on novice operators with the PI's cooperative motion planning algorithms suggest that the technique leads to dramatic reductions in task completion time and collision rate in cluttered environments. The proposed work will conduct further investigations along this line of research to 1) identify characteristics of cooperative planners - such as optimality, responsiveness, and completeness - that yield effective human-operator systems, both in terms of objective performance metrics and subjective preferences, 2) to design planners that optimize cooperativity metrics under computational resource and communication constraints, and 3) to enhance the capabilities of such planners to assist operators in complex manipulation tasks.<br/><br/>The planners developed in this research and the rich datasets acquired via user studies will serve as resources to help human-robot interaction (HRI) researchers design safe and socially acceptable robot behaviors. Moreover, advances in cooperative motion planning may have long-term social and economic impact by enabling new applications of robotics in driver assist systems, space exploration, medicine, household robotics, manufacturing, and construction. Research is integrated with education in a range of activities that include CS curriculum development, development of a new graduate course on optimization and machine learning, and in new software libraries for robotics education. New modules on motion planning, behavior recognition, and HRI will be incorporated in AI and robotics courses. An REU is requested for each summer of the grant and will be recruited from a minority-serving institution in cooperation with the Alliance for the Advancement of African-American Researchers in Computing (A4RC). One or more IU undergraduates will be involved in research and mentored according to the Undergraduate Research Opportunities in Computing (UROC) program, with preference given to minority and women students."
"1553726","CAREER: Crowdsourcing for Multirobot Coordination","IIS","ROBUST INTELLIGENCE","02/01/2016","02/14/2018","Nora Ayanian","CA","University of Southern California","Continuing grant","Reid Simmons","01/31/2021","$339,407.00","","ayanian@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7495","1045, 7495","$0.00","Teams of humans are exceptionally good at coordination. Teams of robots, however, are extremely clumsy at coordination, requiring extensive communication and computation. Reliance on this infrastructure poses a significant roadblock to bringing robot teams into real-world applications. This project is pursuing an integrated research, education, and outreach approach for developing novel, data-driven algorithms for multi-robot coordination, inspired by human coordination. As cognitive beings that make decisions based on broad context, memory, and sensing, human capabilities are challenging to transfer to robotics. To facilitate this transfer, the project is developing an online crowdsourcing application that tasks participants with creating a global structure, such as a shape. The application constrains participants to robot-like capabilities by limiting available information and actions. The application will provide a faithful representation of the capabilities of distributed teams of robots, and will be used to gain insights into human coordination that can then be transferred to a multi-robot system.<br/><br/>The overarching goal of the proposed work is to develop novel methodologies for multi robot coordination firmly grounded in human collaboration, based on models learned from data collected via a crowdsourced online application. To this end, the research objectives are (1) to explicate the relationship between context (communication and sensing) and outcomes in distributed teams of humans working on tightly coupled tasks using data generated from an online multi-person interface; (2) to identify, using statistical methods, parameters for distributed teams of robots solving similar shared objective problems; (3) to infer, using deep learning architectures, diverse ensembles of coordination models for distributed teams of robots solving tightly coupled problems using the data collected from the crowdsourcing application; and (4) to validate these models by evaluating their success in solving tightly coupled problems using a combination of simulation, hardware, and mixed reality experiments."
"1552706","CAREER: Robot Learning from Motor-Impaired Instructors and Task Partners","IIS","ROBUST INTELLIGENCE","02/01/2016","02/14/2018","Brenna Argall","IL","Rehabilitation Institute of Chicago","Continuing grant","Reid Simmons","01/31/2021","$305,345.00","","brenna.argall@northwestern.edu","345 East Superior Street","Chicago","IL","606112654","3122384534","CSE","7495","1045, 7495","$0.00","Assistive machines - like power wheelchairs, robotic arms, exoskeletons, prostheses - are vital for enabling independence for people with severe motor impairments. However, there exists a paradox, where often the more severe a person's impairment, the less able they are to operate these very machines which might improve their quality of life. Here robotics technologies have the potential to transform the field of human health and rehabilitation: by turning the machine into a robot, that can operate itself autonomously and share the control burden. It will be crucial that these robots adapt to the human user's unique preferences and abilities, and how both change over time is crucial for achieving widespread adoption and acceptance, and especially if attached to a human's body to provide physical assistance. <br/><br/>There has been limited study of robot learning from non-experts, and the domain of motor-impaired teachers is even more challenging: their control signals are noisy (due to artifacts in the motor signal) and sparse (if providing motor commands is more effort), and filtered through an interface. Rather than treat these constraints as limitations, the proposed work hypothesizes that such constraints become advantageous for machine learning algorithms that exploit unique characteristics (like problem-space sparsity) of control and feedback signals from motor-impaired humans. The work develops multiple novel machine learning algorithmic techniques, (1) that reason explicitly about the control interface and how it interacts with the full robot control space; (2) that derive information about the human's control patterns and task requirements, from variability in the human's teleoperation commands; and (3) which include the design of adaptation cues informed by reward- and example-based feedback from motor-impaired teachers. The proposed work also performs subject studies with motor-impaired end-users operating multiple robotic platforms, both to explore this problem space and assess the functionality and user acceptance of the contributed algorithmic techniques."
"1611254","Robotic See-Through Imaging with Everyday RF Signals","ECCS","COMMS, CIRCUITS & SENS SYS","09/01/2016","07/14/2016","Yasamin Mostofi","CA","University of California-Santa Barbara","Standard Grant","Jenshan Lin","08/31/2019","$300,000.00","","ymostofi@ece.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","ENG","7564","153E","$0.00","The overall goal of this proposal is to introduce a new multi-disciplinary foundation for see-through imaging with everyday RF signals using unmanned autonomous vehicles.  See-through imaging with everyday RF signals can considerably impact many different areas such as search and rescue operations, surveillance and security, detection/classification of occluded objects, infrastructure assessment, medical imaging, and archaeological exploration, just to name a few.  Robotic networks, on the other hand, can have a tremendous impact in many different areas such as disaster relief, emergency response, environmental monitoring, surveillance, and security.  This proposed work at the intersection of RF sensing and robotics can considerably advance the state-of-the-art in RF sensing by jointly and successively optimizing robotic path planning and RF imaging, and can thus have a transformative impact on our society.  The proposal also has a significant educational component targeting under-represented students. <br/><br/>More specifically, in this research effort, a new multi-disciplinary paradigm is proposed to equip a number of unmanned vehicles with see-through imaging of completely unknown areas using everyday RF signals. Along this line, the first major task focuses on the interplay between motion patterns and RF imaging performance, in order to understand and mathematically characterize robotic motion patterns most informative for RF imaging. The second task then develops the foundation of jointly and successively co-designing the path planning and imaging of the robots while considering the dynamics of the vehicles, environmental navigation constraints, motion energy budget, and operation time.  Finally, the proposed theories and design paradigm are extensively validated with ground and aerial vehicles. Overall, the proposed research can make a significant contribution to enhancing the state-of-the-art in both RF imaging and robotics."
"1542286","RET Site in Mechatronics and Robotics with Entrepreneurship and Industry Experiences","EEC","RES EXP FOR TEACHERS(RET)-SITE, HUMAN RESOURCES DEVELOPMENT","06/01/2016","04/24/2018","Vikram Kapila","NY","New York University","Standard Grant","Mary Poats","05/31/2019","$600,000.00","Sheila Borges Rajguru, Jennifer Listman","vkapila@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","ENG","1359, 1360","115E, 1359, 9177","$0.00","This Research Experiences for Teachers (RET) in Engineering and Computer Science Site at New York University (NYU) seeks to strengthen K-12 education in the STEM disciplines by involving middle and high school science and mathematics teachers from the New York City School District in mechatronics and robotics research, entrepreneurship, and industry experiences through 6-week summer workshops.  The RET participants will gain first-hand multidisciplinary experiences to foster their development of the necessary pedagogical content knowledge to engage their own K-12 students in authentic experiences in science and engineering. The program will impact two areas that are of direct interest to the United States and the world: increasing access for K-12 teachers and their students to a deeper understanding of the STEM disciplines, research, and career opportunities; and inspiring teachers and students to pursue engineering careers. The decreasing cost of electronics and hardware components along with technological advances in additive manufacturing promise to significantly lower the cost of robot hardware, making the use of robots economical in diverse industries. Mechatronics and robotics designs will provide participants with a comprehensive experience in systems integration and product development through which they can practice and hone their skills in creativity, inventiveness, and entrepreneurship and gain an appreciation of the pathway from STEM education to careers.  <br/><br/>Over a three-year period this RET Site will offer an intensive summer research program for a total of 30 middle and high school STEM teachers from schools in underserved New York City neighborhoods with socially, economically, racially, and ethnically diverse student bodies. Planned research projects include: marine robotics, microfluidic biosensing, wearable robotics, mechatronics device for liquid projectile visualization, and robots for disabilities. Project plans include: conduct guided training under the supervision of the Principal Investigator; collaborate with management experts to allow teachers to learn entrepreneurship, conduct innovation case-studies, and shadow entrepreneurs; offer research and industry experiences to teachers, in 2-teacher teams collaborating with faculty/industry mentors and research students; conduct events such as Open House, RET Day@Poly, and research seminars; conduct an Inno/Vention student idea contest and develop a business-philanthropy partnership to offer summer internships to students."
"1750750","CAREER: Drones in Public: Foundational Interaction Research","IIS","Cyber-Human Systems (CHS)","05/01/2018","04/23/2018","Brittany Duncan","NE","University of Nebraska-Lincoln","Continuing grant","Ephraim P. Glinert","04/30/2023","$103,406.00","","bduncan@unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","CSE","7367","1045, 7367, 9150","$0.00","Small Unmanned Aerial Vehicles (sUAVs), or drones, are one of the most adopted types of robot and have become ubiquitous in outdoor public spaces for applications in agriculture and public safety.  But design limitations and lack of interaction principles have limited their adoption for indoor uses.  The goal of this research is to discover broad interaction principles for communicative sUAV flight paths in various spaces and with diverse users, so that when design limitations such as indoor navigation and battery life are solved the drones will be capable of safe, efficient, and informative interactions with people.  To this end, the first challenge will be to identify key communication failures, or barriers between humans and robots, which can create unsafe and inefficient interactions, and to define strategies for avoiding these problems.  Guidelines will be developed for gestural communication from a vehicle to a user in order to generate safer and more natural interactions, while respecting personal space requirements.   The two central hypotheses underlying this research are that gestural communication will allow better visibility of robot state or knowledge to bystanders while being applicable to existing platforms without modifications, and that interaction distances will need to adapt to the design of the vehicle, the user, and the environment to maintain comfort and efficiency in interactions.  This work will have broad impacts both on education and on society through directed activities to improve understanding of human-robot interaction.  Education will be supported through activities such as lesson plans for K-12 students, integration of the research into an undergraduate human-computer interaction class, and informing a semester-long course for both undergraduate and graduate students on human-robot interaction (HRI).  Additional outreach efforts will include a month-long interaction with 6-8th grade students from local Title 1 schools teaching K-5 students about the scientific method, and an evening class for adults to inform them about current robotics and HRI research.  The PI will continue her ongoing efforts to broaden participation in computer science research. <br/> <br/>This research will encompass three parallel objectives related to gestural communications by sUAVs and comfortable distancing.  Objective 1 will focus on communicative motions of state information from the vehicle; gestures will be generated through participatory design and tested using methods from the social sciences.  Objective 2 will also be informed by methods from the social sciences, but will focus on distancing with sUAVs and will take advantage of an existing room in the PI's lab with movable walls, video cameras, and a motion capture system.  Each of these two research objectives could be carried out in the absence of progress from the other; however, their exploration together is natural since the gestures are conveyed by different vehicles, scaled to spaces, and the robots perform tasks which may require human involvement.  This combined investigation will comprise Objective 3, which will focus on efficient signaling, incorporating the distancing work into the flight paths, and reception with users performing a variety of tasks.   Project outcomes will transform close-proximity HRI by enabling sUAVs to generate communicative flight paths that are optimized based on likelihood of receipt and comfort in highly independent human-robot teams.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1663416","Collaborative Research: Processing and Performance of Chained Magnetic Particle Composites for Soft Robotics","CMMI","Materials Eng. & Processing","04/01/2017","03/16/2017","Joseph Tracy","NC","North Carolina State University","Standard Grant","Mary M. Toney","03/31/2020","$307,944.00","","joe_tracy@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","ENG","8092","085E, 7237, 8021, 8025, 8037","$0.00","Soft robotics is a rapidly growing field in which soft materials, such as polymers, are formed into devices whose mechanical response can be triggered by physical or chemical stimuli. Magnetically responsive polymer composites containing embedded magnetic particles are especially attractive for soft robotics, because they allow for non-contact actuation with electromagnets or permanent magnets. Furthermore, chaining the magnetic particles within the polymer imparts an enhanced, directional response. This award supports fundamental experimental and theoretical research to investigate the processing and performance of chained magnetic particle composites for soft robotics. Soft robotic devices based on chained magnetic particle composites developed in this research will be immediately useful in practical applications, including non-contact peristaltic pumps and remotely actuated microfluidic valves and mixers for next-generation medical diagnostic devices. Theoretical tools developed in this research will also drive innovation by providing easily accessible metrics to inform the design and evaluate the performance of chained magnetic particle actuators. Themes and results from this research will be integrated into education and outreach activities designed to inspire and recruit the next generation of scientists and engineers.<br/><br/>While there have been many reports of magnetoactive elastomers for soft robotics, the design of these materials is usually empirical rather than guided by a predictive model, resulting in missed opportunities to optimize their design and performance, such as with chained-particle formulations. This research aims to develop a framework and figures of merit for predicting the behavior of magnetoactive elastomer actuators and to employ them for designing useful devices with enhanced capabilities. Using these tools, the torque in chained-particle magnetoactive elastomers generated in applied magnetic fields will be maximized, elasticity of the polymer and elastic instabilities will be incorporated in device function, and shape memory polymers will enable realization of magnetoactive elastomer materials and devices that are reconfigurable and selectively addressable. This research will advance the field of chained-particle magnetoactive elastomers by developing tools to guide their design for applications in soft robotics and by demonstrating the capabilities of these materials and devices."
"1653322","SCH: CAREER:  Co-Robotic Ultrasound Sensing in Bioengineering","IIS","National Robotics Initiative, Smart and Connected Health","09/01/2017","07/22/2017","Emad Boctor Mikhail","MD","Johns Hopkins University","Standard Grant","Wendy Nilsen","08/31/2022","$419,902.00","","eboctor1@jhmi.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","8013, 8018","1045, 8018, 8086","$0.00","Ultrasound imaging, while frequently used in heathcare, remains challenged by three important issues. First, a very significant percentage of ultrasonographers (63-91%) develop musculoskeletal disorders due to effort required to perform imaging tasks. Second, ultrasound imaging is limited by loss of resolution at increasing depths (e.g., in imaging of obese patients), significantly limiting imaging value with conventional ultrasound imaging. Finally, ultrasound imaging is most commonly qualitative in nature, and quantitative imaging (e.g., measurement of the speed of the ultrasounds signal) has been limited. There is significant gap and need for more accurate imaging of various organs and diseases. All these issues hinder unleashing the potential benefit of ultrasound technology serving a wider sector of patients in hospitals and most importantly outside hospitals, including point-of-cares and homes. All these seemingly distinct issues can be tackled and addressed via a co-robotic and multi-wave ultrasound framework. The objective of this proposal is to characterize fundamental principles at the intersection of robotics, ultrasound physics, signal processing, machine learning and bioengineering, which will enable a new generation of advanced ultrasound imaging technologies capable of providing cost-effective precise interventional guidance and high-quality quantitative diagnostic imaging to a wider sector of people at hospitals, points-of-care, and homes. Additionally, this proposal emphasizes the following educational objectives: (1) create hands-on robotic imaging undergraduate/graduate training curriculum relying on the MUSiiC toolkit; (2) bring research results to local schools including Centennial High School and involve their students in research; and (3) deploy low-cost wireless ultrasound systems and light-weight and human-safe robots in high schools and university classrooms. <br/><br/><br/>The research objective of this proposal is to characterize fundamental principles at the intersection of robotics, ultrasound physics, signal processing, machine learning and bioengineering, which will enable a new generation of advanced ultrasound imaging technologies capable of providing cost-effective precise interventional guidance and high-quality quantitative diagnostic imaging to a wider sector of people at hospitals, points-of-care, and homes. To achieve this objective, this proposal includes an integrated research-education plan consisting of three complementary and interconnected research thrusts. Thrust 1: Novel Multi-wave Ultrasonic and Robotic Imaging Devices focuses on novel multi-wave ultrasound imaging architectures and physics-based simulations that describe their performance under variable calibration and robot tracking accuracies, and beam-width and geometry limitations of ultrasound sensors.  Specifically, the project proposes ultrasonically smart tools, co-robotic multi-wave ultrasound systems, and active calibration platform and validation. Thrust 2: Robust Sensing and Co-Robotic Imaging focuses on using models, architectures and devices from Thrust 1 to endow surgical and interventional guidance with robust sensing and to devise and enable new imaging algorithms with both robust sensing and co-robotic intelligence. Specifically, the project uses a novel thermal imaging algorithm leveraging the unique multi-wave ultrasound architecture described in Thrust 1. Additionally, we explore co-robotic imaging to substantially enhance ultrasound resolution utilizing synthetic aperture reconstruction guided by the robot's precise and accurate motion trajectory.  Thrust 3: Education focuses on integrating research results into education at the high school, undergraduate, and graduate levels, while emphasizing participation by an underrepresented individuals (African American and women) in Biomedical Sciences and Engineering. The proposal will also bring research results to local schools including Centennial High School and involve their students in research. This can easily achieve this by relying on the team's Medical UltraSound Imaging and Intervention Collaboratory (MUSiiC) software toolkit and enabling smart phone and tablets to control ultrasound systems. The plan also includes deployment of a number of low-cost wireless ultrasound systems, along with light-weight and human-safe robots, to high school and university classrooms. The results from all three thrusts will be applied to systems for three clinical testbed setups, including cancer intervention, catheterization, and diagnostic imaging."
"1637789","NRI: Collaborative Research: Software Framework for Research in Semi-Autonomous Teleoperation","IIS","National Robotics Initiative","10/01/2016","05/08/2017","Peter Kazanzides","MD","Johns Hopkins University","Standard Grant","Reid Simmons","09/30/2019","$978,300.00","Russell Taylor","pkaz@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","8013","8086, 9251","$0.00","Telemanipulation systems consist of a human interacting with a mechanical device on the master side to operate a robot at the remote side. They provide natural opportunities for research in intelligent human/robot collaboration, but existing commercial systems, used in areas such as telesurgery, are not intelligent and therefore only replicate the actions of the human operator. These systems are also proprietary, expensive, and not available for modification by researchers. The goal of this NRI project is to provide an open-source software infrastructure that is designed to work with a broad range of hardware and simulated devices to enable a larger community to pursue research and education in intelligent telemanipulation at a lower cost.<br/><br/>The increasing pace of robotics research can be attributed, at least in part, to the increasing availability of software infrastructure, such as Robot Operating System (ROS), and open hardware platforms. This NRI project focuses on providing a software infrastructure for research in intelligent telemanipulation, leveraging infrastructure developed for the Raven II robot and the da Vinci Research Kit (dVRK) and continuing to extend it to other systems, including simulated robots. The three main tasks are to: (1) engage the community to guide development, (2) develop and implement a common API for the diverse hardware platforms, and (3) provide a set of high-level, platform-independent software modules. The goal is to support research towards semi-autonomous telerobotic systems that can more effectively combine the knowledge, reasoning, and decision-making capabilities of a human with the sensing and manipulation capabilities of a robot."
"1829237","WORKSHOP: Bridging the Gap: An NSF Workshop on Conversational Agents and Human-Robot Interaction","IIS","Cyber-Human Systems (CHS), ROBUST INTELLIGENCE, National Robotics Initiative","05/01/2018","03/29/2018","Justine Cassell","PA","Carnegie-Mellon University","Standard Grant","Tatiana D. Korelsky","04/30/2019","$49,869.00","Brian Scassellati","justine@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367, 7495, 8013","7367, 7495, 7556, 8086","$0.00","This award funds participation of researchers in a 2-day workshop to be held in Washington, D.C. entitled ""Bridging the Gap: An NSF Workshop on Conversational Agents and Human-Robot Interaction"". Recent technical advances have led to increased development and adoption of robots and embodied conversational agents in a variety of domains and contexts. As these agents and robots become increasingly ubiquitous in everyday life, it will become essential for researchers and designers of both robots and agents to understand the common challenges and opportunities for collaboration between humans and nonhuman agents. This award funds the attendance of researchers in the fields of embodied conversational agents and human-robot interaction for a workshop to lay the groundwork for a shared research agenda across both fields.<br/> <br/>The workshop involves keynote speakers commenting on the state of each field with panelists from the other, breakout sessions for discussion of crosscutting themes of common interest, and the development of a shared research agenda to identify current grand challenges and opportunities for productive collaboration between the fields of embodied conversational agents and human-robot interaction. The broad themes discussed include the challenges of embodiment (physical or virtual), coordination in mixed human-agent teams, social and affective dynamics of human-agent collaboration, control systems and learning, and the ethical implications of human-agent collaboration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1659774","REU Site: Carnegie Mellon University Robotics Institute REU Site","IIS","RSCH EXPER FOR UNDERGRAD SITES","06/01/2017","03/27/2017","John Dolan","PA","Carnegie-Mellon University","Standard Grant","Wendy Nilsen","05/31/2020","$359,938.00","","jmd@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1139","9250","$0.00","This Research Experiences for Undergraduates (REU) Site will advance knowledge by training students in the key technological area of robotics and preparing them for graduate study and technical leadership.  The sciences that make up the discipline of robotics provide a unique opportunity to immerse students in research with real-world applications. Rapid research advances place robotics at the forefront of the nation's interests. Furthermore, robotics plays a vital role in science, technology, engineering, and mathematics education due to its multi-disciplinary nature. Robotics-related technologies are becoming ubiquitous, for example sensors and wearable devices, and they are dominating national headlines and discussions on such innovations as driverless cars, big data and data mining, or medical robotics.  An emphasis on increasing the participation of under-represented groups in this site has the potential to extend both the range of research projects within the robotics field and the range of societal concerns and problems addressed by these researchers as they enter upon and conduct their careers. <br/><br/>This site will provide high-quality guided research experiences for undergraduate students with leading faculty in computer vision, field and space robotics, artificial intelligence, manipulation, and machine learning. Additional mentors, including researchers and graduate students, will provide unique perspectives and insights into science and engineering education careers. Mentors will meet weekly with scholars to facilitate their research experience and positive learning outcomes. The strategic goal of this site is to provide research experiences and mentorship to U.S. citizens and permanent residents from under-represented groups and those from higher education institutions with fewer research opportunities. Student recruitment and selection will be conducted accordingly and will draw on broad past experience in attracting under-served populations.  The leadership team and participating faculty share this commitment and bring expertise in mentoring students from diverse backgrounds to communicate their research results to coming generations of students, middle school and high school teachers, and the general public."
"1638073","NRI: Guiding with Touch: Haptic Cueing of Surgical Techniques on Virtual and Robotic Platforms","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","01/01/2017","04/13/2018","Marcia O'Malley","TX","William Marsh Rice University","Standard Grant","Reid Simmons","12/31/2019","$1,016,000.00","Michael Byrne","omalleym@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","CSE","7495, 8013","8086, 9251","$0.00","Virtual reality has enabled surgeons to train on procedures without risk to patients. However, the feedback surgical trainees receive is delayed, subjective, and qualitative, thereby lacking support for rapid acquisition of skill. This project will enhance surgical performance and training by providing performance feedback using touch-based cues that convey movement quality and strategies rather than task outcomes like procedure time. This will allow trainees to get feedback that is immediate and quantitative, and result in improved performance in difficult-to-train motor skills. Should this research prove successful, there is an opportunity to make meaningful changes in how surgeons are trained. <br/><br/>Co-robots in the endovascular surgical domain can take several forms, from a virtual reality simulator that mimics patient-specific procedures, enabling high-fidelity procedural rehearsal, to telesurgical systems that are used to navigate flexible robotic tools to anatomical locations. Such systems require significant skill to use and, in turn, a rigorous training protocol before certification to operate with the robot is granted. To date, training protocols rely on practice and subjective feedback by a skilled observer, and acquisition of skill on these systems can be inefficient. Furthermore, there is a lack of objective metrics of skill acquisition. This project will investigate the use of haptic feedback to trainees based on motion-based performance metrics, and will evaluate the potential role of this feedback modality during performance and training for simulated and robotic endovascular surgical tasks. In particular, the project will evaluate the benefit of providing specific performance feedback that highlights task strategies in the motion space, and the effect of providing such directed feedback on learning and retention of the task."
"1617718","RI: Small: Network Formation for Multi-Robot Systems","IIS","ROBUST INTELLIGENCE","09/01/2016","04/13/2018","Ibrahim Isler","MN","University of Minnesota-Twin Cities","Standard Grant","Reid Simmons","08/31/2019","$389,660.00","","isler@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","7495, 7923, 9251","$0.00","Many multi-robot tasks, which arise in search-and-rescue, environmental monitoring and similar applications, require the robots to communicate with one another.  In contrast to most current work, where the robots are deployed in controlled settings and are guaranteed to be connected, as multi-robot systems get deployed in real-world applications, they will often lose connectivity due to navigation errors, communication failures, or planned movements into communications-denied areas. When this happens, the robots need a systematic and efficient way to reconnect into a network. This project studies the theoretical question of how should the robots move so that they can quickly form a network.<br/><br/>Network formation generalizes a number of fundamental problems (e.g. rendezvous search, freeze tag, minimizing movement) that have been studied in relatively simple settings by disjointed groups of communities. This work attempts to introduce a unified treatment and address aspects relevant to robotics applications, such as the presence of obstacles and sensing limitations. The proposed work will study three variants of network formation for a number of practically relevant environment models. The first two variants are based on the information available to the robots (e.g., whether the initial locations are known).  The third variant will introduce novel network formation problems in which a team of heterogeneous vehicles with different motion capabilities (e.g. ground robots on a terrain and aerial vehicles flying over them) try to form a network. These variants are formulated as novel-optimization problems whose solutions will provide efficient network-formation strategies with provable performance guarantees. Results will be evaluated in simulation and field applications with ground-ground and ground-air vehicle teams."
"1724237","S&AS: FND: COLLAB: Learning Manipulation Skills Using Deep Reinforcement Learning with Domain Transfer","IIS","S&AS - Smart & Autonomous Syst","09/01/2017","04/13/2018","Kate Saenko","MA","Trustees of Boston University","Standard Grant","Jie Yang","08/31/2020","$308,000.00","","saenko@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","039Y","046Z, 9102, 9251","$0.00","This project develops new methods of using deep reinforcement learning to solve real world robotics problems. The project focuses on robotic manipulation tasks such as grasping, opening doors, helping out in the home, performing repairs aboard Navy ships, etc. The key operation in all of the above is the ability for the robot to reliably manipulate objects, parts, or tools with its hands in order to perform a task. The project leverages deep reinforcement learning: a new approach to robotic learning that is capable of learning both perceptual features and control policies simultaneously. This project could have important benefits for a variety of practical applications including: explosive ordnance disposal for our military, materials handling aboard Navy ships, dexterous robotic assistants for NASA astronauts in space, assistive technologies that could help seniors age in place longer, better capabilities for handling radioactive materials during nuclear cleanup, assistance for ergonomically challenging tasks in manufacturing, and general assistance in the office and the home.<br/><br/>This research investigates novel deep reinforcement learning approaches for robotic grasping and manipulation that work well in previously unseen, unstructured environments and compose end-to-end tasks from simpler sub-task controllers. The research is built on two main results from research team's recent work, the deep learning approach to grasping and domain adaptation methods for deep neural networks. The research is guided by the following three key ideas: 1) learning in simulation and then using domain transfer techniques to adapt the solutions to reality; 2) simplifying learning for visuomotor control by using planning to estimate the value function; and 3) using symbolic task and motion planning to perform end-to-end tasks by sequencing learned controllers and planned arm/hand motions. The research team performs extensive evaluations to ensure that the system is able to perform novel instances of a task, e.g., those in a context that the robot has not seen before."
"1637941","NRI: Real-Time Semantic Computer Vision for Co-Robotics","IIS","National Robotics Initiative","09/01/2016","04/13/2018","Nuno Vasconcelos","CA","University of California-San Diego","Standard Grant","Jie Yang","08/31/2019","$727,116.00","","nuno@ece.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","CSE","8013","8086, 9251","$0.00","This project develops real-time object recognition algorithms that generate extensive semantic object descriptions as a side effect of recognition. This side-information includes perceived object costs, attributes (object properties), and affordances (actions afforded by objects). With these, the act of recognizing a ""door knob"" would automatically produce the information that this is a ""flexible"" object, ""made of metal,"" which ""can be grasped"" and ""can be twisted,"" but ""cannot be eaten."" For robotics, this information is sometimes more important than the recognition of the object itself. The project enables robots to perform zero shot learning, e.g. learn to recognize door knobs by simply being told that these are objects that ""are flexible, made of metal, can be grasped and twisted but not eaten."" The research has applicability in areas such as manufacturing, intelligent systems, assisted living, and homeland security. Educationally, the project provides an exciting opportunity for undergraduate research.<br/><br/>This research develops new methods for top-down (task-driven) regularization of deep learning algorithms, though a combination of structural and loss-based regularizers. Structural regularizers constrain object and scene recognition models to guarantee speed and automatic generation of rich mid-level semantic (MLS) descriptions as a side effect of recognition. Loss-based regularizers penalize errors in the multiple semantic outputs of these models, enabling simultaneously high performance in object recognition, MLS predictions, and zero-shot learning. The resulting learning algorithms will endow robots with human-like abilities to infer rich MLS descriptions of objects and scenes as a ""side effect"" of object recognition and scene classification, in real-time. These contributions will be developed in the context of a new co-robotics problem, person-following unmanned aerial vehicles, where computer vision plays a mission critical role for tasks such as control and semantic motion planning but whose requirements in terms of speed and MLS inference are far superior to what is feasible today."
"1832383","WORKSHOP: Doctoral Consortium at the 2018 ACM/IEEE Human Robot Interaction (HRI) Conference","IIS","Cyber-Human Systems (CHS)","04/15/2018","04/12/2018","William Smart","OR","Oregon State University","Standard Grant","Ephraim P. Glinert","03/31/2019","$20,000.00","","smartw@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7367","7367, 7556","$0.00","This award support a Pioneers Workshop (doctoral consortium) of approximately 24 students (20 graduate participants, one undergraduate participant, and three student organizers), along with distinguished research faculty.  The event takes place as part of the first day of activities at the 13th International Conference on Human Robot Interaction (HRI 2018), held March 5-8 in Chicago, and which was jointly sponsored by ACM and IEEE.  HRI is the premier conference for showcasing the very best interdisciplinary and multidisciplinary research on human-robot interaction, with roots in diverse fields including robotics, artificial intelligence, social psychology, cognitive science, human-computer interaction, human factors, engineering, and many more.  It is a single-track, highly selective annual international conference that invites broad participation.  The theme of HRI 2018 was ""Robots for Social Good.""  The conference sought contributions from a broad set of perspectives, including technical, design, methodological, behavioral, and theoretical, that advance fundamental and applied knowledge and methods in human-robot interaction, with the goal of enabling human-robot interaction through new technical advances, novel robot designs, new guidelines for design, and advanced methods for understanding and evaluating interaction.  More information about the conference is available online at http://humanrobotinteraction.org/2018.  The Pioneers Workshop was designed to afford a unique opportunity for the best of the next generation of researchers in human-robot interaction to be exposed to and discuss current and relevant topics as they are being studied in several different research communities.  This is important for the field, because it has been recognized that transformative advances in research in this fledgling area can only come through the melding of cross-disciplinary knowledge and multinational perspectives.  Participants were encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years.  Participants also gained leadership and service experience, as the workshop was largely student organized and student led.  The PI expressed his strong commitment to recruiting women and members from under-represented groups.  To further ensure diversity the event organizers considered each applicant's potential to offer a fresh perspective and point of view with respect to HRI, and worked to recruit students who are just beginning their graduate degree programs in addition to students who are further along in their degrees.  <br/><br/>The Pioneers Workshops are designed to complement the conference, by providing a forum for students and recent graduates in the field of HRI to share their current research with their peers and a panel of senior researchers in a setting that is less formal and more interactive than the main conference.  During the workshop, participants talk about the important upcoming research themes in the field.  The formation of collaborative relationships across disciplines and geographic boundaries is encouraged.  To these ends, the workshop format encompasses a variety of activities including keynotes, a distinguished panel session, and breakout sessions.  To start the day, all workshop attendees briefly introduce themselves and their interests.  Following the opening keynote, approximately half of the participants present 3-minute overviews of their work, leading into an interactive poster session.  This enables all participants to share their research and receive feedback from students and senior researchers in an informal setting.  The workshop organizers facilitate the post-presentation discussion and encourage participants to ask questions of their peers during the interactive break and poster session.  After lunch, the remaining workshop participants give their 3-minute overviews, followed by presentation of their posters during a second interactive poster session.  Senior researchers (in addition to those on the panel) are invited to attend the student presentations and poster sessions in order to provide feedback to participants, and workshop participants are invited to present their posters during the main poster session of the HRI conference as well.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1526200","NRI: Collaborative Research: Targeted Observation of Severe Local Storms Using Aerial Robots","IIS","National Robotics Initiative","01/01/2016","08/13/2015","Dezhen Song","TX","Texas A&M Engineering Experiment Station","Standard Grant","Ralph Wachter","12/31/2018","$224,242.00","","dzsong@cs.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","CSE","8013","8086","$0.00","This project addresses the development of self-deploying aerial robotic systems that will enable new in-situ atmospheric science applications. Fixed-wing aerial robotic technology has advanced to the point where platforms fly persistent sampling missions far from remote operators. Likewise, complex atmospheric phenomena can be simulated in near real-time with increasing levels of fidelity. Furthermore, cloud computing technology enables distributed computation on large, dynamic data sets. Combining autonomous airborne sensors with environmental models dispersed over multiple communication and computation channels enables the collection of information essential for examining the fundamental behavior of atmospheric phenomena. The aerial robotic system proposed here will close significant capability gaps in conventional platform?s abilities to collect the data necessary to answer a wide range of scientific questions. The motivating application for this work is improvement in the accuracy and lead-time of tornado warnings.<br/><br/>The proposed project draws on techniques in the areas of robotics, unmanned systems, networked control, wireless communication, active sensing, and atmospheric science to realize the vision of bringing cloud robotics to the clouds. The autonomous self-deploying aerial robotic systems is comprised of multiple robotic sensors and distributed computing nodes including: multiple fixed-wing unmanned aircraft, deployable Lagrangian drifters, mobile Doppler radar, mobile command and control stations, distributed computation nodes in the field and in the lab, a net-centric middleware connecting the dispersed elements, and an autonomous decision-making architecture that closes the loop between sensing in the field and new online numerical weather prediction tools."
"1657548","CRII: SaTC: Towards Securing Social Robots","CNS","CRII CISE Research Initiation","07/01/2017","03/07/2017","Despoina Perouli","WI","Marquette University","Standard Grant","Nina Amla","06/30/2019","$175,000.00","","despoina.perouli@marquette.edu","P.O. Box 1881","Milwaukee","WI","532011881","4142887200","CSE","026Y","025Z, 8228","$0.00","Robotics has traditionally focused on industrial and medical applications until recently with the development of robots, known as social robots, that are designed to intelligently and socially interact with humans. There has been little research on the privacy and security implications of these social robots. Moreover, with the potential wide-spread use of social robots in the next decade for the home, office, and daily living activities, high among the societal challenges will be protecting our privacy and ensuring security of social robots in wide-use.  <br/><br/>This research project addresses the cyber security of social robots, their vulnerabilities and risks. There are four primary objectives of this project: (1) seek to uncover security vulnerabilities of a social robot by focusing on the tools used to program these robots, its sensors and actuators; (2) develop algorithms capable of detecting whether a social robot has been compromised and violated privacy and security directives; (3) analyze relevant capabilities of current social robot prototypes; and, (4) investigate privacy and usability issues of a social robot. In addition, a summer camp at Marquette University on cyber security with special sessions on privacy and security in robotics, and especially social robots, is planned for students and teachers in southeastern Wisconsin."
"1743262","Group Travel Award for 2017 Workshop on Learning Perception and Control for Autonomous Flight: Safety, Memory, and Efficiency","IIS","ROBUST INTELLIGENCE","04/15/2017","06/05/2017","Konstantinos Karydis","CA","University of California-Riverside","Standard Grant","Weng-keen Wong","03/31/2019","$12,000.00","","kkarydis@ece.ucr.edu","Research & Economic Development","RIVERSIDE","CA","925210217","9518275535","CSE","7495","7495, 7556","$0.00","Aerial robots, commonly referred to as drones, offer promise in several research, educational, defense and commercial applications.  Some examples include precise agriculture, aerial photography, agile inspection and monitoring, and package delivery.  In most of those applications that aerial robots have started venturing outside the research lab and into the real world, robot operation is often semi-autonomous.  Semi-autonomous operation typically assumes availability of GPS signal for localization, and at least some prior information about the working environment. Sensory-based, fully autonomous operation in unknown environments remains mostly at the research stage.  Yet, endowing full autonomy to aerial robots can enhance their impact on the nation's education, economy, and defense.  To this end, it is important to seamlessly merge perception, planning, and control for autonomous robotic flight in unknown environments.  This can be achieved by integrating machine learning tools into aerial robot perception and control.  Deep learning has recently emerged as a promising way to extract semantic meaning for autonomy.  Learning perception and control for autonomous flight can be approached by replacing hand-engineered map representations with raw sensor observations, and learning appropriate responses.  However, this is not a straightforward task, and several challenges remain.  This workshop critically addresses how to i) best incorporate memory and ii) derive safety guarantees for the learning-based system.  These two aspects are necessary to improve the capacity of aerial robots to operate autonomously in unknown environments, and to push forward the current state-of-the-art in robotic flight.  In addition to the domain of robotic flight, the outcomes of this workshop are relevant to endowing autonomy in general robotic systems that are able to learn, thus helping make autonomous robots ubiquitous.<br/><br/>The objective of this workshop is to address the theoretical and technical challenges faced in order to endow learning-based systems with the capacity to operate autonomously in unknown environments.  A critical step in this effort is to understand how memory-augmented autonomous learners can operate with provable safety guarantees.  The workshop thus examines two highly-relevant questions.  i) How to theoretically analyze the data and structure of learning-based systems to provide guarantees on safety and task success?  ii) What is the effect of long-term memory and, in particular, can recurrent connections or dynamic external memory replace global map information?  The workshop seeks answers to these questions by bringing together experts from robot planning and control, reinforcement learning and deep learning, and formal methods. The workshop also solicits participation of contributed authors working in relevant areas.  These include but are not limited to applying deep reinforcement learning for vision-based control of underactuated robots; learning visuomotor policies and deriving formal guarantees for learning based on neural networks; and developing neural network architectures that involve temporal recurrence and memory.  The above questions are asked here in the context of high-speed aerial robot autonomous navigation.  However, their scope can be generalized to other areas of robotics that learning perception and control for autonomous operation in unknown environments is desirable; examples include manipulation and legged locomotion."
"1724464","NRI: Collaborative Research: Unified Feedback Control and Mechanical Design for Robotic, Prosthetic, and Exoskeleton Locomotion","IIS","National Robotics Initiative","01/01/2017","07/17/2017","Aaron Ames","CA","California Institute of Technology","Standard Grant","Radhakisan S. Baheti","08/31/2019","$546,325.00","","ames@caltech.edu","1200 E California Blvd","PASADENA","CA","911250600","6263956219","CSE","8013","092E, 8086","$0.00","There is a pressing need for wearable robots, e.g., prostheses and exoskeletons, which improve the quality of life for individuals with limited mobility - devices that work symbiotically with human users to achieve stable, safe and efficient locomotion.  At present, approximately 4.7 million people in the United States would benefit from an active lower-limb exoskeleton due to the effects of stroke, polio, multiple sclerosis, spinal cord injury, and cerebral palsy, and by 2050 an estimated 1.5 million people in the United States will be living with a major lower-limb amputation.  Yet current wearable robotic devices do not address this growing population's needs since they are bulky, heavy, noisy, and require large batteries for even short duration use, while implementing predominately hierarchical control algorithms.  Impeding innovation in this domain is the expensive and slow traditional design-build-test approach that ignores the tight coupling between hardware specifications and control algorithm performance.  The vision of this work is to provide a methodology---inspired by advancements in robotic locomotion---that allows lower-limb prostheses and exoskeletons to meet real-world requirements through the co-design of the electromechanical and feedback systems.  The transformative nature of this work, therefore, stems from its ability to realize wearable robots that synergize with humans to achieve increased mobility, providing a template for the growing robotic assistive device industry and potentially improving the quality of life of millions.  <br/><br/>To realize the vision of this work, the overarching research goal is to create a new unified control and design framework that will allow for the efficient and stable locomotion of robots, prostheses, and exoskeletons.  A key aspect of this control methodology is the ability to continuously mediate between different objectives enforcing stability and safety in an efficient manner through force-based interactions among (wearable) robotic devices, their environment and the user. The resulting framework will be utilized via control-in-the-loop mechanical design of prostheses and exoskeletons with stringent design requirements, tested experimentally on a novel humanoid robot, and clinically evaluated through human subject trials.  This work is, therefore, guided by the following specific goals:  (1) develop a unified online optimization-based control framework for (wearable) robotic locomotion that efficiently mediates stability, safety and force constraints, (2) create a feedback loop between formal control synthesis and the mechanical design of wearable robots that satisfy stringent performance requirements,  (3) accelerate clinical testing by translating controllers formally and experimentally from bipedal humanoid robots to prostheses and exoskeletons.  As a result of these research goals, this work has the potential to create the next generation of robotic systems that enable stable, safe and efficient human mobility."
"1139148","Collaborative Research: Socially Assistive Robots","IIS","INFORMATION TECHNOLOGY RESEARC, Cyber-Human Systems (CHS), ROBUST INTELLIGENCE, EXPERIMENTAL EXPEDITIONS","04/01/2012","09/21/2015","Maja Mataric","CA","University of Southern California","Continuing grant","Ephraim P. Glinert","03/31/2019","$2,583,000.00","Fei Sha, Gisele Ragusa, Donna Spruijt-Metz","mataric@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","1640, 7367, 7495, 7723","1640, 7367, 7723, 9251","$0.00","Socially Assistive Robots<br/>Lead PI/Institution: Brian Scassellati, Yale University<br/>This Expedition will develop the fundamental computational techniques that will enable the design, implementation, and evaluation of robots that encourage social, emotional, and cognitive growth in children, including those with social or cognitive deficits.  The need for this technology is driven by critical societal problems that require sustained, personalized support that supplements the efforts of educators, parents, and clinicians.   For example, clinicians and families struggle to provide individualized educational services to children with social and cognitive deficits, whose numbers have quadrupled in the US in the last decade alone.  In many schools, educators struggle to provide language instruction for children raised in homes where a language other than English is spoken (over 20%), the fastest-growing segment of the school-age population.  This Expedition aims to support the individual needs of these children with socially assistive robots that help to guide the children toward long-term behavioral goals, that are customized to the particular needs of each child, and that develop and change as the child does.  <br/>To achieve this vision, this Expedition will advance the state-of-the-art in socially assistive human-robot interaction from short-term interactions in structured environments to long-term interactions that are adaptive, engaging, and effective. This progress will require transformative computing research in three broad and naturally interrelated research areas. First, the Expedition will develop computational models of the dynamics of social interaction, so that robots can automatically detect, analyze, and influence agency, intention, and other social interaction primitives in dynamic environments. Second, the Expedition will develop machine learning algorithms that adapt and personalize interactions to individual physical, social, and cognitive differences, enabling robots to teach and shape behavior in ways that are tailored to the needs, preferences, and capabilities of each individual. Third, the Expedition will develop systems that guide children toward specific learning goals over periods of weeks and months, allowing for truly long-term guidance and support. Research in these three areas will be integrated into socially assistive robots that are deployed in schools and homes for durations of up to one year.  <br/>This Expedition has the potential to substantially impact the effectiveness of education and healthcare for children, and the technological tools developed will serve as the basis for enhancing the lives of children and other groups that require specialized support and intervention. The proposed computing research is tied to a comprehensive student training program, bringing a compelling, engaging, and grounded STEM experience to K-12 students through in-school and after-school activities. It also establishes an annual training summit to provide undergraduates with the multi-disciplinary background to engage in this promising research area in graduate school. Finally, by establishing a brand name for socially assistive robotics, this effort will create a central authority for the distribution of high-quality, peer-reviewed information, providing a coherent focal point for enhancing outreach and education.<br/>For more information visit www.yale.edu/SAR"
"1717066","RI: Small: Optical Skin For Robots: Tactile Sensing and Whole Body Vision","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","08/01/2017","07/25/2017","Christopher Atkeson","PA","Carnegie-Mellon University","Standard Grant","James Donlon","07/31/2020","$440,000.00","Akihiko Yamaguchi","cga@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495, 8013","7495, 7923","$0.00","This project will enable robots to feel what they touch. The key idea<br/>is to put cameras inside the body of the robot, looking outward at the<br/>robot skin as it deforms, and also through the robot skin to see nearby objects as they are grasped or avoided.  This approach addresses several challenges: 1) achieving close to human resolution (a million biological sensors) using millions of pixels, 2) reducing occlusion during grasping and manipulation, and detecting obstacles before impact, and 3) protecting expensive electronics and wiring while allowing replacement of worn out or damaged inexpensive skin. Humans replace the outer layer of our skin every month.  One theory as to why current robots are so clumsy is that they have little or no feeling in their skin.  Robots that can feel when they touch will make better servants and be more useful, especially when taking care of older adults and others needing help walking, dressing, cleaning, or feeding. A soft touch is needed in many tasks in the home and workplace. Teaching robots to do new tasks, and robot learning,<br/>will be much easier if robots can feel what they are doing. Robots will also be safer, and safer to work with, if they can feel accidental contact or the size of forces they are applying. Possible applications of this approach include aware furniture and car interiors that feel what a human is doing or wants to do, aware<br/>clothes, aware tools, and aware floors, walls, and ceilings. Optical skin-based sensing is a practical, affordable, manufacturable, and maintainable approach to sensing for touching and helping people.<br/><br/>Technical goals for the project include first building and then installing on a robot a network of about 100 off-the-shelf small cameras (less than 1 cubic centimeter) that is capable of collecting information, deciding what video streams to pay attention to, and processing the video streams to estimate forces, slip, and object shape. The wiring, solder joints, and other connections in the sensing system don't have to repeatedly deform or face cyclic or variable stresses--major sources of failure. The materials that do deform or are stressed (the outer layer of the skin) can be optimized for sensing, grasping and manipulation, and mechanical robustness, and can be easily and cheaply replaced when worn or damaged.  The researchers will evaluate their work by co-developing an ""optical skin"" for hands and a synergistic soft hand. A transformative idea is to aggressively distribute high resolution imaging over the entire robot body. This reduces occlusion, a major issue in perception for manipulation. Given the low cost of imaging sensors, there is no longer a need to restrict optical sensing to infrared range finders (single pixel depth<br/>cameras), line cameras, or low resolution area cameras."
"1527113","NRI: Collaborative Research: Targeted Observation of Severe Local Storms Using Aerial Robots","IIS","National Robotics Initiative","01/01/2016","08/13/2015","Adam Houston","NE","University of Nebraska-Lincoln","Standard Grant","Ralph Wachter","12/31/2018","$425,652.00","","ahouston2@unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","CSE","8013","8086, 9150","$0.00","This project addresses the development of self-deploying aerial robotic systems that will enable new in-situ atmospheric science applications. Fixed-wing aerial robotic technology has advanced to the point where platforms fly persistent sampling missions far from remote operators. Likewise, complex atmospheric phenomena can be simulated in near real-time with increasing levels of fidelity. Furthermore, cloud computing technology enables distributed computation on large, dynamic data sets. Combining autonomous airborne sensors with environmental models dispersed over multiple communication and computation channels enables the collection of information essential for examining the fundamental behavior of atmospheric phenomena. The aerial robotic system proposed here will close significant capability gaps in conventional platform?s abilities to collect the data necessary to answer a wide range of scientific questions. The motivating application for this work is improvement in the accuracy and lead-time of tornado warnings.<br/><br/>The proposed project draws on techniques in the areas of robotics, unmanned systems, networked control, wireless communication, active sensing, and atmospheric science to realize the vision of bringing cloud robotics to the clouds. The autonomous self-deploying aerial robotic systems is comprised of multiple robotic sensors and distributed computing nodes including: multiple fixed-wing unmanned aircraft, deployable Lagrangian drifters, mobile Doppler radar, mobile command and control stations, distributed computation nodes in the field and in the lab, a net-centric middleware connecting the dispersed elements, and an autonomous decision-making architecture that closes the loop between sensing in the field and new online numerical weather prediction tools."
"1734501","NRI: INT: COLLAB: Accelerating Large-Scale Adoption of Robotic Lower-Limb Prostheses through Personalized Prosthesis Controller Adaptation","ECCS","National Robotics Initiative","09/01/2017","09/01/2017","Xiangrong Shen","AL","University of Alabama Tuscaloosa","Standard Grant","Radhakisan S. Baheti","08/31/2021","$899,799.00","Edward Sazonov","xshen@eng.ua.edu","801 University Blvd.","Tuscaloosa","AL","354870005","2053485152","ENG","8013","8013, 8086, 9150","$0.00","Experiencing a lower limb amputation is a life-changing event.  A person with lower-limb amputation relies heavily on a leg prosthesis to support himself/herself and stay mobile.  However, most leg prostheses in current use are unpowered, which can cause great inconvenience.  For example, these unpowered prostheses cannot propel the amputee users forward in walking, and cannot push them up while standing up or climbing stairs.  With the advances in medical robotic technologies, powered robotic leg prostheses are starting to become more common.  These powered prostheses can help amputees to walk more easily and naturally, and also provide power to support activities previously unattainable or extremely difficult with existing unpowered prostheses (such as standing up and stair climbing).  On the other hand, these robotic prostheses are much more complex than the existing unpowered prostheses, so tuning such a prosthesis to fit an individual user is very challenging and time-consuming, requiring numerous office visits with a clinician over a long period of time.  This is one of the main reasons why powered leg prostheses have not gained extensive use among the amputee users.<br/><br/>In this project, the research team will help to solve this problem by developing a new method to automate the prosthesis tuning process.  The main idea is to use a pendant-like wearable sensor to measure upper body motion, which provides rich information about how well the prosthesis is being controlled to help the user to walk and perform other basic tasks of daily life.  The new method will use such information and gradually tune the controller parameters over time without the need for constant clinical supervision.  To develop this method, the researchers will study how an experienced prosthetist tunes the prosthesis parameters and develop an algorithm to mimic this process.  Furthermore, the upper body motion will be used to infer the amputee user's intention more precisely, so the prosthesis can reliably understand what the user intends to do even if he/she changes the motion pattern while learning to use the robotic prosthesis.<br/><br/>By conducting research in this project, the researchers aim to develop a complete Personalized Prosthesis Controller Adaptation (PPCA) system, which provides personalized controller adaption on two levels: 1) automatic motion controller tuning, and 2) automatic intent recognizer adaptation.  The researchers anticipate to make significant contributions to the related scientific areas, including: 1) a novel wearable sensor that incorporates an inertial measurement unit (IMU), capacitive sensing (for sensor-torso relative motion), and advanced signal processing to provide reliable trunk motion information; 2) fundamental understanding of robotic prosthesis-assisted amputee locomotion, and how human expertise-based tuning optimizes its gait quality; 3) a novel quasi-supervised adaptation of classifier-based intent recognizer, which provides the advantages of the traditional supervised learning while avoiding its major weakness (highly effective in adapting to changing human conditions, and no repeated training sessions or human-conducted data labeling required).  Impacts of this project will also be generated by its various education activities, including the introduction of robotic technologies to the future prosthetic clinicians through a renowned prosthetics and orthotics education program, and the creation of hands-on robotic projects in undergraduate research, which can also serve as important tools in the K-12 outreach to attract children at different age groups to the science and engineering fields."
"1253488","CAREER: Multi-robot cooperative tasking through local coordination design","ECCS","ENERGY,POWER,ADAPTIVE SYS","03/01/2013","01/21/2016","Hai Lin","IN","University of Notre Dame","Standard Grant","Radhakisan S. Baheti","02/28/2019","$400,000.00","","hlin1@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","ENG","7607","092E, 1045","$0.00","The objective of the proposal is to study cooperative tasking among teams of robots under uncertain environments. The research has four main objectives:<br/>- To develop a formal theory of multi-robot cooperative tasking to guarantee given global specifications through explicitly designing local coordination. This study will address key issues such as control architectures, formal representations of tasks, task decomposition, decomposability, and modular tasking. Multidisciplinary approaches combining hybrid systems, supervisory control, and automata theory will be utilized.<br/>- To further extend the theory to handle faults and uncertainty. This study will investigate the fault tolerant cooperative tasking from the perspectives of both passive fault tolerance and active fault tolerant control. The key issues, such as fault detection, characterization of tolerable fault patterns and dynamic reconfiguration, will be addressed from the hybrid and discrete event system theory point of view.<br/>- To implement and demonstrate the design methods on real robotic systems. This empirical study will be conducted on a multi-robot testbed consisting of both autonomous unmanned ground and aerial vehicles. Prototype applications, such as a coordinated pollution detection and containment scenario, will be implemented to illustrate the effectiveness of the proposed approaches.<br/>- To use effective pedagogy in teaching so as to promote learning and foster young talents in engineering.<br/><br/>Intellectual Merits: The proposed research addresses a fundamental question essential for advancements in swarming robotics, namely how to design local coordination among robots so as to achieve certain desired collective behaviors. This project seeks to develop and demonstrate a formal design theory for multi-robot cooperative tasking based on a variety of models and approaches from disciplines like control, computer sciences and robotics. The proposed theory will guarantee a given global performance from a team of swarming robots through designing their local coordination rules and control laws. Thus, the proposed method is of a top-down and correct-by-design nature. It therefore complements well the prevailing bottom-up design practices in swarming robotics, where the local interactions are usually predefined heuristically with inspirations from natural social behaviors.<br/><br/>Broader Impacts: The project has potential to provide a new perspective in tackling the complexity of large-scale distributed dynamical systems, such as sensor actuator networks, power grids and transportation systems. The study will help to advance our understanding of the relationship between emergent behaviors from a complex engineered system and local interactions among its distributed dynamical components. This understanding is critical to building more reliable and efficient future engineered systems. In particular, the theoretical and practical studies in this project may help swarming robotics to see more real applications, such as coordinated environment monitoring, emergency response, and law enforcement. Furthermore, undergraduate and graduate students will be engaged to support the project's testbed and algorithm developments."
"1752575","CAREER: Robots for Everyone, Everywhere","ECCS","ENERGY,POWER,ADAPTIVE SYS","02/15/2018","01/25/2018","Ankur Mehta","CA","University of California-Los Angeles","Standard Grant","Anil Pahwa","01/31/2023","$500,001.00","","mehtank@ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","ENG","7607","1045, 155E","$0.00","The everyday world is pervaded by computational devices laptops, smart phones, and many other personal and household electronic devices make it increasingly easier to find solutions to any computational problem one may have.  However when it comes to physical problems in the real world, personal technology lags far behind: typical users often have minimal to no interaction with robots in daily life.  The research in this project aims to address unmet needs, creating the technology necessary to make robotics as ubiquitous as computing is today; by democratizing access to robot creation reducing barriers to entry we can advance technology in developing fields, bring opportunities for technical advancement to under-served communities, and excite and encourage students to further their education throughout the country and the world.  The project will result in creation of user-friendly tools that allow anyone with any background or expertise to design custom, personalized robots. The research will include development of new fabrication processes that enable the on-demand fabrication of the designed robots. Also, new algorithms and frameworks will be investigated for expanding autonomous control of distributed networks of these devices.  The  goal of the project is for everyone to eventually be able to say, for any personal physical task that needs to be solved, ""there's a robot for that.""<br/><br/>The proposed research plan will address theory and systems issues under the three parallel thrusts of design, fabrication, and control for pervasive personal robots.  Ubiquitous cyber-physical systems must deliver uniquely specified functionality, and so this program will investigate design automation algorithms that generate manufacturable specifications from high-level task descriptions provided by inexpert users, feeding back verification and validation results into user-in-the-loop and automated optimization.  These designs must then be realized into integrated electromechanical machines at a personal scale, for which this research will explore rapid manufacturing tools and processes that use robust mechanical materials and integrated electromechanical metamaterials for subtractive manufacturing and develop discrete microfabricated active elements for additive manufacturing.  Finally, these robots must be controlled; this program will investigate universal communications and control subtasks at an integrated system level, using the intended ubiquity of personal robots to develop algorithms and protocols for distributed localization, communication-aware motion planning, and mobility-enhanced networking."
"1733812","AiTF: Collaborative Research: Distributed and Stochastic Algorithms for Active Matter: Theory and Practice","CCF","Algorithms in the Field, ALGORITHMIC FOUNDATIONS","01/01/2018","08/30/2017","Dana Randall","GA","Georgia Tech Research Corporation","Standard Grant","Rahul Shah","12/31/2020","$408,000.00","Daniel Goldman","randall@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7239, 7796","7934, 9102, 9251","$0.00","Swarm robotics explores how groups of robots can work towards a singular goal, which is typically achieved by equipping each robot with sensory capabilities, basic computing power, and movement. The sensors detect and use information about the environment to decide on the next action. Swarm robotics has made many advances in recent years, but is still in its infancy. This project proposes to explore swarm robotics systems in a non-standard way as  physical systems. The PIs take a ""task-oriented"" approach to develop the distributed algorithmic rules that the robots will run (at the microscopic level) in order to converge to the desired collective behavior (at the macroscopic level).  This will provide understanding of the minimal requirements for individuals to accomplish the desired behavior, for both algorithmic and physical realizations, and will provide a more principled approach for studying swarm robotics. The robots envisioned are small in scale, ranging in size from millimeters to centimeters, so that when deployed in dense environments, they will behave as programmable active matter.<br/><br/>The PIs have strong records for interdisciplinary research, including initiating interdisciplinary areas (e.g., robo-physics, self-organizing particle systems, and the fusion of statistical physics and randomized algorithms). They have a strong commitment toward supporting minorities, women, and undergrad research (e.g., through NSF REUs, including through this project, NSF S-STEM programs at ASU; ADVANCE and S.U.R.E. programs at Georgia Tech).  Any breakthrough in this combination of swarm and active matter systems will require employing analyses and techniques from stochastic systems, condensed matter physics, swarm systems, robotics, and distributed algorithms to understand and achieve the desired group dynamics, and hence will bring together and educate researchers from different disciplines and specialties.  New research approaches and findings will be incorporated into multiple graduate courses and workshops will provide tutorials for bridging multiple disciplines, making material accessible to young researchers and helping to widely disseminate results. Findings (including open source code) will be published in the various disciplines, and will be be made available on our web pages and ArXiv.   <br/> <br/>The project explores the fundamentals of swarm robotics from a physics standpoint, by viewing the ensemble as active matter composed of programmable elements at the micro-level.  The project will follow a (macro-)task oriented approach, and design a distributed stochastic algorithmic framework to design and evaluate algorithms at the micro-level that will yield the targeted emergent macroscopic behavior.  The emergent behaviors it addresses include compression (maintaining coherence of a connected community while minimizing perimeter), bridging (connecting two or more locations in the most efficient manner), alignment (determining an agreed upon direction of orientation), jamming (obstruction of movement by increased collective flow), and locomotion (collectively moving while maintaining cohesiveness). Many of these have interesting converse problems which are also equally worthwhile, such as exploration (maintaining a connected population, but exploring maximal area) and non-alignment (representing a disordered ensemble). In some cases the collective behavior acts like a physical system changing between a liquid (disordered) and a solid (ordered) state, as determined by phase transitions in the systems. The project will explore stochastic and distributed algorithms for rigorously achieving these goals."
"1446434","CPS: Synergy: Collaborative Research: Designing semi-autonomous networks of miniature robots for inspection of bridges and other large infrastructures","ECCS","CYBER-PHYSICAL SYSTEMS (CPS)","11/01/2014","08/19/2014","Mehdi Khandani","MD","Resensys, LLC","Standard Grant","Radhakisan S. Baheti","10/31/2018","$150,000.00","","mehdi@resensys.com","387 Technology Dr.","College Park","MD","207420001","3013953892","ENG","7918","7918, 8235","$0.00","Designing semi-autonomous networks of miniature robots for inspection of bridges and other large civil infrastructure<br/><br/>According to the U.S. Department of Transportation, the United States has 605102 bridges of which 64% are 30 years or older and 11% are structurally deficient. Visual inspection is a standard procedure to identify structural flaws and possibly predict the imminent collapse of a bridge and determine effective precautionary measures and repairs. Experts who carry out this difficult task must travel to the location of the bridge and spend many hours assessing the integrity of the structure.  <br/><br/>The proposal is to establish (i) new design and performance analysis principles and (ii) technologies for creating a self-organizing network of small robots to aid visual inspection of bridges and other large civilian infrastructure. The main idea is to use such a network to aid the experts in remotely and routinely inspecting complex structures, such as the typical girder assemblage that supports the decks of a suspension bridge. The robots will use wireless information exchange to autonomously coordinate and cooperate in the inspection of pre-specified portions of a bridge. At the end of the task, or whenever possible, they will report images as well as other key measurements back to the experts for further evaluation. <br/><br/>Common systems to aid visual inspection rely either on stationary cameras with restricted field of view, or tethered ground vehicles. Unmanned aerial vehicles cannot access constricted spaces and must be tethered due to power requirements and the need for uninterrupted communication to support the continual safety critical supervision by one or more operators.  In contrast, the system proposed here would be able to access tight spaces, operate under any weather, and execute tasks autonomously over long periods of time. <br/><br/>The fact that the proposed framework allows remote expert supervision will reduce cost and time between inspections. The added flexibility as well as the increased regularity and longevity of the deployments will improve the detection and diagnosis of problems, which will increase safety and support effective preventive maintenance. <br/><br/>This project will be carried out by a multidisciplinary team specialized in diverse areas of cyber-physical systems and robotics, such as locomotion, network science, modeling, control systems, hardware sensor design and optimization. It involves collaboration between faculty from the University of Maryland (UMD) and Resensys, which specializes in remote bridge monitoring. The proposed system will be tested in collaboration with the Maryland State Highway Administration, which will also provide feedback and expertise throughout the project.<br/><br/>This project includes concrete plans to involve undergraduate students throughout its duration. The investigators, who have an established record of STEM outreach and education, will also leverage on exiting programs and resources at the Maryland Robotics Center to support this initiative and carry out outreach activities. In order to make student participation more productive and educational, the structure of the proposed system conforms to a hardware architecture adopted at UMD and many other schools for the teaching of undergraduate courses relevant to cyber-physical systems and robotics. <br/><br/>This grant will support research on fundamental principles and design of robotic and cyber-physical systems. It will focus on algorithm design for control and coordination, network science, performance evaluation, microfabrication and system integration to address the following challenges: (i) Devise new locomotion and adhesion principles to support mobility within steel and concrete girder structures. (ii) Investigate the design of location estimators, omniscience and coordination algorithms that are provably optimal, subject to power and computational constraints. (iii) Methods to design and analyze the performance of energy-efficient communication protocols to support robot coordination and localization in the presence of the severe propagation barriers caused by metal and concrete structures of a bridge."
"1815930","CAREER: Solar-Powered Unmanned Aerial and Ground Vehicles for Long-Term Operation in Dynamic Environments","ECCS","ENERGY,POWER,ADAPTIVE SYS, EPSCoR Co-Funding","10/25/2017","01/11/2018","Ran Dai","OH","Ohio State University","Standard Grant","Radhakisan S. Baheti","02/29/2020","$327,430.00","","dai.490@osu.edu","Office of Sponsored Programs","Columbus","OH","432101016","6146888735","ENG","7607, 9150","092E, 1045, 9150","$0.00","Current technology in solar-powered robotic systems is limited to homogeneous robots that act independently within the constraints of their design and are subject to power limitations and inability to intelligently adapt to changeable situations. These limitations prevent the widespread adoption of solar robots in applications. This career project proposes a transformative approach to the development of next generation solar-powered robotic systems that overcome these limitations. An innovative strategy will integrate heterogeneous aerial and ground vehicle operations in order to accomplish long-duration high-efficiency missions, improve adaptability to dynamic environments, and enable the effective use of environmental but variable energy sources. Results of this work will enable societally-important technological advancements in environmental monitoring, search and rescue, surveillance, and agriculture, which will contribute to U.S. economic vitality, public health, and security. This research also provides necessary insights into general robotics applications pertaining to alleviating the dependence of robotic missions on non-renewable energy sources during long-duration operations. The use and application of solar-powered robots increases the demand for high-quality photovoltaic products, which will subsequently boost development in related technologies. This work will incorporate a hierarchy of educational activities appropriate to different groups of students, from the general public to more advanced scholars. These activities include a synergy-based education platform, industry-oriented training projects, and educational open-source software for a solar robot. In collaboration with the Experimental Program to Stimulate Competitive Research team at Iowa State University, the PI will provide public visitors, especially community college and K-12 students, with access to robotic systems.<br/><br/>The research will contribute to a novel paradigm enabling experimentation on energy-aware long-duration autonomous multi-platform systems. Establishing advanced autonomy in solar-powered robotic systems will be accomplished by leveraging interdisciplinary methodologies in the fields of dynamic networks, distributed control, and convex optimization, and by developing novel strategies for coordinating and controlling heterogeneous aerial and ground vehicles toward mission accomplishment. These multidisciplinary methodologies will be consistently integrated to yield a new paradigm for modeling, optimization, and distributed control of solar-powered robotic systems. The project will systematically infuse solar energy into a demanding technological area, namely robotic systems, with specific applications to wide-area long-duration operations. The proposed optimization and control schemes will address fundamental problems of multi-agent dynamical systems whose performance can be improved by cooperation among internal agents."
"1555822","SBIR Phase II:  Object Pose Estimation System for Pick and Place Robots","IIP","SMALL BUSINESS PHASE II","05/01/2016","11/07/2017","Nicholas Wettels","CA","Perception Robotics","Standard Grant","Muralidharan S. Nair","10/31/2018","$915,960.00","","nwettels@perceptionrobotics.com","525 S. Hewitt St","Los Angeles","CA","900132215","2134770710","ENG","5373","169E, 5373, 6840, 7744, 8035, 8240, 9139, 9261, HPCC","$0.00","The broader impact/commercial potential of this project is improvement in cost-efficiency, energy-efficiency, and quality in manufacturing automation, increasing worker productivity and reducing repetitive motion injuries. This integrated visual-tactile system will be 3-4 times more inexpensive ($20,000 purchase cost vs. existing $65,000-80,000 vision system), improve the speed and accuracy of current robotic handling systems, and facilitate the automation of repetitive, injury-prone manual tasks. By enabling new robotic applications and increasing productivity in current automation, this solution will help the U.S. maintain a competitive domestic manufacturing sector.  In 2009 there were 36,190 logged repetitive motion injuries in the U.S.; the median missed work time from these injuries was 21 days (U.S. Bureau of Labor Statistics).  This innovative solution will facilitate the automation of repetitive, injury-prone manual tasks and greatly improve the speed, accuracy, and cost-efficiency of current robotic handling systems.  The immediate commercial applications are in industrial robotics, specifically robotics in agile manufacturing. In the long term, the technology will be applied in personal, healthcare, and military robots. The current market potential for tactile sensors for industrial robots is estimated as $576 million - $1.15 billion and expected to more than double by 2025.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project will result in a combined visual-tactile system that will give robots an integrated sense of touch and vision, much like the hand-eye coordination of humans. It incorporates a technically novel compliant tactile sensing solution?a rubber ?skin? that can be molded into any form factor and is inexpensive and durable.  This advanced skin technology can resolve object shape, contact/slip events, and forces of contacted objects.  It will uniquely fuse visual and tactile information for object handling and pose estimation resulting in flexible robotic system that handles objects more like humans do.  This approach addresses key weaknesses in vision-based robotic manufacturing, such as occlusion and dislodging when parts are grasped.  Current industrial robots are restricted in their ability to handle small, irregularly shaped, soft, or fragile parts. Existing solutions rely on expensive and complex 3D-vision systems or repetitive manual labor. This solution is two-fold: (1) A new flexible tactile sensor that can be tailored to a wide variety of form factors; (2) Software to fuse the tactile data with a vision system to estimate pose of objects in pick-and-place tasks."
"1750483","CAREER:Designing Robots that Learn: Closing the Gap Between Machine Learning and Engineering","IIS","ROBUST INTELLIGENCE","06/01/2018","03/22/2018","Byron Boots","GA","Georgia Tech Research Corporation","Continuing grant","Reid Simmons","05/31/2023","$87,583.00","","bboots@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","1045, 7495","$0.00","Robotics has enjoyed great success when a robot's interaction with its environment can be precisely defined. However, if the models that robots use to predict, plan, and control their behaviors are inaccurate, it can lead to suboptimal or even dangerous behaviors.  Unfortunately, as robots and their environments become more complex, it is increasingly difficult to accurately specify robot behavior.  An alternate approach is to learn the models from experience, but most such approaches need large amounts of data, in a variety of situations, which is practically infeasible to collect.  This project attempts to combine the strengths of hand-crafted, physics-based models and machine learning algorithms to tackle such problems.  Such a combined approach will better position engineers to design robots that can operate in less-structured real-world environments. The project also addresses educational goals related to this vision by providing cross-disciplinary experiences that combine machine learning and robotics. <br/><br/>The goal of this project is to develop new theory and algorithms that close the gap between machine learning and engineering approaches to robotics, which have traditionally been studied separately. While engineering uses physics knowledge to provide interpretability, transparency, and guarantees about the reliability and robustness of engineered systems, machine learning studies data and information, and provides guarantees that focus on the expressivity of models, computational cost, and sample efficiency of learning algorithms.  The current project consists of three research initiatives to bring these disciplines closer together. The first aims to develop new semi-parametric models for robotics that combine parametric physical models and non-parametric statistical models. The second will tackle the problem of learning state space models from data when given incomplete information about dynamics and state. The third will investigate how structural knowledge from engineering can be used to constrain the hypothesis space of nonparametric learning algorithms and deep neural network models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1828170","Doctoral Consortium at the 2018 International Conference on Robotics and Automation (ICRA)","IIS","Dynamics, Control and System D, National Robotics Initiative","04/01/2018","03/21/2018","Matthew Walter","IL","Toyota Technological Institute at Chicago","Standard Grant","Reid Simmons","03/31/2019","$35,000.00","","mwalter@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372803","7738340409","CSE","7569, 8013","030E, 034E, 7556, 8024, 8086","$0.00","This grant provides funds to partially support U.S. Ph.D. students working in robotics the opportunity to attend a Doctoral Consortium at the International Conference on Robotics and Automation (ICRA), one of the major international robotics conferences. The conference, to be held May 21-25, 2018 in Brisbane, Australia, attracts an international audience that includes academics, industry, entrepreneurs, and funding agency leaders.<br/><br/>Participation in the Doctoral Consortium will enable the students to share their knowledge and interact with each other and with senior researchers outside their own institutions, to learn about different sub-fields within robotics, to understand industry needs, and to become apprised of new technology that will be demonstrated by vendors. The Doctoral Consortium includes an afternoon of activities, including oral and poster presentations by students, focused breakout sessions, a keynote address, and two panels led by researchers in academia and industry.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1560219","REU Site: Interdisciplinary Research Experiences in Robotics for Assistive Technology","IIS","RSCH EXPER FOR UNDERGRAD SITES","03/15/2016","02/20/2018","Cheng Liu","WI","University of Wisconsin-Stout","Standard Grant","Wendy Nilsen","02/28/2019","$230,400.00","Cheng Liu, Devin Berg, Catherine Anderson","shiw@uwstout.edu","PO Box 790","Menomonie","WI","547510790","7152321123","CSE","1139","9250","$0.00","REU Site: Interdisciplinary Research Experiences in Robotics for Assistive Technology<br/><br/>This Research Experiences for Undergraduates (REU) Site award funds a new REU site focused on Robotics in Assistive Technology at the University of Wisconsin-Stout. Robotics has potential appeal across a wide range of disciplines, especially as robots become increasingly integrated into society, performing useful tasks in the home and elsewhere. The REU site will provide 8-week interdisciplinary research experiences in robotics targeting first generation, underrepresented students, and students from institutions with limited research opportunities. Students and faculty will participate in professional development, interdisciplinary data sharing, and research activities designed to empower and prepare students for advanced degrees and careers in engineering. This project will make a meaningful impact in how we apply robots in enhancing our quality of life. It is imperative that we provide a larger pool of individuals trained in the field of robotics to address the increasing number of national needs. <br/><br/>This is a new REU proposal in the area of assistive robotics. The proposed research projects for participants focus on several areas such as dynamic model design, control, human-machine communication, teleoperation, and wireless control. The proposed comprehensive three stage program touches all components of an REU site from introductory workshops for the basic concepts to the preparation of their final research report that could lead to a publication. The PI is an expert in the area of assistive technologies and the other faculty members are experts in the areas of rehabilitation, robotics, and bio-sensing. This REU site provides modern facilities and professional mentors to guide undergraduates in explorations of real-world problems related to robotics in assistive technology. Students will learn how to use current tools and techniques to solve those problems through exciting research projects across a wide range of research topics. The goal of the site is to increase participation of first generation, underrepresented minorities, women and persons with disabilities, and provide opportunities for students from schools with limited research opportunities. The students will participate in research and professional development activities all designed to achieve the goals of retaining and graduating undergraduate students in engineering and increasing recruitment of students into graduate programs."
"1149965","CAREER: Toward Automating Surgical Tasks","IIS","COLLABORATIVE RESEARCH, IIS SPECIAL PROJECTS, ROBUST INTELLIGENCE","03/01/2012","12/24/2015","Ron Alterovitz","NC","University of North Carolina at Chapel Hill","Continuing grant","Reid Simmons","02/28/2019","$499,542.00","","ron@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7298, 7484, 7495","1045, 5936, 7484, 8086","$0.00","This project, developing a new motion planning framework for medical robots that combines automatic planning algorithms, robot control, and human oversight to enable new and safer robotic procedures that are beyond current clinical capabilities, will increase the autonomy of surgical robotic systems. This framework will result in improved speed, accuracy, and precision of existing procedures and enable entirely new classes of procedures that require dexterity and control beyond the capability of a human operator. <br/><br/>The funding of this proposed work will introduce and evaluate a new motion planning framework that simultaneously addresses the challenges of deformations, uncertainty, and optimality that arise in medical applications. The research will combine ideas from multiple areas of computer science and engineering, including robotics, computer graphics, finite element methods, optimization theory, Markov decision processes, stochastic modeling, and learning from demonstrations. Expected scientific contributions include new motion planning algorithms that efficiently integrate physically-based simulation, motion planning under uncertainty, and sensor placement, as well as new approaches to integrate user input into feedback-based motion planning. In the long term, these contributions may lead to new avenues of research at the intersection of motion planning, anatomy and biomechanical modeling, learning from demonstrations, and medical robotics.<br/><br/>Broader Impacts: A motion planning framework for medical robots will improve patient care and the resulting increased autonomy will reduce surgical errors -- which currently contribute to 1 in 10 post-surgical deaths -- by enabling physicians to focus on high-level tasks rather than low-level motion control. The application of this framework to prostate interventions, lung biopsies, and neurosurgery could affect hundreds of thousands of people annually and have broad societal impact. The ability of computer science to improve healthcare may attract new students to computer science who might previously not have been interested in the field, particularly women and underrepresented groups. The PI will develop new outreach activities centered around an interactive game-like simulation of medical procedures that highlights the impact that computer science can have on medicine, create a new undergraduate course for pre-meds to teach future physicians crucial computer science concepts, and revamp the robotics curriculum to create excitement through labs and provide students with the skills necessary to pursue a career in America's growing healthcare and service robotics industries."
"1638070","NRI: Liquid Handling Robots - A New Paradigm for STEM Education","IIS","ITEST, National Robotics Initiative","10/01/2016","12/22/2017","Hans Riedel-Kruse","CA","Stanford University","Standard Grant","David Haury","09/30/2019","$892,230.00","Mark Miller, Paulo Blikstein","ingmar@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7227, 8013","8086, 9251","$0.00","This National Robotics Initiative project will test a series of liquid handling robots in school biology and chemistry classes to determine the range of learning opportunities that can be supported through the instructional use of collaborative robots.  Low-cost robots using the Lego Mindstorms platform will be used to implement classroom activities ranging from artistic expression using colorful arrangements of liquids to performing experiments using dilution series, density gradients, and spectral measurements. The aim is to make biotechnology more tangible and relevant to students while supporting interdisciplinary learning as recommended by the Next Generation Science Standards (NGSS). This innovative approach to engaging students in biology and chemistry will be tested with teachers and students in grades 6-12, with a range of user studies being employed to examine learning outcomes and guide the development process.  The goal is to integrate liquid handling into educational robotics to enhance current science curricula by enabling deeper inquiry, more variety in learning experiences, and increased attention to interdisciplinary and project-based education.<br/><br/>The research of this project will focus on two themes:  students' sense making as they engage in inquiry activities using the platform, and the pedagogical and infrastructural support needed for sustainable deployment and implementation.  Multimodal data collected from students running experiments will be combined with traditional qualitative and quantitative methods to answer three primary questions related to the two research themes: 1) How effectively does the system capture the practices and inquiry activities of real scientists using similar tools?  2) How do the affordances identified by the first question map onto the learning goals of engaging in extended inquiry cycles within the context of limited amounts of time available to 6-12 grade science teachers? And 3) What implementation challenges are associated with our proposed curricular distribution model which relies on software and instructions being downloaded and fabricated in local Makerspaces or Lego/Arduino kits being used in schools?  The research plan for the project will progress over three years from Microgenetic design and testing during the first year to controlled study of in-class effectiveness during year 2.  In the final year of the project, teacher-led in-class effectiveness will be examined."
"1637759","NRI: Collaborative Research: Software Framework for Research in Semi-Autonomous Teleoperation","IIS","National Robotics Initiative","10/01/2016","08/18/2016","Gregory Fischer","MA","Worcester Polytechnic Institute","Standard Grant","Reid Simmons","09/30/2019","$550,157.00","","gfischer@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","8013","8086","$0.00","Telemanipulation systems consist of a human interacting with a mechanical device on the master side to operate a robot at the remote side. They provide natural opportunities for research in intelligent human/robot collaboration, but existing commercial systems, used in areas such as telesurgery, are not intelligent and therefore only replicate the actions of the human operator. These systems are also proprietary, expensive, and not available for modification by researchers. The goal of this NRI project is to provide an open-source software infrastructure that is designed to work with a broad range of hardware and simulated devices to enable a larger community to pursue research and education in intelligent telemanipulation at a lower cost.<br/><br/>The increasing pace of robotics research can be attributed, at least in part, to the increasing availability of software infrastructure, such as Robot Operating System (ROS), and open hardware platforms. This NRI project focuses on providing a software infrastructure for research in intelligent telemanipulation, leveraging infrastructure developed for the Raven II robot and the da Vinci Research Kit (dVRK) and continuing to extend it to other systems, including simulated robots. The three main tasks are to: (1) engage the community to guide development, (2) develop and implement a common API for the diverse hardware platforms, and (3) provide a set of high-level, platform-independent software modules. The goal is to support research towards semi-autonomous telerobotic systems that can more effectively combine the knowledge, reasoning, and decision-making capabilities of a human with the sensing and manipulation capabilities of a robot."
"1638072","NRI: Collaborative Research: Learning Adaptive Representations for Robust Mobile Robot Navigation from Multi-Modal Interactions","IIS","National Robotics Initiative","10/01/2016","08/10/2016","Matthew Walter","IL","Toyota Technological Institute at Chicago","Standard Grant","Reid Simmons","09/30/2019","$332,728.00","","mwalter@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372803","7738340409","CSE","8013","8086","$0.00","Most existing autonomous systems reason over flat, task-dependent models of the world that do not scale to large, complex environments. This lack of scalability and generalizability is a significant barrier to the widespread adoption of robots for common tasks. This research will advance the state-of-the-art in robot perception, natural language understanding, and learning to develop new models and algorithms that significantly improve the scalability and efficiency of mapping and motion planning in large, complex environments. These contributions will impact the next generation of autonomous systems that interact with humans in many domains, including manufacturing, healthcare, and exploration.  Outcomes will include the release of open source software and data, workshops, K-12 STEM outreach efforts, and undergraduate and graduate education in the unique, multidisciplinary fields of perception, natural language understanding, and motion planning.<br/><br/>As robots perform a wider variety of tasks within increasingly complex environments, their ability to learn and reason over expressive models of their environment becomes critical. The goal of this research is to develop models and algorithms for learning adaptive, hierarchical environment representations that afford efficient planning for mobility tasks. These representations will take the form of probabilistic models that capture the rich spatial-semantic properties of the robot's environment and are factorable to enable scalable inference. This research will develop algorithms that learn and adapt these representations by fusing knowledge conveyed through human-provided natural language utterances with information extracted from the robot's multimodal sensor streams. This research will develop algorithms that then reason over the complexity of these models in the context of the inferred task, thereby identifying simplifications that enable more efficient robot motion planning. <br/>"
"1756031","CRII: CHS: Enabling Safe and Adaptive Robot-aided Gait Training through Biomechanical Characterization and Learning from Demonstration","IIS","Cyber-Human Systems (CHS)","09/01/2018","03/16/2018","Wenlong Zhang","AZ","Arizona State University","Standard Grant","Ephraim P. Glinert","08/31/2020","$175,000.00","","Wenlong.Zhang@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7367","7367, 8228","$0.00","The unprecedented growth in the elderly population is generating a high demand for gait rehabilitation due to age-related neurological diseases.  To address this urgent need various assistive robots have been developed to improve gait training outcomes, and impedance control (controlling the force of resistance to external motions that are produced by the environment) has been widely employed in these robots to ensure safe human-robot interaction.  However, it is difficult to personalize the virtual impedance for such robots due to the complex nature of human neurological and musculoskeletal dynamics.  On the other hand, a physical therapist can provide adaptive assistance to a patient at the correct moment in a gait cycle based on real-time sensory feedback and clinical experience.  Inspired by this observation, one could imagine designing an assistive robot control system by learning from therapists' demonstrations, but such a purely data-driven approach could lead to significantly degraded performance with new gait patterns, which creates safety risks for users. This research will develop a hybrid assistive robot control approach, which integrates model-based impedance control with machine learning from therapists' behaviors so that the resultant robot assistance is safe yet adaptive.  Project outcomes will include a novel algorithm framework for physical human-robot collaboration that exhibits both performance guarantees due to the model-based control and intelligent adaptation resulting from robot learning.  The new technology will have a wide range of applications in many other safety-critical human-robot collaboration scenarios, including collaborative manufacturing, (semi) autonomous driving, and service robots.  The broader impacts of the work will be further enhanced by tight integration of the research with educational activities including new modules in existing robotics classes, research opportunities for undergraduate students from underrepresented groups, and internships for local high-school students.<br/>  <br/>The scientific contribution of the work will include: 1) integration of heterogeneous wearable sensor data to build the robot learning model from therapists' demonstrations, and human knee impedance characterization to build the robot impedance control model; 2) a robot planning approach based on a fusion of learning from demonstration and impedance control, with the weights determined by the degree of confidence in the robot learning model; and 3) automatic requests for new demonstration data and incorporation of subject feedback to refine both the robot learning and impedance control models.  Performance of the approach will be assessed in biomechanical simulations, in lab tests with healthy subjects, and in a pilot study with stroke and Parkinson's disease patients.  It is envisioned that project outcomes will make assistive robots highly intelligent so that a therapist could work with multiple patients simultaneously and even remotely, which could significantly reduce both the therapists' labor intensity and cost of rehabilitation training for patients.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637824","NRI: Collaborative Research: Towards Robots with Human Dexterity","IIS","National Robotics Initiative","01/01/2017","08/31/2016","Neville Hogan","MA","Massachusetts Institute of Technology","Standard Grant","Reid Simmons","12/31/2019","$500,000.00","","neville@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","8013","8086, 8089","$0.00","Despite vastly slower ""hardware"" and ""wetware,"" human dexterity vastly out-performs modern robots. This project studies apparently-simple tasks - managing the kinematic constraint on hand motion required to open a door; and dealing with the dynamic complexity of liquid sloshing in a cup of coffee - that profoundly challenge robots but humans perform with ease. The key idea is that humans manage skillful physical interaction with these objects by exploiting clever combinations of primitive dynamic actions that do not require continuous intervention. A novel theory to describe the effectiveness of this approach is developed and tested by experiments with human subjects. The theory is applied to transfer comparable skill to robots, despite manifestly different hardware. If successful, these robots will be more capable, more comprehensible, and more collaborative partners with humans.<br/><br/>The central experimental challenge is to determine the essential strategy underlying humans' remarkable competence in physical interaction tasks. Three hypotheses reflecting major themes in contemporary motor neuroscience are tested: Humans 1) develop models of object dynamics sufficient to pre-compute and execute required hand motions (similar to modern robot programming); 2) choose forces and motions to minimize muscular effort (similar to optimizing efficiency); or 3) exploit dynamic primitives to robustly achieve satisficing (good-enough) performance. The theoretical challenge is to formulate a coherent account combining the information-processing of brains (or computers) with the ""energy-processing"" of physical objects and their interactions. Classical equivalent circuit theory is re-purposed to define a neo-classical equivalent network theory, combining dynamic motion primitives with mechanical impedances (interactive dynamics). Mechanical impedances enjoy a key property, compositionality, that overcomes the curse of dimensionality."
"1637647","NRI: Rethinking Multi-Legged Robots: Passive Terrain Adaptability through Underactuated Mechanisms and Exactly-Constrained Kinematics","IIS","National Robotics Initiative","10/01/2016","08/04/2016","Aaron Dollar","CT","Yale University","Standard Grant","Reid Simmons","09/30/2019","$718,214.00","","aaron.dollar@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","CSE","8013","8086","$0.00","Legged vehicles have long intrigued us with the promise of moving with animal-like agility, gracefully and swiftly going where wheeled vehicles cannot.  Despite numerous successes, however, current legged robots are mostly unable to traverse rough terrain, and are mechanically complex, requiring elaborate hardware and control, and having short operation-times. Work on this project will investigate the development of multi-legged robots that utilize adaptive motors and transmissions, to reduce the complexity and cost, while also allowing the legs to adapt to rough terrain. These legged robot designs will be made freely available through OpenRobotHardware.org, and will be able to be easily and inexpensively fabricated with rapid prototyping techniques.<br/><br/>The project takes a new approach to legged robots by proposing new architectures that reduce over-constraint in the closed kinematic chains with the ground by applying under-actuated mechanisms - equipping robots with legs that passively adapt to large variations in terrain roughness with minimal disturbance forces to the body. As a result of this kind of passive adaptability, the robot is able to find a stable footing on rough terrain without any sensing or planning: the legs simply fall into place. Furthermore, adaptability in the mechanism also enables the forces and torques applied by the legs to the body to be passively regulated so as to minimize disturbances that would tend to destabilize the vehicle or cause it to lose its heading. This ability will drastically simplify the control of legged robot systems, greatly increase power efficiency and their robustness to terrain variations, and decrease production and maintenance costs."
"1830129","Towards Modeling & Simulation-Enabled Design of Intelligent Robots  A Meeting Dedicated to Identifying Opportunities, Summarizing Challenges, and Brainstorming for Impactful Di","IIS","National Robotics Initiative","04/01/2018","03/09/2018","Dan Negrut","WI","University of Wisconsin-Madison","Standard Grant","Reid Simmons","03/31/2019","$29,917.00","","negrut@wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","8013","7556, 8086","$0.00","Robots are becoming increasingly expected to operate in complex, unstructured environments.  To successfully achieve their tasks, they must use models to plan and control their actions.  For reliable performance, these models should adequately capture the types of interactions the robot has with the world.<br/>This workshop brings together researchers in the areas of robotics, modeling and simulation (M&S), and machine learning (ML), to examine the roles that M&S and ML play in robotic planning and control, and how these two different approaches can be combined to produce robust robot behavior. Approximately 35 researchers from academia and industry, from various backgrounds, are invited to participate in open discussion and brainstorming sessions.  <br/>The one-day format, held at the National Institute of Standards and Technology (NIST), includes overview talks and breakout sessions.  The outcome will be a report summarizing the main ideas and themes that emerge from the discussions, with the aim of publishing the results in a robotics journal.<br/><br/><br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637813","NRI: Collaborative Research: Learning Adaptive Representations for Robust Mobile Robot Navigation from Multi-Modal Interactions","IIS","National Robotics Initiative","10/01/2016","08/10/2016","Thomas Howard","NY","University of Rochester","Standard Grant","Reid Simmons","09/30/2019","$289,376.00","","thomas.howard@rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","CSE","8013","8086","$0.00","Most existing autonomous systems reason over flat, task-dependent models of the world that do not scale to large, complex environments. This lack of scalability and generalizability is a significant barrier to the widespread adoption of robots for common tasks. This research will advance the state-of-the-art in robot perception, natural language understanding, and learning to develop new models and algorithms that significantly improve the scalability and efficiency of mapping and motion planning in large, complex environments. These contributions will impact the next generation of autonomous systems that interact with humans in many domains, including manufacturing, healthcare, and exploration. Outcomes will include the release of open source software and data, workshops, K-12 STEM outreach efforts, and undergraduate and graduate education in the unique, multidisciplinary fields of perception, natural language understanding, and motion planning. <br/><br/>As robots perform a wider variety of tasks within increasingly complex environments, their ability to learn and reason over expressive models of their environment becomes critical. The goal of this research is to develop models and algorithms for learning adaptive, hierarchical environment representations that afford efficient planning for mobility tasks. These representations will take the form of probabilistic models that capture the rich spatial-semantic properties of the robot's environment and are factorable to enable scalable inference. This research will develop algorithms that learn and adapt these representations by fusing knowledge conveyed through human-provided natural language utterances with information extracted from the robot's multimodal sensor streams. This research will develop algorithms that then reason over the complexity of these models in the context of the inferred task, thereby identifying simplifications that enable more efficient robot motion planning. <br/>"
"1652083","CAREER:  Towards Autonomously Generating Robot Behavior for Coordination with Humans -- Accounting for Effects on Human Actions","IIS","ROBUST INTELLIGENCE","03/01/2017","02/14/2018","Anca Dragan","CA","University of California-Berkeley","Continuing grant","Reid Simmons","02/28/2022","$168,177.00","","anca@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495","1045, 7495","$0.00","Robots that interact, collaborate, and come in support of people are inevitable, from autonomous cars, to assistive devices, to collaborative industrial arms, to personal robots in the home. Interactions with people should be natural, fluent, and well-coordinated.  The project aims to move from hand-designed strategies for interaction to algorithms that produce such strategies in a generalizable way, using models of human behavior and how a robot?s actions may affect people?s actions and perceptions of the robot.  The project also addresses educational goals that augment this vision: enabling the next generations of students to define and solve robotics and AI problems through a combination of computational and human-centered perspectives.<br/><br/>While robotics algorithms typically reason about the physical state of the world and how the robot can affect it in useful ways, an important criterion when interacting with people is how the actions affect them and their internal state: what they plan to do, what they think the robot will do, how much they trust the robot. The project will address this by developing planning algorithms that incorporate the internal state of the human agent that is not directly observable. Rather than treating the human as a physical (dynamic) obstacle that needs to be avoided, this project proposes a game-theoretic formulation of interaction, and introduces an approximation to it as an underactuated dynamical system: the robot has direct control over its actions, but its actions affect the human's actions, and so the robot indirectly influences what the human does. Preliminary results in a driving domain suggest that this improves robot efficiency and fluency of coordination with people.<br/>"
"1734380","NRI: INT: COLLAB: Development, Deployment and Evaluation of Personalized Learning Companion Robots for Early Literacy and Language Learning","IIS","ITEST, National Robotics Initiative","09/01/2017","08/16/2017","Abeer Alwan","CA","University of California-Los Angeles","Standard Grant","David Haury","08/31/2021","$615,646.00","Alison Bailey","alwan@ee.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","CSE","7227, 8013","8086","$0.00","This National Robotics Initiative project will develop, deploy and evaluate personalized companion robots to assist kindergarten-age children in learning language and vocabulary skills. The aim is to accelerate the impacts of social robots for early education in schools and at home. The four-year project will advance knowledge in three key areas: (1) automatic speech recognition models for young children; (2) multi-modal student assessment algorithms for early language and literacy skills; and (3) personalization of activities, content, and dialogic question generation to boost learning outcomes. The project will generate new insights for how to develop expressive, socially responsive robots that provide more effective, engaging, and empathetic educational experiences for young children. To evaluate the impacts of long-term interactions on educational outcomes, the project team will conduct a 4-month study with Kindergarten classrooms, as well as a 3-month at-home study. The project will engage teachers and parents to develop key guidelines for best practices for use of social robots in classroom and home settings, and participating undergraduate and graduate students will be trained in the multidisciplinary aspects of social robotics, speech recognition and understanding, human participation studies, interactive machine learning for automatic assessment and personalization tools, and early education research. <br/><br/>This research and development project will be implemented in two phases: An initial phase consisting of short pilot deployments to train and continually iterate development of project technologies and systems, followed by longer term deployment of the robot to examine autonomous interactions with social robots in school and home educational settings. During the development stage of individual components (automatic reading and language assessment tools, automatic question-generation algorithm, automatic speech recognition and spoken language understanding system models, and activities with the autonomous social robot learning companion) the project team will collect and analyze data with practical and performance measures, and refine and iterate each component of the system being developed. After development of the individual components, the autonomous social robot storytelling companion will be developed through repeated iterations with children. In the final year of the project, two 4-month studies will be conducted in six Kindergarten classrooms with 15 to 20 students each. This project is expected to result in five key contributions: (1) Development of Automatic Speech Recognition and Spoken Language Understanding systems for young children's speech, (2) Multi-modal automatic assessment algorithms for Kindergarten age children's spoken language and early reading skills; (3) Automatic personalization algorithms for story content customization and dialogic question generation in the context of young children's verbal storytelling; (4) Development of a fully autonomous, collaborative, peer-like social robot system with effective educational activities; and (5) Long-term studies with deployed social robots in schools and homes spanning several months and demonstrating sustained engagement and positive learning outcomes."
"1625364","MRI: Development of a PhenoNet - an Integrated Robotic Network for Field-based Studies of Genotype x Environment Interactions","DBI","MAJOR RESEARCH INSTRUMENTATION","09/15/2016","12/21/2016","Lie Tang","IA","Iowa State University","Standard Grant","Robert Fleischmann","08/31/2019","$873,718.00","Patrick Schnable, Srikant Srinivasan","lietang@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","BIO","1189","9150","$0.00","An award is made to Iowa State University to develop and deploy PhenoNet - an integrated robotic network for field-based studies of genotype crossed with environment (GxE) interactions. The core component of PhenoNet is a set of PhenoBots; lightweight robots that are able to autonomously navigate between crop rows using GPS and local range sensors while employing advanced sensing technologies to phenotype crop plants. The PhenoBots can measure indicators such as stalk size, plant height, leaf angle and tassel/inflorescence properties over time. The robots will be optimized for maize research and can be easily adapted for other row crops. The network (PhenoNet) is a universal platform which enables comprehensive field-based research on genotype and environment interactions. The broader impacts of this project are threefold. First, PhenoNet will have an important impact on society as understanding genome X environment interactions will help address the need for sufficient food, feed, and fiber for the planet's growing population, which is vital in an ever-changing environment. PhenoNet will bring ""big data"" more deeply into agriculture by cementing connections between plant scientists and engineers in their efforts to reach this goal. Second, this project is synergistic with the NSF-NRT project, ""Predictive Phenomics of Plants"", recently awarded to Iowa State University. The research and engineering outlined in this Major Research Instrumentation project will provide an outstanding opportunity for students from engineering disciplines, computer science, statistics, and agronomy to collaborate and engage in state-of-the-art interdisciplinary research. This project will also advance the training of current engineers and plant scientists who are experienced with networking, robotics and agronomy. Third, this project will reach out to underrepresented groups by targeting minority-serving institutions for student recruitment and will work with the Society of Women Engineers and other similar groups in seeking women participants to help meet the NSF-NRT award's efforts to broaden participation. <br/><br/>The PhenoBots are an important and essential advancement in the fields of agriculture and technology because they more efficiently characterize tall plants over time to their maturity. Previous technology and platforms are either incapable of, or are greatly hindered by various constraints. The design improvements of the Phenobots enable the robots to be more robust, stable, lightweight, integrated and economical. This creates a pathway for transformative research as it enables in situ, non-invasive monitoring of the traits of tall crops, like maize, over time. PhenoNet will consist of a network of four PhenoBots, which will be deployed by plant scientists in Iowa, Kansas, Minnesota, Nebraska, and Wisconsin. The data generated from high throughput phenotyping will address whether it is possible to predict the phenotype of a given genotype in a specified environment."
"1637753","NRI: Collaborative Research: Accelerating Robotic Manipulation with Data-Enhanced Contact Mechanics","IIS","National Robotics Initiative","09/01/2016","07/27/2016","Alberto Rodriguez Garcia","MA","Massachusetts Institute of Technology","Standard Grant","Jie Yang","08/31/2019","$430,000.00","","albertor@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","8013","8086","$0.00","Robotic manipulation depends upon mechanical contact between robot and object.  A better understanding of mechanical contact enables a wider range of more flexible manipulation techniques, which in turn enables the applications of greatest societal benefit such as eldercare, disaster response, or surgery.   This project is developing a broader and more accurate understanding of frictional contact, using a fusion of physics and data.  The project combines recent advances in a physics-based understanding of frictional contact with new machine learning techniques applied to a large corpus of experimental data.  One operation of great interest is manipulation of an object held in the robot gripper, even when the gripper is very simple.  Other operations of interest are handling objects in clutter, and manipulation of flexible objects, such as clothing.<br/><br/>The project is attacking several central challenges: modeling frictional contact, modeling deformation, measuring small motions and interaction forces, gathering large amounts of data, and developing techniques for learning in a closed-loop system.  Parametric and semi-parametric models enable the project to apply engineering models enhanced with observation data, for both planning and control.  New machine learning techniques such as predictive state representations (PSRs) enable identification and modeling of previously hidden state, as well as learning in closed-loop systems.  New infrastructure enables gathering of relevant, precise data, on a large scale.  The project is developing and employing a Robotic Manipulation Arena, with a unique combination of manipulation resources and instrumentation to provide high volumes of high quality experimental data.  The primary outcomes are robust and practical contact models, so that robots can work more dexterously and opportunistically."
"1560268","REU Site: Research Opportunities in Bioinspired Robotics","EEC","HUMAN RESOURCES DEVELOPMENT","01/01/2017","09/07/2016","Hugh Bruck","MD","University of Maryland College Park","Standard Grant","Mary Poats","12/31/2019","$382,184.00","Sarah Bergbreiter","bruck@eng.umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","ENG","1360","116E, 9178, 9250","$0.00","This Research Experiences for Undergraduates (REU) Site program at the University of Maryland (UMD)College Park offers new and exciting summer research opportunities to diverse and talented cohorts of undergraduates, from institutions with limited or no research opportunities in the field of bioinspired robotics (defined as robots that are inspired by natural systems such as insects, birds, mammals, and reptiles). Bioinspired robots will be used to target the efforts of first responders after a natural disaster and provide a number of tasks to assist humans (e.g., carrying extra goods, repairing damaged goods, building structures, etc.). However, designing, fabricating, and applying these robots is a long-term scientific and engineering challenge. Each summer, this REU site will provide 10 undergraduates with resources and opportunities to begin tackling some of these challenges. The program will collaborate with UMD's Women in Engineering program and the Center for Minorities in Science and Engineering to better recruit and assess the impact of this program on women and underrepresented minority students who traditionally suffer from the ""leaky pipeline"" in which percentages of these students decrease as they move up through the ranks of research positions. This problem will be addressed by focusing on career and academic development (seminars and graduate student mentors) in addition to providing a new network of role models through a diverse mentoring pool. A more diverse group of highly educated researchers in this critical research field will create a larger workforce to solve the nation's toughest environmental, technical, and national security challenges.<br/><br/>Bioinspired robotics offer a truly interdisciplinary systems research challenge that encompasses biology, materials, mechanical design, control, sensors and actuators, power, and electronics. To provide the collaborations necessary to solve some of these challenges and encourage students toward future research careers, the program will: 1. Define diverse teams of faculty, graduate student mentors, and undergraduate researchers. 2. Provide exciting research topics covering many aspects of bioinspired robotics. 3. Encourage collaboration and discussion through non-traditional means, including social media forums like Facebook and informal lunch talks among students. 4. Offer tutorial and professional development seminars in addition to field trips to local labs. 5. Assess project success through short-term, long-term, quantitative and qualitative metrics. The discoveries made during these collaborations will be communicated to the broader scientific community via publications and presentations."
"1317926","NRI: Small: Collaborative Research: Learning from Demonstration for Cloud Robotics","IIS","National Robotics Initiative","10/01/2013","02/09/2016","Andrea Thomaz","GA","Georgia Tech Research Corporation","Standard Grant","Reid Simmons","09/30/2018","$426,060.00","","athomaz@ece.utexas.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","7923, 8086","$0.00","The proposed work seeks to leverage cloud computing to enable robots to efficiently learn from remote human domain experts - ""Cloud Learning from Demonstration."" Building on RobotsFor.Me, a remote robotics research lab, this research will unite Learning from Demonstration (LfD) and Cloud Robotics to enable anyone with Internet access to teach a robot household tasks. The value of this work stems from three aspects. First is the remote system that can learn task models from a series of remote demonstrations from a single user, focusing on learning high-level tasks as opposed to low-level motor skills. The second is the extension of learning from demonstration to multiple teachers. This represents an important relaxation of a limiting assumption to focus on evaluating teacher strengths and effectively handling distinct task solutions. Finally, transparency mechanisms to allow a remote user to develop a correct mental model about the robot?s learning process.<br/><br/>The long term goal of this research is to one day make personal robots accessible to everyday people. The interactive learning framework based on RobotsFor.Me provides unique opportunities for education and outreach. Thomaz and Chernova will outreach to K-12 teachers and students by creating an education portal surrounding RobotsFor.Me containing hands-on workshop curricula. This material will be integrated with the WPI Frontiers program for middle school students, and the GT ePDN professional education network for teachers. A key impact on students at GT and WPI will be direct involvement in this research agenda, and integration with AI, robotics and HRI courses. Chernova is the Diversity Coordinator in the Robotics Engineering Program, and faculty advisor for Women In Robotics Engineering and Women in Technology student groups which will enable braod exposure. Thomaz mentors the RoboWomen graduate women?s group. Software components will also be made available as open source and the PIs have a collaboration plan in place with researchers at Willow Garage, and through student internships will transfer technology to their labs."
"1327614","NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects","IIS","National Robotics Initiative","10/01/2013","09/25/2013","Ioannis Poulakakis","DE","University of Delaware","Standard Grant","Jie Yang","09/30/2018","$400,000.00","","poulakas@udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","8013","7298, 7925, 8086","$0.00","Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation.  The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.<br/><br/>By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM."
"1637953","Understanding the Influence of a Teachable Robot on STEM Skills and Attitudes","IIS","ITEST","10/01/2016","06/05/2017","Amy Ogan","PA","Carnegie-Mellon University","Standard Grant","David Haury","09/30/2018","$38,000.00","","aeo@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7227","7227, 8086","$0.00","This National Robotics Initiative project will develop a robotic learning environment for middle school geometry students where students who are novices in geometry will learn new concepts by tutoring a humanoid robot to manipulate its gestures and spoken prompts in response to student utterances and problem-solving actions.  The project is based on the principle that the act of tutoring can lead to motivational benefits such as student engagement, positive attitudes toward the subject being studied, and increased confidence.  In this application, the robot is simultaneously a tool that students can program and a social actor that intelligently responds.  This research project will engage a broadly diverse population and is aimed at increasing the participation and retention of underrepresented groups in fields of science, technology, engineering, and mathematics (STEM). There are three components to the broader impacts of this project: 1) Scientific understanding of how robotic learning companions affect STEM attitudes and confidence, 2) Learning among students from traditionally underrepresented groups in the research process, and 3) Creation of a human-robot interaction platform for education and experimentation. The principles discovered through this project are expected to promote increased  participation of women and other underrepresented populations in STEM educational activities and STEM-related careers.<br/><br/>The goals of this research are to link robot behaviors to mediating motivational factors and STEM outcomes with the ultimate goal of understanding how to manipulate robot behaviors to improve a learning interaction. The proposed research will make contributions to understanding of how robotic learning environments can be designed to have a transformative impact on STEM learning.  The research is guided by two questions:  1) How do robot behaviors influence students' mediating motivational factors and affect STEM skills and attitudes?  And 2) What is the impact of adapting robot behaviors to student behaviors on mediating variables and STEM skills and outcomes?  To find answers to these questions, the project will undertake three initiatives: 1) Further development of NaoTAG (Nao Tangible Activities for Geometry) to serve as a platform for experimenting with how different aspects of robot behaviors influence student-robot interactions within the teachable agent context; 2) Understand how student and robot behaviors influence the mediating factors that have identified, and STEM skills and outcomes; and 3) Modeling student-robot interactions."
"1544895","CPS: TTP Option: Synergy: Collaborative Research: Nested Control of Assistive Robots through Human Intent Inference","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2015","02/26/2016","Deniz Erdogmus","MA","Northeastern University","Standard Grant","Sylvia J. Spengler","09/30/2019","$602,999.00","Taskin Padir, Gunar Schirner","erdogmus@ece.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","7918","7918, 8235","$0.00","Part 1: Upper-limb motor impairments arise from a wide range of clinical conditions including amputations, spinal cord injury, or stroke. Addressing lost hand function, therefore, is a major focus of rehabilitation interventions; and research in robotic hands and hand exoskeletons aimed at restoring fine motor control functions gained significant speed recently. Integration of these robots with neural control mechanisms is also an ongoing research direction. We will develop prosthetic and wearable hands controlled via nested control that seamlessly blends neural control based on human brain activity and dynamic control based on sensors on robots. These Hand Augmentation using Nested Decision (HAND) systems  will also provide rudimentary tactile feedback to the user. The HAND design framework will contribute to the assistive and augmentative robotics field. The resulting technology will improve the quality of life for individuals with lost limb function. The project will help train engineers skilled in addressing multidisciplinary challenges. Through outreach activities, STEM careers will be promoted at the K-12 level, individuals from underrepresented groups in engineering will be recruited to engage in this research project, which will contribute to the diversity of the STEM workforce.<br/><br/>Part 2: The team previously introduced the concept of human-in-the-loop cyber-physical systems (HILCPS). Using the HILCPS hardware-software co-design and automatic synthesis infrastructure, we will develop prosthetic and wearable HAND systems that are robust to uncertainty in human intent inference from physiological signals. One challenge arises from the fact that the human and the cyber system jointly operate on the same physical element. Synthesis of networked real-time applications from algorithm design environments poses a framework challenge. These will be addressed by a tightly coupled optimal nested control strategy that relies on EEG-EMG-context fusion for human intent inference. Custom distributed embedded computational and robotic platforms will be built and iteratively refined. This work will enhance the HILCPS design framework, while simultaneously making novel contributions to body/brain interface technology and assistive/augmentative robot technology. Specifically we will (1) develop a theoretical EEG-EMG-context fusion framework for agile HILCPS application domains; (2) develop theory for and design novel control theoretic solutions to handle uncertainty, blend motion/force planning with high-level human intent and ambient intelligence to robustly execute daily manipulation activities; (3) further develop and refine the HILCPS domain-specific design framework to enable rapid deployment of HILCPS algorithms onto distributed embedded systems, empowering a new class of real-time algorithms that achieve distributed embedded sensing, analysis, and decision making; (4) develop new paradigms to replace, retrain or augment hand function via the prosthetic/wearable HAND by optimizing performance on a subject-by-subject basis."
"1637562","NRI: Collaborative Research: Scalable Robot Autonomy through Remote Operator Assistance and Lifelong Learning","IIS","National Robotics Initiative","09/01/2016","07/27/2016","Sonia Chernova","GA","Georgia Tech Research Corporation","Standard Grant","Tatiana D. Korelsky","08/31/2019","$266,167.00","","chernova@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","8086","$0.00","One of the most significant barriers to the wider adoption of autonomous robotic systems in commercial applications is the challenge of achieving 100% reliable autonomy in unconstrained human environments. One path toward more robust autonomy is to spend more time in research labs improving robot capabilities, delaying deployment until autonomy is entirely robust.  Instead, it may be valuable to deploy robots out in the wild and adapt their behavior based on the rare examples, corner cases, and contingencies encountered after deployment in order to achieve near-term, fully reliable autonomy. This approach is specifically motivated by the call center model, in which robots are deployed at end-user sites and contact a remote human operator for assistance whenever an error is encountered.  This project develops a system that enables robots to perform lifelong, incremental improvement from remote human assistance with the long-term goal of achieving full autonomy. This research program has significant broader impacts, making personal robots more accessible to everyday people, while also providing opportunities for human-robot interaction that are ideal for educational K-12 programs, as well as undergraduate and graduate education. <br/><br/>Towards these goals, novel algorithms, interfaces, and user studies are being developed to advance the state of the art in three key areas related to the call center model: (1) Robust, Multi-Sensory Task Outcome Detection: multimodal techniques for identifying conditions under which to seek assistance or deploy recovery behaviors; (2) Transparency Devices for Situated Awareness: visual and language interface modalities for increasing the situational awareness of the remote operator and allowing for intuitive interaction, leading to more efficient and correct recovery procedures; (3) Low-Level and High-Level Task Model Refinement: lifelong learning techniques for incorporating corrections and recovery procedures into existing task models, as well as active learning methods to collect more targeted data.  The proposed approach is being evaluated on a variety of mobile manipulation tasks that a hotel concierge robot might perform, such as delivery tasks or preparing for and cleaning up after a conference banquet."
"1453129","CAREER: Lifesaving Capsule Robots","IIS","ROBUST INTELLIGENCE","02/01/2015","05/10/2016","Pietro Valdastri","TN","Vanderbilt University","Standard Grant","Reid Simmons","01/31/2020","$452,000.00","","p.valdastri@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","CSE","7495","1045, 7218, 7495, 9150, 9251","$0.00","Capsule robots are pill-sized devices that leverage extreme miniaturization to operate in environments that are out of reach for larger robots. In medicine, capsule robots can enter the human body through natural orifices or small incisions, and perform endoscopy and surgery while minimizing the invasiveness of the procedure. If successful, this research will have an impact on millions of Americans by enabling painless colonoscopy for colorectal cancer screening, allowing pediatric patients to benefit from minimally invasive surgery, and improving the current complication rate in radical prostatectomy. In this project, research in capsule robotics is being integrated with education and outreach by involving three tiers of students, from high school to graduate level. Students will have the opportunity to experiment with a capsule robot educational toolkit and will get first-hand exposure to this new technology. Visits to middle and high schools are being organized to convey the excitement for engineering and robotics, encouraging young minds to engage in STEM disciplines.<br/><br/>The goal of this research is to characterize fundamental principles at the intersection of robotics, magnetism, and control which will enable intelligent capsule robots to amplify the diagnostic and interventional capabilities of gastroenterologists and surgeons.  Through this project, the science and application of capsule robot architectures, real-time control, and teleoperation of magnetic pill-size devices will be advanced. Further, computationally efficient approximations of the magnetic field and models for capsule-tissue interaction, combined with miniature wireless electronics, will enable proprioceptive sensing techniques that can be effectively adopted in clinical settings. For the first time in magnetically manipulated capsule robots, environmental awareness and proprioceptive sensing will be leveraged to explore the full spectrum of human-robot interaction. This research will advance medical science as well by enabling new diagnostic and therapeutic procedures targeting organs deep inside the human body."
"1527919","NRI: Collaborative Research: Targeted Observation of Severe Local Storms Using Aerial Robots","IIS","National Robotics Initiative","01/01/2016","08/13/2015","Eric Frew","CO","University of Colorado at Boulder","Standard Grant","Ralph Wachter","12/31/2018","$611,859.00","Brian Argrow","eric.frew@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","8013","8086","$0.00","This project addresses the development of self-deploying aerial robotic systems that will enable new in-situ atmospheric science applications. Fixed-wing aerial robotic technology has advanced to the point where platforms fly persistent sampling missions far from remote operators. Likewise, complex atmospheric phenomena can be simulated in near real-time with increasing levels of fidelity. Furthermore, cloud computing technology enables distributed computation on large, dynamic data sets. Combining autonomous airborne sensors with environmental models dispersed over multiple communication and computation channels enables the collection of information essential for examining the fundamental behavior of atmospheric phenomena. The aerial robotic system proposed here will close significant capability gaps in conventional platform's abilities to collect the data necessary to answer a wide range of scientific questions. The motivating application for this work is improvement in the accuracy and lead-time of tornado warnings.<br/><br/>The proposed project draws on techniques in the areas of robotics, unmanned systems, networked control, wireless communication, active sensing, and atmospheric science to realize the vision of bringing cloud robotics to the clouds. The autonomous self-deploying aerial robotic systems is comprised of multiple robotic sensors and distributed computing nodes including: multiple fixed-wing unmanned aircraft, deployable Lagrangian drifters, mobile Doppler radar, mobile command and control stations, distributed computation nodes in the field and in the lab, a net-centric middleware connecting the dispersed elements, and an autonomous decision-making architecture that closes the loop between sensing in the field and new online numerical weather prediction tools."
"1704366","RI: Medium: RUI: Collaborative Research: A Structure-Math-Function Approach for Designing Robustly Intelligent Synthetic Nervous Systems","IIS","ROBUST INTELLIGENCE, EPSCoR Co-Funding","10/01/2017","09/07/2017","Joshua Martin","ME","Colby College","Standard Grant","Kenneth C. Whang","09/30/2021","$324,958.00","","jpmartin@colby.edu","4000 Mayflower Hill","Waterville","ME","049018840","2078594342","CSE","7495, 9150","7495, 7924, 8089, 8091, 9150, 9229","$0.00","Robots are becoming integrated into more areas of life, no longer confined to the predictable environment of a factory, performing the same task. Robots that work among humans require greater intelligence and the ability to adapt to changing tasks in an unpredictable environment. This work develops a sophisticated control system for robotics by modeling the control systems in the brain of a remarkably intelligent, capable, and adaptable insect: the praying mantis. This work promises to transform our understanding of intelligence in both robotics and neuroscience. A model of decision-making in the relatively simple brains of insects advances the study of more complex brains. The model will then be used to allow a legged robot to adapt its movement to suit its goals such as assisting humans, or its ""needs"" such as seeking energy or avoiding danger. These advances seek to give robots the autonomy that animals have. Instead of being programmed for every possible situation, a robot could be trained, continue to learn from experience, and improve efficiency even in novel situations. At an after-school robotics program at an inner-city school, students will benefit from hands-on experience creating robots with the unique perspective of bio-inspired design and modeling of nervous systems.  <br/><br/>This work expands the scale and sophistication of a synthetic nervous system (SNS), a continuous time dynamical model of praying mantis nervous system, and applies it to robotic control. Multi-channel neural recording and stimulation techniques are revealing how insects simplify motor control by distributing computation throughout the nervous system. This project leverages these techniques to understand how the capability of the ""higher"" level (the brain, where sensory input is processed) is directly supported by intelligence in the ""lower"" level (ganglia that coordinate the legs). These data will be used to develop and implement an SNS to control the six-legged MantisBot, endowing it with online learning and intelligent autonomy. Neurobiology will inform this work in all three specific aims: 1) Investigate the lower-level intelligence of the mantis nervous system and use the results to increase the intelligence of MantisBot's low-level control networks; 2) Investigate the correlation between descending commands and behavior and use the results to develop a simplified brain (i.e. high-level controller) for MantisBot; and 3) Investigate the effect of conflicting visual inputs (e.g. simultaneous prey and predator) on descending commands, and use these findings to endow MantisBot with robust intelligence distributed throughout its SNS."
"1531700","MRI: Acquisition of a Novel Assistive Robot Arm for Collaborative Research in Assistive and Rehabilitation Robotics at a Predominantly Undergraduate Institution","CNS","MAJOR RESEARCH INSTRUMENTATION","10/01/2015","07/30/2015","Cheng Liu","WI","University of Wisconsin-Stout","Standard Grant","Rita V. Rodriguez","09/30/2018","$39,339.00","Cheng Liu, Paul Schwartz, Catherine Anderson, John Lui","shiw@uwstout.edu","PO Box 790","Menomonie","WI","547510790","7152321123","CSE","1189","1189","$0.00","This project, acquiring a shared state-of-the-art JACO-2 robot arm for collaborative research in assistive and rehabilitation robotics, aims to improve the quality of life of individuals with disabilities and the elderly by increasing their independence and community reintegration. It supports research in three areas: <br/>- Assistive technology and vocational rehabilitation systems; <br/>- Robotics and control systems; and <br/>- Health monitoring systems. <br/>In these areas, the participating researchers will use the equipment collaboratively on diverse research projects. In addition, the award should facilitate development of assistive robotics research and training across multiple departments. <br/><br/>This novel instrument enables access by the research community to an instrument that will accelerate research in assistive robotics, vocational rehabilitation, health-care and monitoring, and home care. The proposed projects introduce a simple robot arm manipulation scheme for enabling the incorporation of robotic systems into home environment, thus enhancing the independence and autonomy of individuals with disabilities, and minimizing the necessity for a caregiver. The research projects will also contribute to assisting the elderly and persons with disability to manipulate and communicate with the robot in complex unstructured environments, thereby enhancing safety and reliability of the robotic system, especially for people with lower or upper limb limitations or both lower and upper limb limitations to perform tasks in a more complicated workplace."
"1544636","CPS: TTP Option: Synergy: Collaborative Research: Nested Control of Assistive Robots through Human Intent Inference","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2015","10/14/2015","Taskin Padir","MA","Worcester Polytechnic Institute","Standard Grant","Sylvia J. Spengler","09/30/2019","$200,000.00","Cagdas Onal","t.padir@northeastern.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","7918","7918, 8235","$0.00","Part 1: Upper-limb motor impairments arise from a wide range of clinical conditions including amputations, spinal cord injury, or stroke. Addressing lost hand function, therefore, is a major focus of rehabilitation interventions; and research in robotic hands and hand exoskeletons aimed at restoring fine motor control functions gained significant speed recently. Integration of these robots with neural control mechanisms is also an ongoing research direction. We will develop prosthetic and wearable hands controlled via nested control that seamlessly blends neural control based on human brain activity and dynamic control based on sensors on robots. These Hand Augmentation using Nested Decision (HAND) systems  will also provide rudimentary tactile feedback to the user. The HAND design framework will contribute to the assistive and augmentative robotics field. The resulting technology will improve the quality of life for individuals with lost limb function. The project will help train engineers skilled in addressing multidisciplinary challenges. Through outreach activities, STEM careers will be promoted at the K-12 level, individuals from underrepresented groups in engineering will be recruited to engage in this research project, which will contribute to the diversity of the STEM workforce.<br/><br/>Part 2: The team previously introduced the concept of human-in-the-loop cyber-physical systems (HILCPS). Using the HILCPS hardware-software co-design and automatic synthesis infrastructure, we will develop prosthetic and wearable HAND systems that are robust to uncertainty in human intent inference from physiological signals. One challenge arises from the fact that the human and the cyber system jointly operate on the same physical element. Synthesis of networked real-time applications from algorithm design environments poses a framework challenge. These will be addressed by a tightly coupled optimal nested control strategy that relies on EEG-EMG-context fusion for human intent inference. Custom distributed embedded computational and robotic platforms will be built and iteratively refined. This work will enhance the HILCPS design framework, while simultaneously making novel contributions to body/brain interface technology and assistive/augmentative robot technology. Specifically we will (1) develop a theoretical EEG-EMG-context fusion framework for agile HILCPS application domains; (2) develop theory for and design novel control theoretic solutions to handle uncertainty, blend motion/force planning with high-level human intent and ambient intelligence to robustly execute daily manipulation activities; (3) further develop and refine the HILCPS domain-specific design framework to enable rapid deployment of HILCPS algorithms onto distributed embedded systems, empowering a new class of real-time algorithms that achieve distributed embedded sensing, analysis, and decision making; (4) develop new paradigms to replace, retrain or augment hand function via the prosthetic/wearable HAND by optimizing performance on a subject-by-subject basis."
"1734876","NCS-FO: Collaborative Research: Understanding the neural basis for sensorimotor control loops using whisker-based robotic hardware platforms","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2017","08/07/2017","Sarah Bergbreiter","MD","University of Maryland College Park","Standard Grant","Betty H. Tuller","08/31/2020","$320,520.00","","sarahb@umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","SBE","8624","8089, 8091, 8551, 9251","$0.00","This project will construct robots in order to understand how animals gather information through the sense of touch and how animals use touch information to perform complex behaviors. The results will be important to both neuroscience and engineering. On the neuroscience side, the results will address how the brain combines information about movement and touch, thereby improving our understanding of stroke and brain injury. On the engineering side, the work will develop novel robots and sensors that use touch to sense object location, shape, and texture, to track fluid wakes in water, and to sense the direction of airflow. These capabilities will improve the ability of robots to work in challenging environments; for example, robots could explore dark areas more easily or provide surgeons with a better sense of touch during surgery. To train the next generation of scientists and engineers, both undergraduate and graduate students will help construct the robots and will explore industry- and government-related applications of whisker-based touch sensing. The research team will investigate technology transfer opportunities in robotics and medicine, flow sensing, instrument placement, corrosion detection, three-dimensional tactile profilometry, and compliance sensing. <br/><br/>The fundamental scientific rationale for the work is that understanding how animal nervous systems process complex sensory and motor information necessarily requires quantification of the input. However, it is currently impossible for neuroscientists to record from all primary sensory neurons involved in a particular sensorimotor behavior. The three stages of this project exploit the whisker system of mammals in an endeavor to completely quantify whisker-based input and early neural processing in the rat (Rattus norvegicus) and the harbor seal (Phoca vitulina). The first stage of work will focus on the development of modular, reconfigurable, artificial whiskers that can sense both touch and fluid flow. The materials, manufacturing, and sensor designs necessary for whiskers at multiple length scales will be investigated and signals from the whiskers will be represented based on known coding properties of primary whisker-sensitive neurons in the trigeminal ganglion (TG). The second stage of work will involve the construction of whisker arrays that anatomically match those of the rat and the seal. These arrays will be used to develop combined hardware and software models of the responses of the entire population of TG neurons. Finally, in the third stage of work, the whisker arrays will be mounted on robotic platforms, and the robots will be put through the same head movements as real animals during natural behavior. This process will allow us to simulate the entire TG neuron population response during complex, natural behaviors. Overall, the project will help unlock the basis by which low-level but powerful neural circuits confer animals with flexibility and resourcefulness in sensing and movement.<br/><br/>This project is funded by Integrative Strategies for Understanding Neural and Cognitive Systems (NSF-NCS), a mulitdisciplinary program jointly supported by the Directorates for Computer and Information Science and Engineering (CISE), Education and Human Resources (EHR), Engineering (ENG), and Social, Behavioral, and Economic Sciences (SBE)."
"1544815","CPS: TTP Option: Synergy: Collaborative Research: Nested Control of Assistive Robots through Human Intent Inference","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2015","09/14/2015","Paolo Bonato","MA","Spaulding Rehabilitation Hospital","Standard Grant","Sylvia J. Spengler","09/30/2019","$296,998.00","","pbonato@partners.org","300 First Street","Charlestown","MA","021293109","8572821769","CSE","7918","1640, 7918, 8235","$0.00","Part 1: Upper-limb motor impairments arise from a wide range of clinical conditions including amputations, spinal cord injury, or stroke. Addressing lost hand function, therefore, is a major focus of rehabilitation interventions; and research in robotic hands and hand exoskeletons aimed at restoring fine motor control functions gained significant speed recently. Integration of these robots with neural control mechanisms is also an ongoing research direction. We will develop prosthetic and wearable hands controlled via nested control that seamlessly blends neural control based on human brain activity and dynamic control based on sensors on robots. These Hand Augmentation using Nested Decision (HAND) systems  will also provide rudimentary tactile feedback to the user. The HAND design framework will contribute to the assistive and augmentative robotics field. The resulting technology will improve the quality of life for individuals with lost limb function. The project will help train engineers skilled in addressing multidisciplinary challenges. Through outreach activities, STEM careers will be promoted at the K-12 level, individuals from underrepresented groups in engineering will be recruited to engage in this research project, which will contribute to the diversity of the STEM workforce.<br/><br/>Part 2: The team previously introduced the concept of human-in-the-loop cyber-physical systems (HILCPS). Using the HILCPS hardware-software co-design and automatic synthesis infrastructure, we will develop prosthetic and wearable HAND systems that are robust to uncertainty in human intent inference from physiological signals. One challenge arises from the fact that the human and the cyber system jointly operate on the same physical element. Synthesis of networked real-time applications from algorithm design environments poses a framework challenge. These will be addressed by a tightly coupled optimal nested control strategy that relies on EEG-EMG-context fusion for human intent inference. Custom distributed embedded computational and robotic platforms will be built and iteratively refined. This work will enhance the HILCPS design framework, while simultaneously making novel contributions to body/brain interface technology and assistive/augmentative robot technology. Specifically we will (1) develop a theoretical EEG-EMG-context fusion framework for agile HILCPS application domains; (2) develop theory for and design novel control theoretic solutions to handle uncertainty, blend motion/force planning with high-level human intent and ambient intelligence to robustly execute daily manipulation activities; (3) further develop and refine the HILCPS domain-specific design framework to enable rapid deployment of HILCPS algorithms onto distributed embedded systems, empowering a new class of real-time algorithms that achieve distributed embedded sensing, analysis, and decision making; (4) develop new paradigms to replace, retrain or augment hand function via the prosthetic/wearable HAND by optimizing performance on a subject-by-subject basis."
"1700696","NRI: Collaborative Research: Learning Deep Sensorimotor Policies for Shared Autonomy","IIS","National Robotics Initiative","09/01/2016","12/06/2016","Sergey Levine","CA","University of California-Berkeley","Standard Grant","Weng-keen Wong","08/31/2019","$500,000.00","","sergey.levine@gmail.com","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","8013","8086","$0.00","Assistive robots have the potential to transform the lives of persons with upper extremity disabilities, by helping them perform basic daily activities, such as manipulating objects and feeding. However, human control of assistive robots presents substantial challenges. The high dimensionality of robotic arms means that joystick-like interfaces are unnatural hard to use intuitively, and motions resulting from direct teleoperation are often slow, imprecise, and severely limited in their dexterity. This research address these challenges by developing learning algorithms for shared autonomy, where the robot anticipates the user's intent and provides a degree of assistive autonomy to ensure fluid and successful motions. This research will also pave the way for future research that can bootstrap from teleoperation and build towards full robot autonomy. <br/><br/>The research proposes a hierarchical and multi-phased approach to shared autonomy, using techniques from deep learning and reinforcement learning. The system begins by using deep inverse reinforcement learning to quickly ascertain the user's high-level goal, such as whether the user wants to grasp a particular object or operate an appliance, from raw sensory inputs. This goal inference layer supplies objectives to the lower control layer, which consists of deep neural network control policies that can directly process raw sensory input about the environment and the user to make decisions. These policies choose low-level controls to satisfy the high-level objective while minimizing disagreement with the user's commands. The algorithms will be deployed and tested on a wheelchair-mounted robot arm with the potential to assist users with upper extremity disabilities to perform activities of daily living."
"1527183","NRI: Collaborative Research: Targeted Observation of Severe Local Storms Using Aerial Robots","IIS","National Robotics Initiative","01/01/2016","08/13/2015","Christopher Weiss","TX","Texas Tech University","Standard Grant","Ralph Wachter","12/31/2018","$346,246.00","","chris.weiss@ttu.edu","349 Administration Bldg","Lubbock","TX","794091035","8067423884","CSE","8013","8086","$0.00","This project addresses the development of self-deploying aerial robotic systems that will enable new in-situ atmospheric science applications. Fixed-wing aerial robotic technology has advanced to the point where platforms fly persistent sampling missions far from remote operators. Likewise, complex atmospheric phenomena can be simulated in near real-time with increasing levels of fidelity. Furthermore, cloud computing technology enables distributed computation on large, dynamic data sets. Combining autonomous airborne sensors with environmental models dispersed over multiple communication and computation channels enables the collection of information essential for examining the fundamental behavior of atmospheric phenomena. The aerial robotic system proposed here will close significant capability gaps in conventional platform?s abilities to collect the data necessary to answer a wide range of scientific questions. The motivating application for this work is improvement in the accuracy and lead-time of tornado warnings.<br/><br/>The proposed project draws on techniques in the areas of robotics, unmanned systems, networked control, wireless communication, active sensing, and atmospheric science to realize the vision of bringing cloud robotics to the clouds. The autonomous self-deploying aerial robotic systems is comprised of multiple robotic sensors and distributed computing nodes including: multiple fixed-wing unmanned aircraft, deployable Lagrangian drifters, mobile Doppler radar, mobile command and control stations, distributed computation nodes in the field and in the lab, a net-centric middleware connecting the dispersed elements, and an autonomous decision-making architecture that closes the loop between sensing in the field and new online numerical weather prediction tools."
"1746212","SBIR Phase I:  Robotic Gripper for Fragile Produce","IIP","SMALL BUSINESS PHASE I","01/01/2018","12/23/2017","Stephen Jens","MA","Harvest Moon Automation","Standard Grant","Muralidharan S. Nair","10/31/2018","$225,000.00","","harvestmoonautomation@gmail.com","19 Franklin Road","Winchester","MA","018904014","7819295161","ENG","5371","5371, 8034","$0.00","The broader impact/commercial potential of this project is that it will enable the automated harvesting of fragile produce such as strawberries to help offset a shrinking workforce and increased labor costs. The world population is expected to grow from 7.3 billion to 11.2 billion by 2100, this population growth and a rising middle class will place more demand on the agricultural industry. Presently, the agricultural industry relies solely on manual labor to harvest its fragile produce. There is no mechanized option that can reliably and cost effectively harvest these crops. Consequently, the industry is struggling to harvest its crop, maintain quality and control its costs. High quality and lower costs can only be maintained if robotic harvesters are utilized that can pick fragile produce without damage. One of the key elements on the automated harvester is a gripper that can grab and pick the produce without damage. There is a market for a reliable and low cost robotic gripper that can gently pick and handle strawberries and other fragile produce.<br/><br/>This Small Business Innovation Research (SBIR) Phase I project involves the development of a robotic end effector that can be used to harvest and handle fragile produce. Advances in machine vision and robotics has made it possible to commercially harvest fragile produce such as strawberries, however, the key component that still needs to be developed is an end effector that can pick the fruit without damage and be reliable and cost effective. Design and development of this end effector will use a new and novel method for grabbing the strawberry with advances in design, materials and actuation. The proposed R&D plan will involve repeated testing of the interaction between the fruit and the end effector. Analytical studies using a series of thin film load sensors mounted on the end effector will provide real time load profiles that can be used to optimize the design and performance of the end effector. Shelf life testing of the fruit will be used to assess the success of the end effector in properly picking and handling the fruit without damage."
"1734400","NRI: INT: Co-Multi-Robotic Exploration of the Benthic Seafloor - New Methods for Distributed Scene Understanding and Exploration in the Presence of Communication Constraints","IIS","National Robotics Initiative","01/01/2018","08/24/2017","Yogesh Girdhar","MA","Woods Hole Oceanographic Institution","Standard Grant","Ralph Wachter","12/31/2021","$1,337,101.00","James Kinsey, Brian Claus","ygirdhar@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","CSE","8013","8086","$0.00","This project addresses the control and communications among underwater robotic vehicles to explore and map in ocean environments, where the communications are inherently low bandwidth, may be degraded and even disrupted due to natural ocean phenomena.  The research focuses on coordinating robots and cooperating teams of such robots under such conditions with limited human intervention.  It is expected the principles learned from this project will be generalizable to deployment of teams of cooperating robots operating in harsh environments with similar communication challenges such as what might be expected in the aftermath of natural disasters.<br/> <br/>The project addresses technical challenges with robots learning to describe their environment using high-level descriptors, using state of the art unsupervised machine learning techniques, and exchanging compact messages with each other to keep the description model consistent across all the cooperating robots. This high-level scene description is used by the robots to efficiently communicate the state of the exploration to each other, and to the human operator as possible. Furthermore, the human operators can efficiently control the robot team by specifying their interests in terms of these learned scene descriptors. The automatically generated exploration trajectories aim to maximize the information content, human interest, and spatial coverage, while taking into account the difficult constraints imposed by communication range in such harsh environments."
"1718755","RI:  Small:  Collaborative Research:  A Modular Approach to Robot Systems Incorporating Compliant and Soft Elements","IIS","ROBUST INTELLIGENCE","09/01/2017","08/13/2017","Isuru Godage","IL","DePaul University","Standard Grant","Reid Simmons","08/31/2020","$289,900.00","","igodage@depaul.edu","1 East Jackson Boulevard","Chicago","IL","606042287","3123627595","CSE","7495","7495, 7923","$0.00","Biological systems can demonstrate impressive energy efficient manipulation, from picking up fragile objects to lifting heavy weights.  To do so, they rely on building blocks of varying stiffness, such as bones and muscles.  Inspired by these biological systems, this project is investigating the combination of ""stiff"" and ""soft"" robotic components, creating novel ""hybrids"" that exploit the advantages, and conceal the inherent weaknesses, of the individual technologies. Such ""hybrids"" aim to bring safe and practical soft robotics to previously inaccessible domains and applications, including urban search/rescue, disaster relief, and assistance for the elderly and people with disabilities.  The project will also promote robotics among underrepresented groups at both DePaul and Clemson.<br/><br/>The project is collaboratively designing, modeling, creating, and demonstrating a series of innovative soft, modular robots. The modules are exploiting the hard/soft component interaction and constrained actuator arrangement to control stiffness independently from bending. Exploiting modularity, these robots can reassemble, or ""evolve"", into different manipulators and locomotors. The project is developing a unified design and optimization framework to optimize, per user specifications, the composition of hard/soft modules and optimal sensor placement. Resulting modules are fabricated and assembled into a variety of robotic configurations to demonstrate the importance of stiffness modulation in dealing with unforeseen circumstances. Using these modules, the project is also creating a sophisticated physical platform for providing new theoretical insights and innovative operational modes for soft modular robots, as well as demonstrating the fundamentals of morphological computation. Morphological computation utilizes physical body properties (e.g., stiffness and bending shape) as a computational resource that can share the burden of control to optimize stability and locomotion efficiency in real-time. This thrust is exploiting the intrinsic resonant motions of modular systems, via stiffness and shape modulation, to minimize energy loss and improve stability."
"1734482","NRI: FND: COLLAB: Coordinating Human-Robot Teams in Uncertain Environments","IIS","National Robotics Initiative","09/01/2017","08/23/2017","Laurel Riek","CA","University of California-San Diego","Standard Grant","James Donlon","08/31/2020","$375,000.00","","lriek@eng.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","CSE","8013","8086","$0.00","The decreasing cost and increasing sophistication of robot hardware is creating new opportunities for teams of robots to be deployed in combination with skilled humans to support and augment labor-intensive and/or dangerous manual work. The vision is for robots to free up time of skilled workers so they can focus on the tasks that they are skilled at (complex problem solving, dextrous manipulation, customer service, etc.) and robots can help with the distracting and frustrating parts of working, such as delivering materials or fetching supplies. This vision is being realized across many sectors of the US economy and abroad, such as in warehouse management, assembly manufacturing, and disaster response. However, progress in this area is being stymied by current methods that are rigid and inflexible, and rely on unrealistic models of human-robot interaction. This project seeks to overcome these problems by proposing new models and methods for teams robots to coordinate with teams humans to complete complex problems. <br/><br/>In particular, this project will create and solve realistic models for coordinating teams of humans and robots in uncertain environments. The PIs will investigate innovative approaches to this research area, and will make the following contributions: 1) Enable a transformative re-conceptualization of multi-human multi-robot teamwork the accurately reflects the strengths and limitations of the team, as situated within a temporally dynamic, stochastic environment, 2) develop realistic and general models of human-robot teamwork that consider uncertainty and partial observability, and 3) Contribute innovative and scalable techniques for planning and learning in these models. This research will build off of methods that have been successful in single-robot problems under uncertainty and partially observability: partially observable Markov decision processes (POMDPs). POMDPs model robots and environments, but not humans. However, explicitly including people in these models will be critical in almost all real-world applications.  By extending POMDPs to multiple robots interacting with teams of humans, complex and realistic problems with mixed human and robot teams can be represented. The solution methods developed in this project will allow the robots to reason about the uncertainty about the domain and their human teammates, while optimizing their behavior. The methods are broadly applicable to human-robot collaboration domains, but they will be evaluated in an emergency department, an environment with a large amount of uncertainty and many delivery and supply tasks during high-volume times. A team of robots can assist in these tasks. Experiments will take place in simulation and in the UC San Diego Simulation and Training Center with various numbers of humans and robots. The results of this project have the potential to transform the way human-robot coordination is performed."
"1734492","NRI: INT: COLLAB: Integrated Modeling and Learning for Robust Grasping and Dexterous Manipulation with Adaptive Hands","IIS","National Robotics Initiative","09/01/2017","07/27/2017","Kostas Bekris","NJ","Rutgers University New Brunswick","Standard Grant","James Donlon","08/31/2021","$867,729.00","Abdeslam Boularias","kostas.bekris@cs.rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","8013","8086","$0.00","Robots need to effectively interact with a large variety of objects<br/>that appear in warehouses and factories as well as homes and offices.<br/>This requires robust grasping and dexterous manipulation of everyday<br/>objects through low cost robots and low complexity solutions.<br/>Traditionally, robots use rigid hands and analytical models for such<br/>tasks, which often fail in the presence of even small errors. New<br/>compliant hands promise improved performance, while minimizing<br/>complexity, and increased robustness. Nevertheless, they are<br/>inherently difficult to sense and model. This project combines ideas<br/>from different robotics sub-fields to address this limitation. It<br/>utilizes progress in machine learning and builds on a strong tradition<br/>in robot modeling. The objective is to provide adaptive, compliant<br/>robots that are better in grasping objects in the presence of multiple<br/>unknown contact points and sliding or rolling objects in-hand. The<br/>broader impact will be strengthened by the open release of new or<br/>modified robot hand designs, improved control algorithms and software,<br/>as well as corresponding data sets. Furthermore, academic<br/>dissemination will be accompanied by educational outreach to<br/>undergraduate and high school students.<br/><br/>Towards the above objective, the first step will be the definition of<br/>new hybrid models appropriate for adaptive, compliant hands.  This<br/>will happen by improving analytical solutions and extending them to<br/>allow adaptation based on data via novel, time-efficient learning<br/>methods. The objective is to capture model uncertainty inherent in<br/>real-world interactions; a process that suffers from data scarcity.<br/>In order to reduce the amount of data required for learning, different<br/>models will be tailored to specific tasks through an automated<br/>discovery of these tasks and of underlying motion primitives for each<br/>one of them. This task identification process will operate iteratively<br/>with learning and utilize improved models to discover new tasks. It<br/>can also provide feedback for improved hand design. Once these<br/>learning-based and task-focused models are available, they will be<br/>used to learn and synthesize controllers for grasping and in-hand<br/>manipulation. To learn controllers, this work will consider a<br/>model-based, reinforcement learning approach, which will be evaluated<br/>against alternatives. For controller synthesis, existing tools for<br/>this purpose will be integrated with task planning primitives and<br/>extended through learning processes to identify the preconditions<br/>under which different controllers can be chained together. The project<br/>involves extensive evaluation on a variety of novel adaptive hands and<br/>robotic arms designed in the PIs' labs. Modern vision-based solutions<br/>will be used to track grasped objects and provide feedback for<br/>learning and closed-loop control.  The evaluation will measure whether<br/>the developed hybrid models can significantly improve robustness of<br/>grasping and the effectiveness of dexterous manipulation."
"1734361","NRI: FND: Mutually Aware Social Navigation","IIS","National Robotics Initiative","09/01/2017","08/29/2017","Aaron Steinfeld","PA","Carnegie-Mellon University","Standard Grant","Tatiana D. Korelsky","08/31/2020","$743,549.00","","steinfeld@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","8013","8086","$0.00","This project seeks to provide robots with the social intelligence to be aware of the mutual<br/>dependency between their movements and the movements of humans around them. To this<br/>end, the work will focus on (1) improving the way robots reason about spatial behavior, and (2)<br/>developing navigation methods that lead to understandable and appropriate motion patterns in<br/>social environments. This project will build upon prior work in robot perception and social<br/>behavior in crowds and groups. This work will impact the future use of robots in many application domains, <br/>especially for those where people untrained in robotics are present (e.g., delivery robots, guide robots, etc.). <br/>Almost all robots that move near people will need to behave appropriately, so it is necessary to discover<br/>socially intelligent navigation techniques, thereby increasing human acceptance and market<br/>success. The team will also continue established and successful efforts in fostering diversity,<br/>integrating education with research, disseminating new knowledge to the general public,<br/>industry stakeholders, and other researchers.<br/><br/>Prior work has identified the importance of human-aware navigation, and has developed<br/>methods to incorporate the social norms that govern human physical space into aspects of robot<br/>path planning. Building on this foundational work, the team will address three main social<br/>intelligence tasks: (1) enabling robots to reason jointly about nearby human spatial behavior and<br/>their own, (2) enabling robots to communicate their intentions as they navigate so that their<br/>motion is understandable by nearby humans, and (3) giving robots the ability to decide when it is<br/>acceptable to violate pre-established social conventions. Research in these areas is<br/>incomplete since most efforts do not include awareness or reasoning about mutual dependency.<br/>This makes it difficult for a robot to reason intelligently on how to alter crowd motions in a<br/>socially appropriate manner. Methods discovered by the team will also support the case where<br/>multiple robots must mix with multiple humans."
"1734362","NRI: INT: COLLAB: Robust, Scalable, Distributed Semantic Mapping for Search-and-Rescue and Manufacturing Co-Robots","IIS","National Robotics Initiative","09/01/2017","08/03/2017","Dario Pompili","NJ","Rutgers University New Brunswick","Standard Grant","James Donlon","08/31/2020","$426,161.00","","pompili@ece.rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","8013","8086","$0.00","The goal of this project is to enable multiple co-robots to map and understand the environment they are in to efficiently collaborate among themselves and with human operators in education, medical assistance, agriculture, and manufacturing applications. The first distinctive characteristic of this project is that the environment will be modeled semantically, that is, it will contain human-interpretable labels (e.g., object category names) in addition to geometric data. This will be achieved through a novel, robust integration of methods from both computer vision and robotics, allowing easier communications between robots and humans in the field. The second distinctive characteristic of this project is that the increased computation load due to the addition of human-interpretable information will be handled by judiciously approximating and spreading the computations across the entire network. The novel developed methods will be evaluated by emulating real-world scenarios in manufacturing and for search-and-rescue operations, leading to potential benefits for large segments of the society. The project will include opportunities for training students at the high-school, undergraduate, and graduate levels by promoting the development of marketable skills.<br/><br/>The project will advance the state of the art in robust semantic mapping from multiple robots by 1) developing a new optimization framework that can handle large, dynamic, uncertain environments under significant measurement errors, 2) explicitly allowing and studying interactions and information exchanges with humans with an hybrid discrete-continuous extension of the optimization framework, and 3) allowing an intelligent use and sharing of the limited computational resources possessed by the network of co-robots as a whole by enabling approximations and balancing of the computations. These developments will be driven by two particular case studies: a job-shop (small factory) scenario, where robots and fixed cameras are used to track and assist human workers during production and assembly of parts; and a classic search-and-rescue scenario, where operators use an heterogeneous team of robots to quickly assess damages and to discover survivors. These two applications, when considered together, highlight all the limitations of the currently prevalent geometric mapping solutions, and will be used as benchmarks for the project's results."
"1741552","NRI: Small: Collaborative Research: Learning from Demonstration for Cloud Robotics","IIS","National Robotics Initiative","10/01/2016","05/08/2017","Sonia Chernova","GA","Georgia Tech Research Corporation","Standard Grant","Reid Simmons","09/30/2018","$226,480.00","","chernova@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","7923, 8086, 9251","$0.00","The proposed work seeks to leverage cloud computing to enable robots to efficiently learn from remote human domain experts - ""Cloud Learning from Demonstration."" Building on RobotsFor.Me, a remote robotics research lab, this research will unite Learning from Demonstration (LfD) and Cloud Robotics to enable anyone with Internet access to teach a robot household tasks. The value of this work stems from three aspects. First is the remote system that can learn task models from a series of remote demonstrations from a single user, focusing on learning high-level tasks as opposed to low-level motor skills. The second is the extension of learning from demonstration to multiple teachers. This represents an important relaxation of a limiting assumption to focus on evaluating teacher strengths and effectively handling distinct task solutions. Finally, transparency mechanisms to allow a remote user to develop a correct mental model about the robot?s learning process.<br/><br/>The long term goal of this research is to one day make personal robots accessible to everyday people. The interactive learning framework based on RobotsFor.Me provides unique opportunities for education and outreach. Thomaz and Chernova will outreach to K-12 teachers and students by creating an education portal surrounding RobotsFor.Me containing hands-on workshop curricula. This material will be integrated with the WPI Frontiers program for middle school students, and the GT ePDN professional education network for teachers. A key impact on students at GT and WPI will be direct involvement in this research agenda, and integration with AI, robotics and HRI courses. Chernova is the Diversity Coordinator in the Robotics Engineering Program, and faculty advisor for Women In Robotics Engineering and Women in Technology student groups which will enable braod exposure. Thomaz mentors the RoboWomen graduate women?s group. Software components will also be made available as open source and the PIs have a collaboration plan in place with researchers at Willow Garage, and through student internships will transfer technology to their labs."
"1556109","SBIR Phase II:  Collaborative Subsea Manipulation Interface","IIP","SMALL BUSINESS PHASE II","04/15/2016","08/30/2018","Fredrik Ryden","WA","BluHaptics Inc","Standard Grant","Muralidharan S. Nair","12/31/2020","$1,396,184.00","","BluHaptics@gmail.com","108 NW Canal St","Seattle","WA","981074933","2067478277","ENG","5373","165E, 169E, 5373, 6840, 8035, 9139, HPCC","$0.00","The broader impact/commercial potential of this project results from the advancement of telerobotic control technology for subsea operations. As humans deploy and maintain ever more complex underwater hardware, conduct subsea scientific sampling and exploration and develop natural resources in hostile, deep and remote locations, the need for ROVs (Remotely Operated Vehicles) is increasing. ROVs have transitioned from basic transport and inspection tools to mission critical machines for construction, maintenance and intervention. Despite advances in sensing and machinery, significant challenges persist which have plagued the industry with high costs and unacceptable downtime, as well as safety risks. Limited situational awareness, data deluge and inadequate manual operator controls combine to create high rates of equipment breakage, unpredictable and inefficient task completion and high mission overhead. This work is developing innovative products for 3-dimensional visual awareness and computer assisted control systems for subsea teleoperated robots. Divers can be replaced in hazardous situations by telerobots using this technology. The rate of untoward incidents and their severity will be reduced for a large range of subsea activities. Economic benefits include reduced costs, new employment opportunities, competitive advantages and contributions to the national technological infrastructure in subsea operations. <br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project will address fundamental challenges of connecting higher-dimensional data from remote environments to intuitive controls. Its intellectual merit is the refinement of a collaborative approach to command and control allowing ROV pilots to communicate seamlessly with each other and the robotic system. This will be done by developing several foundational innovations that, separately, enhance capabilities (and may become individual products), and that together derive immense value to the customer. These technologies are in the areas of: (1) Pilot Interface/Control room software; (2) Sensor fusion and processing; (3) Task assistance and workflow management; and (4) Manipulator and vehicle control. Successful implementation of visualization, sensor fusion, control methods, and haptic virtual fixtures serves as an excellent demonstration example of these technologies. With these technologies combined into a single software platform and integrated with a robotic system, increased performance, predictability, and safety can be achieved in a way that surpasses what is currently possible for purely automated or manual robotic systems. Although this work is focused on underwater operations, it can also be extended to terrestrial applications, such as industrial assembly, welding and machining, nuclear maintenance and robotic dredging and excavation."
"1717951","RI:   Small:  Collaborative Research:  Information-driven Autonomous Exploration in Uncertain Underwater Environments","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2017","08/13/2017","Todd Murphey","IL","Northwestern University","Standard Grant","Reid Simmons","08/31/2020","$234,711.00","","t-murphey@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7495, 8013","7495, 7923","$0.00","This project develops the theory and algorithms for autonomous navigation of mobile sensing platforms, such as unmanned ground, aerial, and underwater vehicles, so that the collected information is maximized while constraints on movement capabilities and energy expenditure are accommodated. This work facilitates the use of autonomous robots in environmental monitoring, search and rescue, surveillance and security, among other applications of societal importance. The algorithms are evaluated in field trials using unique gliding robotic fish.  The project provides training for both graduate and undergraduate students, including those from underrepresented groups. Through showcasing at the Museum of Science and Industry in Chicago and offering of an open-source robotic fish education kit, the project promotes the interest of K-12 students and the general public in science and engineering. The project further facilitates transfer of software and hardware for robotic sensing to the market.<br/><br/>The goal of this project is to bridge the gap between the theory and practice in information-driven mobile sensing and to develop a principled theoretic and algorithmic framework for autonomous exploration in uncertain, specifically underwater, environments. The approach exploits the concept of ergodic exploration, where the underlying optimization problem is solved using methods from nonlinear optimal control. The research consists of: 1) Establishing a rigorous theoretical framework for ergodic exploration for guaranteeing solution well-posedness and stability, and developing synthesis methods for real-time control; 2) exploring active probing of flow conditions via auxiliary measurement of tracer agents to mitigate environmental uncertainty; 3) investigating collaborative exploration schemes that strike balance among performance, complexity, and robustness; and 4) conducting field experiments to validate the framework using a group of gliding robotic fish to monitor harmful algal blooms and localize sources of chemical spills.<br/>"
"1748067","EAGER:  Data-Driven Contact Modeling","IIS","National Robotics Initiative","08/15/2017","08/14/2017","C. Karen Liu","GA","Georgia Tech Research Corporation","Standard Grant","Reid Simmons","07/31/2019","$200,000.00","","ckarenliu@gmail.com","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8013","7916","$0.00","Accurate physics simulation has become an essential component for developing robots that physically interact with the world.  A particularly important aspect is simulating contacts between the robots and objects in the environment, which can be useful for both planning and machine learning.  However, robots that learn in simulation often perform poorly in the real world due to inaccurate parameters, idealized dynamic and contact models, or other unmodeled factors.  This project therefore tackles an important challenge in physics simulation: accurate modeling of contacts. The results will significantly improve contact modeling in physics simulation, which offers a safe space to learn difficult and highly risky motor skills such that the robots can operate more efficiently and robustly even in unseen scenarios in the real world. This capability will have potential impact on robotics in healthcare, search-and-rescue, and space exploration.<br/><br/>This proposal introduces a technique that effectively utilizes real-world data to model the complex, poorly understood contact phenomena. Specifically, the new data-driven technique accurately computes contact states (sticking, sliding, or breaking) and contact forces such that the simulated results match the real-world phenomena. Instead of taking the conventional approach of system identification, this proposal leverages empirical evidence and deep learning techniques to enhance the existing contact model, namely, an implicit time-stepping, velocity-based Linear-Complementarity Program (LCP).  The key insight is that the contact problem can be broken down into two steps: predicting the next state of each contact point and calculating contact forces based on the prediction and current dynamic state. The first step is solved by learning a classifier from real-world data. By doing so, the second step can be simplified from an LCP to a Linear Program (LP), thus making the calculation of contacts much more efficient.<br/>"
"1715714","RI:  Small:  Collaborative Research:  Information-driven Autonomous Exploration in Uncertain Underwater Environments","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2017","08/13/2017","Xiaobo Tan","MI","Michigan State University","Standard Grant","Reid Simmons","08/31/2020","$265,000.00","","xbtan@msu.edu","Office of Sponsored Programs","East Lansing","MI","488242600","5173555040","CSE","7495, 8013","7495, 7923","$0.00","This project develops the theory and algorithms for autonomous navigation of mobile sensing platforms, such as unmanned ground, aerial, and underwater vehicles, so that the collected information is maximized while constraints on movement capabilities and energy expenditure are accommodated. This work facilitates the use of autonomous robots in environmental monitoring, search and rescue, surveillance and security, among other applications of societal importance. The algorithms are evaluated in field trials using unique gliding robotic fish.  The project provides training for both graduate and undergraduate students, including those from underrepresented groups. Through showcasing at the Museum of Science and Industry in Chicago and offering of an open-source robotic fish education kit, the project promotes the interest of K-12 students and the general public in science and engineering. The project further facilitates transfer of software and hardware for robotic sensing to the market.<br/><br/>The goal of this project is to bridge the gap between the theory and practice in information-driven mobile sensing and to develop a principled theoretic and algorithmic framework for autonomous exploration in uncertain, specifically underwater, environments. The approach exploits the concept of ergodic exploration, where the underlying optimization problem is solved using methods from nonlinear optimal control. The research consists of: 1) Establishing a rigorous theoretical framework for ergodic exploration for guaranteeing solution well-posedness and stability, and developing synthesis methods for real-time control; 2) exploring active probing of flow conditions via auxiliary measurement of tracer agents to mitigate environmental uncertainty; 3) investigating collaborative exploration schemes that strike balance among performance, complexity, and robustness; and 4) conducting field experiments to validate the framework using a group of gliding robotic fish to monitor harmful algal blooms and localize sources of chemical spills.<br/>"
"1830554","NRI: INT: COLLAB: Synergetic Drone Delivery Network in Metropolis","ECCS","National Robotics Initiative","09/15/2018","09/07/2018","Marco Pavone","CA","Stanford University","Standard Grant","Radhakisan S. Baheti","08/31/2021","$287,313.00","","pavone@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","ENG","8013","8086","$0.00","Synergetic Drone Delivery Network in Metropolis<br/><br/><br/>The rapid growth of e-commerce demands has put additional strain on dense urban communities resulting in increased traffic of delivery trucks while slowing down the pace of delivery operations. With recent quick-purchase innovations like the Amazon Dash button, e-commerce drastically modified the consumers behavior to buy smaller products separately and regularly, adding more load to delivery operations. Another growing trend is the offering of fast delivery services such as same-day and instant delivery. Instacart, Uber Eats and Amazon Now are examples of services that can fulfill a delivery order in just under 2 hours. These services rely heavily on the infrastructure of ride-sharing vehicles as Uber or Lyft drivers. This solution offers great flexibility to the consumer, but a single person can only deliver one purchase order to a customer at a time, and it is not scalable or cost-effective.  There is an unquestionable need to redesign the current method of distribution packages in urban environments. This project envisions a framework that synergizes manipulatable distribution networks, comprising autonomous flying robots (drones) with existing transport networks, towards enhanced autonomy and economics in logistics. Imagine that a ride-sharing vehicle outfitted with a docking device for packages on its roof is traveling through a distribution center towards downtown. A drone can place a package on the vehicle's roof while it drives by the distribution center, and another drone can recover the package once the vehicle is driving through another distribution center in proximity to its destination. An operator that owns several base stations, at each of which it employs a network of drones to pick packages from the respective base station and drop it on a ground vehicle assigned to the package, is a required assumption by the framework. The ground vehicles can be public transport vehicles (PTVs), ride-sharing vehicles (RSVs), or operator owned vehicles (OOVs), which carry the package for most of the distance.<br/><br/>The approach relies on three main thrusts: i) socially aware robotics, ii) safe and robust motion planning and execution, iii) cooperative network logistics. Motion planning for robots will be developed with account of peoples perception of safety, privacy, and comfort. Socially-aware motion planning methods to generate trajectories with guarantees of safety in the presence of obstacles and humans will be developed. Psychological experiments will be developed to study human's subtle behavior in response to the presence of multiple drones using virtual reality test environment. Local control algorithms will be developed for each drone to follow a feasible collision free path. Robust local communication protocols will be investigated so that flying robots can perform collaborative tasks over busy air/ground traffic conditions and unreliable communication networks. Another objective is to achieve robust and safe rendezvous with fast moving vehicles under communication, schedule, and other modeling uncertainties. Algorithms that generate (possibly multi-hop) routes for each package, consisting of vehicle route segments, with the objective of minimizing cumulative delivery time, will be developed. The series of vehicle segments on which each package travels, and the associated schedule, is required as input for drones.  This in turn necessitates solving the underlying network design problem for the centralized entity, to determine locations of distribution centers (bases) and number of OOVs required for feasible and reliable delivery of all packages, while explicitly estimating uncertainty from traffic trends and overall frequency of travel of RSVs between various points in the network. Game-theoretic mechanisms that incentivize cooperation among multiple independent operators of PSVs and RSVs will be developed. Mechanisms have to be specifically designed to ensure truthful bidding, because the objectives of the operator, the RSVs and the PSVs are not naturally aligned.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830512","NRI: INT: COLLAB: Synergetic Drone Delivery Network in Metropolis","ECCS","National Robotics Initiative","09/15/2018","09/07/2018","Xiaofeng Wang","SC","University of South Carolina at Columbia","Standard Grant","Radhakisan S. Baheti","08/31/2021","$175,000.00","","wangxi@cec.sc.edu","Sponsored Awards Management","COLUMBIA","SC","292080001","8037777093","ENG","8013","8086","$0.00","Synergetic Drone Delivery Network in Metropolis<br/><br/><br/>The rapid growth of e-commerce demands has put additional strain on dense urban communities resulting in increased traffic of delivery trucks while slowing down the pace of delivery operations. With recent quick-purchase innovations like the Amazon Dash button, e-commerce drastically modified the consumers behavior to buy smaller products separately and regularly, adding more load to delivery operations. Another growing trend is the offering of fast delivery services such as same-day and instant delivery. Instacart, Uber Eats and Amazon Now are examples of services that can fulfill a delivery order in just under 2 hours. These services rely heavily on the infrastructure of ride-sharing vehicles as Uber or Lyft drivers. This solution offers great flexibility to the consumer, but a single person can only deliver one purchase order to a customer at a time, and it is not scalable or cost-effective.  There is an unquestionable need to redesign the current method of distribution packages in urban environments. This project envisions a framework that synergizes manipulatable distribution networks, comprising autonomous flying robots (drones) with existing transport networks, towards enhanced autonomy and economics in logistics. Imagine that a ride-sharing vehicle outfitted with a docking device for packages on its roof is traveling through a distribution center towards downtown. A drone can place a package on the vehicle's roof while it drives by the distribution center, and another drone can recover the package once the vehicle is driving through another distribution center in proximity to its destination. An operator that owns several base stations, at each of which it employs a network of drones to pick packages from the respective base station and drop it on a ground vehicle assigned to the package, is a required assumption by the framework. The ground vehicles can be public transport vehicles (PTVs), ride-sharing vehicles (RSVs), or operator owned vehicles (OOVs), which carry the package for most of the distance.<br/><br/>The approach relies on three main thrusts: i) socially aware robotics, ii) safe and robust motion planning and execution, iii) cooperative network logistics. Motion planning for robots will be developed with account of peoples perception of safety, privacy, and comfort. Socially-aware motion planning methods to generate trajectories with guarantees of safety in the presence of obstacles and humans will be developed. Psychological experiments will be developed to study human's subtle behavior in response to the presence of multiple drones using virtual reality test environment. Local control algorithms will be developed for each drone to follow a feasible collision free path. Robust local communication protocols will be investigated so that flying robots can perform collaborative tasks over busy air/ground traffic conditions and unreliable communication networks. Another objective is to achieve robust and safe rendezvous with fast moving vehicles under communication, schedule, and other modeling uncertainties. Algorithms that generate (possibly multi-hop) routes for each package, consisting of vehicle route segments, with the objective of minimizing cumulative delivery time, will be developed. The series of vehicle segments on which each package travels, and the associated schedule, is required as input for drones.  This in turn necessitates solving the underlying network design problem for the centralized entity, to determine locations of distribution centers (bases) and number of OOVs required for feasible and reliable delivery of all packages, while explicitly estimating uncertainty from traffic trends and overall frequency of travel of RSVs between various points in the network. Game-theoretic mechanisms that incentivize cooperation among multiple independent operators of PSVs and RSVs will be developed. Mechanisms have to be specifically designed to ensure truthful bidding, because the objectives of the operator, the RSVs and the PSVs are not naturally aligned.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1726865","MRI: Development of a Next-Generation 3-D Printer for Smart Product Design - Purdue PolymerMakers","CNS","MAJOR RESEARCH INSTRUMENTATION, INFORMATION TECHNOLOGY RESEARC, IIS SPECIAL PROJECTS","10/01/2017","09/15/2017","Richard Voyles","IN","Purdue University","Standard Grant","Rita V. Rodriguez","09/30/2020","$1,867,017.00","Karthik Ramani, Bedrich Benes, Wenzhuo Wu, Brittany Newell","rvoyles@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","1189, 1640, 7484","1189","$0.00","This project, developing an entirely new generation of 3D printers, aims to enable new areas of research into co-design, robotic meta-materials, soft robotics, nano-structures, neuromorphic architectures, and planning. This new generation of 3D printers (Purdue PolymerMaker 3-D Smart Printers) will realize the structure of a prototype (form) in addition to its sensors, computation, and actuation (function) that make it work, ushering a new era of smart product design that will be achieved through a combination of 3-D printing of polymer structure, 2-1/2 D printing of polymer electronics for sensing, computation and actuation, 3-D printing liquid metal interconnect, and automated planning for over-molding of non-polymer components, such as silicon microprocessors and electromagnetic motors. This work relies on the solid work of a large number of researchers in a variety of disciplines. The invention of polymers had a sudden impact on the form of objects designers could design. The invention of polymer 3-D printing has a more dramatic impact on how innovators could realize prototypes of those exciting new forms. The expected next giant leap in polymers and design will be the simultaneous realization of both form and function. Imagine creating an entire smart product prototype at the press of a button!<br/><br/>The deposition of polymers, either as a structure, as active semiconductor, or as activated sensing site, depends on the surface it adheres to, the environment, and the process steps that follow deposition. This project proposes to select and develop automated processes and materials that, when integrated, are carefully selected and tuned to ""minimize impedance mismatches"" at the interfacial boundaries. The mechatronic integration of precise, closed-loop, motion control for deposition and curing will assure materials are placed when and where needed. Micro-active doctor blading will be employed to locally level the thick extruded liquids. The blade is robotically controlled. <br/><br/>Broader Impacts:<br/>This new generation of 3-D printers will cut across most fields, allowing social and behavioral scientists to explore new forms of technology, medical and biological experts to print new types of smart assays, educators from ""K to Gray"" to develop new hands-on activities, and engineers and computer scientists to do their jobs faster and with greater impact. Graduate and undergraduate students will be engaged in new class materials to reach out to K-12 schools with Science, Technology, Engineering, Math-related recruitment drives and activity camps, and to create new start-ups in many fields. A new Purdue-sponsored inner city high school will offer new avenues of long-term outreach with robotics focus, as well as a university-wide examination of robotics curriculum across 13 departments and 5 colleges where aspects of this work will be embraced."
"1826990","An Optimization Approach for Nonlinear Optimal Feedback Control Design and Uncertainty Propagation","CMMI","Dynamics, Control and System D","08/15/2017","03/15/2018","Puneet Singla","PA","Pennsylvania State Univ University Park","Standard Grant","Robert Landers","08/31/2019","$317,761.00","","psingla@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","ENG","7569","030E, 034E, 8024","$0.00","The multi-resolution articulation abilities of the next-generation autonomous systems, used in advanced robotics, rehabilitation, tele-operation, manufacturing and infrastructure applications are made possible by unique designs and complex mechanisms. These next generation robotic systems can benefit greatly by the development of computationally efficient tools to synthesize optimal feedback control laws to achieve specified output signal statistics in presence of model and sensing uncertainties. To support commercial applications such as package delivery, it is imperative that the robotic systems operating in uncertain environments negotiate specific waypoints with prescribed tolerance. This unique challenge of routing the vehicles operating in uncertain environments involves a strong coupling between the uncertainty propagation and control. Successful negotiation of this challenge is contingent on the development of stable optimal feedback control laws, while accounting for the uncertainties that pervade dynamical systems. The fundamental formalisms that underpin this research are widely applicable to the control of next generation robotic systems and unmanned vehicles. The project includes plans to integrate research into educational efforts involving graduate and undergraduate students, including expanding efforts to reach under-represented populations in science and engineering. Outreach activities include the technical interchange meetings with local school teachers and instituting robotics related tutorial courses to motivate middle and high school students.<br/><br/>The focus of the research is to investigate a unified approach to stable optimal feedback control laws and uncertainty propagation methods by developing computationally efficient solutions to the Hamilton Jacobi Bellman (HJB) and Fokker-Planck-Kolmogorov (FPK) partial differential equations (PDEs), respectively. Recent advances in sparse approximation and non-product quadrature rules are exploited to solve the HJB and FPK equations. The intellectual merits are drawn from advancing the state of knowledge in uncertainty quantification, optimal control theory, and numerical analysis, and integrating them effectively to realize a scalable framework for study of dynamical systems. The Conjugate Unscented Transformation (CUT) technique in conjunction with sparse approximation methods forms an enabling tool to drive the uncertainty propagation and optimal feedback control realization processes. This research culminates in the development of nonlinear stable feedback control laws for uncertain dynamic systems, impacting various estimation and control problems in engineering. The proposed research will be demonstrated on several benchmark problems, along with two key applications involving optimal momentum transfer in control of gyroscopic systems and surveillance of a ground region with the help of unmanned vehicles.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830639","NRI: INT: COLLAB: Synergetic Drone Delivery Network in Metropolis","ECCS","National Robotics Initiative","09/15/2018","09/07/2018","Naira Hovakimyan","IL","University of Illinois at Urbana-Champaign","Standard Grant","Radhakisan S. Baheti","08/31/2021","$1,037,687.00","Ranxiao Wang, Srinivasa Salapaka, Lavanya Marla","nhovakim@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","8013","8086, 9102","$0.00","Synergetic Drone Delivery Network in Metropolis<br/><br/><br/>The rapid growth of e-commerce demands has put additional strain on dense urban communities resulting in increased traffic of delivery trucks while slowing down the pace of delivery operations. With recent quick-purchase innovations like the Amazon Dash button, e-commerce drastically modified the consumers behavior to buy smaller products separately and regularly, adding more load to delivery operations. Another growing trend is the offering of fast delivery services such as same-day and instant delivery. Instacart, Uber Eats and Amazon Now are examples of services that can fulfill a delivery order in just under 2 hours. These services rely heavily on the infrastructure of ride-sharing vehicles as Uber or Lyft drivers. This solution offers great flexibility to the consumer, but a single person can only deliver one purchase order to a customer at a time, and it is not scalable or cost-effective.  There is an unquestionable need to redesign the current method of distribution packages in urban environments. This project envisions a framework that synergizes manipulatable distribution networks, comprising autonomous flying robots (drones) with existing transport networks, towards enhanced autonomy and economics in logistics. Imagine that a ride-sharing vehicle outfitted with a docking device for packages on its roof is traveling through a distribution center towards downtown. A drone can place a package on the vehicle's roof while it drives by the distribution center, and another drone can recover the package once the vehicle is driving through another distribution center in proximity to its destination. An operator that owns several base stations, at each of which it employs a network of drones to pick packages from the respective base station and drop it on a ground vehicle assigned to the package, is a required assumption by the framework. The ground vehicles can be public transport vehicles (PTVs), ride-sharing vehicles (RSVs), or operator owned vehicles (OOVs), which carry the package for most of the distance.<br/><br/>The approach relies on three main thrusts: i) socially aware robotics, ii) safe and robust motion planning and execution, iii) cooperative network logistics. Motion planning for robots will be developed with account of peoples perception of safety, privacy, and comfort. Socially-aware motion planning methods to generate trajectories with guarantees of safety in the presence of obstacles and humans will be developed. Psychological experiments will be developed to study human's subtle behavior in response to the presence of multiple drones using virtual reality test environment. Local control algorithms will be developed for each drone to follow a feasible collision free path. Robust local communication protocols will be investigated so that flying robots can perform collaborative tasks over busy air/ground traffic conditions and unreliable communication networks. Another objective is to achieve robust and safe rendezvous with fast moving vehicles under communication, schedule, and other modeling uncertainties. Algorithms that generate (possibly multi-hop) routes for each package, consisting of vehicle route segments, with the objective of minimizing cumulative delivery time, will be developed. The series of vehicle segments on which each package travels, and the associated schedule, is required as input for drones.  This in turn necessitates solving the underlying network design problem for the centralized entity, to determine locations of distribution centers (bases) and number of OOVs required for feasible and reliable delivery of all packages, while explicitly estimating uncertainty from traffic trends and overall frequency of travel of RSVs between various points in the network. Game-theoretic mechanisms that incentivize cooperation among multiple independent operators of PSVs and RSVs will be developed. Mechanisms have to be specifically designed to ensure truthful bidding, because the objectives of the operator, the RSVs and the PSVs are not naturally aligned.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1421168","RI: Small: Robot Developmental Learning of Skilled Actions","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2014","08/22/2014","Benjamin Kuipers","MI","University of Michigan Ann Arbor","Standard Grant","Reid Simmons","08/31/2019","$446,823.00","","kuipers@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","7495, 8013","7495, 7923, 8086","$0.00","The goal of this project is to show how a robot --- using a continuous stream of visual and tactile data --- can learn to work at a human level of skill in tasks normally done by humans.  To function at a human level, it must be able to plan with ""object-level"" abstractions such as putting a red block into the box, and it must also be able to grasp objects and move them while avoiding bumping into things and causing damage to its surroundings.  This project is inspired by human cognitive development.  A baby learns about objects and actions by bootstrapping from early regularities and unreliable actions to hierarchies of more complex and reliable actions.  The hypothesis to be tested is that this bootstrap learning approach allows a robot to achieve human levels of skillful and robust action in a wide range of human-dominated environments.<br/><br/>This project draws on extensive prior work on foundational knowledge representations and machine learning.  Learning begins by detecting low-level contingencies --- regularities among observed events --- and refining them into increasingly accurate predictive rules, that can be used to define reliable actions.  For a given rule, a simple MDP model is formulated, and reinforcement learning methods learn a policy for accomplishing an action at the next level of the action hierarchy.  Learned actions are initially unreliable, but policies and actions improve with experience.  Attention is focused where learning is likely to be most productive by intrinsic motivation methods that reward actions that result in successful learning, including the important special case of rewarding attempts to imitate the successful actions of other agents."
"1703340","RI: Medium: Collaborative Research: Experimental and Robotics Investigations of Multi-Scale Spatial Memory Consolidation in Complex Environments","IIS","ROBUST INTELLIGENCE","09/01/2017","09/01/2017","Jean-Marc Fellous","AZ","University of Arizona","Standard Grant","Kenneth C. Whang","08/31/2021","$500,516.00","","fellous@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","CSE","7495","7495, 7924, 8089","$0.00","Navigation technologies are an increasingly important component of everyday life in an ever more dynamic and complex world. One limitation of these technologies is that they are optimized for a specific spatial scale. Another limitation is that they do not use the knowledge of previous navigation to compute new paths, essentially starting from scratch every time they are invoked. Recent evidence shows, however, that the mammalian brain has evolved to use multiple spatial navigation scales in parallel, and to use spatial memory to improve path planning. How these scales are used and what advantages such uses provide are still unknown. This project hypothesizes that multiscale spatial navigation is crucial in large and cluttered environments. Experiments recording from the neurons of the ""brain GPS"" system of the rodent (an excellent and efficient spatial navigator) seek to elucidate the basic principles of memory-based multiscale spatial navigation. These experiments will inform new algorithms that will be implemented on a computer to simulate complex multiscale spatial navigation, mimicking the neural computations of the brain. The simulations will then be tested and improved on actual autonomous mobile robots navigating in challenging complex environments.<br/><br/>The project will use wireless high density neural recording technologies allowing for parallel recording of large populations of individual neurons. Optogenetic techniques will be used to manipulate the activity of these neurons and study their impact on the behavior and spatial memory of the animal. The multiscale pattern of neural activity will be used in the development of a mechanistic computational model, which will be tested in new and arbitrary simulated environments, and generate predictions as to how the neural system might succeed or fail. Finally, the simulations will be ported onto a mobile robot, where the algorithms can be tested and improved when the robot is faced with real sensor noise and unreliable world features."
"1703225","RI: Medium: Collaborative Research: Experimental and Robotics Investigations of Multi-Scale Spatial Memory Consolidation in Complex Environments","IIS","ROBUST INTELLIGENCE","09/01/2017","09/01/2017","Alfredo Weitzenfeld","FL","University of South Florida","Standard Grant","Kenneth C. Whang","08/31/2021","$494,420.00","","aweitzenfeld@usf.edu","3702 Spectrum Blvd.","Tampa","FL","336129446","8139742897","CSE","7495","7495, 7924, 8089","$0.00","Navigation technologies are an increasingly important component of everyday life in an ever more dynamic and complex world. One limitation of these technologies is that they are optimized for a specific spatial scale. Another limitation is that they do not use the knowledge of previous navigation to compute new paths, essentially starting from scratch every time they are invoked. Recent evidence shows, however, that the mammalian brain has evolved to use multiple spatial navigation scales in parallel, and to use spatial memory to improve path planning. How these scales are used and what advantages such uses provide are still unknown. This project hypothesizes that multiscale spatial navigation is crucial in large and cluttered environments. Experiments recording from the neurons of the ""brain GPS"" system of the rodent (an excellent and efficient spatial navigator) seek to elucidate the basic principles of memory-based multiscale spatial navigation. These experiments will inform new algorithms that will be implemented on a computer to simulate complex multiscale spatial navigation, mimicking the neural computations of the brain. The simulations will then be tested and improved on actual autonomous mobile robots navigating in challenging complex environments.<br/><br/>The project will use wireless high density neural recording technologies allowing for parallel recording of large populations of individual neurons. Optogenetic techniques will be used to manipulate the activity of these neurons and study their impact on the behavior and spatial memory of the animal. The multiscale pattern of neural activity will be used in the development of a mechanistic computational model, which will be tested in new and arbitrary simulated environments, and generate predictions as to how the neural system might succeed or fail. Finally, the simulations will be ported onto a mobile robot, where the algorithms can be tested and improved when the robot is faced with real sensor noise and unreliable world features."
"1617744","RI: Small: Taming Combinatorial Challenges in Multi-Object Manipulation","IIS","ROBUST INTELLIGENCE","09/01/2016","07/24/2017","Kostas Bekris","NJ","Rutgers University New Brunswick","Continuing grant","Reid Simmons","08/31/2019","$468,390.00","Jingjin Yu","kostas.bekris@cs.rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","7495","7495, 7923","$0.00","A key challenge in many autonomous robot manipulation applications is<br/>the rearrangement of multiple objects.  There are two situations where<br/>such needs arise: (i) the manipulation task itself is to rearrange<br/>objects, and (ii) occluding items must be rearranged to allow the<br/>robot access to the target object(s). Examples of such scenarios can<br/>arise in warehouses and industrial setups, where a robot has to<br/>frequently select, pick and transfer products, packages and pallets in<br/>the presence of many other similar objects. Another example comes from<br/>service robotics, where a robotic assistant that operates in a human<br/>space has to frequently retrieve or rearrange multiple items placed in<br/>narrow spaces, such as objects in shelves.<br/><br/>This project investigates which classes of multi-object manipulation<br/>planning can be efficiently addressed given progress in multi-body<br/>motion planning and develops a powerful suite of novel computational<br/>solutions.  The key insight is that for many real-world rearrangement<br/>tasks the sequence of object motions to solve the problem, ignoring<br/>grasping aspects, look similar to solutions of multi-body motion<br/>planning, especially for similar sized objects. The study of this link<br/>reveals it is possible to cast certain multi-object manipulation<br/>problems as a ""pebble motion problem on a graph"", which is well<br/>studied in algorithmic theory and multi-body motion planning. The<br/>overall objective is to provide rigorous methods with desirable<br/>completeness and optimality guarantees for multi-object manipulation,<br/>which exhibit good scalability and efficiency for problems where<br/>current methods face issues with the inherent combinatorial<br/>complexity.  Such methods could also be used as guiding heuristics for<br/>tasks with additional constraints, such as non-trivial dynamics and<br/>uncertainty."
"1759150","Trans-disciplinary Education in Biology and Engineering Technology","DRL","ITEST","08/01/2018","07/16/2018","Stephanie Rollmann","OH","University of Cincinnati Main Campus","Standard Grant","Brian K. Smith","07/31/2021","$1,198,120.00","Bridgette Peteet, John Layne, Dieter Vanderelst, Kathie Maynard","stephanie.rollmann@uc.edu","University Hall, Suite 530","Cincinnati","OH","452210222","5135564358","EHR","7227","","$0.00","This project focuses on increasing diversity in STEM and increasing student and teacher experiences and competency in the fields of biology and engineering. An integrated education program at the intersection of biology and engineering - the sensory guidance of behavior in biological organisms and autonomous robots - will be developed and studied. The project will consist of: (a) an integrated three-week summer program for rising 12th-grade students and in-service secondary education teachers; (b) a college credit course and workshops for students during their 12th grade school year, and; (c) paid summer internships upon graduation. In these programs, students will engage in hands-on biological investigations to learn how animals sense and respond to their environments. They will then integrate scientific principles with authentic engineering technology to build and program robots based on animals. The robots will be equipped with sensors and behaviors and execute tasks designed by the students. Subsequent internships will serve to further connect student knowledge of integrated biology and engineering with real-world experiences. Creating this program under the framework of animal/robot sensorimotor systems is particularly timely since biology and robotics are producing exciting, emerging technologies and are major growth industries. This project will advance efforts of the Innovative Technology Experiences for Students and Teachers (ITEST) program to better understand and promote practices that increase student motivations and capacities to pursue careers in fields of science, technology, engineering, or mathematics (STEM).<br/><br/>The research seeks to (1) increase awareness and participation of underrepresented groups in STEM fields; (2) increase interest, attitudes, knowledge, and self-efficacy in biology, engineering, and technology fields and occupations, and; (3) develop a model to educate students and to train teachers in concepts that examine the interrelatedness between science and engineering. The project's formative and summative evaluation methods, including surveys, focus groups, and open-ended evaluations of workshop and internship experiences, will be used to study these issues. The research will contribute new insights into integrated STEM curricula and how they support students in developing and sustaining interests in learning and working in scientific fields. The project also engages underrepresented youth in critical thinking, problem-solving, and real-world investigations in biology and engineering that may lead them to pursue STEM careers.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1449155","EAGER: Toward Ethical Intelligent Autonomous Systems, A Case-Supported Principle-Based Behavior Paradigm","IIS","Cyber-Human Systems (CHS)","09/01/2014","05/31/2018","Michael Anderson","CT","University of Hartford","Standard Grant","Ephraim P. Glinert","08/31/2019","$241,193.00","","anderson@hartford.edu","200 Bloomfield Avenue","West Hartford","CT","061171545","8607685938","CSE","7367","7367, 7916","$0.00","Intelligent autonomous systems (IAMs) are on the verge of being widely deployed in domains in which they will interact closely with people (e.g., personal assistance, healthcare, driverless cars, search and rescue), and they will be expected to navigate this ethically-charged landscape responsibly.  As correct ethical behavior not only involves not doing certain things, but also doing certain things to bring about an ideal state of affairs, ethical issues concerning the behavior of IAMs are likely to elude simple, static solutions and exceed the grasp of their designers.  The PI argues that the behavior of such systems should be guided by explicit ethical principles abstracted from particular cases where a consensus of ethicists exists.  Laying the foundations for such technology is the focus of this exploratory research.  Project outcomes will help alleviate concerns with intelligent autonomous systems, since the behavior of such systems guided by ethical principles is likely to be more acceptable in real-world environments than that of such systems without this dimension.  Indeed, ethical intelligent autonomous systems capable of functioning with more autonomy might be permitted to assist human beings in a wider range of domains.  The PI expects that an important byproduct of this work is that a more thorough understanding of the ethical theory involved is likely to result, as it is made concrete.<br/><br/> To ensure correct ethical behavior, IAMs should weigh alternative possible actions against each other to determine which is ethically preferable at any given moment.  The PI will leverage his previous research in developing and deploying principles that weigh the ethical preference of actions, and justify action choices for autonomous systems across multiple domains, to develop a paradigm of case-supported principle-based behavior (CPB) in which intensionally defined ethical action preference is abstracted from particular cases of ethical dilemmas and used to order ethically significant actions.  The PI will refine and codify CPB using the domain of eldercare robots as a test bed by, first employing a virtual component based upon simulation and then reifying this simulation in a laboratory setting.  In particular, the PI will define a comprehensive set of ethically significant actions for an eldercare robot.  He will then develop and validate via an Ethical Turing Test an ethical principle that can be used to order this set by ethical preferences, and use this principle to guide the behavior of a simulated Unbounded Robotics UBR-1 robot with this set of behaviors situated in a Gazebo simulation of an assisted-living facility.  He will next reify this simulation with an actual UBR-1 robot in a laboratory setting.  Finally, he will refine and codify the requirements, methods, implementation specifics, and testing aspects of the case-supported principle-based behavior paradigm.  Besides developing and implementing a general methodology for ensuring ethical behavior in intelligent autonomous systems, this research will provide evidence that ethical principles and decision-making can be computed and function effectively in domains where machines are likely to interact with human beings."
"1526016","NRI: Collaborative Research: Enabling Risk-Aware Decision Making in Human-Guided Unmanned Surface Vehicle Teams","ECCS","National Robotics Initiative","09/01/2015","09/03/2015","Karl von Ellenrieder","FL","Florida Atlantic University","Standard Grant","Radhakisan S. Baheti","05/31/2019","$449,520.00","","ellenrie@fau.edu","777 GLADES RD","BOCA RATON","FL","334316424","5612970777","ENG","8013","092E, 8086","$0.00","Over the last ten years, substantial progress has been made in the development of small low-cost unmanned surface vehicles (USVs). There are a number of civilian applications where deploying a human-robot team consisting of several small USVs and one or more human supervisors can significantly reduce costs, improve safety, and increase operational efficiencies. Representative applications include remote/persistent ocean sensing, marine search and rescue, maritime operations in congested port environments, and industrial offshore supply and support. USVs face unique challenges that are not experienced by robots operating indoors, such as: the need to adhere to marine navigation rules (COLREGs); local current, wave and wind conditions that can severely reduce the dynamic range of sensors and actuators; frequent communication interruptions; and risk and urgency due to rapidly changing situations during outdoor on-water operations. This research aims to develop decision making foundations for enabling teams of humans and USVs to perform complex collaborative tasks. Advances in this area could be extremely important from both a regulatory and practical standpoint for the future deployment of USV systems. Results from this research will enable leveraging the tremendous potential of USVs by reducing the cost of deployment and operational risks in civilian applications. The integration of the research with graduate and undergraduate courses will enhance the robotics and ocean engineering curricula and enrich learning experiences of the participating students. Outreach activities will educate and inform K-12 students about career opportunities in marine robotics. <br/> <br/>The overall goal of the proposed effort is to make advances in risk-informed decision making so that teams of USVs and human supervisors can work cooperatively on a wide variety of missions. The proposed work will develop a comprehensive distributed decision making approach by leveraging the latest advances in task coordination and assignment, planning, reactive behaviors, and control to enable the deployment of human-guided USV teams in civilian applications. Progress in these constituent components will be pursued to ensure that they are consistent with each other and to explicitly account for risk during decision making. This research will develop methodologies to model team missions to ensure that all phases of decision making will have the required information for making informed decisions. Decision making methodologies will be developed for sparse advisory control of USV teams to mitigate risks and for coordinating and assigning tasks to different USVs in the team. Algorithms will also be developed for risk-aware deliberative trajectory planning and generating and executing reactive behaviors for mitigating risks. The methods developed will be validated through on-water field experiments."
"1513108","CI-NEW: Collaborative Research: A Modular Platform for Enabling Computing Research in Intelligent Human-Robot Interaction","CNS","COMPUTING RES INFRASTRUCTURE","06/01/2015","06/05/2015","Mark Yim","PA","University of Pennsylvania","Standard Grant","Reid Simmons","05/31/2019","$675,000.00","Simon Kim","yim@grasp.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7359","7359","$0.00","This project is to design, develop, and freely distribute novel, affordable, modular hardware and accompanying software platforms for enabling non-contact human-robot interaction (HRI) research. Such research is a significant portion of HRI today, and encompasses a broad spectrum of computing challenges and compelling application domains, including education, training, rehabilitation, and health. The goal of this project is to significantly increase access to hardware to a large body of researchers, so that computing advances can be applied to physical systems and evaluated in real-world environments, in order to drive progress in the computing community.<br/><br/>Advances in sensor and communication technologies have facilitated progress in computing research on physical platforms. The field of human-robot interaction in particular has grown significantly and actively brings together an interdisciplinary community of researchers across computing, robotics, and social science. However, progress has been limited by the lack of affordable, general-purpose, modular hardware platforms with available low-level software that would enable large numbers of computing researchers to enter the field and develop and test algorithms, as well as conduct statistically significant user studies by deploying systems in the real world and collecting user data to inform further computational research in HRI."
"1634433","NRI: Collaborative Research: Enabling Risk-Aware Decision Making in Human-Guided Unmanned Surface Vehicle Teams","ECCS","National Robotics Initiative","01/06/2016","03/14/2016","Satyandra Gupta","CA","University of Southern California","Standard Grant","Radhakisan S. Baheti","08/31/2019","$526,167.00","","guptask@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","ENG","8013","092E, 8086","$0.00","Over the last ten years, substantial progress has been made in the development of small low-cost unmanned surface vehicles (USVs). There are a number of civilian applications where deploying a human-robot team consisting of several small USVs and one or more human supervisors can significantly reduce costs, improve safety, and increase operational efficiencies. Representative applications include remote/persistent ocean sensing, marine search and rescue, maritime operations in congested port environments, and industrial offshore supply and support. USVs face unique challenges that are not experienced by robots operating indoors, such as: the need to adhere to marine navigation rules (COLREGs); local current, wave and wind conditions that can severely reduce the dynamic range of sensors and actuators; frequent communication interruptions; and risk and urgency due to rapidly changing situations during outdoor on-water operations. This research aims to develop decision making foundations for enabling teams of humans and USVs to perform complex collaborative tasks. Advances in this area could be extremely important from both a regulatory and practical standpoint for the future deployment of USV systems. Results from this research will enable leveraging the tremendous potential of USVs by reducing the cost of deployment and operational risks in civilian applications. The integration of the research with graduate and undergraduate courses will enhance the robotics and ocean engineering curricula and enrich learning experiences of the participating students. Outreach activities will educate and inform K-12 students about career opportunities in marine robotics. <br/> <br/>The overall goal of the proposed effort is to make advances in risk-informed decision making so that teams of USVs and human supervisors can work cooperatively on a wide variety of missions. The proposed work will develop a comprehensive distributed decision making approach by leveraging the latest advances in task coordination and assignment, planning, reactive behaviors, and control to enable the deployment of human-guided USV teams in civilian applications. Progress in these constituent components will be pursued to ensure that they are consistent with each other and to explicitly account for risk during decision making. This research will develop methodologies to model team missions to ensure that all phases of decision making will have the required information for making informed decisions. Decision making methodologies will be developed for sparse advisory control of USV teams to mitigate risks and for coordinating and assigning tasks to different USVs in the team. Algorithms will also be developed for risk-aware deliberative trajectory planning and generating and executing reactive behaviors for mitigating risks. The methods developed will be validated through on-water field experiments."
"1208626","NRI-Small: Measuring Unconstrained Grasp Forces Using Fingernail Imaging","IIS","National Robotics Initiative","08/01/2012","07/18/2012","Stephen Mascaro","UT","University of Utah","Standard Grant","Jie Yang","09/30/2018","$917,999.00","John Hollerbach","smascaro@mech.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","8013","7923, 8086, 9150","$0.00","This project develops the technology for unconstrained measurement of human grasp forces. Measurement of multi-fingered grasp forces typically requires a human to grasp an object at predefined sensor locations or to wear instrumented gloves that impede haptic sensations. The objective of this project is to characterize the ability to estimate three-dimensional grasp forces at the fingertips by measuring the color change of the fingernail.  This fingernail imaging technique allows the human subject to freely choose where to place the fingers on the object, allowing for completely unconstrained multi-finger grasping. A magnetic levitation device is used to apply a range of 3-D forces to the human fingertip while collecting images of the fingernail.  Various image processing techniques are being explored to register the fingernail images to a standard template, and various mathematical models relating pixel intensity to force are being investigated to determine an optimal method.  A robotic motion-tracking technique is being implemented to keep the fingers in view of the camera as the hand moves during grasping experiments. The fingernail imaging technique is first validated using constrained grasping experiments, and then applied to unconstrained grasping experiments.<br/><br/>This research enables a co-robot to detect the individual finger forces of a human partner using a technique that does not interfere with the human's haptic sense. A co-robot trained with the appropriate calibration data could recognize and emulate or adapt to a human partner's grasp forces, measured using only vision.  Research efforts are being integrated into the Robotics education and outreach at the University of Utah."
"1462555","Leg Mechanics for Dynamic Locomotion","CMMI","ENGINEERING DESIGN AND INNOVAT, Dynamics, Control and System D","08/15/2015","05/11/2018","Ross Hatton","OR","Oregon State University","Standard Grant","Irina Dolinskaya","07/31/2019","$426,901.00","Jonathan Hurst","ross.hatton@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","ENG","1464, 7569","030E, 031E, 032E, 033E, 034E, 067E, 068E, 073E, 116E, 1464, 8024, 9178, 9231, 9251","$0.00","This research moves towards walking and running robots that will meet and exceed the agility, efficiency, and robustness of human walking and running. Specifically, the research will address fundamental principles behind the physical design of legs, including describing configurations of joints, springs, and other components to best enable legged locomotion. This work falls within a broad, interdisciplinary effort to understand leg function and dynamics, and will have utility and impact among the robotics, dynamics, and biomechanics communities. The foundational design guidelines initiated here will enable robots that can go anywhere that animals and humans go, and many places they cannot, such as nuclear power plant disaster areas and burning buildings. The same foundation will enable prosthetic limbs and exoskeletons that match the natural dynamics of a human leg, while running all day on a single battery charge. <br/><br/>This research will enhance understanding of the interaction between the design of a legged system and its dynamics during touchdown, stance, and swing, focusing on three key aspects of the design: First, the inertia distribution in the leg, with an emphasis on how mass placement, number of links, and ""redundant"" elements of leg kinematics (such as pointing the knee ""up"" or ""down"") contribute to the impact felt by the system at touchdown and the dynamics during swing phase.  Second, the motor coupling to the linkages, focusing on how different mappings between actuation and mechanism degrees of freedom can lead to the motors either sharing loads or fighting against each other.  Third, spring function and placement, including desirable nonlinearities for mitigation of impacts and swing-phase ringing, alignment of principle stiffness axes with mechanism degrees of freedom, and transmissions that allow for configuration-dependent elasticity.  The research approach draws on examples from biology and previously constructed robots, utilizes mathematical tools from applied mechanics, and builds on prior work with experimental walking and running robots."
"1657245","CRII: CHS: Improving Dexterous Manipulation with Telerobots Through Operator-Sensitive Haptic Display","IIS","CRII CISE Research Initiation, Cyber-Human Systems (CHS)","08/01/2017","05/04/2018","Jeremy Brown","MD","Johns Hopkins University","Standard Grant","Ephraim P. Glinert","07/31/2019","$190,991.00","","jbrow262@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","026Y, 7367","7367, 8228, 9251","$0.00","Human-in-the-loop tele-robotic systems (HiLTS) should provide their operators with the haptic sensory feedback needed to support dexterous manipulation akin to what is capable with the natural body.  Unfortunately, providing robust kinesthetic haptic feedback often comes at the expense of control stability, which cannot be improved using simplified models of the operator's arm impedance that fail to take into account that individuals typically dynamically modulate this value throughout a given task.  A primary objective of this research is to test the hypothesis that modulation of a kinesthetic haptic device's controlled and/or inherent impedance in accordance with the operator's impedance will improve the interface to and utility of HiLTS.   Improving haptic feedback methodologies is an important area of research in HiLTS, haptic display, and human-machine interaction more generally.  This work will provide a framework for relating haptic device impedance to user impedance and produce a set of generalizable principles for investigating all aspects of haptic device impedance on user impedance.  Ultimately, project outcomes will lead to tele-robots that come closer to being embodied by their operators, thereby allowing for more robust and dexterous manipulation.  The work will have broad impact on a variety of applications including surgical robotics, upper-limb prosthetics, and rehabilitation robotics.  Educational and outreach activities will include conference workshops, a special topics course on HiLTS, lab tours, and summer activities for K-12 and underrepresented students.<br/><br/>Real-time measurements of the operator's arm impedance are possible using only knowledge of muscle activation and joint configuration, and further, these measures can be used as a basis for robotic control and stability.  However, these methods have yet to gain widespread attention in the field of haptic display, where significant potential exists given the coupled nature of the human and device dynamics through a kinesthetic haptic device.  Therefore, improving upon current methods of haptic display, especially for HiLTS, should involve active modulation of the operator's impedance through the haptic device, in a manner consistent with the modulations which occur through physical interaction with the natural limb.  This research will contribute to both a theoretical and empirical understanding of the effect of haptic device impedance on the endpoint arm stiffness of a human user for the purpose of improved utility in HiLTS.  The approach will involve: (1) identifying relationships between endpoint arm stiffness and environment impedance; (2) identifying relationships between endpoint arm stiffness and haptic device impedance; and (3) quantifying the effect of haptic device impedance modulation on endpoint arm stiffness in HiLTS."
"1637927","NRI: A Cognitive Navigation Assistant for the Blind","IIS","National Robotics Initiative","09/01/2016","07/27/2016","Kris Kitani","PA","Carnegie-Mellon University","Standard Grant","Wendy Nilsen","08/31/2019","$1,000,000.00","Manuela Veloso","kkitani@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","8013","8086","$0.00","The focus of this project is on implementation of a navigation assistant that uses a collection of sensing modalities and algorithms to guide a blind person through the knowledge landscape (e.g., social context, visual landmarks, scene functionality) of an unfamiliar environment.  The approach is based on a portfolio of complex processes that provide within a single framework a coherent account of the state of the world, with the help of novel techniques which meld information at various levels of abstraction.  In the near term, project outcomes will directly improve the quality of life for those with visual impairments through public release of a smartphone app.  In the longer term, the societal impact of this research will extend beyond improving sensory capabilities for the blind in that it describes an approach towards human augmentation through the use of machine intelligence.  The work will directly shed light on the variety of environmental knowledge which can be automatically acquired using machine perception, and how that information can be conveyed through a physical co-robot interface.  From an educational perspective, this work will develop important models for integrating knowledge obtained by intelligent machines into one source, and will also develop new theories regarding the translation of that rich knowledge in a manner which can be easily understood by the user.<br/><br/>Leveraging prior work, sensing modalities such as Bluetooth low energy beacons, depth sensors, color cameras and wearable inertial motion units will be used to enable continuous localization within a novel environment.  An additional layer of higher-order algorithms will further build upon physical measurements of location to develop computational contextual awareness, enabling the navigation assistant to understand the knowledge landscape by identifying meaningful visual landmarks, modes of interaction (functionality) within the environment and social context.  This knowledge structure will then be conveyed to the blind user to enable contextual hyper-awareness, that is to say a contextual understanding of the environment which goes beyond normative sensing capabilities, in order to augment the user's ability to navigate the knowledge landscape of the environment.  The navigation assistant will be instantiated as two concrete manifestations: a compact wearable interface, and a physical robotic interface.  The wearable interface will be a smartphone-based system that gives audio-based navigation feedback to facilitate the creation of a cognitive map.  The robotic interface will be a wheeled hardware platform that guides the user through haptic feedback to further reduce the cognitive load of interpreting and following audio feedback.  Both platforms will be refined and evaluated in real-world scenarios based on principles derived from rigorous user studies.  Project outcomes will include a navigation assistant that can help a blind person walk a path through novel indoor or outdoor suburban environments to a desired destination.  The two physical interfaces will also be used to develop working theories and models for co-robot scenarios that must take into account situational context and the preferential dynamics of the user."
"1816343","RI: Small: Robust motion planning for multirobot target tracking","IIS","ROBUST INTELLIGENCE","08/01/2018","07/26/2018","Sourabh Bhattacharya","IA","Iowa State University","Continuing grant","Reid Simmons","07/31/2021","$119,737.00","","sbhattac@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","CSE","7495","7495, 7923","$0.00","Autonomous mobile robots have recently been used for tasks such as surveillance and intruder detection. Coordinating a network of such robots, though, is a difficult task, especially if the people are trying to avoid detection. This research aims to develop a network of autonomous aerial vehicles that can detect and track intruders in farmlands. In the face of recent incidents related to agricultural espionage and biotech piracy in open farms, a robotic intrusion detection system would be helpful to farmers. The techniques developed would also be applicable in areas such as air traffic control, surveillance of transportation networks, and patrol of coastal areas. Through educational and outreach activities, the project aims to create a highly skilled workforce in the growing areas robotics and cyber-security.   <br/><br/>The proposed research tackles the problem of designing robust motion plans for multirobot systems deployed for tracking unpredictable and adversarial targets. A serious challenge in such problems is the lack of information about the targets' future actions. Based on tools from differential game theory, this research develops target allocation and trajectory generation algorithms for a team of observer robots to track multiple intruders, with guarantees on tracking performance. Using a bottom-up approach, a motion planner is proposed for multirobot target tracking that can handle sensing and motion constraints posed by obstacles in the environment, variable number of targets, and noisy sensor and actuator measurements. The proposed research includes testing and validation of the tracking planner on a multi-quadrotor testbed in the PI's lab to detect unauthorized intrusion in agricultural farmlands.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1723520","EAGER: MAKER: Nebraska Innovative Maker Co-laboratory","DRL","ITEST","07/15/2017","07/25/2018","Bradley Barker","NE","University of Nebraska-Lincoln","Standard Grant","Robert Russell","06/30/2019","$358,835.00","Shane Farritor, Jennifer Melander","bbarker@unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","EHR","7227","058Z, 7916, 8212, 8244, 9251","$0.00","This project will advance efforts of the Innovative Technology Experiences for Students and Teachers (ITEST) program to better understand and promote practices that increase students' motivations and capacities to pursue careers in fields of science, technology, engineering, or mathematics (STEM). The project will design, develop and test a Makerspace engagement model that connects geographically dispersed learning communities and mentors participating in Maker activities and spaces to provide informal STEM learning pathways and to broaden participation for STEM activities for youth and their community.  The project will establish a dedicated public library-based Makerspace in a rural, relatively isolated and underserved community with close connections to an anchor space at the University of Nebraska-Lincoln that supports open-ended, self-directed learning, idea exploration, technical skills, entrepreneurship, and collaborative projects.  The project design will bring together experts from a wide variety of fields (e.g., engineering, textiles, photography, robotics, and STEM education) to provide youth with hands-on opportunities in six focus areas, electronics, textiles including e-textiles with wearable electronics, computers, digital media creation, music technology, and digital fabrication.  Youth will select a project and learning pathway based on their interests. Youth will then complete mini-courses and receive certification on the equipment and skills relevant to their chosen project. The expected synergy between virtual collaborative spaces and robotic telepresence will provide opportunities for teams of youth and mentors to collaborate regardless of geographic location and to creatively collaborate, problem solve and innovate. (Telepresence robots are defined as platforms that allow users to perceive that they are operating in another, typically remote physical space via technology.)  <br/><br/>This project focuses on using two main strategies; a) virtual collaborative spaces and b) robotic telepresence, to provide rural youth access to the Maker movement. This model will provide a replicable strategy of reaching rural underserved youth audiences within their communities so that they may establish wider learning communities with experts and mentors and thereby fully participate in the maker experience.  The use of telepresence robotics for focused one-on-one collaboration and guidance in the Makerspace will particularly help to address the physical needs of such mentoring. Virtual innovative lab spaces will allow youth to develop project ideas and engage in collaborative problem solving. The spaces will be accessible via mobile phone based Head-Mounted Displays. Student surveys, observation, social network analysis, and the systematic coding of interactions between youth and mentors will be used to research the nature of the collaboration, problem solving and innovation that occurs through shared making activities."
"1703765","AF:Medium:Collaborative:RUI:Structure in Motion:Algorithms for Kinematic Design","CCF","ALGORITHMIC FOUNDATIONS","06/01/2017","06/20/2018","Ileana Streinu","MA","Smith College","Continuing grant","Rahul Shah","05/31/2021","$445,526.00","","istreinu@smith.edu","10 ELM STREET","Northampton","MA","010636304","4135842700","CSE","7796","7924, 7929, 9229","$0.00","New technologies and techniques in robotics (miniature fabrication), computational biology (DNA assembly), material science (nano-technology), and even origami give rise to new questions in kinematic design ? the design of moving assemblies.  This project addresses the theory and corresponding algorithms for a number of fundamental problems in kinematic design. The goal is to design the shape of a (deformable) geometric object, along with one or a family of its deformation trajectories. In robotics, for instance, one may want to build a robot arm capable of moving its end-effector from any point in a source domain to any point in a destination domain (geometric structure design), in a way that would avoid singularities and collisions (trajectory design). In manufacturing and CAD, one is interested in designing structures that can be assembled from standard smaller parts; for example, a polyhedral surface might be assembled from rigid triangular pieces whose sides are joined together. Another example is folding a 3D origami shape from a creased piece of (flat) paper: both the 3D shape and the folding trajectories have to be designed in advance. The results are anticipated to have an impact on several scientific fields where geometric modeling and geometric simulations are being used, including mechanics, robotics, computational biology and materials science (nano-technology).  The project will engage a diverse population of students, at all levels (post-doc, graduate and undergraduate). The PIs will develop new educational materials related to emerging multidisciplinary connections.<br/><br/>New kinematic design principles rely on the mutual dependence of mobility and structure. Recent results of the PIs on robot-arm singularities and precise positional workspace determination provide insights and techniques for an integrated approach, which coordinates structural parameters and path-planning. For innovative patterns of metamaterials with auxetic capabilities, a rigorous geometric theory of periodic frameworks will be combined with efficient algorithms  for framework generation and visualization. Advancing these methods will throw new light on conformational changes in crystals and biological self-assembly problems."
"1704285","AF:Medium:Collaborative:RUI:Structure in Motion:Algorithms for Kinematic Design","CCF","ALGORITHMIC FOUNDATIONS","06/01/2017","06/20/2018","Ciprian Borcea","NJ","Rider University","Continuing grant","Rahul Shah","05/31/2021","$63,851.00","","borcea@rider.edu","2083 Lawrenceville Road","Lawrenceville","NJ","086480400","6098965000","CSE","7796","7924, 7929, 9229","$0.00","New technologies and techniques in robotics (miniature fabrication), computational biology (DNA assembly), material science (nano-technology), and even origami give rise to new questions in kinematic design ? the design of moving assemblies.  This project addresses the theory and corresponding algorithms for a number of fundamental problems in kinematic design. The goal is to design the shape of a (deformable) geometric object, along with one or a family of its deformation trajectories. In robotics, for instance, one may want to build a robot arm capable of moving its end-effector from any point in a source domain to any point in a destination domain (geometric structure design), in a way that would avoid singularities and collisions (trajectory design). In manufacturing and CAD, one is interested in designing structures that can be assembled from standard smaller parts; for example, a polyhedral surface might be assembled from rigid triangular pieces whose sides are joined together. Another example is folding a 3D origami shape from a creased piece of (flat) paper: both the 3D shape and the folding trajectories have to be designed in advance. The results are anticipated to have an impact on several scientific fields where geometric modeling and geometric simulations are being used, including mechanics, robotics, computational biology and materials science (nano-technology).  The project will engage a diverse population of students, at all levels (post-doc, graduate and undergraduate). The PIs will develop new educational materials related to emerging multidisciplinary connections.<br/><br/>New kinematic design principles rely on the mutual dependence of mobility and structure. Recent results of the PIs on robot-arm singularities and precise positional workspace determination provide insights and techniques for an integrated approach, which coordinates structural parameters and path-planning. For innovative patterns of metamaterials with auxetic capabilities, a rigorous geometric theory of periodic frameworks will be combined with efficient algorithms  for framework generation and visualization. Advancing these methods will throw new light on conformational changes in crystals and biological self-assembly problems."
"1816382","NSF-BSF: RI: Small: Decentralized Active Goal Recognition","IIS","ROBUST INTELLIGENCE","07/01/2018","06/25/2018","Christopher Amato","MA","Northeastern University","Standard Grant","James Donlon","06/30/2021","$469,987.00","","c.amato@northeastern.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","7495","014Z, 7495, 7923","$0.00","Autonomous systems often need to coordinate with other sensors, robots, autonomous cars, and people.  This results in multi-agent systems, in which agents must be able to determine what others are currently doing and predict what they will be doing in the future. This task of plan and goal recognition, typically relies upon a passive observer that continually observes the multi-agent system. In many real-world systems, such as assistive robotics in the home, this is not practical. Real-world systems will require active goal recognition, where information has a cost, and other tasks are pursued and completed continuously during goal recognition. For example, consider a team of robots assisting a disabled or an elderly person. The robots must fetch items and clean areas, while also opening doors or otherwise escorting the person. The agents will have to balance completion of their own tasks with information gathering about the target person's behavior. Current goal recognition methods cannot solve this active goal recognition problem. Furthermore, in realistic multi-agent domains including agricultural applications, disaster assistance, or military settings, communication will be limited or noisy. This will require decentralized active goal recognition methods where agents make choices based on their own limited viewpoints. Developing such active goal recognition methods will be the focus of this research. <br/><br/>More specifically, the research will develop new methods for active goal recognition to allow teams of agents to coordinate with other systems. The project will  develop methods for: active goal recognition, combining the observer's planning problem with goal recognition to balance information gathering with task completion for a single agent (observer) and single target, decentralized active goal recognition, combining multi-agent planning for the observers with goal recognition to balance information gathering with task completion and coordination for multiple observer agents and a single target agent, and decentralized active goal recognition of multiple targets, combining multi-agent planning for the observers with goal recognition to balance information gathering with task completion and coordination for multiple observer agents and target agents. The research will develop a range of methods that are based on classical, information-theoretic and decision- theoretic planning that exploit the special structure in our problem. The work will be tested on a range of common benchmarks, against current methods and in multi-robot domains to ensure realistic experiments. This research will consider active goal recognition (combining an observer's planning problem with goal recognition of a target) in single-agent and decentralized multi-agent environments. The resulting work will greatly extend the usefulness of goal recognition, making it realistic to use in scenarios when information gathering has a cost and other tasks may need to be completed by the observer(s).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1453549","CAREER: Creating Robust, Adaptable Computational Intelligence by Recreating Key Properties of Animal Brains","IIS","ROBUST INTELLIGENCE, EPSCoR Co-Funding","09/01/2015","06/20/2018","Jeff Clune","WY","University of Wyoming","Continuing grant","Kenneth C. Whang","08/31/2020","$472,248.00","","jeffclune@uwyo.edu","1000 E. University Avenue","Laramie","WY","820712000","3077665320","CSE","7495, 9150","1045, 7495, 9150","$0.00","Natural animals display awe-inspiring adaptability and robustness (e.g. three-legged dogs that can still run and catch frisbees). One reason neuroscientists believe animals are so capable is because their brains are structurally organized in that they exhibit neural regularity, modularity, and hierarchy. This project will test whether those neural properties also improve the robustness, adaptability, and overall intelligence of evolved computational agents, specifically robots.  Evolutionary algorithms (EAs) evolve, rather than engineer, computational agents to produce qualities seen in nature, such as robustness and adaptability. While EAs often outperform human engineers, the robot bodies and brains they design pale in comparison to those of natural animals. Recent advances by the PI (Professor Clune) and others enable the evolution of neural networks (computational brains) that exhibit regularity, modularity, and hierarchy.<br/><br/>Professor Clune and his students will test whether regularity, modularity, and hierarchy, separately and in combination, improve (1) robustness to noise (2) robustness to damage (3) adaptability to new environments (4) learning, and (5) overall intelligence, measured as the ability to solve challenges of varying complexities. Based on his previous work and preliminary results, Clune anticipates that neural regularity, modularity, and hierarchy could increase all of these desirable behavioral qualities. Such knowledge will accelerate humanity's ability to deploy effective, autonomous robots, which will provide tremendous benefits to society (e.g. search and rescue, putting out fires, and elderly care).   The research is woven into a tightly integrated educational plan that generates broader impacts via a robotics club in Laramie, a research-oriented course in evolutionary robotics, public education via videos and the press, and broadening participation in graduate training."
"1513275","CI-NEW: Collaborative Research: A Modular Platform for Enabling Computing Research in Intelligent Human-Robot Interaction","CNS","SPECIAL PROJECTS - CISE, COMPUTING RES INFRASTRUCTURE","06/01/2015","10/26/2017","Maja Mataric","CA","University of Southern California","Standard Grant","Reid Simmons","05/31/2019","$336,334.00","","mataric@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","1714, 7359","7359, 9251","$0.00","This project is to design, develop, and freely distribute novel, affordable, modular hardware and accompanying software platforms for enabling non-contact human-robot interaction (HRI) research. Such research is a significant portion of HRI today, and encompasses a broad spectrum of computing challenges and compelling application domains, including education, training, rehabilitation, and health. The goal of this project is to significantly increase access to hardware to a large body of researchers, so that computing advances can be applied to physical systems and evaluated in real-world environments, in order to drive progress in the computing community.<br/><br/>Advances in sensor and communication technologies have facilitated progress in computing research on physical platforms. The field of human-robot interaction in particular has grown significantly and actively brings together an interdisciplinary community of researchers across computing, robotics, and social science. However, progress has been limited by the lack of affordable, general-purpose, modular hardware platforms with available low-level software that would enable large numbers of computing researchers to enter the field and develop and test algorithms, as well as conduct statistically significant user studies by deploying systems in the real world and collecting user data to inform further computational research in HRI."
"1739315","CPS: Medium: Enabling Real-time Dynamic Control and Adaptation of Networked Robots in Resource-constrained and Uncertain Environments","CNS","S&AS - Smart & Autonomous Syst, Computer Systems Research (CSR, CYBER-PHYSICAL SYSTEMS (CPS)","09/01/2017","08/14/2017","Dario Pompili","NJ","Rutgers University New Brunswick","Standard Grant","David Corman","08/31/2020","$999,904.00","Jingang Yi, Francisco Diez-Garias","pompili@ece.rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","039Y, 7354, 7918","046Z, 7354, 7918, 7924","$0.00","Near-real-time water-quality monitoring in rivers, lakes, and water reservoirs of different physical variables is critical to prevent contaminated water from reaching the civilian population and to deploy timely solutions, or at least to issue early warnings so as to prevent damage to human and aquatic life. In order to make optimal decisions and ""close the loop"" promptly, it is necessary to collect, aggregate, and process water data in real time. Therefore, the goal of this project is to design a Cyber Physical System (CPS) where drones such as the Rutgers multi-medium Naviator, a Hybrid Unmanned Air/Underwater Vehicle (HUA/UV), and autonomous underwater robots (e.g., modified BlueROVs) can (i) first identify Regions of Interest (RoIs) and take measurements and well as, if needed, collect biosamples from them; (ii) and then, through collaborative information fusion and integration, perform in-situ transformation of these measurements/raw data into valuable information and, finally, into knowledge. To achieve the above goal, this project will need to solve the problem of uncertainties that arise in in-situ processing of data from sensors in any CPS. This project will provide greater autonomy and cooperation in CPSs and, at the same time, will improve scalability, reliability, and timeliness in comparison to traditional sensing systems. The challenges to achieve dynamic collaboration between local and cloud resources will be handled in Task 1, in which novel adaptive-sampling solutions that minimize the sampling cost of a RoI (in terms of time or energy expenditure) will also be developed. In Task 2, novel solutions will be designed to handle model uncertainties in the local resources due to the unpredictable behavior of computational models to input data and resources' availability. In Task 3, the project aims at developing a biosampler, i.e., ""lab-on-robot"", that uses in-situ measurements and communicates with the cloud resources to give results in real time on the water quality; also, new solutions to optimize the Naviator's current hybrid air/water multirotor platform/propulsion system will be designed in order for it to be able to carry and perform testing with the biosampler while also increasing its endurance. Finally, in Task 4, integrated field testing on the Raritan River, NJ, will be performed so as to validate the algorithms as well as to analyze their scalability (from an economical and feasibility perspective) and confidence/accuracy performance. Specifically, the Naviators will identify the RoIs via multimodal operations, i.e., in water and air; and then the BlueROVs (which, during the course of the project, will be made autonomous and will be modified to carry on-board water-quality sensors) will perform underwater adaptive sampling in each of those RoIs using the algorithms designed in Task 1.<br/><br/>In terms of broader impacts, the collaboration between cloud and local resources can benefit any CPS in the following ways: (i) outsourcing computation to the cloud will allow resource-constrained vehicles (in terms of computational capability) to meet mission deadlines, and (ii) using clouds comes at a price, hence, in order to accomplish the mission goals within budget constraints, the computational tasks composing a workflow should be migrated from the local network to the cloud only when the former does not have enough computational resources to execute successfully the tasks (outbursting). In terms of outreach, this project will develop a pipeline of diverse and computer literate engineers who will be able to solve self-management CPS problems. The PIs will 1) create a course on real-time in-situ distributed computing (for graduate computer engineering and undergraduate non-engineering majors); 2) develop teaching modules for incorporation into key high-school activities; 3) leverage existing minority student outreach programs and networks at Rutgers; 4) incorporate exchange programs and team-teaching approaches; and 5) utilize distributed education technologies with application to robotics and networking. Our electrical/computer and mechanical engineering team has the theoretical and system-level skills, cross-disciplinary expertise, as well as a verifiable history of fruitful collaboration to exploit fully this project's research and educational potential."
"1563807","RI: Medium: Combining Optimal and Neuromuscular Controllers for Agile and Robust Humanoid Behavior","IIS","ROBUST INTELLIGENCE","08/01/2016","04/13/2018","Hartmut Geyer","PA","Carnegie-Mellon University","Continuing grant","James Donlon","07/31/2019","$1,008,000.00","Christopher Atkeson","hgeyer@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7924, 9251","$0.00","The goal of making humanoid robots that assist people in the real world a reality requires that these robots can walk reliably in many different environments and terrains. This project leverages strong progress made by the PIs in the DARPA Robotics Challenge to address new techniques for whole-body locomotion of humanoid robots, based on the blending of model-based and parametric control approaches.<br/><br/>A central conundrum in humanoid robotics is that manually designed, policy-based controllers are often more robust than model-based optimizing controllers, but model-based controllers more easily generalize to automated behavior generation with direct control of foot or hand placements. This project tests the hypothesis that incorporating policy-based control as either a cost, a constraint, or a replacement within the model-based online optimal control framework produces controllers that combine the advantages of both approaches."
"1724222","S&AS: FND: A Stochastic Ethical Decision-Making Framework for Long-Term Autonomy","IIS","S&AS - Smart & Autonomous Syst","08/01/2017","04/13/2018","Katia Sycara","PA","Carnegie-Mellon University","Standard Grant","Tatiana D. Korelsky","07/31/2020","$608,001.00","","sycara@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","039Y","046Z, 9251","$0.00","For robots to effectively collaborate with humans, they must be able to reason about the ethical consequences of their decisions and actions, incorporating societal values, rules, and conventions. Consider, for example, autonomous cars, which are envisioned to become commonplace in 5-10 years. Autonomous cars will provide many advantages for road safety, and they will offer mobility to those with physical challenges. For such cars to be successful, however, multiple ethical problems must be solved. For example, is it allowable for a car to break traffic laws as it is taking a wounded person to a hospital? What should a car do if it recognizes that an accident is unavoidable? How can a car reason in a way that is understandable and acceptable in human society (and courts of law)? Important ethical questions also arise in applications of robotics to areas such as military engagements, law enforcement, and healthcare. To address these issues, the research will provide ways for robots to reason and plan their tasks and make ethically sound decisions. These reasoning procedures will enable robots to learn and adapt over time as laws and social conventions change. <br/><br/><br/>The research approach is based on normative reasoning integrated with Markov Decision Process (MDP) planning to enable the creation of an ethical intelligent Physical System (IPS) that will be evaluated via human experiments.  The research  is innovative in that it will provide:  (a)  an integrated way of reasoning about task performance and ethical behavior in the context of long-term autonomy,  where ethical rules  can be changing and action consequences could  be task and context dependent,  (b) principled ways of  evaluating consequences of  robot actions,  by considering and resolving  conflicts between domain goals and normative goals,  (c)  criteria to determine norm priority in a flexible and context dependent manner, (d) methods to  consider  the whole  life-cycle of norms, namely norm activation, deactivation, contradiction, violation and obsolescence."
"1826973","AAAI Student Outreach Workshop","IIS","ROBUST INTELLIGENCE","03/15/2018","03/15/2018","Sheila Tejada","CA","Association for the Advancement of Artificial Intelligence","Standard Grant","James Donlon","04/30/2019","$15,000.00","","sheilatejada@gmail.com","2275 E BAYSHORE RD STE 160","East Palo Alto","CA","943033224","6503283123","CSE","7495","7495, 7556","$0.00","This grant supports the participation of undergraduate students in the AAAI Student Outreach Workshop, to be held in conjunction with the AAAI (Association for the Advancement of Artificial Intelligence) and EAAI (Educational Applications of Artificial Intelligence) conferences, February 2-7, 2018 in New Orleans.  This outreach program is aimed at undergraduate students with an interest in AI or Robotics.  Through this workshop, students will work with the Cozmo robot and the Calypso robot intelligence framework to gain hands-on experience in applying artificial intelligence to a commercial robot.  <br/><br/>This activity will expose undergraduate students to practical skills and research issues involved in developing systems with robust intelligence.  The activity promotes student interest in artificial intelligence and autonomous robots for future education and development. The workshop also contributes to the development of effective methods for teaching about artificial intelligence, which has the potential to impact the computer science and engineering education community's ability to recruit future researchers and workforce more broadly.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1547178","INSPIRE: The RAVE Revolution for Children with Minimal Language Experience During Sensitive Periods of Brain and Language Development","IIS","Science of Learning, INFORMATION TECHNOLOGY RESEARC, DS - Developmental Sciences, Cyber-Human Systems (CHS), ROBUST INTELLIGENCE, Science of Learning Activities, INSPIRE","10/01/2015","07/24/2017","Laura-Ann Petitto","DC","Gallaudet University","Standard Grant","Tatiana D. Korelsky","09/30/2018","$1,150,000.00","David Traum","LauraAnn.Petitto@gmail.com","800 Florida Avenue, NE","Washington","DC","200023660","2026515497","CSE","004Y, 1640, 1698, 7367, 7495, 7704, 8078","5920, 7367, 7495, 8089, 8653","$0.00","This Integrated NSF Support Promoting Interdisciplinary Research and Education (INSPIRE) project ""The RAVE Revolution for Children with Minimal Language Experience During Sensitive Periods of Brain and Language Development"" is jointly funded by  Robust Intelligence and Cyber-Human Systems Programs of the Computer and Information Science and Engineering Directorate;  the Developmental and Learning Sciences Program, and the Science of Learning Centers Program of the Directorate for Social, Behavioral & Economic Sciences; the Office of International Science and Engineering; and the Office of Integrated Activities. The interdisciplinary team expands the boundaries of traditionally separate disciplines by uniting synergistically to explore a transformative learning tool to reduce the devastating impact of minimal language experience on children. Children's dramatically reduced language experience has been shown to have a deleterious impact on learning language, reading, and achieving normal cognitive functions across life,a problem facing many children in the nation (e.g., children from low SES backgrounds; late-exposed bilingual children). Deaf babies are at particular risk, as beyond minimal language experience, many receive no accessible language experience in early life. The Robot AVatar thermal-Enhanced learning tool, or RAVE, is placed near a baby's high-chair and makes available multiple core components of sign language, with speech options, in first-time socially interactive ways, and, crucially, during critical periods of human brain and behavior development. Exploration of this revolutionary learning tool involves scientists spanning four disciplines (Developmental Cognitive Neuroscience, Virtual Human Science, Robotics, and Applied Psychophysiology/Biomedical Engineering), provides science answers about how all babies discover core components of language, resolves previously insoluble problems in the four sciences, and is propelled by the shared objective to enhance early learning gains for populations that would otherwise be at a lifelong disadvantage.<br/><br/>Of particular novelty, fNIRS brain imaging provides first-time discovery of babies' sensitivities to multiple rhythmic components underlying language vital to healthy language learning. This forms the basis for creating rhythmic patterns at the core of nursery rhymes and conversational samples in sign language (through Motion Capture) and speech. Thermal IR imaging+eye tracking identifies when deaf babies who cannot yet produce language are in a peaked arousal state and ready to learn. This triggers the robot+virtual human to start, cease, or solicit interaction based on the baby's social engagement. When the baby's gaze locks with the robot, the robot initiates gaze direction to virtual humans, initiating joint attention and socially-contingent conversation in human artificial agent interaction. This triggers an interfaced screen where virtual humans provide rhythmic nursery rhymes and conversations in sign language, with speech options. Together, the RAVE team explores a new aid to children with minimal or no language input; provides the nation with a competitive science and technological edge; and, trains under-represented groups in STEM, students in interdisciplinary science, and young deaf scientists in the advancement of science with transformative translational significance for all society."
"1700697","RI: Small: Model-Based Deep Reinforcement Learning for Domain Transfer","IIS","ROBUST INTELLIGENCE","09/01/2016","10/24/2016","Sergey Levine","CA","University of California-Berkeley","Standard Grant","Weng-keen Wong","08/31/2019","$479,279.00","","sergey.levine@gmail.com","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495","7495, 7923","$0.00","The goal of this project is to develop machine learning algorithms that can enable automated decision making and control in applications that require autonomous agents to interact with the real world. In particular, the project will examine two application areas: autonomous robots and educational agents that interact with human students to facilitate learning. The principal technical development investigated in this project will center around applications of deep neural networks (deep learning) to efficiently learn predictive models of the world, such as the physical environment of the robot or the behavior of a human student using an interactive educational agent. Deep learning has enabled impressive advances in passive perception domains such as computer vision and speech recognition, but typically requires very large amounts of data to succeed. This is often a major challenge in interactive settings, where a robot cannot interact with its environment for weeks or months just to learn a single behavior. To address this challenge, this project will investigate how predictive models can be transferred from prior tasks into a new task. The technologies developed as part of this project could enable substantially more sophisticated autonomous systems that can adapt quickly to new situations through transfer. Economic impact could include new consumer robotics products and improved education through intelligent automation.<br/><br/>Reinforcement learning holds the promise of automating complex decision making and control in the presence of uncertainty. For a wide range of real-world problems, from robotic control and autonomous vehicles to interactive educational tools, this would provide dramatic improvements in capability and reduction in engineering cost. However, applying reinforcement learning to complex, unstructured environments and real-world problems with raw inputs, such as images and sounds, remains tremendously difficult. Deep learning has shown a great deal of promise for tackling complex learning problems, especially ones that require parsing high-dimensional, raw sensory signals, but the most successful applications of deep learning use very large amounts of labeled data. This is at odds with the demands of reinforcement learning, where the goal is typically to learn an effective policy using the minimal amount of interaction. This projects aims to address this challenge by developing algorithms for model-based deep reinforcement learning, where a generalizable model is learned from past experience on related but different tasks, and then transferred to a new task to learn it very quickly, directly using raw sensory inputs."
"1534524","SBIR Phase II:  Artificial Characterization of Objects Relating to Human Tactile Perception","IIP","SMALL BUSINESS PHASE II","09/15/2015","08/27/2018","Jeremy Fishel","CA","SynTouch LLC","Standard Grant","Muralidharan S. Nair","07/31/2019","$1,113,517.00","Jeremy Fishel","jeremy.fishel@syntouchinc.com","3720 Clifton Place","Montrose","CA","910201516","2134934400","ENG","5373","165E, 169E, 5373, 6840, 8035, 8240, 9139, HPCC","$0.00","The broader impact/commercial potential of this project is to provide a new standard of quantifying touch for industries currently relying on qualitative data from expert sensory panels (the tactile equivalent of professional wine tasters). Advancing the understanding of the role and function of tactile sensing in perception and manipulation is also essential if robots are to behave like humans. Studies have demonstrated that humans who cannot feel due to permanent disease or temporary anesthesia perform poorly in fine manipulation tasks (similar to even the best robotic systems without touch). The research proposed in this project is the next step to bring tactile sensing and sensory-motor intelligence to the next generation of robotics. The successful demonstration of a tactile sensor with perceptual similarity to the human fingertip would mark substantial progress in the field of telemanipulation, bringing the world one step closer to remote haptic perception.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project seeks to develop the world's first standard of human tactile perception. It has been proposed that tactile recognition presents a more difficult problem than vision and hearing, requiring not only intelligent sensory processing, but also intelligent algorithms to select and control movements, which have a tremendous influence on what is sensed. Artificial sensors that mimic the mechanical properties and sensitivity of the human fingertip have not existed until recently. The research proposed herein will test hypotheses that a biologically inspired robotic system can measure properties that correspond to subjective percepts, descriptors and associations that humans use to characterize objects by touch."
"1528110","NRI: Development of Autonomous Sub-Gram Flapping-Wing Artificial Flyers Using Novel Combustion-Driven SMA-Based Actuators","CMMI","National Robotics Initiative","09/01/2015","07/31/2015","Nestor Perez-Arancibia","CA","University of Southern California","Standard Grant","Irina Dolinskaya","08/31/2019","$750,000.00","Paul Ronney","perezara@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","ENG","8013","030E, 031E, 032E, 033E, 034E, 6840, 8024, 8086, 9102","$0.00","This project addresses power and control questions central to achieving maneuverable, autonomous, untethered, insect-scale, flying robots. The amount of energy stored per unit mass in even the best small batteries is low enough that flight times would be limited to at most a few minutes. Furthermore, when the high rate at which the battery must supply energy is considered, it is questionable whether a winged microrobot could even lift its own weight. Instead, this project emulates flying insects in nature, which use animal fat as fuel, with an energy density about 100 times greater than state-of-the-art batteries. Accordingly, this project will demonstrate liquid-fuel catalytic combustion engines expected to be capable of over 90 minutes of powered flight. This result will be achieved through innovative integrated modeling, analysis, design, fabrication, and control of insect-scale aerodynamics, combustion, and flight. Broader impacts will arise from application of insect-scale flying robots to, for example, artificial pollination, search-and-rescue operations, and field biological research. Indirectly, this project will produce new methods for energy conversion, novel algorithms for control synthesis, and fabrication techniques, applicable to a wide gamut of wheeled, winged, and legged microrobots.<br/><br/>To accomplish the project goals, the research advances knowledge in three specific areas: (i) biologically inspired design and fabrication of aerodynamically efficient flapping-wing microflyers, where principles from nature are translated into robotic designs, employing a systems-and-control conceptual framework. In this framework, the interaction between aerodynamics, power, design, and controls is analyzed using tools such as input-output modeling and system identification; (ii) mechanical actuation using fuel-powered shape-memory-alloys-based mechanisms, where flameless catalytic combustion generates the heat required to induce material phase transitions, necessary for the production of mechanical work; (iii) control, which emerges naturally from the first two areas as new aerodynamically efficient designs require the invention of novel control strategies for stable flight and new techniques for controller synthesis. Similarly, new actuation technologies require the invention of new low-level, physically implementable controllers. In this case, the dynamics of the combustion-driven actuators and flapping mechanisms are nonlinear and time-varying, reason for which a significant part of the research effort is dedicated to the development and real-time implementation of novel robustly stable nonlinear and adaptive controllers."
"1727303","CI-EN: Enhancement of a Large-scale Multiagent Simulation Tool","CNS","COMPUTING RES INFRASTRUCTURE","09/01/2017","07/11/2017","Sean Luke","VA","George Mason University","Standard Grant","James Donlon","08/31/2020","$896,303.00","Robert Simon, Andrew Crooks","sean@cs.gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7359","7359","$0.00","An agent-based simulation is a software simulation of many independent actors (people, robots, animals, companies, etc.) interacting in complex ways.  For example, one might build a simulation of a swarm of ants, a school of fish, a large group of robots collectively building a house, a city of people under siege by a large medieval army, or the spread of urban legends over a social network. These kinds of simulations are used for everything from building software for swarms of delivery robots, to understanding the spread of disease in third-world slums, to predicting the impact of climate change on human migration patterns.  Similarly, these simulations help researchers and policy makers in engineering and robotics, in artificial intelligence, and in the biological and social sciences.  Such simulations can get very large, with large numbers of actors.  This project involves building a software tool to assist in the development of large-scale agent-based simulations spread over potentially many separate computers, and to make it easy for them to place their agents in simulated locations on the Earth.  At the same time the tool will be easy to use for high school and undergraduate students.<br/><br/>The project will develop a distributed agent-based modeling tool for constructing large simulations of swarms and groups of agents.  The project enhances an existing, successful open-source Java multiagent simulation library called MASON.  MASON is designed to run on a single machine; but the enhanced version will also allow distribution over many machines.  The enhanced tool will also include facilities for embedding agents in geographical information systems (GIS), model optimization and automation, interfaces for alternative programming languages targeting the Java Virtual Machine, statistics facilities, internal testing and verification, and integration with software tools.  The enhancement will not only provide a distributed simulation facility for researchers in the social sciences, biology, and engineering, but will also improve on MASON's graphical interface and language facilities to make it easier to use as a teaching tool."
"1427419","NRI: Electrosense imaging for underwater telepresence and manipulation","IIS","National Robotics Initiative","09/01/2014","08/01/2016","Michael Peshkin","IL","Northwestern University","Continuing grant","David Miller","08/31/2019","$1,816,000.00","Malcolm MacIver, Konrad Kording, Joshua Smith, Alexander Makhlin, James Solberg","peshkin@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","8013","8086, 9251","$0.00","Human telepresence underwater is essential for tasks such as security sweeps in harbors and oil field servicing. Co-robotic solutions are needed, because the risks are great for human divers, while autonomous robots do not deal well with contingencies. A major problem is that vision works poorly in murky environments, such as when mud is kicked up from the bottom. In this National Robotics Initiative (NRI) project the researchers are investigating and developing a replacement for vision -- electrosense -- used by Amazonian fish that navigate and hunt in murky water. These ""weakly electric fish"" generate an AC electric field that is perturbed by objects nearby. Electroreceptors covering the body of the fish detect the perturbations, which the fish decodes into information about its surroundings. The researchers are developing methods of preprocessing electric images for human understanding, and new computed methods for machine interpretation. <br/><br/>The research creates electrosense hardware and practical testbeds, for navigation and for manipulation underwater.  It investigates methods and software to facilitate human interpretation of electric images, as well as machine interpretation. In hardware, the researchers are creating a kilopixel-scale electrosense array as an input sensor for human interpretation of electric images, and development of preprocessing algorithms to make human interpretation workable.  The researchers are also using sparser and non-coplanar groups of electroreceptors on a manipulator, for control of pre-grasp and manipulation tasks.  For human interpretation, electric image preprocessing includes contour painting and spatial high-pass filtering, as well as temporal filtering. For machine interpretation, methods include specific recognition strategies for simple geometric primitives, and sparse beamforming techniques for more complex environments."
"1839353","TRIPODS+X:VIS: The DISC Institute Workshop Series on Machine Learning + X.","DMS","TRIPODS Transdisciplinary Rese, OFFICE OF MULTIDISCIPLINARY AC","10/01/2018","09/10/2018","Katya Scheinberg","PA","Lehigh University","Standard Grant","Tracy J. Kimbrel","09/30/2021","$199,353.00","Hector Munoz-Avila","kas410@lehigh.edu","Alumni Building 27","Bethlehem","PA","180153005","6107583021","MPS","041Y, 1253","047Z, 062Z","$0.00","This project encompasses the planning and organization of several specialized workshops that will bring together top experts in multiple areas to shape new and emerging multidisciplinary fields, tapping the tremendous recent surge in the adoption of machine learning tools in various areas of science and engineering. The premise of this project is the need for sophisticated computational tools  to analyze data and improve our ability to understand and harness phenomena  associated with complex domains such as chemical processes, autonomous robots operating in open and dynamic environments, supply chain optimization involving large organizations with multiple and competing objectives, and cognitive neuroscience bridging electrical brain impulses and high-level functions such as problem solving. Towards this end it is necessary to foster interdisciplinary collaborations and to promote convergent research and develop fertile space for collaborations among industrial, academic, and governmental partners to attack some of the most pressing problems in technology and society. <br/><br/>Under the umbrella of the new Institute for Data, Intelligent Systems, and Computation (I-DISC) at Lehigh University, which builds upon the foundation of Lehigh research expertise in areas such as machine learning, optimization, and data-driven decision making, four workshops will be organized that will bring together leading researchers from different research communities that otherwise may not interact. All of these workshops are on newly emerging topics which are expected to gain significant traction in the near future. These topics are as follows: (1) Chemistry, chemical engineering, materials science, and related disciplines where machine learning is used  to elucidate and design complex processes (chemical/biological, engineered/natural) or material systems with wide ranging applications addressing grand challenges in energy, health, environment, and water. (2) Robotics, where applications of machine learning, also known as robot learning, has been rapidly growing in recent years, where the main focus has been to develop algorithms to assist robots to acquire novel skill or adapt to their environment through sensing. (3) Supply chain management with the specific focus on applying machine learning models for prescriptive analytics, such as optimization, in contrast to already popular use of machine learning (deep learning) models for predictive and descriptive analytics, such as predicting customer demands. (4) Cognitive Neuroscience with the focus on understanding the brain-cognition-behavior interface, which requires expertise in neuroscience as well as computational modeling, machine learning and big data science in order (a) to enable sophisticated analyses of complex patterns in brain data and (b) to provide insight into how hypothesized brain-level implementations could in fact produce observed behavioral outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637899","NRI: Receding Horizon Integrity-A New Navigation Safety Methodology for Co-Robotic Passenger Vehicles","CMMI","National Robotics Initiative","09/01/2016","04/10/2017","Matthew Spenko","IL","Illinois Institute of Technology","Standard Grant","Irina Dolinskaya","08/31/2019","$899,926.00","Mathieu Joerger","mspenko@iit.edu","10 West 35th Street","Chicago","IL","606163717","3125673035","ENG","8013","8086","$0.00","The objective of this research is to ensure the integrity of vehicle position, heading, and velocity estimates that are used by self-driving cars as the basis for life-critical decisions such as the initiation and execution of hazard-avoidance maneuvers.  Integrity, which is a measure of trust in a sensor's information, has been successfully implemented in commercial aircraft to guarantee the safety of maneuvers such as landing. This project addresses several obstacles in translating integrity from aviation applications to self-driving cars, including integrating the disparate sensor types used by ground vehicles; meeting the stringent demands of routine autonomous driving; accounting for the number, proximity, and high relative velocity of other vehicles on the road; and evaluating multiple, distinct, and mutually exclusive courses of action in a timely manner. Project subtasks include characterization of integrity for representative sensors, construction of appropriate models for uncertainty propagation, and experimental validation of the resulting integrity framework. The project will advance the larger research effort to realize the potential of self-driving cars for relieving congestion, reducing emissions, and saving lives. The work includes public outreach efforts on autonomous navigation for self-driving cars, which will build upon an ongoing relationship with Chicago's Museum of Science and Industry, including a hands-on demonstration during National Robotics Week to illustrate how safety can be ensured despite uncertainties related to sensor readings, vehicle dynamics, and the driving environment.<br/><br/>Specifically, this research will provide new experimental and analytical methods to quantify and prove self-driving car safety. The results of this work will create a high-level, sensor-independent, quantifiable metric that can be used to compare, evaluate, and certify safety across self-driving car manufacturers. Knowledge will be advanced in several previously-unexplored areas, including first-ever demonstrations of: 1) high-integrity sensor measurement error and fault models for non-GPS sensors, 2) analytical methods to quantify the safety risk of feature extraction and data association algorithms required in lidar, radar, and camera-based localization, 3) multi-sensor pose estimators and integrity monitors designed to evaluate the impact of undetected sensor faults on safety risk, and 4) rigorously derived and experimentally validated integrity risk prediction methods in dynamic environments."
"1823260","CRI: CI-New: Collaborative Research: Extensible, Software Enabled Unmanned Aerial Vehicles","CNS","COMPUTING RES INFRASTRUCTURE","10/01/2018","09/04/2018","Yu David Liu","NY","SUNY at Binghamton","Continuing grant","M. Mimi McClure","09/30/2021","$128,247.00","","davidl@cs.binghamton.edu","4400 VESTAL PKWY E","BINGHAMTON","NY","139026000","6077776136","CSE","7359","7359, 7918","$0.00","Unmanned aerial vehicles (UAVs) are an emerging computing platform increasingly becoming common in our society. Unfortunately, most UAV systems today are either proprietary, or specific to goals of aviation and robotic missions. This project will develop an open-source and extensible software infrastructure for UAVs to promote research and education of this exciting technology.<br/><br/>The proposal will result in an infrastructure to allow for extensible UAV software design across the computing stack, spanning operating systems (OS), virtual machines (VM), compilers, programming languages, and applications. This significantly shifts the focus of state of the art of UAV software where refined support is limited to hardware drivers and robotics control, OS/VM support is primitive, and high-level Application Programming Interface is minimal. The resulting infrastructure will promote whole-stack extensibility, portability, resource awareness, and application friendliness of UAV systems. The infrastructure will enable researchers from non-UAV specific domains to conduct research on the platform.<br/><br/>The infrastructure will impact researchers spanning areas of avionics, robotics, real-time systems, programming languages, and software engineering. Other beneficiaries of the proposed infrastructure include students and UAV users. The technologies developed under this award will provide training and research opportunities for Ph.D. students, master's students, and advanced undergraduates in UAV education. UAVs, robotics, and aviation are interesting and exciting to k-12 students. The artifacts from this project will be tailored for student outreach.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1823230","CRI: CI-New: Collaborative Research: Extensible, Software Enabled Unmanned Aerial Vehicles","CNS","COMPUTING RES INFRASTRUCTURE","10/01/2018","09/04/2018","Lukasz Ziarek","NY","SUNY at Buffalo","Continuing grant","M. Mimi McClure","09/30/2021","$328,844.00","Karthik Dantu","lziarek@buffalo.edu","520 Lee Entrance","Amherst","NY","142282567","7166452634","CSE","7359","7354, 7359","$0.00","Unmanned aerial vehicles (UAVs) are an emerging computing platform increasingly becoming common in our society. Unfortunately, most UAV systems today are either proprietary, or specific to goals of aviation and robotic missions. This project will develop an open-source and extensible software infrastructure for UAVs to promote research and education of this exciting technology.<br/><br/>The proposal will result in an infrastructure to allow for extensible UAV software design across the computing stack, spanning operating systems (OS), virtual machines (VM), compilers, programming languages, and applications. This significantly shifts the focus of state of the art of UAV software where refined support is limited to hardware drivers and robotics control, OS/VM support is primitive, and high-level Application Programming Interface is minimal. The resulting infrastructure will promote whole-stack extensibility, portability, resource awareness, and application friendliness of UAV systems. The infrastructure will enable researchers from non- UAV specific domains to conduct research on the platform.<br/><br/>The infrastructure will impact researchers spanning areas of avionics, robotics, real-time systems, programming languages, and software engineering. Other beneficiaries of the proposed infrastructure include students and UAV users. The technologies developed under this award will provide training and research opportunities for Ph.D. students, master's students, and advanced undergraduates in UAV education. UAVs, robotics, and aviation are interesting and exciting to k-12 students. The artifacts from this project will be tailored for student outreach.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813805","SHF: Small: Hot DNA Computation: Speeding up DNA-based Computation, CRNs, and Robotics using Strand-Displacing Polymerase","CCF","COMPUTATIONAL BIOLOGY","10/01/2018","09/04/2018","John Reif","NC","Duke University","Standard Grant","Mitra Basu","09/30/2021","$224,999.00","","reif@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7931","7923, 7946","$0.00","To date, there has been considerable success in experimental demonstrations of DNA-based molecular devices to implement molecular-scale Boolean circuit computations, chemical reaction systems, and robotics. However, these experiments take hours to perform due to relatively slow reaction rates. Some progress has been made (by the project's investigators and others) in speeding up DNA-based computations, but the reactions still take tens of minutes. The objective of this project is to substantially speed-up DNA-based computations. The work is highly interdisciplinary and will provide interdisciplinary education at undergraduate and graduate levels. The project will engage students (with stress on women and under-represented minorities) from different academic levels across multiple disciplines in mentoring and teaching. Hands-on demonstrations of DNA computing and robotic devices will be designed for outreach programs at Duke and North Carolina Science & Math High School. Workshops and lectures will help disseminate knowledge of advanced DNA-based nanoscience concepts to undergraduate and graduate student audiences.<br/><br/>The project work will include design, simulation, and experimental demonstration of protocols which make use of only DNA hybridization and strand-displacing polymerization reactions. In particular, the project will not make use of the much slower either strand-displacement hybridization reactions or restriction enzyme reactions). The designs for Boolean circuit computations will be simulated and optimized. Experimental demonstrations will be made for each design, first in solution, and then experimentally demonstrated with the components attached to DNA nanostructures to allow for further speed-up via localized reactions. The project tasks include as Task 1, the design, simulation and demonstration of fast DNA logic circuits using strand-displacing polymerase reactions; this will include experimental demonstrations of multiple large-scale Boolean circuit computations executed in solution. Initial work by the project's investigators has already experimentally demonstrated a Boolean circuit computation (in solution) of a square root computation with 4 Boolean inputs that ran in approximately 15 minutes, and it is expected that considerable speed-ups when these reactions are localized. Task 2 is the experimental demonstration of localized reactions using strand-displacing polymerase; here DNA logical circuits will be attached to self-assembled DNA nanotracks and DNA origami, and the work will include experimental demonstrations of Boolean circuit computations executed in a localized fashion. Task 2 will also demonstrate a high-speed localized chain reaction on a self-assembled DNA track using strand-displacing polymerase reactions using a novel design where the gates form a self-assembled nanotrack and the reaction gradually de-assembles the track; this may provide a swift medical diagnostic system for targeted nucleic acid detection of infections.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1458496","Scholarships for Robotics and Mechatronics Systems Engineering","DUE","S-STEM:SCHLR SCI TECH ENG&MATH","09/01/2015","08/23/2015","Shuvra Das","MI","University of Detroit Mercy","Standard Grant","Rupa Iyer","08/31/2020","$593,500.00","Mark Paulik","dass@udmercy.edu","4001 W MCNICHOLS","Detroit","MI","482213038","3139271000","EHR","1536","9178, SMET","$0.00","In order to address the increasing demand for engineers who need to be trained for multi-disciplinary product innovation, University of Detroit Mercy (UDM) launched a new undergraduate degree program entitled ""Robotics and Mechatronic Systems Engineering.""  The objectives of this proposed S-STEM project is to attract talented students, particularly women and minorities, into this new program and increase the number of engineering graduates trained in interdisciplinary engineering through financial help, mentoring, improved student support, and retention efforts.  The long-term strategy includes several components: (a) working with the extensive pre-college program that the college already sponsors to increase the interest of students in engineering disciplines, (b) working with high schools, For Inspiration and Recognition of Science and Technology (FIRST) Robotics Competition teams and community colleges to attract more students into engineering disciplines, and (c) provide scholarships and academic support to qualified and financially challenged students who enroll in this new degree program.<br/><br/>The project has an aggressive retention plan including:  strong academic support for the S-STEM scholars with comprehensive, focused, and cohort-based advising; cohort-based registration in most classes to help develop camaraderie within the group; tutoring in math and other challenging subjects, as needed; participation of all S-STEM students in a one-year paid co-op experience in industry; mentoring from alumni and industry leaders on the college advisory board; annual field trips and networking events to develop professional relationships with potential employers and develop career insights.  This project will help develop the understanding of the effect of early cohort formation and mentoring on college success, enable formation of closer ties with specific industrial partners through the expansion of the co-op program, and improve the student support structure at UDM through evidence-based techniques of academic intervention.  This project will also help establish a committed group of alumni from the new degree program who will make the program stronger for future generations of engineers.  The results from this program will be presented at educational conferences such as American Society for Engineering Education Annual conference and the Frontiers in Engineering Education conference."
"1637937","NRI: Collaborative Research: A Framework for Hierarchical, Probabilistic Planning and Learning","IIS","National Robotics Initiative","09/01/2016","04/13/2018","Marie desJardins","MD","University of Maryland Baltimore County","Standard Grant","Reid Simmons","08/31/2019","$381,437.00","","mariedj@cs.umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","8013","8086, 9150, 9251","$0.00","This project is an effort to create a unified framework for solving very large problems with uncertain states and actions, such as manipulator robots acting in real-world environments.  The results may have especially great promise for assistive technologies, including autonomous robots that can be used by elderly and disabled populations to aid them in their daily activities.  The proposed integrated framework will represent, apply, and learn hierarchical domain knowledge, and will include the ability to transfer knowledge from simpler problems to more complex ones. The research will enable autonomous agents to develop a structured representation of complex domains based on experience. The agents will use learned representations to interpret natural language commands for both low-level and high-level requests.  <br/><br/>The technical focus is enabling tractable planning in large, uncertain domains by generating and leveraging probabilistic domain knowledge at multiple levels of abstraction. Agents will autonomously create layered representations in which the layers build on one another to produce complex behaviors. Agents will learn to perform useful behaviors, such as navigating using low-level sensor feedback or assembling complex objects such as a bridge or a table.  The key technical contributions will be methods for (1) planning in large state/action spaces using the abstract object-oriented Markov decision process (AMDP) model, a new formalism for representing probabilistic domain knowledge at multiple levels of abstraction; (2) learning hierarchical task knowledge in the form of AMDPs; and (3) interpreting natural language commands at multiple levels of abstraction by mapping to the learned hierarchical structure. The formalism will be demonstrated and validated in several domains, including a simulated ""cleanup"" toy domain, challenging and complex video games, and a robot manipulation task."
"1734383","NRI: FND: Light-Powered Microrobots for Future MIcrofactories","CMMI","National Robotics Initiative","09/01/2017","08/20/2017","Dan Popa","KY","University of Louisville Research Foundation Inc","Standard Grant","Irina Dolinskaya","08/31/2021","$747,259.00","","dan.popa@louisville.edu","The Nucleus","Louisville","KY","402021959","5028523788","ENG","8013","030E, 034E, 8024, 8086, 9150","$0.00","The goal of this project is to use focused laser light as a method for powering and remotely controlling millimeter-sized manufacturing microrobots suitable for fabricating and assembling even smaller devices. Swarms of multi-legged, light-driven microrobots, capable of operation in either dry or wet environments, will be built and studied. This project will pave the way for the microfactories of the future, enabling the production of nanopositioning and nanotransport devices with applications to nanomanufacturing and biotechnology. Microrobots have long been envisioned as a gateway for full human telepresence at the micro- and nanoscales, where conventional tools cannot be used for manipulation or assembly. Potential outcomes of this project include unprecedented manufacturing capabilities in nano- and biotechnology, leading to new opportunities for US industry.<br/><br/>The research objective of this project is to study novel and efficient light-based wireless energy transfer and control methods for collectives of microrobots that can accomplish precision nano-scale positioning and manipulation tasks. The project will provide fundamental new knowledge for programming multi-actuator locomotors with a single light source, using differential responses of the robot limbs to generate multi-legged gaits. The project will create new photo-thermo-dynamic robot models, and new learning control algorithms suitable for physical inter-robot cooperation. To validate the models and control schemes, a unique hardware infrastructure will be prototyped and experimentally demonstrated to drive and test two types of light-powered microrobots. The first type of light-powered microrobot, called ""Micro-laser-hopper,"" is an untethered microrobot with flexure legs that can accomplish controlled stick-slip crawling over a dry surface using a single, large diameter laser beam source. Micro-laser-hopper gait is controlled by changing temporal laser parameters, such as intensity, pulse frequency and duty cycle. The second type of light-powered microrobot, called ""Micro-solar-one,"" is an integrated microrobot containing a solar cell, in-plane microactuators, microassembled legs, and a vertical electronic backpack. Micro-solar-one is powered by concentrated, broad spectrum white light, and is able to store and execute complex gaits, at the expense of more complex manufacturing and thermal management challenges."
"1800955","Guitar, Robotics, and Rocketry Projects to Enhance Advanced Technological Education","DUE","ADVANCED TECH EDUCATION PROG","07/01/2018","04/09/2018","Cheryl Calhoun","FL","Santa Fe College","Standard Grant","Heather Watson","06/30/2021","$467,713.00","Cheryl Canova, Gina Greenidge, Shellie Banfield","cheryl.calhoun@sfcollege.edu","3000 NW 83rd Street","Gainesville","FL","326066210","3523955000","EHR","7412","1032, 9178, SMET","$0.00","Increasing the workforce in STEM fields is important for the nation's global competitiveness. Industries in the rural communities served by Santa Fe College in Florida have increasing demand for highly-skilled and effective technicians. To address this need, Santa Fe College will develop educational resources to promote participation in STEM disciplines and awareness of career possibilities in STEM by providing unique experiences for students. The project will design a single multidisciplinary course to engage students in the scientific methods used for research and analysis. Three different versions of the course will be developed to include a hands-on project focused on either guitar building, rocketry, or robotics. The math, technology, and science skills will be woven throughout these student projects. The courses will be offered to students at three rural educational centers. These students include those who are transitioning from secondary to postsecondary education and first-time college students. Many students in these populations are unfamiliar with STEM technician jobs.  The project aims to enhance student abilities and promote interest in career opportunities that will help strengthen the nation's STEM technician workforce.<br/><br/>The objectives of this project will be to: 1) create and implement a project-based Research and Analysis course with three experiential learning project options: guitar building, robotics, and rocketry; 2) provide faculty professional development to ensure consistent implementation of the pedagogy at three rural educational centers; 3) engage a minimum of three local businesses in development and implementation of career exploration presentations and/or videos; and 4) evaluate the change in STEM career attitudes and intentions of program participants through a pre- and post-test research study. Curriculum development will use evidence-based pedagogical practices designed to mitigate stereotype threat and enhance self-efficacy. Building on the work of others, this project will adapt, integrate, and enhance relevant curriculum and resources from other ATE projects, to meet the needs of Santa Fe College's students and community. Because of the rural nature of the participating educational centers, students will include a higher than average percentage of low socioeconomic status students and first-time college students. The project aims to emphasize collaboration with industry partners to better meet employer needs for STEM technicians, and to connect students with industry so they obtain firsthand knowledge of requirements for developing a successful career. The change in STEM attitudes and interest in STEM careers will be measured using a validated pre-post analysis. The results of this project will be disseminated through project presentations and publications, and shared on the ATE Central website.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1844463","PIRE: Bio-Inspired Materials and Systems","OISE","RSCH EXPER FOR UNDERGRAD SITES, Molecular Biophysics, Engineering of Biomed Systems, ROBUST INTELLIGENCE, PIRE, Materials Eng. & Processing","06/01/2018","08/24/2018","LaShanda Korley","DE","University of Delaware","Continuing grant","Cassandra M. Dudka","08/31/2022","$1,939,208.00","","lkorley@udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","O/D","1139, 1144, 5345, 7495, 7742, 8092","5950, 7465, 8007, 9102","$0.00","LaShanda Korley, Jonathan Pokorski, Gary Wnek (Case Western Reserve University), Stuart Rowan (University of Chicago)<br/><br/>Materials that are found in Nature display a wide range of properties including responsiveness to the environment, signal transmission, and the ability to adapt to support life. Learning from Nature or biomimicry can be a powerful tool in designing, developing and accessing the next generation of synthetic materials and systems. Furthermore, biomimetic concepts will account for an estimated $1.2 trillion in global economic development, and have already contributed to familiar products like Velcro and wind turbines. Thus, there is a critical need for the US to educate the next generation of internationally-minded biomimicry thinkers to develop a new wave of innovative materials. As such, this PIRE brings together an interdisciplinary team of US and Swiss collaborators to carry out research and education in the area of Bio-Inspired Materials & Systems. Specifically, the PIRE will utilize inspiration from Nature to design new materials that can change toughness in response to their environment, are safer and more effective biological implants, will transmit nerve-like electrical signals, and can respond to the environment to initiate biological processes, all for use in soft robotic applications. <br/><br/>A range of innovative educational and outreach activities will train US students in learning from Nature and in a bio-inspired philosophy. This training will happen in an international context with Swiss collaborators, world leaders in biomimetic concepts and research. Students will gain exposure to themes cutting across chemistry, polymers, physics, biology, and engineering in the development of multi-functional, active materials. Mentoring, diversity, cultural competency, globalization, and effective scientific communication are emphasized as critical elements of the PIRE.<br/><br/>Nature has a multitude of examples of complex materials and systems that go well beyond the current capabilities of synthetic systems. The innovation potential in this domain is vast and a large-scale interdisciplinary effort is required to realize paradigm-changing scientific breakthroughs. To that end, an international partnership between biomimicry experts at Case Western Reserve University (CWRU), the University of Chicago (UoC), and the University of Fribourg/Adolphe Merkle Institute in Switzerland in Bio-inspired Materials and Systems is established. Building upon collaborative strengths in polymer synthesis, computational modeling, mechanical characterization, robotics, imaging, manufacturing, biology, biomedical engineering, physics, and molecular engineering, five Bio-inspired Materials and Systems projects are envisioned: (1) Silk-inspired Nanocomposites: Spider/Caddisfly Silk Mimics; (2) Sea Cucumber, Squid Beak and Pine Cone Inspired Adaptive Composites; (3) Excitable Polyelectrolyte Fiber Networks/Gels: Toward Artificial Neurons; (4) Dynamic and Functional Fibers Inspired by the Extracellular Matrix; and (5) Soft Robotics Inspired by Worm Locomotion. These research thrusts are directed toward the development of functional, programmable, and responsive materials for deployment in soft robotic systems.  Faculty, graduate, and undergraduate students will spend time in Switzerland engaging in synergistic research/educational activities. An educational and innovation partnership with local thought leaders in biomimicry will guide the training of the next-generation of global scientists and engineers in this interdisciplinary endeavor. Effective science communication will be highlighted via existing programming with the Museum of Science and Industry (MSI) of Chicago. Community outreach activities include research opportunities at CWRU and UoC for underrepresented high school students in STEM as part of an expanded Biomimetic Envoys program and the development of biomimetic hands-on demonstrations for annual participation in the Martin Luther King Jr. (MLK) Discovery Day at the Cleveland Museum of Natural History."
"1528047","NRI: Planning, Collaborative Guidance and Navigation in Uncertain Dynamic Environments","IIS","National Robotics Initiative","08/01/2015","08/04/2015","Lydia Tapia","NM","University of New Mexico","Standard Grant","James Donlon","08/31/2019","$999,998.00","Patrick Kelley, Meeko Oishi","tapia@cs.unm.edu","1700 Lomas Blvd. NE, Suite 2200","Albuquerque","NM","871310001","5052774186","CSE","8013","8086, 9150","$0.00","Navigation in dynamic, uncertain environments is a difficult yet ubiquitous problem in diverse applications such as search and rescue, coordinated movement, distributed monitoring and surveillance.  Collaborative solutions are highly promising because of their potential to exploit strengths of both the human and the automation.  However, major challenges in collaborative navigation include not only the ability of the underlying automation to effectively handle novel scenarios and changing environments that may not have been considered at the design stage, but also human-automation interaction requirements.  The design of methods and tools that can address these challenges could enable fundamentally new functionality in collaborative human-robot systems.   The novelty of the proposed research is in the integration of control theory, motion planning, and human guidance to provide highly effective solutions for navigation in highly dynamic and uncertain environments.  The proposed project will also create opportunities to involve under-represented minorities in K-12 outreach and in undergraduate and graduate research, to facilitate interdisciplinary collaboration, and to develop a new interdisciplinary graduate course. <br/><br/>This proposal aims to develop a generic framework for collaborative navigation in complex environments that can accommodate hundreds of moving obstacles (with possibly stochastic dynamics), non-trivial static obstacles, and humans in the loop.  We propose to a) evaluate the tradeoff between short-term and long-term information for both users and autonomous systems in highly dynamic environments, b) extend our existing algorithmic techniques to environments of higher complexity, e.g., multi-robots and non-planar environments, c) design and test several user-interfaces, which satisfy pre-determined conditions for user-observability and user-predictability, for their effectiveness in improving safe navigation, and d) experimentally validate our existing setup for collaborative navigation in dynamic, uncertain environments via an Android app.  We will develop tightly coupled planning and control tools, integrate human guidance and decision making with automated tools, and complete a rigorous analysis of safety in highly dynamic environments with uncertainty.  The developed methods will be validated in multiple environments, with human subjects, and on a micro robot testbed."
"1829398","Functional Organization of Navigational Coding in the Human Brain","BCS","GEOGRAPHY AND SPATIAL SCIENCES, COGNEURO","09/01/2018","08/21/2018","Chantal Stern","MA","Trustees of Boston University","Standard Grant","Uri Hasson","08/31/2021","$669,803.00","Elizabeth Chrastil, Samuel Ling","chantal@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","SBE","1352, 1699","1352, 1699","$0.00","With funding from NSF, the researchers will study how the human brain represents dimensions that are needed for finding our way around in the world. The interdisciplinary approach combines cognitive and visual neuroscience methods, aimed towards understanding how the human brain processes spatial navigation information. The studies incorporate behavioral, cognitive, and neuroimaging techniques to examine how the human brain codes for distance, heading direction, speed, and time, which may contribute to higher-level navigation mechanisms, such as planning a route to a known destination or finding one's way home. The results have the potential to impact other fields, including robotics and spatial sciences.  In robotics, autonomous systems have difficulty determining whether they have successfully returned back to their origin after an outbound journey, which robotics researchers call the loop closure problem.  In contrast, humans and animals can readily solve this problem.  Understanding how visual information is used to localize and orient will provide knowledge that could potentially facilitate innovation in mobile robots and self-driving cars or training for more efficient navigation in humans.  Greater knowledge of the basic properties of navigation in humans could also lead to improved electronic navigation systems, emergency response training, and more effective transportation signage.<br/><br/>The scientific goals harness the strengths of cognitive neuroscience, visual neuroscience, and spatial sciences to examine navigation in humans.  While much is known about the navigation system in rodents, the rat and primate have fundamentally different visual systems. Contributions from the visual system provide critical information necessary for self-motion guided navigation, and the theoretical basis for this proposal stems from computational models that posit that perceptual information, including optic flow, speed, and direction signals, are necessary for successful navigation. The researchers propose a framework in which spatial representations transform from a retinotopic to a spatiotopic organization. This framework posits testable hypotheses about the nature of self-motion guided navigational representations in the brain. A series of experiments will examine how the human brain codes lower-level representations, such as distance, heading direction, speed, and time, which may serve as basis functions for generating higher-level level navigational representations. The studies will examine how these selective properties are spatially organized in the brain, as well as the higher-level computations that bring this information together to compute path integration. To do so, the proposed studies employ innovative functional MRI paradigms adapted from visual neuroscience, including population receptive-field mapping, phase-encoded analyses, and model-based time-series analyses. The proposed work is critical for extending computational models of navigation to the systems level in humans.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1842574","NSF National Robotics Initiative (NRI) 2018 Principal Investigators Meeting","IIS","National Robotics Initiative","09/01/2018","08/18/2018","Peter Kazanzides","MD","Johns Hopkins University","Standard Grant","David Miller","02/28/2019","$39,952.00","Russell Taylor, Gregory Chirikjian","pkaz@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","8013","063Z, 7556, 8086","$0.00","This award will support the organization of the annual Principal Investigators (PI) meeting for the National Robotics Initiative (NRI), which was launched in 2011. The PI meeting will bring together the community of active NRI participants to provide cross-project coordination of intellectual challenges and best practices in education, technology transfer and general outreach.  This activity will also establish a repository illustrating the research ideas explored and milestones achieved by the NRI projects. <br/><br/>The meeting is planned for two days in October 2018 in the vicinity of Washington DC. The format will include presentations by the attending PIs of projects in their final year, a poster session with all other projects, keynote speeches, and panel discussions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1743475","PIRE: Bio-Inspired Materials and Systems","OISE","RSCH EXPER FOR UNDERGRAD SITES, Molecular Biophysics, Engineering of Biomed Systems, ROBUST INTELLIGENCE, PIRE, Materials Eng. & Processing","09/01/2017","08/29/2017","LaShanda Korley","OH","Case Western Reserve University","Continuing grant","Cassandra M. Dudka","09/30/2018","$1,119,024.00","Jonathan Pokorski, Stuart Rowan, Gary Wnek","lkorley@udel.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","O/D","1139, 1144, 5345, 7495, 7742, 8092","5950, 7465, 8007, 9102","$0.00","LaShanda Korley, Jonathan Pokorski, Gary Wnek (Case Western Reserve University), Stuart Rowan (University of Chicago)<br/><br/>Materials that are found in Nature display a wide range of properties including responsiveness to the environment, signal transmission, and the ability to adapt to support life. Learning from Nature or biomimicry can be a powerful tool in designing, developing and accessing the next generation of synthetic materials and systems. Furthermore, biomimetic concepts will account for an estimated $1.2 trillion in global economic development, and have already contributed to familiar products like Velcro and wind turbines. Thus, there is a critical need for the US to educate the next generation of internationally-minded biomimicry thinkers to develop a new wave of innovative materials. As such, this PIRE brings together an interdisciplinary team of US and Swiss collaborators to carry out research and education in the area of Bio-Inspired Materials & Systems. Specifically, the PIRE will utilize inspiration from Nature to design new materials that can change toughness in response to their environment, are safer and more effective biological implants, will transmit nerve-like electrical signals, and can respond to the environment to initiate biological processes, all for use in soft robotic applications. <br/><br/>A range of innovative educational and outreach activities will train US students in learning from Nature and in a bio-inspired philosophy. This training will happen in an international context with Swiss collaborators, world leaders in biomimetic concepts and research. Students will gain exposure to themes cutting across chemistry, polymers, physics, biology, and engineering in the development of multi-functional, active materials. Mentoring, diversity, cultural competency, globalization, and effective scientific communication are emphasized as critical elements of the PIRE.<br/><br/>Nature has a multitude of examples of complex materials and systems that go well beyond the current capabilities of synthetic systems. The innovation potential in this domain is vast and a large-scale interdisciplinary effort is required to realize paradigm-changing scientific breakthroughs. To that end, an international partnership between biomimicry experts at Case Western Reserve University (CWRU), the University of Chicago (UoC), and the University of Fribourg/Adolphe Merkle Institute in Switzerland in Bio-inspired Materials and Systems is established. Building upon collaborative strengths in polymer synthesis, computational modeling, mechanical characterization, robotics, imaging, manufacturing, biology, biomedical engineering, physics, and molecular engineering, five Bio-inspired Materials and Systems projects are envisioned: (1) Silk-inspired Nanocomposites: Spider/Caddisfly Silk Mimics; (2) Sea Cucumber, Squid Beak and Pine Cone Inspired Adaptive Composites; (3) Excitable Polyelectrolyte Fiber Networks/Gels: Toward Artificial Neurons; (4) Dynamic and Functional Fibers Inspired by the Extracellular Matrix; and (5) Soft Robotics Inspired by Worm Locomotion. These research thrusts are directed toward the development of functional, programmable, and responsive materials for deployment in soft robotic systems.  Faculty, graduate, and undergraduate students will spend time in Switzerland engaging in synergistic research/educational activities. An educational and innovation partnership with local thought leaders in biomimicry will guide the training of the next-generation of global scientists and engineers in this interdisciplinary endeavor. Effective science communication will be highlighted via existing programming with the Museum of Science and Industry (MSI) of Chicago. Community outreach activities include research opportunities at CWRU and UoC for underrepresented high school students in STEM as part of an expanded Biomimetic Envoys program and the development of biomimetic hands-on demonstrations for annual participation in the Martin Luther King Jr. (MLK) Discovery Day at the Cleveland Museum of Natural History."
"1838347","2018 NSF NRI PIs Meeting Logistics","IIS","National Robotics Initiative","09/01/2018","08/15/2018","Frankie King","TN","Vanderbilt University","Standard Grant","David Miller","05/31/2019","$267,047.00","","frankie.king@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","CSE","8013","063Z, 7556, 8086","$0.00","The objective of this award is to organize the logistics portion of the annual Principal Investigators (PI) meeting for the National Robotics Initiative (NRI), which was launched in 2011. The PI meeting brings together the community of researchers, companies, and program officers who are actively engaged in the NRI to provide cross-project coordination in terms of common intellectual challenges, methods for education and training, best practices in education, technology transfer and general outreach, and a centralized and lasting repository illustrating the research ideas explored and milestones achieved by the NRI projects.<br/><br/>The meeting of the Principal Investigators of the National Robotics Initiative will be two days in October 2018 in the vicinity of Washington DC. The format will include presentations by the attending PIs of projects in their final year, a poster session with all other projects, keynote speeches, and panel discussions. Invitations to the meeting will include all PIs with active NRI grants, program managers with robotics-related programs, and members of the press. This award will take care of the venue, travel, A/V, supplies, and many of the personnel involved in organizing the meeting.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1831177","STTR Phase II: A Low Cost Robotics kit for Elementary Education","IIP","STTR PHASE II","08/15/2018","08/15/2018","Tom Lauwers","PA","BirdBrain Technologies","Standard Grant","Rajesh Mehta","07/31/2020","$749,999.00","Illah Reza Nourbakhsh","tlauwers@birdbraintechnologies.com","544 Miltenberger St","Pittsburgh","PA","152195971","8883716161","ENG","1591","1591, 8031","$0.00","This STTR Phase II project supports standards-based math education in elementary school classrooms with a hands-on technology intervention. Research has shown that many elementary teachers suffer from low confidence and limited subject content knowledge in math and struggle to develop instruction designed to meet or exceed common core math learning goals. Teachers and researchers alike seek new approaches to engage students and improve teacher effectiveness to improve learning outcomes. The primary goal of this project is the development of a flexible, user-friendly, hands-on robotics kit with associated curriculum and support for teachers, that will engage students in learning math content, align with core curriculum, and measurably increase student achievement. The commercialization of this research-based classroom kit will enable school districts to adopt active learning into their math pedagogy. Ultimately, this promotes the NSF mission to increase national prosperity through science innovation by improving math preparation for students across the United States and preparing them to participate in careers that drive the advancement of science and technology.<br/><br/><br/>The core contribution of this work is composed of a flexible hardware kit to enable active learning within the core elementary curriculum as well as more traditional maker activities, and a suite of apps that allow students to use this kit to learn specific math content while also providing options to learn computational thinking through general purpose programming apps. To accomplish this, the team employs a proven design process in which hardware, software, and curriculum are simultaneously designed to align to learner goals, evaluated in classroom studies, and iteratively refined. The kit will combine the ease of use and simplicity of a regular snap-together style electronics kit with the flexibility of a programmable microcontroller. The apps developed for this project will build on a new math-based paradigm for robot programming. These math-oriented apps will remove the barrier of programming skills for elementary teachers and students alike when using the electronics kit for math instruction. Simultaneously, programming apps will enable open-ended explorations of making and computational thinking. Another contribution of this project will be the testing and analysis of the hardware system and complementary math curricula. Formative evaluation will enable exploration and understanding of novel mechanisms for learning math, and evaluation of the program's efficacy will enable characterization of the impact on student outcomes in math achievement and attitudes towards math.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1808898","Collaborative Research: Reinforcement learning based adaptive optimal control of powered knee prosthesis for human users in real life","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/15/2018","08/14/2018","He Huang","NC","North Carolina State University","Standard Grant","Anthony Kuh","07/31/2021","$149,075.00","","hhuang11@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","ENG","7607","1653","$0.00","The proposed research aims at designing robust, real time learning controllers for powered lower limb prosthesis worn by above-knee amputees. It centers on adaptive optimal tuning of prosthetic knee joint impedance parameters with an ultimate goal of achieving human-prosthesis symbiosis. Current state-of-the-art approaches rely on a predetermined collection of knee joint impedance parameters, resulted from tedious manual tuning in a clinic. In addition to a lack of adaptability to different users, current impedance controls do not adapt to different use environments. One of the key design challenge is due to the constant interaction between the human user and the robotic leg. As such, advanced robotics including those employing latest artificial intelligence technologies, control system theory and design, and existing biomechanics based controls cannot meet the needs of real time learning control of a powered prosthetic leg in a human-prosthesis system. Given the nature of the problem, reinforcement learning based adaptive optimal control, also referred to as adaptive dynamic programming (ADP), holds great promise to delivering the next generation of prosthesis control solutions. <br/><br/>Intellectual Merit: The design challenge requires innovative approaches of real time reinforcement learning control. The learning controller has to be designed without knowing an explicit dynamic system model describing the human-prosthesis system, while assuring human user safety and system stability, and being scalable and adaptable to different users and use conditions. Putting it all together, the success of this project will be an important milestone for machine learning, control engineering, and rehabilitation engineering. <br/><br/>Broader Impacts: This research has a direct impact on improving the lives of above-knee amputees. Also of great societal impact is the potential of reducing health care cost. New knowledge gained from human-robot interaction will not only aid amputees but also stroke patients who use exoskeleton as assistive devices. The proposed research will also benefit several research communities such as wearable robots, machine learning, and rehabilitation to develop new technologies addressing real applications. To excite and educate future leaders and researchers in science and engineering, the project will provide an opportunity for integration of our research work into graduate education and postdoc training.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1808752","Collaborative Research: Reinforcement learning based adaptive optimal control of powered knee prosthesis for human users in real life","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/15/2018","08/14/2018","Jennie Si","AZ","Arizona State University","Standard Grant","Anthony Kuh","07/31/2021","$250,925.00","","si@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","ENG","7607","1653","$0.00","The proposed research aims at designing robust, real time learning controllers for powered lower limb prosthesis worn by above-knee amputees. It centers on adaptive optimal tuning of prosthetic knee joint impedance parameters with an ultimate goal of achieving human-prosthesis symbiosis. Current state-of-the-art approaches rely on a predetermined collection of knee joint impedance parameters, resulted from tedious manual tuning in a clinic. In addition to a lack of adaptability to different users, current impedance controls do not adapt to different use environments. One of the key design challenge is due to the constant interaction between the human user and the robotic leg. As such, advanced robotics including those employing latest artificial intelligence technologies, control system theory and design, and existing biomechanics based controls cannot meet the needs of real time learning control of a powered prosthetic leg in a human-prosthesis system. Given the nature of the problem, reinforcement learning based adaptive optimal control, also referred to as adaptive dynamic programming (ADP), holds great promise to delivering the next generation of prosthesis control solutions. <br/><br/>Intellectual Merit: The design challenge requires innovative approaches of real time reinforcement learning control. The learning controller has to be designed without knowing an explicit dynamic system model describing the human-prosthesis system, while assuring human user safety and system stability, and being scalable and adaptable to different users and use conditions. Putting it all together, the success of this project will be an important milestone for machine learning, control engineering, and rehabilitation engineering. <br/><br/>Broader Impacts: This research has a direct impact on improving the lives of above-knee amputees. Also of great societal impact is the potential of reducing health care cost. New knowledge gained from human-robot interaction will not only aid amputees but also stroke patients who use exoskeleton as assistive devices. The proposed research will also benefit several research communities such as wearable robots, machine learning, and rehabilitation to develop new technologies addressing real applications. To excite and educate future leaders and researchers in science and engineering, the project will provide an opportunity for integration of our research work into graduate education and postdoc training.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1456471","Neuromechanics of Soft-bodied Locomotion","IOS","Engineering of Biomed Systems, CROSS-EF ACTIVITIES, ACTIVATION","08/01/2015","09/01/2015","Barry Trimmer","MA","Tufts University","Continuing grant","Sridhar Raghavachari","07/31/2019","$610,000.00","","barry.trimmer@tufts.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","BIO","5345, 7275, 7713","004E, 137E, 8007, 9178, 9179","$0.00","Animals are remarkably good at moving in complex and changing environments, far exceeding the capability of the most advanced robots. This adaptability is possible because the nervous system and the body interact with the environment as a single ""neuromechanical system"". In animals, this process is dominated by soft tissues such as muscles and skin but it is largely unknown how the movements of soft materials are controlled. This project will answer this question by studying how neural, mechanical and sensing mechanisms contribute to adaptable locomotion. The experiments will be carried out on caterpillars because they provide a unique opportunity to use electrophysiology (recording the electrical activity of neurons and muscles), motion capture and mechanical measurements during free behavior. In addition to addressing issues that are largely missing from our understanding of terrestrial soft animal locomotion, these studies have wide applications in robotics including the design and control of climbing machines, building assistive devices and manipulators and for controlling better prosthetics. Understanding the mechanical and sensory features that are important for caterpillar locomotion could also impact the development of pesticide-free pest-control strategies (e.g., plant surface engineering), managing sensitive ecological niches and modeling insect/host plant interactions.<br/><br/>Three areas of research will determine how caterpillars adjust their locomotion in different environments. The first uses motion capture to analyze the stepping patterns (gaits) on different substrates and changes in orientation. The mechanical properties of the substrate (including stiffness, density, curvature, resilience, pseudo-elasticity, friction) will be altered systematically to establish what mechanical features of the environment are essential cues for caterpillars. The second will use implanted flexible electrode arrays to monitor the activity of neurons that underlie each gait. The Environmental Skeleton hypothesis predicts that motor patterns controlling the body wall muscles will change with orientation but that motor patterns controlling grip will determine the gait. Recently developed Softworm robots (entirely soft, 3D-printed crawling robots) will be used to further examine the mechanisms of gait switching and the evolution of inching behavior. Third, to begin identifying how interactions with the environment are detected by soft animals, recordings will be made from specific groups of touch and other mechanosensing neurons in the body wall to ascertain what movements they encode and how that relates to crawling and changes in gait."
"1514882","INSPIRE: Legged Locomotion for Desert Research","IIS","INFORMATION TECHNOLOGY RESEARC, GEOMORPHOLOGY & LAND USE DYNAM, SURFACE EARTH PROCESS SECTION, National Robotics Initiative, INSPIRE","10/01/2015","03/17/2015","Daniel Koditschek","PA","University of Pennsylvania","Standard Grant","Reid Simmons","09/30/2018","$1,000,000.00","Douglas Jerolmack","kod@ese.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","1640, 7458, 7570, 8013, 8078","8086, 8653","$0.00","This INSPIRE project is supported by the Directorate of Computer and Information Science and Engineering, the Division of Information and Intelligent Systems, the Directorate of Geosciences, Division of Earth Sciences, and the Office of International and Integrative Activities.  Sand and dust storms menace the world. They impact large human populations on nearly every continent, damage habitation, disrupt transportation, threaten agriculture, biodiversity, human health and life, and degrade the environment (desertification). A team of scientists and engineers is developing an autonomous legged robot research assistant, designed to operate within harsh desert environments for purposes of gathering heretofore unavailable measurements of wind and sand movement under conditions far too uncomfortable and dangerous for human presence. These data may offer new insights into dust production and its global effects that could significantly impact predictions of environmental degradation by climate change in drylands. At the same time, meeting the formidable mobility and perceptual capabilities arising from scientists' requirements will advance the foundations and practice of robotics. Ultimately, advances in control of dust emissions from soils made possible by this novel collaboration could prolong the sustainability of the agroecosystem and result in improved air quality of downwind population centers.<br/><br/>Dust emission has traditionally been assumed to release sediment previously deposited in soil, but there is growing evidence that sand abrasion may actually produce significant quantities of new dust. Establishing sand seas as dust factories, rather than simply dust reservoirs represents a qualitatively new result that would cascade through aeolian and climate science. But the severe events of interest are hidden from existing conventional instruments and they pose presently insurmountable challenges to flying,  wheeled or even tracked vehicles.  Aeolian science needs legged machines to negotiate the steep, shifting slopes, and broken ground under the environmental conditions of interest. Steady running over simple terrain is a largely solved problem in robotics, but transitional maneuvers and agile negotiation of geometrically complex, unstable, fragile terrain characteristic of desert substrates pose a daunting next challenge for legged locomotion, requiring new approaches to turning, gait control, and perception."
"1446592","CPS: Frontier: Collaborative Research: BioCPS for Engineering Living Cells","CNS","S&AS - Smart & Autonomous Syst, SPECIAL PROJECTS - CISE, CYBER-PHYSICAL SYSTEMS (CPS)","05/01/2015","09/15/2017","R. Vijay Kumar","PA","University of Pennsylvania","Continuing grant","Ralph Wachter","04/30/2019","$1,425,147.00","","Kumar@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","039Y, 1714, 7918","7918, 8236, 9251","$0.00","Recent developments in nanotechnology and synthetic biology have enabled a new direction in biological engineering: synthesis of collective behaviors and spatio-temporal patterns in multi-cellular bacterial and mammalian systems. This will have a dramatic impact in such areas as amorphous computing, nano-fabrication, and, in particular, tissue engineering, where patterns can be used to differentiate stem cells into tissues and organs. While recent technologies such as tissue- and organoid on-a-chip have the potential to produce a paradigm shift in tissue engineering and drug development, the synthesis of user-specified, emergent behaviors in cell populations is a key step to unlock this potential and remains a challenging, unsolved problem. <br/><br/>This project brings together synthetic biology and micron-scale mobile robotics to define the basis of a next-generation cyber-physical system (CPS) called biological CPS (bioCPS). Synthetic gene circuits for decision making and local communication among the cells are automatically synthesized using a Bio-Design Automation (BDA) workflow. A Robot Assistant for Communication, Sensing, and Control in Cellular Networks (RA), which is designed and built as part of this project, is used to generate desired patterns in networks of engineered cells. In RA, the engineered cells interact with a set of micro-robots that implement control, sensing, and long-range communication strategies needed to achieve the desired global behavior. The micro-robots include both living and non-living matter (engineered cells attached to inorganic substrates that can be controlled using externally applied fields). This technology is applied to test the formation of various patterns in living cells. <br/><br/>The project has a rich education and outreach plan, which includes nationwide activities for CPS education of high-school students, lab tours and competitions for high-school and undergraduate students, workshops, seminars, and courses for graduate students, as well as specific initiatives for under-represented groups. Central to the project is the development of theory and computational tools that will significantly advance that state of the art in CPS at large. A novel, formal methods approach is proposed for synthesis of emergent, global behaviors in large collections of locally interacting agents. In particular, a new logic whose formulas can be efficiently learned from quad-tree representations of partitioned images is developed. The quantitative semantics of the logic maps the synthesis of local control and communication protocols to an optimization problem. The project contributes to the nascent area of temporal logic inference by developing a machine learning method to learn temporal logic classifiers from large amounts of data. Novel abstraction and verification techniques for stochastic dynamical systems are defined and used to verify the correctness of the gene circuits in the BDA workflow."
"1663037","Collaborative Research: Exploiting Tunable Stiffness for Dynamic Adhesion Control at the Macro- and Micro-Scale","CMMI","Materials Eng. & Processing","04/01/2017","05/15/2018","Kevin Turner","PA","University of Pennsylvania","Standard Grant","Thomas F. Kuech","03/31/2020","$284,982.00","","kturner@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","ENG","8092","024E, 116E, 1444, 8021, 9178, 9231, 9251","$0.00","Surfaces with dynamically switchable adhesion have a wide range of applications in fields such as robotics and manufacturing. For example, surfaces with switchable adhesion enable new types of gripping surfaces for use in climbing and perching robots. This award supports research to realize a new concept in switchable adhesive surfaces based on the use of composite materials where the stiffness of one component of the material can be changed via the application of an electrical signal. By modulating the stiffness of one component of the composite, the manner in which force is distributed to the interface is altered, and as a result, the effective adhesion strength of the interface is changed. The underlying adhesion mechanics of these materials will be established through modeling and experiments, thus enabling the optimized design of composite structures with dynamically switchable adhesion. This project is a collaboration between researchers at the University of Nevada, Reno and the University of Pennsylvania and will result in the training of students in advanced materials, mechanics, manufacturing, and soft robotics, thus contributing to the development of the engineering workforce in the U.S.<br/><br/>The research will realize new composite materials with dynamically tunable adhesion through a research plan that includes the design, fabrication, and characterization of two classes of elastomer-based composite materials with high dry adhesion strength. Finite element-based multiphysics models will be used to investigate the how the structure of the composite and the stiffness heterogeneity contribute to the effective adhesion strength. Scalable routes to realize flat and fibrillar surfaces made of these composite materials will be developed by leveraging microfabrication techniques and recent manufacturing advances from the field of soft robotics and electronics. Characterization efforts will focus on establishing: (1) the mechanical and adhesion properties of the constituent materials in order to inform the modeling and simulation effort, and (2) the adhesion properties and performance of the novel composite material systems that are fabricated. This research will lead to an improved fundamental understanding of the mechanics and manufacturing of composite material systems with tunable adhesion."
"1527202","NRI: Novel Prosthetic Arm Control Based on a Low-Dimensional Internal Musculoskeletal Biomechanical (LIMB) Model","IIS","Disability & Rehab Engineering, National Robotics Initiative","08/01/2015","07/05/2016","He Huang","NC","North Carolina State University","Standard Grant","Irina Dolinskaya","07/31/2019","$889,387.00","Jonathan Stallrich","hhuang11@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","5342, 8013","010E, 8086, 9251","$0.00","Upper limb amputation is a major cause of disability for nearly 160,000 Americans, many of whom could benefit from emergent sophisticated robotic, multifunctional prosthetic arms/hands. In these advanced prostheses, movements are typically controlled by interpreting the user's electromyographic (EMG) signals from residual or reinnervated muscles. State-of-the-art pattern recognition (PR) has been the most promising EMG control interface for multifunctional artificial arms. However, EMG PR-based control algorithms often require lengthy and frequent algorithm training and lack reliability when the external loading or arm posture changes. This is partly because EMG PR is data-driven and does not account for the behavior of the underlying neural or biomechanical system from which the EMG signals are sourced. The objective of this project is to develop a novel EMG control of multifunctional transradial (TR) prostheses based on a systematic study of neuromuscular control and biomechanical roles of residual muscles in TR amputees. This research can potentially enhance the health, function, and quality of life of upper limb amputees. This project's concept, methods, and frameworks for enhancing EMG-based prosthesis control may be extended to other assistive robotics to benefit other patient populations such as stroke survivors. This project will impact STEM education by promoting project-based cross-training among K-12, undergraduate, and graduate students in underrepresented groups including females, minorities, and students with disabilities. The research may also impact the neuroscience and movement science communities by elucidating the control mechanism of the arm/hand and unveiling new knowledge of neuroplasticity and the internal model in upper limb amputees. <br/><br/>At the core of the multifunctional prosthesis control is a musculoskeletal model of the missing limb that will be used to interpret intended joint motions from EMG signals. The intellectual merit of this project includes a new concept for the control of robotic, multifunctional prosthetic arms/hands. The PIs' musculoskeletal model-based interface is fundamentally different from existing data-driven, EMG PR-based control because it interprets EMG signals and decodes user movement intent in a more biological way. Additionally, this effort will result in new knowledge regarding the neuroplasticity, neuromuscular control, and perceived biomechanical roles of residual muscles in upper limb amputees, which has not been systematically investigated based on the investigators' knowledge. Ultimately, the project will result in a new prosthesis control that, compared to state-of-the-art EMG PR-based control, may require significantly fewer and shorter calibrations, provide more intuitive, robust control (against posture changes, external loading, etc.), and enable multi-joint coordinated prosthesis operations. The investigators expect that the research may transform the way in which upper limb amputees operate multifunctional prostheses in daily life."
"1527140","NRI: Balance Recovery Control for Amputees Using Powered Leg Prostheses","CMMI","National Robotics Initiative","08/01/2015","04/27/2018","Hartmut Geyer","PA","Carnegie-Mellon University","Standard Grant","Irina Dolinskaya","07/31/2019","$908,000.00","Steve Collins","hgeyer@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","8013","116E, 8086, 9178, 9231, 9251","$0.00","Falls among amputees are frequent, costly and negatively impact quality of life. In 2005, there were one million people in the United States with lower limb amputation. About 10 percent of these people experience at least one fall that results in serious injury, resulting in estimated costs to the United States health care system of about $1.1 billion annually. This number is expected to quadruple by the year 2050 due to increasing rates of obesity and diabetes. People with amputation are conscious of their increased fall risk, leading to reduced mobility and social activity. About half of the amputee population reports a fear of falling. Similarly large numbers list as major limitations to their quality of life the inability to walk on uneven terrain or without a stabilizing gait aid. These facts highlight the challenge imposed by imbalance, and suggest that improving balance recovery in amputee locomotion would significantly improve the quality of life of lower-limb amputees as well as reduce related health care costs. The emerging field of robotic prosthetics provides the opportunity to attack this problem with novel prosthesis designs and control strategies. The project seeks to take advantage of this opportunity. It combines computational models of the human neuromuscular control system with novel designs of powered knee-and-ankle prostheses and biomechanical gait analysis to establish new control paradigms for powered prostheses that substantially improve the ability of amputees to recover from large disturbances. Implemented in commercial devices, these control techniques could reduce fall rates and fear of falling, thereby improving the mobility and quality of life for millions of people. Other benefits of the project include the support of education. Graduate and undergraduate students will be trained and mentored, and research tools and outcomes will be integrated into coursework, including the  software and hardware tools developed in this project for studying prosthesis control and disturbance recovery in human locomotion. In addition, the project supports the dissemination of research results by publishing and freely providing simulation code, control implementation code, and hardware designs online.<br/><br/>The overarching goal of this project is to test the hypothesis that a reflex-like prosthesis control strategy inspired by human motor control substantially improves the balance recovery for above-knee amputees during walking. Balance recovery has evolved into a major research area as fall-connected injuries are one of the main causes of impairment, disability and death in aging societies. Lower limb amputees are especially at risk of falling as current prosthetic limbs provide only limited functionality for recovering from unexpected disturbances. The project combines methods from computational neuromechanics, robotic prosthetics, and biomechanical gait analysis to identify prosthesis control strategies that help above-knee amputees recover balance after large disturbances such as trips, slips and pushes. An existing reflex control model of human locomotion is adapted to amputee gait, involving theoretical research on feedback control algorithms for powered prosthetic limbs and predictions of amputee recovery behavior in simulated experiments. Prototypes of powered knee-ankle prostheses are developed, including a tethered prosthesis emulator for rapid human-in-the-loop control design and evaluation on a treadmill, and a mobile prosthesis allowing evaluation outside the laboratory. Control algorithms identified in the reflex control model are embedded in these prototypes and systematically evaluated in balance recovery experiments with above-knee amputees. An outcome confirming the hypothesis could establish new control paradigms for powered prostheses and enable practical controllers for improved balance recovery in amputee gait. In addition, the project will advance theoretical models of human balance recovery as well as control algorithms and hardware designs for robotic knee-ankle prostheses."
"1724135","CRCNS US-German-Israeli Collaborative Research Proposal: Hierarchical Coordination of Complex Actions","BCS","PERCEPTION, ACTION & COGNITION, CRCNS, Dynamics, Control and System D","09/01/2017","08/14/2017","Neville Hogan","MA","Massachusetts Institute of Technology","Standard Grant","Betty H. Tuller","10/31/2020","$300,000.00","","neville@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","SBE","7252, 7327, 7569","014Z, 030E, 034E, 7252, 7327, 7569, 8024, 8089","$0.00","There are many arenas where humans outperform machines. For example, when coordinated interaction with the physical environment is needed, humans (and animals) vastly out-perform modern robots.  This occurs despite the biological systems having far slower 'hardware' and 'wetware' and much greater complexity than even the most modern robots. This research project seeks to understand the role of complexity in human sensory and motor performance. Human walking under challenging balance conditions will be studied and the use of canes to enhance stability will be included.  The investigators emphasis on learning to balance in challenging environments should lead to new rehabilitation therapies (with or without robotic assistance) to aid recovery of balance and walking (e.g., after stroke). The researchers will create educational units suitable for online presentation to K-12 students and will devise exhibits based on their research for the Museum of Science in Boston.<br/><br/>The central hypothesis to be tested in this project is that complex movements involving physical interaction with objects are organized as a hierarchy formed of modules or primitives. Experiments will study how unimpaired humans learn to walk on narrow beams. Beams of different roundness will vary the challenge. Hand-held canes will alter the available support (like training wheels on a child's bicycle). Computer simulations combined with machine learning will study the benefits and drawbacks of organization as a hierarchy. New mathematical tools will be developed and tested to see if they enable insightful description of human performance in challenging conditions. The research involves a multinational collaboration among scientists from the U.S., Israel, and Germany, each with complementary expertise. The bridge between experimental and theoretical work and the diverse Principal Investigators will help to attract women into the traditionally male-dominated fields of computational neuroscience, robotics and control engineering. Companion projects are being funded by the Federal Ministry of Education and Research, Germany (BMBF) and the US-Israel Binational Science Foundation (BSF)."
"1723998","CRCNS US-German-Israeli Collaborative Research Proposal: Hierarchical Coordination of Complex Actions","BCS","PERCEPTION, ACTION & COGNITION, CRCNS, Dynamics, Control and System D","09/01/2017","08/14/2017","Dagmar Sternad","MA","Northeastern University","Standard Grant","Betty H. Tuller","10/31/2020","$319,919.00","","d.sternad@northeastern.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","SBE","7252, 7327, 7569","014Z, 030E, 034E, 7252, 7327, 7569, 8024, 8089, 9251","$0.00","There are many arenas where humans outperform machines. For example, when coordinated interaction with the physical environment is needed, humans (and animals) vastly out-perform modern robots.  This occurs despite the biological systems having far slower 'hardware' and 'wetware' and much greater complexity than even the most modern robots. This research project seeks to understand the role of complexity in human sensory and motor performance. Human walking under challenging balance conditions will be studied and the use of canes to enhance stability will be included.  The investigators emphasis on learning to balance in challenging environments should lead to new rehabilitation therapies (with or without robotic assistance) to aid recovery of balance and walking (e.g., after stroke). The researchers will create educational units suitable for online presentation to K-12 students and will devise exhibits based on their research for the Museum of Science in Boston.<br/><br/>The central hypothesis to be tested in this project is that complex movements involving physical interaction with objects are organized as a hierarchy formed of modules or primitives. Experiments will study how unimpaired humans learn to walk on narrow beams. Beams of different roundness will vary the challenge. Hand-held canes will alter the available support (like training wheels on a child's bicycle). Computer simulations combined with machine learning will study the benefits and drawbacks of organization as a hierarchy. New mathematical tools will be developed and tested to see if they enable insightful description of human performance in challenging conditions. The research involves a multinational collaboration among scientists from the U.S., Israel, and Germany, each with complementary expertise. The bridge between experimental and theoretical work and the diverse Principal Investigators will help to attract women into the traditionally male-dominated fields of computational neuroscience, robotics and control engineering.<br/><br/>Companion projects are being funded by the Federal Ministry of Education and Research, Germany (BMBF) and the US-Israel Binational Science Foundation (BSF)."
"1604853","Collaborative Research: INFEWS: N/P/H2O: Remote and autonomous sensing for managing the economic and environmental consequences of salinity-impacted agricultural waterways","CBET","ENVIRONMENTAL ENGINEERING","07/01/2016","06/27/2016","Meagan Mauter","PA","Carnegie-Mellon University","Standard Grant","Karl Rockne","06/30/2019","$230,795.00","Paul Scerri","mmauter@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","1440","004Z","$0.00","1604853 / 1604906<br/>Mauter / Viers<br/><br/>Increasing salinity of agricultural waterways is a global problem with critical economic and ecological impacts. When cropland is irrigated with moderately saline waters, salts accumulate in the soil leading to reduced crop yields or permanent land fallowing. While this problem is neither new (ancient irrigation systems led to the degradation of the once fertile soils across Mesopotamia), nor declining in scale (soil salinization is now estimated to impact nearly one-third of all irrigated land worldwide), there are few decision tools for evaluating the techno-economic feasibility of intervention which is the focus of this proposal. Developing decision tools is critical to informing farmers, managers and others who are interested in slowing salinization trends and ensuring the sustainability and resilience of global food systems.<br/><br/>Agricultural waterway salinization imposes considerable economic and ecological damages. The proposed research will develop methods for valuing those damages and comparing the cost-effectiveness of technology and policy interventions. The proposed research will also develop novel methods for efficiently generating a broad, multi-resolution dataset of agricultural waterway salinization critical to implementing these decision models. Finally, the proposed research will evaluate the techno-economic feasibility of salinity reduction interventions, including subsidizing land fallowing, limiting tile drain discharge, and desalinating saline agricultural waters, in a multi-objective decision framework. This research will test and implement the proposed methodology in the Panoche Water and Drainage District and the Westlands Water District, salinity-impacted districts within the San Joaquin River Basin of California and very nearby UC Merced. Collecting, processing, and leveraging data high-resolution data to inform environmental decisions remains a methodological challenge in agricultural systems. The PIs propose to develop a comprehensive decision analysis framework that leverages remote and autonomous sensing to rapidly and cost-effectively evaluate salinity management practices for agricultural waterways. Design and integration of multi-modal sensor networks will inform fundamental relationships between water quality, soil salinity, ecological health, and land use in agricultural environments. Incorporating this information into a decision analysis framework will aid agricultural producers, regulators, and state infrastructure managers in evaluating technologies and policies for salinity management across multiple, often competing, objectives. The first objective of the proposed research is to implement a valuation model to assess the benefits of salinity reduction to agricultural and ecological systems. The second objective is to develop a hierarchical, multi-modal data collection methodology using remote sensing, autonomous robotic watercraft sensors, and sparse, distributed, static sensor networks for efficiently and cost-effectively developing models of agricultural water salinization. The third objective is to evaluate the cost-effectiveness of distributed salinity reduction technologies and policies available to agricultural producers and regulators to minimize the economic and ecological impacts associated with salinized agricultural waterways. This will result in novel, hierarchical, low cost methods for generating high-resolution data sets on agricultural waterway salinity that can be extended to the detection and monitoring of other non-point source emissions in the agricultural industry. The proposed research will also develop novel valuation methods for quantifying the benefits of reducing agricultural waterway salinity for private actors (growers) and the public (ecosystems) at a sufficient resolution to inform policy and technology implementation, a major barrier to policy and technology development for combating salinization issues. Finally, the proposed research will develop algorithms for positioning static sensors to maximize the value of information collected. Throughout, the PIs will develop methods to manage uncertainty in the processing of large datasets. The proposed work will enhance the sustainability of irrigated agriculture by providing a quantitative decision framework in which to compare public and private costs and benefits of salinity reduction. It will also promote workforce development in the emerging field of autonomous and robotic sensing for environmental decision-making by engaging UC Merced undergraduate students in data collection, data management, and data visualization research. UC Merced is a minority serving institution in the Central Valley of CA, and students participating for course credit or full time summer employment will be trained for emerging, high tech jobs in the local agricultural industry. Finally, the PIs will continue the development of an education module for high school students that provides hands-on exposure to environmental science, robotics, and data processing via deployment of autonomous robotic watercraft sensors."
"1617639","RI: Small: High Confidence, Efficient Learning Under Rich Task Specifications","IIS","ROBUST INTELLIGENCE","08/01/2016","06/10/2016","Scott Niekum","TX","University of Texas at Austin","Standard Grant","James Donlon","07/31/2019","$470,000.00","Ufuk Topcu","sniekum@cs.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","7495","7495, 7923","$0.00","Artificially intelligent machines such as autonomous vehicles and personal robots are poised to contribute in  many economic sectors, but cannot be deployed on a large scale without measurable confidence that they will operate correctly.  This is especially true for safety-critical systems in which humans could be injured or infrastructure could be damaged by incorrect behavior.  The proposed research will address this key issue by developing methods that allow intelligent agents to learn to perform challenging tasks and adapt to new situations, while simultaneously providing strong guarantees of correctness and safety.  Once deployed, these future robotic systems will have broad impacts on society ranging from automating small manufacturing to giving new freedom to disabled and elderly populations through safe and personalized in-home care.  The proposed robotics applications will additionally create opportunities for interactive educational K-12 programs to encourage interest in STEM areas, as well as undergraduate and graduate education.<br/><br/>Towards these goals, the proposed work focuses on three primary research thrusts: 1) We will design safe learning algorithms that provide theoretical probabilistic satisfaction and data efficiency guarantees over both the expected reward of a policy and its correctness with respect to a high-level specification. 2) In order to account for the gap between theoretical and practical efficiency in learning, we will develop model-based and model-free off-policy evaluation methods that leverage active sampling strategies and bootstrapping to achieve practical efficiency. 3) We will develop hybrid techniques that combine and amplify the advantages of both strong theoretical and efficient practical guarantees.  The merit of the proposed algorithms will be systematically evaluated on complex, real-world problems in robotic reconfigurable manufacturing that require learning optimized, yet safe policies with a high degree of confidence in settings with low-to-medium quantities of available data."
"1526406","AF:  Small:  Approximation Algorithms for Geometric Network Optimization","CCF","ALGORITHMIC FOUNDATIONS","07/01/2015","06/17/2015","Joseph S. Mitchell","NY","SUNY at Stony Brook","Standard Grant","Rahul Shah","06/30/2019","$450,983.00","Esther Arkin","jsbm@ams.sunysb.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","CSE","7796","7923, 7929, 9102","$0.00","Networks are the backbone of our modern world, from the internet to cellular communication networks, to transportation networks of roads and rails, to the power grid, to social networks, neural networks, computer circuitry, and more.  Optimization problems (such as finding the most efficient way to place sensors or transmitters/relays to achieve coverage and connectivity, or computing a shortest route to visit a set of locations, or determining a set of routes for a fleet of robots to search a domain) arise naturally in logistics applications, including vehicle routing, robotics, advanced transportation systems, and communication.  Many networks are geometric, involving infrastructure deployed in physical spaces or involving geographic coordinates and connectivity based on proximity.  Even abstract networks often have special structure that essentially make them ""geometric"" when viewed appropriately, and this can have an impact on the efficiency of methods used to study them.  This project investigates how to exploit special geometric structure of networks in order to obtain efficient algorithms for solving various optimization problems --- studying them through the lens of computational geometry and approximation algorithms.  A particular challenge addressed by this project is the fact that data is often plagued with errors and sources of uncertainty that must be addressed within the model and the solutions.  <br/><br/>The discovery of ""polynomial-time approximation schemes"" for a wide variety of problems related to the classic ""traveling salesperson problem"" has shown that provable approximation algorithms with substantially better theoretical guarantees are often possible in geometric settings.  The project will advance the state of the art in approximation algorithms for several variants of the vehicle routing problem in geometric domains.  Examples include visibility coverage optimization for static sensors as well as mobile agents (robotic ""watchmen"").  Of special interest are problems involving uncertain geometric data, which may arise from a stochastic process (e.g., weather events) or from imprecise knowledge of deterministic data.  While many of the solution techniques are considered to be purely theoretical, there is some hope that simplifications of earlier techniques will give rise to practical methods and that a deeper understanding of what makes some geometric problems easier to solve than their most general abstract counterparts.  The problems will be attacked on two fronts, through the use of formal algorithmic analysis, with proofs of the tightest possible provable bounds (upper and lower) on worst-case or average-case performance metrics (time, space, and approximation ratio), and through the development of solution techniques designed to be simple, fast, and practical, with new methods and heuristics compared experimentally.<br/><br/>The research has broader impact in transportation engineering, energy optimization, air traffic management, sensor networks, robotics, manufacturing processes and logistics, virtual environments, automated inspection, homeland security, and geographic information systems.  Tools of optimization, network analysis, approximation algorithms, and computational geometry will be developed and applied to attack these problems.  The project will advance the research frontier, while training students at all levels, and from varied disciplines, in the pursuit of research and problem solving.  The project incorporates a tightly-integrated educational mission, through courses, seminars, and training of both graduate and undergraduate students."
"1527432","NRI: Robust Stochastic Control for Agile Aerial Manipulation","IIS","National Robotics Initiative","09/01/2015","08/05/2015","Marin Kobilarov","MD","Johns Hopkins University","Standard Grant","Reid Simmons","08/31/2019","$496,093.00","","marin@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","8013","8086","$0.00","A new class of flying robots are beginning to, not only navigate and observe, their surroundings, but also reach and manipulate objects in places that are difficult for humans to go. Such systems will assist people through manipulation in unsafe or remote locations, and will automate manual labor-intensive tasks such as package delivery, agricultural inspection, and infrastructure repair. Current aerial manipulator prototypes lack the control fidelity to ensure reliability and efficiency that is expected from such operations. To overcome these limitations, the proposed project develops novel control techniques that exploit the capabilities of the aerial vehicle. If successful, this research project will enable agile and safe aerial manipulation in extreme environments that is presently impossible or infeasible using standard methods. <br/><br/>The goal of this research is the realization of planning and control methods with built-in robustness for robots that can interact with and manipulate the environment in autonomous and human-assisted modes. This is accomplished by posing the coupled perception-control problem as a statistical learning problem and adaptively computing decision policies to optimize future performance and minimize probability of safety violation. At the core of the approach lies a provably-stable adaptive control methodology equipped with probabilistic robustness guarantees in terms of maximum expected cost and probability of collision. These bounds correspond to concentration-of-measure inequalities derived through Bayesian probably-approximately-correct analysis. Two experimental platforms provide proof-of-concept for: 1) an autonomous ""Air-gripper"" for repetitive tasks such as load delivery, crop sampling, and remote cleaning; 2) co-robotic ""hands in the sky"" in direct assistance to a human operator enabling access to dangerous or difficult-to-access places, e.g. for inspection and repair in extreme environments, during rescue or security-sensitive missions. The implemented techniques are generally applicable and will be released as open-source ROS-compatible software."
"1604906","Collaborative Research: INFEWS: N/P/H2O: Remote and autonomous sensing for managing the economic and environmental consequences of salinity-impacted agricultural waterways","CBET","ENVIRONMENTAL ENGINEERING","07/01/2016","06/27/2016","Joshua Viers","CA","University of California - Merced","Standard Grant","Karl Rockne","06/30/2019","$105,000.00","","jviers@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2097566405","ENG","1440","004Z","$0.00","1604853 / 1604906<br/>Mauter / Viers<br/><br/>Increasing salinity of agricultural waterways is a global problem with critical economic and ecological impacts. When cropland is irrigated with moderately saline waters, salts accumulate in the soil leading to reduced crop yields or permanent land fallowing. While this problem is neither new (ancient irrigation systems led to the degradation of the once fertile soils across Mesopotamia), nor declining in scale (soil salinization is now estimated to impact nearly one-third of all irrigated land worldwide), there are few decision tools for evaluating the techno-economic feasibility of intervention which is the focus of this proposal. Developing decision tools is critical to informing farmers, managers and others who are interested in slowing salinization trends and ensuring the sustainability and resilience of global food systems.<br/><br/>Agricultural waterway salinization imposes considerable economic and ecological damages. The proposed research will develop methods for valuing those damages and comparing the cost-effectiveness of technology and policy interventions. The proposed research will also develop novel methods for efficiently generating a broad, multi-resolution dataset of agricultural waterway salinization critical to implementing these decision models. Finally, the proposed research will evaluate the techno-economic feasibility of salinity reduction interventions, including subsidizing land fallowing, limiting tile drain discharge, and desalinating saline agricultural waters, in a multi-objective decision framework. This research will test and implement the proposed methodology in the Panoche Water and Drainage District and the Westlands Water District, salinity-impacted districts within the San Joaquin River Basin of California and very nearby UC Merced. Collecting, processing, and leveraging data high-resolution data to inform environmental decisions remains a methodological challenge in agricultural systems. The PIs propose to develop a comprehensive decision analysis framework that leverages remote and autonomous sensing to rapidly and cost-effectively evaluate salinity management practices for agricultural waterways. Design and integration of multi-modal sensor networks will inform fundamental relationships between water quality, soil salinity, ecological health, and land use in agricultural environments. Incorporating this information into a decision analysis framework will aid agricultural producers, regulators, and state infrastructure managers in evaluating technologies and policies for salinity management across multiple, often competing, objectives. The first objective of the proposed research is to implement a valuation model to assess the benefits of salinity reduction to agricultural and ecological systems. The second objective is to develop a hierarchical, multi-modal data collection methodology using remote sensing, autonomous robotic watercraft sensors, and sparse, distributed, static sensor networks for efficiently and cost-effectively developing models of agricultural water salinization. The third objective is to evaluate the cost-effectiveness of distributed salinity reduction technologies and policies available to agricultural producers and regulators to minimize the economic and ecological impacts associated with salinized agricultural waterways. This will result in novel, hierarchical, low cost methods for generating high-resolution data sets on agricultural waterway salinity that can be extended to the detection and monitoring of other non-point source emissions in the agricultural industry. The proposed research will also develop novel valuation methods for quantifying the benefits of reducing agricultural waterway salinity for private actors (growers) and the public (ecosystems) at a sufficient resolution to inform policy and technology implementation, a major barrier to policy and technology development for combating salinization issues. Finally, the proposed research will develop algorithms for positioning static sensors to maximize the value of information collected. Throughout, the PIs will develop methods to manage uncertainty in the processing of large datasets. The proposed work will enhance the sustainability of irrigated agriculture by providing a quantitative decision framework in which to compare public and private costs and benefits of salinity reduction. It will also promote workforce development in the emerging field of autonomous and robotic sensing for environmental decision-making by engaging UC Merced undergraduate students in data collection, data management, and data visualization research. UC Merced is a minority serving institution in the Central Valley of CA, and students participating for course credit or full time summer employment will be trained for emerging, high tech jobs in the local agricultural industry. Finally, the PIs will continue the development of an education module for high school students that provides hands-on exposure to environmental science, robotics, and data processing via deployment of autonomous robotic watercraft sensors."
"1818982","SBIR Phase I:  Situational Awareness in Autonomous Agriculture","IIP","SMALL BUSINESS PHASE I","06/15/2018","06/14/2018","Jianfei Chen","MO","Aware Vehicles, Inc","Standard Grant","Muralidharan S. Nair","02/28/2019","$225,000.00","","jchen@awarevehicles.com","1224 w 62nd st Ste 2","Kansas City","MO","641132907","8168449649","ENG","5371","5371, 8034","$0.00","The broader impact/commercial potential of this project is to enable real-time situational awareness in autonomous vehicles.  With the global population expected to reach 9 billion by 2050 and the uncertain climate changes that create concern over the resources allocated to farming activities, precision agriculture has become the ultimate solution to increase agricultural productivity and efficiency. The proposed system, aiming to integrate aerial and terrain robotics and provide high-throughput crop imaging, will push precision agriculture to the next evolutionary stage ? fully autonomous agriculture. With the R&D efforts in this project, the integrated aerial-terrain robotics and high-throughput imaging system will be ready for commercialization under the proposed sustainable business model and impact farming industries globally. Moreover, the system prototype enabled by smart and mobile docking can be readily adapted to accommodate needs in a variety of other industries, where geospatially large-scale sensing and analytics are in demand, such as transportation network monitoring, civil infrastructure and urban monitoring, logistics and freight management, and monitoring of environmental hazards. The proposed invention and its future robotic products are expected to impact all these sectors by imparting automation in terms of high-dimensional data collection and real-time analytics. <br/><br/>This Small Business Innovation Research Phase I project provides a technology leap that furnishes state-of-the-art terrain robotics with long-range and real-time situational awareness, including pre-operation reconnaissance and post-operation evaluation. A smart docking platform will be developed that provides an unlimited energy supply while serving as an ad-hoc computing engine and enables the possibility of high-throughput imaging for single plants or plant groups.  Such a systematically coupled docking-imaging-computing platform is not found to date. The docking will be realized through three independent mechanisms, including kinetic sensing and calculation, low-cost stereo vision, and radar ranging; and real-time positioning algorithms based on the three mechanisms will be developed through a fail-safe data fusion process. The aerial imaging drone, charged by the docking platform, can perform two modes of imaging activities either towards conventional terrain/field mapping or the novel 4-dimensional (4D) reconstruction proposed in this project. The reconstruction algorithms will be developed based on the fusion of the stereo data and the hyperspectral data, which produces the first-of-its kind 4D spatial-spectral models for high-throughput phenotyping.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1626098","MRI: Development of Experiential Supercomputing: Developing a Transdisciplinary Research and Innovation Holodeck","CNS","MAJOR RESEARCH INSTRUMENTATION, INFORMATION TECHNOLOGY RESEARC","09/15/2016","09/16/2016","Winslow Burleson","NY","New York University","Standard Grant","Rita V. Rodriguez","08/31/2021","$2,888,815.00","Kenneth Perlin, Jan Plass, Michael Shelley, Agnieszka Roginska","wb50@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","1189, 1640","1189","$0.00","This project, developing a distributed instrument to physically integrate seamlessly the physical with the virtual, aims to create a unique experiential supercomputer, an immersive, collaborative, virtual/physical research environment with unparalleled tools for intellectual and creative output, a Holodeck that scientifically exceeds Star Trek science fiction. The work should advance the next-generation experiences in human interaction and deep integration of virtual and physical settings, creating rich actualizing environments to support research and discovery of new paradigms. The flexible, modular, reconfigurable infrastructure will connect researchers, research, and educational facilities across the university, the NYU Global Network University (GNU), and external researchers, communities, and industry partners worldwide. The instrument will enable exploration of a myriad of research questions involving virtual environments, telepresence, collaborative engagement, and remote interaction and create a strong foundation for extended collaborations. The project integrates qualitative and quantitative assessment of affect and motivation, with foundations of learning science, motion science, acoustics, modeling and simulation, robotics and fabrication to improve research effectiveness and scalability to address real world challenges.<br/><br/>The work is accomplished by integrating 3-D printing to physically realize simulated forms, robots to allow virtual models to impact the physical world and interact with it, haptics to provide to human collaborators a sense of tactile feel of virtual objects, and physiological state monitors to try to get ""inside"" the human experience. This ""experiential supercomputing"" serves as a paradigm for human collaboration that translates to all disciplines spanning computer science, engineering, music, psychology, nursing, radiology, applied math, biology, and medicine. The effort transcends visualization to approach human collaboration in its totality and has the potential to transform our fundamental understanding of collaboration, learning, creativity, discovery, and innovation. The NYU Holodeck will be a well-integrated software/hardware instrument incorporating visual, audio, and physical components and novel technologies to enhance social interactions (human-human, human-agent, and human-robot). In its incorporation of rapid prototyping and fabrication tools, this unique instrument fosters creative capacity, and tight coupling of interactive visual, audio, and physical experience. Its research capabilities support comprehensive capture of behavioral, physiological, affective, and cognitive data, and visualization and analysis of the data in real time. Creating innovative environments that bridge simulation, cyber learning, scientific visualization, human-computer interaction, and applied physical science research; the effort enables new types of science where researchers from diverse disciplines can interact with theoretical models, real objects, robots, and agents, engendering insights not possible using 2D, 3D, or other currently available representations."
"1663658","Collaborative Research: Exploiting Tunable Stiffness for Dynamic Adhesion Control at the Macro- and Micro-Scale","CMMI","Materials Eng. & Processing","04/01/2017","05/22/2018","Wanliang Shan","NV","Board of Regents, NSHE, obo University of Nevada, Reno","Standard Grant","Thomas F. Kuech","03/31/2020","$371,610.00","","wshan@unr.edu","1664 North Virginia Street","Reno","NV","895570001","7757844040","ENG","8092","024E, 116E, 1444, 8021, 9150, 9178, 9231, 9251","$0.00","Surfaces with dynamically switchable adhesion have a wide range of applications in fields such as robotics and manufacturing. For example, surfaces with switchable adhesion enable new types of gripping surfaces for use in climbing and perching robots. This award supports research to realize a new concept in switchable adhesive surfaces based on the use of composite materials where the stiffness of one component of the material can be changed via the application of an electrical signal. By modulating the stiffness of one component of the composite, the manner in which force is distributed to the interface is altered, and as a result, the effective adhesion strength of the interface is changed. The underlying adhesion mechanics of these materials will be established through modeling and experiments, thus enabling the optimized design of composite structures with dynamically switchable adhesion. This project is a collaboration between researchers at the University of Nevada, Reno and the University of Pennsylvania and will result in the training of students in advanced materials, mechanics, manufacturing, and soft robotics, thus contributing to the development of the engineering workforce in the U.S.<br/><br/>The research will realize new composite materials with dynamically tunable adhesion through a research plan that includes the design, fabrication, and characterization of two classes of elastomer-based composite materials with high dry adhesion strength. Finite element-based multiphysics models will be used to investigate the how the structure of the composite and the stiffness heterogeneity contribute to the effective adhesion strength. Scalable routes to realize flat and fibrillar surfaces made of these composite materials will be developed by leveraging microfabrication techniques and recent manufacturing advances from the field of soft robotics and electronics. Characterization efforts will focus on establishing: (1) the mechanical and adhesion properties of the constituent materials in order to inform the modeling and simulation effort, and (2) the adhesion properties and performance of the novel composite material systems that are fabricated. This research will lead to an improved fundamental understanding of the mechanics and manufacturing of composite material systems with tunable adhesion."
"1446474","CPS: Frontier: Collaborative Research: BioCPS for Engineering Living Cells","CNS","SPECIAL PROJECTS - CISE, CYBER-PHYSICAL SYSTEMS (CPS)","05/01/2015","05/21/2018","Ron Weiss","MA","Massachusetts Institute of Technology","Continuing grant","Ralph Wachter","04/30/2019","$1,200,000.00","","rweiss@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","1714, 7918","7918, 8236","$0.00","Recent developments in nanotechnology and synthetic biology have enabled a new direction in biological engineering: synthesis of collective behaviors and spatio-temporal patterns in multi-cellular bacterial and mammalian systems. This will have a dramatic impact in such areas as amorphous computing, nano-fabrication, and, in particular, tissue engineering, where patterns can be used to differentiate stem cells into tissues and organs. While recent technologies such as tissue- and organoid on-a-chip have the potential to produce a paradigm shift in tissue engineering and drug development, the synthesis of user-specified, emergent behaviors in cell populations is a key step to unlock this potential and remains a challenging, unsolved problem. <br/><br/>This project brings together synthetic biology and micron-scale mobile robotics to define the basis of a next-generation cyber-physical system (CPS) called biological CPS (bioCPS). Synthetic gene circuits for decision making and local communication among the cells are automatically synthesized using a Bio-Design Automation (BDA) workflow. A Robot Assistant for Communication, Sensing, and Control in Cellular Networks (RA), which is designed and built as part of this project, is used to generate desired patterns in networks of engineered cells. In RA, the engineered cells interact with a set of micro-robots that implement control, sensing, and long-range communication strategies needed to achieve the desired global behavior. The micro-robots include both living and non-living matter (engineered cells attached to inorganic substrates that can be controlled using externally applied fields). This technology is applied to test the formation of various patterns in living cells. <br/><br/>The project has a rich education and outreach plan, which includes nationwide activities for CPS education of high-school students, lab tours and competitions for high-school and undergraduate students, workshops, seminars, and courses for graduate students, as well as specific initiatives for under-represented groups. Central to the project is the development of theory and computational tools that will significantly advance that state of the art in CPS at large. A novel, formal methods approach is proposed for synthesis of emergent, global behaviors in large collections of locally interacting agents. In particular, a new logic whose formulas can be efficiently learned from quad-tree representations of partitioned images is developed. The quantitative semantics of the logic maps the synthesis of local control and communication protocols to an optimization problem. The project contributes to the nascent area of temporal logic inference by developing a machine learning method to learn temporal logic classifiers from large amounts of data. Novel abstraction and verification techniques for stochastic dynamical systems are defined and used to verify the correctness of the gene circuits in the BDA workflow."
"1453886","CAREER: Autonomous Underwater Power Distribution System for Continuous Operation","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","05/15/2015","05/07/2018","Nina Mahmoudian","MI","Michigan Technological University","Continuing grant","David Corman","04/30/2020","$409,701.00","","ninam@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","CSE","7918","1045, 7918","$0.00","This CAREER project responds to an urgent need to develop mobile power distribution systems that lower deployment and operating costs while simultaneously increasing network efficiency and response in dynamic and often dangerous physical conditions.  The significant need for an efficient and effective mobile power distribution system became evident during search and rescue/recovery missions following the Japan tsunami and the disappearance of the Malaysia MH370 airplane.  The technology outcomes from this project will apply to a broad range of environments (in space, air, water or on ground) where the success of long-term robotic network missions is measured by the ability of the robots to operate, for an extended period of time, in highly dynamic and potentially hazardous environments. These advanced features will provide the following advantages: efficiency, efficacy, guaranteed persistence, enhanced performance, and increased success in search/rescue/recovery/discovery missions.  <br/><br/>Specifically, this project addresses the following technology problems as it translates from research discovery toward commercial application: inflated energy use currently required when the autonomous vehicles break from mission to return to recharging station; lack of multi-robot coordination needed to take into account both fundamental hardware and network science challenges necessary to respond to energy needs and dynamic environment conditions. By addressing these gaps in technology, this work establishes the theoretical, computational, and experimental foundation for mobile power delivery and onsite recharging capability.  Moreover, the new technology developed in this project is universally adaptable for disparate autonomous vehicles especially autonomous underwater vehicles (AUVs). In more technical terms, this project creates network optimization and formation strategies that will enable a power distribution system to reconfigure itself depending on the number of operational autonomous vehicles and recharging specifications to meet overall mission specifications, the energy consumption needs of the network, situational conditions, and environmental variables. Such a system will play a vital role in real-time controlled applications across multiple disciplines such as sensor networks, robotics, and transportation systems where limited power resources and unknown environmental dynamics pose major constraints. In addition to addressing technology gaps, undergraduate and graduate students will be involved in this research and will receive interdisciplinary education/ innovation/ technology translation/ outreach experiences through: developing efficient network energy routing, path planning and coordination strategies; designing and creating experimental test-beds and educational platforms; and engaging K-12th grade students in Science, Technology, Engineering and Math including those from underrepresented groups.  <br/><br/>This project engages Michigan Tech's Great Lake Research Center (GLRC) and Center for Agile Interconnected Microgrids (AIM) to develop experimental test-beds and conduct tests that validate the resulting methods and algorithms, and ultimately, facilitate the technology translation effort from research discovery toward commercial reality."
"1446607","CPS: Frontier: Collaborative Research: BioCPS for Engineering Living Cells","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","05/01/2015","08/31/2017","Calin Belta","MA","Trustees of Boston University","Continuing grant","Ralph Wachter","04/30/2019","$1,882,852.00","Douglas Densmore","cbelta@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7918","7918, 8236","$0.00","Recent developments in nanotechnology and synthetic biology have enabled a new direction in biological engineering: synthesis of collective behaviors and spatio-temporal patterns in multi-cellular bacterial and mammalian systems. This will have a dramatic impact in such areas as amorphous computing, nano-fabrication, and, in particular, tissue engineering, where patterns can be used to differentiate stem cells into tissues and organs. While recent technologies such as tissue- and organoid on-a-chip have the potential to produce a paradigm shift in tissue engineering and drug development, the synthesis of user-specified, emergent behaviors in cell populations is a key step to unlock this potential and remains a challenging, unsolved problem. <br/><br/>This project brings together synthetic biology and micron-scale mobile robotics to define the basis of a next-generation cyber-physical system (CPS) called biological CPS (bioCPS). Synthetic gene circuits for decision making and local communication among the cells are automatically synthesized using a Bio-Design Automation (BDA) workflow. A Robot Assistant for Communication, Sensing, and Control in Cellular Networks (RA), which is designed and built as part of this project, is used to generate desired patterns in networks of engineered cells. In RA, the engineered cells interact with a set of micro-robots that implement control, sensing, and long-range communication strategies needed to achieve the desired global behavior. The micro-robots include both living and non-living matter (engineered cells attached to inorganic substrates that can be controlled using externally applied fields). This technology is applied to test the formation of various patterns in living cells. <br/><br/>The project has a rich education and outreach plan, which includes nationwide activities for CPS education of high-school students, lab tours and competitions for high-school and undergraduate students, workshops, seminars, and courses for graduate students, as well as specific initiatives for under-represented groups. Central to the project is the development of theory and computational tools that will significantly advance that state of the art in CPS at large. A novel, formal methods approach is proposed for synthesis of emergent, global behaviors in large collections of locally interacting agents. In particular, a new logic whose formulas can be efficiently learned from quad-tree representations of partitioned images is developed. The quantitative semantics of the logic maps the synthesis of local control and communication protocols to an optimization problem. The project contributes to the nascent area of temporal logic inference by developing a machine learning method to learn temporal logic classifiers from large amounts of data. Novel abstraction and verification techniques for stochastic dynamical systems are defined and used to verify the correctness of the gene circuits in the BDA workflow."
"1637614","NRI: Collaborative Research: A Framework for Hierarchical, Probabilistic Planning and Learning","IIS","National Robotics Initiative","09/01/2016","08/17/2016","Stefanie Tellex","RI","Brown University","Standard Grant","Reid Simmons","08/31/2019","$542,682.00","Michael Littman","stefie10@cs.brown.edu","BOX 1929","Providence","RI","029129002","4018632777","CSE","8013","8086, 9150","$0.00","This project is an effort to create a unified framework for solving very large problems with uncertain states and actions, such as manipulator robots acting in real-world environments.  The results may have especially great promise for assistive technologies, including autonomous robots that can be used by elderly and disabled populations to aid them in their daily activities.  The proposed integrated framework will represent, apply, and learn hierarchical domain knowledge, and will include the ability to transfer knowledge from simpler problems to more complex ones. The research will enable autonomous agents to develop a structured representation of complex domains based on experience. The agents will use learned representations to interpret natural language commands for both low-level and high-level requests.  <br/><br/>The technical focus is enabling tractable planning in large, uncertain domains by generating and leveraging probabilistic domain knowledge at multiple levels of abstraction. Agents will autonomously create layered representations in which the layers build on one another to produce complex behaviors. Agents will learn to perform useful behaviors, such as navigating using low-level sensor feedback or assembling complex objects such as a bridge or a table.  The key technical contributions will be methods for (1) planning in large state/action spaces using the abstract object-oriented Markov decision process (AMDP) model, a new formalism for representing probabilistic domain knowledge at multiple levels of abstraction; (2) learning hierarchical task knowledge in the form of AMDPs; and (3) interpreting natural language commands at multiple levels of abstraction by mapping to the learned hierarchical structure. The formalism will be demonstrated and validated in several domains, including a simulated ""cleanup"" toy domain, challenging and complex video games, and a robot manipulation task."
"1637815","NRI: 3-D Maneuverable Feedback-Controlled Micro Swimming Drone for Biomedical Applications","ECCS","National Robotics Initiative","09/01/2016","07/07/2017","Sung Cho","PA","University of Pittsburgh","Standard Grant","Radhakisan S. Baheti","08/31/2019","$732,691.00","Kang Kim, Nitin Sharma","skcho@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","ENG","8013","092E, 8013, 8086, 9251","$0.00","Inspired by the old classic movie ""Fantastic Voyage"" and the relatively recent movie ""Inner Space"", many scientist and engineers have investigated and developed medical microswimmers that possibly navigate inside human body for the purpose of drug delivery, bio-sensing, imaging, micro surgery, etc. in the hard-to-reach spots. So far, several methods for microswimmers have been developed including magnetic actuation, harness of bacteria, use of biological chemical/biological fuels, etc. However, these methods have many drawbacks including high bulkiness, high cost and incompatibility with human body. In addition, all the above methods were never or rarely integrated with feedback control or tracing systems to maneuver the microswimmer in a three-dimensional space. This National Robotics Initiative (NRI) award supports fundamental research on manufacturing three-dimensionally maneuverable, biodegradable, untethered, micro swimming drones, studying/developing feedback control algorithms to control their three-dimensional trajectory, and evaluating them in biological environments. The proposed micro drone is propelled by acoustically excited micro bubbles such that its driving system can be integrated with the current clinical ultrasound system with minimal amendment. The proposed drone has tremendous impact with societal benefits on various potential medical applications: local treatments of tumors, removal of fatty deposits on blood vessel walls, break or removal of blood clots, kidney stones, liver stones, gouts, burn cleaning and wound debriding, attack and removal of parasites, removal and break of tar in lungs, drug delivery and controlled release, etc. This research project will also have significant impact on education by (i) re-engineering coursework for both undergraduates and graduates in inter/multi-disciplinary areas; (ii) having graduates and undergraduates involved in research especially from the underrepresented groups; and (iii) demonstrating results from this project in K-12 schools and in public websites and hosting a robotics workshop for underrepresented high school students. Finally, the completion of experimental setups in this research will improve infrastructure for training in science and engineering at University of Pittsburgh. <br/><br/>The 3-D micro swimming drone will be microfabricated from biodegradable materials. The drone has gaseous bubbles being oscillated by externally applied ultrasound waves. The waves with focused or unfocused excitation allows individual drones to maneuver in a 3-D space. A dynamic inversion-based feedback controller and a state observer will control the frequency and amplitude of the exciting US waves to force the drone to follow/track a user-defined 3-D path. The developed drone integrated with actuation and control units will be tested under hydrodynamic conditions similar to living organs to explore possible practical applications. In parallel, the underlying physics of 3-D manufacturing, bubble/fluid dynamics, ultrasound beamforming method, and a Lyapunov stability based feedback controller-estimator configuration will be investigated. In addition, stability and convergence guarantees in control will be provided. The fabrication and assembly technique of 3-D structures can be readily applied to many fields whose applications otherwise remain on 2-D structures. Novel beamforming technologies developed for US actuating/imaging of micro object can be adapted for high quality ultrasound imaging for broader, general applications. Advances in understanding and new findings of nonlinear (bubble) cavity oscillation and associated fluid dynamics will help develop the best imaging strategy for microbubbles inside microvasculature structures. In addition, the Lyapunov stability-based nonlinear control design method with a state estimator can be applied to control other robots (and other nonlinear systems with zero dynamics) where only partial information is available. The research results will be disseminated through academic/industrial meetings and publications and integrated with multi-/inter-disciplinary education and public outreach programs."
"1461157","REU Site: Advancing California Community College Students Through Engineering Research","EEC","HUMAN RESOURCES DEVELOPMENT","03/15/2015","10/20/2015","Jeffrey Bokor","CA","University of California-Berkeley","Standard Grant","Mary Poats","02/28/2019","$359,893.00","Sharnnia Artis","jbokor@eecs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","ENG","1360","116E, 9178, 9250","$0.00","BROADER SIGNIFICANCE OF THE PROJECT:<br/><br/>The federal government has forecasted that over the next decade the U.S. economy will need approximately one million more technical professionals than are being produced at the current rate. Increasing the retention of science and engineering majors from 40% to 50% alone would generate three-quarters of the targeted one million additional STEM degrees. The Transfer-to-Excellence Research Experiences for Undergraduates (TTE REU) program of the University of California, Berkeley (UC Berkeley) supports retention in STEM fields by offering hands-on research opportunities in nanotechnology, biotechnology, and robotics to increase the confidence and persistence of community college students in their pursuit of science and engineering education and ultimately technical careers. The program's three research areas have been chosen because they are economically-salient, offer many exciting research opportunities, and will resonate with community college students. The nine-week program brings 10 students per year from California Community Colleges (CCC), the largest community college system in the U.S., to UC Berkeley, where engineering faculty will host students in their world-class research laboratories and mentor them in their own research projects. TTE REU participants will also be trained in research protocol, laboratory safety, scientific ethics, and science communications. The program also provides students with transfer advising, and academic and professional development activities to better prepare them to complete a B.S. degree, pursue graduate studies, and succeed in a technical career.<br/><br/>PROJECT DESCRIPTION:<br/><br/>The Transfer-to-Excellence Research Experiences for Undergraduates (TTE REU) program of the University of California, Berkeley (UC Berkeley) aims to: 1) increase the number of community college students, particularly women and underrepresented minority students, who receive baccalaureate degrees in science and engineering; and 2) expand and diversify the pipeline of future graduate school students. To accomplish these objectives, the TTE REU program builds the research capacity of a diverse body of community college students through hands-on research in nanotechnology, biotechnology, and robotics and encourages them to continue their science and engineering studies and pursue STEM careers. Through generous support from the Division of Engineering Education and Centers (EEC) of the National Science Foundation, REU Site award EEC-1461157, students from California Community Colleges (CCC), the largest community college system in the U.S., will engage in leading-edge research, hosted and advised by the engineering faculty at UC Berkeley. The TTE REU program is integrated with the Center for Energy Efficient Electronics Science an NSF Science and Technology Center based at UC Berkeley. The program enables its CCC students to participate in: 1) nanotechnology research on novel nanomaterials, innovative device concepts, and improving device performance in electronics, optoelectronics and sensors; 2) biotechnology research that advances the underlying science and enhances the research tools for advanced biofuels and bio-based chemicals production; and 3) robotics research on how robots can adapt to their environment and human-in-the-loop systems such as autonomous vehicles and tele-healthcare monitoring that integrate sensing, actuation, and control. In collaboration with UC Berkeley's Transfer Alliance Project, the TTE REU program provides academic advising and enrichment programs that prepare community colleges students to be competitive transfer applicants to 4-year colleges. The individualized academic and transfer advising continues for one academic year following the completion of the TTE REU."
"1440581","Collaborative: SI2-SSE - A Plug-and-Play Software Platform of Robotics-Inspired Algorithms for Modeling Biomolecular Structures and Motions","OAC","SPECIAL PROJECTS - CCF, Software Institutes, CDS&E","02/01/2015","08/08/2014","Amarda Shehu","VA","George Mason University","Standard Grant","Rajiv Ramnath","01/31/2019","$217,288.00","","ashehu@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","2878, 8004, 8084","2878, 7433, 8004, 8005, 8084, 9216","$0.00","This project aims to develop a novel plug-and-play platform of open-source software elements to advance algorithmic research in molecular biology. The focus is on addressing the algorithmic impasse faced by computational chemists and biophysicists in structure-function related problems involving dynamic biomolecules central to our biology. The software platform resulting from this project provides the critical software infrastructure to support transformative research in molecular biology and computer science that benefits society at large by advancing our modeling capabilities and in turn our understanding of the role of biomolecules in critical mechanisms in a living and diseased cell.<br/><br/>The project addresses the current impasse on the length and time scales that can be afforded in biomolecular modeling and simulation. It does so by integrating cutting-edge knowledge from two different research communities, computational chemists and biophysicists focused on detailed physics-based simulations, and AI researchers focused on efficient search and optimization algorithms. The software elements integrate sophisticated energetic models and molecular representations with powerful search and optimization algorithms for complex modular systems inspired from robot motion planning. The plug-and-play feature of the software platform supports putting together novel algorithms, such as wrapping Molecular Dynamics or Monte Carlo as local search operators within larger robotics-inspired exploration frameworks, and adding emerging biomolecular representations, models, and search techniques even beyond the timeline of this project."
"1440587","Collaborative: SI2-SSE - A Plug-and-Play Software Platform of Robotics-Inspired Algorithms for Modeling Biomolecular Structures and Motions","OAC","SPECIAL PROJECTS - CCF, Software Institutes, CDS&E","02/01/2015","08/08/2014","Erion Plaku","DC","Catholic University of America","Standard Grant","Rajiv Ramnath","01/31/2019","$215,476.00","","plaku@cua.edu","620 Michigan Ave.N.E.","Washington","DC","200640001","2026355000","CSE","2878, 8004, 8084","2878, 7433, 8004, 8005, 8084, 9216","$0.00","This project aims to develop a novel plug-and-play platform of open-source software elements to advance algorithmic research in molecular biology. The focus is on addressing the algorithmic impasse faced by computational chemists and biophysicists in structure-function related problems involving dynamic biomolecules central to our biology. The software platform resulting from this project provides the critical software infrastructure to support transformative research in molecular biology and computer science that benefits society at large by advancing our modeling capabilities and in turn our understanding of the role of biomolecules in critical mechanisms in a living and diseased cell.<br/><br/>The project addresses the current impasse on the length and time scales that can be afforded in biomolecular modeling and simulation. It does so by integrating cutting-edge knowledge from two different research communities, computational chemists and biophysicists focused on detailed physics-based simulations, and AI researchers focused on efficient search and optimization algorithms. The software elements integrate sophisticated energetic models and molecular representations with powerful search and optimization algorithms for complex modular systems inspired from robot motion planning. The plug-and-play feature of the software platform supports putting together novel algorithms, such as wrapping Molecular Dynamics or Monte Carlo as local search operators within larger robotics-inspired exploration frameworks, and adding emerging biomolecular representations, models, and search techniques even beyond the timeline of this project."
"1662029","Integrated Computer Vision System Based on Human Eye Motion","CMMI","Dynamics, Control and System D","07/01/2017","05/16/2017","Jun Ueda","GA","Georgia Tech Research Corporation","Standard Grant","Robert Landers","06/30/2020","$332,659.00","","jun.ueda@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","7569","030E, 034E, 8024, 8086","$0.00","The goal of this project is to build a robotic vision system that mimics human eye motions. In particular, this research will lead to an enhanced vision system that can achieve quick scanning capability (saccadic eye motion) and smooth object following capability (smooth-pursuit) with minimal computational overhead and using an inexpensive generic hardware.  Current state-of-the-art systems require significant computer post-processing and expensive hardware.  This project will lead to a novel camera positioning system (hardware) and real-time vision (software) system that does not require any post-processing and produces ready-to-use images in real-time. To achieve this goal, the project draws upon the biomechanical and cognitive principles of human vision. The innovative methods and algorithms that can produce motions with speed, accuracy, and smoothness to mimic human eye can greatly enhance capabilities of autonomous vehicles used in a wide variety of applications such as agriculture, military, security, and traffic monitoring. The project will integrate research and outreach activities for K-12 and undergraduate students. <br/><br/>This project studies a bio-inspired dynamics-based method for coordinating motion control and image processing where the system can mechanically displace the field of view by a large angle between frames. The concept behind this research is to merge the system dynamics area and image processing area while previous studies focused solely on either mechanical design or image processing.  The method is motivated by the principles of human vision for effective image de-blurring and panoramic image stitching. In coordination with inherently discrete and rapid ocular movements, the developed image processing methods inspired by ocular physiology will mimic saccades and smooth-pursuit in a fast-moving robotic eye.  A piezoelectrically driven robotic camera positioning mechanism will be employed to demonstrate the effectiveness of this ocular physiology-inspired approach. Hardware architecture that can synchronize image processing and real-time motion control will be configured and tested. A panoramic image of a scene will be generated from multiple images acquired during saccades by removing motion blur and stitching images within a single frame rate. The system architecture will be optimized to best coordinate hardware and software for real-time motion control."
"1636203","Three-dimensional Micromechanics of Adhesion and Friction between Micro-pillar Arrays and Soft Gel Substrates","CMMI","Mechanics of Materials and Str","09/01/2016","07/10/2016","Rong Long","CO","University of Colorado at Boulder","Standard Grant","Siddiq Qidwai","08/31/2019","$366,090.00","Mark Rentschler","Rong.Long@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","ENG","1630","022E, 024E, 027E, 8086, 9161, AMPP","$0.00","This award investigates the mechanics of how synthetic surfaces with micrometer-sized pillars adhere to and slide on soft and wet substrates. Micro-pillar arrays have been introduced on the wheel treads of robotic devices to improve their mobility on soft tissues, but the underlying mechanism is yet to be understood. Most existing theoretical models on the contact mechanics of micro-structured surfaces assume stiff substrates, and thus are not directly transferable to the case of soft substrates which can deform significantly during adhesive and frictional contact. Results of this research will improve the design of in vivo robotic devices for the next generation technology of non-invasive medical diagnosis and surgery.  More broadly, new knowledge in soft material contact mechanics can also enable robotic handling of food, medical transplants and implants, thus benefiting the food and healthcare industries.  Education and outreach programs will be developed to engage high school though graduate school students, exposing them to the fundamental concepts and exciting forefront of mechanics. Activities include course development, undergraduate student research program, and outreach lessons.<br/><br/>A soft substrate can undergo large deformation upon contact with a micro-pillar array, which is three-dimensional in nature and inherently nonlinear. The large substrate deformation is expected to lead to a strong coupling between the normal and shear loadings of the micro-pillars, as well as between neighboring pillars. Understanding this coupling will facilitate the search for optimal pillar arrangement to achieve desired adhesion and friction properties.  The PIs will develop a new experimental apparatus to achieve in situ mapping of the three-dimensional deformation fields in soft hydrogel substrates under contact, adhesion and friction.  The soft gel substrate serves as a model material to simulate biological tissue or other soft and wet materials.  The in situ deformation mapping capability will be combined with adhesion and friction tests and finite element modeling. The finite element model will connect the local micromechanics at the level of individual pillars to the global adhesion and friction, through an experimentally validated pillar-surface interface model.   Results will offer new theoretical insights on the contact mechanics between micro pillar arrays and soft substrates, and enable high-fidelity simulations to drive the design of micro-pillar structures for optimized adhesion and friction on soft substrates."
"1715251","RI:  Small:  Collaborative Research:  Seeing Surfaces:  Actionable Surface Properties from Vision","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2017","08/09/2017","Ko Nishino","PA","Drexel University","Standard Grant","Jie Yang","08/31/2020","$250,000.00","","kon@drexel.edu","1505 Race St, 10th Floor","Philadelphia","PA","191021119","2158955849","CSE","7495, 8013","7495, 7923","$0.00","This project is to enable computers and robots the capability of estimating actionable, physical properties of surfaces (the feel) from their appearance (the looks). The key idea is to leverage the deeply interwoven relation between radiometric and physical surface characteristics. By learning models that make explicit the physical surface properties encoded in full and partial measurements of radiometric appearance properties, computers can estimate crucial physical properties of real-world surfaces from passive observations with novel camera systems. This project paves the path for integrating these models and estimation algorithms into scene understanding, robotic action planning, and efficient visual sensing. The research results provide a currently missing but fundamental capability to computer vision that benefits a number of applications in areas of computer vision, robotics, and computer graphics. The project provides hands-on research opportunities for both undergraduate and graduate students and are integrated in the PIs' undergraduate and graduate courses taught at Drexel and Rutgers. They are also used as a backdrop for K-12 outreach activities including high school and middle school mentorship programs. The data collection activities provide an ideal platform to expose K-12 students to physics and computer science.<br/><br/>This research investigates the methods to infer actionable surface properties from images and detailed surface reflectance measurements. The research activities are centered on four specific aims: 1) controlled and uncontrolled large-scale data collection of actionable physical properties and appearance measurements of everyday surfaces, 2) derivation of prediction models for deducing physical properties from local surface appearance, 3) integration of global semantic context including object and scene information, and 4) development of efficient appearance capture and its use for novel physics-from-appearance sensing. These research thrusts collectively answer the fundamental question of how computer vision can anticipate the physical properties of a surface without touching it and knowing what it is, laying the foundation for computational vision-for-action."
"1715195","RI:  Small:  Collaborative Research:   Seeing Surfaces:  Actionable Surface Properties from Vision","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2017","08/09/2017","Kristin Dana","NJ","Rutgers University New Brunswick","Standard Grant","Jie Yang","08/31/2020","$249,931.00","","kdana@ece.rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","7495, 8013","7495, 7923","$0.00","This project is to enable computers and robots the capability of estimating actionable, physical properties of surfaces (the feel) from their appearance (the looks). The key idea is to leverage the deeply interwoven relation between radiometric and physical surface characteristics. By learning models that make explicit the physical surface properties encoded in full and partial measurements of radiometric appearance properties, computers can estimate crucial physical properties of real-world surfaces from passive observations with novel camera systems. This project paves the path for integrating these models and estimation algorithms into scene understanding, robotic action planning, and efficient visual sensing. The research results provide a currently missing but fundamental capability to computer vision that benefits a number of applications in areas of computer vision, robotics, and computer graphics. The project provides hands-on research opportunities for both undergraduate and graduate students and are integrated in the PIs' undergraduate and graduate courses taught at Drexel and Rutgers. They are also used as a backdrop for K-12 outreach activities including high school and middle school mentorship programs. The data collection activities provide an ideal platform to expose K-12 students to physics and computer science.<br/><br/>This research investigates the methods to infer actionable surface properties from images and detailed surface reflectance measurements. The research activities are centered on four specific aims: 1) controlled and uncontrolled large-scale data collection of actionable physical properties and appearance measurements of everyday surfaces, 2) derivation of prediction models for deducing physical properties from local surface appearance, 3) integration of global semantic context including object and scene information, and 4) development of efficient appearance capture and its use for novel physics-from-appearance sensing. These research thrusts collectively answer the fundamental question of how computer vision can anticipate the physical properties of a surface without touching it and knowing what it is, laying the foundation for computational vision-for-action."
"1830331","NRI: FND: COLLAB: Distributed Bayesian Learning and Safe Control for Autonomous Wildfire Detection","CNS","National Robotics Initiative","10/01/2018","09/09/2018","Baris Aksanli","CA","San Diego State University Foundation","Standard Grant","Ralph Wachter","09/30/2021","$75,000.00","","baksanli@sdsu.edu","5250 Campanile Drive","San Diego","CA","921822190","6195945731","CSE","8013","8086","$0.00","Wildfires destroy millions of hectares of forest, sensitive ecological systems, and human infrastructure. A critical aspect of mitigating wildfire-related damages is early fire detection, well before initiating fires grow to disastrous proportions. Current practices are based on expensive assets, such as satellites, watchtowers, and remote-piloted aircraft, that require constant human supervision, limiting their use to high-risk or high-value areas. This project aims to take advantage of the hyperconvergence of computation, storage, sensing, and communication in small unmanned aerial vehicles (UAVs) to realize large-scale mapping of environmental factors such as temperature, vegetation, pressure, and chemical concentration that contribute to fire initiation. UAV teams that recharge autonomously and communicate intermittently among each other and with static sensors is a compelling research objective that will aid firefighters with continuous real-time surveillance and early detection of ensuing fires.<br/><br/>This proposal offers three fundamental innovations to address the scientific challenges associated with autonomous, collaborative environmental monitoring. First, a new Satisfiability Modulo Optimal Control framework is proposed to handle mixed continuous flight dynamics and discrete constraints and ensure collision avoidance, persistent communication, and autonomous recharging for UAV navigation. Second, a distributed systems architecture using new uncertainty-weighted models will be developed to enable cooperative mapping across a heterogeneous team of UAVs and static sensors and avoid bandwidth-intensive data streaming. Lastly, a new Bayesian learning and inference approach is proposed to generate multi-modal (e.g., thermal, semantic, geometric, chemical) maps of real-time environmental conditions with adaptive accuracy and uncertainty quantification. This project with its focus on multi-robot teams benefits, e.g., conservation management and search-and-rescue operations. Both applications demand robot coordination, cooperation, and autonomy, including multi-modal mapping, collaborative inference over heterogeneous networks, and multi-objective navigation with safety, communication, and energy constraints.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1730657","CI-P:Collaborative Research:  Open-Source Mobile Underwater Acoustic Network Infrastructure","CNS","COMPUTING RES INFRASTRUCTURE","10/01/2017","07/31/2017","Xiaoyan Hong","AL","University of Alabama Tuscaloosa","Standard Grant","Thyagarajan Nandagopal","03/31/2019","$100,000.00","Aijun Song","hxy@cs.ua.edu","801 University Blvd.","Tuscaloosa","AL","354870005","2053485152","CSE","7359","7359, 9150","$0.00","The capability to explore and monitor our aquatic environments, such as the ocean, lakes, and seaports, is vital to science advancements and societal needs. Examples of applications include environmental monitoring, geophysical surveys, ocean resource management, and more. The next technological breakthrough is to use a fleet of aquatic robots as a mobile underwater acoustic network that autonomously collect and transmit information while navigating in the aquatic environment. Although recent years have seen many new advancements in related fields, the much-needed underwater network technologies still have not materialized. There is a need within the research community for an at-scale community testing infrastructure for underwater networks that can support a wide array of research to enable this future. This project seeks to identify the fundamental research challenges that the community would like to explore in such a testbed, and also have the community define and specify the type of infrastructure that will be most conducive for such wide-ranging experimentation. To this end, the project aims to organize two workshops to engage personnel from the scientific, federal, and commercial sectors in order to develop an infrastructure blueprint to advance the field of underwater mobile communications and networking. The project advances the progress of science by bringing together resources and facilitating development of a research vision for multiple technical fields, including underwater communications and networking, marine robotics, and ocean monitoring. It incubates innovation to address multiple societal challenges, for example, disaster response in the ocean or water quality monitoring in waterways. The workshops aim to broaden the impact by engaging K-12 educators, for example science teachers and aquarium curators. <br/><br/>The main contributions of the project are a research workshop and an infrastructure workshop. The research workshop engages scientists and practitioners from multiple sectors, domestic and international, including: 1) scholars from diverse technical fields in academia with interest or stake in the ocean/underwater ecosystems; 2) scientific staff from various federal funding agencies; 3) scientists from naval research centers; 4) scientists and practitioners from sub-sea industries. The goal of the research workshop is to identify emerging trends, urgent needs, potential users and innovative technologies that will require the services of a large-scale test infrastructure. The goals of the infrastructure workshop are to generate an infrastructure blueprint and to form an able research team to develop, deploy and maintain the community infrastructure. Through these two workshops, the project fosters collaboration among workshop participants from diverse sectors. The envisioned infrastructure is an open-source mobile underwater acoustic network testbed that provides easy access and shared use by the communities of acoustic communications, underwater networking and systems, marine robotics, and data sciences. It seeks to lower the threshold for the research community to utilize underwater mobile communications and, thus, fosters interdisciplinary research."
"1633952","Collaborative Research: Uncovering the Dynamics and Functionality of Origami Structures and Materials","CMMI","Dynamics, Control and System D","09/01/2016","07/19/2016","Suyi Li","SC","Clemson University","Standard Grant","Irina Dolinskaya","08/31/2019","$192,604.00","","suyil@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","ENG","7569","030E, 031E, 032E, 033E, 034E, 035E, 039E, 040E, 099E, 1059, 7234, 8024","$0.00","Origami is the ancient art of folding paper into decorative shapes and geometries.  Over the last several decades, it evolved and became a design framework for many engineering and architecture applications.  Examples include deployable space structures, kinetic buildings, self-folding robots, surgery devices, and advanced materials.  Origami folding so far has been considered as a static process.  People typically focus on its design and geometry, or internal actuation mechanisms that makes the folding autonomous.  This award supports a collaborative project that will investigate the fundamental dynamic characteristics of origami folding.  In particular, the research will explore how to harness the extraordinary properties of origami for applications like vibration isolation at low frequency, recoverable impact absorption, and impulsive actuation.  Furthermore, the research will produce design tools that can generate sophisticated folding patterns and assign material properties that are suitable for a wide variety of dynamic performance requirements.  The results of this project will become the building blocks for the next generation of air, marine, and land vehicles, intelligent machines and robots, or smart infrastructures, enhancing their functionality, safety and sustainability. The findings will thus advance the aerospace, civil, mechanical, robotics and many other industries. Education and broadening participation plans will focus on student learning and community outreach at various levels and on the enhancement diversity through inclusion in the research activities of members of underrepresented minorities in science and engineering.<br/><br/>This research will, for the first time, rigorously investigate the dynamic characteristics of origami folding and develop its corresponding engineering potentials.  Preliminary studies have discovered that origami with generic crease patterns exhibits many attractive properties via folding, such as zero/negative stiffness, pressure dependent multi-stability, and piece-wise stiffness jump.  Such surprisingly rich properties and the corresponding dynamic responses will be analyzed in detail based on an equivalent truss-frame model, which transforms the continuous origami structure into a finite degree of freedom system.  The truss frame model would also become the basis of a comprehensive synthesis tool that incorporates crease perturbation and optimization, so that the origami can be customized for prescribed dynamic performances.  This synthesis tool will bridge the currently separated branches of studies: the mathematical theories of origami design/folding and the engineering of origami based applications.  Overall, the new modeling, analysis and synthesis tools for origami dynamics will create a significant intellectual leap and build a strong foundation for many future related research and development efforts."
"1830399","NRI: FND: COLLAB: Distributed Bayesian Learning and Safe Control for Autonomous Wildfire Detection","CNS","National Robotics Initiative","10/01/2018","09/09/2018","Nikolay Atanasov","CA","University of California-San Diego","Standard Grant","Ralph Wachter","09/30/2021","$675,000.00","Tajana Rosing, Sicun Gao","natanasov@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","CSE","8013","8086","$0.00","Wildfires destroy millions of hectares of forest, sensitive ecological systems, and human infrastructure. A critical aspect of mitigating wildfire-related damages is early fire detection, well before initiating fires grow to disastrous proportions. Current practices are based on expensive assets, such as satellites, watchtowers, and remote-piloted aircraft, that require constant human supervision, limiting their use to high-risk or high-value areas. This project aims to take advantage of the hyperconvergence of computation, storage, sensing, and communication in small unmanned aerial vehicles (UAVs) to realize large-scale mapping of environmental factors such as temperature, vegetation, pressure, and chemical concentration that contribute to fire initiation. UAV teams that recharge autonomously and communicate intermittently among each other and with static sensors is a compelling research objective that will aid firefighters with continuous real-time surveillance and early detection of ensuing fires.<br/><br/>This proposal offers three fundamental innovations to address the scientific challenges associated with autonomous, collaborative environmental monitoring. First, a new Satisfiability Modulo Optimal Control framework is proposed to handle mixed continuous flight dynamics and discrete constraints and ensure collision avoidance, persistent communication, and autonomous recharging for UAV navigation. Second, a distributed systems architecture using new uncertainty-weighted models will be developed to enable cooperative mapping across a heterogeneous team of UAVs and static sensors and avoid bandwidth-intensive data streaming. Lastly, a new Bayesian learning and inference approach is proposed to generate multi-modal (e.g., thermal, semantic, geometric, chemical) maps of real-time environmental conditions with adaptive accuracy and uncertainty quantification. This project with its focus on multi-robot teams benefits, e.g., conservation management and search-and-rescue operations. Both applications demand robot coordination, cooperation, and autonomy, including multi-modal mapping, collaborative inference over heterogeneous networks, and multi-objective navigation with safety, communication, and energy constraints.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1801756","RET Site: Authentic Research Experiences for Teachers (ARETe): Connecting Community College Faculty and Students to University Engineering and Computer Science Labs","EEC","RES EXP FOR TEACHERS(RET)-SITE","09/15/2018","09/07/2018","Sean Shaheen","CO","University of Colorado at Boulder","Standard Grant","Mary Poats","08/31/2021","$599,360.00","Janet Yowell","sean.shaheen@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","ENG","1359","115E, 9177","$0.00","This RET Site: Authentic Research Experiences for Teachers (ARETe): Connecting Community College Faculty and Students to University Engineering and Computer Science Labs enhances coordination between the University of Colorado Boulder (CU) and five, 2-year degree granting community colleges (2YCs) in the Denver-Boulder metropolitan area: Arapahoe Community College, Community College of Aurora, Community College of Denver, Front Range Community College, and Red Rocks Community College. The project creates and cultivates a network of science, technology, engineering, and mathematics (STEM) 2YC faculty with specific expertise on cutting edge topics from first-hand research experience, along with a set of collaboratively-developed educational modules that integrate content with 2YC learning and curricula development goals. <br/><br/>In each year of the project, ten 2YC faculty will collaborate with CU faculty to carry out laboratory research in engineering and computer science disciplines. Example research topics include: organic and hybrid photovoltaics for renewable electric energy generation; remote sensing for precision agriculture; soft robotic manipulators for tactile sensing and robotic perception; ultrafast laser pulse experiments for infrared sensing and chemical characterization; metal nanoparticle catalysis for reduced automotive emissions and renewable material synthesis from biomass; dynamic solar windows for energy-efficient building; coherent laser sources for biomedical imaging; and organic electrochemical transistors for bioelectronic sensing and drug delivery. The 2YC faculty will come away from the immersive experience with in-depth understanding of topics of national need and at the forefront of research on areas as diverse as renewable energy, materials science, biomedical research, robotics, and other areas. In addition to advancing research in a broad array of topics while developing 2YC faculty research knowledge and skills, the project will help 2YCs to integrate their research into STEM curriculum modules specifically targeting 2YC learning goals, but focusing on ARETe research topics. Collaborative module development will be primarily driven by participating 2YC faculty, based on their research experiences at CU. The project aims to establish and cultivate learning communities to facilitate transfer of knowledge to 2YC students, rapid progression of 2YC STEM curricula, and stronger connections between CU and Colorado 2YCs. CU faculty and graduate students will provide in-person and remote support of the implementation and assessment of new curricula, including co-instruction on 2YC campuses. Research teams will follow a structured backward design approach to curriculum module development, utilizing blended and active learning to convey important modern content. As a broad-ranging goal, the cultivation of these Colorado learning communities is expected to help lower the barrier for student transfer from Colorado 2YCs to CU Engineering, through both academic preparation and social/emotional benefits from mentoring by CU faculty and graduate students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637892","NRI: Towards Restoring Natural Sensation of Hand Amputees via Wearable Surface Grid Electrodes","IIS","National Robotics Initiative","09/01/2016","08/31/2016","Xiaogang Hu","NC","University of North Carolina at Chapel Hill","Standard Grant","Wendy Nilsen","08/31/2019","$1,000,000.00","Yong Zhu, He Huang","xiaogang@unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","8013","8086","$0.00","Hand amputation can severely limit the quality of life, for example by making it impossible to sense and manipulate objects, or to express gestures.  Many robotic prosthetic hands have been developed to date, some of which have dexterity approaching that of a human hand, but a key factor limiting acceptance of these devices is the lack of natural and reliable sensory feedback to the user; the substitution of un-natural stimuli such as skin vibration, visual or audio cues doesn't really cut it.  The PI's goal in this research is to explore the use of non-invasive grid electrodes for electrically stimulating the peripheral sensory nerves so they transmit natural (high resolution) haptic sensations to the central nervous system.  Success of this project will revolutionize the way in which human beings communicate with robotic prostheses and transform research in close-loop prosthesis control, shifting amputee haptic sensation feedback from invasive implant techniques to non-invasive surface probing techniques.  The non-invasive nature of the new technology presents the potential for rapid clinical translations with high functional efficiency and user acceptance.  Thus, the research will lead to dramatic improvements in hand amputees' quality of life.  In addition, the work will be integrated into graduate and undergraduate student education at the PI's institution, and outreach programs for K-12 students (especially underrepresented STEM students) will expose them to this innovative science.<br/><br/>This highly creative project adopts an approach that is completely different from the existing techniques for providing sensory restoration/augmentation, and which is supported by the team's preliminary studies.  First, the investigators will design a novel, non-invasive nanowire sensor array that will provide natural sensation of the missing hand.  The thin-film electrode grid will be self-adhesive and highly stretchable.  The multifunctional electrodes will be able not only to provide targeted nerve stimulation but also to record pressures applied on the prosthetic hand, so they can both obtain a rich set of haptic information and also deliver this information to the user accurately and precisely, while inducing minimal interference such as skin discomfort, added weight due to the device, and control signal interference.  Second, the team will create a new way of affording sensory restoration by developing a dynamic stimulation scheme that encodes spatially distinct haptic sensations in the digits and palm.  This will be achieved by selectively recruiting the various afferent fibers innervating different regions of the hand.  The investigators believe that with high spatial resolution based on hand region mapping, the haptic feedback could for the first time enable users to truly perceive the environment by ""using"" their lost hand, and thereby push the sense of embodiment to a new level.  Lastly, new knowledge will be obtained by quantifying the effect of the sensorimotor integration process on closed-loop control of a dexterous prosthetic hand in amputees."
"1400167","Combining Optimality and Correctness in Control Systems","CMMI","Dynamics, Control and System D","08/01/2014","07/17/2014","Calin Belta","MA","Trustees of Boston University","Standard Grant","Robert Landers","07/31/2019","$349,999.00","","cbelta@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","ENG","7569","030E, 031E, 034E","$0.00","Optimal control is an area of engineering focused at maintaining systems close to desired behaviors, while at the same optimizing certain costs. Examples include driving a vehicle along a trajectory while minimizing fuel consumption, controlling a set of thermostats in a building to follow a desired temperature profile while maintaining electricity consumption to a minimum, etc. Formal verification is an area of computer science focused at proving the correctness of system designs. The systems are computer programs and digital circuits, while correctness specifications include safety (making sure nothing bad happens) and liveness (making sure something good eventually happens). With the increasing integration of physical and digital systems into safety critical cyber physical systems, there is a need for computational tools that combine optimal control and correctness requirements. This project establishes a connection between optimal control and formal verification and impacts a large number of areas where correctness and optimality are crucial, such as air traffic control (design safe minimum-energy paths for airplanes taking off and landing in a crowded airport), vehicle autonomy (e.g., persistent surveillance for disaster relief), medical robotics (optimality and safety are fundamental in the robotic needle steering problem), etc. The education and outreach plan includes related courses at the undergraduate and graduate level, the involvement of undergraduate and high school students in research, collaborations with elementary school robotics teams, and the involvement of the Principal Investigator in high school summer internship programs.<br/><br/>The results of this project will include formulations and solutions to optimal control problems with correctness requirements expressed as temporal logic formulas for both finite and infinite systems, in both probabilistic and non-probabilistic setups. The systems under consideration are finite-state transition systems and Markov decisions processes, and infinite-state discrete-time (stochastic) linear systems and piecewise affine systems. Correctness is specified as formulas of Linear Temporal Logic. The optimization objectives include classical average costs per stage and quadratics over state and control variables, as well as some special costs induced by particular specifications. Central to the approach are receding-horizon implementations of the optimal control strategies. The main application area is autonomous vehicle control for search and rescue in disaster relief scenarios."
"1555916","Collaborative Research: Olfactory Navigation: Dynamic Computing in the Natural Environment","PHY","OFFICE OF MULTIDISCIPLINARY AC, Chemistry of Life Processes, PHYSICS OF LIVING SYSTEMS, CROSS-EF ACTIVITIES, MATHEMATICAL BIOLOGY","11/01/2015","06/28/2017","Nathan Urban","PA","University of Pittsburgh","Continuing grant","Krastan B. Blagoev","10/31/2019","$1,818,513.00","G. Bard Ermentrout","nurban@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","MPS","1253, 6883, 7246, 7275, 7334","7237, 8007, 8091, 8251, 9178, 9179, 9183","$0.00","This project was developed at an NSF Ideas Lab on ""Cracking the Olfactory Code"" and is jointly funded by the Physics of Living Systems program in the Physics Division, the Mathematical Biology program in the Division of Mathematical Sciences, the Chemistry of Life Processes program in the Chemistry Division, and the Neural Systems Cluster in the Division of Integrative Organismal Systems. The project is a synergistic combination of laboratory experiments and computer modeling that will lead to better understanding of how animals use the sense of smell to navigate in the real world. Almost universally, from flies to mice to dogs, animals use odors to find critical resources, such as food, shelter, and mates. To date, no engineered device can replicate this function and understanding the code used by the brain will lead to many novel applications. Cracking codes, from neural codes to the Enigma code of WWII, is aided by a deep understanding of the content of messages that are being transmitted and how they will be used by their intended receivers. To crack the olfactory code, the team will focus on how odors move in landscapes, how animals extract spatial and temporal cues from odor landscapes, and how they use movement for enhancing these cues while progressing towards their targets. The proposed work encompasses physical measurement of odor plumes, behavioral measurement of animals' paths through olfactory environments, electrophysiological and optical measurement of neural activity during olfactory navigation, perturbations of the environment via virtual reality and of neuronal hardware via genetics, and multilevel mathematical modeling. The PIs will teach and work with undergraduate, graduate and postdoctoral students and especially recruit students from underrepresented groups in science. The project's results may lead to improved methods for the detection of explosives, new olfactory robots to replace trained animals, and new theoretically-grounded advances in robotic control. The project will inform the development of technologies that interfere with the ability of flying insects (including disease vectors and crop pests) to locate their odor target, thus opening a new door for developing 'green' technologies to solve problems that are of global economic and humanitarian importance.<br/> <br/>This proposal is a synergistic combination of laboratory experiments and computational modeling that will probe how animals use olfaction to navigate in their environment. Specifically, this effort seeks to solve the difficult problem of olfactory navigation through the following aims: (i) Generate and quantify standardized, naturalistic odor environments that can be used to perform empirical and theoretical tests of navigation strategies; (ii) Determine phenomenological algorithms for odor-guided navigation through behavioral experiments in diverse animal species; (iii) Determine how odor cues for navigation are encoded and used in the nervous system by recording neuronal data and simulating putative neural circuits that implement these processes; (iv) Manipulate olfactory environments and neural circuitry, to evaluate model robustness. In contrast to previous attempts to understand olfactory navigation, the present strategy emphasizes mechanisms that are biologically feasible and explores the wide range of temporal and spatial scales in which animals successfully navigate. The project will generate datasets of immediate use and importance to scientists in theoretical biology and mathematics, engineering (fluid mechanics, electronic olfaction, and robotics) and biology (neuroscience, ecology and evolution)."
"1811889","Computations and Analysis of Efficient Snake Locomotion","DMS","MATHEMATICAL BIOLOGY, MSPA-INTERDISCIPLINARY, ANIMAL BEHAVIOR","08/15/2018","08/15/2018","Silas Alben","MI","University of Michigan Ann Arbor","Standard Grant","Junping Wang","07/31/2021","$220,063.00","","alben@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","MPS","7334, 7454, 7659","068Z, 9251","$0.00","Snake locomotion has been studied for several decades by biologists and engineers, but a general quantitative understanding of how snakes bend their bodies to move efficiently is lacking.  A small number of typical snake motions (for example, lateral undulation and sidewinding) have been described and studied, but a much wider range of motions can occur biologically and mechanically. This project will use mathematical analysis and simulations to study a wide range of snake motions, identify those that move the snake body most efficiently, and understand how they depend on physical parameters and constraints. Snakes lack limbs but can nonetheless move efficiently on land. The research will develop accurate simulations of snake dynamics in the presence of friction and contact forces. Measuring the forces on real snakes performing a wide range of movements is difficult in experiments, so mathematical models and simulations are essential. The research will have broader impacts in the ongoing development of robust snake robots to explore, perform inspections and search-and-rescue operations, and assist internal medical procedures, often in confined and/or hazardous environments. The underlying physical principles will apply to efficient locomotion by a range of terrestrial organisms and robots. The project will involve interdisciplinary research training of undergraduates and a graduate student.<br/> <br/>Improvements in computations and analysis of two-dimensional snake locomotion will aim to accurately characterize optimally efficient motions in the regimes of moderate and small transverse friction, which are important biologically and for robotics. Little is known about such optima at present, and why transverse undulation is ineffective in this regime. Optimal motions will be identified under constraints including zero time-averaged body rotation and fixed energy consumption. Optimal motions in the presence of walls and obstacles will be computed using penalty forces preventing penetration of the solid barriers and giving additional frictional interactions. Such sharply varying forces will be computed accurately using adaptive quadrature of frictional and barrier forces in the vicinity of contact. The benefits of passive elasticity, well known for aquatic organisms, will be studied in snakes. Accurate computations of contact forces with the ground will allow for the study of optimal snake motions in three dimensions, accounting for the work done against gravity.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1350154","CAREER:  Steerable Powered Ankle-foot Prostheses for Increased Mobility in Amputees","CBET","Disability & Rehab Engineering","06/01/2014","03/24/2014","Mo Rastgaar","MI","Michigan Technological University","Standard Grant","Aleksandr Simonian","05/31/2019","$497,393.00","","rastgaar@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","ENG","5342","010E, 1045","$0.00","1350154<br/>Rastgaar<br/><br/>Overview: Mobility is a key factor to well-being, both emotionally (through increased independence and decreased depression and anxiety) and physically (through reduced disease risk, bone maintenance, muscle strength, and weight control). Over a million US citizens are limb amputees, primarily lower leg amputees. This CAREER program will 1) work to improve the mobility of lower extremity amputees through research in design and control of powered ankle-foot prostheses, which mimic the steering mechanism of human gait by having two controllable degrees of freedom (DOF) and 2) integrate research with education and outreach to inspire and equip a diverse next generation of engineers. To work toward these long-term goals, this CAREER program will develop ? and use in education and outreach - a lightweight, cable-driven, powered ankle-foot prosthesis capable of steering and traversing slopes by learning from human ankle impedance in the sagittal and frontal planes during gait.<br/>Intellectual Merit: This project is based on the hypothesis that an ankle-foot prosthesis capable of applying torques and impedance modulation in both the sagittal and frontal planes, similar to the human ankle, will improve maneuverability and increase mobility by lowering the metabolic cost of gait - both when walking straight and turning. Advances in powered prostheses have shown the ability to reduce metabolic cost and increase the preferred speed of gait for unilateral transtibial amputees during straight walking by providing sufficient power during push-off. Powered prostheses can also reduce asymmetrical gait patterns and thus may lower risk of secondary complications. However, studies show that turning steps account for 8-50% of steps, depending on activity, and thus may account for 25% of daily steps. Modulation of ankle impedance in the sagittal and frontal planes plays a major role in controlling lateral and propulsive ground reaction forces. While a non-amputee relies on hip movement in the coronal plane and the moment generated in the ankle joint, an amputee using a passive prosthesis uses the hip extension in the sagittal plane as a gait strategy [5-8]. The hypothesis is supported by the PI?s preliminary results which show a large inversion of the ankle during the stance period of step turns, indicating a significant deviation of ankle rotations from the straight-step pattern. Understanding the role of the ankle in locomotion and developing a platform for design and control of a new ankle-foot prostheses will allow exploratory research and education. Research will include: Thrust 1: Estimate ankle impedance in the sagittal and frontal planes during the stance period of gait; Thrust 2: Develop a powered ankle-foot prosthesis with two controllable DOF; Thrust 3: Evaluate the design and control of the prosthesis using an evaluation platform and with below-knee amputees through collaboration with Mayo Clinic; and Thrust 4: Education/Outreach: Utilize the steerable ankle-foot prosthesis for education, outreach, and research experiences to impact diverse K-12, community college, undergraduate, and graduate students. The work is significant in that it will contribute 1) new knowledge about multivariable impedance modulation of the human ankle during the stance period of gait, an area not yet fully explored, and 2) a unique framework for developing and evaluating powered ankle-foot prostheses. The steerable ankle-foot prosthesis is innovative because it will enable amputees to walk with a more natural gait by using the ankle joint, rather than merely the hip and knee. Development of this novel platform will be a substantial step toward the PI?s long-term goal of improving design and maneuverability in lower extremity assistive prostheses and robots.<br/>Broader Impacts: Robotics is a high-impact way to attract the attention of future engineers. This project will develop outreach activities that spark and sustain STEM interest in pre-college students, especially underrepresented minorities. Development of an inexpensive powered ankle-foot prosthesis will improve well-being of Wounded Warriors and civilian amputees, while at the same time inspiring and training the future STEM workforce. In addition, the PI has designed and developed a low-cost EMG-controlled manipulator as educational platform that will be used in outreach programs to teach fundamentals of mechatronics, robotics, and biomechanics to K-12, community college, undergraduate, and graduate students. The developed outreach programs will be rigorously evaluated and then made publicly available to other researchers."
"1246400","Collaborative Research: Flow and Fracture Dynamics in an Ice Shelf Lateral Margin: Observations and Modeling of the McMurdo Shear Zone","OPP","ANTARCTIC GLACIOLOGY","06/01/2013","07/28/2017","Peter Koons","ME","University of Maine","Continuing grant","Paul Cutler","05/31/2019","$387,782.00","Peter Koons","Peter.Koons@maine.edu","5717 Corbett Hall","ORONO","ME","044695717","2075811484","GEO","5116","9150","$0.00","Hamilton/1246400<br/><br/>This award supports an integrated field observation, remote sensing and numerical modeling study of the McMurdo Shear Zone (SZ). The SZ is a 5-10 km wide strip of heavily crevassed ice that separates the McMurdo and Ross ice shelves, and is an important region of lateral support for the Ross Ice Shelf. Previous radar and remote sensing studies reveal an enigmatic picture of the SZ in which crevasses detected at depth have no apparent surface expression, and have orientations which are possibly inconsistent with the observed flow field. In the proposed work, we seek to test the hypothesis that the SZ is a zone of chaotic Lagrangian mixing with (intersecting) buried crevasses which leads to rheological instability, potentially allowing large scale velocity discontinuities. The work will involve detailed field-based observations of crevasse distributions and structure using ground-penetrating radar, and GPS and remote sensing observations of the flow and stress field in the SZ. Because of the hazardous nature of the SZ, the radar surveys will be conducted largely with the aid of a lightweight robotic vehicle. Observations will be used to develop a finite element model of ice shelf shear margin behavior.  The intellectual merit of this project is an increased understanding of ice shelf shear margin dynamics. Shear margins play a key role in ice shelf stability, and ice shelves in turn modulate the flux of ice from the ice sheet across the grounding line to the ocean. Insights from this project will improve large-scale models being developed to predict ice sheet evolution and future rates of sea level rise, which are topics of enormous societal concern.  The broader impacts of the project include an improved basis for US Antarctic Program logistics planning as well as numerous opportunities to engage K-12 students in scientific discovery. Intensified crevassing in the shear zone between the Ross and McMurdo ice shelves would preclude surface crossing by heavy traverse vehicles which would lead to increased costs of delivering fuel to South Pole and a concomitant loss of flight time provided by heavy-lift aircraft for science missions on the continent. Our multidisciplinary research combining glaciology, numerical modeling, and robotics engineering is an engaging way to show how robotics can assist scientists in collecting hazardous field measurements. Our outreach activities will leverage Dartmouth's current NSF GK-12 program, build on faculty-educator relationships established during University of Maine's recent GK-12 program, and incorporate project results into University of Maine's IDEAS initiative, which integrates computational modeling with the existing science curriculum at the middle school level. This award has field work in Antarctica."
"1563805","RI: Medium: Active Sensing, Localization, and Mapping in Dynamic Deformable Environments for Image-Guided Interventions","IIS","ROBUST INTELLIGENCE","08/01/2016","05/04/2018","M. Cenk Cavusoglu","OH","Case Western Reserve University","Continuing grant","David Miller","07/31/2020","$1,016,000.00","Michael Branicky, Mark Griswold, Nicole Seiberlich","mcc14@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","CSE","7495","7495, 7924, 9251","$0.00","This study aims to address two important research problems in realizing intelligent robotic systems for image-guided needle and catheter based surgical interventions.  The first research thrust focuses on localization and tracking of flexible instruments and anatomical targets during the surgical intervention using medical imaging.  Algorithms for robustly tracking the instrument, target tissue, and other relevant anatomical structures, including obstacles and anatomical structures that need to be avoided, under noisy, incomplete sensor measurements are essential for the robotic system for successfully performing the procedure.  The second research thrust aims to develop algorithms for dynamically controlling the medical imaging system during the procedure.  The goal is to minimize the number of sensor measurements, and hence reduce costs associated with sensing, while still obtaining sufficient sensing information. This project will have direct broad societal impacts in healthcare, by developing technologies that will improve percutaneous interventions, which are widely used for both diagnostic and therapeutic applications.  <br/><br/>The purpose of the present study is the development of methods for active control of intra-operative medical imaging systems for localization and tracking of instruments and anatomical structures during percutaneous interventions.  Specifically, the research will focus on development of algorithms for active localization and mapping in dynamic deformable environments, and active sensing algorithms for dynamically controlling intra-operative imaging system.  The developed technologies will be realized in hardware and validated in benchtop experimental studies on a clinical interventional magnetic resonance imaging system using real-time magnetic resonance imaging techniques.  The intellectual merit of the project comes from the scientific contributions to the fields of robotics and medical imaging as well as a synergistic integration of the two technologies."
"1535036","The role of naturalistic movements on the generalization of locomotor learning","BCS","Disability & Rehab Engineering, PERCEPTION, ACTION & COGNITION","07/15/2015","07/18/2017","Gelsy Torres-Oviedo","PA","University of Pittsburgh","Continuing grant","Betty H. Tuller","06/30/2019","$517,340.00","","gelsyto@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","SBE","5342, 7252","010E, 7252, 9251","$0.00","A major issue in rehabilitation robotics is that devices like exoskeletons and treadmills correct patients' movements only while they are using the device. This lack of generalization of motor learning limits the efficacy of robotic interventions. The proposed work will investigate how to manipulate robotic-assisted motor learning to increase its generalization to natural movements in unimpaired people and post-stroke patients. The research has broad impact to public heath because it aims to guide the use of technology for effective gait rehabilitation after stroke, which is the leading cause of long-term disability in the United States. In addition, the PI will use the research objectives in this proposal as a means to increase the participation of students from under-represented groups in science and  engineering by recruiting and mentoring undergraduate students from Hispanic-serving universities in Puerto Rico to pursue graduate training. She will also incorporate her research activities with the INVESTING NOW and Pitt EXCEL programs at The University of Pittsburgh. These programs prepare high school students from under-represented groups to pursue degrees in science and engineering and mentor them during their undergraduate studies to ensure their success.  <br/><br/>Split-belt walking, in which one leg moves faster than the other, has been shown to induce locomotor learning in the unimpaired and in post-stroke patients. The PI will use analytical tools to characterize the statistics of movements when walking on the treadmill vs. over ground. The empirical studies will determine if the learning phase on the split-belt treadmill can be altered to enhance the generalization of learned movements to natural walking. The research will be informative about motor learning mechanisms available to patients post-stroke and will suggest ways to improve their mobility beyond the clinical setting."
"1833098","RII Track-4: Advancing Machine Learning in Biological Oceanography Through Interdisciplinary Collaborations","OIA","EPSCoR Research Infrastructure","10/01/2018","08/20/2018","Roy Collins","AK","University of Alaska Fairbanks Campus","Standard Grant","Chinonye Whitley","09/30/2020","$187,301.00","","recollins@alaska.edu","West Ridge Research Bldg 008","Fairbanks","AK","997757880","9074747301","O/D","7217","9150","$0.00","Non-Technical Description<br/>Modern scientists in interdisciplinary fields like oceanography and genomics regularly generate complex datasets with billions or trillions of data points. Machine learning is revolutionizing the way these data are observed. As a merger between statistics and computer science, the techniques of machine learning have been used for decades, but recent improvements in high-performance computing, and research investment from the commercial sector have supercharged the utility of these methods. Environmental scientists have been relatively slow to take up these new methods, in part because the rapid pace of discovery makes it difficult to stay at the cutting edge, but as scientific datasets grow ever larger and more complex, it is becoming increasingly important to make use of machine learning as a way to explore and understand the world. In collaboration with colleagues at Woods Hole Oceanographic Institute, the PI aims to stimulate progress in oceanography and genomics by bringing cutting edge tools and techniques from the world of machine learning to Alaska. Acquiring these skills in parallel with an early career scientist, and applying them to ongoing research projects in the Arctic, will enable a substantially improved understanding of ongoing changes in the marine ecosystems of Alaska. Passing on this knowledge to students by designing and teaching a new course on Machine Learning in the Environmental Sciences will ensure that future generations of Alaskans have access to the skills they will need to succeed in science and beyond.<br/><br/>Technical Description<br/>The broad goals of this visit are to advance machine learning in biological oceanography through interdisciplinary collaborations and knowledge transfer. The PI aims to leverage extensive expertise at Woods Hole Oceanographic Institution (WHOI) to advance research on Arctic marine microbial communities using machine learning methods. The WHOI Autonomous Robotics and Perception Laboratory (WARP) Lab specializes in adaptive sampling, marine robotics, computer vision, autonomous robotic exploration, semantic perception, bayesian nonparametrics, deep learning, surprise detection, and data summarization. Objectives of this project include learning the theory and concepts of machine learning in structured and informal settings, which include several common programming languages and toolkits. Using this base, the PI and a graduate trainee will apply the tools and techniques of machine learning to predict spatiotemporal distributions of Arctic marine microbes, their use and transformations of metals, and advance biological oceanographic sampling techniques.  The PI will accomplish this effort by designing methods for adaptive biological sampling using flow-through systems and ocean profilers. Outcomes of the project will include the development of a new course on Machine Learning in the Environmental Sciences to be taught at the University of Alaska Fairbanks and online via the University of the Arctic. Career development and mentorship of the graduate student will include training in computing fluency in the Software Carpentry program and subsequent training as an instructor. As part of the knowledge exchange with WHOI, the PI will host an Oxford Nanopore minION sequencing workshop in Woods Hole to share this cutting edge technology, and lead cross-cutting discussions on the use of machine learning in advancing this technology.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1634545","Collaborative Research: Uncovering the Dynamics and Functionality of Origami Structures and Materials","CMMI","Dynamics, Control and System D","09/01/2016","07/19/2016","Kon-Well Wang","MI","University of Michigan Ann Arbor","Standard Grant","Irina Dolinskaya","08/31/2019","$360,205.00","","kwwang@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","7569","030E, 031E, 032E, 033E, 034E, 035E, 039E, 040E, 099E, 1059, 7234, 8024","$0.00","Origami is the ancient art of folding paper into decorative shapes and geometries.  Over the last several decades, it evolved and became a design framework for many engineering and architecture applications.  Examples include deployable space structures, kinetic buildings, self-folding robots, surgery devices, and advanced materials.  Origami folding so far has been considered as a static process.  People typically focus on its design and geometry, or internal actuation mechanisms that makes the folding autonomous.  This award supports a collaborative project that will investigate the fundamental dynamic characteristics of origami folding.  In particular, the research will explore how to harness the extraordinary properties of origami for applications like vibration isolation at low frequency, recoverable impact absorption, and impulsive actuation.  Furthermore, the research will produce design tools that can generate sophisticated folding patterns and assign material properties that are suitable for a wide variety of dynamic performance requirements.  The results of this project will become the building blocks for the next generation of air, marine, and land vehicles, intelligent machines and robots, or smart infrastructures, enhancing their functionality, safety and sustainability. The findings will thus advance the aerospace, civil, mechanical, robotics and many other industries. Education and broadening participation plans will focus on student learning and community outreach at various levels and on the enhancement diversity through inclusion in the research activities of members of underrepresented minorities in science and engineering.<br/><br/>This research will, for the first time, rigorously investigate the dynamic characteristics of origami folding and develop its corresponding engineering potentials.  Preliminary studies have discovered that origami with generic crease patterns exhibits many attractive properties via folding, such as zero/negative stiffness, pressure dependent multi-stability, and piece-wise stiffness jump.  Such surprisingly rich properties and the corresponding dynamic responses will be analyzed in detail based on an equivalent truss-frame model, which transforms the continuous origami structure into a finite degree of freedom system.  The truss frame model would also become the basis of a comprehensive synthesis tool that incorporates crease perturbation and optimization, so that the origami can be customized for prescribed dynamic performances.  This synthesis tool will bridge the currently separated branches of studies: the mathematical theories of origami design/folding and the engineering of origami based applications.  Overall, the new modeling, analysis and synthesis tools for origami dynamics will create a significant intellectual leap and build a strong foundation for many future related research and development efforts."
"1547864","EAGER: Dynamics of collaboration between humans and engineered systems: system design for collective expertise","CBET","EFRI RESEARCH PROJECTS","09/01/2015","09/02/2015","Maurizio Porfiri","NY","New York University","Standard Grant","Aleksandr Simonian","08/31/2019","$300,000.00","Oded Nov","mporfiri@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","ENG","7633","010E, 7916, 8089","$0.00","1547864(Porfiri)<br/><br/>Humans are being continuously involved as cognitive and social agents in engineered systems, and, in a similar vein, engineered systems are becoming increasingly integral to systems of interacting humans. A particularly elusive issue entails understanding and predicting the evolution of the collaboration between humans and engineered systems, across behavioral and technological domains. This award supports experimental and theoretical research to elucidate the dynamics of collaboration in human-engineered systems, through the integration of dynamical systems theory, robotics, and human-computer interactions. Humans will socially interact with engineered systems in an engineering context, which will be, in turn, enabled by an engineering infrastructure. This research will contribute to lay the foundation for the next generation of autonomous environmental monitoring systems, which capitalize on human intelligence and low-cost distributed robots for rapidly and accurately monitoring the environment.  Complementing the research are interdisciplinary formal and informal education activities that will benefit the training of underprivileged students and reach out to economically-disadvantaged local communities.<br/><br/>This research program seeks to establish a transformative experimental and theoretical framework for understanding, predicting, and, ultimately, controlling the evolution of the collaboration between humans and engineered systems. In a novel crowdsourcing infrastructure, online groups comprised of real humans and artificial experts will collaboratively perform aquatic environmental monitoring, by virtually patrolling mobile aquatic robots in a polluted canal in Brooklyn, NY, to explore the water basin, collect and classify wildlife images, and identify sources of pollution.  Similar to a mechanics experiment in which one applies a sequence of mechanical forces to a solid and measures its mechanical deformation, this project will study the response of humans to the controlled actions of artificial experts and investigate their intertwined dynamics, in terms of social interactions and task performance. A series of hypothesis-driven studies will explore the roles of human cognitive abilities, dispositional factors, and behavioral plasticity on technology-mediated social interactions and performance. A new data-driven mathematical framework based on signal processing, network science, and information theory will be formulated to uncover the interplay between personal attributes and plasticity of humans, their interactions with engineered systems, and how to better design a human-engineered system for collective expertise."
"1555933","Collaborative Research: Olfactory Navigation: Dynamic Computing in the Natural Environment","PHY","OFFICE OF MULTIDISCIPLINARY AC, Chemistry of Life Processes, PHYSICS OF LIVING SYSTEMS, CROSS-EF ACTIVITIES, MATHEMATICAL BIOLOGY","11/01/2015","06/28/2017","Katherine Nagel","NY","New York University Medical Center","Continuing grant","Krastan B. Blagoev","10/31/2019","$999,999.00","","katherine.nagel@nyumc.org","One Park Avenue, 6th FL","New York","NY","100165800","2122638822","MPS","1253, 6883, 7246, 7275, 7334","7237, 8007, 8091, 8251, 9178, 9179, 9183","$0.00","This project was developed at an NSF Ideas Lab on ""Cracking the Olfactory Code"" and is jointly funded by the Physics of Living Systems program in the Physics Division, the Mathematical Biology program in the Division of Mathematical Sciences, the Chemistry of Life Processes program in the Chemistry Division, and the Neural Systems Cluster in the Division of Integrative Organismal Systems. The project is a synergistic combination of laboratory experiments and computer modeling that will lead to better understanding of how animals use the sense of smell to navigate in the real world. Almost universally, from flies to mice to dogs, animals use odors to find critical resources, such as food, shelter, and mates. To date, no engineered device can replicate this function and understanding the code used by the brain will lead to many novel applications. Cracking codes, from neural codes to the Enigma code of WWII, is aided by a deep understanding of the content of messages that are being transmitted and how they will be used by their intended receivers. To crack the olfactory code, the team will focus on how odors move in landscapes, how animals extract spatial and temporal cues from odor landscapes, and how they use movement for enhancing these cues while progressing towards their targets. The proposed work encompasses physical measurement of odor plumes, behavioral measurement of animals' paths through olfactory environments, electrophysiological and optical measurement of neural activity during olfactory navigation, perturbations of the environment via virtual reality and of neuronal hardware via genetics, and multilevel mathematical modeling. The PIs will teach and work with undergraduate, graduate and postdoctoral students and especially recruit students from underrepresented groups in science. The project's results may lead to improved methods for the detection of explosives, new olfactory robots to replace trained animals, and new theoretically-grounded advances in robotic control. The project will inform the development of technologies that interfere with the ability of flying insects (including disease vectors and crop pests) to locate their odor target, thus opening a new door for developing 'green' technologies to solve problems that are of global economic and humanitarian importance.<br/> <br/>This proposal is a synergistic combination of laboratory experiments and computational modeling that will probe how animals use olfaction to navigate in their environment. Specifically, this effort seeks to solve the difficult problem of olfactory navigation through the following aims: (i) Generate and quantify standardized, naturalistic odor environments that can be used to perform empirical and theoretical tests of navigation strategies; (ii) Determine phenomenological algorithms for odor-guided navigation through behavioral experiments in diverse animal species; (iii) Determine how odor cues for navigation are encoded and used in the nervous system by recording neuronal data and simulating putative neural circuits that implement these processes; (iv) Manipulate olfactory environments and neural circuitry, to evaluate model robustness. In contrast to previous attempts to understand olfactory navigation, the present strategy emphasizes mechanisms that are biologically feasible and explores the wide range of temporal and spatial scales in which animals successfully navigate. The project will generate datasets of immediate use and importance to scientists in theoretical biology and mathematics, engineering (fluid mechanics, electronic olfaction, and robotics) and biology (neuroscience, ecology and evolution)."
"1433431","Collaborative Research: Innovative Technology-Enabled Astronomy for Middle Schools II (ITEAMS II)","DRL","ITEST","09/01/2014","06/16/2015","Philip Sadler","MA","Harvard University","Standard Grant","Julia Clark","08/31/2019","$609,066.00","","psadler@cfa.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","EHR","7227","8244","$0.00","Nationwide, middle-school youth from underrepresented communities have few opportunities to engage in authentic STEM (Science, Technology, Engineering, and Mathematics) investigations that build on the students' intrinsic interests in space science and robotics to increase their interests in both ICT (Information and Communication Technologies) and STEM careers. ITEAMS II is a collaborative project of science educators and researchers at the Harvard College Observatory and the Smithsonian Astrophysical Observatory. It is a nationwide online learning community of grades 5-8 students, educators, and parents and caregivers. The project goal is to transfer the intrinsic and active learning of students in space science and robotics into increased interest in ICT or STEM careers. ITEAMS II features research-quality, remotely-controlled, online telescopes (http://mo-www.harvard.edu/Micro-Observatory/ ) accessible from school, home, or any location with internet connection, plus complementary curricula. ITEAMS II will use a wide range of cyber-learning tools to provide ongoing professional development to the educators who are central to the online learning community. At least 80 educators and upwards of 120 students will be involved over the course of the three-year project.<br/><br/>Students access the robotic telescopes to acquire solar system or deep space images, and use project software to process the images. Then as part of an online learning community the students will engage in events and contests, and complete and share capstone projects. Educators will participate in online synchronous and asynchronous professional development and take on leadership roles in the learning community. Upwards of 150 parents will be involved each year, collaborating with their children in activities from using the telescopes to shared learning in community events."
"1433345","Collaborative Research: Innovative Technology-Enabled Astronomy for Middle Schools II (ITEAMS II)","DRL","ITEST","09/01/2014","03/02/2015","Susan Sunbury","MA","Smithsonian Institution Astrophysical Observatory","Standard Grant","Julia Clark","08/31/2019","$590,907.00","Mary Dussault","ssunbury@cfa.harvard.edu","60 Garden St","Cambridge","MA","021381516","6174967923","EHR","7227","8244","$0.00","Nationwide, middle-school youth from underrepresented communities have few opportunities to engage in authentic STEM (Science, Technology, Engineering, and Mathematics) investigations that build on the students' intrinsic interests in space science and robotics to increase their interests in both ICT (Information and Communication Technologies) and STEM careers. ITEAMS II is a collaborative project of science educators and researchers at the Harvard College Observatory and the Smithsonian Astrophysical Observatory. It is a nationwide online learning community of grades 5-8 students, educators, and parents and caregivers. The project goal is to transfer the intrinsic and active learning of students in space science and robotics into increased interest in ICT or STEM careers. ITEAMS II features research-quality, remotely-controlled, online telescopes (http://mo-www.harvard.edu/Micro-Observatory/ ) accessible from school, home, or any location with internet connection, plus complementary curricula. ITEAMS II will use a wide range of cyber-learning tools to provide ongoing professional development to the educators who are central to the online learning community. At least 80 educators and upwards of 120 students will be involved over the course of the three-year project.<br/><br/>Students access the robotic telescopes to acquire solar system or deep space images, and use project software to process the images. Then as part of an online learning community the students will engage in events and contests, and complete and share capstone projects. Educators will participate in online synchronous and asynchronous professional development and take on leadership roles in the learning community. Upwards of 150 parents will be involved each year, collaborating with their children in activities from using the telescopes to shared learning in community events."
"1829008","NRT: Technology-Human Integrated Knowledge Education and Research (THINKER)","DGE","NSF Research Traineeship (NRT), PROGRAM EVALUATION","09/01/2018","08/22/2018","Laine Mears","SC","Clemson University","Standard Grant","Laura Regassa","08/31/2023","$2,993,421.00","Amy Apon, Deborah Switzer, Laura Stanley, Joshua Summers","mears@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","EHR","1997, 7261","062Z, 9150, 9179, SMET","$0.00","The pervasiveness of new digital technologies in manufacturing is changing the way that data are generated, interpreted and shared over networks of machines, robotics and software systems. This ""industrial internet of things"" holds great promise for improving the quality and productivity of manufacturing in the United States. However, the ability of human workers to effectively interface with such digital systems is limited, potentially leading to disruptions in cognition that may negatively affect output and job satisfaction. This National Science Foundation Research Traineeship (NRT) award prepares master's and doctoral degree students at Clemson University to advance discoveries at the nexus of humans, technology, work, and health, through the convergence of human factors, robotics, cognitive sciences, artificial intelligence, systems engineering, education, manufacturing and social behavioral sciences. This will be achieved through the design and integration of human digital technologies that enhance humans' physical and cognitive interaction and abilities in manufacturing environments. The project anticipates training fifty (50) M.S. and Ph.D. students, including twenty-two (22) funded trainees, from electrical engineering, industrial engineering, computer science, manufacturing, systems integration, psychology, and sociology. These students will interface with a parallel program of undergraduate and technical college students in a controlled manufacturing environment to test deployment and integration across multiple academic levels.<br/><br/>This project responds to the critical need to help shape and better prepare the STEM graduate student of tomorrow through an innovated curriculum that focuses on the new digital and smart manufacturing, automation, and associated data systems.  The training and research takes a human-centered design approach in the emerging digital manufacturing enterprise (i.e., Industrial Internet of Things), by quantifying physical and human cognition and developing augmented technologies (e.g. augmented reality aids for worker empowerment) to improve worker behaviors and attitudes in the manufacturing enterprise.  This project will focus on an automotive industry exemplar (i.e., vehicle assembly operation), employing a factory setting which includes parts manufacture, structural and subassembly operations, robotics, kitting, logistics, and a full-scale vehicle assembly line, together with parallel programs in undergraduate and technical college curricula. The multi-level educational approach is expected to drive improved team communication, generate knowledge on worker behaviors and attitudes, and prepare students for leading implementation of the technologies under study in manufacturing and other industries.  <br/><br/>The NSF Research Traineeship (NRT) Program is designed to encourage the development and implementation of bold, new potentially transformative models for STEM graduate education training. The program is dedicated to effective training of STEM graduate students in high priority interdisciplinary research areas through comprehensive traineeship models that are innovative, evidence-based, and aligned with changing workforce and research needs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1755336","Greater than the sum of its parts? The role of mechanical sensitivity and integration in the evolution of power-amplified systems","IOS","Physiolg Mechansms&Biomechancs","09/15/2018","08/21/2018","Philip Anderson","IL","University of Illinois at Urbana-Champaign","Standard Grant","Emily Carrington","08/31/2021","$613,182.00","Andrew Suarez","andersps@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","BIO","7658","1228, 9178, 9179","$0.00","Trap-jaw ants are renowned for their extreme ability to amplify power with their mouthparts, which can generate forces hundreds of times greater than their body weight and reach speeds over 60 meters per second (over 130 miles per hour). Moreover, they do this using very simple, fracture resistant materials. The research will combine high-speed videography, biomechanics, and mathematics to characterize and model power-amplification in a diverse group of trap-jaw ants. The findings will provide insight into the mechanisms animals use to achieve extremely high speeds and forces with their limbs and to determine how variation in these high-performance biological systems generates diverse animal forms. The research also has the potential to inform biologically-inspired applications for robotics and machinery. The project will provide interdisciplinary research training opportunities to undergraduate and graduate students, including those from groups traditionally underrepresented in STEM fields. The researchers will also run robotics summer camps for children, exposing students to the many ways insects can be used to provide inspiration for innovations in technology and engineering.<br/><br/>The objective of this research is to examine the mechanical sensitivity and integration of power-amplified systems using a combination of experimental data and computer-based biomechanical models. The results of these mechanical analyses will be incorporated into phylogenetic comparative analyses to test whether patterns of mechanical sensitivity influence morphological and ecological diversification. Specifically, the research will take advantage of repeated transitions to power amplification in trap-jaw ants to explore how performance metrics (such as speed, force and energy) respond to shifts in morphology. The power-amplified trap-jaw system is composed of multiple components (i.e. muscle, latch, spring) all of which may be important to several aspects of performance (i.e. speed, force). The specific aims of the project are to 1) evaluate how various performance variables of the trap-jaw system (speed, force, damage resistance) vary with morphological changes in components of the system,  2) test multiple hypotheses for the source of the power-amplifying mechanism in trap-jaw ants, and 3) determine how patterns of biomechanical integration influence evolutionary patterns within and among trap-jaw clades. The interdisciplinary research approach offers a mechanistic framework for evaluating the integration and evolution of biomechanical systems, and how ecological function can influence morphological diversification. The research findings have the potential to provide translational applications for the bio-inspired design of high-performance robotic systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1517351","Collaborative Research: From Biology to Mechanism:","DMS","FLUID DYNAMICS, CROSS-EF ACTIVITIES, MATHEMATICAL BIOLOGY, MSPA-INTERDISCIPLINARY, Physiolg Mechansms&Biomechancs","09/01/2015","08/20/2018","Howard Choset","PA","Carnegie-Mellon University","Continuing grant","Junping Wang","08/31/2019","$180,000.00","","choset@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","MPS","1443, 7275, 7334, 7454, 7658","058E, 8007","$0.00","Inventors have long viewed the agility and grace of animals that crawl, swim, and fly in all environments with awe and envy. However, the ability to replicate the versatility, stability, and efficiency of biological locomotion in engineered systems has eluded scientists and engineers alike. This project will identify fundamental principles of locomotion, with an emphasis on the role of one of the most fundamental biological attributes, compliance. Compliance is ubiquitous in biological locomotion, appearing in diverse forms of life from the elastic ribbed tail of a fish, to the membrane wings of an insect, to the sinewy muscular body of a snake;  when a human turns a door knob or picks up a spoon -- tasks that are nontrivial for robotic systems --  they can rely on compliance in the hand to passively adjust to small disturbances and uncertainties in the environment.  This project seeks to bridge the gap between classical studies in rigid body mechanics that have long been the purview of the discipline of robotics, and compliant biological strategies for locomotion. The research will rationalize compliant strategies and structures that appear in nature.  This knowledge can in turn be used to design new classes of versatile compliant machines, which may include robust strategies for locomotion and manipulation in robotic systems and new compliant mechanisms for harvesting energy. <br/><br/>This research, which lies at the intersection of controls and the mechanics of continuously deformable systems, will develop two new mathematical approaches to tame the complexity associated with optimization of compliant systems.  The first takes its roots in geometric mechanics, which has already proven effective in the study of locomotion of simple systems. The second inverts the optimization problem by first solving for optimal kinematics (e.g. optimal stroke patterns for swimmers) with a dynamic cost function, and subsequently inverting the optimal kinematics to find the associated dynamic parameters (such as bending stiffness). In addition to the development of these two new mathematical tools, the project will investigate the role of compliance within the context of different biological locomotion modes. Through decades of cumulative research, the scientific community has established a reasonable understanding of the role of compliance in isolated applications, such as legged walking and running, but comparatively little is known in terms of how this concept extends to other modes such as crawling, swimming, and insect flight. This research will address the issue through investigations of the underlying physical principles that motivate the form and physiology of each of these systems.  However, the greatest contribution will come through the amalgamation of these results. By developing new insights across multiple locomotion modes, this project aims to extend the findings into a generalized framework for compliance and locomotion. This framework will then serve as a jumping off point for engineers, who can situate their own systems within a greater map of compliant design methodologies."
"1338118","MRI Collaborative: Development of iRehab, an Intelligent Closed-Loop Instrument for Adaptive Rehabilitation","CNS","INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE","10/01/2013","04/26/2018","Fillia Makedon","TX","University of Texas at Arlington","Standard Grant","Rita V. Rodriguez","09/30/2018","$879,890.00","Heng Huang, Vassilis Athitsos, Mario Romero-Ortega, Robert Gatchel","makedon@cse.uta.edu","701 S Nedderman Dr, Box 19145","Arlington","TX","760190145","8172722105","CSE","1640, 1714","1189, 9178, 9251","$0.00","Proposal #: 13-38118  Collaborative  Proposal #: 13-37866<br/>PI(s):  Makedon, Fillia S    PI(s):  Betke, Margrit<br/>Athitsos, Vassilis; Gatchel, Robert J; Huang, Heng; Romero-Ortega, Mario I<br/>Institution:      University of Texas-Arlington              INstitution:     Boston Univeristy    <br/>Title:  MRI/Dev :Collab Dev. of iRehab, an Intelligent Closed-loop Instrument for Adaptive Rehabilitation<br/>Project Proposed:<br/>This project, developing of an instrument referred to as iRehab, aims to enable personalized rehabilitation therapy for individuals suffering from brain injury, motor disabilities, cognitive impairments, and/or psychosocial symptoms. The instrument, a modular rehabilitation device, in its simplest form consists of a computer, a camera, and adaptive software for assessment and training of cognitive functions. In its final, most complex form, the instrument will integrate data from a 4-degree-of-freedom robotic-arm with gimbals and torque sensing, a Kinect sensor, multiple cameras, an eye-tracking device, a touch screen, a microphone, and an fNIRS brain imaging sensor. <br/>The instrument will be developed in two phases. In the first phase, the investigators develop a Barrett robot arm. In the second phase, the instrument will extend to a Kinect sensor, multiple cameras, an eye-tracking device, and related low-cost components, along with the assessment software for assessing motor function and cognitive, emotional, and personality functioning. <br/>iRehab consists integrates multidisciplinary methodologies and sensors to assess and assist the cognitive and physical rehabilitation of persons affected by various impairments. This work highly interdisciplinary work follows a cyber-physical approach. It provides new research opportunities across the fields of human-centered computing, computer vision, assistive technology, robotics, machine learning, and neuroimaging. This work advances research in human brain activity mapping, personalized medicine, and big data.<br/>Broader Impacts:  <br/>The proposed instrument exhibits potential for large broader impact as it directly contributes to future healthcare and human wellbeing improving accessibility to affordable rehabilitation for a broad range of patients. The instrument is likely to accelerate the recovery of a large spectrum of injuries and diseases including those causing motor, neurological, and cognitive disorders. An education plan includes course development, internships, workshops and tutorials, and an on-line resource center. In addition to many educational impacts, impact will be felt on the fundamental research in the areas addressed."
"1810447","Online Learning-based Real-time Control of Unknown Autonomous Systems","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/15/2018","08/15/2018","Rahul Jain","CA","University of Southern California","Standard Grant","Anthony Kuh","07/31/2021","$329,999.00","","rahul.jain@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","ENG","7607","1653","$0.00","Many emerging autonomous systems, e.g., robots in unstructured environments, are too complex to be accurately modeled. There are unknown model parameters, partial state observations, or a drift in system characteristics. This makes the problem of system identification and control quite challenging. Real-time adaptation is needed for optimal and resilient operation. It is well-known that the classical adaptive con-trol approach of system identification and `certainty equivalent' control in the feedback-loop doesn't work. <br/><br/>In this project, we introduce a new paradigm of 'Learning-to-Control' unknown Autonomous Systems based on the newly developing approach of Thompson/Posterior sampling-based online learning. We will focus on discrete state space models of Markov decision processes (MDPs). We will first develop a posterior sampling-inspired algorithms for online learning-based control with real-time adaptation for MDP models with partial observation of the system state. We note that such approaches may be inter-preted to provide just the right amount of randomization for optimally trading off exploration and exploi-tation that is needed for online learning of the optimal policy at the fastest rate. We will then extend this to the setting where the system parameter may be varying or drifting with time. We will then develop such algorithms for more relevant but also more complicated system models - stochastic hybrid systems, that have both discrete and continuous states. The developed algorithms will be extensively validated in sim-ulation experiments in the classical control and robotics environments in OpenAI Gym. <br/><br/>The intellectual merit of the research lies in its contribution to the 'Science of Autonomous Systems' by development of foundations of online learning-based real-time control and adaptation for autonomous systems by addressing fundamental questions about separation of parameter estimation, state estima-tion and control for various stochastic system models, particularly when model parameters must be learnt from data. The broader impacts will include impact on the smart grid, autonomous robotics, and medical CPS devices via dissemination of research results, training of a female PhD student and a K-12 STEM outreach effort.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1555880","Collaborative Research: Olfactory Navigation: Dynamic Computing in the Natural Environment","PHY","OFFICE OF MULTIDISCIPLINARY AC, Chemistry of Life Processes, PHYSICS OF LIVING SYSTEMS, CROSS-EF ACTIVITIES, MATHEMATICAL BIOLOGY","11/01/2015","06/28/2017","Justus Verhagen","CT","John B. Pierce Laboratory, Incorporated","Continuing grant","Krastan B. Blagoev","10/31/2019","$1,109,895.00","","jverhagen@jbpierce.org","290 Congress Ave","New Haven","CT","065191403","2035629901","MPS","1253, 6883, 7246, 7275, 7334","7237, 8007, 8091, 8251, 9178, 9179, 9183","$0.00","This project was developed at an NSF Ideas Lab on ""Cracking the Olfactory Code"" and is jointly funded by the Physics of Living Systems program in the Physics Division, the Mathematical Biology program in the Division of Mathematical Sciences, the Chemistry of Life Processes program in the Chemistry Division, and the Neural Systems Cluster in the Division of Integrative Organismal Systems. The project is a synergistic combination of laboratory experiments and computer modeling that will lead to better understanding of how animals use the sense of smell to navigate in the real world. Almost universally, from flies to mice to dogs, animals use odors to find critical resources, such as food, shelter, and mates. To date, no engineered device can replicate this function and understanding the code used by the brain will lead to many novel applications. Cracking codes, from neural codes to the Enigma code of WWII, is aided by a deep understanding of the content of messages that are being transmitted and how they will be used by their intended receivers. To crack the olfactory code, the team will focus on how odors move in landscapes, how animals extract spatial and temporal cues from odor landscapes, and how they use movement for enhancing these cues while progressing towards their targets. The proposed work encompasses physical measurement of odor plumes, behavioral measurement of animals' paths through olfactory environments, electrophysiological and optical measurement of neural activity during olfactory navigation, perturbations of the environment via virtual reality and of neuronal hardware via genetics, and multilevel mathematical modeling. The PIs will teach and work with undergraduate, graduate and postdoctoral students and especially recruit students from underrepresented groups in science. The project's results may lead to improved methods for the detection of explosives, new olfactory robots to replace trained animals, and new theoretically-grounded advances in robotic control. The project will inform the development of technologies that interfere with the ability of flying insects (including disease vectors and crop pests) to locate their odor target, thus opening a new door for developing 'green' technologies to solve problems that are of global economic and humanitarian importance.<br/> <br/>This proposal is a synergistic combination of laboratory experiments and computational modeling that will probe how animals use olfaction to navigate in their environment. Specifically, this effort seeks to solve the difficult problem of olfactory navigation through the following aims: (i) Generate and quantify standardized, naturalistic odor environments that can be used to perform empirical and theoretical tests of navigation strategies; (ii) Determine phenomenological algorithms for odor-guided navigation through behavioral experiments in diverse animal species; (iii) Determine how odor cues for navigation are encoded and used in the nervous system by recording neuronal data and simulating putative neural circuits that implement these processes; (iv) Manipulate olfactory environments and neural circuitry, to evaluate model robustness. In contrast to previous attempts to understand olfactory navigation, the present strategy emphasizes mechanisms that are biologically feasible and explores the wide range of temporal and spatial scales in which animals successfully navigate. The project will generate datasets of immediate use and importance to scientists in theoretical biology and mathematics, engineering (fluid mechanics, electronic olfaction, and robotics) and biology (neuroscience, ecology and evolution)."
"1555862","Collaborative Research: Olfactory Navigation: Dynamic Computing in the Natural Environment","PHY","OFFICE OF MULTIDISCIPLINARY AC, Chemistry of Life Processes, PHYSICS OF LIVING SYSTEMS, CROSS-EF ACTIVITIES, MATHEMATICAL BIOLOGY","11/01/2015","06/28/2017","John Crimaldi","CO","University of Colorado at Boulder","Continuing grant","Krastan B. Blagoev","10/31/2019","$999,596.00","","crimaldi@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","MPS","1253, 6883, 7246, 7275, 7334","7237, 8007, 8091, 8251, 9178, 9179, 9183","$0.00","This project was developed at an NSF Ideas Lab on ""Cracking the Olfactory Code"" and is jointly funded by the Physics of Living Systems program in the Physics Division, the Mathematical Biology program in the Division of Mathematical Sciences, the Chemistry of Life Processes program in the Chemistry Division, and the Neural Systems Cluster in the Division of Integrative Organismal Systems. The project is a synergistic combination of laboratory experiments and computer modeling that will lead to better understanding of how animals use the sense of smell to navigate in the real world. Almost universally, from flies to mice to dogs, animals use odors to find critical resources, such as food, shelter, and mates. To date, no engineered device can replicate this function and understanding the code used by the brain will lead to many novel applications. Cracking codes, from neural codes to the Enigma code of WWII, is aided by a deep understanding of the content of messages that are being transmitted and how they will be used by their intended receivers. To crack the olfactory code, the team will focus on how odors move in landscapes, how animals extract spatial and temporal cues from odor landscapes, and how they use movement for enhancing these cues while progressing towards their targets. The proposed work encompasses physical measurement of odor plumes, behavioral measurement of animals' paths through olfactory environments, electrophysiological and optical measurement of neural activity during olfactory navigation, perturbations of the environment via virtual reality and of neuronal hardware via genetics, and multilevel mathematical modeling. The PIs will teach and work with undergraduate, graduate and postdoctoral students and especially recruit students from underrepresented groups in science. The project's results may lead to improved methods for the detection of explosives, new olfactory robots to replace trained animals, and new theoretically-grounded advances in robotic control. The project will inform the development of technologies that interfere with the ability of flying insects (including disease vectors and crop pests) to locate their odor target, thus opening a new door for developing 'green' technologies to solve problems that are of global economic and humanitarian importance.<br/> <br/>This proposal is a synergistic combination of laboratory experiments and computational modeling that will probe how animals use olfaction to navigate in their environment. Specifically, this effort seeks to solve the difficult problem of olfactory navigation through the following aims: (i) Generate and quantify standardized, naturalistic odor environments that can be used to perform empirical and theoretical tests of navigation strategies; (ii) Determine phenomenological algorithms for odor-guided navigation through behavioral experiments in diverse animal species; (iii) Determine how odor cues for navigation are encoded and used in the nervous system by recording neuronal data and simulating putative neural circuits that implement these processes; (iv) Manipulate olfactory environments and neural circuitry, to evaluate model robustness. In contrast to previous attempts to understand olfactory navigation, the present strategy emphasizes mechanisms that are biologically feasible and explores the wide range of temporal and spatial scales in which animals successfully navigate. The project will generate datasets of immediate use and importance to scientists in theoretical biology and mathematics, engineering (fluid mechanics, electronic olfaction, and robotics) and biology (neuroscience, ecology and evolution)."
"1809455","Collaborative Research: Microengineered electroactive polymer strain sensors towards soft self-powered wearable cyber-physical systems","ECCS","COMMS, CIRCUITS & SENS SYS","08/15/2018","08/07/2018","Kam Leang","UT","University of Utah","Standard Grant","Shubhra Gangopadhyay","07/31/2021","$149,972.00","","kam.k.leang@utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","ENG","7564","090E","$0.00","Recent research efforts have emphasized the vital role of soft strain sensors in a variety of applications in bioengineering, rehabilitation and medicine, soft robotics, and human-machine interactions. Current soft strain sensors often necessitate external power for operation that severely limits the possibility to make such sensors light weight, comfortable to wear, and capable of functioning over long periods of time. On the other hand, existing self-powered sensors, such as piezoelectric ceramics, are typically very stiff, non-stretchable, and limited to extremely small deformations. Thus, there exists a clear and urgent need to identify novel sensing systems that combine self-powered behavior with soft mechanical characteristics.  This research will result in the development of the next generation of soft, self-powered, high sensitivity polymer-based strain sensors for applications in novel biomedical and soft robotics endeavors. When successfully deployed, these sensors could be embedded in smart gloves for use in hand rehabilitation by patients suffering from stroke or Parkinson's disease, as well as an instrumentation suite for prosthetic devices or in human-machine interfaces, or could be embedded in wearable adhesive patches and interfaced with smartphones and the internet for continuous remote personal health monitoring of vital signs. Furthermore, this project will lead to discover novel electroactive materials systems, promote advancements in advanced manufacturing and mechatronics, and benefit the multiphysics modeling community. This research will support and impact the education of graduate and undergraduate students, contributing to the formation of the next generation of researchers, engineers, and educators. Active involvement of underrepresented students will be pursued via educational and outreach activities. <br/><br/>This project aims at establishing a new class of electroactive materials with superior multiphysics properties towards soft, self-powered, high sensitivity strain sensor applications in cyber-physical systems. Ionic polymer metal composites are electroactive soft composite materials that comprise a thin electrically charged polymer membrane, plated with noble metal electrodes, and infused with a charged solution. Due to their combined self-powered sensor behavior and soft mechanical characteristics, ionic polymer metal composites emerge as an ideal candidate for soft strain sensor applications. However, inconsistent and uncontrollable morphology of their polymer-metal interfaces poses the challenges of limited sensitivity, poor property control, and non-versatile mode of operation. So far, these challenges have limited the use of these materials in critical engineering applications. It is hypothesized that the multiphysics sensing properties of ionic polymer metal composites can be dramatically enhanced by tailored 3D-structured microengineered polymer-metal interfaces. To test this hypothesis, this research will develop a novel fabrication process integrating electroless chemical reduction with inkjet printing to prepare ionic polymer metal composites with microengineered interfaces. These interfaces are responsible for inhomogeneous strain developed in response to a mechanical stimulus and its subsequent electrochemical transduction and sensing performance. The main goal of this research is to gain a comprehensive understanding of the structure-property relationships in microengineered ionic polymer metal composites that determine enhanced strain sensing performance. This goal will be achieved by integrating theoretical multiphysics modeling and experimental efforts and by synergizing the investigators' complementary expertise in modeling of smart materials and systems, advanced manufacturing, sensing systems, and mechatronics and controls. This project will elucidate the role of polymer-electrode interfaces in shaping the chemoelectromechanical response of the system and formalize experimentally validated models that incorporate interface morphology information to predict multiphysics sensing properties. The potential of the proposed sensing system will be demonstrated by designing, manufacturing, and testing functional sensors in experimental platforms for studies on soft robotics and human-machine interaction. The knowledge gained through this project will significantly advance the state of understanding of electroactive materials towards development of high performance sensing systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1545106","CPS: TTP Option: Synergy: Learning and Adaption in Pediatric Robotics","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2015","08/10/2016","Homayoon Kazerooni","CA","University of California-Berkeley","Standard Grant","Sylvia J. Spengler","09/30/2019","$1,200,000.00","Francesco Borrelli","kazerooni@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7918","7918, 8235","$0.00","Children affected by neurological conditions (e.g., Cerebral Palsy, Muscular Atrophy, Spina Bifida and Severe head trauma) often develop significant disabilities including impaired motor control.  In many cases, walking becomes a non-functional and exhausting skill that demands the use of the aids or the substitution of function, such as wheelchair. This usually cause these children not to acquire locomotion skills, and consequently to lose their independence. However, it is well understood that bipedal locomotion, an essential human characteristic, ensures the best physiological motor pattern acquisition. For this reason, in children with neurological and neuromuscular diseases, independent walking is a significant rehabilitation goal that must be pursued in a specific temporal window due to the plasticity of central nervous system. In other words, children with neurological conditions have a small window of time to acquire locomotion skills through assisted walking rehearsals.  The objective of this research work is to create and experimentally validate a set of technologies that form the framework for the development of adaptive, self-balancing, and modular exoskeleton robotics systems for children with neurological disorders. It is our belief that the exoskeleton (and its associated infrastructure) resulting from this research will offer an effective tool to promote locomotion skill acquisition, and in general health, during a critical period in the early life of children with neurological conditions. <br/><br/><br/>This research proposal develops a data-driven human-machine modeling specific to physiological conditions.  This creates regression models that predict the user behavior without explicit modeling the complex human musculoskeletal dynamics and motor control mechanism.  Additionally this research project formulates a safe adaptive control problem as a model predictive control (MPC) problem.  In this method, an optimal input sequence is computed by solving a constrained finite-time optimal control problem where exoskeleton intrusion (input from exoskeleton) is minimized to maximize the user's intent to promote learning.  This project further develops a novel approach for stabilizing and preventing fall of the exoskeleton and the child as a whole. This method allows a child wearing an exoskeleton to learn locomotion skills described above with less likelihood of falls.  This research project furthermore evaluates the developed technologies in terms of efficiency and efficacy and creates a novel fun game using exoskeleton for children to promote locomotion skills."
"1809852","Collaborative Research: Microengineered electroactive polymer strain sensors towards soft self-powered wearable cyber-physical systems","ECCS","COMMS, CIRCUITS & SENS SYS, EPSCoR Co-Funding","08/15/2018","08/07/2018","Matteo Aureli","NV","Board of Regents, NSHE, obo University of Nevada, Reno","Standard Grant","Shubhra Gangopadhyay","07/31/2021","$299,865.00","Yiliang Liao","maureli@unr.edu","1664 North Virginia Street","Reno","NV","895570001","7757844040","ENG","7564, 9150","090E, 9150","$0.00","Recent research efforts have emphasized the vital role of soft strain sensors in a variety of applications in bioengineering, rehabilitation and medicine, soft robotics, and human-machine interactions. Current soft strain sensors often necessitate external power for operation that severely limits the possibility to make such sensors light weight, comfortable to wear, and capable of functioning over long periods of time. On the other hand, existing self-powered sensors, such as piezoelectric ceramics, are typically very stiff, non-stretchable, and limited to extremely small deformations. Thus, there exists a clear and urgent need to identify novel sensing systems that combine self-powered behavior with soft mechanical characteristics.  This research will result in the development of the next generation of soft, self-powered, high sensitivity polymer-based strain sensors for applications in novel biomedical and soft robotics endeavors. When successfully deployed, these sensors could be embedded in smart gloves for use in hand rehabilitation by patients suffering from stroke or Parkinson's disease, as well as an instrumentation suite for prosthetic devices or in human-machine interfaces, or could be embedded in wearable adhesive patches and interfaced with smartphones and the internet for continuous remote personal health monitoring of vital signs. Furthermore, this project will lead to discover novel electroactive materials systems, promote advancements in advanced manufacturing and mechatronics, and benefit the multiphysics modeling community. This research will support and impact the education of graduate and undergraduate students, contributing to the formation of the next generation of researchers, engineers, and educators. Active involvement of underrepresented students will be pursued via educational and outreach activities. <br/><br/>This project aims at establishing a new class of electroactive materials with superior multiphysics properties towards soft, self-powered, high sensitivity strain sensor applications in cyber-physical systems. Ionic polymer metal composites are electroactive soft composite materials that comprise a thin electrically charged polymer membrane, plated with noble metal electrodes, and infused with a charged solution. Due to their combined self-powered sensor behavior and soft mechanical characteristics, ionic polymer metal composites emerge as an ideal candidate for soft strain sensor applications. However, inconsistent and uncontrollable morphology of their polymer-metal interfaces poses the challenges of limited sensitivity, poor property control, and non-versatile mode of operation. So far, these challenges have limited the use of these materials in critical engineering applications. It is hypothesized that the multiphysics sensing properties of ionic polymer metal composites can be dramatically enhanced by tailored 3D-structured microengineered polymer-metal interfaces. To test this hypothesis, this research will develop a novel fabrication process integrating electroless chemical reduction with inkjet printing to prepare ionic polymer metal composites with microengineered interfaces. These interfaces are responsible for inhomogeneous strain developed in response to a mechanical stimulus and its subsequent electrochemical transduction and sensing performance. The main goal of this research is to gain a comprehensive understanding of the structure-property relationships in microengineered ionic polymer metal composites that determine enhanced strain sensing performance. This goal will be achieved by integrating theoretical multiphysics modeling and experimental efforts and by synergizing the investigators' complementary expertise in modeling of smart materials and systems, advanced manufacturing, sensing systems, and mechatronics and controls. This project will elucidate the role of polymer-electrode interfaces in shaping the chemoelectromechanical response of the system and formalize experimentally validated models that incorporate interface morphology information to predict multiphysics sensing properties. The potential of the proposed sensing system will be demonstrated by designing, manufacturing, and testing functional sensors in experimental platforms for studies on soft robotics and human-machine interaction. The knowledge gained through this project will significantly advance the state of understanding of electroactive materials towards development of high performance sensing systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1540916","SL-CN: Cortical Architectures for Robust Adaptive Perception and Action","SMA","Science of Learning, SCIENCE OF LEARN CTRS- CENTERS","09/15/2015","08/07/2018","Cornelia Fermuller","MD","University of Maryland College Park","Standard Grant","Soo-Siang Lim","08/31/2019","$797,779.00","Shihab Shamma, Andreas Andreou, Timothy Horiuchi, Ralph Etienne-Cummings","fer@cfar.umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","SBE","004Y, 7278","059Z, 110E, 1340, 7298, 7556, 7956, 8089","$0.00","The motivation for this biologically-inspired approach is to design systems that perceive and act in cluttered and noisy scenes that they have never experienced. This stands in contrast with the state of the art in computational engineering systems that need to be re-trained each time they confront an unanticipated environment. The main reason is that current approaches to perception address specific problems in isolation and do not consider that the primary role of perception is to support systems with bodies in action. As a result, they are constrained to the situations for which they were trained and cannot react to changing tasks and scenes. By focusing on cognition primitives rather than specific applications, the work is expected to greatly advance the state of the art of machine perception and lead to the development of systems that can robustly and on-line adapt to new environments, react to novel situations and learn new contexts. To do so, novel theoretical formulations of perception and action and high-speed, low-power, hardware implementations with on-line learning capabilities will be studied while assimilating new insights from the neurosciences. Consequently, this work will network neuroscience, cognitive science, applied mathematics, computer science and engineering so as to lower one of the few remaining barriers that keeps interactive robots in the realm of science fiction. Beyond the scholarly contribution, the work is expected to provide know-how for the design of systems with adaptive perception in a modular fashion with reusable components. Such systems have applications in computational vision and auditory perception problems and can advance the industry of cognitive biologically-inspired robotics and assistive devices.<br/><br/>This proposal sets forward novel ideas in the design of intelligent perceptual systems and the development of synthetic intelligence. Just about any task which an intelligent system solves involves the interplay of four basic processes that are devoted to: (a) context, (b) attention, (c) segmentation and (d) categorization. The members of the proposed network will study these canonical cognitive primitives by combining neural modeling with neural and behavioral experiments, theoretical and computational modeling and implementation in robotics.  The findings of theoretical insights will then be adapted to satisfy the demands of realistic behavior, and to develop technological solutions for applications of robust and invariant perception and action. The proposed collaborative network will consist of a small science and engineering research team to directly address the questions in robust adaptive perception and action. It will then direct personnel, and inject results and pedagogical content to a Summer Workshop that aims to include a global network of researchers."
"1749634","Collaborative Research: Individual and Collective Dynamics of  Marangoni Surface Tension Effects between Particles","CBET","FLUID DYNAMICS","06/12/2017","05/04/2018","Hassan Masoud","MI","Michigan Technological University","Standard Grant","Ronald Joslin","07/31/2020","$201,155.00","","hmasoud@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","ENG","1443","9150","$0.00","The principal goal of this research is to investigate the motion of active particles at fluidic interfaces due to a gradient of surface tension stemming from the discharge of a surface-active agent, a surface reaction, or from the release of heat by the particle. Powered by converting chemical energy into mechanical work, these self-propelled ""Marangoni"" particles, both at the individual level and as a collection, can bring to bear functionalities that resemble those of biological organisms. The findings of this study will determine the guiding principles for designing miniature self-propelled particles, which can lead to transformative innovations in robotics, microfluidics, and biomedical engineering. These tiny surfing robots can potentially execute missions that are currently very difficult or even impossible to accomplish. The results of this project will also give rise to the development of active self-assembly techniques, which can be used for rapid fabrication of small-scale structured materials. Further, the outcome of this research will shed light on the role of self-generated Marangoni stresses in the colonization and survival of antibiotic-resistant infectious bacteria living at fluidic interfaces. The new insight provided by these studies can thus facilitate the design of more effective antibiotics. Graduate students supported by the project will gain advanced training in fluid dynamics, transport and interfacial phenomena, and high-performance simulations. Educational modules on Marangoni propulsion and flow-driven self-assembly at interfaces will be created and showcased during outreach activities, in addition to being integrated into the existing engineering courses. Active involvement of underrepresented minority and female students will be pursued via educational and outreach activities.<br/><br/>This research will establish a fundamental understanding of the Marangoni-driven motion of active particles alone and in groups, which appear in various contexts ranging from robotics and manufacturing to biology and medicine. New knowledge will be created by introducing a comprehensive numerical-theoretical-experimental framework to examine the hydrodynamics of self-propelled interface-bound active particles. The successful completion of this project will lead to the development of a physics-based speed and stability charts for Marangoni surfers that serves as engineering guidelines for tailoring the system parameters to elicit the desired performance characteristics in a variety of applications. Additionally, the outcome of this study will advance the state-of-the-art in multi-physics computational analysis of particle-laden interfacial flows by developing a high-performance simulation technique capable of capturing the intricate interplay between the motion of the active particles, transport of released species or heat, and interface deformation and dynamics. The specific objectives of this project are: (i) characterizing the Marangoni propulsion of single particles in unbounded domains; (ii) investigating the influence of confinement on the propulsion dynamics of particles; (iii) analyzing the translational and rotational stability of self-propelled surfers; and (iv) exploring the self-assembly and collective surfing of active particles."
"1705519","Collaborative Research: Individual and Collective Dynamics of  Marangoni Surface Tension Effects between Particles","CBET","FLUID DYNAMICS","08/01/2017","06/09/2017","Jonathan Rothstein","MA","University of Massachusetts Amherst","Standard Grant","Ronald Joslin","07/31/2020","$179,138.00","","rothstein@ecs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","ENG","1443","","$0.00","The principal goal of this research is to investigate the motion of active particles at fluidic interfaces due to a gradient of surface tension stemming from the discharge of a surface-active agent, a surface reaction, or from the release of heat by the particle. Powered by converting chemical energy into mechanical work, these self-propelled Marangoni particles, both at the individual level and as a collection, can bring to bear functionalities that resemble those of biological organisms. The findings of this study will determine the guiding principles for designing miniature self-propelled particles, which can lead to transformative innovations in robotics, microfluidics, and biomedical engineering. These tiny surfing robots can potentially execute missions that are currently very difficult or even impossible to accomplish. The results of this project will also give rise to the development of active self-assembly techniques, which can be used for rapid fabrication of small-scale structured materials. Further, the outcome of this research will shed light on the role of self-generated Marangoni stresses in the colonization and survival of antibiotic-resistant infectious bacteria living at fluidic interfaces. The new insight provided by these studies can thus facilitate the design of more effective antibiotics. Graduate students supported by the project will gain advanced training in fluid dynamics, transport and interfacial phenomena, and high-performance simulations. Educational modules on Marangoni propulsion and flow-driven self-assembly at interfaces will be created and showcased during outreach activities, in addition to being integrated into the existing engineering courses. Active involvement of underrepresented minority and female students will be pursued via educational and outreach activities.<br/><br/>This research will establish a fundamental understanding of the Marangoni-driven motion of active particles alone and in groups, which appear in various contexts ranging from robotics and manufacturing to biology and medicine. New knowledge will be created by introducing a comprehensive numerical-theoretical-experimental framework to examine the hydrodynamics of self-propelled interface-bound active particles. The successful completion of this project will lead to the development of a physics-based speed and stability charts for Marangoni surfers that serves as engineering guidelines for tailoring the system parameters to elicit the desired performance characteristics in a variety of applications. Additionally, the outcome of this study will advance the state-of-the-art in multi-physics computational analysis of particle-laden interfacial flows by developing a high-performance simulation technique capable of capturing the intricate interplay between the motion of the active particles, transport of released species or heat, and interface deformation and dynamics. The specific objectives of this project are: (i) characterizing the Marangoni propulsion of single particles in unbounded domains; (ii) investigating the influence of confinement on the propulsion dynamics of particles; (iii) analyzing the translational and rotational stability of self-propelled surfers; and (iv) exploring the self-assembly and collective surfing of active particles."
"1615891","CHS: Small: Collaborative Research: Teleoperation with Passive, Transparent Force Feedback for MR-Guided Interventions","IIS","Cyber-Human Systems (CHS)","08/01/2016","05/04/2018","Mark Cutkosky","CA","Stanford University","Standard Grant","Ephraim P. Glinert","07/31/2019","$328,000.00","Bruce Daniel","cutkosky@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7367","7367, 7923, 9251","$0.00","Magnetic resonance imaging (MRI) is a widely used diagnostic tool that provides physicians with a remarkable extension to their natural vision, offering unparalleled high-definition visuals which enable soft tissue pathophysiology diagnosis, lesion delineation, and therapy monitoring without ionizing radiation.  Increasingly, physicians would like to use MRI not only for diagnosis but also for guided procedures like biopsy or tumor ablation, for greater accuracy.  However, the MR bore's geometry compels the physician to stand outside and transmit motions and forces remotely to tools operating on the patient within.  So although MR provides superior imaging, the sense of touch is absent.  To overcome this deficiency and achieve telepresence, physicians require a high-fidelity force-reflecting teleoperation system.  Added challenges are imposed by MR's intense magnetic field; ferromagnetic materials and electronics with current flow must be avoided, and even non-ferrous metals can produce imaging artifacts, which constrains the choice of actuators, transmissions, and sensors.   The PIs' goal in this project is to empower physicians to operate as if they were directly in contact with their patients, by integrating real-time 3D tissue imaging with kinesthetic and force feedback for physical interactions.  Project outcomes have the potential to directly affect a large population, because the high-fidelity force transmission developed here will be applicable to other image-guided interventions such as drug delivery and ultrasound.  The hybrid hydrostatic transmission will be applicable to (and indeed was initially conceived for) interactive human-safe robots; advances made in adapting it to MR-guided interventions will allow maturation of the technology and reductions in size and cost that will help push it into additional fields like medical robotics and bilateral teleoperation.  <br/><br/>This research represents a collaboration among experts in robotics, haptics and interventional radiology.  The work will build upon and extend a novel bilateral teleoperator based on hydrostatic and pneumatic elements with rolling diaphragm actuators that provides a unique combination of low inertia, passivity, high stiffness and transparency, and negligible friction and backlash, and which is ideally suited to provide kinesthetic and force feedback between a physician outside the MR bore and tools operating on a patient within, allowing physicians to feel tissue property variations, for example.  Sensitive, dexterous tasks will be realizable with a passive teleoperator if it is sufficiently stiff and light.  MR-guided interventions are a compelling application for the proposed hybrid transmission because of MR's particular constraints, which as noted above rule out many other technologies.   A key question this research addresses is how to scale the promising performance of single-axis prototypes to a complex multi-axis system able to perform MR-guided procedures.   The PIs will combine kinematic and dynamic analyses with user tests for ergonomics to ensure that it supports intuitive motions and provides transparent feedback while fitting inside the MR bore's constrained space.  They will integrate the teleoperated system's motions with MR images via compatible sensors and imaging fiducials to provide visual feedback and prevent accidental intrusion into undesirable regions while the physician focuses on tool tip interactions.  Together, the novel force-reflecting transmission, kinematic mechanism, sensors, and software constitute a cyber-human system with unprecedented capabilities.  This telepresence system will be an ideal platform to expand scientific understanding of the impact that transmission transparency provides for MR-guided interventions."
"1463482","Guided Evolutionary Games for Influencing Interacting Agents' Behavior in Large Populations","CMMI","Dynamics, Control and System D","09/01/2015","08/30/2015","Andrew Belmonte","PA","Pennsylvania State Univ University Park","Standard Grant","Irina Dolinskaya","08/31/2019","$400,000.00","Christopher Griffin","andrew.belmonte@gmail.com","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","ENG","7569","030E, 031E, 032E, 033E, 034E, 035E, 099E, 8024","$0.00","Swarm robotics is the use of a large number of small, simple robots to accomplish common goals, mimicking the cooperative task sharing observed naturally in hives and colonies. As this technology becomes a reality, there is an increasing need to develop methods for guiding and controlling the swarm. The standard approach to controlling a system of multiple agents relies on treating them as approximately separate, however other paradigms will be needed as the number of these agents becomes unmanageably large, and their interactions dominate their behavior. The growing success of evolutionary game theory in biology and ecology suggests a mechanism for control at the population level, in which individual interactions are manipulated to drive the agent community towards global goals. This award is concerned with developing and studying these guided evolutionary games, and testing their consequences in simulations of interacting agents. Applications include the control of microscopic robot swarms in medical applications and the guided management of online social phenomena, including the development of active influence mechanisms for decreasing negative online behaviors like cyberbullying. This project will provide valuable interdisciplinary training for young researchers, and target outreach activities towards high school students, and undergraduates.<br/><br/>This project takes the first steps in bridging the gap between evolutionary game theory, massively distributed mechanism design, and the design of control systems. The work focuses on semi-autonomous agents who interact with each other through localized communication, and describes their behavior via evolutionary games using either replicator or discontinuous imitation dynamics. Communications play out either on a network or in Euclidean space; both topologies increase the problem complexity and can lead to organized spatial patterns. Connections will be made systematically between microscale, agent-based simulations, and macroscale, density-based evolutionary equations, such as the replicator and other alternatives. The dynamics of hybrid controllers, that modify the game played by the interacting agents, will also be considered. Control of the population is accomplished by periodic actuation of the game governing the interactions. The goals of this project are to understand the control-theoretic preliminaries necessary to allow equilibrium shaping in order to control populations, to determine the theoretical limits of control in this setting, and finally to apply this approach to the control of autonomous agents in high-fidelity simulations."
"1654268","CAREER:   Form and Function in Cortical Neuronal Networks","DMS","MATHEMATICAL BIOLOGY, MSPA-INTERDISCIPLINARY, MODULATION, Division Co-Funding: CAREER","07/01/2017","05/02/2017","Robert Rosenbaum","IN","University of Notre Dame","Continuing grant","Junping Wang","06/30/2022","$239,980.00","","robert.rosenbaum@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","7334, 7454, 7714, 8048","1045, 1096, 8007, 9179","$0.00","The cerebral cortex is the central processing area of the brain.  Nearly all higher cognitive functions depend on the activity patterns of cortical neuron populations.  These activity patterns are shaped by the structure of connectivity between cortical neurons and, conversely, cortical connectivity is shaped by cortical activity through changes in connection strengths called ""synaptic plasticity.""  This project will develop novel computational models and mathematical analyses to understand the interplay between cortical connectivity and cortical activity, and how it gives rise to cognitive functions like sensory processing and motor learning.  The results will lead to a better understanding of how the cortex functions and how it dysfunctions in disease states.  The results will also inform the development of biologically-inspired machine learning algorithms.  Graduate and undergraduate students will be involved in all aspects of the research and benefit from coursework inspired by the research projects.  Students at a public high school will be guided in a project to incorporate learning algorithms from the research into a robot, providing hands on experience with applied mathematics, computer programming, and robotics.<br/><br/>The project comprises three sub-projects that build on each other.  The first sub-project utilizes the notion of excitatory-inhibitory balance in cortical networks to derive scaling laws for connection strengths at large network size.  Previous theoretical work elucidates the computational utility of an inverse square root scaling law and recent experimental work provides biological evidence for it, but the mechanisms through which the law could emerge are unknown.  Candidate biological mechanisms will be analyzed mathematically and evaluated in collaboration with an experimental neuroscientist.  For the second project, the theory of neuronal networks with excitatory and inhibitory balance will be refined and extended to account for the imprecision of balance observed in experiments.  Preliminary calculations suggest that this imprecision is mathematically necessary, produces biologically realistic activity, and invokes intricate response properties that have implications for artificial neural networks used for image analysis.  The third project will develop and analyze a mathematical model of motor learning that combines Hebbian plasticity in a cortical pathway with reward modulated plasticity in a sub-cortical pathway, inspired by experimental observations.  This two-pathway motor learning algorithm has implications for biological motor learning, motor disease, and robotics."
"1617122","CHS: Small: Collaborative Research: Teleoperation with Passive, Transparent Force Feedback for MR-Guided Interventions","IIS","Cyber-Human Systems (CHS)","08/01/2016","08/04/2016","John Whitney","MA","Northeastern University","Standard Grant","Ephraim P. Glinert","07/31/2019","$180,000.00","","j.whitney@northeastern.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","7367","7367, 7923","$0.00","Magnetic resonance imaging (MRI) is a widely used diagnostic tool that provides physicians with a remarkable extension to their natural vision, offering unparalleled high-definition visuals which enable soft tissue pathophysiology diagnosis, lesion delineation, and therapy monitoring without ionizing radiation.  Increasingly, physicians would like to use MRI not only for diagnosis but also for guided procedures like biopsy or tumor ablation, for greater accuracy.  However, the MR bore's geometry compels the physician to stand outside and transmit motions and forces remotely to tools operating on the patient within.  So although MR provides superior imaging, the sense of touch is absent.  To overcome this deficiency and achieve telepresence, physicians require a high-fidelity force-reflecting teleoperation system.  Added challenges are imposed by MR's intense magnetic field; ferromagnetic materials and electronics with current flow must be avoided, and even non-ferrous metals can produce imaging artifacts, which constrains the choice of actuators, transmissions, and sensors.   The PIs' goal in this project is to empower physicians to operate as if they were directly in contact with their patients, by integrating real-time 3D tissue imaging with kinesthetic and force feedback for physical interactions.  Project outcomes have the potential to directly affect a large population, because the high-fidelity force transmission developed here will be applicable to other image-guided interventions such as drug delivery and ultrasound.  The hybrid hydrostatic transmission will be applicable to (and indeed was initially conceived for) interactive human-safe robots; advances made in adapting it to MR-guided interventions will allow maturation of the technology and reductions in size and cost that will help push it into additional fields like medical robotics and bilateral teleoperation.  <br/><br/>This research represents a collaboration among experts in robotics, haptics and interventional radiology.  The work will build upon and extend a novel bilateral teleoperator based on hydrostatic and pneumatic elements with rolling diaphragm actuators that provides a unique combination of low inertia, passivity, high stiffness and transparency, and negligible friction and backlash, and which is ideally suited to provide kinesthetic and force feedback between a physician outside the MR bore and tools operating on a patient within, allowing physicians to feel tissue property variations, for example.  Sensitive, dexterous tasks will be realizable with a passive teleoperator if it is sufficiently stiff and light.  MR-guided interventions are a compelling application for the proposed hybrid transmission because of MR's particular constraints, which as noted above rule out many other technologies.   A key question this research addresses is how to scale the promising performance of single-axis prototypes to a complex multi-axis system able to perform MR-guided procedures.   The PIs will combine kinematic and dynamic analyses with user tests for ergonomics to ensure that it supports intuitive motions and provides transparent feedback while fitting inside the MR bore's constrained space.  They will integrate the teleoperated system's motions with MR images via compatible sensors and imaging fiducials to provide visual feedback and prevent accidental intrusion into undesirable regions while the physician focuses on tool tip interactions.  Together, the novel force-reflecting transmission, kinematic mechanism, sensors, and software constitute a cyber-human system with unprecedented capabilities.  This telepresence system will be an ideal platform to expand scientific understanding of the impact that transmission transparency provides for MR-guided interventions."
"1717569","RI:   Small:  Collaborative Research:  Hidden Parameter Markov Decision Processes: Exploiting Structure in Families of Tasks","IIS","ROBUST INTELLIGENCE","08/01/2017","08/04/2017","George Konidaris","RI","Brown University","Standard Grant","Weng-keen Wong","07/31/2020","$208,000.00","","George_konidaris@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","CSE","7495","7495, 7923, 9150","$0.00","Part 1<br/>Machine learning has the potential to automate many complex, real-life tasks. However, learning algorithms typically require a substantial amount of data from each specific task they are asked to solve, requiring repeated interactions with the world, each of which take time and effort. Many real-life learning scenarios involve repeated interactions with tasks that are similar, but not identical. For example, an immunologist may encounter HIV patients with different comorbid conditions and latent viral reservoirs - each has a similar disease but a different progression, requiring individualized treatment; a robot may have to manipulate objects of different size and weight - each requiring similar but not identical grasping strategies. In such cases treating all of the tasks as the same results in poor performance, but learning to solve each as if they were completely different takes far too long. This project will develop intelligent agents that can use knowledge gained when solving prior tasks to much more rapidly learn new tasks that are similar but not quite the same.<br/><br/>The principal technical component of this project will lie in rigorously defining what it means for tasks to be related and in producing algorithms for leveraging that definition to enable rapid learning. To do so, the project will introduce the Hidden-Parameter Markov Decision Process, which models a family of tasks through a parameter which describes variation through the family but is hidden from the learner. The project will investigate methods that exploit this structure by learning a model of task variation and then seeking to identify the parameter value for each specific task. The planned work will focus on healthcare applications, where families of related but distinct tasks are common (i.e. each patient will have unique characteristics).  However, the project aims to produce foundational learning algorithms applicable to many application areas, ranging from robotics to systems design. This research will also be integrated into the courses taught by the PIs at Harvard and Brown and made available online; the PIs will include a diverse population, including REUs, both in these classes and in their research groups.<br/><br/>Part 2<br/>Many real-life learning scenarios involve repeated interactions with tasks that have similar, but not identical, dynamics.  For example, an immunologist may encounter HIV patients with different comorbid conditions and latent viral reservoirs; a robot may have to manipulate objects of different size and weight.  These cases describe a family of related tasks, each of which is similar but not quite the same. An intelligent agent should be able to transfer knowledge learned during previous experiences to rapidly solve new tasks in the same family. However, while many algorithms have been developed to transfer knowledge, the lack of a model of task relatedness inhibits our ability to formally understand the benefits of such algorithms or the structure they exploit.<br/><br/>The planned work will model such scenarios by embedding the tasks on a low dimensional manifold that captures relevant variation between instances.  Each location on this manifold (unobserved by the agent) describes a task instance, forming a sufficient statistic for solving the task in the context of the task family.  Preliminary work by the PIs has shown that it is possible to learn such a manifold after solving just a few individual task instances and enable the rapid optimization of policies for new task instances.  Building on these promising initial results, the PIs plan to: 1) Develop methods for task family characterization, by determining whether a collection of tasks can be modeled via a single manifold or consists of several clusters; whether a new task belongs to an existing cluster or manifold; and if so, and whether or not transfer is worthwhile. 2) Scale inference by adapting recent results from machine learning to deal with large state and action spaces. 3) Generate policies using Bayesian reinforcement learning algorithms, and by exploiting formal links between state and policy representations.<br/><br/>In addition to synthetic domains, progress on these directions will be applied to problems of treatment optimization for patients with HIV, sepsis, and depression via clinical collaborations that the PIs have with world-experts in these diseases."
"1534890","DMREF: Programmable Chemomechanical Materials","DMR","DMREF","09/01/2015","08/14/2015","Seth Fraden","MA","Brandeis University","Standard Grant","John Schlueter","08/31/2019","$1,159,386.00","Bing Xu, Michael Hagan, Klaus Schmidt-Rohr","fraden@brandeis.edu","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024532728","7817362121","MPS","8292","8400","$0.00","NON-TECHNICAL SUMMARY<br/>This project draws inspiration from the sinuous motion of a lamprey, in which neurons running down the spinal column are excited in sequence causing the musculature to contract, thereby propelling the lamprey. The fundamental principles underlying this behavior are understood, and this team seeks to engineer nonliving materials that possess these properties of living matter. They will develop purely synthetic materials that will operate autonomously, driven solely by chemistry without electricity, computers, or motors. These materials will execute multiple functions and be externally triggered to modify their behavior. Thus, this work will establish a new paradigm of precise and programmable chemical control for the fledgling field of soft robotics, in which soft, tissue-like materials replace the rigid, hard materials now found in robots on factory floors.<br/><br/>TECHNICAL SUMMARY<br/>The objective of the project is to develop purely synthetic, chemomechanical materials that emulate biological processes, such as the beating of a heart, at programmable rates and rhythms. The long-term goal is to elucidate the fundamental physical principles of active soft matter based on reaction-diffusion chemistry, enabling engineering of materials capable of chemical control and chemomechanical transduction. This research will address two fundamental challenges in the design of chemomechanical materials. The first is to understand and develop mechanisms of volume transitions in redox-sensitive gels, by which forces can be actuated. Materials engineered from a selection of promising building blocks will be probed over length scales ranging from nanometers to millimeters in order to fully elucidate gel structure and dynamics. These findings will be fed into atomistic and mesoscopic computer models, which will in turn inform the chemical synthesis of next-generation materials with desirable properties. The second challenge is to engineer a control mechanism comprised of an array of micron-scale compartmentalized reactors that contain an oscillating chemical reaction, and are physically networked via diffusion. Coupling the control and actuation sub-systems will yield chemically responsive gels that can change volume in concert with predictable and tunable chemical activity. Such materials will have attributes heretofore found only in living matter, such as flexibility in mammalian tongues, pulsatile contractions in human intestines, and heliotropism in plants. Thus, this work will establish a new paradigm of precise and programmable chemomechanical control for the fledgling field of soft robotics."
"1725636","MRI: Acquisition of a Power-Hardware-in-the-Loop (PHIL) System to Enhance Research and Student Research Training in Engineering and Computer Science","ECCS","MAJOR RESEARCH INSTRUMENTATION","09/15/2017","09/07/2017","Jin Ye","CA","San Francisco State University","Standard Grant","Jenshan Lin","08/31/2020","$297,318.00","Cheng Chen, Hao Yue, Adelbert Cheng, Mohamed Badawy","jin.ye@uga.edu","1600 Holloway Ave","San Francisco","CA","941321722","4153387090","ENG","1189","1189","$0.00","Abstract:<br/>Nontechnical <br/>This Major Research Instrumentation award will enable the acquisition of a state-of-the-art Power-Hardware-in-the-Loop system that is currently revolutionizing test engineering on many levels, including power/smart grids, vehicle and communication systems, civil structures, robotics, and aerospace. The acquisition of this highly scalable and configurable, computationally efficient simulation and experimental testing platform will enable the diverse multi-user community of engineers, computer scientists, and student researchers at San Francisco State University and San Jose State University to develop and evaluate complex systems and/or physical components in an integrated fashion. This system will significantly enhance the research capability at the two participating Hispanic-serving, non-Ph.D-granting institutions that rank among the leaders in ethnic diversity in the U.S. It will create well-equipped research environments that integrate research and research training and provide crucial research infrastructure needed to catalyze cross-disciplinary collaborations among faculty members and initiate and/or strengthen their collaborations with other research institutions and industrial partners. It will enrich the education of Hispanic, female, and African-American students by providing them hands-on research training in frontier technology. It will advance the careers of junior female faculty members enabling them to serve as role models for female students who remain underrepresented in Science, Technology, Engineering, and Mathematics. It will also lead to the creation of new teaching and research laboratories that will be integrated into the engineering and computer science curricula.<br/>Technical<br/>The Power-Hardware-in-the-Loop system will become an indispensable tool to stimulate new research in four key sectors of engineering and computer science research: vehicle system, power/smart grid, prosthetic robotic arm development, and structural analysis. In vehicle system research, it will be used to catalyze progress in the following areas: (1) improvements of the reliability, cost-effectiveness, and efficiency of key electric drive components in electrified vehicles; (2) development of hybrid energy storage systems to accelerate the introduction of electrified vehicles in the transportation sector; and (3) development of in-cylinder control strategies for advanced combustion modes in compression-ignition engines. In the power/smart grid research sector, it will be used to enhance research opportunities in the following areas: (1) investigation of the grid integration impacts of electric vehicle charging and renewable energy sources; (2) experimental evaluation of power electronic interfaces in smart grids; (3) failure analyses of power equipment in power grids; and (4) development of communication and/or smart sensing infrastructure in smart grids. The instrument will also enhance the computational capacity for high-fidelity simulation of analytical substructure and facilitate the developments of advanced control interfaces for the next-generation of myoelectric prosthetic robotic arms."
"1751291","CAREER: Nanoscale Resolution of Interfacial Materials Physics in Dry, Ionic Polymers","DMR","POLYMERS","03/01/2018","11/15/2017","Christopher Evans","IL","University of Illinois at Urbana-Champaign","Continuing grant","Andrew J. Lovinger","02/28/2023","$116,000.00","","cme365@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","MPS","1773","1045, 8396, 8399","$0.00","NON-TECHNICAL SUMMARY:<br/><br/>Polymers are important industrial materials that are flexible, lightweight, and readily processable. When positive or negative  electric charges are attached to these polymer molecules they become ""ionic polymers"" which can enable applications in technologies ranging from flexible batteries to soft robotics to wearable sensors. In all of these areas, a positive and negative electrode will be in contact with the material and the behavior of the polymer/electrode interface will impact the overall performance. In batteries, polymers must adhere to the electrode as it charges/discharges to prevent device failure. For soft robots, the movement of ions and polymer at the interface determines how a polymer bends in response to an electrical signal.  This project is pursuing a fundamental understanding of how the structure and dynamics of a polymer are impacted within 10-100 nanometers of a charged surface and how it is different from bulk behavior. Custom made ionic polymers with fluorescent labels will be used to selectively probe the polymer dynamics either adjacent to or far away from the electrode. X-ray experiments will provide further information on how the polymer structure is impacted by electrodes. Insights from this work will be used to design the next generation of improved ionic materials. Such polymers could benefit society by providing cheap and reliable energy storage, advanced real-time wearable health sensors, and soft autonomous robotic systems which could be deployed for defense purposes.   The project will contribute to education of students in forefront scientific and technological areas.  Outreach activities include a day camp and weekend engineering fair with underrepresented demographics starting at a young age (elementary to middle school). A recurring, off-campus event will host talks open to the public to highlight cutting edge materials research. <br/><br/><br/>TECHNICAL SUMMARY:<br/><br/>This research seeks to advance the fundamental physical understanding of dry, ionic polymers in the bulk and at electrified interfaces. This work is novel in two key aspects which will enable new fundamental insights. The first is the use of bulky, delocalized ionic groups which weaken the charge interactions and render the polymer processable even at high ion contents and without plasticizers or water (which is incompatible with many battery chemistries). The second is the use of fluorescence and time-correlated X-ray experiments to spatially explore the material physics with sub 10-nm precision. The role of ionic interactions, both intra- and interchain, on influencing ionic polymer mobility and the surface and interfacial tension of polymer films will be investigated. Perturbations to ionic polymers due to electrodes or free surfaces will be directly investigated using nanoscale approaches. First, multilayer films will be constructed where a ca. 10 nm thick layer is placed either at the electrode or in the bulk to selectively probe regions of the stack. In single layer films, coherent X-ray methods will probe the surface fluctuations and provide information on how both surface dynamics and the surface tension depend on ionic correlations and structure (determined in separate scattering experiments) in the material.  New insights will provide a better understanding of the physics of polymer electrolytes at electrodes, thin film coatings and adhesives, and self-healing materials. A major contribution of this work is developing a molecular understanding of how ionic associations and electric fields impact the diffusion of dry, charged polymers. Prior work on polyelectrolyte diffusion has been limited to systems with low (< 15 mol%) ionic content or systems that are plasticized with water/solvent, and thus this research is at a fundamentally different regime of ionic polymer physics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1652113","CAREER: Provably Correct Shared Control for Human-Embedded Autonomous Systems","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","04/01/2017","05/09/2018","Ufuk Topcu","TX","University of Texas at Austin","Continuing grant","David Corman","03/31/2022","$201,030.00","","utopcu@utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","7918","1045, 7918","$0.00","The proposed effort will help develop systems in which humans and autonomy are responsible for collective information acquisition, perception, cognition and decision-making. Such collective operation is a necessity as much as it is an augmenting technology. In assistive robotics, for example, the autonomy exists to support functionality that the human users cannot perform. On the other hand, in cases in which a human can adequately operate a platform (e.g., semi-autonomous unmanned vehicles), she effectively augments the robot's abilities. Establishing provable trust is one of the most pressing bottlenecks in deploying autonomous systems at scale. Embedding a human as a user, information source or decision aid into the operation of autonomous systems amplifies the difficulty. While humans offer cognitive capabilities that complement machine implementable functionalities, the impact of this synergy is contingent on the system's ability to infer the intent, preferences and limitations of the human and the imperfections imposed by the interfaces between the human and the autonomous system. We expect the proposed theory, methods and tools to cut across the spectrum of cyberphysical systems that are to work with and in the vicinity of humans. Such systems include, to name a few, human-robot interactions, a range of assistive medical devices, semi-autonomous driving or safety augmentation systems in modern automobiles and control rooms of large-scale plants.<br/><br/>The proposed effort targets a major gap in theory and tools for the design of human-embedded autonomous systems. Its objective is to develop languages, algorithms and demonstrations for the formal specification and automated synthesis of shared control protocols. Our technical approach is based on bridging formal methods, controls, learning and human behavioral modeling. It is based on three main research thrusts. (i) Specifications and modeling for shared control: What does it mean to be provably correct in human-embedded autonomous systems, and how can we represent correctness in formal specifications? (ii) Automated synthesis of shared control protocols: How can we mathematically abstract shared control, and automatically synthesize shared control protocols from formal specifications? (iii) Shared control through human-autonomy interfaces: How can we account for the limitations in expressivity, precision and bandwidth of human-autonomy interfaces, and co-design controllers and interfaces? The mathematically-based specifications and automated synthesis algorithms will diffuse the process of building trust throughout the design, have the potential to mitigate the need for purely empirical testing, and diagnose failure modes in advance of costly and restricted user studies. This systematic and early integration will help develop autonomous systems in which the operator and autonomy protocols are equally essential components of the same system and reduce the so-called ``automation surprises."" While we expect the theoretical and algorithmic outcomes of the proposed effort to be application- and hardware-agnostic, we concretize our research plan in a specific hardware platform. It is composed of an existing quadrotor testbed with 3D motion capture; human monitoring and decoding functionality through neural, visual, audial and biopotential signals; and human-autonomy interfaces with virtual reality embeddings."
"1651822","CAREER: Robust and Reliable Multiagent Scheduling under Uncertainty","IIS","ROBUST INTELLIGENCE","05/01/2017","05/07/2018","Jim Boerkoel","CA","Harvey Mudd College","Continuing grant","Reid Simmons","04/30/2022","$206,577.00","","boerkoel@cs.hmc.edu","301 Platt Boulevard","CLAREMONT","CA","917115901","9096218121","CSE","7495","1045, 7495","$0.00","Planning is important for autonomous systems, and planning for the real world typically involves reasoning about uncertainty in perception, action, and how the environment will react to actions of the agents.  This work will improve the robustness and reliability or plans in applications such as autonomous driving, automated warehousing, and personal robots by addressing limitations in how current planning systems handle real-world scheduling uncertainty.  The research will explore fundamental questions such as: What makes a plan good?  How good is it?  How can we make it better?  And, how should we adjust plans when faced with uncertainty?  The research will produce automated planning and scheduling techniques that can robustly adapt to real-world, uncertain interactions with physical environments and teammates.  The project will also develop and share curricula for two new undergraduate courses in robotics that highlight this research and will host a national AI Predoctoral Workshop that aims to broaden the pipeline of under-represented students into AI graduate research.<br/><br/>This work addresses a fundamental gap that currently exists between AI temporal planning theory and the execution of such plans, in practice. The specific research objectives are to (1) equip agents with more accurate plan representations by learning models of temporal uncertainty; (2) develop more useful measures of plan quality by introducing novel robustness and reliability metrics that predict the prospects of successful execution; (3) design more resilient scheduling methods by devising new online and offline heuristics that hedge against uncertainty; (4) construct more durable multi-agent coordination protocols by creating new decentralized algorithms for decoupling agents' schedules to allow robust, independent execution; and (5) demonstrate the efficacy of these ideas in the real world by evaluating on a diverse corpus of multi-robot benchmark problems.  If successful, this research will significantly improve the efficiency and usefulness of existing planning techniques in real-world settings and reframe how researchers analyze temporal plans.<br/>"
"1729486","Collaborative Research:   CI-P: ShapeNet: An Information-Rich 3D Model Repository for Graphics, Vision and Robotics Research","CNS","COMPUTING RES INFRASTRUCTURE","09/01/2017","06/07/2017","Qixing Huang","TX","University of Texas at Austin","Standard Grant","James Donlon","08/31/2019","$33,333.00","","huangqx@cs.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","7359","7359","$0.00","The goal of this project is to plan the development of a richly annotated repository of 3D models called ShapeNet that currently exists only in a preliminary form. ShapeNet will include 3-4 million 3D models of everyday objects in 4-5 thousand categories, in a variety of representations. Models in the ShapeNet repository will be annotated with multiple annotation types: geometric (parts, symmetries), semantic (keywords for the shape and its parts), physical (weight, size), and functional (affordances, scene context). The availability of ShapeNet data, capturing the 3D geometry of a significant fraction of object categories in the world, together with associated detailed meta-data and semantic information, will catalyze major developments in graphics, vision and robotics by providing adequate data against which new proposed techniques and methodologies for shape or scene analysis and synthesis can be vetted -- and with which machine learning algorithms can be trained. ShapeNet can be considered an encyclopedia that facilitates the creation of intelligent systems and agents capable of operating autonomously in the world --- because they can have deep knowledge of that world.<br/><br/>While most of the ShapeNet models will be initially found on the Web, the annotations will be obtained through an active learning combination of modest human input (including crowd-sourcing), extensive algorithmic transport, and human verification. During the planning period the effort will focus on mathematical representations of the semantic knowledge associated with 3D models, as well as on a design framework for key algorithms allowing knowledge transport from one model to another. Further challenges to be addressed include the quantification of data quality issues and the specification of all the multimodal (3D, image, language) UIs and APIs needed for users to be able to exploit and search this wealth of data, or to contribute additional models and annotations to it."
"1724101","S&AS: FND: Reliable Semi-Autonomy with Diminishing Reliance on Humans","IIS","S&AS - Smart & Autonomous Syst, ROBUST INTELLIGENCE","09/01/2017","05/29/2018","Shlomo Zilberstein","MA","University of Massachusetts Amherst","Standard Grant","Irene Sattler","08/31/2020","$707,512.00","Joydeep Biswas","shlomo@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","039Y, 7495","046Z, 9251","$0.00","Building reliable autonomous systems that can construct and execute plans to achieve some assigned goals, without human intervention, has been the hallmark of artificial intelligence and robotics since their inception.  Reliable autonomy is becoming increasingly important as it enables innovative new applications in areas such as transportation, health, and sustainable living.  Despite substantial progress, there are still considerable barriers to the long-term, large scale deployment of fully autonomous systems such as self-driving cars or mobile service robots.  These barriers range from technological and economic constraints to ethical and legal issues.  This project offers a comprehensive approach to circumvent these barriers by building semi-autonomous systems that rely on rich forms of human assistance, ranging from advice to constant supervision of the system with the possibility of taking over control.  The project develops techniques to assure the safety of such systems when human assistance is delayed and to reduce their reliance on human assistance over time.  Additionally, the project contributes to training of undergraduate and graduate students in this interdisciplinary area, mentoring of students with special attention to underrepresented groups, outreach activities to local schools, and strengthening of industrial collaborations.<br/><br/>The project answers fundamental questions about the feasibility, efficiency, and scalability of planning and learning algorithms to support semi-autonomous systems.  The main thrusts of the project are (1) develop techniques that can delegate autonomy to a system with some restrictions, and provide strong guarantees that these restrictions will be respected and that the system will maintain a safe state even when human assistance is delayed; (2) develop planning and learning algorithms that are cognizant of the availability of rich forms of human assistance and can effectively factor such assistive actions into the overall plan; (3) handle the high computational complexity of optimizing the interaction with humans under uncertainty and partial observability by creating a hierarchical multi-objective decision model; and (4) leverage human assistance to enable robust and accurate mapping and navigation in new areas, while reducing the reliance on human supervision over time.  The project evaluates these capabilities in complex realistic settings involving a campus-scale robot deployment, a driving simulator, and autonomous vehicles in collaboration with Nissan."
"1619050","RI: Small: A Paradigm for Motion Planning Based on Parameterization of Free Space","IIS","ROBUST INTELLIGENCE","09/01/2016","07/11/2016","Gregory Chirikjian","MD","Johns Hopkins University","Standard Grant","Reid Simmons","08/31/2019","$433,866.00","","gregc@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","7495","7495, 7923","$0.00","Motion planning is an important part of robotics research that enables robots to move without colliding into obstacles. This project focuses on a new paradigm for motion planning in cluttered environments in which robots and obstacles are represented as unions of ellipsoids, rather than the traditional approach of using polyhedral, which makes it more efficient to calculate potential collisions during planning. In addition to the scientific goals of the project, a longstanding outreach activity with Baltimore Polytechnic High School is part of the project. Two students from this high school per year will spend their ""research practicum"" in the PI's laboratory during their senior years.<br/><br/>In terms of detailed scientific questions, this project builds on the fact that the set of rigid-body motions that cause two ellipsoids to be in collision can be parameterized in closed form, thereby facilitating the sampling of collision-free configurations outside of these sets rather than wasting computational resources on sampling, evaluating whether collisions occur, and throwing away large numbers of<br/>samples. This is particularly important in so-called ""narrow-passage"" problems. This approach therefore has the potential to dramatically improve the performance of motion planning algorithms.<br/>"
"1708299","Collaborative Research: ACI-CDS&E: Highly Parallel Algorithms and Architectures for Convex Optimization for Realtime Embedded Systems (CORES)","OAC","CDS&E-MSS, CDS&E","09/01/2017","08/24/2017","Saeid Nooshabadi","MI","Michigan Technological University","Standard Grant","Vipin Chaudhary","08/31/2020","$349,988.00","","saeid@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","CSE","8069, 8084","026Z, 7433, 8084, 9263","$0.00","Embedded processors are ubiquitous, from toasters and microwave ovens, to automobiles, planes, drones and robots and are typically very small processors that are compute and memory constrained. Real-time embedded systems have the additional requirement of completing tasks within a certain time period to accurately and safely control appliances and devices like automobiles, planes, robots, etc. Convex optimization has emerged as an important mathematical tool for automatic control and robotics and other areas of science and engineering disciplines including machine learning and statistical information processing.  In many fields, convex optimization is used by the human designers as optimization tool where it is nearly always constrained to problems solved in a few hours, minutes or seconds. Highly Parallel Algorithms and Architectures for Convex Optimization for Realtime Embedded Systems (CORES) project takes advantage of the recent advances in embedded hardware and optimization techniques to explore opportunities for real-time convex optimization on the low-cost embedded systems in these disciplines in milli- and micro-seconds. The development of novel algorithms and their high-performance implementations for the real-time solution of practical engineering and scientific optimization problems on the embedded system will open new opportunities in the area of emerging computational science and engineering for cyber physical systems on low-cost platforms. Equally important is the CORES contributions to the education of the next generation of researchers and creators of future infrastructure for realtime computational systems for problems involving engineering optimization. Foremost, CORES will provide undergraduate and graduate level educational opportunities with a multidisciplinary breadth spanning areas as diverse as optimization theory, parallel algorithms for numerical optimization, embedded computer systems, and heterogeneous computing architectures.  Interactions with the control engineering and auto industries in the State of Michigan confirms the need for the development of expertise in this area for present and future engineering research and development. The results from CORES research will have an impact in the fields of engineering optimization and computing infrastructure for cyber physical systems.<br/><br/><br/><br/>The current algorithms for realtime convex optimization can only solve the problem with about a hundred unknowns in the Karush Kuhn Tucker (KKT) convex optimization matrices. This is because the realtime solution enforces a strict time limit on the linear solver (e.g., in microseconds) and  the current algorithms are not designed to fully utilize the limited compute power of the embedded system (e.g., a few CPU cores, plus a GPU). The CORES project will analyze the structure of complex multi-dimensional convex optimization algorithms and replaces the existing sequential implementations, which are the current performance bottleneck, with implementations of new tracking algorithms. Efficient implementations of the algorithms that can effectively leverage the compute power of the scalable heterogeneous system  architecture (SHSA) of the embedded system will be developed. The goal is to speed up the solution process and scale up the size of the optimization problems by orders of magnitude for realtime embedded applications such as control of complex cyber-physical systems (CPS). Specifically, CORES will focus on: (1) Development of high performance linear solvers that exploit the structures of the KKT matrices and leverage the compute power of SHSA and (2) Development of automatic code generation and analysis tools that analyze the structure of the convex optimization problem from a high level modeling language like MATLAB or PYTHON, perform a mapping to a decomposed parallel algorithm, and generate a hybridized multicore CPU and GPU code in OpenCL/CUDA format. Tools that CORES aims to develop come with hierarchical parallel-feature extraction, targeted for various computing elements of SHSA e.g. CPUs and GPU) in a way that eliminates the inefficiencies of inter-processors data sharing. Emerging SHSA combines general-purpose low-latency CPU cores with programmable high-bandwidth vector processing engines on a single platform, connected through a high speed data transfer engines that could still become the performance bottleneck. This feature creates unique opportunities for CORES, and others, to develop sophisticated and specialized computational algorithms and tools for engineering applications such as machine learning and autonomous vehicles  that can exploit such architectures for significantly enhancing performance and scaling up the problem size, while reducing the cost.<br/><br/>This project is supported by the Office of Advanced Cyberinfrastructure in the Directorate for Computer & Information Science & Engineering and the Division of Mathematical Sciences in the Directorate of Mathematical and Physical Sciences."
"1709069","Collaborative Research: ACI-CDS&E: Highly Parallel Algorithms and Architectures for Convex Optimization for Realtime Embedded Systems (CORES)","OAC","CDS&E-MSS, CDS&E","09/01/2017","08/24/2017","Jack Dongarra","TN","University of Tennessee Knoxville","Standard Grant","Vipin Chaudhary","08/31/2020","$412,083.00","","dongarra@icl.utk.edu","1 CIRCLE PARK","KNOXVILLE","TN","379960003","8659743466","CSE","8069, 8084","026Z, 7433, 8084, 9263","$0.00","Embedded processors are ubiquitous, from toasters and microwave ovens, to automobiles, planes, drones and robots and are typically very small processors that are compute and memory constrained. Real-time embedded systems have the additional requirement of completing tasks within a certain time period to accurately and safely control appliances and devices like automobiles, planes, robots, etc. Convex optimization has emerged as an important mathematical tool for automatic control and robotics and other areas of science and engineering disciplines including machine learning and statistical information processing.  In many fields, convex optimization is used by the human designers as optimization tool where it is nearly always constrained to problems solved in a few hours, minutes or seconds. Highly Parallel Algorithms and Architectures for Convex Optimization for Realtime Embedded Systems (CORES) project takes advantage of the recent advances in embedded hardware and optimization techniques to explore opportunities for real-time convex optimization on the low-cost embedded systems in these disciplines in milli- and micro-seconds. The development of novel algorithms and their high-performance implementations for the real-time solution of practical engineering and scientific optimization problems on the embedded system will open new opportunities in the area of emerging computational science and engineering for cyber physical systems on low-cost platforms. Equally important is the CORES contributions to the education of the next generation of researchers and creators of future infrastructure for realtime computational systems for problems involving engineering optimization. Foremost, CORES will provide undergraduate and graduate level educational opportunities with a multidisciplinary breadth spanning areas as diverse as optimization theory, parallel algorithms for numerical optimization, embedded computer systems, and heterogeneous computing architectures.  Interactions with the control engineering and auto industries in the State of Michigan confirms the need for the development of expertise in this area for present and future engineering research and development. The results from CORES research will have an impact in the fields of engineering optimization and computing infrastructure for cyber physical systems.<br/><br/><br/><br/>The current algorithms for realtime convex optimization can only solve the problem with about a hundred unknowns in the Karush Kuhn Tucker (KKT) convex optimization matrices. This is because the realtime solution enforces a strict time limit on the linear solver (e.g., in microseconds) and  the current algorithms are not designed to fully utilize the limited compute power of the embedded system (e.g., a few CPU cores, plus a GPU). The CORES project will analyze the structure of complex multi-dimensional convex optimization algorithms and replaces the existing sequential implementations, which are the current performance bottleneck, with implementations of new tracking algorithms. Efficient implementations of the algorithms that can effectively leverage the compute power of the scalable heterogeneous system  architecture (SHSA) of the embedded system will be developed. The goal is to speed up the solution process and scale up the size of the optimization problems by orders of magnitude for realtime embedded applications such as control of complex cyber-physical systems (CPS). Specifically, CORES will focus on: (1) Development of high performance linear solvers that exploit the structures of the KKT matrices and leverage the compute power of SHSA and (2) Development of automatic code generation and analysis tools that analyze the structure of the convex optimization problem from a high level modeling language like MATLAB or PYTHON, perform a mapping to a decomposed parallel algorithm, and generate a hybridized multicore CPU and GPU code in OpenCL/CUDA format. Tools that CORES aims to develop come with hierarchical parallel-feature extraction, targeted for various computing elements of SHSA e.g. CPUs and GPU) in a way that eliminates the inefficiencies of inter-processors data sharing. Emerging SHSA combines general-purpose low-latency CPU cores with programmable high-bandwidth vector processing engines on a single platform, connected through a high speed data transfer engines that could still become the performance bottleneck. This feature creates unique opportunities for CORES, and others, to develop sophisticated and specialized computational algorithms and tools for engineering applications such as machine learning and autonomous vehicles  that can exploit such architectures for significantly enhancing performance and scaling up the problem size, while reducing the cost.<br/><br/>This project is supported by the Office of Advanced Cyberinfrastructure in the Directorate for Computer & Information Science & Engineering and the Division of Mathematical Sciences in the Directorate of Mathematical and Physical Sciences."
"1555643","Collaborative Research: Olfactory Navigation: Dynamic Computing in the Natural Environment","PHY","OFFICE OF MULTIDISCIPLINARY AC, Chemistry of Life Processes, PHYSICS OF LIVING SYSTEMS, CROSS-EF ACTIVITIES, MATHEMATICAL BIOLOGY","11/01/2015","06/25/2017","Lucia Jacobs","CA","University of California-Berkeley","Continuing grant","Krastan B. Blagoev","10/31/2019","$780,932.00","","jacobs@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","MPS","1253, 6883, 7246, 7275, 7334","7237, 8007, 8091, 8251, 9178, 9179, 9183","$0.00","This project was developed at an NSF Ideas Lab on ""Cracking the Olfactory Code"" and is jointly funded by the Physics of Living Systems program in the Physics Division, the Mathematical Biology program in the Division of Mathematical Sciences, the Chemistry of Life Processes program in the Chemistry Division, and the Neural Systems Cluster in the Division of Integrative Organismal Systems. The project is a synergistic combination of laboratory experiments and computer modeling that will lead to better understanding of how animals use the sense of smell to navigate in the real world. Almost universally, from flies to mice to dogs, animals use odors to find critical resources, such as food, shelter, and mates. To date, no engineered device can replicate this function and understanding the code used by the brain will lead to many novel applications. Cracking codes, from neural codes to the Enigma code of WWII, is aided by a deep understanding of the content of messages that are being transmitted and how they will be used by their intended receivers. To crack the olfactory code, the team will focus on how odors move in landscapes, how animals extract spatial and temporal cues from odor landscapes, and how they use movement for enhancing these cues while progressing towards their targets. The proposed work encompasses physical measurement of odor plumes, behavioral measurement of animals' paths through olfactory environments, electrophysiological and optical measurement of neural activity during olfactory navigation, perturbations of the environment via virtual reality and of neuronal hardware via genetics, and multilevel mathematical modeling. The PIs will teach and work with undergraduate, graduate and postdoctoral students and especially recruit students from underrepresented groups in science. The project's results may lead to improved methods for the detection of explosives, new olfactory robots to replace trained animals, and new theoretically-grounded advances in robotic control. The project will inform the development of technologies that interfere with the ability of flying insects (including disease vectors and crop pests) to locate their odor target, thus opening a new door for developing 'green' technologies to solve problems that are of global economic and humanitarian importance.<br/> <br/>This proposal is a synergistic combination of laboratory experiments and computational modeling that will probe how animals use olfaction to navigate in their environment. Specifically, this effort seeks to solve the difficult problem of olfactory navigation through the following aims: (i) Generate and quantify standardized, naturalistic odor environments that can be used to perform empirical and theoretical tests of navigation strategies; (ii) Determine phenomenological algorithms for odor-guided navigation through behavioral experiments in diverse animal species; (iii) Determine how odor cues for navigation are encoded and used in the nervous system by recording neuronal data and simulating putative neural circuits that implement these processes; (iv) Manipulate olfactory environments and neural circuitry, to evaluate model robustness. In contrast to previous attempts to understand olfactory navigation, the present strategy emphasizes mechanisms that are biologically feasible and explores the wide range of temporal and spatial scales in which animals successfully navigate. The project will generate datasets of immediate use and importance to scientists in theoretical biology and mathematics, engineering (fluid mechanics, electronic olfaction, and robotics) and biology (neuroscience, ecology and evolution)."
"1637535","NRI: Design of nanorobotics based on iron-palladium alloy nanohelicses for a new diagnosis and treatment of cancer","ECCS","National Robotics Initiative","10/01/2016","07/07/2017","Minoru Taya","WA","University of Washington","Standard Grant","Radhakisan S. Baheti","09/30/2019","$1,508,000.00","Donghoon Lee, Yasuo Kuga","tayam@u.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","ENG","8013","092E, 8013, 8086, 9102, 9251","$0.00","Nanohelix is considered a new and attractive building block element for designing a set of new synthetic nano-actuators and -sensors and combination of them, namely nanorobotics which has broader applications; biomedicine, nanomedicine, key catalyst for synthesis of pharmaceutical medicine, key electrodes for energy devices (battery, solar cells, etc), and proximity tactile sensor of soft-matter robotic hands. If the nanohelix is mechanically flexible and made of magnetically active material, which is controlled under applied magnetic field, such magnetically active nanohelix can be designed into a new robotics system for diagnosis and treatment of difficult-to-treat cancers. The proposed nanorobotics can have multi-functions; (i) swimming under magnetic guidance, thanks to the shape of ""helical spring"", (ii) mechanical vibrations of the nanorobotics with flexible nanohelix  under applied magnetic field and gradient, thus, killing cancer cells due to mechanical stress loading, and (iii) magnetically active material for nanorobotics plays also as a magnetic resonance imaging enhancer, thus, accurate locations of the nanorobots if they are attached to cancer cell sites, can be identified by the magnetic resonance imaging. <br/><br/>We recently synthesized iron-palladium alloy nanohelices by using chemistry processing route; alumina-silica template and electroplating to make solid-state iron-palladium alloy nanohelices. This iron-palladium alloy nanohelix is down-sizing from our previous design of macro-iron-palladium alloy spring which exhibited the fast vibrations under applied magnetic gradient. The key scientific mechanism associated with the macro-iron-palladium alloy spring, which we discovered is a new actuation mechanism (hybrid mechanism), a set of chain-reactions; applied magnetic gradient, magnetic force, stress induced martensite phase from austensite phase, resulting in fast-actuation within a very short time. We recently made molecular dynamics modelling to simulate another actuator mechanism of iron-palladium alloy nanohelices under applied ""constant""  magnetic field. We also synthesized another nanorobot which is composed of iron-palladium alloy cylindrical head (head) and nanohelix where we can replace the iron-palladium alloy head by an iron head, thus, the nanorobot based on the combination of iron head and iron-palladium alloy helix may serve more effective nanorobot concept. <br/>The goals of the proposed NSF project are multi-fold: (1) to prove the hypothesis driven mechanical stress-induced apoptosis of cancer cells by using the nanorobots under magnetic field, (2) to establish the optimum navigation control of the magnetic nanorobots and (3) to demonstrate the effectiveness of the nanorobots for cancer diagnosis and treatment using in vitro experiment. To achieve the above goals, we propose the following five tasks over a three-year period:<br/><br/>Task-A: High-yield processing of magnetic nanohelices and their nanorobots (Taya)<br/>Task-B: Characterization of the nanostructure and properties of iron-palladium alloy nanohelices (Taya)<br/>Task-C: Modeling work (Kuga/Taya)<br/>Task-D: Production of nanorobots containing solution for apoptosis study (Takao/Taya)<br/>Task-E: In vitro experiment for magnetic nanorobots under applied magnetic field/gradient (Lee/Kuga)<br/><br/>The broader impact of this proposal is that the proposed nanorobots based on magnetic  nanohelices, leading to opening up new applications discussed above. We plan to incorporate the results into education,i.e., into the existing graduate course on active and sensing materials and their integrated systems and educational summer program at University of Washington. <br/>The intellectual significances of this NSF project are: (i) to establish high-yield processing route for key building block element of nanorobots, i.e. iron-palladium nanohelices, and combined magnetic  head and iron-palladium alloy nanohelix , (ii) to study if the hybrid mechanism of actuation in magnetic nanohelix is realized, (iii) to construct a cohesive model for an accurate control of nanorobots navigation, (iv) to test the hypothesis of mechanical stress loading-induced cell death and (v) to design Helmholtz coil system tailored for accurate navigation of nanorobots."
"1816039","RI: Small: A Cognitive Framework for Technical, Hard and Explainable Question Answering (THE-QA) with respect to Combined Textual and Visual Inputs","IIS","ROBUST INTELLIGENCE","08/01/2018","06/25/2018","Chitta Baral","AZ","Arizona State University","Standard Grant","James Donlon","07/31/2021","$499,999.00","Yezhou Yang","chitta@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7495","7495, 7923","$0.00","Understanding of visual and textual inputs are important aspects of Artificial Intelligence systems. Often such inputs are presented together to instruct and explain.  As examples, an intelligent robot might learn about its tasks and environment by observing both language and gesture; and an intelligent system addressing scientific questions must interpret figures and diagrams along with text. While there has been a lot of research concerning visual understanding and textual understanding in isolation, there has been very little research that addresses them jointly. This project is developing a framework for answering hard questions about combined visual and textual inputs, and providing supporting explanations. By developing a system that integrates visual and linguistic information for this task, the project could provide the basis for automated tutoring systems in K-12 education, and interpretable interfaces for the workers operating intelligent machines. <br/><br/>The project will employ an integrated approach of deep model-based visual recognition and natural language processing, and knowledge representation and reasoning to develop a question answering engine and its components. It will create a challenge corpus that has visual and textual inputs and questions about those inputs given in natural language. It will provide a baseline for semantic image and text parsing and reasoning-based question answering systems. It will develop semantic parsing of non-continuous text items, such as figures, diagrams, and graphs. It will enhance semantic parsing to various formats of natural language text and questions. It will develop methods to acquire knowledge and reasoning with them for answering questions and providing explanations to the answers. Together these contributions of the project will advance Artificial General Intelligence and allow future service robots and personal mobile applications to understand combined visual and textual inputs. The findings from this project will advance the development of knowledge-driven, reasoning-based question answering by filling the current gap on how to efficiently conduct explainable probabilistic reasoning over deep models.  This helps to overcome the fragility of the trained visual and textual understanding models. It will also uncover the intrinsic connections between deep model-based vision and language understanding algorithms and probabilistic knowledge representation and reasoning by exploring a joint solution for answering the hard questions. In general, this project may result in advances in multiple sub-fields of Artificial Intelligence; namely, computer vision, natural language processing, and question answering; and may impact others such as robotics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1718306","RI:  Small:  Collaborative Research:  Hidden Parameter Markov Decision Processes: Exploiting Structure in Families of Tasks","IIS","ROBUST INTELLIGENCE","08/01/2017","08/04/2017","Finale Doshi-Velez","MA","Harvard University","Standard Grant","Weng-keen Wong","07/31/2020","$242,000.00","","finale@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","7495","7495, 7923","$0.00","Part 1<br/>Machine learning has the potential to automate many complex, real-life tasks. However, learning algorithms typically require a substantial amount of data from each specific task they are asked to solve, requiring repeated interactions with the world, each of which take time and effort. Many real-life learning scenarios involve repeated interactions with tasks that are similar, but not identical. For example, an immunologist may encounter HIV patients with different comorbid conditions and latent viral reservoirs - each has a similar disease but a different progression, requiring individualized treatment; a robot may have to manipulate objects of different size and weight - each requiring similar but not identical grasping strategies. In such cases treating all of the tasks as the same results in poor performance, but learning to solve each as if they were completely different takes far too long. This project will develop intelligent agents that can use knowledge gained when solving prior tasks to much more rapidly learn new tasks that are similar but not quite the same.<br/><br/>The principal technical component of this project will lie in rigorously defining what it means for tasks to be related and in producing algorithms for leveraging that definition to enable rapid learning. To do so, the project will introduce the Hidden-Parameter Markov Decision Process, which models a family of tasks through a parameter which describes variation through the family but is hidden from the learner. The project will investigate methods that exploit this structure by learning a model of task variation and then seeking to identify the parameter value for each specific task. The planned work will focus on healthcare applications, where families of related but distinct tasks are common (i.e. each patient will have unique characteristics).  However, the project aims to produce foundational learning algorithms applicable to many application areas, ranging from robotics to systems design. This research will also be integrated into the courses taught by the PIs at Harvard and Brown and made available online; the PIs will include a diverse population, including REUs, both in these classes and in their research groups.<br/><br/>Part 2<br/>Many real-life learning scenarios involve repeated interactions with tasks that have similar, but not identical, dynamics.  For example, an immunologist may encounter HIV patients with different comorbid conditions and latent viral reservoirs; a robot may have to manipulate objects of different size and weight.  These cases describe a family of related tasks, each of which is similar but not quite the same. An intelligent agent should be able to transfer knowledge learned during previous experiences to rapidly solve new tasks in the same family. However, while many algorithms have been developed to transfer knowledge, the lack of a model of task relatedness inhibits our ability to formally understand the benefits of such algorithms or the structure they exploit.<br/><br/>The planned work will model such scenarios by embedding the tasks on a low dimensional manifold that captures relevant variation between instances.  Each location on this manifold (unobserved by the agent) describes a task instance, forming a sufficient statistic for solving the task in the context of the task family.  Preliminary work by the PIs has shown that it is possible to learn such a manifold after solving just a few individual task instances and enable the rapid optimization of policies for new task instances.  Building on these promising initial results, the PIs plan to: 1) Develop methods for task family characterization, by determining whether a collection of tasks can be modeled via a single manifold or consists of several clusters; whether a new task belongs to an existing cluster or manifold; and if so, and whether or not transfer is worthwhile. 2) Scale inference by adapting recent results from machine learning to deal with large state and action spaces. 3) Generate policies using Bayesian reinforcement learning algorithms, and by exploiting formal links between state and policy representations.<br/><br/>In addition to synthetic domains, progress on these directions will be applied to problems of treatment optimization for patients with HIV, sepsis, and depression via clinical collaborations that the PIs have with world-experts in these diseases."
"1665201","Advanced Programmable Logic Controllers, Robotics, and Networking","DUE","ADVANCED TECH EDUCATION PROG","07/01/2017","03/09/2017","Bruce Caraway","TX","Lone Star College System College District","Standard Grant","Elizabeth Teles","12/31/2019","$198,671.00","","Bruce.E.Caraway@lonestar.edu","20515 SH 249","Houston","TX","770702607","2816553730","EHR","7412","1032, 9178, SMET","$0.00","According to the Wall Street Journal, manufacturing executives indicate that they struggle to find workers with the required skills to operate in the modern factory, despite the presence of two unemployed manufacturing workers per manufacturing job opening (Sussman, 2016), because there is a knowledge gap between traditional and current and future industry requirements due to the accelerated pace of technological advances. In collaboration with industry partners, this project at Lone Star College University Park (LSC-UP) in Texas entitled Advanced PLC, Robotics, and Networking is designed to better prepare technicians to operate and maintain modern factory machines and work in the digital plant of the future, thus enhancing the employability of graduates and developing a diverse, globally competitive science, technology, engineering, and mathematics (STEM) workforce. Project activities will include curriculum and educational materials development, the evaluation of curriculum, and dissemination of the knowledge gained. It will assist employees as they become more employable and are trained on cutting edge industry standard equipment. This will allow future employees to enhance their personal well-being and that of their families while increasing the economic competiveness of the United States by ensuring that employee education and training keeps pace with employer demand and is aligned with industry skill needs. The knowledge obtained from this project will allow for the dissemination of industry driven curricula to transform the education and training of technicians to account for advancing technology and lead to long term enhanced technician education at the college as the courses are institutionalized through the Energy & Manufacturing Institute. The curricula will be disseminated through a paper for publication, conference presentations, and submission to the Workforce Education Course Manual (WECM), impacting the education of technicians at higher education institutions across the state and the country.<br/><br/>To address the industry needs for a multi-skilled technician to work in the manufacturing plant of the future that will rely heavily on integrated and intelligent ecosystems that use real-time and historical data to run efficiently and safely, the college will stack computer networking courses upon their current Mechatronics Technician education and training programs. Two new Mechatronics courses will be developed to incorporate computer networking to better prepare technicians for the modern digital plant. These new networking courses will provide students with the knowledge, skills, and competencies necessary to utilize the distributed control systems used to control manufacturing processes that are continuous or batch-oriented as well as the Supervisory Control and Data Acquisition (SCADA) systems used for remote monitoring and control in technical workplaces. This project will advance knowledge regarding technician education and training by identifying the emerging needs of employers hiring graduates of Mechatronics programs. The curricula will be evaluated by industry partners to ascertain its compliance with the current and projected needs of the occupations supported by Mechatronics programs, such as engineering technicians, process technicians, and mechatronics technicians."
"1746887","SBIR Phase I:  Flexible Robotics for Mass Customization of Shoe Sizing","IIP","SMALL BUSINESS PHASE I","01/01/2018","12/21/2017","Pamela Berkeley","NY","RE Shoes, LLC","Standard Grant","Ben Schrag","02/28/2019","$224,995.00","","pmberkeley@gmail.com","49 Cayuga St","Rochester","NY","146202142","5089819918","ENG","5371","5371, 8029","$0.00","This SBIR Phase I project will study the development of a digitally configurable shape around which a shoe can be created. The results of this project will enable the mass-customization of shoes so they can precisely fit the feet of the individuals who wear them. Properly fitting shoes are intended to improve the quality of life of customers through reduced pain and improved musculoskeletal health. This development in shoe-making technology is of broad interest to the population of the United States, but particularly important to women, who often suffer from physical deformities and injuries caused by ill-fitting shoes. The proposed innovation relies on mass-customization methods and flexible robotics technology. Its anticipated success will provide additional jobs in the shoe industry and related fields, and improve productivity nationwide through reduced healthcare costs.<br/><br/><br/>The strong technical innovation in this project will be the adaptation of granular jamming technology for use in programmable shape technology. The driving goal of the proposed project is to develop a last for use in the mass-customization of shoes that is capable of changing shape in response to a digital representation of the customer's foot shape. After changing shape, it will lock into a rigid but smooth form appropriate for use in traditional shoe manufacturing methods. The scope of the research will cover the development of the last in a manner appropriate for use in manufacturing conditions (in terms of both physical and temperature durability) and the creation and implementation of algorithms for transforming foot shape data into an appropriately fitting shoe shape and for transforming a standard shoe pattern onto an arbitrary foot shape. Iterative design practices and just-in-time manufacturing techniques will facilitate the development of this new technology and manufacturing methodology."
"1744426","Collaborative Research with Ethical, Legal and Social Implications","IIS","SCIENCE, TECH & SOCIETY, National Robotics Initiative","07/01/2017","06/21/2017","Joseph Gerdes","CA","Stanford University","Standard Grant","Reid Simmons","10/31/2018","$21,800.00","","gerdes@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7603, 8013","7556, 7603, 8086","$0.00","With the increasing use of autonomous systems in society, such as self-driving vehicles, issues of ethics becomes paramount.  The proposal seeks to bring researchers in AI and Robotics together with researchers in ethics and the law to discuss the relationships between research in ethical, legal and social implications (ELSI) and research in technological development and design.  The focus of the workshop will be both on the ethics and legality of using autonomous systems and on how to imbue autonomous systems with a set of ethical behaviors.  The workshop will discuss the issues and how NSF can promote interdisciplinary work between technologists and ethicists in the ELSI arena.  Approximately 30 researchers in AI, robotics, ethics and the law, together with regulators and industrial people from the automotive industry will be invited.  The one-day format, which will be held at Stanford University, will include lightning talks by participants, several breakout sessions, and work towards an executive summary and electronic reference guide on ?best practices? for such collaborative research."
"1837867","I-Corps Teams: Dynamically Tunable Reversible Dry Adhesives for Soft Grasping","IIP","I-Corps","07/01/2018","06/15/2018","Wanliang Shan","NV","Board of Regents, NSHE, obo University of Nevada, Reno","Standard Grant","Cindy WalkerPeach","12/31/2018","$50,000.00","","wshan@unr.edu","1664 North Virginia Street","Reno","NV","895570001","7757844040","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project, based on robotic gripping systems, is multifaceted and has societal, economic, and educational potential. From a societal and economic standpoint, it contributes to addressing the national need for increased automation in multiple application domains, including advanced manufacturing, agriculture such as fruit picking, as well as rehabilitation and elderly care of an aging population in the US. The soft grasping approach proposed to be commercialized here is based on a recently patented dynamically tunable reversible dry adhesion technology, which can help resolve pain points in electronics assembly and advanced manufacturing processes such as irregular-shaped parts manipulation on automotive assembly lines. The commercialization potential is estimated to be on the order of one billion dollars. From an educational standpoint, this project not only helps train the senior personnel on the project about entrepreneurship, but also helps instill entrepreneurship principles and practices among students and researchers. <br/><br/>This I-Corps project aims to identify the technical challenges faced by the industry on robotic gripping systems, which could help formulate ensuing application-driven fundamental problems pertaining to soft grasping. Soft grasping of objects with various shapes and stiffness has been a longstanding challenge in the robotics field. The approach proposed here is a spinoff of an ongoing NSF project, where novel smart materials and adhesion mechanics are integrated to realize a ""core-shell"" composite structure featured with dynamically tunable reversible dry adhesion. By modulating the stiffness of the ""core"" made of smart materials, the manner in which force is distributed to the interface between the composite and the adhered object is altered, and as a result, the effective adhesion strength of the adhered interface is changed.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1538830","Geometric Mechanics of Cellular Origami Assemblages","CMMI","Mechanics of Materials and Str, EFRI RESEARCH PROJECTS","09/01/2015","08/21/2015","Glaucio Paulino","GA","Georgia Tech Research Corporation","Standard Grant","Siddiq Qidwai","08/31/2019","$465,385.00","","glaucio.paulino@ce.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","1630, 7633","022E, 024E, 9161, AMPP","$0.00","Origami inspired structures can have applications ranging in scale from man-made materials and micro-robotics to deployable solar arrays and building facades. These systems can be created by creasing a thin sheet or connecting thin panels with flexible hinges. Origami appeals for practical applications because it can be stowed compactly and it can be deployed into a transformable moving structure. Such deployable assemblages can drastically enhance the characteristics and potential applications of the thin sheet system. Much remains unknown about these configurations.  The overarching goal of this research is to create mathematical models and physical prototypes that capture the behavior (both linear and nonlinear, including instability) of thin sheets, and to use these to explore the mechanics of tubular and cellular origami assemblages. This translational research will provide a new paradigm for using thin sheet assemblages in engineering through the integration of active materials, design theory, mathematics (geometric origami), and artistic expression. These systems may provide solutions for space exploration (e.g. deployable structures), robotics (e.g. robotic arms), medicine (e.g. stents), and other fields of study. The interdisciplinary approach will help broaden participation of underrepresented groups in research and positively impact engineering education by using origami as a means to integrate knowledge in different disciplines. The computer codes and geometric origami variations will be distributed in open-source platforms, greatly extending the practical applications of origami.<br/><br/>The intellectual merit of this research lies in understanding origami assemblages for their geometric variations and elastic properties, nonlinear mechanics, and instabilities including bistable-multistable configurations. The research will explore geometric variations of rigid foldable origami tubes and assemblages, create analytical models to simulate nonlinearities in thin sheet origami systems, and capture instability in transformable/reconfigurable origami structures. It will study novel origami assemblages such as those with curved profiles, polygonal cross-sections (N-gons), or multiple tubes coupled together. The research will generalize the geometric definitions for different assemblages, and study the kinematics, eigen-mode deformations, and material behavior of each system. Because thin sheet assemblages are useful beyond the assumptions of small displacements, the research will explore large displacements and the associated nonlinear behavior of origami. New computer models will be established, which can capture various nonlinearities associated with the thin sheet systems. A unified iterative scheme will be used to study origami that demonstrates either near-zero or negative stiffness. The energy states of these instabilities will inform practical applications of the transformable origami. The mechanical properties will be useful to scientist and engineers when using thin sheet origami systems of varying scales."
"1555891","Collaborative Research: Olfactory Navigation: Dynamic Computing in the Natural Environment","PHY","OFFICE OF MULTIDISCIPLINARY AC, Chemistry of Life Processes, PHYSICS OF LIVING SYSTEMS, CROSS-EF ACTIVITIES, MATHEMATICAL BIOLOGY","11/01/2015","06/28/2017","Jonathan Victor","NY","Joan and Sanford I. Weill Medical College of Cornell University","Continuing grant","Krastan B. Blagoev","10/31/2019","$667,865.00","","jdvicto@med.cornell.edu","1300 York Avenue","New York","NY","100654805","6469628290","MPS","1253, 6883, 7246, 7275, 7334","7237, 8007, 8091, 8251, 9178, 9179, 9183","$0.00","This project was developed at an NSF Ideas Lab on ""Cracking the Olfactory Code"" and is jointly funded by the Physics of Living Systems program in the Physics Division, the Mathematical Biology program in the Division of Mathematical Sciences, the Chemistry of Life Processes program in the Chemistry Division, and the Neural Systems Cluster in the Division of Integrative Organismal Systems. The project is a synergistic combination of laboratory experiments and computer modeling that will lead to better understanding of how animals use the sense of smell to navigate in the real world. Almost universally, from flies to mice to dogs, animals use odors to find critical resources, such as food, shelter, and mates. To date, no engineered device can replicate this function and understanding the code used by the brain will lead to many novel applications. Cracking codes, from neural codes to the Enigma code of WWII, is aided by a deep understanding of the content of messages that are being transmitted and how they will be used by their intended receivers. To crack the olfactory code, the team will focus on how odors move in landscapes, how animals extract spatial and temporal cues from odor landscapes, and how they use movement for enhancing these cues while progressing towards their targets. The proposed work encompasses physical measurement of odor plumes, behavioral measurement of animals' paths through olfactory environments, electrophysiological and optical measurement of neural activity during olfactory navigation, perturbations of the environment via virtual reality and of neuronal hardware via genetics, and multilevel mathematical modeling. The PIs will teach and work with undergraduate, graduate and postdoctoral students and especially recruit students from underrepresented groups in science. The project's results may lead to improved methods for the detection of explosives, new olfactory robots to replace trained animals, and new theoretically-grounded advances in robotic control. The project will inform the development of technologies that interfere with the ability of flying insects (including disease vectors and crop pests) to locate their odor target, thus opening a new door for developing 'green' technologies to solve problems that are of global economic and humanitarian importance.<br/> <br/>This proposal is a synergistic combination of laboratory experiments and computational modeling that will probe how animals use olfaction to navigate in their environment. Specifically, this effort seeks to solve the difficult problem of olfactory navigation through the following aims: (i) Generate and quantify standardized, naturalistic odor environments that can be used to perform empirical and theoretical tests of navigation strategies; (ii) Determine phenomenological algorithms for odor-guided navigation through behavioral experiments in diverse animal species; (iii) Determine how odor cues for navigation are encoded and used in the nervous system by recording neuronal data and simulating putative neural circuits that implement these processes; (iv) Manipulate olfactory environments and neural circuitry, to evaluate model robustness. In contrast to previous attempts to understand olfactory navigation, the present strategy emphasizes mechanisms that are biologically feasible and explores the wide range of temporal and spatial scales in which animals successfully navigate. The project will generate datasets of immediate use and importance to scientists in theoretical biology and mathematics, engineering (fluid mechanics, electronic olfaction, and robotics) and biology (neuroscience, ecology and evolution)."
"1538003","Manipulation of Elastic Deformation in Bio-inspired Wet Adhesion","CMMI","Mechanics of Materials and Str","09/01/2015","05/01/2017","Joelle Frechette","MD","Johns Hopkins University","Standard Grant","Siddiq Qidwai","08/31/2019","$338,000.00","","jfrechette@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","ENG","1630","022E, 024E, 116E, 9102, 9161, 9178, 9231, 9251, AMPP","$0.00","The choice of materials to control adhesion depends on the desired application. In robotics, for example, multiple adhesive cycles are necessary for locomotion, gripping, and manipulation. Synthetic hierarchical structures based on the gecko toe pads demonstrated these capabilities in air. Fulfilling these requirements for reversible adhesion in fluid environments (for example underwater), however, is more challenging. In fluids, dynamic effects such as drag and swelling can deform surface structures prior to contact and prevent adhesion. The objective of the work is to develop the fundamental understanding in mechanics necessary for the creation of structured surfaces that can act as reversible adhesives in liquids. The strategy to be followed is the fabrication of porous soft material films with a surface topography inspired by the frog toe pads. These films will be employed to investigate the role played by porosity and deformation on adhesion. The development of coatings for reversible underwater adhesion will advance the manufacturing of robotic components, bandages and wound sealants, and could help understand the mechanisms of biofouling. Beyond underwater adhesion for robotic and larger scale applications, a better understanding of poroelasticity in compliant materials could lead to better performing materials to replace joint cartilage. Outreach efforts include participation of high school and undergraduate students in the laboratory. Students participating in the project will be encouraged to present at conferences and be involved with additional outreach efforts at local elementary schools.<br/><br/>The dynamics of friction, adhesion, and fracture of porous compliant materials involve poorly understood phenomena because transport, deformation, and adhesion are highly coupled. To address this issue, new instrumentation will be developed to study the mechanical performance of soft and porous coatings to measure simultaneously dissipative forces and spatiotemporal deformation. The performance (e.g. adhesion and poroelastic relaxation) of polymer coatings fabricated with three different type of anisotropic pillars will be investigated and results will be compared with uniform coatings of the same material. In particular, dissipative force measurements in fluids will be performed to determine the role played by out-of-contact deformation alter the magnitude and directionality of adhesion. Throughout the project, experiments will be compared to existing theories and continuum numerical finite element models for elastohydrodynamics and poroelasticity that are based on lubrication, elasticity, and transport in porous media. The contributions of multi-scale porosity (e.g. mesh scale, pillar spacing, and surface roughness), modulus, and directional anisotropy in surface topography will be characterized in terms of their ability to be engineered toward applications in reversible adhesion in wet environments."
"1658696","IRES Cambodia: Mechatronics For Humanitarian Remediation of Explosive Remnants Of War","OISE","IRES Track I: IRES Sites (IS)","04/15/2017","04/12/2017","Garrett Clayton","PA","Villanova University","Standard Grant","Joseph Miller","03/31/2020","$249,867.00","Jordan Ermilio","garrett.clayton@villanova.edu","800 Lancaster Avenue","Villanova","PA","190851676","6105196000","O/D","7727","5978, 7727","$0.00","Explosive remnants of war (ERW) present a significant issue for Cambodia and other low-income countries. In response to this problem, the field of humanitarian ERW remediation seeks to detect, dispose, and even recycle ERW with the goal of rendering the ERW-contaminated land safe. Thus, these activities are of critical importance to the growth of affected nations and safety of their people. This international research experiences for students (IRES) program is focused on using mechatronics - a field which integrates mechanical engineering, electrical engineering, control systems engineering, and computer science - to develop solutions for the humanitarian ERW remediation community. This program, run from Villanova University (VU), will send 6 students - at least 2 of which will be graduate students - to do research in Cambodia, one of the most ERW contaminated countries in the world. These students will undertake a 10 week long summer program, including 7.5 weeks in-country. While in Cambodia, the students will collaborate with researchers affiliated with the Institute of Technology of Cambodia (ITC) - the premiere technical university in Cambodia - and the Golden West Humanitarian Foundation (GWHF) - one of the world leaders in humanitarian ERW remediation research and development. In addition to the main research goal of finding mechatronic solutions to problems in the humanitarian ERW remediation community, the program will also serve to 1) strengthen an existing VU-GWHF collaboration, 2) develop globally-engaged engineering researchers and 3) introduce future leaders in engineering research to humanitarian engineering issues. <br/><br/>The proposed research program will focus on difficult, real-world problems in the area of humanitarian ERW remediation. Projects will be jointly agreed upon by the researchers at VU, ITC, and GWHF. Potential projects include robotic non-technical and/or technical survey for area reduction, automated visual inspection of ordinance, and communications for explosive ordnance disposal (EOD). In general, the fundamental research in this project has the potential to impact mechatronics in a number of ways, including advancements to novel robotics platforms, advanced control and search algorithms, new sensors and sensing strategies, swarm robotics algorithms, and communications."
"1151805","Body Movement and Action Perception","BCS","CROSS-DIRECTORATE  ACTIV PROGR, PERCEPTION, ACTION & COGNITION, OTHER GLOBAL LEARNING & TRNING","07/01/2012","09/12/2016","Ayse Saygin","CA","University of California-San Diego","Continuing grant","Betty H. Tuller","06/30/2019","$587,350.00","","apsaygin@gmail.com","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","SBE","1397, 7252, 7731","1045, 5946, 7252, CL10","$0.00","Understanding the movements of others is critical for a wide range of functions such as detecting prey and predators, inferring the goals and intentions of others, and engendering emotional responses, such as feeling compassion and empathy toward others.  The investigators will use a range of complementary methods to understand how the human brain detects and interprets the body language of others.  For example, body movements can be characterized by very minimalist visual representations, consisting of a dozen points of light attached to the joints on the body seen in darkness (a method used in many motion capture systems).  In addition, the investigators will use high-resolution videos to link the work to the field of social cognition by determining how processing is affected when the movements are produced by an artificial agent like a robot, rather than by a human.  <br/><br/>Understanding the perceptual and neural basis for body movement processing is essential to an account of how humans negotiate objects and events in the world and can inform fields as wide-ranging as cognitive science, neuroscience, robotics, brain-computer interfaces, social cognition, technology design, visual arts, and computer vision.  In addition, social artificial agents such as humanoid robots and virtual animated characters are becoming increasingly common in a range of domains such as education, defense, healthcare and entertainment.  This research can help guide the design of these interactive technologies.  The investigators also aim to further science and education through recruitment and retention of young people, especially minorities underrepresented in science.  Since early engagement is critical for this goal, the focus will be on the development of hands-on research and computation skills for high school and undergraduate students."
"1745477","Convergence HTF: RCN: Enhancing Small and Mid-level Farm Viability Through a Systems-based Research Network: Linking Technology and Sustainable Development and Practice","CMMI","S&CC: Smart & Connected Commun, SPECIAL INITIATIVES, IUSE, INSPIRE","09/01/2017","08/23/2017","Divya Srinivasan","VA","Virginia Polytechnic Institute and State University","Standard Grant","Irina Dolinskaya","08/31/2022","$498,924.00","Alexander Leonessa, Kimberly Niewolny","sdivya1@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","ENG","033Y, 1642, 1998, 8078","042Z, 060Z, 063Z, 9102","$0.00","This convergence Research Coordination Network addresses the future of work at the human-technology frontier in the context of small- and medium-sized farms. Intelligent, interactive, and highly networked machines -- with which people increasingly interact -- are a growing part of the landscape, particularly in regard to work.  As automation today moves from the factory floor to knowledge and service occupations, research is needed to reap the benefits in increased productivity and increased job opportunities, and to mitigate social costs.  Convergence is the deep integration of knowledge, theories, methods, and data from multiple fields to form new and expanded frameworks for addressing scientific and societal challenges and opportunities. The Research Coordination Network supported by this award will define key challenges and research imperatives at the nexus of humans, technology, and work through the convergence of robotics, human factors, systems and control theory, neuromotor and cognitive sciences, machine learning, systems engineering, data analytics, precision agriculture, ergonomics, health and safety, and sustainability. This project promotes Convergence by exploring methods for incorporating a human-centric focus, including social and economic considerations, throughout the entire technology research and development process.<br/><br/>The specific focus of this Research Coordination Network is to build research collaborations among multiple stakeholders in order to fully realize the potential benefits of emerging technological capabilities in the context of small- and medium-sized farms. The stakeholders include academic researchers with complementary expertise in human factors, robotics, systems engineering, education, and sustainability, among other areas. Small- and medium-sized farms face a variety of serious economic and demographic challenges. Farming is a strenuous and dangerous occupation, which takes a physical toll on an aging workforce. Innovations in automation and robotics may augment individual capabilities as well as reduce the risk of injury, but with these potential benefits come the threat of job displacement and the possible exacerbation of economic inequity. Currently, creation and development of emerging technological solutions are typically driven along parallel, isolated lines of inquiry, with no awareness of the broad and interrelated nature of the issues involved. This research network seeks to provide researchers across relevant disciplines with this integrated perspective, as well as to involve stakeholders in the agricultural community at a much earlier stage in the technology development process."
"1350138","CAREER: Unifying representation stability via Fl-categories","DMS","TOPOLOGY, Division Co-Funding: CAREER","09/01/2014","08/29/2017","Thomas Church","CA","Stanford University","Continuing grant","Christopher W. Stark","08/31/2019","$344,988.00","","church@math.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","MPS","1267, 8048","1045","$0.00","<br/><br/>Award: DMS 1350138, Principal Investigator: Thomas F. Church<br/><br/>The physical distinction between bosons and fermions explains why photons can cohere into a laser, or helium-4 nuclei into a superfluid, whereas neutrons resist each other, as is necessary for the stability of neutron stars. Mathematically, this distinction is explained by the shape of their configuration space, which describes all possible ways that a collection of indistinguishable particles (such as photons or neutrons) can be configured in space. The investigator studies configuration spaces via their symmetries, proving that no matter what space the particles move within, the topology of configurations will stabilize, yielding identical behavior no matter how many particles are present. Configurations in restricted spaces have widespread applications: when electrons are confined to 2-dimensional surfaces as in field-effect transistors, new topology on the configuration space predicts new types of quasiparticles, which manifest in the fractional quantum Hall effect; in robotics, the topology of robots configured on a factory floor describes when one robot can be trapped by others. The proposed project would extend this stability to new types of configuration spaces possessing even more symmetry, whose stability cannot currently be understood or proved.  The investigator will also develop and teach Math Discovery Lab, a new discovery-based course for undergraduates which develops critical skills in independent research. Students in MDL will investigate open-ended problems, collect data via computer experimentation and simulation, formulate conjectures, and prove theorems about their results, presenting their findings through written reports and lectures.<br/><br/>The investigator's research focuses on representation stability, a technique applying representation theory to stability problems in topology and algebra. Representation stability has been very successful, leading to 20+ papers since its introduction by the investigator three years ago. The investigator proposes to extend and strengthen the power of representation stability by undertaking a long-term project to develop the combinatorial, categorical, and homological properties of FI-categories. These provide a coherent framework for studying a wide variety of symmetry groups, including many which could not be handled using previous methods. The proposed project will unify four distinct strands of stability as facets of the same theory: representation stability, homological stability, twisted stability, and central stability. A key advance is that the dependence on representation theory is removed, replaced instead by the combinatorial and homological properties of FI-categories, so that representation stability can be applied even to integral or modular representations."
"1527133","NRI: Collaborative Research: Dynamic Braces for Quantification and Treatment of Abnormal Curves in the Human Spine","CMMI","National Robotics Initiative","09/01/2015","08/11/2015","Charles Kim","PA","Bucknell University","Standard Grant","Irina Dolinskaya","08/31/2019","$141,993.00","","cjk019@bucknell.edu","One Dent Drive","LEWISBURG","PA","178372111","5705773510","ENG","8013","030E, 031E, 032E, 033E, 034E, 8086","$0.00","Idiopathic scoliosis is a condition in which the spine develops a strong left/right curvature, forming a C- or S-shape instead of a straight line. Approximately 2% to 3% of adolescents suffer from the disorder, with about 1 in 500 required to wear corrective braces until skeletal maturity, and about 1 in 5,000 requiring spinal surgery. A typical scoliosis brace is worn around the trunk and hips, and completely immobilizes the upper body, which substantially degrades quality of life. This project will demonstrate a hybrid dynamic brace for correcting scoliosis, while minimally affecting the activities of daily living. Compliant passive braces tailored to the treatment needs of individual wearers allow greater freedom of movement, but cannot respond to changes in posture or more gradual evolution of the wearer's condition. Active braces provide dynamically responsive corrective forces, but require power-hungry motors, and greatly increase weight and complexity. This project will demonstrate a hybrid approach, providing freedom of movement and dynamic response, but without the weight and power requirements of fully active designs. The result is essentially a wearable robot that continually monitors and responds to the needs of the user.<br/><br/>This project will lay the scientific foundation for the design of dynamic brace co-robots, and the evaluation of their effectiveness for both quantification and treatment of the abnormal spine. These dynamic braces will be designed to modulate the corrective forces on the spine in desired directions while still allowing the users to perform typical activities of daily life. The project will investigate the hypothesis that dynamic braces have the potential to transform treatment in this field, as these can provide effective control of corrective forces on the spine both spatially and temporally. The scientific studies will characterize the spatial stiffness of the spine in a specific pose and during different functions. The studies will target treatment outcomes in subjects with abnormal spine. Furthermore, this project will train students in interdisciplinary research and will result in future workshops and courses appealing to engineers, clinicians, medical caregivers, and high school students, motivating careers in STEM."
"1654944","Standard Grant: Textiles, Technology, and the Return of Manufacturing in the United States","SES","CULTURAL ANTHROPOLOGY, SCIENCE, TECH & SOCIETY","06/01/2017","01/26/2017","Caitrin Lynch","MA","Franklin W. Olin College of Engineering","Standard Grant","Frederick M Kronz","05/31/2019","$196,515.00","","caitrin.lynch@olin.edu","1000 Olin Way","Needham","MA","024921200","7812922426","SBE","1390, 7603","7567","$0.00","General Audience Summary   <br/><br/>This award supports a study of the daily impact of globalization and deindustrialization in the US, as seen on the shop floor and in the boardroom of a small 160-year-old New England textile mill, one of the oldest in the US. It examines the role of technological change in efforts of the mill to stay in business; in doing so, it expects to show how individuals and communities in the contemporary US transition from an old form of manufacturing centered on manual labor and mass production to a new digitally equipped one. The theoretical aim of the project is to contribute to studies in STS on human-technology interactions in the workplace by developing more complex narratives about human-automata interchangeability. The project will involve both intensive collaborative factory-based ethnographic research and engineering projects involving engineering students and senior personnel in materials science and mechanical engineering/robotics. The PI aims to reach a diverse audience with her research findings. She is an anthropologist who teaches anthropology to engineers, and values bringing anthropological understandings to public audiences and into the engineering classroom. She will share her research findings from this project with engineering students as part of a continual effort to engage with critical questions that impact the choices engineering students make in their engineering work. The project will also be an important resource for consumers and business people; it will point to important lessons to be learned from the sociological life of textiles and their fabrication, including larger lessons for other manufacturing in the US.<br/><br/>Technical Summary  <br/><br/>The PI aims to analyze the experiences of people and the contexts of those experiences all along the production process at the textile factory site; she plans to pay equal attention to the goals and stresses of the president and to those of the minimum-wage production worker. She will leverage the expertise of engineering colleagues to analyze how humans and machinery are transformed together in contemporary US manufacturing. More broadly, she will brings anthropological methods to long-studied questions in the history of technology, such as human-machine interaction, automation in the workplace, and the changing meanings of labor. Her analysis will include relationships among materials, machinery, workers, and managers, and how automation impacts the meaning, structure, and experience of work for people at all workforce levels. The project will engage with work in economics and in STS studies on whether robotics and automation will someday render human labor obsolete. Her working hypothesis is that workers and managers enroll a combination of analog and digital technologies in their quest to continue manufacturing domestically in novel, understudied ways. She aims to disrupt the popular narrative that robots will replace humans in the workplace, by hypothesizing that digital technology and processes can keep workers employed and can stimulate novel sensory experiences as opposed to merely eliminating them."
"1617630","RI: Small: Incremental Sampling-Based Algorithms and Stochastic Optimal Control on Random Graphs","IIS","ROBUST INTELLIGENCE","06/15/2016","07/24/2017","Panagiotis Tsiotras","GA","Georgia Tech Research Corporation","Continuing grant","Reid Simmons","05/31/2019","$335,757.00","","p.tsiotras@ae.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7495, 7923","$0.00","Autonomous and semi-autonomous vehicles and systems have become indispensable both for civil (fire-fighting, nuclear waste handling, law-enforcement, deep ocean exploration and drilling, weather forecasting, transportation) and military (guided missiles, spacecraft, unmanned drones) applications. Automation, when coupled with information technology, will continue to permeate our society at ever increasing levels. Autonomous systems, which, thus far, have been a crucial component in homeland security applications (e.g., border patrol, persistent monitoring, etc), are now seen as a key factor of empowering people in their daily lives across work, leisure, and domestic tasks. The next generation of autonomous systems will operate and interact with humans in the household or the office. The recent investment of information technology companies such as Amazon and Google in robotics technology is likely to accelerate the adoption of these new technologies by the general public. The safe and reliable operation of all these autonomous systems hinges crucially on their ability to reason and navigate about their environment.  The theory and methodologies developed in this research will make it possible to run highly sophisticated algorithms inside the ""brain"" of these autonomous systems to enable optimal decision-making, thus increasing their reliability, predictability, performance and fail-safe operation. Self-driving vehicles, anthropomorphic robots, aerial drones, manufacturing automation systems, and precision surgical instruments among others, will all benefit from the results of this research.<br/><br/><br/>The proposed research tackles a fundamental problem in the area of motion planning and trajectory generation for robotic and intelligent autonomous systems. A serious bottleneck in solving such problems under limited resource constraints (e.g., computer memory, time) is their high dimensionality that precludes the nave use of discretizing the (continuous) state space. In this research it is proposed to develop new incremental, optimal sampling-based motion planning algorithms with improved convergence rates over existing methods, so as to enable close-to-real-time trajectory generation for autonomous vehicles operating in an uncertain and dynamically changing environment. To achieve this objective, this research will build on recent results and ideas from Rapidly-exploring Random Graphs (RRG), along with relaxation methods borrowed from the areas of Asynchronous Dynamic Programming (ADP) and Machine Learning (ML). Specifically, recent advances from machine learning can be used to address the three main issues hindering the broader applicability of probabilistic sampling based motion planners to a wider variety of problems: collision checking, efficient sampling, and local steering. One main tenet of the proposed research is the exploitation of the inherent parallelism of the proposed algorithms, which -- coupled with the recent advances in multi-core computer architectures and GPUs -- will enable real-time computations."
"1617791","SHF: Small: DNA Circuits for Analog Computations","CCF","SOFTWARE & HARDWARE FOUNDATION","07/01/2016","06/30/2016","John Reif","NC","Duke University","Standard Grant","Mitra Basu","06/30/2019","$308,001.00","","reif@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7798","7923, 7946, 9251","$0.00","Analog devices have potential advantages over Boolean circuits, particularly for performing numerical computations, and analog circuits are often much more compact and require less resources. These advances are enhanced at molecular scales, where resources are scarce and compact designs are crucial. PI proposes extension of DNA computation from Boolean to analog computation. The analog DNA circuits can be used to control a wide variety of molecular devices. The central goals of this project are (i) to develop (design, simulate, and experimentally test) two architectures for analog DNA circuits, (ii) develop DNA-based methods for digital-to-analog and analog-to-digital conversions to allow hybrid analog-digital DNA circuits, and (iii) to provide demonstrations of applications of analog DNA circuits.<br/><br/>The work will involve students at all levels: the graduates students, undergraduates, and high school students. Females and minority students will especially be recruited. Students working on this project will receive training at Duke Univ. in computer science, chemistry, and DNA-based nanoscience. In addition, there are also opportunities for summer internships for undergraduates and high school students. Analog DNA circuits have many important potential applications such as analog control devices, where real values are sensed and analog computations provide controlling output. Prior devices for control of chemical reactions systems that provide for molecular species sensing and response have been limited to finite-state control; analog DNA circuits will allow much more sophisticated analog processing and control. DNA-based molecular robotics have allowed devices to operate autonomously (e.g., to walk on a nanostructure) but have been limited to finite-state control, and analog DNA circuits will allow molecular robotics to include real-time analog control circuits to provide much more sophisticated control, e.g. for control articulated joints of a molecular robot?s limb. Many systems that dynamically learn (e.g., neural networks and probabilistic inference) require analog computation, and analog DNA circuits can be used for back-propagation computation of neural nets and Bayesian inference computation of probabilistic inference systems.<br/><br/>The project introduces two architectures for molecular-scale analog computation. In both, the input and outputs of analog gates are directly encoded by relative concentrations of input and output strands respectively, without requiring thresholds for converting to Boolean signals. The 1st architecture has 3 gates: addition, subtraction, and multiplication. Analog circuits constructed from these gates can compute polynomials as well as approximate inverse, and division. The 2nd proposed architecture provides a novel DNA-based method to compute analytic functions such as sqrt(x), ln(x), and exp(x) using multiple DNA-based autocatalytic reaction systems working together. The project also introduces DNA analog-to-digital (A/D) and digital-to-analog (D/A) converters that enable the communication between analog and digital DNA circuits. The project includes full-scale designs, simulations, and experimental demonstrations of the two architectures, demonstrations of hybrid analog-digital DNA circuits, and a small-scale demonstration of an application of analog DNA circuits for control of a chemical reaction system: sensing input concentrations of molecules and controlling output of concentrations of molecules."
"1762560","Design and Investigation of Electrospun Artificial Muscle Fibers","CMMI","Materials Eng. & Processing","04/01/2018","03/01/2018","Shengqiang Cai","CA","University of California-San Diego","Standard Grant","Thomas F. Kuech","03/31/2021","$438,174.00","Renkun Chen","s3cai@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","ENG","8092","1773, 8021, 9146","$0.00","This grant will support the research that will create new knowledge relevant to soft robotics and active structures that are widely used in biomedical, manufacturing and energy sectors and will serve to advance our national health and prosperity. The grant allows the design and investigation of artificial muscle fibers fabricated from electrospinning technique. Artificial muscle materials can generate an active deformation and force when subjected to external stimuli, behaving like real muscle.  Previously developed artificial muscle materials have often suffered from poor scalability and slow response, which greatly limit their applications. Consequently, performance of artificial muscle has been increasingly recognized as one of the bottlenecks in designing novel soft robots and active structures. The artificial muscle material in this grant will have superior mechanical properties, a faster response rate, diverse actuating modes and excellent scalability. These new materials will contribute to the rapidly developing fields of soft robotics, novel actuators and energy conversion systems. The project will also provide interdisciplinary education and training opportunities to graduate and undergraduate students and seeks to attract underrepresented groups into science and engineering. Short disseminated demonstrations of artificial muscles to be developed will serve as an attractive education and research platform for disadvantaged, first generation high school and college students.<br/><br/>The artificial muscle assembled from electrospun polymer fibers can be easily fabricated into different shapes with various actuating modes, scaled up and down to various sizes, made to respond to different stimuli. A comprehensive understanding of processing-structure-property relationship for the electrospun polymer fibers is essential for the rational design of the artificial muscle fibers. The research team will electrospin three different types of polymer fibers: semicrystalline polyamide, polyelectrolyte and liquid crystal polymer, conduct systematic chemo-thermo-mechanical characterizations of these individual fibers using novel electrospinning tools, and design artificial muscle with diverse actuating modes by assembling these polymer fibers into different patterns.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1659833","REU Site:  Summer Undergraduate Program in Engineering Research at Berkeley (SUPERB):  Collecting and Using Big Data for the Public Good","CCF","RSCH EXPER FOR UNDERGRAD SITES","02/01/2017","01/17/2017","James Demmel","CA","University of California-Berkeley","Standard Grant","Rahul Shah","01/31/2020","$259,200.00","","demmel@cs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","1139","9250","$0.00","It is evident to all of us that the widespread and growing availability of vast amounts of real-time data presents both a tremendous opportunity to improve our understanding of the world and make better automated decisions, as well as a great technical challenge to collect, communicate and process this data efficiently and reliably. Leading researchers in Electrical Engineering and Computer Science will mentor undergraduate students on their proposed REU projects. Potential impacts range from more efficient sensor networks, to improved wireless access to the data they produce, to better human robot interaction, to better analysis of medical data from microscopes, and even helping prevent nuclear war. The project seeks to address a multitude of societal problems that can be examined by collecting and using big data while inspiring students to dedicate themselves to this work. The project is committed to exposing a diverse group of undergraduate researchers that will expand the impact of this project and the engineering research pipeline. At the conclusion of the program, participants will be proficient in using big data to solve societal problems that have direct impacts on their communities. <br/><br/>The goal of the Summer Undergraduate Engineering Research project in the Electrical Engineering and Computer Sciences Department is to prepare and motivate a group of diverse competitive candidates for graduate student.  The focus of the REU site is electrical engineering and computer science to support collecting and using big date for the public good.  Students spend nine weeks during the summer working on high caliber research projects addressing technical challenges arising in collecting, communicating and processing the vast amounts of data becoming available both efficiently and reliably. This project covers the entire range of challenges and opportunities, from better sensor networks to collect this data more efficiently; to improved wireless resource management to move the data; to machine learning techniques for processing the images, including from microscopes, that make up much of the new data; to designing robots that can learn to interact better with humans based on the data they collect; to better enforcement of the Comprehensive Nuclear Test Ban Treaty by analyzing seismic data used to detect underground nuclear tests. The project will have research contributions in areas such as communications and networking, human computer interaction, machine learning, robotics, scientific computing and visualization."
"1330789","BSF:2012166:A Framework for Composite Techniques in Motion Planning","CCF","SPECIAL PROJECTS - CCF","10/01/2013","09/11/2013","Kostas Bekris","NJ","Rutgers University New Brunswick","Standard Grant","Nina Amla","09/30/2018","$40,000.00","","kostas.bekris@cs.rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","2878","7798","$0.00","This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program. Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers. This project aims to design a framework for the integration of advanced foundational methods from computational geometry with effective sampling-based methods from motion planning. This will allow the practical use of these techniques in important applications and the development of useful educational experiences.  Motion planning, in its basic form, corresponds to the problem of finding a collision-free path for a robot in a workspace cluttered with static obstacles. It is important for many application domains, such as manufacturing and warehouse management, product assembly,  surgical planning, architectural design, graphical animation, computer games, and computational biology. The collaboration of the US and Israeli researchers will impact the application areas through the development of novel efficient tools based on sound theory for motion planning of complex systems. Furthermore, the availability of these tools can have an impact in educational efforts in the areas of algorithms, computational geometry and robotics.<br/><br/>Towards achieving these objectives, the investigators will implement and evaluate composite methods for motion planning, that lie at the intersection of computational geometry and sampling-based planning. In particular, the investigators will utilize foundational methods to compute compact motion planning representations that provide optimality guarantees, based in part on recent advances in summary of big data in other fields.  The collaboration can also lead to advances in the area of multi-robot motion planning, by taking advantage of recent progress in combinatorial solvers and transferring these results in the continuous motion planning domain. Overall, the integrated framework will allow advances in geometry-based algorithms to be readily available to the motion planning community, especially in sampling entire low-dimensional manifolds of the configuration space instead of individual configurations, collision detection and space decomposition."
"1632341","SBIR Phase II:  Intuitive Touch Feedback via Ungrounded Tactile Shear Feedback for Virtual Reality and Human-Machine Interfaces","IIP","SMALL BUSINESS PHASE II","08/15/2016","09/05/2018","William Provancher","CA","Tactical Haptics","Standard Grant","Muralidharan S. Nair","01/31/2021","$1,409,168.00","","AOR@tacticalhaptics.com","2819 Whipple Rd","Union City","CA","945871233","5105161494","ENG","5373","165E, 169E, 5373, 6840, 8035, 8240, 9139, 9150, HPCC","$0.00","The broader impact/commercial potential of this project is its potential to revolutionize human-machine interfaces, with possible applications in computer-aided design (CAD); military, maintenance, and pilot training interfaces; industrial and construction operator interfaces; robotic and laparoscopic surgery; physical therapy, rehabilitation, and swing training; education; telerobotics; automotive navigation and safety systems; and video games. While haptic interactions in these applications can already be portrayed with desktop robotic force feedback devices, the developed haptic technology could provide realistic haptic feedback at a much lower price point (required for consumer devices) and unlike current force feedback devices, the developed haptic devices can be used to naturally interact in large workspace applications like motion-input video games or VR experiences. The proposed research will enhance the scientific understanding of human-haptic and multi-modal interactions in virtual environments, and will create a model for this technology to migrate into adjacent fields.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project seeks to meet the market demand for intuitive, immersive, and inexpensive haptic technologies in the emerging field of consumer virtual reality (VR). Multiple companies are now making inexpensive 3D head-mounted displays (HMDs) for VR, but current haptic interfaces are either too expensive, have limited range of motion, or are too crude to portray realistic haptic interactions in VR. The company has created an ungrounded haptic motion controller that utilizes a new form of touch feedback that applies in-hand shear forces to create compelling physical feedback at a price that is viable for consumer markets. The proposed research objectives are based on feedback from key stakeholders and VR enthusiasts who have tried the company?s current high-end haptic controllers. Their feedback suggests improving the overall user experience of the controllers through reducing device size, mass, and system latency, while improving device ergonomics and reducing cost. The Phase II research builds on the findings of Phase I, which showed that even simpler implementations of the newly developed haptic technology were still found to be more compelling than traditional vibration feedback. The project will result in a reference design that can be mass produced."
"1446765","CPS: Synergy: Autonomous Vision-based Construction Progress Monitoring and Activity Analysis for Building and Infrastructure Projects","CMMI","CYBER-PHYSICAL SYSTEMS (CPS)","01/01/2015","08/06/2014","Mani Golparvar-Fard","IL","University of Illinois at Urbana-Champaign","Standard Grant","Bruce M. Kramer","12/31/2018","$999,935.00","Derek Hoiem, Timothy Bretl","mgolpar@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","7918","029E, 071E, 078E, 079E, 6840, 7397, 8235","$0.00","This Cyber-Physical Systems (CPS)  award supports research to enable the automated monitoring of building and infrastructure construction projects. The purpose of construction monitoring is to provide developers, contractors, subcontractors, and tradesmen with the information they need to easily and quickly make project control decisions. These decisions have a direct impact on the overall efficiency of a construction project. Given that construction is a $800 billion industry, gains in efficiency could lead to enormous cost savings, benefiting both the U.S. economy and society. In particular, both construction cost and delivery time could be significantly reduced by automated tools to assess progress towards completion (progress monitoring) and how construction resources are being utilized (activity monitoring). These tools will be provided by advances in the disciplines of computer vision, robotics, and construction management. The interdisciplinary nature of this project will create synergy among these disciplines and will positively influence engineering education. Partnerships with industry will also ensure that these advances have a positive impact on construction practice.<br/><br/>The process of construction monitoring involves data collection, analysis, and reporting. Research will address the existing scientific challenges to automating these three activities. Data collection will be automated by recording video with aerial robots and a network of cameras. Key research objectives are to derive planning algorithms that guarantee complete coverage of a construction site and to derive vision-based control algorithms that enable robust placement and retrieval of cameras. Analysis will be automated with a digital building information model with respect to which construction resources can be tracked. Key research objectives are to improve the efficiency and reliability of image-based reconstruction, to recognize material properties as well as geometry, to establish a formal language for representing construction activities, and to extend a parts-based approach for automated activity recognition. Reporting will be automated with a ubiquitous display of the digital building information model. Key research objectives are to formalize a constraint construction ontology with associated classification mechanisms and allow for systematic earned value analysis of construction progress. Experimental validation will focus on monitoring construction of substructure and superstructure skeletal elements in buildings and infrastructure systems as well as the associated earth-moving, concrete placement, and steel erection activities that are common in construction projects."
"1738888","STTR Phase II:  Dynamic Robust Hand Model for Gesture Intent Recognition","IIP","STTR PHASE II","09/01/2017","03/16/2018","Raja Jasti","CA","ZeroUI Inc","Standard Grant","Muralidharan S. Nair","02/29/2020","$899,999.00","Karthik Ramani","raja@zeroui.com","10570 Whitney Way","Cupertino","CA","950144442","4088630555","ENG","1591","1591, 169E, 4080, 6840, 8035","$0.00","The broader impact/commercial potential of this project stems from addressing the<br/>important hand gesture based input challenges of VR/AR (expected to grow to $150B by<br/>2020), Robotics and IoT ($135B by 2019 and $1.7T by 2020 respectively). This technology,<br/>if successful in mitigating the high technical risks, represents a huge leap in the state of the<br/>art in 3D hand models for gesture recognition and has the potential to be the industry<br/>standard for AR, VR, Robotics and IoT applications with broad societal impact in education,<br/>medical and healthcare. Its broader impact is further amplified by the potential in serving the<br/>needs of the disabled community in improving their quality of life by being better able to<br/>communicate, learn and adapt to their interaction needs.<br/><br/>This Small Business Technology Transfer (STTR) Phase 2 project aims to significantly<br/>advance current 3D hand gesture recognition technology by developing a dynamic hand<br/>tracking model for gesture intent recognition. It is robust against occlusion and tolerant to<br/>variations in camera orientation and position. This research will result in a transformative<br/>leap above the current state of academic and commercial hand models and overcome key<br/>technical hurdles that have so far proven difficult to overcome. It solves the following key<br/>challenges and involves very high technical risks: 1) robust hand tracking while holding<br/>objects and 2) robust tangible interactions using objects without using any fiducial markers<br/>2) low profile hand wearable for touch interaction detection. This Phase 2 project will<br/>achieve these objectives by 1) data acquisition and hand-object pose estimation, 2)<br/>understanding user intents with enhanced tangible interactions, and 3) system validation<br/>and user testing."
"1339666","NRI-Small: A Novel Light-weight Cable-driven Active Leg Exoskeleton (C-ALEX) for Training of Human Gait","IIS","SPECIAL STUDIES AND ANALYSES, CONTROL SYSTEMS, ROBUST INTELLIGENCE","01/01/2013","09/13/2017","Sunil Agrawal","NY","Columbia University","Continuing grant","Reid Simmons","09/30/2018","$659,000.00","","Sunil.Agrawal@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","1385, 1632, 7495","7923, 8086","$0.00","Motorized exoskeletal orthoses are being actively researched today for gait training of stroke patients. These machines are typically designed to apply assistive/resistive forces on the impaired leg to help human subjects to improve walking, similar to what therapists do during training. While a number of such machines have been developed and used for gait training, these studies have only yielded ""mixed"" results in benefiting stroke patients clinically. The reasons for these disappointing results are the high inertia of the mechanisms, a mis-match in constraints between human and machine, and misalignment of the mechanism joints with the human joints. The proposed work investigates a novel and ground-breaking design of a cable driven exoskeleton to address these shortcomings. Based on extensive study of mechanisms and therapeutic control methods, cables will actuate the moving limbs and will also serve as structural members in tension. The design will consist of an inertial fixed cuff attached to the pelvis and three lightweight cuffs on the thigh, shank, and foot of each leg. This results in an order-of-magnitude reduction in the inertia of the links and eliminates rigid joints which, in turn, eliminates the mis-match and misalignment. Yet, the fact that cables can only pull and not push raises many scientific and design challenges that will be addressed theoretically and experimentally.<br/><br/>Broader Impact: Each year, about 700,000 people in the U.S. have an incidence of a stroke and currently there are 4.5 million people in the U.S. living with the after-effects of stroke. This research can directly impact the quality of life of these individuals with potentially better rehabilitative equipment and better rehabilitative results for retraining of their gait. This project will broaden the application of cable-driven robots to the emerging field of ""neuro-rehabilitation"" and ""functional learning."" This project will also involve close co-operation with Professor Clement Gosselin's research group at Laval University, who along with the PI, is credited with fundamental developments to the field of ""cable robots."" The project will also encourage undergraduate involvement in research as well as provide training and examples for a high school teacher/student to incorporate into the local curriculum. The PI has active links with high schools through a college-wide NSF-funded RET program. Several high school teachers and students have worked in the PI's laboratory to identify technologies to improve quality of life of neural impaired subjects."
"1638099","NRI: Enabling Unmanned Aerial Systems (UAS) Fire Ignitions in Complex Firefighting Contexts","IIS","National Robotics Initiative","08/01/2016","07/17/2018","Carrick Detweiler","NE","University of Nebraska-Lincoln","Standard Grant","Reid Simmons","07/31/2019","$1,003,270.00","Carrick Detweiler, Dirac Twidwell, Justin Bradley, Brittany Duncan","carrick@cse.unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","CSE","8013","8086, 9150, 9251","$0.00","Prescribed fire is critical for reducing catastrophic wildfires and sustaining healthy ecosystems. Yet the technology to support fire ignition and monitoring remains stagnant, risky, and expensive. This project aims to develop the Unmanned Aerial System (UAS) technology that can transform prescribed fire ignition and monitoring by: 1) enabling the communication between UASs and humans by sharing the vehicle intention through maneuvers, 2) improving UAS operation by taking into account operator availability, 3) leveraging the operator's knowledge to improve control of multiple vehicles, 4) fixing failures by enabling the operator and the system to work together, and 5) assessing the technological capabilities and associated users' acceptance of this technology. This effort is significant because it addresses unique co-robotic challenges in the UAS domain and is transformative in its potential to change how a range of organizations maintain their ecosystems and manage wildfires.<br/><br/>The project aims at developing and assessing techniques, tools, and systems to dramatically improve the potential for UASs to safely ignite and monitor fire.  To achieve that goal, it conducts multidisciplinary work on: 1) motion-based languages that communicate UAS intention and knowledge to operators and bystanders, 2) co-regulation methodologies that incorporate operator availability and attention into traditional control and planning loops, 3) integrative functions that map the environmental knowledge and domain expertise of an operator into a fleet of vehicles to support different levels of autonomy, 4) co-debugging techniques from program analysis that collaborate with the operator to help diagnose and overcome failures caused by misconfigurations, and 5) cross-cutting studies to gain a better understanding of the attitudes of stakeholders towards UASs, and the features that are likely to promote stakeholder trust and acceptance."
"1538658","Nonlinear Fracture Mechanics of Hydrogel-Like Soft Materials","CMMI","Mechanics of Materials and Str","08/01/2015","07/06/2015","Rui Huang","TX","University of Texas at Austin","Standard Grant","Siddiq Qidwai","07/31/2019","$442,000.00","Krishnaswamy Ravi-Chandar, Chad Landis","ruihuang@mail.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","ENG","1630","022E, 024E, 9161, AMPP","$0.00","Hydrogel-like soft materials are abundant in nature including soft tissues such as cartilage, tendons and ligaments. With similar mechanical properties and biocompatibility, synthetic polymer-based hydrogels have been used extensively for a wide range of biomedical applications such as artificial tissues and drug delivery. More recently, hydrogel-like materials have been explored as a class of soft active materials in the development of soft machines and soft robotics. For many of these applications, mechanical properties of the hydrogel-like soft materials are important, governing how they deform and fail under various conditions. In particular, fracture of hydrogel-like soft materials has not been well understood, and it remains a challenge to predict if and when such materials would fracture. This project aims to establish a knowledge base necessary for failure analysis and prediction of hydrogel-like soft materials. The results will enable engineering of such materials with reliable fracture properties for a range of applications including tissue engineering and soft robotics. The three PIs, jointly with expertise in fracture mechanics/dynamics, soft materials, experiments, modeling and simulations, will collaborate to bring different perspectives onto this project. Education and outreach activities will be integrated within the project to enhance its broader societal impacts, which include research experience for undergraduates, engaging minorities and underrepresented groups, and outreach to high school students and general public.<br/><br/>The fracture processes of hydrogel-like soft materials are highly nonlinear in general, coupling large deformation with particular kinetic processes due to solvent diffusion and polymer viscoelasticity. This project is to establish a nonlinear, transient theoretical framework that defines the fracture driving force and a fracture criterion for crack growth in hydrogel-like soft materials, with explicit recognition of the associated kinetic processes. The theoretical framework will enable implementation of numerical simulations that would predict particular fracture behaviors relevant to hydrogel-like materials such as delayed fracture and rate dependence. The results will be compared to experimental measurements for validation. The developed methodology with modeling and experiments will then be used for measuring fracture properties of hydrogel-like soft materials. The distinct effects of solvent diffusion and viscoelasticity on fracture will be elucidated through numerical simulations and a set of experiments from quasistatic to dynamic regimes."
"1637875","NRI: Collaborative Research: Autonomous Quadrotors for 3D Modeling and Inspection of Outdoor Infrastructure","IIS","National Robotics Initiative","09/01/2016","08/18/2016","Stergios Roumeliotis","MN","University of Minnesota-Twin Cities","Standard Grant","Jie Yang","08/31/2019","$830,280.00","Peter Seiler","stergios@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","8013","8086","$0.00","This project develops technologies to collect visual and inertial data necessary for constructing, offline, high-accuracy 3D maps of the structure for civil and industrial infrastructure such as bridges, power plants, and refineries.  It also develops technologies for online processing including localization, path planning and obstacle avoidance. The project builds a system that employs quadrotors to assist their human co-workers in visual inspections of the outdoor infrastructure to enhance efficiency and effectiveness of such operations.  The research advances the current state of the art in key areas of sensing, estimation, and control necessary for enabling small-size quadrotors to assist humans in visual inspections. In addition to improving the reliability of the nation's infrastructure, the project benefits researchers, developers, educators, and end-users in robotics by developing open-source, modular algorithms for quadrotors. The project offers educational and community outreach activities aligned with local efforts and state-wide initiatives, and seeks to increase diversity and attract underrepresented groups to Science, Technology, Engineering, and Mathematics (STEM) via a partnership with local high schools. <br/><br/>This research addresses the fundamental challenges stemming from sensing and processing limitations that prevent the use of low-cost, small-size quadrotors in visual-inspection tasks. It focuses on a four-step process, where initially a quadrotor is tele-operated at a safe distance from the structure of interest to collect visual and inertial data necessary for constructing, offline, high-accuracy 3D maps of the structure. These maps are then used, by the inspection engineer, to designate areas of interest. Lastly, the quadrotor employs its onboard sensors to precisely localize with respect to the structure and navigate along the inspection route, while collecting additional data for increasing the accuracy and improving the reliability of future inspections. A key innovation is making information available in multiple forms and levels of abstraction so as to meet the often-conflicting needs of offline (e.g., visualization of inspection areas and planning information-rich paths) and online (e.g., map-based localization and obstacle avoidance) uses. Also critical is an information-driven approach for making maximum use of the limited sensing and processing resources available to the quadrotor. Lastly, a key advantage of the proposed approach is that it provides the foundation for continual improvement in accuracy and efficiency after each inspection flight."
"1637761","NRI: Collaborative Research: Autonomous Quadrotors for 3D Modeling and Inspection of Outdoor Infrastructure","IIS","National Robotics Initiative","09/01/2016","08/18/2016","Philippos Mordohai","NJ","Stevens Institute of Technology","Standard Grant","Jie Yang","08/31/2019","$290,734.00","","Philippos.Mordohai@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","CSE","8013","8086","$0.00","This project develops technologies to collect visual and inertial data necessary for constructing, offline, high-accuracy 3D maps of the structure for civil and industrial infrastructure such as bridges, power plants, and refineries.  It also develops technologies for online processing including localization, path planning and obstacle avoidance. The project builds a system that employs quadrotors to assist their human co-workers in visual inspections of the outdoor infrastructure to enhance efficiency and effectiveness of such operations.  The research advances the current state of the art in key areas of sensing, estimation, and control necessary for enabling small-size quadrotors to assist humans in visual inspections. In addition to improving the reliability of the nation's infrastructure, the project benefits researchers, developers, educators, and end-users in robotics by developing open-source, modular algorithms for quadrotors. The project offers educational and community outreach activities aligned with local efforts and state-wide initiatives, and seeks to increase diversity and attract underrepresented groups to Science, Technology, Engineering, and Mathematics (STEM) via a partnership with local high schools. <br/><br/>This research addresses the fundamental challenges stemming from sensing and processing limitations that prevent the use of low-cost, small-size quadrotors in visual-inspection tasks. It focuses on a four-step process, where initially a quadrotor is tele-operated at a safe distance from the structure of interest to collect visual and inertial data necessary for constructing, offline, high-accuracy 3D maps of the structure. These maps are then used, by the inspection engineer, to designate areas of interest. Lastly, the quadrotor employs its onboard sensors to precisely localize with respect to the structure and navigate along the inspection route, while collecting additional data for increasing the accuracy and improving the reliability of future inspections. A key innovation is making information available in multiple forms and levels of abstraction so as to meet the often-conflicting needs of offline (e.g., visualization of inspection areas and planning information-rich paths) and online (e.g., map-based localization and obstacle avoidance) uses. Also critical is an information-driven approach for making maximum use of the limited sensing and processing resources available to the quadrotor. Lastly, a key advantage of the proposed approach is that it provides the foundation for continual improvement in accuracy and efficiency after each inspection flight."
"1828678","MRI: Development of an Underwater Mobile Testbed Using a Software-Defined Networking Architecture","CNS","MAJOR RESEARCH INSTRUMENTATION, EPSCoR Co-Funding","10/01/2018","09/07/2018","Aijun Song","AL","University of Alabama Tuscaloosa","Standard Grant","Rita V. Rodriguez","09/30/2021","$300,000.00","Yang-Ki Hong, Fei Hu, Fumin Zhang","song@eng.ua.edu","801 University Blvd.","Tuscaloosa","AL","354870005","2053485152","CSE","1189, 9150","1189, 9150","$0.00","This project, developing one of the first Software Defined Network (SDN)-based underwater mobile testbeds to support the operation of marine robot fleets, aims to address a technological bottleneck, that of achieving integrated communications and navigation underwater. A fleet of Autonomous Surface Vehicles (ASV)s are directed to follow sampling Autonomous Underwater Vehicles (AUVs) to provide acoustic and Magnetic Induction (MI) communication over relatively short ranges. Launching the following effort thrusts: Acoustic & MI Communication; Control of ASVs & UAVs; SDN architecture; and Integration and evaluation.<br/><br/>The testbed will be designed to achieve cost-effectiveness, transferability, flexibility, and scalability and is expected to become a stable instrument that is accessible by multiple research communities that include ocean acoustics, communication and networking, robotics, oceanography and environmental sciences. The hybrid acoustic/MI communication will be used to achieve reliability and high data rates across the mobile network for ASVs and AUVs, while smooth autonomy of the fleet would be ensured by cooperative localization and real-time data transfer among the ASV-AUV pairs. The testbed is expected to enable various research directions, including underwater swarming, deep-learning-based underwater joint networking and navigation, and integrated oil spill responses.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1634286","Collaborative Research: Persistent Presence in the Ocean Interior: Developing a Low-power, Autonomous System for Geo-referenced Navigation","OCE","OCEAN TECH & INTERDISC COORDIN","01/01/2017","09/06/2018","Sarah Webster","WA","University of Washington","Continuing grant","Kandace S. Binkley","12/31/2019","$190,452.00","","swebster@apl.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","GEO","1680","","$0.00","Facilitating an accurately navigated persistent presence for the interior of the deep ocean has the potential to transform how oceanography is conducted.  This capability is currently not provided by existing technologies; however, if developed would transform the scope of projects undertaken by underwater vehicles with longer range and endurance than can currently be deployed unsupported from research ships.  This research develops a new low power navigation system that improves navigational accuracy from 1000s of meters to 100s meters.  This advance will enable multiple new lines of oceanographic investigation.  Examples include deployment of coordinated glider fleets to investigate complex physical-biogeochemical interactions; deep studies of topographically induced mixing; long-range characterization of seafloor habitats/ecosystems at the scale of entire ocean basins; and better resolution of the scales of bottom-boundary-layer processes in regions with steep underwater terrain.   The researchers will engage in outreach activities including undergraduate participation in our research and continuation of established collaborations with local high school robotics and environmental science classes. <br/><br/>This research develops and tests a low-power acoustic positioning system that enables accurate externally aided navigation in the deep ocean.  A glider (or fleet of gliders) operates at depth while an autonomous surface robot (ASV) follows on the sea surface. The ASV transmits its geo-reference position to the gliders at a regular interval. Each glider  then independently employs a precision time base (provided by chip-scale atomic clocks) and array processing to determine its position relative to the ASV. Each ASV combines this relative position estimate with the ASV's position encoded in the received packet to compute its geo-referenced position. System performance depends on a number of factors including the precision of vehicle attitude sensors. Accuracies of 250-400m are possible at 5000m depth using low-power sensors already in use on the glider. Hence, for deep-diving gliders, this method will provide a 10-100 fold improvement in positioning accuracy over the current paradigm (i.e., infrequent GPS fixes) and would allow vehicles to spend more time at depth making relevant observations. This research will enable new operating paradigms, advance observational capabilities and facilitate spatially denser observations than were previously possible. Furthermore, the new system will also improve the ability to estimate depth-averaged ocean currents. The developed capability is also a prerequisite for coordinated motion control of multiple deep-diving AUGs, further increasing the density and cadence of deep ocean observations, providing an ever closer-to-synoptic view of the deep ocean interior.  The developed system will be tested first in the tank and then in two ocean cruises including a Year 3 deployment on a Seaglider."
"1840834","EAGER: Developing and Bio-Inspired Assembly of Highly Scalable Electromagnetic Soft Actuators for Active Elbow Brace","CBET","Disability & Rehab Engineering","08/01/2018","07/24/2018","Amir Jafari","TX","University of Texas at San Antonio","Standard Grant","Aleksandr Simonian","07/31/2020","$189,918.00","Wei Gao","Amir.Jafari@utsa.edu","One UTSA Circle","San Antonio","TX","782491644","2104584340","ENG","5342","7916","$0.00","Neurologically impaired people such as stroke patients often need assistance in moving their joints. However, current wearable rehabilitation and assistive devices are either 1) powerful and active but bulky and made of rigid elements such as exoskeletons and artificial limbs, or 2) flexible but passive with limited functionality such as joint braces.  In spite of recent advances in soft robotics, there is still no soft actuator (motion-generating device) that is portable, i.e. can be operated by on-board power sources, scalable to be adapted to different joint sizes and still have the short response time and high output force-to-size ratio needed to assist joint motions.  To address this need, the goal of this project is to design, fabricate and evaluate a novel Electromagnetic Soft Actuator (ESA) that can be easily powered by on-board batteries and can produce linear force and contraction in a manner that mimics the behavior of the contractile filaments (Actin and Myosin) inside a sarcomere (the basic human muscle actuation unit).  The ESA is highly scalable and can be miniaturized to create an artificial sarcomere when assembled in parallel and in series. A series of artificial sarcomeres will create an ExoFiber. As the primary activation unit, each artificial sarcomere will be electrically excited separately. The ExoFibers straps will then be embedded into joint braces to make them active.  Being activated based on the principle of electromagnetism, the ExoFibers can be quickly energized to generate force and motion.  The performance of an ExoFibers-actived brace for the human elbow joint will be evaluated in a small-scale pilot study in humans with and without elbow disabilities. Findings will advance the next generation of flexible, powerful and portable active braces through scalable soft actuators for joint motion assistance and rehabilitation applications and will lay the foundations for interdisciplinary research on the design and analysis of soft actuator networks with dynamic system and materials design and rehabilitation therapy.  Education and outreach impact will be achieved through the development of a new graduate level class in Soft Rehabilitation Robotics and working with the UTSA Center for Excellence in Engineering Education (CE3) and iTEC to involve students from underrepresented groups from San Antonio in the project.<br/><br/>This exploratory project investigates the possibility of fabricating an Electromagnetic Soft Actuator (ESA) that can be powered by on-board batteries, can produce linear force and contraction in a manner that mimics the behavior of the contractile actin and myosin filaments inside a sarcomere and can be miniaturized to create an artificial sarcomere when assembled in a bioinspired parallel and series pattern.  The artificial sarcomeres can be networked into ExoFibers that can be embedded in a human elbow brace that can be used for rehabilitation or as an assistive device.  The Research Plan is organized under two aims.  AIM 1 is focused on design and fabrication.  The ESA design consists of two antagonistic solenoids with a spring linkage in between and an internal ferromagnetic core built with soft materials. By injecting electric current into micro-coils, two antagonistic electromagnetic fields will be induced, resulting in repulsive or attractive forces that stretch or compress the springy linkage.  The artificial sarcomere and ExoFibers designs will be assembled using ESAs that have been bioprinted to facilitate ease of production.  The number of ESAs assembled in parallel will determine the output source and the number of ESAs in series defines the overall contraction.  AIM 2 is focused on development and evaluation of dynamic properties of an active brace, i.e., brace embedded with an ExoFiber.  Experimental platforms will be set up to test performance at three levels: single ExoFiber, active brace, and human elbow. The output performance can be defined in terms of: 1) contraction length, output force, linear stiffness and bandwidth for ExoFiber, 2) flexion range, torque, angular stiffness and bandwidth for active brace, and 3) flexion range and comfort and ease of use with a human elbow.  The active brace level will be evaluated while the brace is placed on a bioprinted arm model.  The human elbow level will be evaluated by conducting a small-scale pilot study in two cohorts of adults: healthy individuals and subjects with elbow weakness, decreased range of motion, or stiffness due to stroke. Participants will be asked to perform three types of exercises: 1) to hold their arm at 5 different flexion-extension stationary angles while suddenly perturb by a 2Nm torque, 2) to flex and extend their arm while holding a 2Kg weight at two different speeds (slow and normal) and 3) to flex their arm while working against a constant torque of 2Nm.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1646641","CPS: Synergy: Securing the Timing of Cyber-Physical Systems","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2016","09/14/2016","Qi Zhu","CA","University of California-Riverside","Standard Grant","Ralph Wachter","10/31/2018","$750,000.00","Matthew Barth, Fabio Pasqualetti, Nael Abu-Ghazaleh, Zhiyun Qian","qzhu@northwestern.edu","Research & Economic Development","RIVERSIDE","CA","925210217","9518275535","CSE","7918","7918, 8235","$0.00","This project addresses timing attacks in cyber-physical systems, where attackers attempt to compromise the system functionality by changing the timing of computation and communication operations. Timing attacks could be particularly destructive for cyber-physical systems because the correctness of system functionality is affected not only by the data values of operations but also significantly by at what time operations are conducted. The discoveries and methodologies developed in this project will provide fundamental advances in addressing timing attacks, and lead to the design and implementation of more secure cyber-physical systems in a number of key sectors, including automotive and transportation systems, industrial automation, and robotics. In addition to disseminate the research results through publications and workshops, the PIs will collaborate with industry partners on transitioning the research findings into practice. The PIs will also integrate the research into the curriculum at UCR and leverage it for K-12 education through the use of Lego Mindstorm platforms.<br/><br/>The project will build a framework for identifying, analyzing and protecting cyber-physical systems against timing attacks. Building the framework consists of three closely-related research thrusts: 1) Investigate potential timing-based attack surface, and further analyze what types and patterns of timing variations the attacks may cause and how attackers may try to hide the traces of such attacks. 2) Based on the identified attack surface and strategies, analyze how timing changes caused by these attacks may affect the overall system properties, in particular safety, stability and performance. 3) Develop control-based and cyber-security defense strategies against timing attacks. This includes run-time security detectors and mitigation/adaptation strategies across control layer and embedded system layer, as well as design-time mechanisms to provide systems that are resilient to timing attacks. This project will focus on vehicle networks and multi-agent robotic systems as main application domains."
"1839511","CPS: Synergy: Securing the Timing of Cyber-Physical Systems","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","02/01/2018","09/04/2018","Qi Zhu","IL","Northwestern University","Standard Grant","Ralph Wachter","09/30/2019","$659,770.00","","qzhu@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7918","7918, 8235","$0.00","This project addresses timing attacks in cyber-physical systems, where attackers attempt to compromise the system functionality by changing the timing of computation and communication operations. Timing attacks could be particularly destructive for cyber-physical systems because the correctness of system functionality is affected not only by the data values of operations but also significantly by at what time operations are conducted. The discoveries and methodologies developed in this project will provide fundamental advances in addressing timing attacks, and lead to the design and implementation of more secure cyber-physical systems in a number of key sectors, including automotive and transportation systems, industrial automation, and robotics. In addition to disseminate the research results through publications and workshops, the PIs will collaborate with industry partners on transitioning the research findings into practice. The PIs will also integrate the research into the curriculum at UCR and leverage it for K-12 education through the use of Lego Mindstorm platforms.<br/><br/>The project will build a framework for identifying, analyzing and protecting cyber-physical systems against timing attacks. Building the framework consists of three closely-related research thrusts: 1) Investigate potential timing-based attack surface, and further analyze what types and patterns of timing variations the attacks may cause and how attackers may try to hide the traces of such attacks. 2) Based on the identified attack surface and strategies, analyze how timing changes caused by these attacks may affect the overall system properties, in particular safety, stability and performance. 3) Develop control-based and cyber-security defense strategies against timing attacks. This includes run-time security detectors and mitigation/adaptation strategies across control layer and embedded system layer, as well as design-time mechanisms to provide systems that are resilient to timing attacks. This project will focus on vehicle networks and multi-agent robotic systems as main application domains."
"1607854","Collaborative Research:   A biomimetic dynamic self-assembly system programmed using DNA nanostructures","DMR","BIOMATERIALS PROGRAM","09/01/2016","09/06/2016","Nils Walter","MI","University of Michigan Ann Arbor","Standard Grant","Mohan Srinivasarao","08/31/2019","$150,000.00","","nwalter@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","MPS","7623","7237, 7573, 8007, 8614","$0.00","Non-technical: These collaborative awards by the Biomaterials program in the Division of Materials Research to Arizona State University (lead) and University of Michigan Ann Arbor (non-lead) are to study DNA polymerization and depolymerization to biomimic the functions of microtubules in cells. This award is co-funded by the following programs: 1) BioMaPS program in the Division of Materials Research; and 2) Biotechnology and Biochemical Engineering program in the Division of Chemical and Bioengineering, Environmental, and Transport Systems (ENG). The award will study the dynamic self-assembly and disassembly observed in cellular microtubules, which are involved in a number of cell functions such as intracellular transport, cell division, gene expression, etc. With this award, the microtubule functions will be mimicked by designing the self-assembly seen in DNA system. Scientific broader impacts of this study will be in developing biocompatible motors, robotics, and other applications such as drug and gene delivery systems. As part of the broader impact activities, this project will provide interdisciplinary training opportunities to students at the interface between DNA nanotechnology and single molecule biophysics. In addition, this project aims to engage high school students through experiential learning, providing them with teaching tools, and developing a STEM volunteer network. Finally, the single-molecular probing will be performed in the NSF-funded Single Molecule Analysis in Real-Time (SMART) Center at the University of Michigan, which has a vigorous outreach program to the broader scientific community.<br/><br/>Technical: This project will build synthetic DNA-based assemblies that biomimic the salient features of dynamic self-assembly seen in cellular microtubules. Taking advantage of the DNA nanostructure programmability, this project aims to: investigate the kinetic determinants of interactions including cooperative binding, nucleation, and growth; mimic the treadmilling (active transport by self-assembly and disassembly) and dynamic instability of microtubules by employing driving forces intrinsic to Holliday junction isomerization with intermediate assembly stages that can be isolated and studied; and visualize and control of the treadmilling and dynamic instability of the DNA assembly line using comprehensive single-molecule characterization methods. Examination of this synthetic dynamic assembly system will lay the groundwork in the design and construction of sophisticated dynamic molecular assemblies based on DNA. Results from this project will provide a theoretical foundation for DNA-based motors, robotics, and other dynamic transport systems. These studies could in turn pave the way for assembling a DNA tile system that can directionally step on a programmed dynamic assembly line that mimics the motion of motor proteins (e.g., dynein or kinesin) seen in microtubules."
"1739452","CPS: TTP Option: Medium: Synthetic, Distributed Sensing, Soft and Modular Tissue (sTISSUE)","CNS","INFO INTEGRATION & INFORMATICS, CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2017","08/30/2017","Mark Rentschler","CO","University of Colorado at Boulder","Standard Grant","Sylvia J. Spengler","09/30/2021","$1,250,000.00","Nicolaus Correll, James Humbert, Christoph Keplinger","mark.rentschler@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","7364, 7918","7364, 7918, 7924","$0.00","The goal of this research is to gain a fundamental understanding of the integrated actuation, embedded sensing, reactive control, and distributed control needs of a cyber-physical, synthetic, distributed sensing, soft and modular tissue (sTISSUE). Realizing this cyber-physical, physiological testbed will enable surgically relevant tasks, procedures, and devices to be much more refined ahead of animal testing, which can be dramatically reduced with such high-fidelity simulators. Furthermore, such simulators could open an entirely new approach to medical resident training that could not only improve surgical performance skills, but also establish a new paradigm in patient-specific surgical practice before the actual procedure.  The proposed strategy will also harness the excitement surrounding autonomous systems, robotic control, and embedded sensing, and leverage it with the investigators' infrastructure for education innovation and outreach to provide new, inspirational educational experiences for students.<br/><br/>This research program will formulate the techniques required for a synthetic tissue to autonomously sense and react to external stimuli, thereby replicating smooth muscle's sense and actuation capability. In essence, an autonomous tissue will be created that simulates in vivo behavior, while maintaining scalability and modularity. The intellectual merit of this research lies in 1) addressing current shortcomings in embedded sensing and actuation that ensure modularity and distributed control, 2) modeling the dynamics of, and creating global and distributed control strategies that account for, the unconventional in vivo environment requirements, and 3) enabling a paradigm-altering platform that will allow technology developers to both quickly and reliably apply this sTISSUE to numerous applications. More broadly, this research will establish a crucial body of knowledge needed for the design of synthetic tissue materials that integrate sensing, actuation, computation, and control. While the proposed approach includes the goal to transition the fundamental research into a gastrointestinal simulator, numerous other applications in the field of medicine and co-robotics exist. Finally, the proposed research in modularity and scalability design can broadly impact a number of other areas that would benefit from the developed novel methodologies in integrated sensing, actuation, computation and control."
"1822092","Planning IUCRC at University of Nebraska-Lincoln:  Center for Engineering and Manufacturing Technologies Advancing Food Safety and Security (CAFSS)","IIP","INDUSTRY/UNIV COOP RES CENTERS","09/01/2018","08/28/2018","Theodore Lioutas","NE","University of Nebraska-Lincoln","Standard Grant","Andre Marshall","08/31/2019","$15,000.00","Jeyamkondan Subbiah","Theo.lioutas@unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","ENG","5761","5761","$0.00","The US food and beverage industry employs 1.46 million individuals and is responsible for more than 10% of all manufacturing shipments. Even though sanitation is one of the food industry's biggest production expenses, inadequate sanitation remains one of the greatest threats to America's food safety and security due to the lack of modern technology and consistent application of sanitation policies.<br/><br/>CAFSS will strive to integrate and streamline the entire food supply chain in the US from 'Farm to Fork' and supply safe (pathogen and allergen free), secure (uninterrupted and fully traceable sources), wholesome and plentiful supply of food to the US and Global consumers.<br/><br/>CAFSS objectives will focus on addressing two grand challenges of national importance:<br/><br/>1) Ensuring a stable and sustainable supply of affordable, safe, nutritious food not only for the US but also for the rest of the world.<br/>2) Equipping and empowering US food manufacturers and their supporting industries, to establish highly competitive manufacturing plants in the US and the world.<br/><br/>The US food industry adds commercial value to agricultural products and provides employment opportunities in both rural and urban areas and CAFSS will enhance the overall sustainability and profitability through automation and new private-public partnerships.<br/><br/>The proposed CAFSS will bridge technological gaps, which fall under the general theme of food safety, security and traceability of all raw materials throughout the entire supply chain from 'Farm to Fork'.  Bridging these gaps will require multidisciplinary collaborations among public and private enterprises and groundbreaking research and development within the following fundamental science and engineering platforms:<br/><br/>1) Automation, control and robotics; IoT systems and data integration; <br/>2) New sensors; big data analytics and artificial intelligence; <br/>3) New functionalized surfaces, new materials / coatings  <br/>4) Novel food sterilization technologies. <br/><br/>Automation, control, and robotics minimize human contact with food and greatly enhance food safety. Newer sensors with data analytics enable the food companies to improve food safety, quality, and traceability. Novel functionalized surfaces enhance food sanitation efficiency thereby reducing production downtime, and energy and water requirements.  Novel food sterilization and pasteurization technologies improve food safety with minimal deterioration in food quality and they meet consumers' demand for minimally processed foods.<br/><br/>Research projects will be carried out at CAFSS hub facilities in Nebraska and Georgia and the resulting breakthroughs will allow the US food manufacturing industry to join other industries in terms of efficiency, automation, lower cost, predictability, safety and security of goods supplied.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822117","Planning IUCRC at Georgia Institute of Technology:  Center for Engineering and Manufacturing Technologies Advancing Food Safety and Security (CAFSS)","IIP","INDUSTRY/UNIV COOP RES CENTERS","09/01/2018","08/28/2018","Douglas Britton","GA","Georgia Tech Applied Research Corporation","Standard Grant","Andre Marshall","08/31/2019","$15,000.00","","doug.britton@gtri.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","5761","5761","$0.00","The US food and beverage industry employs 1.46 million individuals and is responsible for more than 10% of all manufacturing shipments. Even though sanitation is one of the food industry's biggest production expenses, inadequate sanitation remains one of the greatest threats to America's food safety and security due to the lack of modern technology and consistent application of sanitation policies.<br/><br/>CAFSS will strive to integrate and streamline the entire food supply chain in the US from 'Farm to Fork' and supply safe (pathogen and allergen free), secure (uninterrupted and fully traceable sources), wholesome and plentiful supply of food to the US and Global consumers.<br/><br/>CAFSS objectives will focus on addressing two grand challenges of national importance:<br/><br/>1) Ensuring a stable and sustainable supply of affordable, safe, nutritious food not only for the US but also for the rest of the world.<br/>2) Equipping and empowering US food manufacturers and their supporting industries, to establish highly competitive manufacturing plants in the US and the world.<br/><br/>The US food industry adds commercial value to agricultural products and provides employment opportunities in both rural and urban areas and CAFSS will enhance the overall sustainability and profitability through automation and new private-public partnerships.<br/><br/>The proposed CAFSS will bridge technological gaps, which fall under the general theme of food safety, security and traceability of all raw materials throughout the entire supply chain from 'Farm to Fork'.  Bridging these gaps will require multidisciplinary collaborations among public and private enterprises and groundbreaking research and development within the following fundamental science and engineering platforms:<br/><br/>1) Automation, control and robotics; IoT systems and data integration; <br/>2) New sensors; big data analytics and artificial intelligence; <br/>3) New functionalized surfaces, new materials / coatings  <br/>4) Novel food sterilization technologies. <br/><br/>Automation, control, and robotics minimize human contact with food and greatly enhance food safety. Newer sensors with data analytics enable the food companies to improve food safety, quality, and traceability. Novel functionalized surfaces enhance food sanitation efficiency thereby reducing production downtime, and energy and water requirements.  Novel food sterilization and pasteurization technologies improve food safety with minimal deterioration in food quality and they meet consumers' demand for minimally processed foods.<br/><br/>Research projects will be carried out at CAFSS hub facilities in Nebraska and Georgia and the resulting breakthroughs will allow the US food manufacturing industry to join other industries in terms of efficiency, automation, lower cost, predictability, safety and security of goods supplied.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1827314","MRI: Acquisition of a GPU Accelerated Vermont Advanced Computing Core","OAC","MAJOR RESEARCH INSTRUMENTATION","09/01/2018","08/23/2018","Adrian Delmaestro","VT","University of Vermont & State Agricultural College","Standard Grant","Stefan Robila","08/31/2020","$893,120.00","Hugh Garavan, Yolanda Chen, Juan Vanegas, Joshua Bongard","Adrian.Delmaestro@uvm.edu","85 South Prospect Street","Burlington","VT","054050160","8026563660","CSE","1189","026Z, 062Z, 075Z, 1189, 8089, 8091, 9150","$0.00","This project will enable interdisciplinary science through the acquisition of a high-performance computer cluster, named DeepGreen.  Based on cutting-edge massively parallel graphics processing unit (GPU) technologies, DeepGreen will be utilized by the over 300 users from six Colleges at the University of Vermont, and throughout the Northeast. The unique hybrid architecture was designed to optimize artificial intelligence (AI) applications and will allow for rapid progress on problems of great societal importance. They include: quantum computing, drug discovery and design, safe robotics, control of adaptive crop pests, and new computer vision tools for use in the health care and transportation industries.  As an example, DeepGreen will allow the training of neural networks on the world's largest brain imaging datasets of illicit drug users, yielding novel health and policy strategies to combat the opioid epidemic.  A focus of the scientific and technical team is to broaden the number of personnel able to exploit GPU hardware for problem solving, producing the highly trained and diverse technical workforce required for the current and future AI economy. <br/><br/>DeepGreen was designed by a team of experts from the physical, medical, biological, computational, and agricultural sciences, partnered with an experienced group of information technology professionals.  It will be capable of over 8 petaflops of mixed precision calculations based on the latest NVIDIA Tesla V100 architecture with a hybrid design allowing high bandwidth message passing across heterogeneous compute nodes.  Its extreme parallelism will facilitate research in three interconnected areas: quantum many-body systems, molecular simulation and modeling, and deep learning, artificial intelligence and evolutionary algorithms.  DeepGreen will forge transformative research pipelines. It will enable the study of thousands of quantum entangled atoms, and millions of interacting components in biological systems providing insights into structure-function mechanisms.  Machine learning and deep neural networks will exploit DeepGreen's Tensor Cores to solve diverse problems. These problems include: the development of coarse grained potentials for use in molecular dynamics simulations, real time dynamic processing of crowd sourced decision making for robotics, genomic sequencing of invasive pests, and feature recognition in medical imaging to distinguish cancerous tumors from benign nodules.  Software designed for use on DeepGreen will be released to the public as open source, with other scientists and researchers being able to immediately use and extend it. This project will also support the next generation of data scientists. Training workshops focused on GPU computing and machine learning frameworks, new university courses, and partnerships with existing local NSF-funded graduate training initiatives, will drive broad utilization of DeepGreen.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1652052","CAREER: Active and Action-Centric Visual Understanding","IIS","ROBUST INTELLIGENCE","07/01/2017","08/22/2018","Ali Farhadi","WA","University of Washington","Continuing grant","Jie Yang","06/30/2023","$124,002.00","","afarhad2@gmail.com","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","7495","1045, 7495","$0.00","This project develops technologies for visual semantic planning; the problem of producing ordered sequences of actions that change the current world state from what is depicted in a given image or video to the state defined by a query task. The project bridges the gap between current levels of image understanding and what is needed to actively understand the visual world to the extent that an agent can plan and perform tasks. The project develops the technology for a crucial next step in recognition: active and action-centric image understanding by semantic understanding of actions, their preconditions and effects, and visual planning.  Doing so empowers several applications in healthcare, prospective memory failure care, visually impaired care, elderly care, robotics, entertainment, and education.<br/><br/>This research addresses the visual planning problem that entails knowing what actions are, how they change the world state, and which sequences of actions change the current state to a desired one. Successful active understanding of images requires addressing several fundamental and challenging problems at the intersection of computer vision and artificial intelligence. The research is focused on the development of a framework for active visual understanding, new scalable algorithms for joint detection of actions and their arguments, new datasets and representations for actions' preconditions and effects, new algorithms for predicting the consequences of actions with intuitive laws of physics, and visual semantic planning. The developed framework is designed for active and action-centric image understanding by large-scale, semantic action recognition, modeling actions' preconditions and effects, predicting consequences of actions, and visual planning. These resources not only enable new research directions in computer vision, robotics, and AI, but also bring together some of the independent efforts across these disciplines."
"1719506","Broadening Participation Research Project: Investigating the Impact of Collaborative Project-Based Learning on the Self-Efficacy of Minority STEM Students","HRD","HIST BLACK COLLEGES AND UNIV","07/01/2017","02/26/2018","George Acquaah","MD","Bowie State University","Standard Grant","Earnestine P. Easter","06/30/2019","$350,000.00","George Acquaah","gacquaah@bowiestate.edu","14000 Jericho Park Road","BOWIE","MD","207159465","3018604399","EHR","1594","8212","$0.00","Bowie State University will study the impact of collaborative project-based learning on the self-efficacy of minority freshmen enrolled in STEM courses and examine the underlying instructional system using a participatory strategy and socio-constructivist theories. The project is designed also to enhance the educational research skills of STEM faculty through their engagement in action research.         The intervention incorporates small in-class collaborative projects to inspire students' interest in learning new theory and to train students in the design process. The researchers will leverage the Robotics Clinics learning environment at Bowie State to understand why the intervention is effective and to generalize the innovative teaching practice to the broader STEM education community, particularly minority serving institutions. <br/><br/>The researchers propose to investigate two research questions in two phases. The research questions are what are the learning characteristics of minority freshmen in STEM, and how do various features in collaborative learning and group dynamics influence the development of efficacy. In the first phase, the investigators will collect and analyze survey data of students enrolled in the Robotics Clinic freshman seminar courses using a social constructivist framework. They will then conduct a learner and contextual analysis to study the influences of learner characteristics and group differences. In the second phase, the investigators will use the results of the first phase to design and test the effectiveness of the evidence-based instructional system in fostering self-efficacy. The researchers will assess the impact of the project on faculty through surveys, focus groups, and self-reported anecdotes. The project is expected to produce a measure to evaluate the developmental impacts of the collaborative learning strategy on learning outcomes, to articulate an effective instructional system that integrates community inquiry, and to indirectly enhance the training of STEM faculty in educational research."
"1564521","Collaborative Research: ABI Development: A User-friendly Tool for Highly Accurate Video Tracking","DBI","ADVANCES IN BIO INFORMATICS","08/01/2016","07/20/2016","Anna Dornhaus","AZ","University of Arizona","Standard Grant","Peter H. McCartney","07/31/2019","$206,774.00","","dornhaus@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","BIO","1165","","$0.00","Biological science has made great strides recently both by capitalizing on automated methods of data collection and by enabling researchers to share results efficiently via public databases. This project will achieve the same for applications that use videos to track movement of animals, cells, or robots, by producing freely available software for efficient and automatic extraction of movement data and directly adding such data to a public database (the KNB Data Repository). The software will be easy to use and adapt to new types of videos, issues that have so far been roadblocks to widespread adoption of existing video tracking tools. The ability to share both movement data and videos will stimulate collaboration among researchers. Both functionalities will enable fundamentally new advances in such areas as animal group behavior, behavioral genetics, cell biology, and collective robotics, and other fields that record the movements of many individuals. The software, because of its ease of use and enabled access to research videos from the database, will also serve as a tool in teaching at the K-12 and college level. In addition, this project will serve to train several college and graduate students in both biology and computer science; such interdisciplinary training is essential for advances in biological research today.<br/><br/>This project will implement a unique combination of clear, current graphical user interface design to improve usability with state-of-the-art machine learning techniques to improve movement tracking accuracy. In addition, the developed software will enable users to visualize results for validation and analysis, and include functionality for users to correct any remaining tracking errors. This will enable users to get scientific-quality data output without having to employ multiple software applications and without having to manually post-process data files. In the context of the project, several workshops will be held and a website developed to improve accessibility for students and researchers in biology. The project will also develop a direct link to the existing KNB scientific data repository, such that users can access the repository, compare their results, or complete meta-analyses easily. Besides advancing biological research, this will also generate an extensive resource for computer vision scientists by providing a large collection of videos with accurate user annotation for improving core algorithms such as object detection and tracking.  More information may be found at http://www.abctracker.org."
"1813785","RI: Small: Sparse Predictive Coding for Energy Efficient Visual Navigation in Dynamic Environments","IIS","ROBUST INTELLIGENCE, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","08/15/2018","Jeffrey Krichmar","CA","University of California-Irvine","Standard Grant","Kenneth C. Whang","09/30/2021","$450,000.00","Charless Fowlkes","jkrichma@uci.edu","141 Innovation Drive, Ste 250","Irvine","CA","926173213","9498247295","CSE","7495, 8624","7495, 7923, 8089, 8091","$0.00","This project develops efficient machine vision algorithms inspired by the architecture and energetic efficiency of the primate visual system for motion processing. Navigating through a rich cluttered natural environment, while both the observer and the objects in the scene are moving, is a difficult problem in machine vision, particularly for real-time processing under power constraints. However, humans and other animals perform these tasks with ease. The nervous system is under tight metabolic constraints and this leads to incredibly efficient representations of important environmental features, such as the observer's heading, the depth of objects, and the motion of objects.  In addition, these efficient machine vision algorithms can be applied to robotics, the IoT, and edge processing.  The algorithms can be applied to a wide range of applications, including augmented reality, assistive robotics, autonomous vehicles, and the Internet of Things (IoT) Thus, they could have a transformative economic and societal impact by creating applications that can operate autonomously over long periods in remote locations.<br/><br/>Inspired by ability of the nervous system to efficiently encode and appropriately respond to the visual features that make up a dynamic scene, the algorithm uses sparse predictive coding techniques to process data streams from cameras. Because the algorithms can be realized in spiking neural networks, where the artificial neurons only send signals when an event occurs, they can run efficiently on low powered neuromorphic systems; computers that support such representations.  By employing an architecture inspired by the brain, where op-down signals from the frontal cortex and parietal cortex predict where objects will be in the future, the system will have better object tracking and overcome difficulties when objects become hidden from view.  These representations are sparse and reduced, leading to energy efficient processing, less computation, and thus low power consumption.  In summary, the machine vision algorithms: (1) increase our understanding of how the brain encodes behaviorally relevant signals in the world, (2) lead to computationally efficient handling of large data streams, and (3) realize power efficient processing for a wide range of embedded applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1757793","REU Site: Intelligent Energetic Systems Engineering (INTENSE)","EEC","HUMAN RESOURCES DEVELOPMENT, EPSCoR Co-Funding","09/15/2018","08/16/2018","Michael Hargather","NM","New Mexico Institute of Mining and Technology","Standard Grant","Mary Poats","08/31/2021","$259,182.00","David Grow","michael.hargather@nmt.edu","801 Leroy Place","Socorro","NM","878014681","5758355496","ENG","1360, 9150","116E, 9150, 9178, 9250","$0.00","The Intelligent Energetic Systems Engineering (INTENSE) REU at New Mexico Institute of Mining and Technology (NMIMT, New Mexico Tech) will engage undergraduate students in unique research related to robotics, smart materials, explosives, high-speed fluid dynamics, and shock physics.  There is a distinct need for more US citizens with research experience to fill science and engineering positions across the country, particularly for the Department of Defense (DOD), Department of Energy (DOE), and National Aeronautics and Space Administration (NASA) complexes and associated industrial bases.  Students involved in this REU will complete individual research and design projects directly related to federally-funded research being performed at NMIMT; building skills, knowledge, and exposure to science, technology, engineering, and mathematics (STEM) disciplines relevant to these national hiring needs.  The research projects will investigate the interdisciplinary engineering and science of intelligent and energetic systems, including specific projects to explore human-robot interactions and feedback, and the complex chemical-thermo-fluid-dynamics of reacting energetic material systems.  Participants will be exposed to cutting edge research facilities at NMIMT and at prominent national facilities through tours of Sandia National Laboratories and Kirtland Air Force Base Space Vehicles and Directed Energy Directorates.  Students will be recruited primarily from Southwestern US institutions with limited undergraduate research opportunities.  INTENSE REU will have focused recruitment of under-represented populations of Hispanic, Native American, and Veteran minorities, supporting NMIMT?s Hispanic Serving Institution status. <br/><br/>The INTENSE REU objectives and impacts are to increase interest in STEM research and graduate studies, increase technical knowledge of Intelligent and Energetic Systems, increase research skills, increase exposure to STEM career opportunities, engage students in long-term STEM mentoring relationships, and enhance STEM opportunities for minority and under-represented populations.  Each summer, eight students will participate in a nine-week program conducting research in laboratories with faculty and graduate student mentors, exploring intelligent and energetic systems.  Energetic systems topics including explosives, propulsion, shock physics, and high-rate impacts are taught at extremely few universities nationally, with NMIMT being a recognized national leader in the field. INTENSE REU participants will be exposed to unique research involving intelligent and energetic systems that is being performed through a range of federal funding mechanisms, including support from federally funded research and development centers (FFRDCs).  Participants will broaden their engineering ?toolbox? through hands-on research and a series of group Toolbox Development Activities covering topics including: library resources, experiment planning, data analysis, and technical communication.  Students will connect with each other and their faculty and graduate-student mentors through weekly social lunch gatherings and by presenting a three-minute speech and technical poster in an end-of-summer technical conference held at NMIMT.  Mentor training for faculty and graduate students will improve relationships, increase research effectiveness, and provide long-term connections with REU students.  Targeted student recruitment will result in under-represented minority students with no access to research at their undergraduate institutions to be exposed to STEM research of national interest, and thus expanding the diversity of the national workforce.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1659428","REU Site: Cognitive and Autonomous Test Vehicles","CNS","RSCH EXPER FOR UNDERGRAD SITES","05/01/2017","05/23/2017","Jonathan Sprinkle","AZ","University of Arizona","Standard Grant","Harriet G. Taylor","04/30/2020","$360,000.00","Tamal Bose","sprinkle@ece.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","CSE","1139","9250","$0.00","This funding provides for a first renewal of a CISE Research Experiences for Undergraduates (REU) site at the University of Arizona.  A team of faculty and graduate students will lead undergraduate students in immersive research experiences in the compelling, challenging and timely area of autonomous systems focusing on autonomous cars. Working together in small groups, the students will learn how to design and implement algorithms, test them in a robotics car, analyze data revived from experiments, and present the results. Students will have access to a safe, full-size robotics car testbed for their experiments. The site will target the recruitment of women and groups traditionally under-represented in the computing fields. Participating students will gain first-hand experience in research and get an insight into graduate students' life that will help them make informed decisions in pursuing postgraduate studies as well as in choosing professional careers, hopefully in computer science and engineering.<br/><br/>The project is led by an outstanding team offering state-of-the art facilities and professional mentors to guide undergraduates in explorations of real-world problems. Students will undertake projects in the areas of model-based design, cognitive radio, control algorithms, sensory data processing, vehicle-to-vehicle-infrastructure communication, and multi-vehicle algorithm scalability.  Due to the nature of the testbed, participants will be required to use a spiral development process, where new requirements are added only after previous requirements are verified. The spiral development process will permit projects to have a large number of potential requirements and allow the students to explore the requirements in which they are most interested. The participating students will gain experience in academic authorship and presentations and develop videos for broad dissemination of their projects.  The students will participate in an immersive opportunity to design components of a pervasive system that might prepare them to explore other societal-scale problems in the future."
"1654283","CAREER: Jamming in Flexible Geometries-from Shape Sculpting to Shapeshifting","DMR","CONDENSED MATTER & MAT THEORY","07/01/2017","01/19/2017","Timothy Atherton","MA","Tufts University","Continuing grant","Daryl W. Hess","06/30/2022","$186,419.00","","timothy.atherton@tufts.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","MPS","1765","1045, 7433, 8084","$0.00","NONTECHNICAL SUMMARY<br/>This CAREER award supports theoretical research, education and outreach on jammed soft materials. Materials such as sand, glasses, foams and colloids can become rigid or jam as the density is increased. Jammed materials possess remarkable properties such as fragility and flowing readily if sufficient force is applied. These properties are due to their structure: particles in a jammed state have only the minimum number of neighbors required to hold them in place. <br/><br/>The PI will investigate how the jamming process is altered when it occurs in a system that is changing shape, such as on a fluid droplet or an elastic body. A better understanding would enable the creation of materials and devices in applications that exploit shape, such as soft robotics, drug delivery systems, actuators, and artificial muscles. The PI will develop a computational model of jamming in flexible geometries and use it to determine how particles and initial shape affect the structure and how desired final shapes can be sculpted by carefully choosing the components of the system. By incorporating particles in the simulation that respond to external influences, such as in response to an applied field, or move under their own power, the research team will determine how these particles can be used to create shape-shifting materials that can change shape spontaneously. Computer software developed as part of this project will be made fully accessible to the community on public repositories.<br/><br/>This award also supports outreach and education efforts that are closely integrated with the research. The educational component aims to integrate soft matter and computation by incorporating projects and activities based on the research into the PI's newly developed course in Computational Physics. The outreach component will create and disseminate a web game, together with classroom materials developed by teachers, that communicates jamming to high school students and the general public. This award will also support the participation of Deaf and Hard of Hearing students in summer research at Tufts who will conduct simulations and analysis in support of the research. <br/><br/>TECHNICAL SUMMARY<br/>This CAREER award supports theoretical research, education and outreach on jammed soft materials. Jamming is a transition to rigidity that occurs in granular media. The goal of the research is to understand by computer simulations how the jamming transition is modified when it occurs in a flexible geometry. The central hypothesis of the proposal is that jammed states in flexible geometries constitute a new jamming category called ""metric jammed"" where the system is stable both with respect to collective motions of the surface and deformations of the manifold. Understanding how physical effects such as jamming are modified when shape and order co-evolve provides fundamental insight into these processes and will enable the creation of new materials, devices and industrial techniques such as soft robotics, drug delivery systems, actuators and artificial muscles that exploit the results. <br/><br/>To test the central hypothesis, the PI will create a computational model of the metric jamming process and use this to: i) determine how shape and particles control the properties of the metric jammed state; ii) identify how flexible geometries affect metric jamming and how this can be used to sculpt soft colloidal particles of a desired shape; iii) incorporate actuatable and active particles into the model to determine how such particles can be used to create shape-shifting materials that can change shape spontaneously. This work will help advance the field of soft matter by providing a detailed understanding of the physics of the new metric jammed state in both two and three dimensions, the connections between order and shape change, the shapes that can emerge from these processes, and how microstructural changes can induce shape evolution. To help others navigate the numerous and complex physical effects intrinsic to this class of materials, the research will also provide open-source computational tools to facilitate this design.<br/><br/>This award also supports outreach and education efforts that are closely integrated with the research. The educational component aims to integrate soft matter and computation by incorporating projects and activities based on the research into the PI's newly developed course in Computational Physics. The outreach component will create and disseminate a web game, together with classroom materials developed by teachers, that communicates jamming to high school students and the general public. This award will also support the participation of Deaf and Hard of Hearing students in summer research at Tufts who will conduct simulations and analysis in support of the research."
"1808026","Collaborative Research: Decoding and encoding mechanistic relations between structure and function in crack resistance of articular cartilage and cartilage inspired biomaterials.","DMR","BIOMATERIALS PROGRAM","07/15/2018","07/10/2018","Moumita Das","NY","Rochester Institute of Tech","Continuing grant","Mohan Srinivasarao","06/30/2021","$217,029.00","","modsps@rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757987","MPS","7623","7573","$0.00","Non-Technical Summary<br/><br/>Articular cartilage is a soft tissue which provides a smooth cushion and distributes mechanical load in joints. As a material, articular cartilage is remarkable. It is only a few millimeters thick, can routinely bear up to ten times one's body weight over 100-200 million loading cycles, and still avoids fracturing. The simultaneous strength, fracture resistance (toughness), and longevity of native articular cartilage remains unmatched in synthetic materials. Such properties are desperately needed for tissue engineering, tissue repair, and even soft robotics applications. The molecular mechanism underlying this exceptional toughness, however, is not well understood. This project will obtain an understanding of the underlying principles and mechanisms that lead to the toughness of articular cartilage, and provide criteria, as we do for cracks in airplane wings, for predicting the probability that initially untreated tears in cartilage will fracture further. <br/><br/>The PIs will test the hypothesis that cartilage has such terrific properties due to the fact that it is comprised of two interweaving polymer networks, one which provides mechanical rigidity and one that provides dissipation. Moreover, this double network changes in composition with location in the tissue. These ideas will be tested using numerical simulation and comparison with experimental measurements of the tissue mechanical properties. Using this integrated approach, the PIs will elucidate mechanical structure-function relations underlying fracture toughness of articular cartilage (AC) which will lead to better predictions of cartilage mechanics and failure, and guide the design of new bioinspired materials. The project will provide insights into tissue failure, tissue repair therapies, and design principles for soft robotics. PIs will educate and train a new generation of scientists who understand physics, engineering, and biology, organize workshops aimed at teaching communication skills to graduate students, and promote diversity in STEM workforce. <br/><br/><br/>Technical Summary<br/><br/>Articular Cartilage (AC) is a soft tissue that covers the ends of bones to distribute mechanical load in joints. AC contains relatively few cells and its network-like extracellular matrix primarily determines its mechanical response. Its strength, toughness, and crack resistance are extremely high compared to synthetic materials, but the molecular mechanism underlying this exceptional toughness is not well understood. Given the heterogeneous, depth dependent, and multi-component structure and composition of AC, existing continuum descriptions are too coarse-grained to fully describe its fracture mechanics. <br/><br/>The PIs will address this challenge by approaching cartilage fracture with a new structure function framework that combines rigidity percolation theory and microscale double-network hydrogel models, together with new confocal elastography experiments that can inform and interface with the model development. Using this integrated approach consisting of multi-scale mathematical modeling and state-of-the art experiments, they will test the hypothesis that the toughness of AC arises because (i) the reinforcing network state is in proximity to a mechanical phase transition allowing tunable mechanical response, and (ii) the tissue is a multi-component heterogeneous composite enabling novel response to stress and blunting of cracks. The project will obtain an understanding of the dependence of cracks on structure and composition of cartilage and similar soft tissues, as well as on loading conditions, and provide insights into tissue failure, and tissue repair therapies. More broadly, this new framework will enable novel and concrete predictions on how these structure, composition, and constitutive mechanical properties can be tuned to resist, and blunt cracks in biomimetic and engineered materials. <br/><br/>PIs will educate and train a new generation of scientists who understand physics, engineering, and biology, and promote diversity in STEM workforce. Cohen and Bonassar will develop soft-skills curriculum units for graduate students and postdocs based on a recent science communication workshop held at Cornell by the Alan Alda Center for Communicating Science. Das will mentor minority and 1st generation students via RIT's McNair Program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1751770","CAREER: Robust Geometric Design of Mechanisms for Interaction with Uncertain Environments","CMMI","EDSE-Engineering Design and Sy, CAREER: FACULTY EARLY CAR DEV","07/01/2018","03/19/2018","Nina Robson","CA","California State University-Fullerton Foundation","Standard Grant","Richard Malak","06/30/2023","$500,000.00","","nrobson@fullerton.edu","1121 North State College Blvd.","Fullerton","CA","928313014","6572782106","ENG","072Y, 1045","063Z, 067E, 1045, 9102","$0.00","Many tasks are difficult to automate due to high levels of uncertainty in key task details, such as the shape or size of an object to be manipulated or the operating environment. Even when it is possible to design a robotic system to complete such a task, the resulting system can be too costly and/or lack the robustness required for industrial use. For example, produce picking remains a labor-intensive endeavor for the agriculture industry because variability in the operating environment and fragility of the produce have thus far prevented the design of an economical mechanized solution. Other examples can be found in numerous industries, including semiconductor manufacturing, healthcare and biomedical engineering. This Faculty Early Career Development Program (CAREER) award supports fundamental research to advance mechanical systems design in this setting. The research will lead to a new geometric design methodology that results in robust mechanical systems and motion paths for uncertain operating environments and manipulating uncertain objects. Research outcomes will advance national health and prosperity by impacting industries such as manufacturing, agriculture and healthcare. An innovative educational program will create a cross-disciplinary research-oriented course for lower division undergraduates at a Minority Serving Institution, engage female high school students through a robotics-themed summer program and develop activities to facilitate the transfer of underrepresented community college students to four-year engineering degrees.<br/><br/>This CAREER award applies robust geometric design principals to mechanical systems to explain complex motion in mechanism-object/environment interaction and uncertainty: two critical foci not explicitly captured in existing design methodologies. In this context, uncertainty refers to variations in the object/environment geometry and/or in the realizable mechanism motion paths. The results will yield a novel framework for the design of mechanisms for interaction with uncertain objects/environments. This will be accomplished through a general mechanism-environment contact geometric model formulation and its validation. The design framework will be assessed through designing and experimentally testing industry-related showcase prototypes in the areas of mechanical and biomedical engineering. The central hypothesis is that incorporating mechanism-environment interaction and uncertainty conditions into the design task formulation results in a robust design methodology that is better than existing approaches.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1659190","SUNFEST: Summer Undergraduate Research in Sensor Technologies","EEC","HUMAN RESOURCES DEVELOPMENT","04/01/2017","03/01/2017","Jan Van der Spiegel","PA","University of Pennsylvania","Standard Grant","Mary Poats","03/31/2020","$381,244.00","","jan@ee.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","ENG","1360","116E, 9178, 9250","$0.00","This three year renewal Research Experiences for Undergraduates (REU) Site Program, SUNFEST: Summer Undergraduate Research in Sensor Technologies, at the University of Pennsylvania, will offer a diverse cohort of students from underrepresented groups who have limited opportunities for STEM-oriented research the opportunity to work on research projects involving sensor technologies with the goal to develop new materials and devices. Topics include sensor phenomena, modeling, materials, nano- and micro-technology, sensors for biomedical applications, sensory data processing and sensor systems for robotics. Sensor technology, which acts as a common intellectual focus and which addresses ""real-life"" applications, can have a huge scientific impact that can benefit society and the environment. The program will also serve as an intellectual hub for others' involvement, such as high school students from city high schools and their teachers.  The SUNFEST program will act as a catalyst for broader involvement and a supportive environment for meaningful participation in scientific communities.  <br/><br/>Over 11 summer weeks, the University of Pennsylvania will host 10 undergraduate students who will be involved in high quality, cutting-edge research projects related to sensor technology. By working on a meaningful research project of their own in a dynamic and supportive environment, students will contribute to academically-based discovery that may lead to better devices and systems for medical, robotics, communications, environmental, energy and surveillance applications. To foster students' development as future researchers, they will participate in weekly group meetings and seminars in their labs.  In addition, the REU offers enhancement activities, include workshops on writing proposals and technical reports, responsible conduct of research, applying to graduate school, and effective oral presentations."
"1703791","SHF: Medium: Collaborative Research: Formal Analysis and Synthesis of Multiagent Systems with Incentives","CCF","SOFTWARE & HARDWARE FOUNDATION","07/01/2017","06/29/2017","Rajeev Alur","PA","University of Pennsylvania","Standard Grant","Nina Amla","06/30/2020","$400,000.00","","alur@cis.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","7798","7924, 8206","$0.00","The project develops automated methods for the tool-aided design and analysis of multi-agent systems with incentives. These systems are natural models for real-world situations in which collections of actors interact with one another in an autonomous and self-interested manner. For example, such a system can model a set of software agents that participate in an internet-based protocol, such as an advertisement auction or crypto currency; a collection of robots that share physical or digital infrastructure; or a set of cells that participate in an evolutionary process. The project combines game-theoretic and logical methods to develop techniques for formal modeling, analysis, verification, and synthesis of such systems. The end objectives of the project include reliable engineering of protocols that govern interactions among autonomous agents, and computer-aided understanding of naturally occurring game-theoretic interactions.<br/><br/>The technical approach of the project has three dimensions. The first is the development of new formal models, correctness requirements, and abstraction and reasoning principles for multi-agent systems with incentives. Research directions include richer notions of equilibria in multi-agent systems, and effects of interaction and randomization on equilibria. Second, the project studies algorithmic tools for analysis and verification of multi-agent systems with incentives with respect to desired requirements regarding system behaviors and equilibria. The third direction is to automatically synthesize mechanisms so as to guarantee desired properties. Applications from a range of areas, including financial protocols, robotics, and biology, are used to guide and evaluate the research."
"1607832","Collaborative Research:   A biomimetic dynamic self-assembly system programmed using DNA nanostructures","DMR","Cellular & Biochem Engineering, DMR SHORT TERM SUPPORT","09/01/2016","09/06/2016","Yan Liu","AZ","Arizona State University","Standard Grant","Mohan Srinivasarao","08/31/2019","$270,000.00","","yan_liu@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","MPS","1491, 1712","7237, 7573, 7623, 8007, 8614, 9102","$0.00","Non-technical: These collaborative awards by the Biomaterials program in the Division of Materials Research to Arizona State University (lead) and University of Michigan Ann Arbor (non-lead) are to study DNA polymerization and depolymerization to biomimic the functions of microtubules in cells. This award is co-funded by the following programs: 1) BioMaPS program in the Division of Materials Research; and 2) Biotechnology and Biochemical Engineering program in the Division of Chemical and Bioengineering, Environmental, and Transport Systems (ENG). The award will study the dynamic self-assembly and disassembly observed in cellular microtubules, which are involved in a number of cell functions such as intracellular transport, cell division, gene expression, etc. With this award, the microtubule functions will be mimicked by designing the self-assembly seen in DNA system. Scientific broader impacts of this study will be in developing biocompatible motors, robotics, and other applications such as drug and gene delivery systems. As part of the broader impact activities, this project will provide interdisciplinary training opportunities to students at the interface between DNA nanotechnology and single molecule biophysics. In addition, this project aims to engage high school students through experiential learning, providing them with teaching tools, and developing a STEM volunteer network. Finally, the single-molecular probing will be performed in the NSF-funded Single Molecule Analysis in Real-Time (SMART) Center at the University of Michigan, which has a vigorous outreach program to the broader scientific community.<br/><br/>Technical: This project will build synthetic DNA-based assemblies that biomimic the salient features of dynamic self-assembly seen in cellular microtubules. Taking advantage of the DNA nanostructure programmability, this project aims to: investigate the kinetic determinants of interactions including cooperative binding, nucleation, and growth; mimic the treadmilling (active transport by self-assembly and disassembly) and dynamic instability of microtubules by employing driving forces intrinsic to Holliday junction isomerization with intermediate assembly stages that can be isolated and studied; and visualize and control of the treadmilling and dynamic instability of the DNA assembly line using comprehensive single-molecule characterization methods. Examination of this synthetic dynamic assembly system will lay the groundwork in the design and construction of sophisticated dynamic molecular assemblies based on DNA. Results from this project will provide a theoretical foundation for DNA-based motors, robotics, and other dynamic transport systems. These studies could in turn pave the way for assembling a DNA tile system that can directionally step on a programmed dynamic assembly line that mimics the motion of motor proteins (e.g., dynein or kinesin) seen in microtubules."
"1509245","Collaborative Research: ET-ECS: Electronic Textiles for Exploring Computer Science with High School Students & Teachers to Promote Computational Thinking and Participation for","DRL","ITEST","08/01/2015","05/30/2017","Yasmin Kafai","PA","University of Pennsylvania","Continuing grant","Joseph Reed","07/31/2019","$835,205.00","","kafai@upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","EHR","7227","","$0.00","This project  advances efforts of the Innovative Technology Experiences for Students and Teachers (ITEST) program to better understand and promote practices that increase students' motivations and capacities to pursue careers in fields of science, technology, engineering, or mathematics (STEM by producing empirical findings and/or research tools that contribute to knowledge about which models and interventions with K-12 students and teachers are most likely to increase capacity in the STEM and STEM cognate intensive workforce of the future. <br/><br/>The project will develop implement, and test an expansion unit using electronic textiles for the Exploring Computer Science (ECS) curriculum that is currently implemented in high schools across the nation by providing an alternative to the existing robotics unit that can appeal and recruit larger group of girls and address the longstanding lack of women and minorities in computing. Over the last decade, there has been a steady decline in the number of women earning bachelor's degrees in computing, with the percentage decreasing from 27.5% in 2002 to 18.2% in 2012, continuing a trend where in some US states no female high school students took the Advanced Placement in CS exam. With the current push to re-introduce CS education into the K-12 schools, there is a great need for carefully developed curriculum materials that introduce high school students to key CS concepts and practices that are also rich and diverse in content that can broaden high school students' perceptions of computing and CS career aspirations coupled together with teacher professional development. The project will mainly take place in the Los Angeles Unified School District (LAUSD) in addition to the School District of Philadelphia (SDP), two of the largest public school districts in the country with high percentages of underserved students. The study also uncovered that high numbers of low-income students of color were offering courses labeled as CS, but their coursework included little other than keyboarding and other basic rudimentary computing skills. Rarely did schools offer rigorous computer science courses, but when they did, they were located in affluent communities and included few girls or students of color. Los Angeles Unified School district (LAUSD) students in ECS reveal high participation rates that closely mirror District demographics. In 2013-14, over 2500 LAUSD students enrolled in ECS; 73% of the students were Latino, 11% African American, 7% Asian, 8% White, and 46% female. There are no other nationwide computer science programs that have attracted such diverse students. <br/><br/>The grant's goals will be (1) to develop robust curricular materials that are accessible to a large group of teachers and students, particularly in underserved communities, (2) to provide evidence that students not only can learn key CS concepts and practices with electronic textiles but also broaden their perspectives of computing and STEM career aspirations, (3) to illustrate an alternative model to competitions for showcasing and disseminating students' final e-textile designs and (4) to pilot teacher professional development. Our interdisciplinary team, versed in addressing issues of equity and diversity in CS, will bring together expertise from curriculum design, computer science, and learning sciences. The CS curriculum will be consisted of six units covering: Human-Computer Interaction, Problem-Solving, Web Design, Introduction to Programming (Scratch), Computing and Data Analysis, and Robotics. The instructional design of the course will adopt inquiry-based teaching practices so that all students are given opportunities to explore, design investigations, think critically, test solutions, and solve real problems. These links to computational thinking will also connect ECS to the Common Core State Standards and Next Generation Science Standards. A key part of ECS will be a professional development (PD) program that builds and supports an on-going teacher learning community. The ECS PD program will spans two years with a combination of two summer week-long institutes and quarterly Saturday workshops. The key features of ECS PD will include: (1) immersion into inquiry and equity-based practices; (2) a focus on teachers' instructional practice done through a teacher-learner-observer model, where teachers take turns planning and delivering lessons in teams with feedback in debrief sessions with fellow teachers; and (3) development of an on-going professional learning. The proposed development of the ECS curriculum and teacher professional development will use electronic textiles with middle and high school students to support their learning of computer science CS concepts and practices and their broadening of perceptions of computing. The project will be leveraged with previous foundational work that developed and piloted introductory and advanced electronic textile activities to introduce CS concepts and practices in line with the existing ECS curriculum to promote computational thinking."
"1812948","CAREER: Understanding the Printability of Liquid Metal Dispersions for Additive Manufacturing","CMMI","Materials Eng. & Processing","07/01/2017","02/15/2018","Rebecca Kramer-Bottiglio","CT","Yale University","Standard Grant","Thomas F. Kuech","07/31/2020","$388,894.00","","rebecca.kramer@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","ENG","8092","080E, 1045, 8021, 8025, 9102, 9146, CL10","$0.00","This Faculty Early Career Development (CAREER) Program grant will investigate an additive manufacturing process using liquid metal. This work has the potential to enable a new class of stretchable electronic devices to serve as platforms for soft robotics, safe human-machine interaction, active orthotics, wearable interfaces, or assistive medical devices for motion aid, prolonged endurance, and health-monitoring. In this research program, stretchable composite materials with electronic functionality will be created by printing liquid-metal traces in elastic polymers. The composite materials are expected to retain the function of rigid metal conductors while leveraging the highly deformable properties of the plastic matrix. The work will focus on the fundamental problems surrounding the processing of liquid metal in order to develop a scalable manufacturing process. The educational and outreach activities include the development of a low-cost, accessible, and scalable soft robot designed for middle- and high-school students.<br/><br/>Additive manufacturing with liquid-metal dispersions will bridge the gap between well-established scalable liquid processing, such as printing, and the processing of emerging soft functional materials that exhibit high surface tension, viscosity, and density properties that typically preclude printability. The research objective of this project is to derive and validate the fundamental electromechanical behavior of liquid-metal dispersions during synthesis, deposition, and coalescence. The mechanical response of liquid-metal through these three processing phases will be coupled to its bulk electrical response using experiments, theories, and numerical models across different length scales. This grant will enable a fundamental understanding of the basic principles underlying scalable materials processing for soft electromechanical systems and will significantly improve our ability to design soft machines that deform, react to their environment, and adapt."
"1509084","Detection and Tracking of Multiple Dynamic Targets with Cooperating Networked Agents","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/01/2015","07/06/2017","Sean Andersson","MA","Trustees of Boston University","Standard Grant","Radhakisan S. Baheti","07/31/2019","$407,980.00","Christos Cassandras","sanderss@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","ENG","7607","092E, 9102, 9251","$0.00","In the multi-agent framework, a team of autonomous agents cooperates in carrying out complex tasks in an environment that is potentially dynamic, hazardous, and even adversarial. In general, the team must seek out and then monitor targets that may also be moving while balancing the monitoring task with continued exploration. This setting, broadly termed persistent monitoring, typically arises in mobile robotic applications and sensor networks, but it is surprisingly rich and encompasses a number of other, less obvious, domains. In this project we will develop mathematical techniques for the optimal, or at least near-optimal, behavior of a team of autonomous agents performing persistent monitoring and deploy the theory in the context of tracking multiple biological macromolecules moving inside living cells. In additional to foundational mathematical research with a broad scope, the project aims to construct a new tracking fluorescence microscope that will leverage the mathematical framework to provide significantly better speed, accuracy, and throughput than existing instruments for following the dynamics of single molecules. Both undergraduate and graduate students will be trained in a variety of disciplines, including optimization, control theory, robotics, and microscopy. In addition, the project involves outreach to low-income, first-generation-to-college students in the Boston metro area through the development of one-day modules in single molecule imaging that will be used as part of Nanocamp, a six-week residential summer program for rising high school sophomores and juniors in the target demographic.<br/><br/>The control and coordination of agents in dynamic, hazardous, and possibly adversarial environments is highly challenging since it involves multiple objectives and a considerable amount of information exchange with often severe communication limitations. Since the use of ad hoc control policies frequently leads to poorly performing systems, the approach proposed in this project is the use of optimization methods to create well-designed, rational policies that can guarantee satisfactory, if not optimal, behavior. Because such optimization problems rapidly get computationally intractable and their solution is rarely amenable to on-line scalable, distributed implementations, one of the specific aims is to develop near-optimal, efficient, and uncertainty-robust schemes that use a parametric family of control policies that can be optimized on-line. While the primary project goal is a mathematically rigorous and broadly applicable framework, it will be developed with the primary motivating application in mind, namely tracking of multiple single biological macromolecules. In this setting, the agents are individual confocal volumes, each independently addressed and controlled using a programmable array microscope, and the targets are fluorescently-labeled biological macromolecules. While a decentralized implementation is in general desirable, the single molecule tracking application supports a centralized solution since all implementation is done on a single controller and thus the project will focus on the centralized approach. The mathematical algorithms developed will be implemented on field programmable gate array (FPGA) devices and tested through experiment by tracking freely diffusing quantum dots."
"1319966","RI: Small: Any-Angle Search","IIS","ROBUST INTELLIGENCE","08/01/2013","07/20/2018","Sven Koenig","CA","University of Southern California","Standard Grant","James Donlon","07/31/2019","$452,979.00","","skoenig@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7495","7495, 7923, 9251","$0.00","In this project, the PI studies any-angle search methods. Any-angle search methods are variants of the heuristic search method A* that interleave the search with path optimizations by propagating information only along grid edges (to achieve small runtimes) but without constraining the paths to grid edges (to find short ""any-angle"" paths, namely paths whose headings can change by any angle). The objective of this project is to broaden any-angle search from a few isolated search methods to a well-understood framework and to extend its applicability. To this end, the PI is developing new any-angle search methods and analyzing their properties, which is complicated by the fact that even base properties often do not transfer from A* to them. The team will also evaluate all new and existing any-angle search methods against each other and against alternative search methods, for example, to understand how they trade off among runtime, path length and memory consumption.<br/><br/>Any-angle search is a recent search paradigm that promises to result in a new class of powerful path-planning methods for mobile robots, including underwater and aerial vehicles. The project includes dissemination activities to raise awareness of any-angle search in artificial intelligence and robotics (such as via tutorials, open-source code and web applets) and offers research opportunities to both graduate and undergraduate students."
"1409987","RI: Medium: Collaborative Research: Experience-Based Planning: A Framework for Lifelong Planning","IIS","ROBUST INTELLIGENCE","08/01/2014","06/10/2016","Sven Koenig","CA","University of Southern California","Standard Grant","James Donlon","07/31/2019","$348,000.00","","skoenig@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7495","7495, 7924, 9251","$0.00","Robots need to improve their behavior over time, yet produce consistent behavior in order to allow humans to predict their actions, which is necessary to develop trust in their behavior or even cooperate with them. Furthermore, many tasks repeat, such as opening drawers. This project develops technology that addresses these issues by viewing planning as a lifelong process and exploiting the structure of human environments for efficiency, for example that drawers typically open in similar ways.<br/><br/>This research collaboration is developing a framework for lifelong planning based on experience graphs that aims to improve performance of planning over time by exploiting past experiences when solving similar planning tasks. The concept is novel because experiences are used to guide the heuristic search as opposed to be used for mere replay or adaptation. The idea that makes this possible is a novel heuristic search-based framework that can take advantage of prior experiences and still provide rigorous guarantees on completeness and path quality. The team studies how experiences can be utilized effectively during planning, how planning should gather experiences, how it should prune redundant experiences and how it can obtain experiences from demonstrations. Applications include everyday household tasks and low-volume manufacturing tasks. The software developed in this collaborative research is being integrated into the SBPL library, one of the core libraries in ROS. The project also incorporates educational activities as well as activities that help to bridge the research communities in robotics and artificial intelligence, two separate communities despite their common interest in autonomous systems."
"1815660","NSF-BSF:RI:Small:Collaborative Research:Next-Generation Multi-Agent Path Finding Algorithms","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2018","07/31/2018","Nathan Sturtevant","CO","University of Denver","Standard Grant","James Donlon","08/31/2021","$193,315.00","","sturtevant@cs.du.edu","2199 S. University Blvd.","Denver","CO","802104711","3038712000","CSE","7495, 8013","014Z, 063Z, 7495, 7923, 8086","$0.00","With the increased use of automated vehicles in manufacturing, warehousing, and other environments, it is important to ensure that the plans taken by the automated agents controlling these vehicles are both efficient and safe. That is, we want to minimize the cost of travel while ensuring that agents will not collide with each other or the environment. This project will focus particularly on approaches for planning in environments where the number of agents is limited, but the cost of failure is high. For instance, in an airport there are relatively few airplanes moving on the tarmac at any one time, but the cost of collisions is large. The project will develop efficient and robust approaches that can be used to control agents in these environments. When these approaches are complete, this will enable new applications for the deployment of automated agents that can reduce the cost and pollution of current systems while increasing their efficiency and safety.<br/><br/>Existing algorithms for centralized control of agents have three drawbacks. First, they often make restrictive assumptions about the environment, such as axis-aligned movement with unit-cost actions. Second, the optimal approaches do not scale to large numbers of agents and the fastest algorithms have poor solution quality. Third, these algorithms are only well-defined in fixed scenarios where there is a clear distinction between plan formation and execution. This project will address these limitations by developing new algorithms. These approaches will handle more realistic agent models, such as robotic movement on a state lattice, they will compute near-optimal solutions to ensure that they scale to significantly larger scenarios, and they will be adapted to run on online problems where agents can enter or exit the world and where plan execution is imprecise and must be adapted based on real-world restrictions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1562357","Collaborative Research: Computational Strategies for Resolving Schallamach Waves in Flexible Multibody Dynamics Simulations","CMMI","Dynamics, Control and System D","08/01/2016","06/29/2017","Tamer Wasfy","IN","Indiana University","Standard Grant","Irina Dolinskaya","07/31/2019","$155,027.00","Hazim El-mounayri","twasfy@iupui.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","ENG","7569","031E, 032E, 8024","$0.00","This research project addresses the need for enhanced modeling and simulation of flexible multibody dynamics (FMD) that can accurately capture friction-induced behavior, including stick-slip motion and Schallamach detachment waves. Such system-level frictionally excited vibrations can greatly degrade efficiency and lifetime, and may be especially significant where compliant materials are in frictional contact with relatively rigid bodies, as in soft robots, engineered biological systems, and other emerging engineering areas. In addition to modeling and simulation, this research will apply the enhanced FMD formulations -- together with complementary experiments -- to study biomimetic surface patterning for influencing and controlling undesired frictionally induced behavior. The FMD simulation tools arising from this project will reduce the need for expensive and time-consuming design prototypes in important US industries, including automotive, manufacturing equipment, and robotics. The project includes outreach activities to increase participation of underrepresented groups in engineering through K-12 internship and training opportunities in the investigators' labs.<br/><br/>The primary research objective is to explore the applicability and enhancement of flexible multi-body dynamics simulation tools for analyzing Schallamach waves, and related stick-slip contact dynamics. Resolving such frictional behavior will be accomplished using new and efficient contact formulations, together with efficient implementations and solution procedures. Detailed experiments will test the multi-body dynamics predictions and suggest directions for further refinements. In later stages of the research, both computation and experiments will be exercised to demonstrate new capabilities for exploring design changes, such as various micro- and macro-scale patterns, that can regularize sliding and limit detrimental stick-slip and vibration behavior. Successful completion of the research effort will greatly increase our ability to design and tailor multi-body systems incorporating soft elements while significantly extending the reach of flexible multi-body dynamics simulation to new and important research areas."
"1728186","Collaborative Research: A New Nonlinear Modal Updating Framework for Soft, Hydrated Materials","CMMI","Dynamics, Control and System D","09/01/2017","07/25/2017","Mehmet Kurt","NJ","Stevens Institute of Technology","Standard Grant","Irina Dolinskaya","08/31/2020","$238,202.00","","mkurt@stevens.edu","CASTLE POINT ON HUDSON","HOBOKEN","NJ","070305991","2012168762","ENG","7569","030E, 034E, 072E, 8024","$0.00","The mechanical properties of soft, hydrated materials have long been of interest to the scientific community. Using soft materials in mechanical designs is becoming increasingly prominent due to their obvious advantages such as flexibility in design and intentional exploitation of nonlinearity. Especially, the high-rate response of soft materials has received attention due to their many applications in robotics, materials and the biomedical sciences. Most soft and hydrated materials (e.g., biomaterials) exhibit complex mechanical behavior that is challenging to quantify due to measurement uncertainties, mechanical anisotropy and inhomogeneity. In this project, a new nonlinear dynamics-based system identification and model updating methodology will be formulated to characterize and model soft, hydrated materials. The findings of this research have the potential to drastically enhance the accuracy, cost-efficiency and accessibility of broadband soft material characterization, and, as such, it can be transformative in diverse interdisciplinary areas, such as soft robotic design, mechanical indentation measurements and soft tissue feedback during surgery. The resulting model updating approach for soft materials will be transformative in predictive engineering designs since it will enable the better utilization and integration of soft materials in diverse applications. This approach can be used for both exploiting the nonlinearities in soft mechanical designs, as well as for their health monitoring. This project will also provide training and mentoring opportunities for a diverse group of K12, undergraduate and graduate students, with a special emphasis on underrepresented groups. Interactive demonstrations of the developed methodology are planned to be displayed in local science festivals to engage the interest of the public in this scientific issue.<br/><br/>The main objective of this project is to introduce a new nonlinear dynamics-based system identification and model updating methodology to characterize soft, hydrated materials. It is based on direct analysis of measured response time series, and construction of appropriately defined transitions in appropriately defined frequency-energy plots (FEPs) of a soft-tissue tester and sample system. The dynamics of an underlying conservative system (i.e., the corresponding system with no dissipative effects) modeling the tester is then correlated with the measured response by computing nonlinear normal modes (NNMs). In the conservative system model, soft tissues are modeled as highly flexible elements with stiffness and damping nonlinearities. Then, the reconciliation of the measured and simulated responses in the FEPs is utilized to estimate the broadband dissipative properties of the soft tissues. The experimental validation will be done by testing soft materials such as tendons, hydrated PDMS and brain tissue. The physics-based nonlinear approach in this study for model updating is unprecedented since it is based exclusively on direct time series analysis, and the framework is sufficiently general to be applicable to other engineering applications, such as the reconciliation of nonlinear finite element models with experimental measurements, and the accurate model reduction of mechanical and aerospace components. Moreover, this research will drastically increase our understanding of complicated dynamical transitions and modal interactions in systems with nonlinear viscoelastic properties. It will also enable predictive engineering design of such systems and will provide new insights into the broadband response of soft materials by developing and applying a uniquely new nonlinear-dynamics based model updating framework."
"1162617","HCC: Medium: Collaborative Research: Haptic Display of Terrain Characteristics and its Application in Virtual and Physical Worlds","IIS","Cyber-Human Systems (CHS)","10/01/2012","07/20/2018","Mark Minor","UT","University of Utah","Continuing grant","Ephraim P. Glinert","09/30/2019","$1,116,554.00","John Hollerbach, Kenneth Foreman, Andrew Merryweather","mark.minor@utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7367","7367, 7924, 9150, 9251","$0.00","The PIs' goal in this research is to realistically display terrain in an immersive Virtual Reality (VR) locomotion interface, based upon modification of the foot/terrain interaction coupled with graphical and auditory display of the terrain and user interaction.  Project outcomes will include novel ""smart shoe"" technology capable of sensing and modifying the terrain perceived by the wearer at each step so that terrain slope, surface stiffness, height variations, slip and balance can be actively controlled.  The approach is based upon an instrumented shoe sole with a directionally compliant structure using controllable bladders and embedded sensors to regulate terrain effects as the user walks.  The design and control of the shoe will be based upon dynamic biomechanical and terrain interaction models.  Subject data will provide a baseline for design, verification, and validation of the system.  A robotic test-bed will validate shoe response characteristics prior to subject evaluations.<br/><br/>The platform for this work will be the existing TreadPort Active Wind Tunnel (TPAWT), which is capable of realistically displaying locomotion environments on varying slopes as well as providing controllable wind, heat, and odor display.  The cave-like display of the TPAWT will be converted to a three dimensional stereo graphics system with seamless floor projection in order to present local terrain features such as shape, height variations, and surface texture.  Combined representation, interpretation, and coordination of the graphical and physical artifacts will be considered with the aim of creating an immersive and realistic locomotion experience with the end goal of achieving practical application. This combined system is termed the TPAWT Terrain Display System (TPAWT-TDS).<br/><br/>The target test group for the new technology will be patients with Parkinson's Disease, (PD), for whom VR training has already shown some promising results for improving gait characteristics and reducing the likelihood of falls.  Survey data from PD patients will motivate selection of the specific terrain.  Regular and PD users will first be evaluated on physical mockups of the terrain, which will then be recreated and evaluated in follow-up trials in the VR environment.  Once validated, the VR terrain display will be used for PD training.  Users will again be evaluated on the physical mockups to evaluate gait and balance performance, which will also be compared to untrained subjects.<br/><br/>Broader Impacts:  The ""smart shoe"" technology to be created in this project will allow exploration of new and sophisticated methods for combining 3D graphical terrain cues with an actively changing physical terrain in a novel VR interface.  The resulting environment will have myriad potential applications as a rehabilitation and training tool, not the least of which is improved locomotion and fall prevention (since falls are the single most costly form of injury today).  Development of the new technology will be combined with rigorous human participant studies.  Research findings will be disseminated via websites and at major conferences, and also integrated into the robotics, virtual reality, ergonomics, and physical therapy curricula."
"1433670","Causal Relationships Underlying the Collective Dynamic Behavior of Swarms","CMMI","Dynamics, Control and System D","09/01/2014","04/30/2018","Maurizio Porfiri","NY","New York University","Standard Grant","Irina Dolinskaya","08/31/2019","$394,000.00","","mporfiri@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","ENG","7569","031E, 032E, 034E, 035E, 116E, 8024, 9178, 9231, 9251","$0.00","Living in groups affords several benefits for animals such as better feeding opportunities and reduced predation risks. In both instances-foraging and predator avoidance-critical information is transmitted nonverbally throughout the group, at different time scales. While current methods in animal behavior allow for inferring information sharing during coordinated maneuvers, these interactions are only a small subset of the complex behavioral repertoire of animal groups. This award supports fundamental research to investigate directional information flow underlying collective animal behavior, through the integration of dynamical systems theory and behavioral studies on the zebra fish animal model. The implications of this research are potentially transformative in the area of behavioral brain research and neuropsychobiology, where zebra fish is rapidly emerging as a valid preclinical animal model. Complementing the research are interdisciplinary education and outreach activities that will foster outside-the-box and multidisciplinary thinking in underrepresented students in engineering, and benefit the education of underprivileged students in Brooklyn public schools.<br/><br/>This research program seeks to demonstrate that an information-theoretic approach can be used to measure social animal behavior. Specifically, this award will establish a rigorous model-free framework to study causal relationships in animal interactions. A series of hypothesis-driven experiments on zebra fish will be conducted to emphasize unidirectional information transfer by controlling visual feedback between conspecifics and using independently controlled robotic replicas. Subsequently, the proposed model-free framework and established experimental paradigms will be used to investigate information flow in shoaling and schooling zebra fish along with the social implications of individual differences on their collective behavior. Toward this aim, robotics-based platforms, multi-target tracking software, and novel experimental protocols will be utilized for engineering and dissecting causal relationships that are central to the validation of the envisioned approach. The unique datasets from these laboratory experiments will support the validation of a multitude of theoretical dynamical-systems approaches toward unraveling causality in complex biological and technological systems."
"1562129","Collaborative Research: Computational Strategies for Resolving Schallamach Waves in Flexible Multibody Dynamics Simulations","CMMI","Dynamics, Control and System D","08/01/2016","07/10/2016","Michael Leamy","GA","Georgia Tech Research Corporation","Standard Grant","Irina Dolinskaya","07/31/2019","$277,933.00","Michael Varenberg","michael.leamy@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","7569","031E, 032E, 8024","$0.00","This research project addresses the need for enhanced modeling and simulation of flexible multibody dynamics (FMD) that can accurately capture friction-induced behavior, including stick-slip motion and Schallamach detachment waves. Such system-level frictionally excited vibrations can greatly degrade efficiency and lifetime, and may be especially significant where compliant materials are in frictional contact with relatively rigid bodies, as in soft robots, engineered biological systems, and other emerging engineering areas. In addition to modeling and simulation, this research will apply the enhanced FMD formulations -- together with complementary experiments -- to study biomimetic surface patterning for influencing and controlling undesired frictionally induced behavior. The FMD simulation tools arising from this project will reduce the need for expensive and time-consuming design prototypes in important US industries, including automotive, manufacturing equipment, and robotics. The project includes outreach activities to increase participation of underrepresented groups in engineering through K-12 internship and training opportunities in the investigators' labs.<br/><br/>The primary research objective is to explore the applicability and enhancement of flexible multi-body dynamics simulation tools for analyzing Schallamach waves, and related stick-slip contact dynamics. Resolving such frictional behavior will be accomplished using new and efficient contact formulations, together with efficient implementations and solution procedures. Detailed experiments will test the multi-body dynamics predictions and suggest directions for further refinements. In later stages of the research, both computation and experiments will be exercised to demonstrate new capabilities for exploring design changes, such as various micro- and macro-scale patterns, that can regularize sliding and limit detrimental stick-slip and vibration behavior. Successful completion of the research effort will greatly increase our ability to design and tailor multi-body systems incorporating soft elements while significantly extending the reach of flexible multi-body dynamics simulation to new and important research areas."
"1817189","NSF-BSF:RI:Small:Collaborative Research:Next-Generation Multi-Agent Path Finding Algorithms","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2018","07/31/2018","Sven Koenig","CA","University of Southern California","Standard Grant","James Donlon","08/31/2021","$306,534.00","","skoenig@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7495, 8013","014Z, 063Z, 7495, 7923, 8086","$0.00","With the increased use of automated vehicles in manufacturing, warehousing, and other environments, it is important to ensure that the plans taken by the automated agents controlling these vehicles are both efficient and safe. That is, we want to minimize the cost of travel while ensuring that agents will not collide with each other or the environment. This project will focus particularly on approaches for planning in environments where the number of agents is limited, but the cost of failure is high. For instance, in an airport there are relatively few airplanes moving on the tarmac at any one time, but the cost of collisions is large. The project will develop efficient and robust approaches that can be used to control agents in these environments. When these approaches are complete, this will enable new applications for the deployment of automated agents that can reduce the cost and pollution of current systems while increasing their efficiency and safety.<br/><br/>Existing algorithms for centralized control of agents have three drawbacks. First, they often make restrictive assumptions about the environment, such as axis-aligned movement with unit-cost actions. Second, the optimal approaches do not scale to large numbers of agents and the fastest algorithms have poor solution quality. Third, these algorithms are only well-defined in fixed scenarios where there is a clear distinction between plan formation and execution. This project will address these limitations by developing new algorithms. These approaches will handle more realistic agent models, such as robotic movement on a state lattice, they will compute near-optimal solutions to ensure that they scale to significantly larger scenarios, and they will be adapted to run on online problems where agents can enter or exit the world and where plan execution is imprecise and must be adapted based on real-world restrictions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1727761","Collaborative Research: A New Nonlinear Modal Updating Framework for Soft, Hydrated Materials","CMMI","Dynamics, Control and System D","09/01/2017","07/25/2017","Alexander Vakakis","IL","University of Illinois at Urbana-Champaign","Standard Grant","Irina Dolinskaya","08/31/2020","$259,320.00","Lawrence Bergman","avakakis@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","7569","030E, 034E, 072E, 8024","$0.00","The mechanical properties of soft, hydrated materials have long been of interest to the scientific community. Using soft materials in mechanical designs is becoming increasingly prominent due to their obvious advantages such as flexibility in design and intentional exploitation of nonlinearity. Especially, the high-rate response of soft materials has received attention due to their many applications in robotics, materials and the biomedical sciences. Most soft and hydrated materials (e.g., biomaterials) exhibit complex mechanical behavior that is challenging to quantify due to measurement uncertainties, mechanical anisotropy and inhomogeneity. In this project, a new nonlinear dynamics-based system identification and model updating methodology will be formulated to characterize and model soft, hydrated materials. The findings of this research have the potential to drastically enhance the accuracy, cost-efficiency and accessibility of broadband soft material characterization, and, as such, it can be transformative in diverse interdisciplinary areas, such as soft robotic design, mechanical indentation measurements and soft tissue feedback during surgery. The resulting model updating approach for soft materials will be transformative in predictive engineering designs since it will enable the better utilization and integration of soft materials in diverse applications. This approach can be used for both exploiting the nonlinearities in soft mechanical designs, as well as for their health monitoring. This project will also provide training and mentoring opportunities for a diverse group of K12, undergraduate and graduate students, with a special emphasis on underrepresented groups. Interactive demonstrations of the developed methodology are planned to be displayed in local science festivals to engage the interest of the public in this scientific issue.<br/><br/>The main objective of this project is to introduce a new nonlinear dynamics-based system identification and model updating methodology to characterize soft, hydrated materials. It is based on direct analysis of measured response time series, and construction of appropriately defined transitions in appropriately defined frequency-energy plots (FEPs) of a soft-tissue tester and sample system. The dynamics of an underlying conservative system (i.e., the corresponding system with no dissipative effects) modeling the tester is then correlated with the measured response by computing nonlinear normal modes (NNMs). In the conservative system model, soft tissues are modeled as highly flexible elements with stiffness and damping nonlinearities. Then, the reconciliation of the measured and simulated responses in the FEPs is utilized to estimate the broadband dissipative properties of the soft tissues. The experimental validation will be done by testing soft materials such as tendons, hydrated PDMS and brain tissue. The physics-based nonlinear approach in this study for model updating is unprecedented since it is based exclusively on direct time series analysis, and the framework is sufficiently general to be applicable to other engineering applications, such as the reconciliation of nonlinear finite element models with experimental measurements, and the accurate model reduction of mechanical and aerospace components. Moreover, this research will drastically increase our understanding of complicated dynamical transitions and modal interactions in systems with nonlinear viscoelastic properties. It will also enable predictive engineering design of such systems and will provide new insights into the broadband response of soft materials by developing and applying a uniquely new nonlinear-dynamics based model updating framework."
"1834929","R:SS 2018 Women in Robotics Workshop","IIS","ROBUST INTELLIGENCE","08/01/2018","07/23/2018","Chad Tossell","CO","United States Air Force Academy","Interagency Agreement","David Miller","01/31/2019","$19,876.00","Kerstin Haring, Elizabeth Phillips","chad.tossell@usafa.edu","2354 Fairchild Dr Ste 2h29","USAF Academy","CO","808406208","7193334195","CSE","7495","7495, 7556","$0.00",""
"1238089","Advanced Manufacturing and Prototyping Integrated To Unlock Potential (AMP-IT-UP)","DRL","STEM + Computing (STEM+C) Part, ENGINEERING EDUCATION, MSP-TARGETED AWARDS, ADVANCED TECH EDUCATION PROG","10/01/2012","03/23/2018","William Wepfer","GA","Georgia Tech Research Corporation","Continuing grant","Kathleen B. Bergin","09/30/2019","$7,314,455.00","James Smith, Jeff Rosen, Meltem Alemdar, Marion Usselman","bill.wepfer@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","EHR","005Y, 1340, 1792, 7412","110E, 1792, SMET","$0.00","Advanced Manufacturing and Prototyping Integrated to Unlock Potential (AMP-IT-UP) is a partnership between the Georgia Institute of Technology (GT) and the Griffin-Spalding County School System (GSCS) that focuses on grades six through nine. In this project, students in these middle grades explore their creativity in STEM Innovation and Design (STEM-ID) courses, using rapid prototyping equipment located on GSCS campuses. Students become inspired and drawn into the study of STEM as they watch their creations become reality. <br/><br/>The mathematics, engineering and science modules developed in this partnership promote inquiry and situated learning which contextualizes STEM topics to demonstrate their relevancy to AMP-IT-UP students. Through extracurricular local and national clubs and competitions, student experiences are broadened and deepened. The clubs include Junior Makers and Innovation clubs that are mentored by GT faculty and students. This mentorship provides role models for the students and provides the personal touch that is so critical for student retention and self efficacy. The competitions include robotic competitions such as FIRST LEGO League and FIRST Robotics. Approximately 2,400 students each year participate in the exploratory STEM course modules with a total of approximately 1,200 participating in the extracurricular activities. <br/><br/>AMP-IT-UP is conducting research into various aspects of the impact of the STEM-ID courses on the students and their teachers. Some of the effects being measured include exploring how participation affects academic engagement, content understanding, knowledge transfer and student persistence in STEM. Another related research topic involves the implementation of the professional development of the teachers who are using the STEM-ID materials as well as the fidelity of the curriculum deployment. AMP-IT-UP is also developing a theoretical model for understanding changes to the complex system that is education by utilizing resources from an interdisciplinary team that includes experts in both engineering and the social sciences.<br/><br/>Both core partners in this Math and Science Partnership illustrate the mutually beneficial nature of their work together. GSCS is being transformed by the middle school teacher development efforts that are enhancing teachers' ability to conduct experiential learning in their classrooms. The GT community is being transformed by a greater interaction with the middle school students and teachers, resulting in an increased emphasis on experiential and active learning environments in the GT undergraduate curriculum as well as an increased commitment to service learning among GT faculty and students."
"1540619","SL-CN: Development of Neural Body Maps","SMA","Science of Learning","09/15/2015","08/26/2015","Andrew Meltzoff","WA","University of Washington","Standard Grant","Soo-Siang Lim","08/31/2019","$749,000.00","Rajesh Rao, Peter Marshall","meltzoff@uw.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","SBE","004Y","7298, 7956, 8089","$0.00","A great deal of research with adults has documented the presence of body maps in the human brain. These neural maps have an organized spatial layout. Neighboring parts of the body are connected in an orderly fashion to areas of the brain that process touch and movement. Body maps are important for many aspect of everyday life including the sense of one's own body and controlling our movements. Body maps also likely play an important role in learning from others, through allowing us to register similarities between ourselves and other people. Despite the importance of body maps, very little is currently understood about how they develop in the early months and years of life. The research supported by this award would provide significant new information on the development of body maps and their relation to early learning. The award supports a collaborative, cross-disciplinary network of investigators who will combine expertise in developmental psychology and infant learning, brain science, cognitive science, computer modelling, and robotics. The proposed network will also support the development and training of junior investigators through specific activities designed to expose them to the benefits of an interdisciplinary approach. <br/><br/>Advances in methods for safely measuring the brain activity of human infants are allowing new questions to be asked concerning the role of body maps in early learning. The proposed research involves using magnetoencephalography (MEG) to non-invasively measure responses of the infant brain to tactile stimulation of different parts of the body (e.g., hands vs. feet), and to relate these responses to aspects of infant learning. Another set of studies involving electroencephalography (EEG) will examine how body maps facilitate early imitation and learning from others. Insights from these studies will inform (and be informed by) a further strain of research using computer modelling that takes bodily factors into account in designing robotic systems that can learn from people. The research questions will also provide insight into the control of brain-computer interfaces that can assist disabled individuals in learning to control artificial limbs and other external devices."
"1423189","CHS: Small: Looking Across the Uncanny Valley: Procedural and Data-Driven Methods for Gaze Modeling","IIS","Cyber-Human Systems (CHS)","08/01/2014","07/20/2017","Sophie Joerg","SC","Clemson University","Continuing grant","Ephraim P. Glinert","07/31/2019","$520,513.00","Andrew Duchowski","sjoerg@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","CSE","7367","7367, 7923, 9150, 9251","$0.00","Eye movements play a key role in human communication, yet they remain a significant stumbling block for humanoid animation.  Computer generated avatars currently lack realistic gaze, which subconsciously distracts viewers and thereby detracts from the usefulness of the many applications   that employ these graphical actors (e.g., educational / tutoring / training systems that incorporate animated agents), a perceptual issue that has been dubbed the ""uncanny valley.""  This project represents a collaboration between two investigators with complementary skills who will tackle the problem by developing a holistic model of gaze dynamics for avatars, which combines detailed real-world measurements (with the aid of binocular eye-tracking) and signal analysis of both eye motions and the periocular skin region around the eyes, to generate improved synthetic eye movement animations.  Project activities will include creation of a database of gaze motions,  perceptual experiments to improve our understanding of the saliency of different components of human gaze (eyeball rotation, vergence, jitter, periocular skin motion) and their signal properties in physical space, and the implementation of exemplary tasks (such as reading and conversations) along with a software tool which will enable animators to more easily design convincing gaze in frequently encountered situations.  The PI intends to open-source the software to be developed in this research.  <br/><br/>The gaze model under development by the PI differs from previous approaches in the following ways.   First, while others have modeled cyclopean avatar gaze few have accessed the steadily growing eye tracking literature for inclusion of binocular eye movement.  The PI argues that binocular eye tracking in three-dimensional physical space allows estimation of where the subject is fixating in depth and, consequently, recording, analysis, and modeling of gaze vergence, which will yield more believable characters.  Second, the proposed model provides a component of subtle gaze jitter, which is critical for dynamic realism as the eyes are never perfectly still.  Third, the description of the rotations of the eyes is mathematically concise, follows physiological laws, and is easy to implement.  Finally, the proposed modeling effort includes perceptual studies designed to investigate the influence of each model component and to optimize the parameters of the resulting complete model.  The procedural model is two-staged and reminiscent of the functionality of human vision: a bottom-up stage of eye rotation, which will be used to represent gaze when selecting a series of look points, followed by a top-down stage of gaze orientation dependent on a given task.  Building a perceptual science underlying gaze modeling will foster the believability of synthetic actors, and will more broadly impact diverse areas such as social robotics where realistic gaze simulation is crucial for creating likable robots."
"1815300","RI: Small: Feature Encoding for Reinforcement Learning","IIS","ROBUST INTELLIGENCE","08/01/2018","07/26/2018","Ronald Parr","NC","Duke University","Continuing grant","Weng-keen Wong","07/31/2021","$129,850.00","Lawrence Carin","parr@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495","7495, 7923","$0.00","This project focuses on the subfield of machine learning referred to as Reinforcement Learning (RL), in which algorithms or robots learn by trial and error. As with many areas of machine learning, there has been a surge of interest in ""deep learning"" approaches to reinforcement learning, i.e, ""Deep RL.""  Deep learning uses computational models motivated by structures found in the brains of animals. Deep RL has enjoyed some stunning successes, including a recent advance by which a program learned to play the Asian game of Go better than the best human player. Notably, this level of performance was achieved without any human guidance. Given only the rules of the game, the program learned by playing against itself. Although games are intriguing and attention-grabbing, this feat was merely a technology demonstration. Firms are seeking to deploy Deep RL methods to increase the efficiency of their operations across a range of applications such as data center management and robotics. To realize fully the potential of Deep RL, further research is required to make the training process more predictable, reliable, and efficient. Current techniques require massive amounts of training data and computation, and subtle changes in the configuration of the system can cause huge differences in the quality of the results obtained. Thus, even though RL systems can learn autonomously by trial and error, a large amount of human intuition, experience and experimentation may be required to lay the groundwork for these systems to succeed. This proposal seeks to develop new techniques and theory to make high quality deep RL results more widely and easily obtainable. In addition, this proposal will provide opportunities for undergraduates to be involved in research through Duke's Data+ initiative.<br/><br/>The proposed research is partly inspired by past work on feature selection and discovery for reinforcement learning.  Much of that work focused primarily on linear value function approximation.  Its relevance to deep reinforcement learning is that methods such as Deep Q-learning have a linear final layer.  The preceding, nonlinear layers can, therefore, be interpreted as performing feature discovery for what is ultimately a linear value function approximation process.  Sufficient conditions on the features that were specified for successful linear value function approximation in earlier work can now be re-interpreted as an intermediate objective function for the penultimate layer of a deep network. The proposed research aims to achieve the following objectives: 1) Develop a theory of feature construction that explains and informs deep reinforcement learning methods, 2) develop improved approaches to value function approximation that are applicable to deep reinforcement learning, 3) develop improved approaches to policy search that are applicable to deep reinforcement learning, and 4) develop new algorithms for exploration in reinforcement learning that take advantage of learned feature representations, and 5) perform computational experiments demonstrating the efficacy of the new algorithms developed on benchmark problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1544999","CPS/Synergy/Collaborative Research: Safe and Efficient Cyber-Physical Operation System for Construction Equipment","CMMI","CYBER-PHYSICAL SYSTEMS (CPS)","01/01/2016","08/21/2015","Mani Golparvar-Fard","IL","University of Illinois at Urbana-Champaign","Standard Grant","Bruce M. Kramer","12/31/2019","$325,000.00","Timothy Bretl","mgolpar@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","7918","030E, 034E, 5188, 7339, 7918, 8235","$0.00","Equipment operation represents one of the most dangerous tasks on a construction sites and accidents related to such operation often result in death and property damage on the construction site and the surrounding area. Such accidents can also cause considerable delays and disruption, and negatively impact the efficiency of operations. This award will conduct research to improve the safety and efficiency of cranes by integrating advances in robotics, computer vision, and construction management. It will create tools for quick and easy planning of crane operations and incorporate them into a safe and efficient system that can monitor a crane's environment and provide control feedback to the crane and the operator. Resulting gains in safety and efficiency wil reduce fatal and non-fatal crane accidents. Partnerships with industry will also ensure that these advances have a positive impact on  construction practice, and can be extended broadly to smart infrastructure, intelligent manufacturing, surveillance, traffic monitoring, and other application areas. The research will involve undergraduates and includes outreach to K-12 students.<br/><br/>The work is driven by the hypothesis that the monitoring and control of cranes can be performed autonomously using robotics and computer vision algorithms, and that detailed and continuous monitoring and control feedback can lead to improved planning and simulation of equipment operations. It will particularly focus on developing methods for (a) planning construction operations while accounting for safety hazards through simulation; (b) estimating and providing analytics on the state of the equipment; (c) monitoring equipment surrounding the crane operating environment, including detection of safety hazards, and proximity analysis to dynamic resources including materials, equipment, and workers; (d) controlling crane stability in real-time; and (e) providing feedback to the user and equipment operators in a ""transparent cockpit"" using visual and haptic cues. It will address the underlying research challenges by improving the efficiency and reliability of planning through failure effects analysis and creating methods for contact state estimation and equilibrium analysis; improving monitoring through model-driven and real-time 3D reconstruction techniques, context-driven object recognition, and forecasting motion trajectories of objects; enhancing reliability of control through dynamic crane models, measures of instability, and algorithms for finding optimal controls; and, finally, improving efficiency of feedback loops through methods for providing visual and haptic cues."
"1745463","Convergence HTF: A Research Coordination Network to Converge Research on the  Socio-Technological Landscape of Work in the Age of Increased Automation","IIS","INSPIRE","01/01/2018","08/23/2017","Kevin Crowston","NY","Syracuse University","Standard Grant","Meghan Houghton","12/31/2022","$499,796.00","Jeffrey Nickerson, Ingrid Erickson","crowston@syr.edu","OFFICE OF SPONSORED PROGRAMS","SYRACUSE","NY","132441200","3154432807","CSE","8078","060Z, 063Z","$0.00","The landscape of jobs and work is changing rapidly, driven by the development of new technologies. Intelligent, automated machines and services are a growing part of jobs and the workplace. New technologies are enabling new forms of learning, skills assessments, and job training. The potential benefits of these technologies include increased productivity and job satisfaction, and more job opportunities. But technology connected to work can also come with risks. This research coordination network (RCN) addresses the future of work at the human-technology frontier by focusing on the use of intelligent machines in work settings. The RCN supported by this award will promote convergence across computer science, engineering, and social and behavioral science disciplines to define and address key challenges and research imperatives in the future of work at the human-technology frontier with intelligent machines. This convergence RCN will employ deep integration of knowledge, theories, methods, and data from multiple fields to form new and expanded frameworks for addressing scientific and societal challenges and opportunities. The results will include the identification and sharing of new research directions and tools to reinforce positive outcomes and mitigate negative consequences of intelligent machines in work settings. Ultimately this has the power to strengthen the U.S. economy, and improve worker performance and job satisfaction.<br/><br/>This RCN will focus on advancing the knowledge needed to develop actionable design principles that attend to both sides of the human-technology frontier in work settings that use intelligent machines. Such machines include not only autonomous robots and vehicles, but also algorithms and machine learning processes that support all types of autonomous behavior. At present, the technology side of this frontier is advancing more rapidly than the human side: people, organizations, legal frameworks, and social values, to name a few. What is necessary to bring these two side into alignment is a systems design approach that draws on both social and technological requirements as well as their interdependencies. This RCN aims to adopt this goal, thereby developing the knowledge needed to ensure that the benefits of intelligent machines are gained while the negative consequences reduced.<br/><br/>This RCN will bring together investigators from many disciplines including computer science (artificial intelligence, machine learning), robotics, human computer interaction, cognitive science, economics, sociology, law, organizational science, ergonomics, industrial and organizational psychology, engineering, and information systems, to communicate, coordinate, and integrate their research and educational activities across disciplinary and organizational boundaries. Toward this goal, this award will support three primary RCN activities over its five-year term. First, the RCN will organize annual Convergence Conferences that will focus on the contribution of convergent research on topics regarding the socio-technological landscape of work in the age of increased automation. Second, it will support a series of workshops at different disciplinary conferences to expand the reach of the network and to consolidate, test, verify, and evolve research ideas as they develop. Third, the RCN will maintain a set of shared online resources to support the community and its research efforts."
"1650536","I/UCRC for Building Reliable Advances and Innovation in Neurotechnology (BRAIN)","CNS","SPECIAL PROJECTS - CISE, INDUSTRY/UNIV COOP RES CENTERS","03/01/2017","07/23/2018","Jose Contreras-Vidal","TX","University of Houston","Continuing grant","Dmitri Perkins","02/28/2022","$324,500.00","Luca Pollonini, David Mayerich, Ahmet Omurtag","jlcontreras-vidal@uh.edu","4800 Calhoun Boulevard","Houston","TX","772042015","7137435773","CSE","1714, 5761","5761, 8808, 9251","$0.00","Age-related diseases are increasingly a leading cause of disability. Millions of younger adults live with neurological disorders, limb loss from amputation or paralysis from spinal cord injury. Traumatic brain injury can have lifelong effects on cognitive-motor function, significantly decreasing quality and length of life. There is a critical need for state-of-the art technology to effectively address the care and rehabilitation of these individuals. However, innovation in biomedical devices and other neurotechnologies faces several challenges: 1) The pace of innovation is moving more quickly than the rate of evaluation for acceptable performance; 2) Standards and regulatory science for the rigorous validation of safety, efficacy, and long-term reliability are missing; 3) Lack of open access to technologies that slows the transfer of novel technologies to the market; and 4) Current technologies are not affordable. To address these challenges, the University of Houston will partner with Arizona State University to establish and host a multi-institution Industry/University Cooperative Research Center (IUCRC) for Building Reliable Advances and Innovation in Neurotechnology (BRAIN).<br/>The BRAIN Center's vision is a synergistic, interdisciplinary approach to develop and validate affordable patient-centered technologies.  BRAIN will leverage expertise in neural systems, cognitive and rehabilitation engineering, robotics, device development, clinical testing and reverse-translational research at the University of Houston and Arizona State University to 1) enhance the rate of development and empirical validation of new technologies through partnerships with industry leaders and other strategic partners; 2) develop standards and technologies in human and non-human models, using a multi-scale approach ranging from single neurons to organismal systems; 3) characterize innovative technologies such as biosensors and quantitative analysis tools for systems and behaviors; 4) evaluate the impact of these technologies on quality of life; and 5) reduce the cost of neurotechnologies. The BRAIN Center's mission is multifold: to accelerate the progress of science and advance national health by transferring engineering innovations in neurotechnology to the end users, and to rectify underrepresentation in science, technology, engineering, and math (STEM) fields by broadening new participation and retaining current participants in STEM. It also will focus on problems in the neurological space that affect underrepresented groups disproportionately. BRAIN will become an innovative neurotechnology hub for the Southwest, creating a pipeline from discoveries to solutions while helping talented students, scientists, and engineers in the region take their innovations to the next level and solve one of the greatest unmet medical and health care needs of our time.<br/><br/>BRAIN will leverage a unique concentration of researchers and innovative research and development ecosystems with industrial partnerships to design, develop, test, and characterize neural technologies that can effectively transform the lives of disabled individuals. The Center will investigate all levels of neural function to enhance not only current technologies but also understanding of the mechanisms underlying neurological disease and injury. The University of Houston IUCRC Site - a Hispanic-Serving Institution - will focus on multi-scale, multi-modal, and multi-disciplinary and noninvasive approaches to understanding all aspects of human neural function ""in action and in context"" in complex natural settings, and to deploying noninvasive technologies treating human disability. The University of Houston IUCRC site will bring a broad range of expertise spanning the spectrum of cognitive, affective, neural, and rehabilitation engineering across the human lifespan, big data analytics, computational modeling, wearable electronics, mobile brain-body imaging devices, intervention techniques including peripheral, brain-machine interfaces, smart human-machine systems, wearable robots, virtual and augmented reality and other noninvasive solutions."
"1350685","CAREER: Practical Algorithms and Fundamental Limits for Complex Cyber-Physical Systems","CNS","SPECIAL PROJECTS - CISE, CYBER-PHYSICAL SYSTEMS (CPS)","03/01/2014","07/19/2018","Sertac Karaman","MA","Massachusetts Institute of Technology","Continuing grant","David Corman","02/28/2019","$614,397.00","","sertac@MIT.EDU","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","1714, 7918","1045, 7918, 9178, 9251","$0.00","Designing software that can properly and safely interact with the physical world is an important cyber-physical systems design challenge. The proposed work includes the development of a novel approach to designing planning and control algorithms for high-performance cyber physical systems. The new approach was inspired by statistical mechanics and stochastic geometry. It will (i) identify behavior such as phase transitions in cyber-physical systems and (ii) capitalize this behavior in order to design practical algorithms with provable correctness and performance guarantees. The algorithms developed through this research effort hold the potential for immediate industrial impact, particularly in the development of real-time robotic systems. These algorithms may strengthen the rapidly developing U.S. robotics industry. The proposed research activity will also vitalize the PI?s educational plans. Undergraduate<br/>and graduate courses that make substantial contributions to the embedded systems education<br/>at MIT will be developed. The classes will focus on provably-correct controller synthesis for cyber-physical systems, which is currently not thought at MIT. Undergraduate students will be involved in research activities.<br/>"
"1626424","MRI: Development of a hyper-sensed environmentally controlled wind tunnel","CBET","MAJOR RESEARCH INSTRUMENTATION","10/01/2016","09/16/2016","Jeffrey Riffell","WA","University of Washington","Standard Grant","Song-Charng Kong","09/30/2019","$639,700.00","Steven Brunton, Alberto Aliseda, Joel Thornton, Kristi Morgansen","jriffell@u.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","ENG","1189","1189","$0.00","1626424 - Riffell<br/><br/>This Major Research Instrumentation Award will support the development of a wind tunnel system instrumented with multiple sensor types that allow feedback from and control of the environment within the tunnel, thereby allowing detailed examination of physical, chemical, and biological processes in a conventional laboratory environment. Located at the University of Washington, this system will enable critical research advances in environmental flow control and sensory neuroscience, as both fields share deep connections involving the fusion of uncertain data for real-time control in a rich sensory environment. The ability to characterize and control highly dynamic processes that occur over short time are increasingly important in a number of research efforts. The integration of multiple sensor information types (chemical, flow, motion) for environmental control will enable advances in sensory neuroscience - where neural systems rapidly process information to affect motor decisions remains a fundamental open problem - and advances in flow control and robotics. Work enabled by this instrument has significant research and commercialization potential, resulting in novel technology and processes to integrate multiple sensor streams into effective control algorithms; for instance, the acquired knowledge and experience will impact robotics and semiautonomous systems for search and rescue, agricultural inspection, and environmental monitoring. This program will also have positive impact on the STEM workforce by supporting additional course offerings and laboratory modules in undergraduate and graduate engineering and biology courses, as well as at the K-12 level by providing demonstrations to students that provide real-world examples for creative opportunities in engineering and neuroscience. <br/><br/>An increasing need exists for a state of the art, multi-sensing wind tunnel to study fluid dynamic transport phenomena while also allowing for real-time closed loop control of the wind tunnel environment. Such a system can provide novel insights into bio-inspired research, such as flight control in flapping insect flight or the sensory basis of mosquito navigation to human blood-hosts - while also providing advances in basic fluid dynamical processes, including development of energy harvesting devices, like wind turbines. Currently no commercially available solution is available that enables multimodal sensing (chemical, flow, motion) for environmental control. The unique capabilities of the hypersensed wind tunnel include: (1) coupled analysis of mass spectrometric and PIV systems to illuminate the reaction timescales and turbulent transport of pollutants; (2) new data techniques and laser development for PIV to improve analysis capabilities of existing PIV systems; (3) creating virtual environments based on neural and behavioral feedback from free-flying insects; and (4) advancing closed-loop turbulence control for energy extraction that will translate to technologies in drag reduction, lift increase, mixing enhancement, and noise reduction with countless applications. The findings and results about and from this facility will be disseminated to the research community through conferences, journal publications and news agencies."
"1515592","Characterizing Spatio-Temporal Patterns of Swarms","DMS","APPLIED MATHEMATICS, WORKFORCE IN THE MATHEMAT SCI","09/15/2015","05/24/2017","Sebastien Motsch","AZ","Arizona State University","Standard Grant","Victor Roytburd","08/31/2019","$307,901.00","Dieter Armbruster","smotsch@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","MPS","1266, 7335","019Z, 8549","$0.00","This project is aimed at investigation of collective behavior of large groups of individual agents that is typified by swarming. In addition to its intrinsic scientific value, understanding collective behavior observed in nature (such as in flocks of birds and schools of fish) is expected to facilitate the ability to control technological swarms in the form of nanoparticles delivering drugs or micro-robots performing assemblies and conducting searches. There is a variety of models that provide superficially similar output, that is, they all generate some sort of collective motion. However, there is a lack of studies that distinguish among swarming models and determine their relevance with respect to experimental observations. This project develops a bridge between different mathematical tools to describe swarming behavior and experimentally relevant measures of such behavior in application fields ranging from biology to robotics and from marketing to opinion formation. <br/> <br/>For many common mathematical models, characterizations of swarms are elementary (for example, flocking or milling) and are based on simple global quantities (that is, average velocity or angular momentum). In contrast, this project focuses on more complex observables unveiling key attributes of swarms and swarming models.  For instance, the speed of information propagation is crucial in swarming to avoid obstacles or predators and can be characterized through the analysis of different types of traveling waves. Similarly, interaction with boundaries and other swarms generate internal excitations in the form of standing waves. Connecting swarming behavior and observables requires investigating both micro- and macro-scales. Therefore, this project will combine tools from information theory and statistical physics (micro-models) with the analysis of partial differential equations (macro-models)."
"1634215","Collaborative Research: Persistent Presence in the Ocean Interior: Developing a Low-power, Autonomous System for Geo-referenced Navigation","OCE","OCEAN TECH & INTERDISC COORDIN","01/01/2017","09/15/2017","Andreas Thurnherr","NY","Columbia University","Continuing grant","Kandace S. Binkley","12/31/2019","$53,904.00","","amt2109@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","GEO","1680","","$0.00","Facilitating an accurately navigated persistent presence for the interior of the deep ocean has the potential to transform how oceanography is conducted.  This capability is currently not provided by existing technologies; however, if developed would transform the scope of projects undertaken by underwater vehicles with longer range and endurance than can currently be deployed unsupported from research ships.  This research develops a new low power navigation system that improves navigational accuracy from 1000s of meters to 100s meters.  This advance will enable multiple new lines of oceanographic investigation.  Examples include deployment of coordinated glider fleets to investigate complex physical-biogeochemical interactions; deep studies of topographically induced mixing; long-range characterization of seafloor habitats/ecosystems at the scale of entire ocean basins; and better resolution of the scales of bottom-boundary-layer processes in regions with steep underwater terrain.   The researchers will engage in outreach activities including undergraduate participation in our research and continuation of established collaborations with local high school robotics and environmental science classes. <br/><br/>This research develops and tests a low-power acoustic positioning system that enables accurate externally aided navigation in the deep ocean.  A glider (or fleet of gliders) operates at depth while an autonomous surface robot (ASV) follows on the sea surface. The ASV transmits its geo-reference position to the gliders at a regular interval. Each glider  then independently employs a precision time base (provided by chip-scale atomic clocks) and array processing to determine its position relative to the ASV. Each ASV combines this relative position estimate with the ASV's position encoded in the received packet to compute its geo-referenced position. System performance depends on a number of factors including the precision of vehicle attitude sensors. Accuracies of 250-400m are possible at 5000m depth using low-power sensors already in use on the glider. Hence, for deep-diving gliders, this method will provide a 10-100 fold improvement in positioning accuracy over the current paradigm (i.e., infrequent GPS fixes) and would allow vehicles to spend more time at depth making relevant observations. This research will enable new operating paradigms, advance observational capabilities and facilitate spatially denser observations than were previously possible. Furthermore, the new system will also improve the ability to estimate depth-averaged ocean currents. The developed capability is also a prerequisite for coordinated motion control of multiple deep-diving AUGs, further increasing the density and cadence of deep ocean observations, providing an ever closer-to-synoptic view of the deep ocean interior.  The developed system will be tested first in the tank and then in two ocean cruises including a Year 3 deployment on a Seaglider."
"1710598","Hydrodynamics and Actuation of Magnetic Bacteria in Confined Geometries:Single cells to swarms","ECCS","COMMS, CIRCUITS & SENS SYS","08/01/2017","04/27/2018","Ratnasingham Sooryakumar","OH","Ohio State University","Standard Grant","Shubhra Gangopadhyay","07/31/2020","$344,164.00","Steven Lower, Brian Lower","soory@mps.ohio-state.edu","Office of Sponsored Programs","Columbus","OH","432101016","6146888735","ENG","7564","104E, 9102, 9251","$0.00","In order to navigate their environment, many bacteria and other living micro-organisms swim by rotating a flagellum, a slender helix-shaped attachment connected to the cell body. Near surfaces, the wake produced by this rotating flagellum produces complex forces and torques that act on the bacterium. This gives rise to a range of movements that depend on the orientation of the cell relative to the surface, as well as its rate of rotation and physical geometry. Understanding these interactions at surfaces is important in the study of individual motile bacteria as well as in the development of technologies that can controllably manipulate large micro-organism populations in fluid environments. The proposed investigations will take advantage of the unique features of an inherently magnetic bacterial species, M. magneticum AMB-1, of the magnetotactic bacteria (MTB) group. Their natural magnetism allows them to be externally manipulated, providing a new means of probing the fluid-based forces arising near surfaces. Experiments that explore the role of cell geometry and orientation, magnetic content and flagellar thrust will underlie the development of models for the swimming behavior of MTB and associated fluid flow patterns.  MTB are also promising candidate organisms for biologically powered micro-actuation and robotics. In this vein, large scale cell assemblies permit several magnetic field-based devices such as ""living liquid crystal"" displays and bacterial ""conveyor belts"" to be developed.  The project will undertake outreach activities for several high school teachers in the form of an annual summer workshop. Through these activities, high school students will be able to create a connection between a fun, familiar device, an Xbox controller for example, and concepts in physics, environmental science, biology and engineering disciplines (e.g. magnetism, bacterial habitats, microorganisms, Archimedes principle) in the classroom and laboratory.<br/><br/>The realization of functional biology-based robotics at the microscopic level would introduce a paradigm shift in areas as diverse as materials manufacturing, nanotechnology and medicine. The proposed work will make major advances in this direction by investigating fundamental fluid-surface interactions of a model bacterial species (M. magneticum AMB-1) with innate magnetic properties. Together with micro-magnetic and micro-fluidics techniques, their magnetic organelles allow individual living bacteria and swarms be confined and guided  to yield quantitative measures of the hydrodynamic and magnetic forces as well as torques that are central to their dynamics. These quantitative parameters will serve as the foundation for developing models of their hydrodynamics on scales ranging from single cells to swarms. Integrating actuation and control of living organisms in low Reynolds number surroundings will serve as the basis to enable several novel biological and bio-hybrid machines that operate in a micro-fluidic environments. The in-situ management of the relative positions of individual cells through designed magnetic surface patterns provides for a novel means to explore pairwise cell-cell interactions that have led to the discovery of novel collective behavior such as rotating filamentary bacterial clusters, living liquid crystal magneto-optical modulators and momentum generating ""conveyer-belt"" tracks in these environments where viscous forces dominate. The flow fields generated by the propulsion of these flagellated swimmers will be managed to construct microscopically tunable pumps, mixers and hydrodynamic assemblers. The project will undertake stimulating outreach activities for high school students and teachers that link physics, environmental science, biology and engineering disciplines both in the classroom and laboratory."
"1564850","Collaborative Research: ABI Development: A User-friendly Tool for Highly Accurate Video Tracking","DBI","ADVANCES IN BIO INFORMATICS","08/01/2016","07/13/2018","Min Shin","NC","University of North Carolina at Charlotte","Continuing grant","Peter H. McCartney","07/31/2019","$1,361,015.00","","mcshin@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","BIO","1165","","$0.00","Biological science has made great strides recently both by capitalizing on automated methods of data collection and by enabling researchers to share results efficiently via public databases. This project will achieve the same for applications that use videos to track movement of animals, cells, or robots, by producing freely available software for efficient and automatic extraction of movement data and directly adding such data to a public database (the KNB Data Repository). The software will be easy to use and adapt to new types of videos, issues that have so far been roadblocks to widespread adoption of existing video tracking tools. The ability to share both movement data and videos will stimulate collaboration among researchers. Both functionalities will enable fundamentally new advances in such areas as animal group behavior, behavioral genetics, cell biology, and collective robotics, and other fields that record the movements of many individuals. The software, because of its ease of use and enabled access to research videos from the database, will also serve as a tool in teaching at the K-12 and college level. In addition, this project will serve to train several college and graduate students in both biology and computer science; such interdisciplinary training is essential for advances in biological research today.<br/><br/>This project will implement a unique combination of clear, current graphical user interface design to improve usability with state-of-the-art machine learning techniques to improve movement tracking accuracy. In addition, the developed software will enable users to visualize results for validation and analysis, and include functionality for users to correct any remaining tracking errors. This will enable users to get scientific-quality data output without having to employ multiple software applications and without having to manually post-process data files. In the context of the project, several workshops will be held and a website developed to improve accessibility for students and researchers in biology. The project will also develop a direct link to the existing KNB scientific data repository, such that users can access the repository, compare their results, or complete meta-analyses easily. Besides advancing biological research, this will also generate an extensive resource for computer vision scientists by providing a large collection of videos with accurate user annotation for improving core algorithms such as object detection and tracking.  More information may be found at http://www.abctracker.org."
"1512760","Collaborative Research: ET-ECS: Electronic Textiles for Exploring Computer Science with High School Students & Teachers to Promote Computational Thinking and Participation for","DRL","ITEST","08/01/2015","06/12/2017","Jane Margolis","CA","University of California-Los Angeles","Continuing grant","Joseph Reed","07/31/2019","$250,001.00","","margolis@gseis.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","EHR","7227","","$0.00","This project  advances efforts of the Innovative Technology Experiences for Students and Teachers (ITEST) program to better understand and promote practices that increase students' motivations and capacities to pursue careers in fields of science, technology, engineering, or mathematics (STEM by producing empirical findings and/or research tools that contribute to knowledge about which models and interventions with K-12 students and teachers are most likely to increase capacity in the STEM and STEM cognate intensive workforce of the future. <br/><br/>The project will develop implement, and test an expansion unit using electronic textiles for the Exploring Computer Science (ECS) curriculum that is currently implemented in high schools across the nation by providing an alternative to the existing robotics unit that can appeal and recruit larger group of girls and address the longstanding lack of women and minorities in computing. Over the last decade, there has been a steady decline in the number of women earning bachelor's degrees in computing, with the percentage decreasing from 27.5% in 2002 to 18.2% in 2012, continuing a trend where in some US states no female high school students took the Advanced Placement in CS exam. With the current push to re-introduce CS education into the K-12 schools, there is a great need for carefully developed curriculum materials that introduce high school students to key CS concepts and practices that are also rich and diverse in content that can broaden high school students' perceptions of computing and CS career aspirations coupled together with teacher professional development. The project will mainly take place in the Los Angeles Unified School District (LAUSD) in addition to the School District of Philadelphia (SDP), two of the largest public school districts in the country with high percentages of underserved students. The study also uncovered that high numbers of low-income students of color were offering courses labeled as CS, but their coursework included little other than keyboarding and other basic rudimentary computing skills. Rarely did schools offer rigorous computer science courses, but when they did, they were located in affluent communities and included few girls or students of color. Los Angeles Unified School district (LAUSD) students in ECS reveal high participation rates that closely mirror District demographics. In 2013-14, over 2500 LAUSD students enrolled in ECS; 73% of the students were Latino, 11% African American, 7% Asian, 8% White, and 46% female. There are no other nationwide computer science programs that have attracted such diverse students. <br/><br/>The grant's goals will be (1) to develop robust curricular materials that are accessible to a large group of teachers and students, particularly in underserved communities, (2) to provide evidence that students not only can learn key CS concepts and practices with electronic textiles but also broaden their perspectives of computing and STEM career aspirations, (3) to illustrate an alternative model to competitions for showcasing and disseminating students' final e-textile designs and (4) to pilot teacher professional development. Our interdisciplinary team, versed in addressing issues of equity and diversity in CS, will bring together expertise from curriculum design, computer science, and learning sciences. The CS curriculum will be consisted of six units covering: Human-Computer Interaction, Problem-Solving, Web Design, Introduction to Programming (Scratch), Computing and Data Analysis, and Robotics. The instructional design of the course will adopt inquiry-based teaching practices so that all students are given opportunities to explore, design investigations, think critically, test solutions, and solve real problems. These links to computational thinking will also connect ECS to the Common Core State Standards and Next Generation Science Standards. A key part of ECS will be a professional development (PD) program that builds and supports an on-going teacher learning community. The ECS PD program will spans two years with a combination of two summer week-long institutes and quarterly Saturday workshops. The key features of ECS PD will include: (1) immersion into inquiry and equity-based practices; (2) a focus on teachers' instructional practice done through a teacher-learner-observer model, where teachers take turns planning and delivering lessons in teams with feedback in debrief sessions with fellow teachers; and (3) development of an on-going professional learning. The proposed development of the ECS curriculum and teacher professional development will use electronic textiles with middle and high school students to support their learning of computer science CS concepts and practices and their broadening of perceptions of computing. The project will be leveraged with previous foundational work that developed and piloted introductory and advanced electronic textile activities to introduce CS concepts and practices in line with the existing ECS curriculum to promote computational thinking."
"1618903","RI: Small: Probabilistic Hierarchical Models for Multi-Task Visual Recognition","IIS","ROBUST INTELLIGENCE, IntgStrat Undst Neurl&Cogn Sys","09/01/2016","07/06/2016","Deva Ramanan","PA","Carnegie-Mellon University","Standard Grant","Jie Yang","08/31/2019","$449,989.00","","deva@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495, 8624","7495, 7923, 8089","$0.00","This project studies biologically-inspired architectures for visual recognition. The human visual system can perform a remarkable number of tasks, from estimating the 3D shape of an object that is grasped to inferring subtle differences between two similar makes and models of cars. Such diverse sets of visual tasks are required of a range of autonomous agents, including self-driving cars or humanoid robotics. Such autonomous platforms have the potential to increase general welfare and health of the overall population. This project attempts to build a computational model capable of such diverse visual tasks. Motivated by biological evidence, this project explores the use of feedback logic to enable such computational reasoning. The project provides research opportunities for both undergraduate and graduate students and for increasing diversity in the fields of computer and human vision.  <br/><br/>This research focuses on development of a unified hierarchical probabilistic model that can be used to solve multiple fine-grained visual tasks. Feedforward hierarchical models, of which the most ubiquitous are Convolutional Neural Nets (CNNs), have demonstrated remarkable performance in recent history. This project introduces hierarchical models for vision-with-scrutiny tasks, such as 3D articulated pose estimation and part segmentation. Rather than focusing on increasing performance on established benchmark performance, this research provides a theoretical framework for analyzing bottom-up (feedforward) CNNs and imbuing them with novel top-down reasoning capabilities. It does so by exploring a link between three dominant but disparate paradigms for visual recognition: feedforward neural models, generative probabilistic models (Boltzmann machines), and discriminative latent-variable models (deformable part models). The models introduced in this proposal allow CNNs to be used for large-scale multi-task learning, where tasks span both coarse-grained tasks (such as rapid scene categorization) and fine-grained tasks (such as 3D articulated pose estimation). By addressing multiple fine-grained tasks with a single hierarchical architecture, resource requirements for memory and speed are vastly decreased, important for embedded visual perception applications such as autonomous robots and vehicles."
"1554790","CAREER: A Framework for Revealing How Locomotor Control Emerges from the reciprocal Interactions of Neural and Mechanical Systems","PHY","PHYSICS OF LIVING SYSTEMS","07/01/2016","07/12/2018","Simon Sponberg","GA","Georgia Tech Research Corporation","Continuing grant","Krastan B. Blagoev","06/30/2021","$470,840.00","","sponberg@physics.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","MPS","7246","1045, 1359, 8091, 9250, SMET","$0.00","Animals move with remarkable stability and agility through nearly every environment. To do so, they rely on interacting neural and mechanical systems that must operate in the context of the physics of sensing, actuation, and environmental interactions. Modern data acquisition tools provide unprecedented access to the underlying neural, muscular, and mechanical signals that implement control. However, these signals alone are not a framework for understanding how sensory information transforms into motor outputs. This CAREER project leverages several emerging experimental and analytical techniques to show how locomotor dynamics emerge from this sensorimotor transform. This framework for extracting principles of sensorimotor control is based on combining high-resolution neuromuscular recordings, information theoretic and dimensionality-reduction data analytics, and the formal language of system identification and control theory. The experimental framework of this proposal is transferrable to other living and engineered systems composed of many subsystems connected by feedback such as gene or protein networks, cell mechanics, or population dynamics. Principles of locomotor control that emerge from this work will synergize with the BRAIN initiative and similar programs by providing context through which to interpret a deep, detailed understanding of brain structure, anatomy, and connectivity. They will also address challenges in the new era of robotics and neural engineering. There is a pressing need for neuro-technologies that enable versatile movement while embodied in physical systems. More broadly this work will enable translation of research-based undergraduate learning into scientific and education products. It will bring a neuroscience component to the growing Physics of Living Systems curriculum at Georgia Tech. Within the VIP program, students will receive training at the interface of biology, physics, and engineering by engaging in research-based learning that is organized into a vertical mentoring system. Ultimately the study of how brain and body control movement is an accessible context in which to engage the public and further converge education of physics and biology even outside the walls of the research university.<br/><br/>The research uses three experimental platforms (two animals and one robot). They provide insights into the shared neural and mechanical processing challenges animals face despite using different modes of locomotion. The research program includes recording and altering a nearly complete motor program (the set of all neuromuscular commands to appendages) with spike-level resolution while an animal behaves in a virtual reality environment. The PI's work also explores the performance consequences of different control architectures and the sensorimotor determinants on maneuverability. The program will use the interdisciplinary study of movement to create a scientific foundry for the Physics of Living Systems at Georgia Tech with an emphasis on how physics approaches provide a context for understanding neural signals. The core of the foundry will be a vertically integrated research team of undergraduates that will complete the loop of research-based education to classroom-inspired research. To transfer the impact outside the university, the researchers will team with local high school teachers to innovate new education tools based on the accessibility of high-speed imaging, surface electromyography, and the study of movement."
"1807602","Collaborative Research: Decoding and encoding mechanistic relations between structure and function in crack resistance of articular cartilage and cartilage inspired biomaterials.","DMR","BIOMATERIALS PROGRAM","07/15/2018","07/10/2018","Itai Cohen","NY","Cornell University","Continuing grant","Mohan Srinivasarao","06/30/2021","$200,000.00","Lawrence Bonassar","ic64@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","7623","7573","$0.00","Non-Technical Summary<br/><br/>Articular cartilage is a soft tissue which provides a smooth cushion and distributes mechanical load in joints. As a material, articular cartilage is remarkable. It is only a few millimeters thick, can routinely bear up to ten times one's body weight over 100-200 million loading cycles, and still avoids fracturing. The simultaneous strength, fracture resistance (toughness), and longevity of native articular cartilage remains unmatched in synthetic materials. Such properties are desperately needed for tissue engineering, tissue repair, and even soft robotics applications. The molecular mechanism underlying this exceptional toughness, however, is not well understood. This project will obtain an understanding of the underlying principles and mechanisms that lead to the toughness of articular cartilage, and provide criteria, as we do for cracks in airplane wings, for predicting the probability that initially untreated tears in cartilage will fracture further. <br/><br/>The PIs will test the hypothesis that cartilage has such terrific properties due to the fact that it is comprised of two interweaving polymer networks, one which provides mechanical rigidity and one that provides dissipation. Moreover, this double network changes in composition with location in the tissue. These ideas will be tested using numerical simulation and comparison with experimental measurements of the tissue mechanical properties. Using this integrated approach, the PIs will elucidate mechanical structure-function relations underlying fracture toughness of articular cartilage (AC) which will lead to better predictions of cartilage mechanics and failure, and guide the design of new bioinspired materials. The project will provide insights into tissue failure, tissue repair therapies, and design principles for soft robotics. PIs will educate and train a new generation of scientists who understand physics, engineering, and biology, organize workshops aimed at teaching communication skills to graduate students, and promote diversity in STEM workforce. <br/><br/><br/>Technical Summary<br/><br/>Articular Cartilage (AC) is a soft tissue that covers the ends of bones to distribute mechanical load in joints. AC contains relatively few cells and its network-like extracellular matrix primarily determines its mechanical response. Its strength, toughness, and crack resistance are extremely high compared to synthetic materials, but the molecular mechanism underlying this exceptional toughness is not well understood. Given the heterogeneous, depth dependent, and multi-component structure and composition of AC, existing continuum descriptions are too coarse-grained to fully describe its fracture mechanics. <br/><br/>The PIs will address this challenge by approaching cartilage fracture with a new structure function framework that combines rigidity percolation theory and microscale double-network hydrogel models, together with new confocal elastography experiments that can inform and interface with the model development. Using this integrated approach consisting of multi-scale mathematical modeling and state-of-the art experiments, they will test the hypothesis that the toughness of AC arises because (i) the reinforcing network state is in proximity to a mechanical phase transition allowing tunable mechanical response, and (ii) the tissue is a multi-component heterogeneous composite enabling novel response to stress and blunting of cracks. The project will obtain an understanding of the dependence of cracks on structure and composition of cartilage and similar soft tissues, as well as on loading conditions, and provide insights into tissue failure, and tissue repair therapies. More broadly, this new framework will enable novel and concrete predictions on how these structure, composition, and constitutive mechanical properties can be tuned to resist, and blunt cracks in biomimetic and engineered materials. <br/><br/>PIs will educate and train a new generation of scientists who understand physics, engineering, and biology, and promote diversity in STEM workforce. Cohen and Bonassar will develop soft-skills curriculum units for graduate students and postdocs based on a recent science communication workshop held at Cornell by the Alan Alda Center for Communicating Science. Das will mentor minority and 1st generation students via RIT's McNair Program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1635824","Processing and Properties of Functional Liquid Metal Elastomer Composites","CMMI","Materials Eng. & Processing","08/01/2016","05/16/2018","Carmel Majidi","PA","Carnegie-Mellon University","Standard Grant","Mary M. Toney","07/31/2019","$407,999.00","Kaushik Dayal","cmajidi@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","8092","085E, 116E, 8021, 8025, 9178, 9231, 9251","$0.00","Elastomers (soft polymers) such as silicone are ideal for engineered systems that must mimic the mechanical properties of natural human tissue.  By matching the natural properties of the body, these soft and lightweight materials can conform to skin without causing discomfort or injury.  Applications include wearable computing and electronics, collaborative robots, medical implants, and other emerging technologies that require mechanical compatibility with clothing, skin, and internal organs. However, these applications also require a range of electrical properties that are not possible with conventional elastomers.  While there are several promising techniques to improve the electrical properties of elastomers, these typically involve fillers, additives, or co-polymers that significantly degrade mechanical performance by making the material too stiff.  In this project, we will research an alternative approach in which silicone is filled with a suspension of microscopic droplets of liquid metal (LM).  Because they are metallic, the droplets can be used to dramatically alter the electrical properties of the composite.  Moreover, since they are liquid, they do not cause the silicone to become stiff.  LM-embedded elastomer (LMEE) composites represent an exciting new class of materials that will have a potentially transformative impact on wearable computing and soft collaborative robotics, thereby promoting domestic economic growth and quality of life. This project involves several disciplines including manufacturing, chemistry, materials science, and mechanics that will incorporated into both the research tasks and an outreach program on technology-integrated fashion for academically underserved students in the Pittsburgh area.<br/><br/>Progress in LMEE engineering depends on new processing techniques and a mechanics-based framework for predicting the influence of materials composition, nano-/micro-scale structure, and liquid-solid interactions on bulk electrical and mechanical properties.  The research work will address these aims with an interdisciplinary effort that combines theoretical mechanics modeling, materials processing, and multiscale characterization.  This will include efforts to produce LMEE composites with various compositions and process conditions, compare their bulk properties under different testing configurations, and compare these measurements with predictions based on homogenization analysis and statistical mechanics.  This work will lead to new scientific insights that will contribute to a fundamental understanding of the unique behavior of the composite under extreme mechanical loading. Together, these tasks will result in a new experimental and theoretical framework that could be applied to enable design other classes of multi-phase soft-matter systems."
"1544814","CPS: Synergy: Collaborative Research: Adaptive Intelligence for Cyber-Physical Automotive Active Safety - System Design and Evaluation","CNS","SPECIAL PROJECTS - CISE, CYBER-PHYSICAL SYSTEMS (CPS)","09/15/2015","05/03/2017","Panagiotis Tsiotras","GA","Georgia Tech Research Corporation","Standard Grant","Ralph Wachter","08/31/2019","$576,001.00","Karen Feigh","p.tsiotras@ae.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","1714, 7918","1714, 7918, 8235, 9251","$0.00","The automotive industry finds itself at a cross-roads. Current advances in MEMS sensor technology, the emergence of embedded control software, the rapid progress in computer technology, digital image processing, machine learning and control algorithms, along with an ever increasing investment in vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) technologies, are about to revolutionize the way we use vehicles and commute in everyday life. Automotive active safety systems, in particular, have been used with enormous success in the past 50 years and have helped keep traffic accidents in check. Still, more than 30,000 deaths and 2,000,000 injuries occur each year in the US alone, and many more worldwide. The impact of traffic accidents on the economy is estimated to be as high as $300B/yr in the US alone. Further improvement in terms of driving safety (and comfort) necessitates that the next generation of active safety systems are more proactive (as opposed to reactive) and can comprehend and interpret driver intent. Future active safety systems will have to account for the diversity of drivers' skills, the behavior of drivers in traffic, and the overall traffic conditions.<br/><br/>This research aims at improving the current capabilities of automotive active safety control systems (ASCS) by taking into account the interactions between the driver, the vehicle, the ASCS and the environment. Beyond solving a fundamental problem in automotive industry, this research will have ramifications in other cyber-physical domains, where humans manually control vehicles or equipment including: flying, operation of heavy machinery, mining, tele-robotics, and robotic medicine. Making autonomous/automated systems that feel and behave ""naturally"" to human operators is not always easy. As these systems and machines participate more in everyday interactions with humans, the need to make them operate in a predictable manner is more urgent than ever.<br/><br/>To achieve the goals of the proposed research, this project will use the estimation of the driver's cognitive state to adapt the ASCS accordingly, in order to achieve a seamless operation with the driver. Specifically, new methodologies will be developed to infer long-term and short-term behavior of drivers via the use of Bayesian networks and neuromorphic algorithms to estimate the driver's skills and current state of attention from eye movement data, together with dynamic motion cues obtained from steering and pedal inputs. This information will be injected into the ASCS operation in order to enhance its performance by taking advantage of recent results from the theory of adaptive and real-time, model-predictive optimal control. The correct level of autonomy and workload distribution between the driver and ASCS will ensure that no conflicts arise between the driver and the control system, and the safety and passenger comfort are not compromised. A comprehensive plan will be used to test and validate the developed theory by collecting measurements from several human subjects while operating a virtual reality-driving simulator."
"1637889","NRI: A Model based Approach to Distributed Adaptive Sampling of Spatio-Temporally Varying Fields","ECCS","National Robotics Initiative","09/01/2016","08/10/2016","Suman Chakravorty","TX","Texas A&M Engineering Experiment Station","Standard Grant","Radhakisan S. Baheti","08/31/2019","$499,996.00","Dylan Shell","schakrav@aero.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","ENG","8013","8086","$0.00","This research project studies the problem of designing active sensing systems for monitoring dynamically evolving spatial fields using mobile robotic sensor networks. As a particular motivating problem, we consider fields governed by advection-diffusion equations, a model sufficiently general to cover a huge range of important phenomena: from the recent Aliso Canyon gas leak in California and the volcanic ash clouds of Eyjafjallajokull, to the temperature profile within a building. The development of a realistic open-source simulation toolbox for the active sensing problem will allow the assimilation of K-12/undergraduate/graduate students, and high school teachers in projects related to the research, and also allow a broader dissemination of the research to the general public at the annual TAMU Physics and Engineering fair while educating them about the benefits of the project, for instance, in response to a hazardous situation such as a chemical leak or an oil spill.<br/><br/>In the current literature, statistical black-boxes (such as Gaussian Processes), which were originally developed for (quasi)-static spatial fields, are being used to model fields with structured temporal dynamics.  In this process, two issues which ought to be distinct, the correctness of the model, and considerations of computational efficiency, have become entangled and the consequences can be dangerous: state-of-the-art methods may provide cheap but drastically wrong estimates, along with error bounds that are grossly over-confident when the spatial fields are temporally varying. The investigators will seek to produce adaptive estimation techniques for dynamic spatial fields that are optimal and correct. In particular, randomized model reduction techniques shall be used to attain computational tractability whilst preserving correctness. Further, the project shall seek to develop receding horizon sensor tasking strategies that can drastically outperform greedy strategies in terms of the information content of the estimated field."
"1640970","INSPIRE: Assessing feasible regions of configuration spaces for macromolecular crystals","CCF","ANALYSIS PROGRAM, INFORMATION TECHNOLOGY RESEARC, ALGORITHMIC FOUNDATIONS, INSPIRE","09/01/2016","06/29/2018","Gregory Chirikjian","MD","Johns Hopkins University","Continuing grant","Rahul Shah","08/31/2019","$600,000.00","Bernard Shiffman","gregc@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","1281, 1640, 7796, 8078","7929, 8653","$0.00","This INSPIRE project is jointly funded by Algorithmic Foundations in CISE/CCF, Analysis in MPS/DMS, and the NSF Office of Integrative Activities.<br/><br/>Knowledge of the 3-dimensional structure of protein molecules supports scientific understanding of how proteins perform their functions within cells.  Structures of over 100,000 proteins in the Protein Data Bank have been determined by macromolecular x-ray crystallography: measuring the diffraction of x-ray beams from crystal composed of many symmetrically arranged copies of one or more protein molecules gives partial information (the amplitudes of the Fourier transform) that must be filled in (solving the ""phase problem,"" often by molecular replacement -- taking phases from related molecules) to complete the 3d structure. Molecular replacement works quite well for simple single-domain proteins, but breaks down for multi-domain proteins and large complexes; one needs to explore the possible combinations of domains and their diffraction patterns as replacement candidates. <br/><br/>This cross-disciplinary project brings together experts in robotics and in pure mathematics to address the ''phase problem'' of macromolecular x-ray crystallography.  The mathematical and computational framework developed in this project will enable many more protein structures to be solved in a less laborious way than can be done now. The project also introduces Baltimore City high school students to mathematics and molecular biophysics through unique visualization activities.<br/><br/>The essence of combining domains is geometric.  The team can use articulated multi-rigid-body models from the field of robotics to combine rigid portions of structures, from domains with similar sequences. The relative rigid-body motions between the domains become the unknown degrees of freedom in these articulated models.  Crystal packing constraints will rule out the majority of possible configurations for these domains, and reduce the otherwise high-dimensional nature of the search space. The project will develop new algebro-geometric and computational methods for rapidly discarding the large collision regions in configuration space, so that searches will focus on the remaining small-volume feasible regions in this high-dimensional search space. Computer code will be prepared integrating the resulting methods into existing molecular crystallography software packages."
"1629990","CI-P: Planning for AudioNet: A New Community Infrastructure for Audio Annotations for Acoustic Event Identification","CNS","COMPUTING RES INFRASTRUCTURE","07/01/2016","06/21/2016","Gerald Friedland","CA","International Computer Science Institute","Standard Grant","Tatiana D. Korelsky","12/31/2018","$100,000.00","Julia Bernd","fractor@icsi.berkeley.edu","1947 CENTER ST STE 600","Berkeley","CA","947044115","5106662900","CSE","7359","7359","$0.00","This effort lays the groundwork for AudioNet, a public-domain corpus of audio labels for the nearly 800,000 videos in the open-access YFCC100M dataset. Audio information provides an important complement to visual information in the automatic analysis of video data, allowing systems to detect situations that may not be clearly identifiable from the visual stream alone. However, there are as yet no truly large-scale labeled audio datasets of the kind needed as input to build flexible, accurate analysis systems. Creating such a large-scale corpus will serve as an impetus for better multimedia algorithms to be developed by more researchers and computer science students, translating into an impact on the everyday life of the public at large. Social media videos are increasingly used for scientific research, as they provide an opportunity to observe and model many phenomena in the social sciences, economics, meteorology, and medicine. New capabilities for content analysis will therefore impact many scientific fields. In addition, audio analysis could be used in real-time security surveillance and in robotics applications like autonomous vehicles and household robots to aid and monitor the elderly.<br/><br/>AudioNet is part of a multi-institution collaboration, the Multimedia Commons initiative, which is developing a variety of resources around the YFCC100M dataset of Creative Commons-licensed photos and videos. AudioNet is annotating the audio tracks from the YFCC100M videos, focusing on audio concepts. Audio concepts can be thought of as acoustic ""objects"": concrete, localizable units of sound like ""crowd cheering"" or ""fire alarm"". The approach will be modeled on ImageNet, an image dataset labeled and organized using the WordNet hierarchy of synsets (groups of synonyms); ImageNet has enabled major enabled advances in image processing. However, while ImageNet focuses largely on entities (noun synsets), audio data is inherently temporal. The label set for AudioNet will therefore focus on events and actions, though similarly organized using semantic resources like WordNet."
"1507377","Metric-induced buckling and buckling-induced metrics","DMR","CONDENSED MATTER & MAT THEORY","09/01/2015","07/10/2017","Christian Santangelo","MA","University of Massachusetts Amherst","Continuing grant","Daryl W. Hess","08/31/2019","$285,231.00","","csantang@physics.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","MPS","1765","","$0.00","Nontechnical Summary<br/>This award supports theoretical research and education at the interface between physics, materials science and engineering. Though 3D printing has become inexpensive enough for prototyping, it has numerous drawbacks as a manufacturing technique, including speed and configurability. Yet, there are a number of materials that can be made to controllably grow from a flat sheet to a targeted three-dimensional structure. The PI's group will develop understanding and design tools to optimally pattern a thin sheet to fold and buckle into a targeted shape and study how an elastic sheet wrinkles to accommodate curvature. Together, these projects unveil the relationship between elasticity and geometry, and enable the development of tools to improve manufacturing of structured materials.<br/>The work will have an impact on the design of structured materials by introducing new analytical techniques for the prediction of three-dimensional structures, enabling applications in advanced manufacturing and soft robotics. The award contributes to the education of graduate and undergraduate students in a multidisciplinary field and through substantial interactions with experimental research groups. It also supports the PI's efforts at outreach to the general public.<br/><br/>Technical Summary<br/>This award supports studies of three-dimensional structure formation in two-dimensional elastic sheets. Recent progress in the fabrication of polymeric structures have allowed the development of active materials that can, through spatially non-uniform growth, buckle into targeted three-dimensional structures. <br/>This research project has two goals. First, it will extend the mathematical foundation laid down to understand the buckling of thin films due to non-uniform growth to allow the design of optimal pattern of growth. Second, it will explore the related problem of how a sheet can conform to a curved surface by wrinkling. The results of this second project will then be used to explore what happens when a growing sheet cannot alleviate all of its in-plane stresses by buckling smoothly.<br/>The work will have an impact on the design of structured materials by introducing new analytical techniques for the prediction of three-dimensional structures, enabling applications in advanced manufacturing and soft robotics. The award contributes to the education of graduate and undergraduate students in a multidisciplinary field and through substantial interactions with experiments. It also supports the PI's efforts at outreach to the general public."
"1704883","SHF: Medium: Collaborative Research: Formal Analysis and Synthesis of Multiagent Systems with Incentives","CCF","SOFTWARE & HARDWARE FOUNDATION, Secure &Trustworthy Cyberspace","07/01/2017","09/15/2017","Swarat Chaudhuri","TX","William Marsh Rice University","Standard Grant","Nina Amla","06/30/2021","$800,000.00","Moshe Vardi","swarat@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","CSE","7798, 8060","7434, 7924, 8206","$0.00","The project develops automated methods for the tool-aided design and analysis of multi-agent systems with incentives. These systems are natural models for real-world situations in which collections of actors interact with one another in an autonomous and self-interested manner. For example, such a system can model a set of software agents that participate in an internet-based protocol, such as an advertisement auction or crypto currency; a collection of robots that share physical or digital infrastructure; or a set of cells that participate in an evolutionary process. The project combines game-theoretic and logical methods to develop techniques for formal modeling, analysis, verification, and synthesis of such systems. The end objectives of the project include reliable engineering of protocols that govern interactions among autonomous agents, and computer-aided understanding of naturally occurring game-theoretic interactions.<br/><br/>The technical approach of the project has three dimensions. The first is the development of new formal models, correctness requirements, and abstraction and reasoning principles for multi-agent systems with incentives. Research directions include richer notions of equilibria in multi-agent systems, and effects of interaction and randomization on equilibria. Second, the project studies algorithmic tools for analysis and verification of multi-agent systems with incentives with respect to desired requirements regarding system behaviors and equilibria. The third direction is to automatically synthesize mechanisms so as to guarantee desired properties. Applications from a range of areas, including financial protocols, robotics, and biology, are used to guide and evaluate the research."
"1525972","NRI: A Compliant Lower-Body Exoskeleton to Enable Balanced Walking for Patients with Spinal Cord Injuries","IIS","National Robotics Initiative","09/01/2015","05/18/2017","A. Wicks","VA","Virginia Polytechnic Institute and State University","Standard Grant","Irina Dolinskaya","08/31/2019","$749,598.00","Alexander Leonessa, Tomonari Furukawa","awicks@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","8013","030E, 031E, 034E, 116E, 8086, 9178, 9231, 9251","$0.00","Spinal cord injuries can lead to complete leg paralysis, drastically limiting mobility and reducing quality of life. Significant progress has been made towards wearable exoskeletons that provide some ability to walk, but these require the use of crutches, which create unnatural loads on the wearer, as well as restricting use of the hands and arms. The objective of this research is to develop a lower body exoskeleton able to balance and walk without the use of crutches, thus allowing the wearers to interact with their environment and maintain proper posture. The resulting platform will improve the overall quality of life for those with spinal cord injury by granting them a level of mobility that is currently unachievable. <br/><br/>This work will apply methods advanced in the field of humanoid robots to the design of exoskeletons for functionally impaired persons. Specifically, the project will apply a method called whole-body control, which finds motions that resolve multiple motion objectives at once, to a lower body exoskeleton with 12 degrees of freedom, providing a range of movement similar to natural human locomotion, with the exception of ankle yaw. High fidelity torque control will be achieved using series elastic actuators to enable compliant locomotion of the wearer."
"1610933","GOALI: Paper-based Skin","ECCS","GRANT OPP FOR ACAD LIA W/INDUS, ELECT, PHOTONICS, & MAG DEVICE","06/01/2016","05/02/2018","Aaron Mazzeo","NJ","Rutgers University New Brunswick","Standard Grant","Usha Varshney","05/31/2019","$432,000.00","Paul Stansel, George Weng, Assimina Pelegri, James White","aaron.mazzeo@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","ENG","1504, 1517","107E, 108E, 1504, 8028, 9102, 9251","$0.00","Skin, the largest organ of the human body, is essential for human-environment interactions and survival, yet humanoids, prosthetics, and wearable devices continue to lack comparable sensory devices and protection. An ideal synthetic skin must be flexible, scalable, easy to wrap around limbs, able to detect touch and force from surrounding objects, and protect against or limit the spread of microbes. Large-area, skin-like sensors for detecting spatial distributions of touch, pressure, and impact will be useful for a number of applications ranging from civil infrastructure to prosthetics to robotics to structural health monitoring of ground and aerospace vehicles. To enable these future applications, the proposed work will include design rules to aid engineers in scaling up imprint lithography and assembly for roll-to-roll processing of synthetic skins. Lightweight, inexpensive skin will prevent life-threatening disasters, such as those linked to undetected structural damage (e.g., the catastrophic impact damage from loose tiles on space shuttle Columbia). The active antimicrobial protection will sterilize robots, machines, or wearable garments in sterile or contaminated environments. The industrial and artistic collaborators will provide materials and guidance to the research team working toward commercially viable processing and assembly. Undergraduate and high school students will have opportunities to build paper-based devices with skin-like sensing through their participation in the Rutgers Honors College, Byrne Seminars, Aresty Research Center, and the New Jersey Governor's School of Engineering and Technology. <br/><br/>The research objective of this GOALI proposal is to create scalable, skin-like sensing devices made of tunable paper-based composites with capabilities of sensing touch, measuring spatial distributions of forces, and providing plasma-based sterilization.  The fabricated devices will consist of embossed piezoresistive paper sandwiched between two layers of metallized paper. The sensing mechanisms will be passive and interface with an array of attached electrodes. A central hypothesis is that tunable porosity near a critical/percolation threshold in cellulose-based composites containing conductive nanofillers that will dominate large transitions in electromechanical properties in both mechanically elastic and plastic regimes of strain. The specific tasks will include (i) fabrication and imprint lithography of tunable, piezoresistive paper; (ii) modeling electrical properties in paper-based composites bridging the meso and nano scales; (iii) mechanical modeling and characterization to establish design rules for imprint lithography; (iv) disinfecting mechanisms of plasma-based sterilizers with metallized paper; and (v) stacked integration of multiple layers of paper-based materials for combined sensing of touch, pressure, and plasma-based sterilization."
"1526249","CHS: Small: Interactive Haptic Assembly and Docking for 3D Shapes","IIS","Cyber-Human Systems (CHS)","09/01/2015","08/19/2015","Horea Ilies","CT","University of Connecticut","Standard Grant","Ephraim P. Glinert","08/31/2019","$497,499.00","","ilies@engr.uconn.edu","438 Whitney Road Ext.","Storrs","CT","062691133","8604863622","CSE","7367","7367, 7923","$0.00","Haptic human-computer interaction mechanisms and systems play a critical role in a variety of engineering and scientific activities that rely on the fundamental task of virtual object assembly, from protein docking, drug design and tele-surgery, to advanced manufacturing, rehabilitation, robotics, teleoperation and consumer applications.  One of the key long-standing challenges in developing such practical interactive systems is the lack of a proper formulation of the guidance forces that effectively assist the user in the exploration of the virtual environment, from repulsing collisions to attracting proper contact.  A secondary difficulty is that of achieving an efficient implementation that can maintain an acceptable haptic refresh rate.  Current state-of-the art solutions to these open problems have been developed for severely restricted classes of shapes and motions, and rely heavily on heuristics that exploit drastic geometric limitations.  To address these issues, the PI's goal of this research is to develop a purely geometric model for an artificial energy field that favors spatial relations leading to proper assembly of arbitrarily complex shapes.  Project outcomes will lead to effective interaction mechanisms for intelligent human-computer or human-robot systems and will open the doors to the development of generic and fully automated assembly planners while simultaneously unlocking new levels of expression and productivity in activities that rely on interactive assembly tasks in a broad range of industrial, scientific and consumer applications, in domains as diverse as 3D user interfaces, engineering, and medical and assistive technologies.  The PI's industrial partnerships will facilitate aggressive and widespread technology transfer.  <br/><br/>To these ends, the energy function is expressed in terms of a convolution of shape-dependent affinity fields that rely on the novel concept of a space-continuous, well-defined, and robust density function, called the Skeletal Density Functions (SDF), whose sublevel sets in the limit are related to an implicit definition of the medial axis.  Importantly, the proposed energy field leads to the first practical and automatic approach to detect key features that contribute to proper alignment or assembly, as well as the geometric constraints required for virtual assembly.   Moreover, the proposed approach completely avoids the heuristic recipes and manual intervention that are common to existing methods for haptic assembly.  The PI's preliminary results show that this research can unify the two haptic interaction phases of free motion and precision assembly, which are common in current haptic simulations, into a single interaction mode, and suggest a generic and automatic constraint model for the so-called virtual fixtures, with no restrictive assumption on the types of the assembly features and shapes involved."
"1646204","CPS: Synergy: Collaborative Research: Closed-loop Hybrid Exoskeleton utilizing Wearable Ultrasound Imaging Sensors for Measuring Fatigue","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","01/01/2017","06/18/2018","Siddhartha Sikdar","VA","George Mason University","Standard Grant","Wendy Nilsen","12/31/2020","$415,931.00","Parag Chitnis, Wilsaan Joiner","ssikdar@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7918","7918, 8235, 9251","$0.00","The goal of this project is to develop an automated assistive device capable of restoring walking and standing functions in persons with motor impairments. Although research on assistive devices, such as active and passive orthoses and exoskeletons, has been ongoing for several decades, the improvements in mobility have been modest due to a number of limitations. One major challenge has been the limited ability to sense and interpret the state of the human, including volitional motor intent and fatigue. The proposed device will consist of powered electric motors, as well as the power generated by the person's own muscles. This work proposes to develop novel sensors to monitor muscle function, and, muscle fatigue is identified, the system will switch to the electric motors until the muscles recover. Through research on methods of seamless automated control of a hybrid assistive device while minimizing muscle fatigue, this study addresses significant limitations of prior work. The proposed project has the long-term potential to significantly improve walking and quality of life of individuals with spinal cord injuries and stroke. The proposed work will also contribute to new science of cyber-physical systems by integrating wearable image-based biosensing with physical exoskeleton systems through computational algorithms. This project will provide immersive interdisciplinary training for graduate and undergraduate students to integrate computational methods with imaging, robotics, human functional activity and artificial devices for solving challenging public health problems. A strong emphasis will be placed on involving undergraduate students in research as part of structured programs at our institutions. Additionally, students with disabilities will be involved in this research activities by leveraging an ongoing NSF-funded project. <br/><br/>This project includes the development of wearable ultrasound imaging sensors and real-time image analysis algorithms that can provide direct measurement of the function and status of the underlying muscles. This will allow development of dynamic control allocation algorithms that utilize this information to distribute control between actuation and stimulation. This approach for closed-loop control based on muscle-specific feedback represents a paradigm shift from conventional lower extremity exoskeletons that rely only on joint kinematics for feedback. As a testbed for this new approach, the team will utilize a hybrid exoskeleton that combines active joint actuators with functional electrical stimulation of a person's own muscles. Repetitive electrical stimulation leads to the rapid onset of muscle fatigue that limits the utility of these hybrid systems and potentially increases risk of injury. The goals of the project are: develop novel ultrasound sensing technology and image analysis algorithms for real-time sensing of muscle function and fatigue; investigate closed-loop control allocation algorithms utilizing measured muscle contraction rates to minimize fatigue; integrate sensing and control methods into a closed loop hybrid exoskeleton system and evaluate on patients with spinal cord injury. The proposed approach will lead to innovative CPS science by (1) integrating a human-in-the-loop physical exoskeleton system with novel image-based real-time robust sensing of complex time-varying physical phenomena, such as dynamic neuromuscular activity and fatigue, and (2) developing novel computational models to interpret such phenomena and effectively adapt control strategies. This research will enable practical wearable image-based biosensing, with broader applications in healthcare. This framework can be widely applicable in a number of medical CPS problems that involve a human in the loop, including upper and lower extremity prostheses and exoskeletons, rehabilitation and surgical robots. The new control allocation algorithms relying on sensor measurements could have broader applicability in fault-tolerant and redundant actuator systems, and reliable fault-tolerant control of unmanned aerial vehicles."
"1701023","PFI:AIR-TT: LoCATER:Localization and Accountability Technology for Emergency Responders","IIP","Accelerating Innovation Rsrch","06/01/2017","06/09/2017","Taskin Padir","MA","Northeastern University","Standard Grant","Jesus Soriano Molla","11/30/2018","$200,000.00","","t.padir@northeastern.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","ENG","8019","8019","$0.00","This PFI: AIR Technology Translation project focuses on translating research discoveries on autonomous robot navigation to develop a localization and personal accountability report check technology to fillthe need for a geolocation system with acceptable accuracy in GPS-denied environments. The LocATER, a wearable localization and accountability report check technology, has significant commercial, industrial, emergency response and military applications. It will transform operations and efficiency of emergency response teams by providing the incident commanders with a tool to make metric-based response, rescue and recovery decisions.  The LocATER can enhance the safety of personnel working in environments where GPS and WiFi signals are not available.  <br/><br/>The project will result in a low-cost, integrated proof-of-concept of the LocATER. The research team will develop the LocATER technology with three unique features: (i) ability to accurately localize firefighters inside a burning building to a quadrant and floor, (ii) functionality for providing firefighters with a tool to quickly complete an accountability report check, reducing radio traffic and overhead associated with them, and (iii) low-cost, portable, and light-weight design that can operate without external reference signals such as GPS, WiFi or other pre-deployed systems. These features will make the LocATER technology more advantageous in terms of usability, efficiency, efficacy and practical deploymentswhen compared to the leading competing localization technologies in this market space. <br/><br/>This project addresses the following technology gaps as it translates from research discovery toward commercial application. A 2-dimensional simultaneous localization and mapping algorithm will be designed and implemented on an embedded system by fusing the inertial and visual odometry information. The position and velocity data from an inertial measurement unit will be fused with barometric pressure data to determine the floor information. A holistic model-based design approach will be adopted to develop and validate a system that will meet size, weight and power requirements acceptable for emergency responder operating conditions. In addition, personnel involved in this project,undergraduate and graduate students as well as the postdoctoral researchers will receiveentrepreneurship and technology translation experiences throughparticipation in Northeastern's Entrepreneurship Bootcamp, an 8-week program aimed at enhancing participating teams' understanding of technology translation and commercialization. Furthermore, the project personnel will be empowered to attend and participate in the rich lineup of events within the Boston?s robotics and internet-of-things innovation ecosystem.<br/><br/>The project engagesthe Boston Fire Departmenttoseek critical feedback throughout the design process and access to testing facilities, and a number of firefighting equipment manufacturers to identify pathways for integration with existing products in this technology translation effort from research discovery toward commercial reality."
"1355061","IOS: Sensory networks and collective information processing in animal groups","IOS","ANIMAL BEHAVIOR","08/01/2014","08/04/2014","Iain Couzin","NJ","Princeton University","Standard Grant","Karen Mabry","07/31/2019","$325,000.00","","icouzin@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","BIO","7659","9178, 9179","$0.00","Effective information transfer is essential for the coordination of behavior within intracellular, neuronal, social and economic networks. In many animal groups, such as schooling fish and flocking birds, the degree and speed of inter-individual communication allows individual group members to make fast and accurate collective decisions across a range of contexts, and often under conditions of considerable risk. Such emergent properties are highly desirable for many technological applications, including coordinated search, control and response by groups of robotic agents. This project will employ an experimental approach to map the relationship between sensory input and behavioral output in schooling fish under a range of ecologically-relevant scenarios in order to identify the dynamic networks of sensory communication in groups and relate this to the elementary movement behaviors exhibited by individuals, and the highly effective collective behavior exhibited by groups. These results will directly inform collective robotics. Undergraduate and graduate students will be involved in all aspects of this project and it will be integrated into classes taught by Dr. Couzin. Dr. Couzin will also develop a summer learning module on collective behavior for high-achieving, low-income high school students from local school districts in NJ through the Princeton University Preparatory Program (PUPP) and continue to work with National Geographic digital media and National Geographic Learning to engage the public <br/><br/><br/>This project will reveal the complex structure of the networks underlying information flow in groups.  The predominant paradigm has been to consider individuals in such groups as ""self-propelled particles"", which interact with neighbors through ""social forces"".   A major limitation of this approach is that it neither considers the sensory information available to animals when making movement decisions within groups nor considers that organisms make decisions in a state - dependent and probabilistic fashion. To map the relationship between visual and lateral line sensory input and resulting behavior in schooling fish under ecologically-relevant conditions that vary in timescale and type of response, the PI will use custom software to determine the location, body posture and eye positions of members of the group to reconstruct the visual fields of all individuals in groups of up to several hundred fish. Bayesian, unsupervised learning and inverse methodologies will be used to identify the visual information used by individuals and to map the structure of social response facilitated by the lateral line. Multi-scale network analysis will be used to identify important properties and meaningful motifs/substructures within groups, and to relate these to collective capabilities. Information transfer across sensory networks will be quantified using information theoretic techniques under the different ecological contexts. These data will inform subsequent manipulations of individual behavior to test predictions about how groups filter noise and respond to extraneous cues. From this work the researchers will create new models of collective animal behavior."
"1559890","REU Site: Biomaterials Research Initiative Dedicated to Gateway Experiences","DMR","OFFICE OF MULTIDISCIPLINARY AC, XC-Crosscutting Activities Pro, ","09/01/2016","08/26/2016","Eric Mazur","MA","Harvard University","Standard Grant","Lynnette D. Madsen","08/31/2019","$561,976.00","Kevin Parker","mazur@physics.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","MPS","1253, 7222, P226","1359, 1711, 7736, 9178, 9250","$0.00","NON-TECHNICAL DESCRIPTION: This REU Site will introduce students and teachers to research in biomaterials research. The development of personalized health and assistive care technologies relies on understanding the interplay of materials and biology. Students will work on projects in bio-inspired engineering, wound healing and tissue engineering, medical diagnostic and drug delivery technologies, and soft robotics and prosthetic devices. The BRIDGE Program at Harvard has a strong emphasis on gateway students, especially those students with little or no previous research experience. Student recruitment focuses on students from underrepresented groups, students at non-research intensive institutions, and non-traditional students who have re-entered college, in particular veterans of the armed forces. Students and teachers who are deaf/hard of hearing will also be recruited.  Therefore, research projects are designed to be relevant and accessible for military veterans and students with disabilities.<br/><br/>TECHNICAL DESCRIPTION: This REU Site, Biomaterials Research Initiative Dedicated to Gateway Experiences, focuses on the interplay of materials science and bioengineering via 3 themes: (1) Understanding and exploiting bio-inspired nano- and microscale structures; (2) Tunable materials and devices for diagnostics, tissue engineering and drug delivery; and (3) Materials and strategies for soft and adaptive robotics. The research activities include studies that combine experiment with theory and/or simulation in the study and design of interfaces between cells and surfaces; tunable structures, gels and networks; drug delivery systems; tissue culture scaffolds; and multi-functional biomaterials such as photonic and electronic biomaterials. Importantly, the topics are chosen to appeal to a wide population of students who are at early stages of their academic development, and who have limited awareness of career paths. Research projects are also designed to be relevant and accessible for military veterans and students with disabilities.<br/><br/>This site is supported by the Department of Defense in partnership with the NSF REU program."
"1619078","RI: Small: Modeling and Learning Visual Similarities Under Adverse Visual Conditions","IIS","ROBUST INTELLIGENCE","09/01/2016","07/27/2016","Ying Wu","IL","Northwestern University","Standard Grant","Jie Yang","08/31/2019","$440,000.00","","yingwu@eecs.northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7495","7495, 7923","$0.00","In many emerging applications such as autonomous/assisted driving, intelligent video surveillance, and rescue robots, the performances of visual sensing and analytics are largely jeopardized by various adverse visual conditions in complex unconstrained environments, e.g., bad weather and illumination conditions. This project studies how and to what extend such adverse visual conditions can be coped with. It will advance and enrich the fundamental research of computer vision, and bring significant impact on developing ""all-weather""computer vision systems that benefit security/safety, autonomous driving, and robotics. The project contributes to education through curriculum development, student training, and knowledge dissemination. It also includes interactions with K-12 students for participation and research opportunities.  <br/><br/>This research seeks innovative solution to overcome adverse visual conditions for visual sensing and analytics. It explores a unified approach that avoids explicit image restoration that is in general computationally demanding. It is focused on learning the ""alignment"" between the two image spaces under adverse and normal conditions, rather than learn everything from scratch. Acting on low-quality data directly without image restoration, this research leads to innovative and computationally efficient solutions to handle adverse visual conditions. Visual restoration can also be done as by-products, and the same approach also provides a general solution to target attribute estimation. The research is focused on: (1) constructing a principled model, called space alignment that models and learns visual similarity, and its theoretical foundation, (2) developing new effective visual matching and tracking approaches based on learning the appropriate visual similarity under various adverse visual condition, (3) investigating visual attribute estimation and identification via learning reconstruction-based visual regression, and (4) developing effective and efficient tools and prototype systems for visual detection, identification, tracking and recognition."
"1740452","Achieving Consensus Among Autonomous Dynamic Agents using Control Laws that Maintain Performance as Network Size Increases","CMMI","Dynamics, Control and System D","11/01/2016","05/04/2017","Alexander Olshevsky","MA","Trustees of Boston University","Standard Grant","Irina Dolinskaya","04/30/2019","$152,082.00","","alexols@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","ENG","7569","030E, 031E, 032E, 033E, 034E, 035E, 099E, 8024","$0.00","Recent advances in automation and robotics have created a pressing need for new ""protocols,"" that is, for algorithms or control laws that allow teams of multiple autonomous agents to cooperate and accomplish complex tasks. Unfortunately, many of the best protocols for multi-agent coordination problems suffer from scalability issues, that is, while they perform well when the number of agents is small or moderate, their performance degrades sharply as the number of agents in the network grows. This project will develop new control laws for a range of multi-agent problems whose performance is maintained even as network size becomes very large. A number of tasks with broad practical importance will be considered, including optimal distribution of limited resources among agents, cooperative tracking and estimation, and adaptive positioning for optimal sensing. With these new protocols, large groups of autonomous agents(such as mobile robots or unpiloted aerial vehicles) will be able to quickly accomplish a number of useful and important tasks. These advances are needed to allow emerging technologies for autonomous vehicles and other networked autonomous systems to realize their potential economic and societal benefits.<br/><br/>The main technical contribution will be to speed up a widely-used class of nearest neighbor interactions. It is common to optimize a global objective in multi-agent control by means of local updates that interleave the maximization local objectives with consensus terms that effectively couple these objectives. This project will develop techniques to speed up such consensus-like updates. By a judicious combination of weight-selection and extrapolation by each agent, the convergence time of consensus updates will be improved by one or several orders of magnitude. These speedups further imply quick convergence times for a number of multi-agent problems relying on consensus-like updates. The techniques applied mix recent advances from algebraic graph theory, optimization, switched dynamical systems, and the joint spectral radius."
"1721594","STTR Phase I:  SampleStream: A Sample Preparation Platform for Biologics","IIP","STTR PHASE I","07/01/2017","07/10/2017","Philip Compton","IL","Integrated Protein Technologies, Inc","Standard Grant","Henry Ahn","10/31/2018","$224,218.00","Neil Kelleher","pdcompto@gmail.com","2749 Woodbine Ave","Evanston","IL","602011564","6306646423","ENG","1505","1505, 8038","$0.00","This STTR Phase I projects aims to address major limitations in the analysis of pharmaceuticals that are based on proteins, a group of therapeutics known as biologics.  Current methods for sample preparation and analysis of these drugs require highly trained staff and expensive equipment to execute the multitude of different analytical approaches that are employed to characterize these molecules. Both personnel and equipment costs combine to limit the number of drug candidates evaluated by pharma companies, makes it more difficult for regulatory agencies to reproduce data provided in applications and makes it difficult to identify counterfeit drugs. The company aims to address this issue by creating a highly flexible sample preparation device based on a fluidic channel that operates at reduced pressure. Proteins trapped within the channel can undergo digestion, reduction, alkylation and other common sample preparation procedures in an unattended and automated fashion. Subsequently, prepared samples may be eluted at high concentration, ready for downstream analysis.  By dramatically reducing the equipment costs and reducing the required expertise for sample preparation, the company?s technology will have a large impact on the number of drug candidates that are evaluated by pharma companies, it will make it easier for regulatory agencies to reproduce data provided by manufacturers, and it will improve their ability to detect counterfeit drugs. All of these benefits will result in more and cheaper biologics making it to the market, ultimately improving the health and wellness of the populace.<br/><br/>The company?s device combines concepts of diafiltration, asymmetric flow field flow fractionation and filter assisted sample preparation to create an automated sample preparation platform that avoids the use of robotics. By avoiding robotics and high pressure, the platform can operate with increased robustness and dramatically reduced cost. The proposed research aims to demonstrate the ability of the device to perform common sample preparation steps, such as reduction/denaturation, digestion, and deglycosylation and assess issues of reproducibility, reliability and carryover. While many of the workflows described herein have been demonstrated in molecular weight cutoff filters, implementation of these within a fluidic channel will directly advance the company?s understanding of the mechanisms of loss in sample preparation, provide a refined estimate of the cost savings that might be achieved in real world applications, and improve our understanding of transport for small molecules across these membranes."
"1650545","University of South Florida Planning Grant: I/UCRC for iPERFORM Center for Assistive Technologies to Enhance Human Performance","CNS","INDUSTRY/UNIV COOP RES CENTERS","02/15/2017","02/13/2017","Stephanie Carey","FL","University of South Florida","Standard Grant","Dmitri Perkins","01/31/2019","$15,000.00","Rajiv Dubey, Kyle Reed, Redwan Alqasemi, Stephen Sundarrao","scarey3@usf.edu","3702 Spectrum Blvd.","Tampa","FL","336129446","8139742897","CSE","5761","5761","$0.00","The University of South Florida's, Center for Assistive, Rehabilitation & Robotics Technologies (CARRT) will increase the capacity of engineers, researchers and practitioners in the assistive technology and human performance field by becoming a Site in the existing NSF IUCRC iPERFORM Center for Assistive Technologies to Enhance Human Performance. The iPerform Center currently includes the University of Texas at Arlington (UTA) and at Dallas (UTD). CARRT combines research, education and service to improve human performance, including the capabilities of individuals with a disability or of advanced age. Innovations such as virtual reality for job training, intelligent wheelchairs and powered mobility devices, adaptive driving simulators, training systems for rehabilitation after a stroke, and a mobile app to help with decisions about a prosthesis will be explored with industrial partners. USF will also work with the Tampa VA, the Florida Division of Vocational Rehabilitation, the Museum of Science and Industry, Girls Scouts Minds for Design Camp and Florida-Georgia Louis Stokes Alliance for Minority Participation in order to promote science, engineering and entrepreneurship to a broad audience. Real world problems associated with assistive technologies and enhancing human performance will be integrated into courses such as Capstone Senior Design, Human Factors, Rehabilitation Engineering, Haptics and Bioastronautics motivating future scientists and engineers in the field. USF's student chapters such as the Biomedical Engineering Society will also help in the development and implementation of the research projects related to the goals of the iPERFORM Center.<br/><br/>The objective of this planning grant is to establish the University of South Florida (USF) as a Site addition to the existing iPERFORM Center. USF's CARRT has expertise in integrating research, education and service with a strong record of interdisciplinary and inter-institutional collaborative research that has led to the development of novel assistive, rehabilitation, wearable and robotics technologies. USF's team has expertise in the human testing of assistive technologies that is necessary to improve designs and make them commercially viable. USF has several motion capture systems including two that are implemented into virtual reality systems that allow for testing in realistic environments safely while providing controlled and repeatable testing protocols. This allows for quantitative data that can improve assistive technologies and prepare them for market necessary to attract industry partners. USF's capabilities are synergistic to the focus and goals of the existing NSF IUCRC iPERFORM Center that include attracting support towards the commercialization of assistive technologies and promoting innovation in academia that is driven by customer and industrial needs. Through USF CARRT's integrated holistic model in which engineers and scientists work with clinicians, rehabilitation practitioners and artists, a unique structure for research and development will strengthen the iPERFORM Center."
"1557672","Biocomponent Devices: Developing Actuators from Insect Muscles","IOS","Physiolg Mechansms&Biomechancs","05/15/2016","05/09/2018","Barry Trimmer","MA","Tufts University","Continuing grant","Kathryn Dickson","04/30/2019","$616,724.00","David Kaplan","barry.trimmer@tufts.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","BIO","7658","9178, 9179","$0.00","All human-made devices, from the very first pre-historic tools to present day robots, have been constructed from non-living materials, most of which are very stiff and synthetic. To make modern devices more suitable for use in close proximity to humans and for work in natural environments it is important that we find new ways to build machines that are biologically compatible, biodegradable, environmentally safe and able to interface with tissues. A major challenge for making such biologically compatible machines is that there are no suitable motors (actuators) to make them move. Attempts to use muscle cells derived from animals such as frogs and mice have had limited success because vertebrate tissues require an intricate blood system and they are easily damaged by changing environmental conditions. It is also hard to replicate the conditions found in a vertebrate embryo that make muscles grow appropriately. This research introduces a new biological approach to making such actuators by growing them from insect cells produced during metamorphosis. Adult insect tissues (such as flight muscles) form directly on existing larval tissues and their growth can be controlled using simple manipulations of insect hormones. Preliminary studies show that insect muscles can be grown in culture at room temperature and that they will survive for many months. This research will identify the conditions needed to generate powerful insect muscles and develop methods to grow them for use in living machines. Successful completion of this work will lead to the production of an engineered muscle that can be sustained for several months and that can generate forces ten times greater than current muscle actuators grown in culture. The work will have wider implications in revealing some of the processes (genetic, biochemical and hormonal) that lead to the re-programming of cells that must occur as part of insect metamorphosis. This is expected to stimulate new experimental approaches to studies of tissue specification, growth and repair.<br/> <br/>These studies will test the hypothesis that fully formed tissues can be grown ex-vivo from metamorphic cells of the tobacco hawk moth Manduca sexta. Using the dorsal longitudinal (flight) muscles (DFM) as a target tissue the experiments will focus on four main goals: 1) To characterize the physiological and molecular changes that accompany DFM formation during metamorphosis and in culture. Measurements will be made of in vivo changes in electrical characteristics and the contractile properties using isometric/isotonic tests and dynamic work loops. The gene expression profile (transcriptome) of developing muscles and growing explants will be compared at different stages to help identify gene networks associated with Manduca muscle formation. 2) To characterize the roles of local (cell-cell, mechanical) and systemic (circulating) factors in muscle specification, differentiation and growth. This will involve tissue excision and cross stage transplant methods that are well established for insects. 3) To recapitulate the normal formation of adult dorsal flight muscles from larval precursors in culture by engineering the hormonal and substrate conditions. The transcriptomes of the in-vitro muscles will be compared with both native larval and adult DFMs to look for changes in key developmental and physiological gene networks. 4) To grow and maintain muscle constructs in-vitro for practical actuator applications. The goal is to engineer a muscle that can be sustained for several months and that can generate stress an order of magnitude better than current in-vitro muscle actuators by maximizing survival, cell proliferation and eventual differentiation. It is expected that this process will produce densely packed muscle fibers that can be used for high-stress actuators. The unified contraction of these fibers will be controlled by growing them on micro-electrode arrays or though the expression of light-sensitive channels such as ChR2. This research will engage graduate students in cross-disciplinary research in soft robotics."
"1660145","SBIR Phase II:  Advancing Beyond the Photodiode - Deep Sub-micron Pixels for Next-generation Image Sensors","IIP","SMALL BUSINESS PHASE II","04/01/2017","01/05/2018","Renee Carder","IL","PixelEXX Systems, Inc","Standard Grant","Richard Schwerdtfeger","03/31/2019","$768,000.00","Kenneth Bradley","rcarder@pixelexx.com","8725 W Higgins RD, STE 290","Chicago","IL","606312736","6308653177","ENG","5373","094E, 116E, 5373, 8035, 8240, 9231, 9251","$0.00","This Small Business Innovation Research Phase II project focuses on developing compact camera modules with lower noise and improved contrast using a submicron pixel imaging sensor array. The commercial potential of this project centers on developing compact cameras for endoscopes, navigational and robotic surgical systems and more. Embedding these cameras in endoscope systems, and even the surgical tools themselves, permits new treatments across a broad range of medical specialties that otherwise are not possible. Switching to the minimally invasive forms of some common surgeries could save an estimated $14 billion in healthcare spending. Oncology, urology, gastroenterology, women's health and pediatric medicine are just some of the specialties that will significantly benefit from these ultra-compact cameras. A broader impact will ultimately come from utilizing submicron pixels in unique ways in high density arrays. The sensor?s small size and fast response times offer unique opportunities for spatial and temporal oversampling. The resulting large numbers of pixels can be employed in a compact multi-aperture arrangement to deliver significantly enhanced color mapping over traditional semiconductor imaging arrays, multispectral imaging, 3-dimensional image reconstruction, motion free auto-focusing, or some combination of the above, providing unique applications in medical imaging, defense, robotics, and consumer electronics.  <br/><br/>The miniaturization of camera systems calls for the continuous shrinking of pixel sizes. At a certain point, however, the maximum photo-electrons a pixel can hold becomes limited, yielding lowsignal-to-noise ratios and poor dynamic range. This project develops a novel optical sensor that maintains sensitivity down to hundreds of nanometers. As the size of this sensor decreases, the maximum measurable light intensity can remain constant and the signal-to-noise increases, bringing significant improvements to images? dynamic range and color/feature rendition. This result stands in stark contrast to the behavior of conventional pixels where maximum intensity threshold scales down with pixel size and noise increases with decreasing pixel size. Reducing these image sensors to practice requires transitioning from gallium arsenide based devices to silicon.  The work focuses on 1) finalizing design parameters, fabrication, and characterization of the electrical properties and optical response of the system and 2) fabrication and characterization of a linear photodetector array for the creation of both linear images and 2-D images assembled from linear images to characterize the noise, contrast and other image quality parameters of the prototype."
"1730183","CRI II-NEW: IIS: Omniview Multi-modal Sensor Laboratory for Understanding Human Interactions in Ubiquitous Environments","CNS","COMPUTING RES INFRASTRUCTURE","06/01/2017","04/28/2017","Sean Banerjee","NY","Clarkson University","Standard Grant","Dan Cosley","05/31/2020","$746,916.00","Natasha Banerjee","sbanerje@clarkson.edu","8 Clarkson Avenue","Potsdam","NY","136761401","3152686475","CSE","7359","7359","$0.00","Understanding how people interact with objects and with each other is an important research area in human-computer interaction, particularly in contexts where phones, cameras, sensors, voice assistants, robots, and other computing devices help people accomplish their goals.  To study these interactions, this project will equip a lab with state of the art equipment for capturing human activity that doesn't require attaching markers, wires, or sensors to people, and develop software to manage the large amounts of captured data and interfaces that help researchers and designers make use of the data.  Much of the envisioned fundamental research will focus on how age, gender, physical ability, and experience level affect the way people interact with objects, as well as on using social cues such as emotions, inter-person distances, and gestures to understand how people interact with each other.  A number of researchers at the lead investigators' institution will use the lab for related projects around people- and object-aware technologies, including assistive robotics, self-driving vehicles, teams and collaboration, and smart environments.  The lab will also provide training for a postdoctoral researcher and research opportunities for undergraduates, support a number of courses taught at the PIs' institution, and provide new opportunities for interdisciplinary research.<br/><br/>The PIs will develop a temporally synchronized and spatially calibrated sensor system that includes force plates, microphones, RGB and infrared cameras, and Kinect sensors, and deploy it in 20x20x12 foot lab.  Data will be synchronized using linear time codes (LTCs), including custom hardware previously developed by the PIs to add LTC data to Kinects, and managed by a large cluster of computers and network attached storage devices.  The infrastructure will use computer vision and sound reconstruction algorithms on the raw sensor data to reconstruct 3D spatiotemporal data that provides a full range 3D visualization of human interactions.  By combining data from multiple sensor modalities in 3D, the infrastructure enables research in strengthening recognition of gestures and emotions of people engaged in interactions by analysis of prosody changes, face points, body skeletons, spatiotemporal motions, linguistics, heat signatures, and emotion- or task-driven physical impact.  Further, the PIs will develop large repositories of omniview multi-modal 3D spatiotemporal data, and conduct research on tying these repositories to sensors on next-generation ubiquitous devices to make them people- and object-aware."
"1503742","Scholarship Track: Scholarships for Service at WPI","DGE","CYBERCORPS: SCHLAR FOR SER","01/01/2015","05/03/2018","Kathryn Fisler","MA","Worcester Polytechnic Institute","Continuing grant","Victor P. Piotrowski","12/31/2020","$2,798,831.00","Robert Walls, Craig Shue, Suzanne Mello-Stark, Craig Wills, Susan Landau","kathryn_fisler@brown.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","EHR","1668","1668, 7254, 7434, 9178, 9179, SMET","$0.00","This project seeks to establish a new CyberCorps: Scholarship for Service (SFS) program at the Worcester Polytechnic (WPI) Institute to prepare highly-qualified Cybersecurity professionals for entry into the federal, state, local, and tribal government workforce.<br/><br/>The proposed CyberCorps: SFS program features (a) coursework that includes technical courses, a business course, and at least one course on human-facing aspects of cybersecurity; (b) opportunities to participate in research projects; and (c) a monthly seminar series on ??Working in Cybersecurity for the Government??. WPI also has existing collaborations with two nearby federal labs, MITRE and Lincoln Labs, and its interdisciplinary graduate programs in Robotics, Interactive Media and Game Design, Data Science, and Learning Sciences offer scholars the opportunity to connect cybersecurity studies with other emerging computational fields. WPI is designated as a National Center of Academic Excellence in Information Assurance Research with a dozen faculty across four departments with active research programs related to cybersecurity. A team consisting of two Program Directors, a program manager, and several security faculty will manage the operations and assessment of the program. The project has clear objectives for both scholars and project operations, along with the measurements that will assess progress towards the objectives. CyberCorps students will take a security-themed course with a significant focus on human behavior, privacy and policy extending beyond purely technical aspects of cybersecurity.<br/><br/>All SFS-Scholarship awards share broader impacts on cybersecurity workforce development.<br/>The planned recruiting activities will engage hundreds of students and may motivate more students in pursuing at least some level of cybersecurity education. The proposed seminar series will be open to the public. The recruiting plans include participating in established WPI outreach programs to high-school students, summer residential programs to engage students in STEM and an annual WPI science and technology festival that centers on a NASA robotics challenge. The project has a strong plan for recruiting women and other under-represented students."
"1566186","CRII: RI: Accelerated Stochastic Approximation for Reinforcement Learning","IIS","CRII CISE Research Initiation, ROBUST INTELLIGENCE","06/01/2016","06/10/2016","Martha White","IN","Indiana University","Standard Grant","Weng-keen Wong","12/31/2018","$182,616.00","","martha@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","026Y, 7495","7495, 8228, 9251","$0.00","This project develops a new class of accelerated learning techniques for reinforcement learning. Reinforcement learning is an approach to autonomous decision-making through trial-and-error interaction with an unknown environment, with a focus on learning incrementally from this stream of data. Reinforcement learning has significant industrial potential, particularly for real-time control systems, such as active network management for energy and search-and-rescue robots, and is already used in a wide range of fields, including robotics, psychology, animal learning and neuroscience. To improve the practical application of reinforcement learning, this project proposes a new class of algorithms with the goal to balance computational complexity and the sample efficiency of learning, which often requires significant computation and memory. This space of algorithms that attempt to balance both requirements has been under-explored for reinforcement learning, and provide exciting opportunities to impact industrial applications and the growing area of computational sustainability. An important aspect of this project will be to implement and study these algorithms on a wide-range of simulated environments, and engage a diverse group of students through courses and summer research.<br/><br/>This project develops efficient incremental approximations to summarize gathered samples for improved sample efficiency and an empirical framework to evaluate these algorithms. This new class of accelerated learning techniques formally trade-off computation and accuracy and have many promising extensions and research directions, through a variety of accelerated stochastic gradient descent techniques and incremental matrix approximations. Further, another focus is to develop tools and novel measures for the reinforcement learning community that evaluate this balance between sample efficiency and computational complexity, with the code framework released through an existing open-source platform. This initial systematic exploration of these novel optimization variants will lay the foundation for the long-term goal of improving efficacy of reinforcement learning in industry and for practical autonomous agents."
"1657595","CRII: CHS: Constraint Consistent, Task-Based Musculoskeletal Control Framework for Human Motion Synthesis and Immediate Feedback","IIS","CRII CISE Research Initiation","04/01/2017","03/02/2017","Emel Demircan","CA","California State University-Long Beach Foundation","Standard Grant","Ephraim P. Glinert","03/31/2019","$174,777.00","","Emel.Demircan@csulb.edu","6300 State Univ. Dr.","Long Beach","CA","908154670","5629858051","CSE","026Y","7367, 8228","$0.00","The goal of this research is to create a cyber-human framework that advances both robotics and biomechanics, by deepening our scientific understanding of human motor performance dictated by musculoskeletal physics and neural control, in order to assist clinicians in quantifying the characteristics of a subject's motion and designing effective motion training treatments.   Current technologies do not permit detailed motion reconstruction in real time, which limits their use in clinical settings.  This work will combine theory with software, hardware and sensing technology to synthesize human motion with dynamic, actively controlled subject-specific musculo-skeletal models and to provide real-time visual feedback to a human subject.  The project will deliver open-source algorithms and metrics for quantifying human performance and for understanding the underlying motion characteristics that modify these metrics.  The capabilities developed in this project will have a transformative impact on society by enabling real-time human motion synthesis, with potential applications in rehabilitation, physical therapy, human-robot interaction, kinesiology and occupational biomechanics.  The new control framework and models, validated by motion capture experiments, will be disseminated to researchers through an online repository.  Integration of the research with educational activities will equip involved undergraduates and underrepresented students with new insights and tools for developing future engineering research in a minority serving institution.<br/><br/>Project outcomes will include: (1) computational models of the human musculoskeletal system for task-based control; (2) integrated performance metrics for motion characterization based on a subject's physiological constraints; and (3) control and simulation algorithms to synthesize movement using biomechanical models that accurately match experimental data, compensate for measurement errors, and visualize the model and its motion in real time.  To these ends, task-based models of human motion will first be created.  Motion capture experiments will be conducted to validate the model and to fine tune subject-specific parameters.  The resulting computational platform will then be used to determine long-term performance statistics and metrics to efficiently characterize human motion.  In the second phase, robust control and simulation algorithms will be integrated with the computational system to synthesize movement using biomechanical models.  The framework will be used to identify feasible modifications to improve subject-specific motion characteristics.  Finally, these criteria will be integrated into a feedback mechanism that will visually suggest modified trajectories for optimal motion to the subject."
"1634298","Collaborative Research: Persistent Presence in the Ocean Interior: Developing a Low-power, Autonomous System for Geo-referenced Navigation","OCE","OCEAN TECH & INTERDISC COORDIN","01/01/2017","08/31/2017","James Kinsey","MA","Woods Hole Oceanographic Institution","Continuing grant","Kandace S. Binkley","12/31/2019","$480,524.00","Lee Freitag, Chris German, James Partan, Michael Jakuba","jkinsey@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","1680","","$0.00","Facilitating an accurately navigated persistent presence for the interior of the deep ocean has the potential to transform how oceanography is conducted.  This capability is currently not provided by existing technologies; however, if developed would transform the scope of projects undertaken by underwater vehicles with longer range and endurance than can currently be deployed unsupported from research ships.  This research develops a new low power navigation system that improves navigational accuracy from 1000s of meters to 100s meters.  This advance will enable multiple new lines of oceanographic investigation.  Examples include deployment of coordinated glider fleets to investigate complex physical-biogeochemical interactions; deep studies of topographically induced mixing; long-range characterization of seafloor habitats/ecosystems at the scale of entire ocean basins; and better resolution of the scales of bottom-boundary-layer processes in regions with steep underwater terrain.   The researchers will engage in outreach activities including undergraduate participation in our research and continuation of established collaborations with local high school robotics and environmental science classes. <br/><br/>This research develops and tests a low-power acoustic positioning system that enables accurate externally aided navigation in the deep ocean.  A glider (or fleet of gliders) operates at depth while an autonomous surface robot (ASV) follows on the sea surface. The ASV transmits its geo-reference position to the gliders at a regular interval. Each glider  then independently employs a precision time base (provided by chip-scale atomic clocks) and array processing to determine its position relative to the ASV. Each ASV combines this relative position estimate with the ASV's position encoded in the received packet to compute its geo-referenced position. System performance depends on a number of factors including the precision of vehicle attitude sensors. Accuracies of 250-400m are possible at 5000m depth using low-power sensors already in use on the glider. Hence, for deep-diving gliders, this method will provide a 10-100 fold improvement in positioning accuracy over the current paradigm (i.e., infrequent GPS fixes) and would allow vehicles to spend more time at depth making relevant observations. This research will enable new operating paradigms, advance observational capabilities and facilitate spatially denser observations than were previously possible. Furthermore, the new system will also improve the ability to estimate depth-averaged ocean currents. The developed capability is also a prerequisite for coordinated motion control of multiple deep-diving AUGs, further increasing the density and cadence of deep ocean observations, providing an ever closer-to-synoptic view of the deep ocean interior.  The developed system will be tested first in the tank and then in two ocean cruises including a Year 3 deployment on a Seaglider."
"1352373","CAREER:Predicting the Surface Structures of Crystalline Materials","DMR","CONDENSED MATTER & MAT THEORY","03/01/2014","03/09/2018","Tim Mueller","MD","Johns Hopkins University","Continuing grant","Daryl W. Hess","02/28/2019","$400,000.00","","tmueller@jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","MPS","1765","1045, 7433, 8084","$0.00","TECHNICAL SUMMARY<br/><br/>This CAREER award supports the development and application of machine learning and data mining methods to predict the surface structures of crystalline materials in a variety of chemical environments.  The PI will develop a three-step process which is designed to minimize the computational expense of predicting surface structures by maximizing the re-use of existing data.  In the first step, evolutionary algorithms will be used to develop a re-usable library of likely surface reconstructions for bulk structure types.  In the second step a combination of evolutionary algorithms and data mining methods will be developed to determine the most likely surface structures for a particular material surface.  In the third step, ab-initio calculations and cluster expansions will be used to identify the particular surface structures with the lowest energy.  The structure prediction process will be developed, validated, and applied to three technologically important systems: perovskite-structured oxides, Au-Pd alloys, and spinel-structured oxides.  <br/><br/>The research will be integrated with an educational outreach program that is designed to strengthen the pipeline of researchers who have both the interest and ability to discover and design new materials through computational research.  At the elementary school level, the PI has volunteered to partner with a master teacher at a majority-minority, low-income Baltimore City public school to share scientific knowledge, help construct an effective curriculum, and design a hands-on exercise intended to educate and excite students about STEM activities.  At the middle school level, the PI will teach computer programming skills to Baltimore City students who are participating in a VEX robotics competition.  At the high school level, a female student from a nearby high school will participate in the research project as member of the research team.  The PI will work with the graduate student to develop an online tutorial that covers fundamental topics in materials surface science, and elements of this tutorial will be integrated into the core curriculum of the Department of Materials Science and Engineering at Johns Hopkins University.<br/><br/>NONTECHNICAL SUMMARY<br/><br/>This CAREER award supports the development and application of advanced computational and data mining methods to predict how atoms are arranged on the surfaces of materials.  The ability to use computers to predict the properties of material surfaces will facilitate the design of new materials for a wide range of technologies including batteries, catalysts, and sensors.  However before a property of a surface can be predicted, it is first necessary to predict the atomic structure, or how the atoms are arranged, on the surface.  The PI will address this challenging problem by developing a method to accurately predict material surface structures with low computational cost.  This will be accomplished by combining a variety of computational tools in a way that leverages existing knowledge about the surface structures to predict the surface structure of a new material.  The method developed in this research will be used to predict the surface structures of three representative classes of materials that were chosen for their importance in technologies such as batteries and catalysts. <br/><br/>The research will be integrated with an educational outreach program that is designed to strengthen the pipeline of researchers who have both the interest and ability to use computers to discover and design new materials.  At the elementary school level, the PI has volunteered to partner with a master teacher at a majority-minority, low-income Baltimore City public school to share scientific knowledge, help construct an effective curriculum, and design a hands-on exercise intended to educate and excite students about science and engineering.  At the middle school level, the PI will teach computer programming skills to Baltimore City students who are participating in a robotics competition.  At the high school level, a female student from a nearby high school will participate in the research project as member of the research team.  The PI will work with the graduate student to develop an online tutorial that covers fundamental topics in materials surface science, and elements of this tutorial will be integrated into the core curriculum of the Department of Materials Science and Engineering at Johns Hopkins University."
"1553333","CAREER: Optimizing Computational Range and Velocity Imaging","IIS","ROBUST INTELLIGENCE","02/01/2016","02/13/2018","Gordon Wetzstein","CA","Stanford University","Continuing grant","Jie Yang","01/31/2021","$240,107.00","","gordon.wetzstein@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","1045, 7495","$0.00","This project focuses on developing optimized hardware and software implementations for emerging computational range and velocity imaging. Today, the primary technologies for capturing range and velocity are radar and lidar. These offer a very high precision, but available systems are expensive, bulky, and slow, because they sequentially scan scenes in a point-by-point manner. Time-of-flight (ToF) cameras have emerged as inexpensive and fast alternatives. ToF cameras use active, temporally-modulated illumination and coded, in-pixel sensing to estimate the distance between the camera and each scene point in three dimensions (3D). Recently, simultaneous range and velocity imaging techniques were demonstrated for the first time with ToF cameras. A major roadblock for unlocking the full, transformative potential of range and velocity imaging has been the limited access to low-level sensor and illumination functionalities of commercially-available ToF cameras. Range (or depth) and velocity imaging enables computers to sense and understand the world and 3D scene dynamics. A wide range of applications in medical imaging, defense, human-computer interaction, and robotics rely on depth and velocity information to perform domain-specific tasks, such as object detection, tracking, localization, mapping, and motion analysis.<br/><br/>This research makes computational range and velocity imaging practical by optimizing the speed, resolution, precision of depth and velocity estimation, 3D imaging capabilities, and photon sensitivity of emerging computational imaging systems in direct and non-line-of-sight scenarios. By analyzing the fundamental limitations and benefits of time-resolved imaging systems, optimized hardware implementations and reconstruction algorithms are devised that facilitate novel range and velocity sensing capabilities and make them practical (i.e. robust, inexpensive, and reproducible). The anticipated insights and contributions advance knowledge and gain an understanding of the limits of time-resolved computational imaging and how to practically achieve them. The developed computational imaging systems and mathematical models are expected to provide fundamentally new building blocks for a diversity of applications in computer and machine vision, medical imaging, microscopy, scientific imaging, remote sensing, defense, and robotics."
"1564692","ABI Innovation: Robotics-inspired modeling & design of proteins","DBI","ADVANCES IN BIO INFORMATICS","04/15/2016","03/17/2016","Tanja Kortemme","CA","University of California-San Francisco","Standard Grant","Peter H. McCartney","03/31/2019","$942,675.00","","kortemme@cgl.ucsf.edu","1855 Folsom St Ste 425","San Francisco","CA","941034249","4154762977","BIO","1165","1165","$0.00","This research will permit researchers to design proteins that have new functions, using software tools that improve the success of the production process. By testing and improving the design steps it will also allow researchers and engineers to produce proteins that have functions more complex than could be made before: these new activities have enormous potential to advance basic research and biotechnology. Proteins perform a vast array of complex and important functions in cells and in technology settings: they can speed up the rate of chemical reactions by several hundred fold, they are responsible for how cells communicate, and they are the basic material for building cell structures and tissues. The advantages to designing proteins instead of using those already known include being able to modify what by-products are made so that there is less damage to the environment, make low-toxicity sensors that can probe the action of living cells in real time, and create unique materials that form defined structures at the nanoscale. To ensure the methods are widely available, all approved computational methods will be available as source code via the Rosetta software suite. This software is free of charge for academic users, and is commonly licensed by biotechnology and pharmaceutical companies. The new methods developed under this grant will also be used in classrooms for team-based projects and for interdisciplinary research activities that emphasize collaboration between students in the biological and physical/engineering sciences.<br/><br/>This research aims to address a principal barrier in computational protein design: the lack of computational approaches that predict both sequence and structural changes with sufficient accuracy. Design methods change the protein sequence but in the vast majority of cases allow only minimal structural adjustments. Yet conformational changes not captured by current methods are the rule rather than the exception, and a main reason for failed designs. Moreover, new conformations might be required to engineer new functions, e.g. to reshape an existing functional site to accommodate a different binding partner. Finally, many proteins undergo functional conformational changes, such as molecular switches or enzymes and protein machines that cycle between conformational states; such complex activities are currently not designable. Aim 1 seeks to advance methods to model changes in protein structure, and address challenges in both generating relevant protein conformations and distinguishing correct from incorrect predictions; established and new benchmarks will be used to assess limitations and quantify improvements. Aim 2 will develop an approach to design new functions that require substantial changes in protein conformation. The approach will be tested by experimental forward-engineering applications. Aim 3 will provide ""protocol capture"" documentation for tested methods and utilize developed methods in educational and research activities that seek to broaden participation. Validated methods will be available as source code via<br/>https://www.rosettacommons.org."
"1606895","Collective Ecophysiology and Physics of Social Insects","PHY","PHYSICS OF LIVING SYSTEMS","09/15/2016","09/15/2016","Lakshminarayana Mahadevan","MA","Harvard University","Standard Grant","Krastan B. Blagoev","08/31/2019","$474,291.00","","lm@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","MPS","7246","8091","$0.00","Insects are the most diverse species on our planet, numbering more than five million different types, and have exploited nearly every terrestrial and many aquatic and aerial niches. Social insects, those that form cooperative societies with specialized castes based on division of labor, for example, afford spectacular examples of collective behavior in such instances as termite mounds, locust swarms and bee clusters and hives. These collective architectures are functional and allow the organisms to maintain a relatively uniform micro-environment even with a variable macro-environment. Understanding how this is achieved in a variety of climates and environments is not just a problem in ecology or physiology, but also one in physics, given that they exchange information, energy and matter continually with the environment. The study looks at the collective dynamics of bee colonies that maintain their temperature in a closed environment using active ventilation driven by fanning, and the structural dynamics of actively adherent bee clusters that can respond to vibrotactile stimuli by changing their shape. While current studies in active matter primarily focus on the patterns in space and time that result from interactions, the new experimental and theoretical approaches will focus on how active systems can perform functions by coupling form, flows and forces in the presence of feedback. Organisms live in varying environments and must therefore be able to tolerate variations in the macro-environment they inhabit. They do this by creating niches that damp out the large scale variations without completely isolating themselves. Outside human societies, nowhere is this better seen than in social insects. The current study takes a quantitative physical approach to the problem, building on the empirical information obtained by biologists. It aims to partially break down the artificial barrier between physics and biology, i.e. between non-living and living matter by showing how living matter shapes itself and its physical non-living environment to achieve function. By synthesizing aspects of hydrodynamics, statistical mechanics and decision making for active matter systems, the research will thus have impact on a range of biological and engineered systems where behavior and decision making come together with flows and forces.<br/><br/>The collective behavior of the organisms creates environmental micro-niches that buffer them from environmental fluctuations e.g. temperature, humidity, mechanical perturbations etc., thus coupling organismal physiology, environmental physics and population ecology. The current study proposes to use a combination of biological experiments, theory, computation and robotic biomimicry to understand how a collective of bees can integrate physical and behavioral cues to attain a non-equilibrium steady state that allows them to resist and respond to environmental fluctuations of forces and flows. The researchers will analyze how bee clusters change their shape and connectivity and gain stability by spread-eagling themselves in response to mechanical perturbations, using a combination of optical and x-ray imaging techniques. Similarly, the researchers will study how bees in a colony respond to environmental thermal perturbations by deploying a fanning strategy at the entrance that they use to create a forced ventilation stream that allows the bees to collectively maintain a constant hive temperature. When combined with quantitative analysis and computations in both systems, the researchers will integrate the sensing of the environmental cues (acceleration, temperature, flow) and convert them to behavioral outputs that allow the swarms to achieve a dynamic homeostasis, that will be tested using collective robotics using simple agents that can sense each other, their environment and move in response to both cues."
"1564678","Collaborative Research: ABI Development: A User-friendly Tool for Highly Accurate Video Tracking","DBI","ADVANCES IN BIO INFORMATICS","08/01/2016","07/20/2016","Matthew Jones","CA","University of California-Santa Barbara","Standard Grant","Peter H. McCartney","07/31/2019","$86,443.00","","jones@nceas.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","BIO","1165","","$0.00","Biological science has made great strides recently both by capitalizing on automated methods of data collection and by enabling researchers to share results efficiently via public databases. This project will achieve the same for applications that use videos to track movement of animals, cells, or robots, by producing freely available software for efficient and automatic extraction of movement data and directly adding such data to a public database (the KNB Data Repository). The software will be easy to use and adapt to new types of videos, issues that have so far been roadblocks to widespread adoption of existing video tracking tools. The ability to share both movement data and videos will stimulate collaboration among researchers. Both functionalities will enable fundamentally new advances in such areas as animal group behavior, behavioral genetics, cell biology, and collective robotics, and other fields that record the movements of many individuals. The software, because of its ease of use and enabled access to research videos from the database, will also serve as a tool in teaching at the K-12 and college level. In addition, this project will serve to train several college and graduate students in both biology and computer science; such interdisciplinary training is essential for advances in biological research today.<br/><br/>This project will implement a unique combination of clear, current graphical user interface design to improve usability with state-of-the-art machine learning techniques to improve movement tracking accuracy. In addition, the developed software will enable users to visualize results for validation and analysis, and include functionality for users to correct any remaining tracking errors. This will enable users to get scientific-quality data output without having to employ multiple software applications and without having to manually post-process data files. In the context of the project, several workshops will be held and a website developed to improve accessibility for students and researchers in biology. The project will also develop a direct link to the existing KNB scientific data repository, such that users can access the repository, compare their results, or complete meta-analyses easily. Besides advancing biological research, this will also generate an extensive resource for computer vision scientists by providing a large collection of videos with accurate user annotation for improving core algorithms such as object detection and tracking.  More information may be found at http://www.abctracker.org."
"1660979","Manufacturing of Engineered Materials with User-Specified Microstructures using Freeze Casting and Ultrasound Directed Self-Assembly","CMMI","Manufacturing Machines & Equip","04/15/2017","01/19/2018","STEVEN NALEWAY","UT","University of Utah","Standard Grant","Steven R. Schmid","03/31/2020","$367,601.00","Bart Raeymaekers","steven.naleway@mech.utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","ENG","1468","082E, 083E, 116E, 9178, 9231, 9251","$0.00","Lightweight and strong structures are needed for many engineering applications such as aerospace composites, biomedical implants, and advanced robotics. Existing techniques for creating these structures are often limited to specific types of materials (such as polymers for fused deposition modeling), and therefore cannot work for all applications where different material properties might be necessary. This award supports fundamental research into the combination of freeze casting, which uses growing ice crystals to create porous structures, and ultrasound directed self-assembly, which uses pressure waves to align and strengthen structures. This combined process will be used with ceramic (TiO2, Al2O3, and ZrO2), polymer (chitosan), and metal (Ti) materials to create lightweight and strong structures. Specifically, experiments will be conducted that demonstrate the basic science involved, including a proof-of-concept of the process, careful measurement of material properties, a measure of the statistical variability of the structures created by this process, and the ability to use this process to make strong structures out of TiO2 ceramics that use bio-inspired microstructures. The results of this work will be a new manufacturing process that can be used to create lightweight and strong structures out of ceramics, metals, and polymers. Once demonstrated, the project has direct applicability to biomedical implants, high strength-low density structural composite materials for robotics, and water filtration systems, among many others. This award will train three graduate students and numerous undergraduate students researchers who will gain valuable experience and have the opportunity to publish and present their research. This award will also fund an interactive module on advanced material fabrication and bioinspired design as part of a summer camp for high school girls aimed at increasing the participation of women and minorities in engineering. At the completion of this award, this module will be converted into a self-contained workshop that will be available for K-12 teachers to bring these concepts to their classrooms.<br/><br/>The objective of this research is to conduct basic research on a new manufacturing process that combines freeze casting and ultrasound directed self-assembly, and the mechanical properties of the resulting porous, engineered materials fabricated using this process. To demonstrate the process, a new experimental setup will be built that allows for freeze casting and ultrasound directed self-assembly to simultaneously control the fabrication of an engineered material. Experiments will be carried out that demonstrate the process by testing ceramic (TiO2, Al2O3, and ZrO2), polymeric (chitosan), and metallic (Ti) constituent materials at concentrations of 10 to 20 vol.% and particle sizes of 0.2 to 20 micrometers. The specimen-to-specimen statistical variability of these materials will be investigated. Finally, bio-inspired microstructures will be  manufactured by varying the ultrasound directed self-assembly frequency between 0.5 to 10 MHz, initially using TiO2 as the material. In all cases, the extent to which the materials have been tailored will be structurally imaged and analyzed using SEM and micro-computed tomography (micro-CT), and mechanically tested in compression."
"1351687","CAREER: Midfield Wireless Powering of Subwavelength Probes for Neuroscience and Cardiology Applications","ECCS","COMMS, CIRCUITS & SENS SYS","01/01/2014","12/12/2013","Ada Shuk Yan Poon","CA","Stanford University","Standard Grant","Jenshan Lin","12/31/2018","$400,000.00","","adapoon@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","ENG","7564","096E, 1045","$0.00","Intellectual Merit<br/><br/>Electronics provide powerful capabilities when interfaced with the body. Their miniaturization over the past few decades has paved way for tiny devices capable of biological sensing or stimulation, and hold promise for restoring physiological functions in patients. Although electronics can be made extremely small, existing methods for powering them involve large batteries or energy harvesting modules. The size of these powering components severely constrains the integration of electronics in living systems. The research in this proposal aims to overcome these challenges and enable arrays of optoelectronic probes small enough to be directly injected into the body. Routes to miniaturization are provided by the midfield wireless powering approaches recently established in the PI's lab. These approaches allow the transfer of power to nearly any location in the body at performance levels far exceeding requirements for both complex electronics and physiological stimulation. The research combines a fundamental understanding of power transfer physics with advances in low-power integrated circuits to demonstrate tiny yet fully operational sensors, electrodes, light sources, RF transceivers, and other classes of injectable electronics. Such capabilities represent a considerable advance in applying physics, wireless technology, and integrated circuits towards addressing challenges in biology and medicines.<br/><br/><br/>Broader Impacts<br/><br/>The proposed research enables the integration of electronics into the body through tiny devices, providing previously unavailable diagnostic and therapeutic options such as minimally invasive surgery and continuous monitoring. These capabilities will accelerate scientific discovery and improve overall healthcare cost. To maximize research benefits, results will be synthesized in formats understandable to the general public, including clinicians, patients, and policy makers; and widely disseminated through online platforms. The popular appeal of robotic microsystems, will be leveraged to motivate and inspire high school students over the grant period to strengthen the STEM pipeline in the U.S.  This is done through the internship of local K-12 teachers to multiply impact, mentoring of underrepresented students, and an annual summer workshop on robotics with biomedical applications for local high school students. The PI will also leverage her experience in mentoring female students at the high school level to encourage them to pursue higher degrees in engineering."
"1725935","MRI: Acquisition of an Animal Flight and Aeromechanics Wind Tunnel","DBI","MAJOR RESEARCH INSTRUMENTATION","09/01/2017","08/30/2017","Kenneth Breuer","RI","Brown University","Standard Grant","Robert Fleischmann","08/31/2020","$1,038,456.00","Sharon Swartz","kbreuer@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","BIO","1189","9150","$0.00","An award is made to Brown University to build a new animal flight and aeromechanics wind tunnel. In addition to facilitating conventional aerodynamic experiments, the wind tunnel will be configured for testing of birds, bats, and other flying and gliding animals and will enable new insights into animal flight and bio-inspired flight robotics. The wind tunnel facility will be made available to researchers interested in animal flight, fluid mechanics and related topics throughout and outside the US. Researchers from diverse communities including major research universities, undergraduate teaching colleges, and private and public institutions, will be encouraged to participate in research programs using the new wind tunnel and its associated instrumentation. Postdoctoral researchers, graduate students, and undergraduate students will receive training that uses the wind tunnel facility. The facility will be used to host multi-university workshops and symposia on biological aerodynamics and control, and in the use of advanced measurement diagnostics.<br/><br/>Scientists at Brown are leaders in the study of biological flight and have pioneered many experiments in this field. With the development of advanced diagnostics - high-speed videography, particle image velocimetry, animal-mounted data logging and transmission, etc. - animal flight research has become an area of intense research among biologists, bio-inspired roboticists, and other scientists and engineers. These groups use advanced diagnostic tools to better understand the kinematics, mechanics and dynamics of biological flight and diverse aspects of flight physiology; the results of these studies shed light on the ecology and evolution of life on the wing, and inspire novel engineering designs. The new wind tunnel will permit animal flight scientists throughout and beyond the US to work with a diversity of animal subjects and to employ sophisticated experimental techniques in the study of biomechanics, animal flight and bio-inspired robotics, and will facilitate ongoing and new collaborations among students and faculty. It will enable advanced measurement of kinematics and dynamics of animal fight, muscle function, echolocation, sensing and control during flight. In addition to biological testing, the wind tunnel will be used by a broad and diverse community of researchers in engineering fluid mechanics and aerodynamics research, allowing for transformative experiments in fundamental fluid mechanics, aerodynamics, fluid-structure interactions and energy systems."
"1646009","CPS: Synergy: Collaborative Research: Closed-loop Hybrid Exoskeleton utilizing Wearable Ultrasound Imaging Sensors for Measuring Fatigue","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","01/01/2017","09/07/2016","Nitin Sharma","PA","University of Pittsburgh","Standard Grant","Wendy Nilsen","12/31/2020","$400,000.00","Kang Kim","nis62@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","CSE","7918","7918, 8235","$0.00","The goal of this project is to develop an automated assistive device capable of restoring walking and standing functions in persons with motor impairments. Although research on assistive devices, such as active and passive orthoses and exoskeletons, has been ongoing for several decades, the improvements in mobility have been modest due to a number of limitations. One major challenge has been the limited ability to sense and interpret the state of the human, including volitional motor intent and fatigue. The proposed device will consist of powered electric motors, as well as the power generated by the person's own muscles. This work proposes to develop novel sensors to monitor muscle function, and, muscle fatigue is identified, the system will switch to the electric motors until the muscles recover. Through research on methods of seamless automated control of a hybrid assistive device while minimizing muscle fatigue, this study addresses significant limitations of prior work. The proposed project has the long-term potential to significantly improve walking and quality of life of individuals with spinal cord injuries and stroke. The proposed work will also contribute to new science of cyber-physical systems by integrating wearable image-based biosensing with physical exoskeleton systems through computational algorithms. This project will provide immersive interdisciplinary training for graduate and undergraduate students to integrate computational methods with imaging, robotics, human functional activity and artificial devices for solving challenging public health problems. A strong emphasis will be placed on involving undergraduate students in research as part of structured programs at our institutions. Additionally, students with disabilities will be involved in this research activities by leveraging an ongoing NSF-funded project. <br/><br/>This project includes the development of wearable ultrasound imaging sensors and real-time image analysis algorithms that can provide direct measurement of the function and status of the underlying muscles. This will allow development of dynamic control allocation algorithms that utilize this information to distribute control between actuation and stimulation. This approach for closed-loop control based on muscle-specific feedback represents a paradigm shift from conventional lower extremity exoskeletons that rely only on joint kinematics for feedback. As a testbed for this new approach, the team will utilize a hybrid exoskeleton that combines active joint actuators with functional electrical stimulation of a person's own muscles. Repetitive electrical stimulation leads to the rapid onset of muscle fatigue that limits the utility of these hybrid systems and potentially increases risk of injury. The goals of the project are: develop novel ultrasound sensing technology and image analysis algorithms for real-time sensing of muscle function and fatigue; investigate closed-loop control allocation algorithms utilizing measured muscle contraction rates to minimize fatigue; integrate sensing and control methods into a closed loop hybrid exoskeleton system and evaluate on patients with spinal cord injury. The proposed approach will lead to innovative CPS science by (1) integrating a human-in-the-loop physical exoskeleton system with novel image-based real-time robust sensing of complex time-varying physical phenomena, such as dynamic neuromuscular activity and fatigue, and (2) developing novel computational models to interpret such phenomena and effectively adapt control strategies. This research will enable practical wearable image-based biosensing, with broader applications in healthcare. This framework can be widely applicable in a number of medical CPS problems that involve a human in the loop, including upper and lower extremity prostheses and exoskeletons, rehabilitation and surgical robots. The new control allocation algorithms relying on sensor measurements could have broader applicability in fault-tolerant and redundant actuator systems, and reliable fault-tolerant control of unmanned aerial vehicles."
"1750041","CAREER: Strategic decision-making for communication and control in decentralized systems","ECCS","ENERGY,POWER,ADAPTIVE SYS","02/15/2018","01/25/2018","Ashutosh Nayyar","CA","University of Southern California","Standard Grant","Radhakisan S. Baheti","01/31/2023","$500,097.00","","ashutosn@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","ENG","7607","092E, 1045","$0.00","This project aims to develop a strategic decision-making framework for communication and control in dynamic decentralized systems. Centralized dynamic decision-making problems have a long history in engineering, economics and mathematics literature. Many modern systems, however, involve networks of agents making decisions in an uncertain and dynamic environment. Such decentralized systems arise in diverse application domains: infrastructure systems like power, transportation and communication networks, sensing and surveillance systems like teams of autonomous vehicles or robots, as well as networks of inter-connected devices such as the internet of things. Such systems are characterized by presence of multiple agents/decision-makers that have incomplete information about their environment, limited abilities to communicate with each other and that still have to make decisions that may affect the overall system. These systems have to contend with two key aspects of decentralization: (i) Decentralization of information, and (ii) Decentralization of decision-making. The decentralization of information and decision-making creates the need for communication. This communication may be limited, unreliable and imperfect. Decision-makers need to adapt to their communication environment. On the other hand, communication itself may require decision-making such as deciding when and with whom to communicate and what information to communicate. Thus, communication and decision-making are intimately coupled in decentralized systems. The overarching goal of the proposed research is to investigate this interplay of communication and control/decision-making that arises in decentralized systems operating in dynamic and uncertain environments. The technological and societal impacts of the proposed research will come through the development of new theoretical tools for communication and control in decentralized systems that will impact many applications and industries including: sensing and surveillance systems, robotics, smart grid, communication networks, urban infrastructure maintenance, and cyber-physical security. The educational impact of the project will come through the training of graduate students and engagement with local high-school students through school visits and/or on-campus events.<br/><br/>The focus of the proposed research will be on strategic decision-making which requires identification of decision strategies for agents that allow them to respond to real-time information about unfolding events in their environment in order to optimize the performance of a decentralized dynamic system. The proposed work will address fundamental questions regarding control and decision-making in decentralized systems operating in uncertain and dynamic environments. In particular, it will explore characterization and computation of decision strategies in the following domains: decentralized stochastic control with unreliable and imperfect communication among controllers, minimax decision and control problems in decentralized systems, joint optimization of real-time coding, communication scheduling and control strategies for decentralized control. The fruits of this research will potentially constitute an important step in the further understanding of the interplay of information, communication and decision-making in dynamic decentralized systems."
"1650566","I/UCRC for Building Reliable Advances and Innovation in Neurotechnology (BRAIN)","CNS","INDUSTRY/UNIV COOP RES CENTERS","03/15/2017","09/07/2017","Marco Santello","AZ","Arizona State University","Continuing grant","Dmitri Perkins","02/28/2022","$300,000.00","William Tyler, Jeffrey Kleim","marco.santello@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","5761","5761","$0.00","Age-related diseases are increasingly a leading cause of disability. Millions of younger adults live with neurological disorders, limb loss from amputation or paralysis from spinal cord injury. Traumatic brain injury can have lifelong effects on cognitive-motor function, significantly decreasing quality and length of life. There is a critical need for state-of-the art technology to effectively address the care and rehabilitation of these individuals. However, innovation in biomedical devices and other neurotechnologies faces several challenges: 1) The pace of innovation is moving more quickly than the rate of evaluation for acceptable performance; 2) Standards and regulatory science for the rigorous validation of safety, efficacy, and long-term reliability are missing; 3) Lack of open access to technologies that slows the transfer of novel technologies to the market; and 4) Current technologies are not affordable.  To address these challenges, Arizona State University will partner with University of Houston to establish and host a multi-institution Industry/University Cooperative Research Center (I/UCRC) for Building Reliable Advances and Innovation in Neurotechnology (BRAIN). The BRAIN Center's vision is a synergistic, interdisciplinary approach to develop and validate affordable patient-centered technologies. BRAIN will leverage expertise in neural systems, cognitive and rehabilitation engineering, robotics, clinical testing, and reverse-translational research at the University of Houston and Arizona State University to 1) enhance the rate of development and empirical validation of new technologies through partnerships with industry leaders and other strategic partners; 2) develop standards and technologies in human and non-human models, using a multi-scale approach ranging from single neurons to organismal systems; 3) characterize innovative technologies such as biosensors and quantitative analysis tools for systems and behaviors; 4) evaluate the impact of these technologies on quality of life; and 5) reduce the cost of neurotechnologies. The BRAIN Center's mission is multifold: to accelerate the progress of science and advance national health by transferring engineering innovations in neurotechnology to the end users, and to rectify underrepresentation in science, technology, engineering, and math (STEM) fields by broadening new participation and retaining current participants in STEM. It also will focus on problems in the neurological space that affect underrepresented groups disproportionately. BRAIN will become an innovative neurotechnology hub for the Southwest, creating a pipeline from discoveries to solutions while helping talented students, scientists, and engineers in the region take their innovations to the next level and solve one of the greatest unmet medical and health care needs of our time.<br/><br/>BRAIN will leverage a unique concentration of researchers and innovative research and development ecosystems with industrial partnerships to design, develop, test, and characterize neural technologies that can effectively transform the lives of disabled individuals. The Center will investigate all levels of neural function to enhance not only current technologies but also understanding of the mechanisms underlying neurological disease and injury. The Arizona State University IUCRC Site will focus on multi-scale, multi-modal, and multi-disciplinary and noninvasive approaches to understanding human neural function, and to deploying noninvasive technologies treating human disability. The Arizona State University site will bring a broad range of expertise spanning invasive and non-invasive neurotechnology and rehabilitation engineering to improve neural function across the human lifespan, as well as intervention techniques including peripheral, brain-machine interfaces, neuroprostheses, neuromodulation, data analytics, wearable assistive devices, and rehabilitation robotics. The Arizona State University innovation ecosystem includes a strong culture of entrepreneurship, use-inspired research, and interdisciplinary collaborations among faculty, industry, and clinical partners."
"1754412","Mechanisms for multi-modal gaze stabilization in Drosophila","IOS","ANIMAL BEHAVIOR","03/01/2018","02/27/2018","Jessica Fox","OH","Case Western Reserve University","Continuing grant","Jodie Jawor","02/28/2022","$158,490.00","","jlfox21@gmail.com","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","BIO","7659","9178, 9179","$0.00","Moving animals often use vision to determine where they are and where they are going. However, the scene in an animal's eyes only makes sense if it knows its own body position and movements. While they are moving, animals can also predict how their senses will be affected by their own movements. For example, as a human walks, his eyes bounce up and down with his steps, but he does not see this motion because his brain predicts and ignores this self-generated visual information. Though much is known about how this process works in a single sense organ, less is known about how multiple senses work together to do this. In many animals, the inner ear monitors the position and movement of the body. However, the inner ear is inside the head and difficult to study and manipulate. This project will take advantage of animals with rotation sensors on the outside of their bodies to observe how these organs influence behavior.  In flies, specialized organs called halteres detect body movements and these structures are located outside the body near the wings.  This research will measure changes in fly behavior that occur when the sensory information coming from the haltere is changed and when it does not match information gathered through vision. This work will show how multiple senses are integrated with the animal's own behavior to guide movement. By examining how the brain combines multiple sensory inputs and anticipates the consequences of its own behaviors, this work will uncover mechanisms of the brain's function that can be applied to other species and that can be used to understand biological brains and engineer algorithms for moving machines. The project will also be incorporated into a series of workshops at an all-girls high school with the goal of improving quantitative and computer coding skills in female students. <br/><br/>Distinguishing between self-generated and externally generated body movements is a central challenge for the nervous system. Efference copy, a neural signal of opposite sign to expected sensory input, is a possible mechanism for this distinction. Efference copies have been observed in single sensory systems, but how might they function in a multi-sensory context? Using an animal with a well-understood visual system and an easily-accessible mechanosensory organ, these experiments will investigate how these two sensory modalities combine during voluntary and involuntary movements.  In flies, body rotations are detected by specialized mechanosensors called halteres. These are modified hindwings that perform a function similar to the mammalian vestibular system. This project will investigate the integration of haltere information, visual information, and motor commands through quantitative behavioral analysis of flying flies. Flies will fly under different conditions: flight with imposed body rotations (tethered to a motor), flight with free, self-generated rotations (tethered to pins suspended between magnets), and rigidly tethered flight (no body rotations) with imposed movements of the haltere. The fly's head movement behavior will be observed under these conditions, and the behavior of intact flies will be compared to flies with their mechanosensory halteres removed or manipulated. Finally, information theoretic analysis will be used to quantify the flow of information in the visual and mechanosensory systems and construct a theoretical framework that can be used to understand how information about body rotations is integrated with visual information to control posture and gaze. Taken together, these experiments and model will demonstrate how two sensory modalities are combined and integrated with motor feedback during flight.  Broader impacts include workshops to broaden experience for young women in quantitative and computer coding skills and presentation of the work to various non-scientific audiences. Work completed here has application to the field of robotics and the development of higher quality autonomous aerial robotics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1554500","CAREER:   Bio-Enabled Actuating Materials (BEAM) to Power Autonomous Mobility","DMR","BIOMATERIALS PROGRAM","09/01/2016","10/20/2016","Vasile Nistor","OH","University of Cincinnati Main Campus","Continuing grant","Aleksandr Simonian","08/31/2021","$0.00","","licaseverin@gmail.com","University Hall, Suite 530","Cincinnati","OH","452210222","5135564358","MPS","7623","1045, 7237, 7573","$0.00","Non-Technical Abstract<br/>Autonomous mobility is a hallmark of many living organisms. When feeding, they harvest energy from their natural environment and convert it into mechanical work for movement. In contrast, most man-made systems must carry their own energy sources such as fuel or batteries, and then refuel or recharge in predetermined locations. Because of this limitation, it is not possible to fully assess when, where and why surface waters become contaminated with pathogenic microbes, making thousands of people sick every year. Solving this challenge requires development of an entirely new type of autonomous, mobile devices that can power themselves by feeding from the environment where they are deployed.<br/><br/>To support autonomous mobility in aquatic environments, a new class of Bio-Enabled Actuating Materials (BEAM) will be developed, characterized and tested. BEAM consist of stimuli-sensitive soft hydrogels populated with electricity producing bacteria called Geobacter. Geobacter feed on organics abundant in fresh waters, and produce electric charge. The discharge of electricity forces the hydrogel to change its shape. The process then repeats, creating an oscillatory change in shape that propels the hydrogel. BEAM will become a platform for many applications in robotics, biomedicine, biosensing, wearable textiles, materials science, and micro- and nano-engineering.<br/><br/>This problem can only be tackled through an interdisciplinary approach. While the need for interdisciplinary training and involvement in complex research projects both at graduate and undergraduate levels has been widely acknowledged, such practices are far from being systemic in academia. In this project, a cohort of graduate, undergraduate and 7-12 teachers and students, many from underrepresented groups, will be trained in principles of design and synthesis of BEAM, and in skills needed for interdisciplinary research and collaboration. These students will become proficient in tackling multi-faceted and societally important engineering challenges. <br/><br/>Technical Abstract<br/>Unlike living organisms, most engineered systems must either carry their own fuel/batteries and refuel/recharge in predetermined locations, or be powered remotely. This limits their deployment in environments that are difficult to access, cost-prohibitive for powering remotely or refueling. Development of mobile, fully autonomous systems that mimic living organisms will transform exploration of remote locations, lakes, streams, deep ocean, or human body cavities. To make a qualitative leap in development of such systems, there is urgent need for novel materials capable of harvesting energy from the environment and converting it to support motility. These materials will impact multiple fields from robotics, biomedicine, biosensing, materials science, to micro- and nano-engineering.<br/><br/>In this project, a novel class of Bio-Enabled Actuating Materials (BEAM) will be developed. BEAM contain Geobacter Sulfurreducens biofilm integrated within the network structure of thermosensitive poly-N-isopropylacrylamide (PNIPAAM) hydrogel. Geobacter feed on organics abundant in fresh waters, and produce electric charge. The discharge of electricity forces the hydrogel to change its shape. The process then repeats, creating an oscillatory change in shape that propels the hydrogel. BEAM will be synthesized, and their electrochemical characteristics will be studied to better understand its potential to harvest energy from the environment. Separate studies will focus on mechanical properties for actuation and propulsion. <br/><br/>Solving this problem requires amalgamation of knowledge and skills from several fields, and can only be tackled through an interdisciplinary approach. While the need for interdisciplinary training and involvement in complex research projects has been widely acknowledged, such practices are far from being systemic in academia. In this project, a cohort of graduate, undergraduate and 7-12 teachers and students, many from underrepresented groups, will be trained in principles of design and synthesis of BEAM, and in skills needed for interdisciplinary research and collaboration. Research findings will be incorporated in existing courses to continue interdisciplinary training of current and future students."
"1626236","MRI: Development of an Autonomous, Connected and Data-Driven Vehicle for Multi-Disciplinary Research and Project-Based Learning","CNS","SPECIAL PROJECTS - CISE","10/01/2016","09/13/2016","Xinming Huang","MA","Worcester Polytechnic Institute","Standard Grant","Rita V. Rodriguez","09/30/2019","$300,000.00","William Michalson, Yehia Massoud, Raghvendra Cowlagi, Xiangnan Kong","xhuang@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","1714","1189","$0.00","This project, developing a connected and autonomous vehicle, aims to create WAVE, a shared 'live' testbed/platform for faculty and students to investigate many aspects of the driveless car. Involving research, experiments, and data collection, these aspects include: safety, reliability, performance, connectivity, interaction, and social impacts. Similar to the history of wireless communications research over the past decade, researchers often utilized SDR platforms to prototype and evaluate their proposed communication systems. As connected and autonomous cars hit the road in the future, there will be many issues. A prototype vehicle becomes absolutely necessary for these research projects to collect data, conduct experiments, and prove concepts. The 'live' testbed will be shared by faculty and students across the university to carry out their research and educational missions. A large number of research activities and student projects will utilize this instrument, which will serve the dual purposes of enabling multidisciplinary research and project-based learning. The instrument will enable multidisciplinary research activities that involve, but are not limited to, computer vision and machine learning, V2V and V2I communications, optimal controls and reliability, big data analysis, human-robot interactions, driver behavior and human factors, social impacts and autonomous vehicle policies.<br/><br/>Although a fully autonomous car is not currently commercially available, key components such as sensors, processing platforms, and drive-by-wire devices can readily be integrated to build a prototype. The instrument development team consists of experts from multiple fields, including robotics, electrical, and mechanical engineering, as well as computer science. The main efforts not only includes the hardware/sensors installation, but also the software development for vehicle control, data processing, and path planning. Comparing to the autonomous vehicle prototypes in the literature, the proposed WAVE testbed exhibits three new properties. It will be a 1. Connected vehicle equipped with DSRC (Dedicated Short Range Communications) modules that can evaluate V2V (Vehicle-to Vehicle) and V2I (Vehicle to Infrastructure) active-safety systems; 2. Data-driven platform that will collect big data from roads, vehicles, and drivers; the data will be shared openly with the research community; 3. Real-world tool for university faculty to develop curriculum for project-based learning which will enhance student experience through undergraduate research."
"1729209","CPS/Synergy/Collaborative Research: Safe and Efficient Cyber-Physical Operation System for Construction Equipment","CMMI","CYBER-PHYSICAL SYSTEMS (CPS)","09/01/2016","06/09/2017","Chinemelu Anumba","FL","University of Florida","Standard Grant","Bruce M. Kramer","12/31/2019","$290,325.00","","anumba@ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","ENG","7918","030E, 034E, 5188, 7339, 7918, 8235","$0.00","Equipment operation represents one of the most dangerous tasks on a construction sites and accidents related to such operation often result in death and property damage on the construction site and the surrounding area. Such accidents can also cause considerable delays and disruption, and negatively impact the efficiency of operations. This award will conduct research to improve the safety and efficiency of cranes by integrating advances in robotics, computer vision, and construction management. It will create tools for quick and easy planning of crane operations and incorporate them into a safe and efficient system that can monitor a crane's environment and provide control feedback to the crane and the operator. Resulting gains in safety and efficiency wil reduce fatal and non-fatal crane accidents. Partnerships with industry will also ensure that these advances have a positive impact on  construction practice, and can be extended broadly to smart infrastructure, intelligent manufacturing, surveillance, traffic monitoring, and other application areas. The research will involve undergraduates and includes outreach to K-12 students.<br/><br/>The work is driven by the hypothesis that the monitoring and control of cranes can be performed autonomously using robotics and computer vision algorithms, and that detailed and continuous monitoring and control feedback can lead to improved planning and simulation of equipment operations. It will particularly focus on developing methods for (a) planning construction operations while accounting for safety hazards through simulation; (b) estimating and providing analytics on the state of the equipment; (c) monitoring equipment surrounding the crane operating environment, including detection of safety hazards, and proximity analysis to dynamic resources including materials, equipment, and workers; (d) controlling crane stability in real-time; and (e) providing feedback to the user and equipment operators in a ""transparent cockpit"" using visual and haptic cues. It will address the underlying research challenges by improving the efficiency and reliability of planning through failure effects analysis and creating methods for contact state estimation and equilibrium analysis; improving monitoring through model-driven and real-time 3D reconstruction techniques, context-driven object recognition, and forecasting motion trajectories of objects; enhancing reliability of control through dynamic crane models, measures of instability, and algorithms for finding optimal controls; and, finally, improving efficiency of feedback loops through methods for providing visual and haptic cues."
"1536003","AitF: FULL: Collaborative Research: PEARL: Perceptual Adaptive Representation Learning in the Wild","CCF","Algorithms in the Field","09/01/2015","08/14/2015","Trevor Darrell","CA","University of California-Berkeley","Standard Grant","Tracy J. Kimbrel","08/31/2019","$200,000.00","","trevor@eecs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7239","012Z","$0.00","Vast amounts of digitized images and videos are now commonly available, and the advent of search engines has further facilitated their access. This has created an exceptional opportunity for the application of machine learning techniques to model human visual perception. However, the data often does not conform to the core assumption of machine learning that training and test images are drawn from exactly the same distribution, or ""domain."" In practice, the training and test distributions are often somewhat dissimilar, and distributions may even drift with time. For example, a ""dog"" detector trained on Flickr may be tested on images from a wearable camera, where dogs are seen in different viewpoints and lighting conditions. The problem of compensating for these changes--the domain adaptation problem--must therefore be addressed both in theory and in practice for algorithms to be effective. This problem is not just a second-order effect and its solution does not constitute a small increase in performance.  Ignoring it can lead to dramatically poor results for algorithms ""in the field.""<br/><br/>This project will develop a core suite of theory and algorithms for PErceptual Adaptive Representation Learning (PEARL), which, when given a new task domain, and previous experience with related tasks and domains, will provide a learning architecture likely to achieve optimal generalization on the new task. We expect PEARL to have a significant impact on the research community by providing a much-needed theoretical and computational framework that takes steps toward unifying the subfields of domain adaptation theory and domain adaptation practice. Our theoretical and practical advancements will impact many application areas by allowing the use of pre-trained perceptual models (visual and otherwise) in new situations and across space and time. For example, in mobile technology and robotics, PEARL will help personal assistants and robots better adapt their perceptual interfaces to individual users and particular situated environments.  At the core of this project are three main research thrusts: 1) making theoretical advances for domain adaptation by developing generalized discrepancy distance minimization; 2) using the theoretical guarantees of generalized discrepancy distance to develop algorithms for key adaptation scenarios of deep perceptual representation learning, domain adaptation with active learning, and time-dependent adaptation; 3) advancing the theory and developing algorithms for the multiple-source adaptation scenario. In addition to our core aims, we plan to implement our algorithms within a scalable open-source framework, and evaluate our algorithms on large-scale visual data sets."
"1723379","AitF:  FULL: Collaborative Research:   PEARL: Perceptual Adaptive Representation Learning in the Wild","CCF","Algorithms in the Field","09/01/2016","03/14/2017","Kate Saenko","MA","Trustees of Boston University","Standard Grant","Tracy J. Kimbrel","08/31/2019","$173,754.00","","saenko@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7239","012Z","$0.00","Vast amounts of digitized images and videos are now commonly available, and the advent of search engines has further facilitated their access. This has created an exceptional opportunity for the application of machine learning techniques to model human visual perception. However, the data often does not conform to the core assumption of machine learning that training and test images are drawn from exactly the same distribution, or ""domain."" In practice, the training and test distributions are often somewhat dissimilar, and distributions may even drift with time. For example, a ""dog"" detector trained on Flickr may be tested on images from a wearable camera, where dogs are seen in different viewpoints and lighting conditions. The problem of compensating for these changes--the domain adaptation problem--must therefore be addressed both in theory and in practice for algorithms to be effective. This problem is not just a second-order effect and its solution does not constitute a small increase in performance.  Ignoring it can lead to dramatically poor results for algorithms ""in the field.""<br/><br/>This project will develop a core suite of theory and algorithms for PErceptual Adaptive Representation Learning (PEARL), which, when given a new task domain, and previous experience with related tasks and domains, will provide a learning architecture likely to achieve optimal generalization on the new task. We expect PEARL to have a significant impact on the research community by providing a much-needed theoretical and computational framework that takes steps toward unifying the subfields of domain adaptation theory and domain adaptation practice. Our theoretical and practical advancements will impact many application areas by allowing the use of pre-trained perceptual models (visual and otherwise) in new situations and across space and time. For example, in mobile technology and robotics, PEARL will help personal assistants and robots better adapt their perceptual interfaces to individual users and particular situated environments.  At the core of this project are three main research thrusts: 1) making theoretical advances for domain adaptation by developing generalized discrepancy distance minimization; 2) using the theoretical guarantees of generalized discrepancy distance to develop algorithms for key adaptation scenarios of deep perceptual representation learning, domain adaptation with active learning, and time-dependent adaptation; 3) advancing the theory and developing algorithms for the multiple-source adaptation scenario. In addition to our core aims, we plan to implement our algorithms within a scalable open-source framework, and evaluate our algorithms on large-scale visual data sets."
"1542368","Collaborative Research: Enriching the Professional Development of School Teachers & Community College Faculty in Rural Michigan - An RET Site on Smart Vehicles","EEC","RES EXP FOR TEACHERS(RET)-SITE, HUMAN RESOURCES DEVELOPMENT, ENG DIVERSITY ACTIVITIES","01/01/2016","08/09/2017","Kumar Yelamarthi","MI","Central Michigan University","Standard Grant","Mary Poats","12/31/2018","$616,611.00","Janis Voege, Julie Cunningham","yelam1k@cmich.edu","Office of Research & Graduate St","Mount Pleasant","MI","488590001","9897746777","ENG","1359, 1360, 7680","115E, 116E, 1359, 9177, 9178, 9251","$0.00","Within a coherent theme of Smart Vehicles, this collaborative Research Experiences for Teachers (RET) in Engineering and Computer Science Site at Central Michigan University (CMU) and Western Michigan University (WMU) will expose in-service and pre-service teachers, and community college faculty to leading research spanning mobile robotics, kinematics and kinetics, vehicle manufacturing robots, vehicular sensor networks, ergonomics, material science, and circuit design. The multidisciplinary nature of Smart Vehicles in engineering will provide a holistic ground for developing creative course modules in physics, chemistry, engineering, and technology that aligns well with the Next Generation Science Standards (NGSS), Common Core State Standards (CCSS), and Accreditation Board for Engineering and Technology (ABET) Criteria for STEM curriculum. Engaging regionally automobile focused industrial advisors and university faculty with rural secondary school and community college teachers will serve as a model-platform, and provide rare best-practices-based professional development opportunities and experience. CMU, a regional comprehensive university, is located in the heart of central rural Michigan where it maintains a reputation as ""the"" university to which schools turn for access to newly educated teachers, and for professional development for their current teachers. This RET renewal site will focus on teachers in these rural areas, and support them as they lift the STEM knowledge base of their students, increasing their opportunities for employment and for becoming entrepreneurs. Engaging pre-service teachers in cutting-edge research ensures that they begin their careers well-equipped with research experience and confidence to take into their classrooms. Similarly, with nurtured NGSS-based curriculum design and implementation expertise these teachers will take on leadership roles in their employing schools, thereby multiplying the effect of this project. Overall, through partnership with K-12 schools, community colleges, and a public university, this RET site will provide a profound influence on the learning and career paths of young students in the rural Michigan area, with knowledge, skills, abilities and attitudes which are in high demand, but who have traditionally been underrepresented in the STEM education and employment.<br/><br/>This Site will offer an intensive six-week summer research program for a total of 45 rural STEM teachers over three years with a focus on those serving groups that are underrepresented in science and engineering. RET participants will engage in cutting-edge research on Smart Vehicles, under the guidance of engineering faculty mentors who lead active research programs, and who serve the community through outreach activities. The engineering faculty mentors, curriculum development specialist, Instructional Coach from Science/Mathematics, Technology Center, and staff from CMU's Faculty Center for Innovative Teaching will coach participants as they design standards-compliant curriculum modules and conduct professional development activities for each participant group. Extensive follow-up activities through the academic year include on-site Instructional Coaching, Quarterly Team Meetings, engineering faculty involvement in secondary school and community college classrooms, and Cross Classroom Collaborations to ensure translation of research experience into practice. The annual CMU High-Impact STEM Teaching Symposium will share findings with regional educators, and the annual CMU STEM Day will engage more than 200 secondary school students in exploration of engineering disciplines on CMU campus. The Science and Mathematics Program Improvement (SAMPI) staff at WMU will serve as external program evaluators, track and evaluate the site progress and provide feedback for improvement. They will also conduct longitudinal studies to assess the long-term impact of the proposed RET site.<br/><br/>This RET Site is co-funded by the Directorate for Engineering (ENG), Division of Engineering Education and Centers (EEC) and the Directorate for Computer and Information Science and Engineering (CISE), Division of Computer and Network Systems (CNS)."
"1542336","Collaborative Research: Enriching the Professional Development of School Teachers & Community College Faculty in Rural Michigan: An RET Site on Smart Vehicles.","EEC","RES EXP FOR TEACHERS(RET)-SITE","01/01/2016","09/10/2015","Mary Anne Sydlik","MI","Western Michigan University","Standard Grant","Mary Poats","12/31/2018","$38,206.00","Robert Ruhf","maryanne.sydlik@wmich.edu","1903 West Michigan Avenue","Kalamazoo","MI","490085200","2693878298","ENG","1359","115E, 9177","$0.00","Within a coherent theme of Smart Vehicles, this collaborative Research Experiences for Teachers (RET) in Engineering and Computer Science Site at Central Michigan University (CMU) and Western Michigan University (WMU) will expose in-service and pre-service teachers, and community college faculty to leading research spanning mobile robotics, kinematics and kinetics, vehicle manufacturing robots, vehicular sensor networks, ergonomics, material science, and circuit design. The multidisciplinary nature of Smart Vehicles in engineering will provide a holistic ground for developing creative course modules in physics, chemistry, engineering, and technology that aligns well with the Next Generation Science Standards (NGSS), Common Core State Standards (CCSS), and Accreditation Board for Engineering and Technology (ABET) Criteria for STEM curriculum. Engaging regionally automobile focused industrial advisors and university faculty with rural secondary school and community college teachers will serve as a model-platform, and provide rare best-practices-based professional development opportunities and experience. CMU, a regional comprehensive university, is located in the heart of central rural Michigan where it maintains a reputation as ""the"" university to which schools turn for access to newly educated teachers, and for professional development for their current teachers. This RET renewal site will focus on teachers in these rural areas, and support them as they lift the STEM knowledge base of their students, increasing their opportunities for employment and for becoming entrepreneurs. Engaging pre-service teachers in cutting-edge research ensures that they begin their careers well-equipped with research experience and confidence to take into their classrooms. Similarly, with nurtured NGSS-based curriculum design and implementation expertise these teachers will take on leadership roles in their employing schools, thereby multiplying the effect of this project. Overall, through partnership with K-12 schools, community colleges, and a public university, this RET site will provide a profound influence on the learning and career paths of young students in the rural Michigan area, with knowledge, skills, abilities and attitudes which are in high demand, but who have traditionally been underrepresented in the STEM education and employment.<br/><br/>This Site will offer an intensive six-week summer research program for a total of 45 rural STEM teachers over three years with a focus on those serving groups that are underrepresented in science and engineering. RET participants will engage in cutting-edge research on Smart Vehicles, under the guidance of engineering faculty mentors who lead active research programs, and who serve the community through outreach activities. The engineering faculty mentors, curriculum development specialist, Instructional Coach from Science/Mathematics, Technology Center, and staff from CMU's Faculty Center for Innovative Teaching will coach participants as they design standards-compliant curriculum modules and conduct professional development activities for each participant group. Extensive follow-up activities through the academic year include on-site Instructional Coaching, Quarterly Team Meetings, engineering faculty involvement in secondary school and community college classrooms, and Cross Classroom Collaborations to ensure translation of research experience into practice. The annual CMU High-Impact STEM Teaching Symposium will share findings with regional educators, and the annual CMU STEM Day will engage more than 200 secondary school students in exploration of engineering disciplines on CMU campus. The Science and Mathematics Program Improvement (SAMPI) staff at WMU will serve as external program evaluators, track and evaluate the site progress and provide feedback for improvement. They will also conduct longitudinal studies to assess the long-term impact of the proposed RET site.<br/><br/>This RET Site is co-funded by the Directorate for Engineering (ENG), Division of Engineering Education and Centers (EEC) and the Directorate for Computer and Information Science and Engineering (CISE), Division of Computer and Network Systems (CNS)."
"1535987","AitF: FULL: Collaborative Research: PEARL: Perceptual Adaptive Representation Learning in the Wild","CCF","Algorithms in the Field","09/01/2015","08/14/2015","Mehryar Mohri","NY","New York University","Standard Grant","Tracy J. Kimbrel","08/31/2019","$399,983.00","","mohri@cims.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7239","012Z","$0.00","Vast amounts of digitized images and videos are now commonly available, and the advent of search engines has further facilitated their access. This has created an exceptional opportunity for the application of machine learning techniques to model human visual perception. However, the data often does not conform to the core assumption of machine learning that training and test images are drawn from exactly the same distribution, or ""domain."" In practice, the training and test distributions are often somewhat dissimilar, and distributions may even drift with time. For example, a ""dog"" detector trained on Flickr may be tested on images from a wearable camera, where dogs are seen in different viewpoints and lighting conditions. The problem of compensating for these changes--the domain adaptation problem--must therefore be addressed both in theory and in practice for algorithms to be effective. This problem is not just a second-order effect and its solution does not constitute a small increase in performance.  Ignoring it can lead to dramatically poor results for algorithms ""in the field.""<br/><br/>This project will develop a core suite of theory and algorithms for PErceptual Adaptive Representation Learning (PEARL), which, when given a new task domain, and previous experience with related tasks and domains, will provide a learning architecture likely to achieve optimal generalization on the new task. We expect PEARL to have a significant impact on the research community by providing a much-needed theoretical and computational framework that takes steps toward unifying the subfields of domain adaptation theory and domain adaptation practice. Our theoretical and practical advancements will impact many application areas by allowing the use of pre-trained perceptual models (visual and otherwise) in new situations and across space and time. For example, in mobile technology and robotics, PEARL will help personal assistants and robots better adapt their perceptual interfaces to individual users and particular situated environments.  At the core of this project are three main research thrusts: 1) making theoretical advances for domain adaptation by developing generalized discrepancy distance minimization; 2) using the theoretical guarantees of generalized discrepancy distance to develop algorithms for key adaptation scenarios of deep perceptual representation learning, domain adaptation with active learning, and time-dependent adaptation; 3) advancing the theory and developing algorithms for the multiple-source adaptation scenario. In addition to our core aims, we plan to implement our algorithms within a scalable open-source framework, and evaluate our algorithms on large-scale visual data sets."
"1532239","MRI: Development of an exoskeleton for simultaneous assessment of brain, muscular, and nervous system output during functional arm and hand tasks","CMMI","MAJOR RESEARCH INSTRUMENTATION","09/01/2015","08/23/2015","Joel Perry","ID","University of Idaho","Standard Grant","Joanne D. Culbertson","08/31/2020","$1,084,787.00","Eric Wolbrecht","jperry@uidaho.edu","Office of Sponsored Programs","MOSCOW","ID","838443020","2088856651","ENG","1189","010E, 1632, 6840, 8091","$0.00","The development of a new instrument for simultaneous assessment of brain, muscular, and nervous system output during functional arm and hand tasks will provide unprecedented insight into the inner workings of arm and hand function, including movement intention and movement performance. The developed BiLateral Upper-extremity Exoskeleton for Simultaneous Assessment of Biomechanical and Neuromuscular Output (BLUE SABINO) would be the first of its kind with the ability to record extensive metrics from both left and right hemispheres of the brain, muscle activation patterns, and movement of both left and right arms simultaneously. Particularly evident in populations with neuromuscular impairment, there is a gap in our current knowledge between the action potentials generated by the brain and the resulting movements generated by the muscles. This Major Research Instrumentation award will address this gap by facilitating a better understanding of arm function along the full neuromuscular pathway from thought to action. BLUE SABINO will also enable further study on a variety of cutting-edge research areas from brain-computer-interfaces and virtual environment simulation to advanced control of industrial and medical robotics. <br/><br/>BLUE SABINO will combine the mechanical precision and repeatability of a 28 degree-of-freedom (DOF) dual-arm exoskeleton, with existing high-end acquisition systems for collecting electroencephalographic (EEG) and electromyographic (EMG) data from the brain and neuromuscular system, as well as processing algorithms to compute general assessment metrics. The exoskeleton components will allow natural reach and grasp movements through two 14-DOF (12 active, 2 passive) wearable arms. EEG and EMG acquisition will be performed with at least 32 and 64 channels, respectively, per side. Together, the instrument will provide a groundbreaking, holistic instrument for quantitative assessment and evaluation of arm function not currently possible. Acquisition of biometric data from both left and right sides of the body will allow evaluation of unilateral and bimanual activities of daily living (ADL), as well as a means of monitoring and evaluating task performance for both healthy and impaired users. The comprehensive assessment capacity will enable transformative research across a wide spectrum of domains including: functional outcome assessment, computation and planning of targeted therapeutic approaches, advanced therapy/response correlations, novel brain-machine-body rehabilitation paradigms, and development and optimization of brain-computer interfaces (BCIs) and brain-controlled neuroprosthetics.<br/><br/>This award is supported by the Engineering Directorate's Civil, Mechanical and Manufacturing Innovation (CMMI) Division along with the Chemical, Bioengineering, Environmental, and Transport Systems (CBET) Division."
"1635407","Collaborative Research: Using Boundaries to Create and Control Pathways for Photomechanical Actuation","CMMI","Mechanics of Materials and Str","08/01/2016","05/22/2018","Kaushik Dayal","PA","Carnegie-Mellon University","Standard Grant","Siddiq Qidwai","07/31/2019","$274,000.00","","Kaushik.Dayal@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","1630","022E, 024E, 116E, 8086, 9102, 9161, 9178, 9231, 9251, AMPP","$0.00","This award supports fundamental research into new ways to hold and constrain liquid crystal elastomers that will cause thin sheets to change shape in discrete steps as the sheets are illuminated.  Liquid crystal elastomers are a class of polymers that can be tailored to undergo changes in shape when they are illuminated with light, thereby enabling the direct conversion of light into directed mechanical work. An important advantage of using light is that wiring, circuitry, and mechanical contacts are not needed; devices made of these materials can be operated remotely.  This property can enable applications in a range of technologies, including light-operated microsurgical tools, display technologies integrated with touch feedback, and robotics that harness light for manipulation.  However, the mechanical force generated by these materials is small and the shape change during irradiation with light is difficult to control. The new shape change mechanisms will simultaneously generate fast response times and large forces during the transition between the shapes.  Therefore, the results of this research can enable new device architectures and bring these materials closer to widespread application, thereby benefitting the US economy and society. Outreach to underrepresented K-12 students through local Pittsburgh organizations will also be integrated with the research program.<br/> <br/>Light-driven shape change observed in liquid crystal elastomers can enable a class of next-generation of remotely-driven actuators.  This research will explore the interplay between the photomechanical adaptivity and localized constraints applied at the boundary.  In particular, this interplay triggers a cascade of discrete transitions from a prior flat state into non-self-similar shapes. Integrated experiments and modeling will be used to understand the interactions between microstructural heterogeneity, boundary conditions, material anisotropy and photostrains on the emergent multimorphism and actuation.  The resulting core contribution to mechanics will be the deeper fundamental understanding of the interplay between instabilities and boundary conditions in two-dimensional objects with complex curvature and heterogeneity, using shell and membrane theories from mechanics.  The research tasks include synthesis of thin-film specimens, characterization of light-induced mechanical deformation, development of mathematical models, and numerical and analytical analysis of the models.  The feedback between experiment and theory will enable the formulation of predictive and accurate models, as well as provide physics-based guidance to the experiments."
"1635926","Collaborative Research: Using Boundaries to Create and Control Pathways for Photomechanical Actuation","CMMI","Mechanics of Materials and Str","08/01/2016","07/10/2016","M. Ravi Shankar","PA","University of Pittsburgh","Standard Grant","Siddiq Qidwai","07/31/2019","$200,000.00","","shankarr@engr.pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","ENG","1630","022E, 024E, 8086, 9161, AMPP","$0.00","This award supports fundamental research into new ways to hold and constrain liquid crystal elastomers that will cause thin sheets to change shape in discrete steps as the sheets are illuminated.  Liquid crystal elastomers are a class of polymers that can be tailored to undergo changes in shape when they are illuminated with light, thereby enabling the direct conversion of light into directed mechanical work. An important advantage of using light is that wiring, circuitry, and mechanical contacts are not needed; devices made of these materials can be operated remotely.  This property can enable applications in a range of technologies, including light-operated microsurgical tools, display technologies integrated with touch feedback, and robotics that harness light for manipulation.  However, the mechanical force generated by these materials is small and the shape change during irradiation with light is difficult to control. The new shape change mechanisms will simultaneously generate fast response times and large forces during the transition between the shapes.  Therefore, the results of this research can enable new device architectures and bring these materials closer to widespread application, thereby benefitting the US economy and society. Outreach to underrepresented K-12 students through local Pittsburgh organizations will also be integrated with the research program.<br/> <br/>Light-driven shape change observed in liquid crystal elastomers can enable a class of next-generation of remotely-driven actuators.  This research will explore the interplay between the photomechanical adaptivity and localized constraints applied at the boundary.  In particular, this interplay triggers a cascade of discrete transitions from a prior flat state into non-self-similar shapes. Integrated experiments and modeling will be used to understand the interactions between microstructural heterogeneity, boundary conditions, material anisotropy and photostrains on the emergent multimorphism and actuation.  The resulting core contribution to mechanics will be the deeper fundamental understanding of the interplay between instabilities and boundary conditions in two-dimensional objects with complex curvature and heterogeneity, using shell and membrane theories from mechanics.  The research tasks include synthesis of thin-film specimens, characterization of light-induced mechanical deformation, development of mathematical models, and numerical and analytical analysis of the models.  The feedback between experiment and theory will enable the formulation of predictive and accurate models, as well as provide physics-based guidance to the experiments."
"1841845","EAGER: Toward Magnetic Manipulation of Nonmagnetic Objects","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2018","07/31/2018","Jake Abbott","UT","University of Utah","Standard Grant","Reid Simmons","08/31/2020","$248,739.00","Tucker Hermans","jake.abbott@utah.edu","75 S 2000 E","SALT LAKE CITY","UT","841128930","8015816903","CSE","7495, 8013","063Z, 7495, 7916","$0.00","Over the past decade, researchers have made significant advances on using magnets to precisely move objects without any physical contact. However, the objects are specially designed to be made mostly of ferromagnetic material so that they can be moved by magnets. But what if it were possible to use magnets to manipulate metal objects that contain no magnetic material at all, which is common in many engineered devices? It is well known that moving magnets create electrical fields that, in turn, can generate forces in metal objects through the generation of eddy currents.  The project explores how these forces can be used to control the movement of such objects, enabling manipulation in microgravity and undersea, and enabling new tools for scientific research.<br/><br/>This project methodically characterizes the physics of magnetic manipulation of nonmagnetic-but-conductive spheres (solid and thin walled). For the time-varying magnetic fields used to generate eddy currents in the spheres, rotating magnetic dipole fields are used, which are generated by unique electromagnetic and permanent-magnet hardware platforms developed by the Principal Investigator with prior NSF support. The project characterizes eddy-current-based manipulation as a robotic-manipulation problem, in order to determine how the number and placement of the dipole actuation sources affects manipulability. The project tests the hypothesis that a sphere can be manipulated with limited prior knowledge by learning the model?s parameters while using guarded actions to avoid loss of control authority. This joint learning and control problem is formulated as an information-theoretic, active-learning problem to find informative samples for learning, subject to unknown manipulation constraints imposed by the electromagnetic physics of the system. Finally, the project includes a feasibility study in the practical application of this phenomenon.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1463203","GOALI: Design of Rheologically-Complex Soft Materials","CMMI","GRANT OPP FOR ACAD LIA W/INDUS, Design of Eng Materials (DEMS)","06/01/2015","05/10/2017","Randy Ewoldt","IL","University of Illinois at Urbana-Champaign","Standard Grant","Richard Malak","05/31/2019","$471,000.00","James Allison, Florian Nettesheim","ewoldt@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","1504, 8086","022E, 024E, 027E, 068E, 073E, 116E, 1504, 8086, 9102, 9178, 9231, 9251","$0.00","Many everyday materials do not fit classical definitions of fluid and solid. Instead, rheological materials can have properties of both states. While engineers typically use traditional fluid and solid materials to achieve desired functionality of engineering systems, there is great opportunity for novel performance based on rheological material behavior. The focus of this Grant Opportunity for Academic Liaison with Industry (GOALI) Program research project is to ask the question, given a desired performance, what rheological material behavior is needed, and what material formulations achieve this behavior?  The work here will study design and optimization techniques for these complex soft materials. The research involves theory, computation, and experiment. The methodology aims to transform the search for novel rheologically-complex materials and their use in engineering design. The resulting enhanced system performance would impact numerous application domains such as, but are not limited to, soft robotics, vibration control, fire-suppression systems, and prosthetics.  The GOALI partnership will strengthen the relevance of the new methods to engineering practice and provide a test bed for the new design approach. The interaction with industry will also enhance the training of students.  Associated outreach activities will broaden the general understanding of rheological materials via the development and use of a portal enabling virtual experiments on rheological materials.<br/><br/>The objective of this work is to create a new paradigm for creative and rational design of rheologically-complex materials. This project?s approach directly connects system-level performance optimization to material-level design. A core challenge is that rheological properties are functions, not constants. The work will define and organize design-appropriate mathematical modeling methods that use descriptive material functions (function-valued properties) directly. Rheological complexity derives from time-dependent (viscoelastic) and amplitude-dependent (nonlinear) behavior, and this two-dimensional space will be used to organize the applicability and limitations of different constitutive models for the purpose of design.  Optimization methods for the resulting mathematical structures will be established.  A key challenge is the optimization of functions, such as kernel functions in convolution integrals.  This will be approached with numerical optimal control methods including direct transcription. Once target properties are identified, experiments will be used to demonstrate rational design of rheologically-complex material compositions that best achieve the system performance objectives. This material-level design will leverage known structure-rheology models by considering multiple material strategies including polymeric systems, colloidal systems, and composite combinations. The industry GOALI partner will work closely with the academic team to help translate the work to industry, provide insight on formulation of new material concepts, and provide relevant material formulations.  The methodology will be tested numerically and experimentally with case studies of shear-thinning and linear viscoelastic systems. The new paradigm will lay the foundation for additional integrated design approaches for other materials domains with complex function-valued properties."
"1748161","EAGER: MEMS Co-Steered Optical and Acoustic Dual Modal Communication and Ranging Devices for Underwater Vehicles","IIS","National Robotics Initiative","09/01/2017","08/15/2017","Jun Zou","TX","Texas A&M Engineering Experiment Station","Standard Grant","Ralph Wachter","08/31/2019","$202,779.00","Dezhen Song","junzou@tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","CSE","8013","7916, 8086","$0.00","Autonomous Underwater Vehicles (AUVs) are very important tools for many applications, including infrastructure inspection and maintenance, search and rescue, environmental monitoring, maritime archaeology, oil drilling and pipeline inspection, and defense. However, a significant and fundamental challenge faced by today?s AUVs is communication and perception in the underwater environment. Traditional devices are bulky and have low spatial resolution in ranging/mapping tasks. Acoustic communication is slow in speed. Laser-based communication can achieve high speed, but requires direct light of sight. Therefore, there is no effective way to tightly coordinate a group of AUVs.<br/><br/>The objective of this project is to develop a miniaturized dual-modal Microelectromechanical systems (MEMS)-based Sound Navigation And Ranging (sonar) and Light Detection And Ranging (LiDAR) combo device, named as oPtical and Acoustic communication and Ranging (PAIR) device. The PAIR device functions as both a dual band network adapter and a combination of sonar and LiDAR but with a much smaller footprint and better signal registration. Enabled by the use of a novel MEMS scanning mirror and ultrasound transducer<br/>with unique mechanical and optical properties previously demonstrated, the PAIR devices can simultaneously transmit and receive both sound and laser signals in a co-centered and co-directional fashion."
"1526309","NeTS: Small: Collaborative Research: A Service Centric Architecture for Efficient Spectral Utilization in Wireless Networks","CNS","Networking Technology and Syst","09/01/2015","08/28/2015","Anthony Ephremides","MD","University of Maryland College Park","Standard Grant","Monisha Ghosh","08/31/2019","$250,000.00","","etony@umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","CSE","7363","7923","$0.00","This project will begin by questioning the basic design paradigms of wireless networks, where there are limited spectral resources for a large population of users needing a diverse set of services. The ultimate goal of the project is to expand the application base of wireless networks from wireless Internet, to include scalable mobile healthcare, first-responders, security applications, transportation, factory automation and robotics. The main strength of the project will be to bring theoretical foundations, as well as system level designs and algorithms to develop a realizable network. The PIs plan to work closely with their industrial partners to ensure that project outcomes impact next-generation wireless networks. <br/><br/>This research presents a fundamentally novel approach to address spectrum efficiency that reflects the shifting nature of networking philosophy as networks migrate from the classical paradigm of well-defined users and operators to the notion that networking is a tool for the provision of services. Then the primary objective of future service centric networks is to distribute content and to provide fresh information about on-going processes. Over the last few years, the rise in the number of different wireless services has put unprecedented pressure on providers' networks, to the point that current architectures cannot scale to meet the exponential growth of users' demands and the dissimilarities in the services. To confront the crisis, this research meets the required paradigm shift away from a static view of users' needs and in accord with a vertically integrated architecture to harness features of the services. The driving vision in this project is to architect a wireless network with a prevailing service centric philosophy. The concept of network-wide cognition is introduced in this endeavor to explore attributes and disparities of these services as well as heterogeneity of network nodes. Exercising 'true cognition' at the physical layer, nodes in the network will be assumed to operate with flexible radios and that the network is agnostic to the radio access technology; however, the network will be designed to exploit this flexibility. Therefore, the concept of network- wide cognition substantiates across several layers of wireless network design and revisits core network foundations in two coupled thrusts one on scheduling for service centric networking and the other on network provision for delay sensitive services."
"1555608","SBIR Phase II:  VocaliD - Infusing Unique Vocal Identities into Synthesized Speech","IIP","SMALL BUSINESS PHASE II","04/01/2016","05/09/2018","Rupal Patel","MA","VOCALID INC","Standard Grant","Peter Atherton","09/30/2018","$945,299.00","","rupal@vocaliD.co","50 Leonard Street","Belmont","MA","024782517","3393680416","ENG","5373","116E, 169E, 5373, 8032, 8033, 9231, 9251","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project is to offer custom crafted digital voices for text-to-speech applications. Each one of us has a unique voiceprint - an essential part of our self-identity. Though the quality of text-to-speech technology has improved, voice options remain limited. For the 2.5 million Americans (and tens of millions worldwide) living with voicelessness who rely on devices to talk, access to a custom digital voice is a game changer. It's the difference between a functional solution and being heard, uniquely, as oneself. Enhanced opportunities for social connection increase quality of life, independence, and access to educational and vocational resources that can narrow the gap between those with and without disability. This immediate unmet societal need, coupled with the increasing proliferation of devices that speak to us and for us, creates a compelling, timely and significant commercial opportunity for high quality, personalized digital voices that can be produced at scale. By leveraging the company's crowdsourced human voicebank and proprietary voice matching and blending algorithms the technology has the potential to empower everyone to express themselves through their own voice.<br/><br/>This Small Business Innovation Research Phase II project builds on the company's NSF-funded research and Phase I results that support feasibility and commercialization of a customized voice building technology. The text-to-speech market, encompassing assistive technologies, enterprise and consumer applications, is currently valued at around $1B and is rapidly growing and ripe for innovation. To create custom voices, the company leverages the source-filter theory of speech production. From those who are unable or unwilling to record several hours of speech the company extracts a brief vocal sample - even a single vowel contains enough 'vocal DNA' to seed the personalization process. Identity cues of the source are then combined with filter properties of a demographically and acoustically matched donor in the company's voicebank. The result is a voice that captures the vocal identity of the recipient but the clarity of the donor. Phase II technical objectives address the need for 1) customer-driven voice customization, 2) quality assurance of crowdsourced recordings, 3) voice aging algorithms, and 4) targeted donor recruitment algorithms. These advances will help secure the assistive technology beachhead and spur innovations for broader applications such as virtual reality, personal robotics, and digital persona for the Internet of Things."
"1757690","Transfer-to-Excellence (TTE) Research Experiences for Undergraduates (REU) Site","EEC","HUMAN RESOURCES DEVELOPMENT","02/01/2019","09/06/2018","Jeffrey Bokor","CA","University of California-Berkeley","Standard Grant","Mary Poats","01/31/2022","$359,952.00","","jbokor@eecs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","ENG","1360","116E, 9178, 9250","$0.00","The United States is facing a severe deficit of scientists and engineers in the upcoming decades. One of the main reasons is the lack of diversity of students in STEM disciplines. Typically, students attracted by STEM majors are primarily male and come from non-Hispanic white or Asian populations. The need for appealing to and retaining students coming from non-traditional backgrounds is evident, given the shifts in the U.S. population demographics. As a way to address this issue, the Transfer-to-Excellence Research Experiences for Undergraduates (TTE REU) program of the University of California, Berkeley (UC Berkeley) supports retention in STEM fields by offering hands-on research opportunities in nanotechnology, biotechnology, and robotics to increase the confidence and persistence of community college students in their pursuit of science and engineering education and ultimately technical careers. The nine-week program brings 10 students per year from California Community Colleges (CCC), the largest community college system in the U.S., to UC Berkeley, where engineering faculty will host students in their world-class research laboratories and mentor them in their own research projects. These schools will provide a diverse pool of talented future researchers, including low-income, first-generation, and/or underrepresented minority community college students, who might not otherwise have the resources or opportunities to pursue careers in research. Students will be engaged in leading-edge engineering research projects, including nanotechnology, energy-efficient electronics, biotechnology, sustainable engineering, body-centered sensors, mechatronics, greenhouse gas research, and optoelectronics. <br/><br/>The renewal TTE REU program is a comprehensive summer research program that provides: 1) challenging research projects in leading edge engineering research laboratories; 2) counseling to prepare students to transfer to competitive four-year colleges/universities in science and engineering majors; 3) enrichment activities to build students' confidence to continue in science and engineering; and 4) exposure to the diversity of professional career opportunities that apply science and engineering training. The TTE program partners with advisors of Berkeley's Transfer Alliance Project to support its community college participants for another academic year following their research experience as the participants seek to transfer to a baccalaureate program. The main objectives of this renewal program are increasing 1) the number of underrepresented students who will seek and receive a baccalaureate degree in STEM and 2) the diversity of students pursuing graduate degrees in STEM disciplines. To accomplish these objectives, this REU Site will bring together the Center for E3S, UC Berkeley Transfer Alliance Project (TAP), and UC Berkeley engineering faculty. TAP will be a collaborator to provide academic advising and enrichment programs that prepare community colleges students to be competitive applicants to four-year colleges. Each TTE REU participant will be paired with a faculty member and a graduate student or postdoc, who will guide the student in independent research activities, at laboratory meetings, and through one-on-one mentoring meetings. TTE REU participants will also participate in academic and professional development activities to prepare for a baccalaureate degree and career in science and engineering. In addition, all TTE REU participants will be enrolled in a new online mentorship program after their summer research stay ends. This online program will enable a long-term, sustained and formalized mentoring relationship with all participants with the goal of retaining and further stimulating the students' interest in graduate school.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1345219","CREST Phase II: Computational Center for Fundamental and Applied Science and Education at North Carolina Central University","HRD","HIST BLACK COLLEGES AND UNIV, CENTERS FOR RSCH EXCELL IN S&T","02/01/2014","07/07/2017","Branislav Vlahovic","NC","North Carolina Central University","Continuing grant","Victor A. Santiago","01/31/2020","$5,409,302.00","Alade Tokuta, Gordana Vlahovic, Marvin Wu, Diane Markoff","vlahovic@nccu.edu","1801 Fayetteville Street","Durham","NC","277073129","9195307333","EHR","1594, 9131","9131, 9179, SMET","$0.00","With National Science Foundation support, North Carolina State University will continue to develop the Computational Center for Fundamental and Applied Science and Education.  The vision of the Computational Center is to lead the University?s transformation into a research intensive university with established Ph.D. programs across STEM disciplines. Project objectives are to leverage the successes of Phase I effort to establish a nationally recognized research facility with outstanding scientific and educational programs centered on active collaborations with academia, industry, government and international partners. This objective will be achieved by advancing cross-disciplinary, integrated research, educational, and outreach programs, to meet a confluence of needs in computational science and education. <br/><br/>Intellectual Merit:<br/>The Center will include sustainable, nationally recognized, computationally driven research programs across four areas: (1) development of novel nanomaterials and application of these materials in advanced optoelectronic devices; (2) low-to-medium-energy nuclear and hypernuclear few-body physics; (3) Intelligent systems and robotics; and (4) geophysical characterization of intraplate seismic zones. The center builds on the complementary and closely interwoven research and extensive collaborations established in Phase I.  The computational structures developed by the Center will result in significant new contributions in all of the four research areas.<br/><br/>Broader Impacts :<br/>The Center has already significantly enhanced the STEM research and education capacities at North Carolina Central University, and is now leading the transformation of the institution to a research oriented institution. The Phase II Center will broaden the educational and research infrastructure to enable the expansion of Ph.D. programs in STEM disciplines.   Center activities include: a) improved STEM matriculation and graduation, especially among African-American students, women, and socially and economically disadvantaged students; b) establishment of Ph.D. programs in STEM disciplines; c) improved STEM undergraduate and graduate curriculum; d) STEM graduates trained in fields critically needed by industry; and e) greater awareness of applied computational sciences among middle and high school students and the general public."
"1545481","NRT-DESE LUCID: A project-focused cross-disciplinary graduate training program for data-enabled research in human and machine learning and teaching","DGE","RES IN DISABILITIES ED, NSF Research Traineeship (NRT)","09/01/2015","08/13/2015","Tim Rogers","WI","University of Wisconsin-Madison","Standard Grant","Laura Regassa","08/31/2020","$2,999,767.00","Martina Rau, Xiaojin Zhu, Martha Alibali, Robert Nowak","ttrogers@wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","EHR","1545, 1997","7433, 9179, SMET","$0.00","NRT DESE: Learning, understanding, cognition, intelligence, and data science (LUCID)<br/><br/>In modern life there are many situations requiring people to interact with computers, either so that they may learn from the machine or so that the machine may learn from them. The applications in education, industry, health, robotics, and national security hint at the enormous societal and economic benefits arising from research into the technologies that promote learning in both people and computers. Yet the potential has been difficult to realize because such research requires scientists with expertise in quite different fields of study. While computer scientists receive training in complex computational ideas and methods, they know little about how people learn and behave. This National Science Foundation Research Traineeship (NRT) award to the University of Wisconsin-Madison will prepare trainees with data-enabled science and engineering training to simultaneously understand computational theory and methods, the mechanisms that support human learning and behavior, and the ways these mechanisms behave in complex real-world situations. The traineeship anticipates equipping forty (40) doctoral students with the skills and expertise necessary to advance our understanding of human and machine learning and teaching, through a new training program that focuses on learning, understanding, cognition, intelligence, and data science.<br/><br/>This project will train doctoral students from computer science, engineering, cognitive psychology, and education sciences, with the goal of promoting a common knowledge base that allows these scientists to work productively across traditional boundaries on both basic research questions and practical, real-world problems. The traineeship will include several graduate training innovations: (1) a project-focused ""prof-and-peer"" mentoring system where scientists work in cross-disciplinary teams to address a shared research problem, (2) close involvement of partners in industry, government, and non-profit sectors to develop research problems with real-world application, (3) an information outreach effort that trains scientists to communicate with the public, industry, and policy-makers through traditional and new media outlets, (4) a flexible development plan that allows each trainee to garner the cross-disciplinary expertise needed to advance a particular research focus, and (5) new mechanisms for recruiting and retaining under-represented groups in STEM research. This training will prepare US scientists to compete globally at the highest levels for positions in science, industry, and government, in a growth sector of the 21st century knowledge economy. <br/><br/>The NSF Research Traineeship (NRT) Program is designed to encourage the development and implementation of bold, new, potentially transformative, and scalable models for STEM graduate education training.  The Traineeship Track is dedicated to effective training of STEM graduate students in high priority interdisciplinary research areas, through the comprehensive traineeship model that is innovative, evidence-based, and aligned with changing workforce and research needs.<br/><br/>This award is supported, in part, by the EHR Core Research (ECR) program, specifically the ECR Research in Disabilities Education (RDE) area of special interest.  ECR emphasizes fundamental STEM education research that generates foundational knowledge in the field.  Investments are made in critical areas that are essential, broad and enduring: STEM learning and STEM learning environments, broadening participation in STEM, and STEM workforce development."
"1253538","CAREER: Combinatorial Inference and Learning for Fusing Recognition and Perceptual Grouping","IIS","ROBUST INTELLIGENCE","10/01/2013","08/11/2017","Charless Fowlkes","CA","University of California-Irvine","Continuing grant","Jie Yang","09/30/2019","$507,903.00","","fowlkes@ics.uci.edu","141 Innovation Drive, Ste 250","Irvine","CA","926173213","9498247295","CSE","7495","1045","$0.00","When presented with a novel image, humans typically have little problem providing a consistent interpretation of the scene in terms of contours, surfaces, junctions, and the relations between them. This process of perceptual organization is closely coupled with recognition of familiar shapes and materials. Perceptual organization can aid recognition by reducing the complexity of a cluttered scene to a small number of candidate surfaces while recognition can help resolve ambiguities in grouping based on local image cues.   This project is developing a computational framework that fuses top-down information provided by recognition with bottom-up perceptual organization in order to automatically produce a coherent scene interpretation. This research includes (1) identifying local image features that provide cues to grouping and figure-ground, (2) developing libraries of composable detectors that capture the appearance of objects, parts and their spatial relations, and (3) designing models and efficient inference routines that explicitly reason about occlusion and the binding of image regions and contours into object shapes.<br/><br/>Integrated models of grouping and recognition have direct significance to expand the computer vision capabilities of robotics and assistive technologies that must operate in complex, cluttered environments.  The framework being developed also has applications in automating biological image analysis where top-down shape information are useful in resolving noisy local measurements. The computational tools developed by the project along with dissemination and educational efforts are aimed at forming an interdisciplinary bridge between biological imaging and cutting-edge computer vision research."
"1762829","Switched Adaptive Control Methods for Electrical Stimulation Induced Cycling","CMMI","Dynamics, Control and System D","06/01/2018","05/16/2018","Warren Dixon","FL","University of Florida","Standard Grant","Robert Landers","05/31/2021","$317,330.00","","wdixon@ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","ENG","7569","030E, 034E, 8024","$0.00","This project will create new control methods to maximize the effectiveness of a commonly prescribed rehabilitation therapy for individuals with neurological conditions (NCs), including stroke, spinal cord injury, and traumatic brain injury. Functional Electrical Stimulation (FES) cycling uses an externally applied sequence of voltages to cause the individual's leg muscles to contract to propel a recumbent cycle. The repetitive, coordinated motions of cycling can help restore limb function. An electric motor is available to augment the person's own muscles, if needed. This project will determine how to switch between different muscle groups and the motor to ensure desired behaviors, despite differences in muscle strength and endurance between individuals. For example, the project will examine methods to enable an FES cycle to adapt to the individual attributes of a new participant within a known time interval. The results will be validated in populations of individuals with NCs to demonstrate clinical efficacy. This project will advance the national health by improving the quality of life for individuals with NCs. In addition to these direct benefits, the project will introduce top undergraduate students to advanced research methods in this critical area of biomechanics.<br/><br/>This project will result in new methods of control design for uncertain nonlinear hybrid systems, including adaptation strategies and timing conditions. Essential aspects of the project include 1) the formulation of Lyapunov-based theorems to facilitate adaptive control for arbitrary switching between stable subsystems with a non-strict Lyapunov function; 2) the formulation of a dwell-time switching condition to ensure stability when switching between an uncontrolled (unstable) and adaptive controlled subsystems, as well as a data-driven method for learning a strict Lyapunov function from a given non-strict Lyapunov function; 3) the formulation of a switching controller that can bound the system response within a particular region of state space. Generalized theoretical outcomes will include new insights for the nonlinear systems and robotics communities. The experimental results will provide an inroad to longitudinal clinical studies in specific patient populations, with the potential to improve clinical outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1526301","RI: Small: Knowledge Representation and Reasoning under Uncertainty with Probabilistic Answer Set Programming","IIS","ROBUST INTELLIGENCE","08/01/2015","08/04/2015","Joohyung Lee","AZ","Arizona State University","Standard Grant","James Donlon","07/31/2019","$342,795.00","","joolee@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7495","7495, 7923","$0.00","Combining logic and probability is an important subject in Artificial Intelligence, and is recently being extensively studied in the area of statistical relational learning, where the main goal of representation is to express probabilistic models in a compact way that reflects the relational structure of the domain and ideally supports efficient learning and inference. However, in comparison with main knowledge representation languages, such languages do not allow natural, elaboration tolerant representation of commonsense knowledge. Currently, there is a big gap between the state of the art languages that are used in knowledge representation and the state of the art languages in which machine learning is done.  The success of this project will identify fundamental issues in bridging the gap between the two areas, will produce a uniform framework for both expressive representation and learning, and will contribute to the integration of knowledge representation and machine learning. The outcome of the research will be useful for many applications that require integration of knowledge representation and other areas, such as vision, robotics, and event recognition, where commonsense reasoning has to be applied on uncertain knowledge and data. The software systems developed under this project will be freely available as open source software. The research will involve both graduate and undergraduate students, contributing to a strengthened relationship between education and research. <br/><br/>The goal of the project is to design and implement a knowledge representation language that allows elaboration tolerant representation of expressive commonsense knowledge involving logic and probability, which can be efficiently computed by the techniques developed in related areas.  The proposed research aims at shifting the current logic-based foundation of answer set programming to a novel foundation that combines logic and probability, and achieving its computation by intelligently adapting and combining the methods from probabilistic reasoning and machine learning. It will build upon the existing works on answer set programming, statistical relational learning, and probabilisitic logic programming.  The project will (i) enhance the mathematical foundation of answer set programming to the novel foundation that combines logic and probability. (ii) relate it to other existing approaches in statistical relational learning, Pearl's causal models, and P-Log; (iii) design inference and learning algorithms; (iv) design a high level action language that allows elaboration tolerant representation of probabilistic transition systems; (v) apply probabilistic answer set programming to event recognition; (vi) implement and evaluate involved software systems."
"1662523","Learning Optimal Control Using Forward Backward Stochastic Differential Equations","CMMI","Dynamics, Control and System D","08/15/2017","08/03/2017","Evangelos Theodorou","GA","Georgia Tech Research Corporation","Standard Grant","Robert Landers","07/31/2020","$349,539.00","Panagiotis Tsiotras","evangelos.theodorou@ae.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","7569","030E, 034E, 072E, 8024","$0.00","Stochastic systems are those whose behavior is random and cannot be predicted accurately but can be analyzed statistically. Stochastic optimal control has a wide range of applications in robotics, space exploration, autonomous systems, finance, computational neuroscience and computational biology. Despite the long history of stochastic optimal control theory, existing methodologies suffer from limitations related to assumptions on the structure of the dynamics, the form of cost functions, and connections between control strategies and random disturbances. These assumptions have restricted the applicability of this control method to special classes of problems that typically have simpler descriptions. This project will expand the applicability of stochastic optimal control to a broader class of stochastic optimization problems. The educational benefits of this project involve development of a new course and instructional materials for advanced undergraduate and graduate students.  <br/><br/>In particular, this research aims to develop novel and scalable stochastic control algorithms using the theory of forward-backward stochastic differential equation and their connections to probabilistic representations of solutions of backward nonlinear partial differential equations. To aid future research and adoption of this work into these domains, the code, data, and results developed during the course of this project will be distributed freely to the scientific community. The PIs plan is to integrate powerful methods on adaptive importance sampling and forward-backward stochastic differential equations to develop scalable iterative stochastic control algorithms. In addition, this research project plans to make generalizations and extensions of the theory of forward-backward stochastic differential equations to problems such as stochastic differential games, control-constrained and bang-bang stochastic control and stochastic control under non- smooth cost functions. The work on these generalizations involves the development of algorithms which, will further expand the applicability of stochastic optimal control into new domains and new tasks. The educational plan of this research project has several goals designed to engage undergraduate and graduate students in research and inspire students to work on challenging problems at the intersection of stochastic control and statistics. The educational benefits involve development of a new course and instructional materials for advanced undergraduate and graduate students."
"1435829","DMREF/Collaborative Research: Graphene Based Origami and Kirigami Metamaterials","DMR","DMREF","09/01/2014","09/06/2018","Paul McEuen","NY","Cornell University","Standard Grant","John Schlueter","08/31/2019","$1,199,999.00","Itai Cohen","plm23@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","MPS","8292","054Z, 8400, 9177","$0.00","Graphene-Based Origami and Kirigami Metamaterials<br/><br/>Non-Technical Description: The paper arts of origami and kirigami ('ori' = fold, 'kiri' = cut) provide a powerful framework to design responsive and tunable new materials. For example, a simple series of cuts can turn a sheet of paper into an accordion-like spring, or a sequence of folds can convert it into a swan. Indeed, many biological tissues develop folds and cuts reminiscent of origami and kirigami that endow them with distinct and useful mechanical properties. The seemingly limitless number of forms that can be created speaks to the potential of exploiting such design principles for materials beyond paper. This project will extend these design ideas to the microscale using graphene, an atomically thin two dimensional material, as the nanoscale paper foundation. Lithographic techniques borrowed from the semiconductor industry will be used to pattern the graphene, and a variety of approaches will be employed to create folds, all chosen to realize a specific mechanical property. The focus is on creating mechanical 'metamaterials' - materials whose properties reflect the patterns of folds and cuts rather than the properties of the underlying paper.  With room temperature applications in mind, the theoretical effort will focus on the crucial role of thermally-activated Brownian motion in determining the material properties of graphene monolayers with cuts and folds. This paper-arts-inspired strategy has the potential to fundamentally transform the way materials are designed for the micro-world and could find applications in areas ranging from micro-robotics to mechanical sensors and actuators that mimic biologically 'active' tissues.<br/><br/>Technical Description: Using lithographic techniques, graphene sheets will be perforated and cut to create modules with prescribed mechanical properties. These modules will be assembled to create mechanical meta-materials whose response to applied stresses, temperature, and other environmental signals can be tailored. The project focuses on the following interrelated goals: (a) Experimentally testing current predictions for graphene's thermomechanical properties and their dependence on geometry and boundary conditions; (b) Creating a library of mechanically programmable modular units out of cut graphene sheets; (c) Designing meta-materials assembled out of the basic graphene kirigami and origami modules to achieve a particular function; (d)  Creating a theory of thermally excited atomically thin membranes with cuts and folds, to guide experiments and improve understanding of the basic principles. These goals will form the cornerstone for building a general-purpose open source design tool that can be used by engineers to assemble materials out of the origami and kirigami based modules, simulate their mechanical properties, and allow for iterative design work flows. This tool will be used to promote rapid materials discovery, development, and property optimization of atomic membrane origami and kirigami metamaterials."
"1634709","A Diagnostic Modeling Methodology for Dual Retrospective Cost Adaptive Control of Combustion","CMMI","SPECIAL INITIATIVES, Dynamics, Control and System D","09/01/2016","07/27/2016","Dennis Bernstein","MI","University of Michigan Ann Arbor","Standard Grant","Robert Landers","08/31/2021","$1,250,000.00","Mirko Gamba, Karthikeyan Duraisamy","dsbaero@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","1642, 7569","030E, 031E, 032E, 033E, 034E, 035E, 039E, 040E, 099E, 1059, 7234, 8024","$0.00","Control technology makes it possible to use robotics for manufacturing and autopilots for autonomous vehicles. Control technology enhances productivity, efficiency, and safety. Applications that are especially challenging require computer algorithms that can adapt to unpredictable changes in the system and its environment. This project will use adaptive control to improve the performance of engines that burn fuel in combustion processes.  These engines are used worldwide to generate energy for the electrical grid.  The challenging problem is to burn the fuel more efficiently and reduce pollution despite changes in the demand for electricity.  The technology developed under this project will enhance the operation and reliability of the electrical grid while reducing the emission of greenhouse gases and soot particles.  The project will involve students from multiple engineering disciplines and will enhance the diversity of future professionals working in this area of technology.<br/> <br/>This project will advance knowledge and understanding in the theory and practice of feedback control by developing diagnostic modeling techniques for retrospective cost adaptive control (RCAC). The modeling information required by RCAC concerns the presence of specific features (such as right-half-plane zeros and nonlinearities) as well as the accuracy with which those features must be known (locations of the right-half-plane zeros and details of the nonlinearities).  As an extension of RCAC, adaptation and closed-loop identification are performed concurrently as dual RCAC (DRCAC). This technique depends on efficient algorithms for biquadratic optimization. If identification with DRCAC using feedback sensors fails to reveal the essential modeling details, then non-feedback sensors with more in-depth diagnostic capability will be used to probe the system to obtain data for calibrating reduced-fidelity models. These models will be used by DRCAC for online analysis and closed-loop simulation, and, if necessary, the feedback sensing and actuation strategy will be modified. The intellectual objective of this project is a deeper understanding of dual control and the development of the diagnostic methodology in order to facilitate adaptive control of complex systems in theory and practice."
"1543209","SciGirls Code: A National Connected Learning Model to Integrate Computing in STEM Learning with Middle School Girls","DRL","STEM + Computing (STEM+C) Part, RES ON GENDER IN SCI & ENGINE","09/15/2015","09/09/2015","Joan Freese","MN","Twin Cities Public Television","Standard Grant","Jolene K. Jesse","08/31/2019","$1,239,048.00","Karen Peterson, Rita Karl, Cassie Scharber","jfreese@tpt.org","172 East Fourth Street","Saint Paul","MN","551011492","6512291347","EHR","005Y, 1544","8212","$0.00","This proposal was submitted in response to the STEM + Computing Partnerships (STEM+C) program solicitation NSF 15-537. The STEM+C program seeks to advance new approaches to, and evidence-based understanding of, the integration of computing in K-12 science, technology, engineering and mathematics (STEM) teaching and learning. Twin Cities Public Television in partnership with the National Girls Collaborative Project (NGCP) and the University of Minnesota Learning Technologies Media Lab, will implement A National Connected Learning Model to Integrate Computing in STEM Learning with Middle School Girls. Even though technology is pervasive in modern life, women continue to be underrepresented in computer science (CS) study and professions. Decades of research suggest the issues that contribute to CS pipeline deficits are complex, and they begin early. Although girls and boys do not display a significant difference in their abilities in math and science, research suggests that the cause for the gap in CS is social and environmental. A contributing factor consistently mentioned in the literature is that girls often do not feel they belong in CS classes, because boy peers have more experience with the concepts being taught from exposure to coding outside of school. Furthermore, research suggests that CS courses can isolate girls by their very design with: 1) curriculum that is irrelevant; 2) pedagogies that discourage collaboration; 3) lack of opportunities to take risks and make mistakes; and 4) heavy reliance on lecturing instead of hands-on, project-based learning. Connected learning pedagogy, where youth make things, work on projects they find personally relevant, and have open access to project tools and materials, addresses these issues head-on. Likewise, designing experiences for girls that employ best practice strategies for gender equitable teaching can help diminish the gap in CS. SciGirls Code will offer the CS education field a new model for using digital media to empower girls, role models, and STEM educators, ultimately enriching and supporting girls' pursuit of CS in academic settings.<br/><br/>This two-year pilot program will use principles of connected learning with 16 STEM outreach partners to provide girls and their leaders with computational thinking and coding skills. Findings will inform scale-up within the broader network of girl-serving STEM programs nationwide. Project goals are to: 1) spark and strengthen girls' interest, skills, and confidence as technology creators before high school, when attitudes and academic choices can influence postsecondary CS studies and careers; 2) support girls' efforts by training educators and role models in best practices for engaging girls in gender equitable STEM education; and 3) contribute to the field by researching the connected learning model for out-of-school learning of CS. These goals will be reached by the following activities: a nine-month curriculum centering on three tracks, including e-textiles and wearable technology, robotics, and mobile geospatial technologies; role model training for women technology professionals; professional development for STEM educators; and a research component to inform program success, impact and refinement. The project is grounded in a connected learning approach, which is based on social learning theory, that postulates that the active support of trained educators and role models will boost the development of middle school girls' computational thinking skills, attitudes towards computing pathways/careers, and understanding/appreciation of how participation in technology creation impacts themselves and the world around them."
"1553823","CAREER: Control of Advanced Fuel-Flexible Multi-Cylinder Engines","CMMI","CAREER: FACULTY EARLY CAR DEV, Dynamics, Control and System D","03/01/2016","01/13/2016","Carrie Hall","IL","Illinois Institute of Technology","Standard Grant","Robert Landers","02/28/2021","$500,000.00","","chall9@iit.edu","10 West 35th Street","Chicago","IL","606163717","3125673035","ENG","1045, 7569","030E, 031E, 032E, 033E, 034E, 035E, 039E, 040E, 099E, 1045, 1059, 7234, 8024, 9102","$0.00","This Faculty Early Career Development (CAREER) project will investigate the dynamics and control of advanced combustion strategies that have the potential to increase the efficiency of fuel-flexible diesel engines by up to 20 percent. The use of alternative fuels in modern vehicles typically results in higher production of some pollutants, as well as a drop in efficiency. However, the combination of alternative fuels along with more advanced combustion techniques has the potential to solve this problem, and provide efficient, clean power for transportation. While the benefits of this strategy have been demonstrated in highly monitored laboratory environments, significant improvements in the control of multi-cylinder engines are needed before these benefits can be realized in production vehicles. This project will create estimation and control methods for complex engine systems. The project will also provide  opportunities for underrepresented students to work in this critical area of transportation energy research.<br/><br/>The control of advanced combustion engines is particularly challenging due to the low availability of sensor measurements in the harsh engine environment, the highly nonlinear and internally coupled behavior of the system, and significant cycle-to-cycle and cylinder-to-cylinder variations. To meet these challenges, this research will study and model the dynamics of a multi-cylinder advanced engine system. With an improved understanding of the dynamics, the research team will then create nonlinear estimation techniques that capture key variables for which measurements are not available and which are primary drivers in combustion variations.  This project will culminate in the investigation of nonlinear model predictive control techniques that can provide optimal performance to this complex system with its constrained and coupled inputs. While reliable linear control techniques have existed for decades, control strategies for highly nonlinear applications such as advanced engines are not well established. Expansion of the current nonlinear control strategies to such systems will provide valuable insight not only for internal combustion engine applications but other complex system structures in areas such as robotics and hybrid vehicles."
"1717207","AF:  Small:  Collaborative Research:  Distributed Quasi-Newton Methods for Nonsmooth Optimization","CCF","ALGORITHMIC FOUNDATIONS","09/01/2017","08/30/2017","Nikolaos Freris","NY","New York University","Standard Grant","Balasubramanian Kalyanasundaram","08/31/2020","$163,160.00","","nf47@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7796","7923, 7933","$0.00","Optimization, which finds the inputs to a mathematical function that produce the minimum output, is a workhorse algorithm behind many of the advances in smart devices or applications in the cloud. As data gets larger and more distributed, new ideas are needed to maintain the speed and accuracy of optimization. Operator splitting, which expresses the function to minimize as the sum of two convex functions, one of which is smooth and the other non-differentiable, is an idea that has produced to new first-order optimization methods.  This project explores operator splitting with second-order optimization methods, which have faster convergence to the minimum.  The focus is on large, distributed, and streaming data sets, so that the resulting general-purpose numerical solvers and embedded systems implementations can support optimization in cyberphysical systems and the Internet-of-Things.   The project has as priority the active engagement and training of students and researchers, with specific emphasis on the inclusion of women and under-represented minority groups. This project not only involves collaboration across three top-tier American universities, but also with European research institute, KU Leuven. <br/><br/>In specific, this research project seeks to interpret existing methods for structured convex optimization (such as the celebrated ADMM algorithm) as gradient methods applied to specific functions arising from the original problem formulation, and  interpret of operator-splitting techniques as fixed point iterations for appropriately selected operators.  A key theoretical foundation is the introduction of new envelope functions (smooth upper approximations possessing the same sets of solutions) that can be used as merit functions for variable-metric backtracking line-search. To conclude, a principal focus of the project is to design distributed asynchronous methods applicable to large-scale multi-agent cyberphysical systems that involve big data and impose stringent real-time constraints for decision-making. In this purview, the goal is to deliver methods that will outperform current state-of-the-art in terms of (a) speed of computations, (b) scalability with big data sizes, (c) robustness to various types of uncertainty, and, most topically, (d) distributed asynchronous implementation over networks in real-time. The merits will be illustrated in the context of applications in signal processing, control, machine learning and robotics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1719386","ICN-WEN: Collaborative Research: Light-Speed Networking (LSN): Refactoring the Wireless Network Stack to Dramatically Reduce Information Response Time","CNS","INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE","09/01/2017","07/21/2017","Arun Venkataramani","MA","University of Massachusetts Amherst","Continuing grant","Darleen L. Fisher","08/31/2020","$430,091.00","Phillipa Gill, Deepak Ganesan, Amir Houmansadr","arun@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","1640, 1714","021Z, 7363","$0.00","A key hurdle for next-generation mobile and wireless applications such as autonomous vehicle safety, tactile Internet, virtual/augmented reality, industrial robotics, and tele-surgery is ultra-low information response time (IRT), since these applications continue to see significant improvement in user-perceived experience all the way down to an IRT as low as a millisecond. Unfortunately, today's Internet protocol stack, despite the rather ambitious projections of emerging wireless communications standards, is unable to achieve a 1 millisecond common-case IRT in wireless environments. A fundamental bottleneck for reducing IRT is propagation delays limited by the speed of light as well as a variety of factors across the protocol stack. This project is investigating the design, implementation, and evaluation of a ""light-speed networking"" (LSN) architecture seeking to dramatically reduce IRT in wireless edge networks by incorporating an information-centric approach holistically across the different layers of the network protocol stack. This project will also develop novel curricula and dissemination materials aimed at education of a new generation of workforce in information-aware networking principles that are going to be the foundation of future communication networks.<br/><br/>The LSN project will enable the network to automatically migrate a remote service endpoint close to the end-user, for example, onto a nano-cloud on a virtualized base station, thereby cutting down propagation delays limited by the speed of light. LSN combines this capability with several other novel ideas including information-value-awareness: enabling different layers to leverage application-level knowledge about the value and semantics of the data; private information retrieval: enabling users to access information without revealing to the network what they are accessing; radio polymorphism: enabling intelligent use of different radios based on information value; access-point-centric security and privacy enhancements;  etc. LSN builds upon key ideas from recent next-generation Internet architecture projects including MobilityFirst and XIA."
"1761622","Theory and Algorithms for Feedback Particle Filter","CMMI","Dynamics, Control and System D","08/01/2018","08/01/2018","Prashant Mehta","IL","University of Illinois at Urbana-Champaign","Standard Grant","Robert Landers","07/31/2021","$378,028.00","","mehtapg@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","7569","030E, 034E, 8024","$0.00","Finding accurate solutions for complex optimization problems and other related challenging mathematical problems is very important in many engineering applications. Some example applications include: target tracking and surveillance where multiple sensor measurements are used to track targets, air traffic management to track airplanes, weather surveillance to track hurricanes, ground mapping, geophysical surveys, remote sensing, autonomous navigation, and robotics. State-of-the-art solution approaches to these problems include the Kalman filter algorithm and its many extensions.  However, in practice, such approaches can yield inaccurate and erroneous solutions because of technical issues related to complexity in dynamics and uncertainty.  In the past decade, a new class of algorithmic solution approaches to these problems has emerged referred to as the ""Feedback Particle Filter"".  The Feedback Particle Filter can better handle the technical issues related to such complex dynamics and uncertainty.  This research will advance the theoretical development and verification of the Feedback Particle Filter algorithm, and lay the groundwork for software tools that will be useful in tracking applications noted above. The project also includes several educational initiatives that seek to engage undergraduate students in entrepreneurship.   <br/>   <br/>A major objective of the research concerns the development of optimal control formulations of the feedback particle filter based on optimal transportation theory and mean-field games formalisms.  The theoretical research is closely integrated with the work on computational algorithms.  The algorithmic objectives pertain to numerical solution of the Poisson equation, convergence analysis of the particle system with finitely many particles, and comparisons with importance sampling-based algorithms.  The deliverables include efficient numerical schemes which will be implemented and demonstrated in software.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1811393","High spatial resolution tactile sensing imager using optical exceptional point structures","ECCS","ELECT, PHOTONICS, & MAG DEVICE","09/01/2017","02/06/2018","Liang Feng","PA","University of Pennsylvania","Standard Grant","Dominique M. Dagenais","08/31/2019","$129,217.00","","fenglia@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","ENG","1517","094E","$0.00","Title: High Spatial Resolution Tactile Sensing Imager Using Optical Exceptional Point Structures<br/><br/>Non-technical description:<br/>Tactile sensors have been widely used in touch screens of smart phones to respond to touching force. Such force sensing, monitoring, and mapping are of great interest in smart system-driven healthcare, robotics and military applications. A variety of electronic and optical tactile sensors have been developed to approach the desirable tactile sensing imager with high spatial resolution and great flexibility. However, the major drawback of the state-of-the-art tactile sensors is low spatial resolutions due to their fundamental limitations on the sensor pixel size on the order of sub-centimeter/millimeter. In this work, the investigators will leverage recent advances in quantum-inspired photonics to develop a high spatial resolution tactile sensing system with highly scalable sensor pixels that can monitor strain response at a microscale. Its integration with smart phones can create a compact and portable tactile sensor platform overcoming barriers in low spatial resolution, high cost, and high instrumental complexity of the state-of-the-art tactile sensors. This research is closely integrated with the existing educational activities, providing both undergraduate and graduate students with the opportunity to participate in cutting-edge science and technology in an innovative way. The investigators also provide educational outreach activities to promote the interests and participations of K-12 students and broaden the participations from underrepresented groups. <br/><br/>Technical description: <br/>The primary focus of this research project is to develop novel planar optical systems with optical exceptional points and arrange them on a flexible plastic platform in a chessboard configuration for high spatial resolution tactile sensing and imaging. The optical exceptional point structures, due to their planar nature, can support highly scalable fabrication using the widely used photolithography technique with spatial resolution down to even the microscale in a large area. Based upon a flexible plastic platform, this microscale tactile sensing imager can not only perform high-throughput real-time microscopic strain detection, but also enable simultaneous strain and temperature measurement with a microscopic resolution. The tactile sensor platform can be further integrated with portable electronic devices (e.g. hand-held smart phones), which would create a compact and portable tactile sensor imager platform for real-time detection in microbiology and healthcare, for example, the detection of mechanical properties of biomolecules. The principal investigators have highly complementary expertise in optics theory, advanced micro/nanofabrication technology, and device integration to design and fabricate the unique portable high spatial resolution tactile sensing platform based on novel optical exceptional point structures. The realized tactile sensing systems are expected to represent an important technological breakthrough in strain sensing, mapping and monitoring at a microscale with sensitivities orders of magnitude better than the state-of-the-art tactile sensors."
"1464654","Collaborative Research:  I/UCRC Phase II:  Security and Software Engineering Research Center (S2ERC)","CNS","INDUSTRY/UNIV COOP RES CENTERS, , , , , , , , , , , , ","05/15/2015","09/04/2018","Wayne Zage","IN","Ball State University","Continuing grant","Dmitri Perkins","04/30/2020","$1,407,416.00","Dolores Zage","wmzage@bsu.edu","2000 West University Avenue","Muncie","IN","473060155","7652851600","CSE","5761, O213, O214, O215, O384, P146, P189, P280, P411, Q198, Q233, Q333, R338","170E, 5761, 8032, 8039, 8237","$0.00","The Security and Software Engineering Research Center (S2ERC) is an Industry/University Cooperative Research Center devoted to applied and basic research addressing security and software engineering issues that plague both industrial (defense and commercial) companies and government agencies. Nearly all companies market products and services that involve software. The software is either a commercial product or a supporting technology for other products or services. Advances in software engineering are critical to the technical dominance and market performance not only of IT companies, but also of producers of products such as aircraft and their components, automobiles, medical devices, sensors, computer-aided diagnostics and robotics. Software developers and customers desire software that costs less, matches users needs, is secure, has credible defenses and fewer defects, executes faster, is easier to update and is completed on time. With societies growing dependence on software, it is important that software engineers build secure software cost-effectively and reliably.  The investment in S2ERC has the potential to produce significant results given the expertise at the university sites, the many technical affiliate partners, and the importance of software to our national security and competitiveness.  S2ERC researchers are focused on discovering unique solutions for security and software engineering issues which in turn benefits the whole of society as technology is properly constructed and managed.<br/><br/>The S2ERC's technical goals are the creation and transfer of innovative software technologies and engineering skills to its affiliates and the training of both graduate and undergraduate students in promising research directions. The S2ERC research initiatives include intrusion detection, ad-hoc network security, wireless security, attack-tolerant systems, trustworthiness in cloud and mobile applications, security and vulnerability analyses, information protection, requirements capturing, software design, software metrics, software feature analysis, software testing, software reliability, user interface design, usability issues, global software development, migrating software to multi-core architectures, visualization environments, interactive collaborative environments, dynamic and static analyses, and testing and model checking for concurrent programs.  As S2ERC partners with industry and federal agencies, it is expected that security and software engineering research will continue to integrate into broader programs and activities of national interest."
"1836936","FMitF: Collaborative Research: Synergies between Program Synthesis and Neural Learning of Graph Structures","CCF","FMitF: Formal Methods in the F","01/01/2019","09/04/2018","Mayur Naik","PA","University of Pennsylvania","Standard Grant","Nina Amla","12/31/2022","$450,000.00","","mhnaik@cis.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","094Y","062Z, 8206","$0.00","A challenging problem in a diverse and growing body of applications concerns automatically generating computer programs that satisfy desired functional requirements. Two promising and complementary approaches that have recently emerged to address this problem are program synthesis and neural learning. This project aims to synergistically combine the two approaches to improve the productivity of programmers and the quality of software. The project also aims to train graduate students at the intersection of formal methods and machine learning, engage undergraduate students in research through internships, and disseminate results in the form of publicly available course materials and open-source software artifacts.<br/><br/>Program synthesis ensures that the generated program is correct with respect to a logical specification. Moreover, users can easily guide the synthesizer away from an undesired program and towards a desired one, by changing the specification. On the other hand, neural learning can handle user requirements that are impossible to provide via a logical specification -- a fact highlighted by the success of neural networks in domains such as natural language processing, computer vision, and robotics. Moreover, neural networks scale extremely well, by virtue of their ability to learn latent patterns that repeat across different programs. This project builds upon recent progress in program synthesis by developing novel learning-based mechanisms that enable flexible specifications, richer verifiers, and scalable solvers. In the realm of machine learning, it enables deep neural networks to provide correctness guarantees that are typically required when reasoning about rich structured data. In doing so, it develops novel architectures and methodologies for representation learning, reinforcement learning, and learning with limited data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1623558","EAGER: MAKER: Play in the Making: Supporting Design Thinking in Maker Spaces among Underrepresented, Underserved, and Minority Students through Game Design","DRL","SPECIAL PROJECTS - CISE, IUSE","10/01/2016","09/20/2016","Sinem Siyahhan","CA","University Auxiliary and Research Services Corporation","Standard Grant","Erick Jones","09/30/2019","$295,393.00","Elisabeth Gee","ssiyahhan@csusm.edu","435 East Carmel Street","San Marcos","CA","920784362","7607504700","EHR","1714, 1998","7916","$0.00","The goal of this two-year exploratory research project is to develop an empirically-based teaching and learning model for broadening participation of girls, minority, and low-income middle school students in STEM and Making through game design. The model will center around a series of design challenges that engage middle school students in solving personally and socially significant real world problems using low and high-tech tools that are available in Maker spaces. While game design has been recognized as a potentially powerful means of STEM learning, it has been most commonly used to introduce children to programming. We have yet to explore the potential of making games as a means of enhancing design thinking and inspiring other forms of Making. Making games is not a common activity in Maker spaces, yet game making is an activity that appeals to a wide range of young people. Game design may be a way to attract youth who might find more typical Maker space activities to be intimidating or unappealing. This project will lay the foundation for further inquiry into the pathways that young people from underrepresented backgrounds might take from game design into other forms of Making and STEM learning.<br/><br/>The project leadership will collaborate with six mentors (3 teachers and 3 librarians) to iteratively design, test, and refine design challenges in a formal and informal learning environment. Students will engage in the design thinking process that emphasizes the role of empathy and understanding human needs as central to effective design. They will be introduced to a variety of tools ranging from paper-based and cardboard construction to e-textiles, programming, and robotics as they participate in design cycles of empathizing, defining, prototyping, and testing. Parents will be invited to participate in different stages of the design process as informants, co-designers, and user testers to support students' learning and Making process. The pedagogical strategies that will be developed as part of the project for students will inform ways to design and organize activities in the Maker context to create more inclusive learning experiences for students. Furthermore, the project will explore what support mechanisms mentors need in regard to Making and design thinking to effectively facilitate students' learning and Making. The results from this project will illuminate participation structures that are important to build a Maker community where students, educators, and parents work together as learning partners in schools and libraries. This project is a part of NSF's Maker Dear Colleague Letter (DCL) portfolio (NSF 15-086), a collaborative investment of Directorates for Computer & Information Science & Engineering (CISE), Education and Human Resources (EHR) and Engineering (ENG)."
"1526033","RI: Small: Inferring Non-Rigid Geometry from Object Categories","IIS","ROBUST INTELLIGENCE","09/01/2015","09/17/2015","Simon Lucey","PA","Carnegie-Mellon University","Continuing grant","Jie Yang","08/31/2019","$460,000.00","","slucey@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","7495, 7923","$0.00","This project integrates new theoretical developments in group sparse coding and non-rigid structure from motion (NRSFM) within model-based methods for computer vision. Geometry is at the heart of visual perception. Humans invert the procedure of 3D to 2D projection effortlessly, blissfully ignorant of the mathematics required to make such inversion possible. Computer vision has been striving to unlock these mathematical secrets for the past few decades, with the view that to create any machine that truly ""sees"" it must be able to perform a similar inversion from 2D to 3D. Inferring the camera position and the 3D structure of a scene/object from an ensemble of 2D projected points is known within the field of computer vision as structure from motion (SFM).  By definition a static 3D structure is rigid, however, the set of 3D structures with the same object category label is inherently non-rigid; making large-scale NRSFM crucial for model-based category classification and detection. <br/><br/>Model-based methods for object category classification and detection attempt to understand the interplay between an object's projected photometric appearance and its underlying geometry. These methods, however, have largely been abandoned in computer vision over the last two decades in favor of methods that rely solely on appearance (i.e. view-based approaches). As the space of computer vision and robotics continues to merge it is becoming increasingly important to not only recognize an object, but also understand how to grasp or interact with it - a task much more suited to a model-based methodology. Further, as the space of augmented reality becomes more sophisticated it is clear that 3D understanding of a scene/object is crucial - something that model-based approaches to perception naturally provide. Finally, vision machines are demanding an increasingly deeper understanding of how the visual world is allowed to vary during learning. A model-based framework can naturally accommodate this type of 3D geometric variation within a learning framework."
"1422869","CHS: Small: Fast simulation of geometrically complex multibody systems in contact and self-contact","IIS","Cyber-Human Systems (CHS)","09/01/2014","06/25/2014","Jernej Barbic","CA","University of Southern California","Standard Grant","Ephraim P. Glinert","08/31/2019","$484,210.00","","jnb@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7367","7367, 7453, 7923","$0.00","The ability to simulate complex machinery in contact is broadly applicable to engineering practice.  It can be used for virtual training, say in the operation of heavy machinery.  Perhaps most importantly, it can be used to assemble and test complex mechanical structures in virtual reality (using a human-computer interface that includes haptic feedback).  Such virtual prototyping, as it is commonly called, greatly shortens design cycles, decreases errors, improves product safety and saves millions of dollars in R&D costs.  Applications can be found anywhere a complex structure must be designed and manufactured out of many component parts: airplanes, cars, trains, spaceships, power plants, buildings, tools, heavy equipment, etc.  In this project the PI will develop computationally efficient collision detection and contact resolution methods that can accommodate complex systems consisting of many objects that are connected by joints and undergoing contact and self-contact.  His goal is to devise algorithms that are sufficiently fast to accommodate high update rates (1,000 simulation steps per second for haptics, or more), and that scale to complex real-world mechanisms typically represented by millions of triangles, such as an internal combustion engine or an entire car engine compartment, an airplane landing gear or airplane doors, or excavator machines.  Furthermore, whereas previous fast successful industrial penalty-based methods have typically been limited to pairs of objects in contact, in this research the PI's objective is to deal with more complex and realistic situations including rigid objects, joints, friction and self-contact.<br/><br/>Fast simulation of multi-body systems in contact is challenging due to the severe computational and stability requirements imposed by complex geometry. Such simulations frequently involve distributed contact, that is to say contact involving many collision sites of varying surface areas and normal orientations that change rapidly over time.  Because it is challenging for constraint-based methods to resolve such contact stably at high update rates, the Principal Investigator will exploit industry-proven penalty methods between points and implicit functions (distance fields or voxmaps), and he will extend the approach, which has to date been limited to pairs of objects in contact, to accommodate N >= 2 objects in arbitrary contact, as well as objects connected with joints and undergoing active control.  The technical challenges include how to stably resolve and time-step distributed contact between N >= 2 objects, how to stably simulate and render 6-DOF distributed contact in the presence of constraints (joints), and how to handle self-contact and incorporate friction, all the while maintaining high update rates (or gracefully degrading them in case of extreme contact).  Because the Principal Investigator's preliminary experience suggests that the discrete nature of current algorithms is an important limitation in practice, he will also investigate continuous collision detection between points and distance fields.  Project outcomes will be transitioned to engineering practice via the PI's ongoing collaborations with a number of industrical leaders in high-tech virtual prototyping, and will advance the state of the art in computer graphics, haptics, robotics and virtual reality."
"1629397","XPS: FULL: A Cross-Layer Approach Toward Low-Latency Data-Parallel Applications in Rack-Scale Computing","CCF","Exploiting Parallel&Scalabilty","09/01/2016","09/02/2016","Mosharaf Chowdhury","MI","University of Michigan Ann Arbor","Standard Grant","M. Mimi McClure","08/31/2020","$825,000.00","Barzan Mozafari","mosharaf@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","8283","","$0.00","Although many modern applications, e.g., exploratory analytics and scientific visualization, come with stringent latency requirements, today's in-memory and scale-out solutions often provide only best-effort services. A root cause of unpredictability lies in the traditional design principle of minimizing I/O operations. With the advent of faster storage and networks in rack-scale computing, however, I/O may no longer be scarce anymore. This project revisits the tradeoffs and design principles of scale-out, low-latency applications in this emerging context. Bounded response times will reduce over-provisioning and foster new applications (e.g., business intelligence, robotics, and intensive care units) that require consistent performance. Project findings will be integrated into undergraduate and graduate curricula, and software artifacts will be open-sourced for the wider community across academia and industry.  <br/><br/>This project aims to leverage the influx of new hardware capabilities to enable applications based on bounded response times as their primary design criteria. Specifically, the project leverages approximation, speculation, and scheduling to mask variabilities in latency-sensitive applications. The key technical challenge in realizing this vision lie in making a set of tradeoffs different from the norm: (i) rather than striving for less I/O, this project trades I/O off for better memory locality and aggressively speculate to reduce response times; (ii) when needed, it resorts to approximation techniques for bounded response times; and finally, (iii) it develops new approximation- and speculation-aware schedulers to increase resource efficiency. The project also investigates theoretical and empirical boundaries of approximate and speculative processing as well as new spatiotemporal scheduling techniques in rack-scale computing."
"1539376","Collaborative Research: Neural-cognitive analysis of spatial scenes with competing, dynamic sound sources","BCS","COGNEURO","09/01/2015","08/18/2015","Yi Zhou","AZ","Arizona State University","Standard Grant","Uri Hasson","08/31/2019","$337,759.00","","yizhou@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","SBE","1699","7298","$0.00","This project investigates neurocognitive mechanisms that extract important information from a mixture of sound sources. Imagine a day where you could no longer distinguish the honking horn of a car coming right at you from other street sounds. This cognitive ability to attend to one sound source while ignoring others presents an everyday challenge for people with hearing impairments. While the basic neural mechanisms for detecting and localizing single sounds are known, we do not know how the brain accomplishes auditory scene analysis with multiple sound sources. So far, studies have focused on lower brain centers in rodents and carnivores, while the neural mechanisms for source segregation are expected to be at higher levels, in the auditory cortex. This study will record the responses of single cortical neurons and conduct human-subject experiments for the same acoustic scenarios.  Based on the integration of these results, a functional auditory model will be developed.  This will provide new scientific insights and enable intelligent algorithms for hearing aids, social robotics, and surveillance systems. The project will provide research opportunities for graduate and undergraduate students and include outreach activities and online learning resources for high-school and college students to increase the public awareness of neuroscience. The research results and the model will be shared with the academic community. <br/><br/>This proposal will use an interdisciplinary approach to gain understanding of the central mechanisms of auditory scene analysis by integrating psychoacoustical experiments with single-unit electrophysiology. The study will investigate how the auditory system localizes a target sound temporally embedded in a spatially separated masker. Single-unit recording will target the caudal region of the auditory cortex, the putative ""where"" pathway for complex sound analysis. We hypothesize that cortical activity represents both the old and new sounds, so that the internal representation of the ""old"" masking source can be subtracted from the overall mixture. This facilitates a clearer perception of the ""new"" target element, demonstrating a fundamental psychophysical phenomenon within auditory scene analysis. To test this hypothesis, we will identify the neural signals for individual sound sources separately and in combination. We will then interpret these signals based on the perceptual data gained from sound localization tests with multiple moving and stationary sound sources. Discovering the fundamental brain mechanisms for auditory scene analysis will provide new neurophysiological insight into a well-established psychophysical field and offer potential technical solutions for sound-source segregation."
"1836822","FMitF: Collaborative Research: Synergies between Program Synthesis and Neural Learning of Graph Structures","CCF","FMitF: Formal Methods in the F, SPECIAL PROJECTS - CCF","01/01/2019","09/04/2018","Le Song","GA","Georgia Tech Research Corporation","Standard Grant","Nina Amla","12/31/2022","$450,001.00","","lsong@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","094Y, 2878","062Z, 8206","$0.00","A challenging problem in a diverse and growing body of applications concerns automatically generating computer programs that satisfy desired functional requirements. Two promising and complementary approaches that have recently emerged to address this problem are program synthesis and neural learning. This project aims to synergistically combine the two approaches to improve the productivity of programmers and the quality of software. The project also aims to train graduate students at the intersection of formal methods and machine learning, engage undergraduate students in research through internships, and disseminate results in the form of publicly available course materials and open-source software artifacts.<br/><br/>Program synthesis ensures that the generated program is correct with respect to a logical specification. Moreover, users can easily guide the synthesizer away from an undesired program and towards a desired one, by changing the specification. On the other hand, neural learning can handle user requirements that are impossible to provide via a logical specification -- a fact highlighted by the success of neural networks in domains such as natural language processing, computer vision, and robotics. Moreover, neural networks scale extremely well, by virtue of their ability to learn latent patterns that repeat across different programs. This project builds upon recent progress in program synthesis by developing novel learning-based mechanisms that enable flexible specifications, richer verifiers, and scalable solvers. In the realm of machine learning, it enables deep neural networks to provide correctness guarantees that are typically required when reasoning about rich structured data. In doing so, it develops novel architectures and methodologies for representation learning, reinforcement learning, and learning with limited data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1526059","RI: Small: Combining Reinforcement Learning and Deep Learning Methods to Address High-Dimensional Perception, Partial Observability and Delayed Reward","IIS","ROBUST INTELLIGENCE","09/01/2015","08/06/2015","Satinder Baveja","MI","University of Michigan Ann Arbor","Standard Grant","Weng-keen Wong","08/31/2019","$499,886.00","Richard Lewis, Honglak Lee","baveja@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","7495","7495, 7923","$0.00","Consider the problem faced by a machine agent that has to interact with some dynamical environment to achieve some goals. Concretely, imagine an agent engaged in a virtual competition as a human would. It can see the screen composed of many moving objects. At any time, it can choose one of a dozen or so actions. Its action controls one of the objects on the screen, but it often is not clear which one. Every so often the an evaluation is given of the competition. At some point the competition ends. How should such an agent choose actions, or more importantly how can we build agents that can learn to compete, i.e., achieve high scores, through trial and error. In this project methods will be developed and evaluated to build such agents.   <br/><br/>The above problem is an instance of what is called a reinforcement learning (RL) problem. Such problems abound in sequential decision-making settings. Applications in industry include factory optimization, robotics, and chronic disease management (to list but three diverse domains of interest). Like many of these RL problems, Atari games (used as a testbed here to evaluate learning strategies) have three characteristics of interest to this project. First, they generate high-dimensional images and so the agent faces a difficult perception problem. Second, they often have deeply-delayed rewards; i.e., actions have long-term consequences. For example, losing a resource may not cost at the moment of loss, but could lead to very high losses much later when that resource is critically necessary. Third, they have deep partial observability, i.e., to compete effectively one has to often remember the deep past. For example, a location encountered far back in the past may become valuable much later because a critical resource becomes available at that time and the agent would have to find its way back to that location to use the resource. It is proposed to address these three challenges respectively with new neural network architectures for predicting the consequences of actions, new methods for intrinsically motivating agents even when reward is delayed, and new recurrent neural network architectures to remember the past effectively. Success of the proposed work is expected to significantly expand the scope of application of reinforcement learning. Finally, Atari games will be used instead of, say, factory optimization as an evaluation domain because they are readily available.  They will be used to draw high-school and under-represented undergraduate students interest into complex ideas underlying the proposed work; their fun visualizations will allow them to be integrated into teaching in the PIs' classes, and there are a variety of games that vary in the degree of difficulty of the three challenge dimensions allowing more effective control of the evaluations more effectively."
"1554739","CAREER: Restoring Musculoskeletal Function by Designing Implantable Passive Mechanisms","CBET","Disability & Rehab Engineering","06/01/2016","05/23/2018","Ravi Balasubramanian","OR","Oregon State University","Standard Grant","Aleksandr Simonian","05/31/2021","$532,835.00","","ravi.balasubramanian@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","ENG","5342","1045, 9251","$0.00","1554739<br/>Balasubramanian<br/><br/>This project designs miniature implantable mechanisms for attaching muscles to tendons and bone in orthopedic surgery.  The implants take the form of passive mechanisms, such as soft tendon networks, pulleys, and linkages. Instead of directly attaching muscles to tendons and bone using sutures, a surgeon can use the passive implants to re-route and re-arrange how a patient's tendons create movement at the joint.  By doing so, the implants enable increased force or range of motion at a joint using the patient's own muscles and without using any external power or electronics.  Overall, the implants enable new surgeries that provide the patient improved and customized manipulation and locomotion function when compared with the current suture-based surgical paradigm. In terms of impact, this project is expected improve quality of life for the disabled, seniors, and veterans, lead to new research in allied areas such as biomaterials and bioethics, and lead to new medical devices.<br/><br/>The research develops a framework for the design of such implantable mechanisms after quantifying the movement deficits that arise in the current suture-based surgical paradigm.  In particular, this project develops implants for two surgical applications: an implant that differentially distributes forces and movement from one muscle to multiple tendons for use in a hand surgery to restore grasping capability following median-ulnar nerve palsy; and an implant that scales up forces for use in a foot surgery to restore the collapsed foot arch.  The implants will be validated through biomechanical simulations, human and animal cadaver experiments, and live-animal experiments.  This project integrates this research with extensive educational activities.  Specifically, this project creates new curricula using hands-on open source hardware and software to train the next generation of leaders at the middle-school, high-school, undergraduate, graduate, and teacher levels in understanding the mechanics of human body movement and using robotics to improve human body movement.  The project also includes outreach programs to increase participation of women and under-represented minorities in the STEM fields within a culture of inclusivity and equality."
"1348281","Utilizing STEM Camps and STEM Clubs to Increase Interest in STEM Fields among Females and Students of Color","OIA","EPSCoR Research Infrastructure","10/01/2013","05/13/2014","Christa Jackson","KY","University of Kentucky Research Foundation","Standard Grant","Chinonye Whitley","09/30/2019","$749,999.00","Bruce Walcott, Margaret Mohr-Schroeder, Christa Jackson, Craig Schroeder, Mark Evans","jacksonc@iastate.edu","109 Kinkead Hall","Lexington","KY","405260001","8592579420","O/D","7217","7715, 9150, SMET","$0.00","This five-year project is a joint effort among the colleges of Education, Arts and Sciences, and Engineering at the University of Kentucky.  The goal is to increase middle school students' interest and motivation to learn Science, Technology, Engineering, and Mathematics (STEM) content through providing opportunities to develop identities as STEM learners and future scientists, mathematicians, and engineers. The project focuses on examining the effect of informal STEM learning environments on students in grades 5-8, particularly females and students of color, by engaging them in hands-on activities provided through summer STEM camps and academic-year STEM clubs.   The model of increasing the STEM engagement and interest in middle school students in the Fayette County can be scaled, replicated, and adapted in other regions of Kentucky and across the nation. <br/><br/>Intellectual Merit<br/>The project strengthens two existing programs: the See Blue STEM Camp, run during summer, and the See Blue STEM Club, offered throughout the academic year, by including the development of several hands-on activities.  Examples include Crime Scene Investigation involving analysis of chemicals and dusting for fingerprints, model solar car designing and building, and robotics.  Pre-service teachers and engineering students at the undergraduate and graduate levels from the University of Kentucky are also involved, contributing to and benefiting from the summer and academic year programs.  The project evaluation includes formative and summative aspects and provides useful information on the effectiveness of the middle school student engagement in informal STEM clubs and camps.<br/><br/>Broader Impacts<br/>The project provides solid, replicable, well-tested, and evaluated models for recruiting and conducting both a STEM Camp on a University campus and a STEM Club in an urban community that targets diverse middle school students. The project plans to engage over 700 middle school students, with at least 60% being from groups underrepresented in STEM. The summer camps include not only the students but their parents as well through social media (blog, Twitter) and nightly emails. All curricula and instructional materials will be made available online via Kentucky's public STEM education website so that they may be replicated, continually modified, and sustained beyond the life of the project.  Research results will be made available through publications and conference presentations."
"1617773","NeTS: Small: Collaborative Research: Enabling Application-Level Performance Predictability in Public Clouds","CNS","Networking Technology and Syst","10/01/2016","08/29/2016","Mosharaf Chowdhury","MI","University of Michigan Ann Arbor","Standard Grant","John Brassil","09/30/2019","$238,500.00","","mosharaf@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","7363","7923","$0.00","State-of-the-art resource sharing mechanisms in today's datacenters and compute clouds are agnostic to application-level performance requirements, resulting in unpredictable performance. This is especially true for the network. Unlike, CPU, memory, or disk, cloud operators do not provide any guarantees for the network. Many tenants rely on over-provisioning and static allocation for performance isolation, which results in low utilization and increased cost and environmental impacts. This project aims to build a set of solutions to achieve short- and long-term performance predictability with high resource utilization. The goal is to enable coexisting applications from different tenants to meet a variety of performance objectives including obtaining timely responses and minimizing variance of successive responses, while adhering to organizational hierarchies of individual tenants. The key technical challenges in this project include developing short- and long-term resource allocation algorithms, accurate demand estimation, as well as fast and efficient enforcement, all of which are compounded by the multi-resource and shared nature of the network. Two key techniques guide the proposed work: (i) temporal scheduling ensures predictable performance through short- and long-term performance isolation, and (ii) spatial placement ensures higher utilization through initial placement and periodic migration of tenants' virtual machines.<br/><br/>Predictable, efficient data analytics will have significant socio-economic ramifications. It will also enable mission-critical applications, e.g., anomaly detection, fraud protection, autonomous vehicles, and robotics-- that require a highly consistent and reliable level of performance to coexist with the less sensitive ones. Algorithms and software from the project will be incorporated into existing open-source big data stacks for public reuse.  By leveraging ongoing relationships with the industry, artifacts from this project will be converted from research into practice in a fast manner. The project has significant educational and outreach components, which include introducing new courses at both graduate and undergraduate levels based on the outcomes of this project as well as arranging cloud computing boot camps aimed at students from high schools and involving women and under-represented minorities."
"1553873","CAREER: A Compositional Approach to Modular Cyber-Physical Control System Design","ECCS","ENERGY,POWER,ADAPTIVE SYS, CYBER-PHYSICAL SYSTEMS (CPS)","02/15/2016","01/27/2016","Necmiye Ozay","MI","University of Michigan Ann Arbor","Standard Grant","Radhakisan S. Baheti","01/31/2021","$500,000.00","","necmiye@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","7607, 7918","1045, 7918","$0.00","Complex, networked, distributed cyber-physical systems (CPSs) are emerging in many safety-critical application domains such as aerospace and automotive. Design of such systems heavily relies on insights and experiences of engineers as principled design methodologies that can cope with the complexity of these systems are lacking. As a result, extensive testing and fine-tuning is required to ensure that the final product satisfies the design objectives. As a principled alternative, this project proposes to use modularity for managing complexity during both the design- and the life-cycles of cyber-physical systems. The objective is to develop the scientific foundation and associated algorithmic tools for the design of modular cyber-physical control systems. If successful, in the long-run this research will lead to a ""plug and play"" integration framework for CPSs supported by automated design tools, where one can replace a subsystem with another one or perform upgrades to subsystems while maintaining operational correctness guarantees. Results from this research will be relevant to many application domains, including next generation air vehicles, automotive systems and robotics. Its potential transformative impact will be on the way CPSs in these domains are designed and operated. Translation to the economy will proceed by actively seeking and engaging industrial partners. This research effort will be complemented by an education plan where interdisciplinary research and thinking in the area of CPS will be fostered among undergraduate and graduate students to prepare the next generation of CPS researchers and practitioners.<br/><br/>To be specific, the project will develop theoretical foundations and associated algorithmic tools for distributed synthesis of provably correct control protocols that give rise to compositional design principles for cyber-physical control systems. In particular, algorithms for decompositions of system requirements at the discrete/logic level and of the system states at the continuous/system level will be developed. The main idea is a novel separation between external and internal factors affecting each subsystem that allows internal interactions required for the successful operation of a subsystem to be computed explicitly. These internal interactions, namely interface rules, are captured in terms of assumption and guarantee pairs that are used for solving local synthesis problems to obtain local controllers in a distributed manner, while maintaining global correctness guarantees when these controllers are deployed simultaneously. The modularity-performance trade-off space will be explored by introducing proper partial orders on these interface rules and by tuning the complexity of the interface rules according to these order relations. Tools from control theory (decentralized and robust control, model reduction, discrete event systems) and formal methods (temporal logics, compositional verification, distributed reactive synthesis) will be brought to bear to address these problems."
"1539276","Collaborative Research: Neural-Cognitive Analysis of spatial scenes with competing, dynamic sound sources","BCS","COGNEURO, PERCEPTION, ACTION & COGNITION","09/01/2015","08/18/2015","Jonas Braasch","NY","Rensselaer Polytechnic Institute","Standard Grant","Uri Hasson","08/31/2019","$335,598.00","","braasj@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","SBE","1699, 7252","7298","$0.00","This project investigates neurocognitive mechanisms that extract important information from a mixture of sound sources. Imagine a day where you could no longer distinguish the honking horn of a car coming right at you from other street sounds. This cognitive ability to attend to one sound source while ignoring others presents an everyday challenge for people with hearing impairments. While the basic neural mechanisms for detecting and localizing single sounds are known, we do not know how the brain accomplishes auditory scene analysis with multiple sound sources. So far, studies have focused on lower brain centers in rodents and carnivores, while the neural mechanisms for source segregation are expected to be at higher levels, in the auditory cortex. This study will record the responses of single cortical neurons and conduct human-subject experiments for the same acoustic scenarios. Based on the integration of these results, a functional auditory model will be developed. This will provide new scientific insights and enable intelligent algorithms for hearing aids, social robotics, and surveillance systems. The project will provide research opportunities for graduate and undergraduate students and include outreach activities and online learning resources for high-school and college students to increase the public awareness of neuroscience. The research results and the model will be shared with the academic community. <br/><br/>This proposal will use an interdisciplinary approach to gain understanding of the central mechanisms of auditory scene analysis by integrating psychoacoustical experiments with single-unit electrophysiology. The study will investigate how the auditory system localizes a target sound temporally embedded in a spatially separated masker. Single-unit recording will target the caudal region of the auditory cortex, the putative ""where"" pathway for complex sound analysis. We hypothesize that cortical activity represents both the old and new sounds, so that the internal representation of the ""old"" masking source can be subtracted from the overall mixture. This facilitates a clearer perception of the ""new"" target element, demonstrating a fundamental psychophysical phenomenon within auditory scene analysis. To test this hypothesis, we will identify the neural signals for individual sound sources separately and in combination. We will then interpret these signals based on the perceptual data gained from sound localization tests with multiple moving and stationary sound sources. Discovering the fundamental brain mechanisms for auditory scene analysis will provide new neurophysiological insight into a well-established psychophysical field and offer potential technical solutions for sound-source segregation."
"1734247","NRI: FND: COLLAB: Drones and the Design of Public Outdoor Spaces","IIS","National Robotics Initiative","10/01/2017","09/14/2017","Hala Nassar","SC","Clemson University","Standard Grant","Ralph Wachter","09/30/2020","$299,859.00","","hnassar@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","CSE","8013","8086","$0.00","With recent regulatory changes allowing for the commercial use of unmanned aerial vehicles, aka drones, many new opportunities are emerging for public engagement, especially in areas like filming live music events, coverage of sporting events, and creating powerful imagery of landmarks or monuments. However, these technology advancements have also led to a proliferation of hobbyist drones. As a result, there are increasing reports of illegal drones flying in these same spaces, which present a risk to people on the ground or to those commercial drones legitimately flying in the spaces. Outdoor public space managers could benefit from design guidelines and technology recommendations for systems that could detect and potentially mitigate unwanted drone incursions into their spaces while protecting both people on the ground and legitimate drones. There is a need to explore passive approaches to drone detection and mitigation for public areas that attract small to medium sized crowds, particularly those approaches that are affordable and safe.<br/><br/>Through assembling a multidisciplinary team of engineers and landscape architects, Duke University and Clemson University researchers take a systems-theoretic approach to analyzing and addressing this problem. Such a problem is multidimensional with multiple stakeholders, including venue managers, the general public, and legitimate drone operators contracted by the venues for services. Involving critical stakeholders at all points in the process, a model of those variables that interrelate in the design of passive drone detection and mitigation systems will be developed, including operating environments, physical and cost constraints, and security and aesthetic considerations. Design prototypes will be built and tested. A set of formal guidelines and a design trade space that reflects costs and capabilities for a range of passive technologies will also be developed that can be used by designers and mangers of outdoor public spaces, who will be increasingly struggling with this problem."
"1723606","SaTC: EDU: Software Defined Radio Wars for Cybersecurity and Information Assurance Education","DGE","Secure &Trustworthy Cyberspace","09/01/2017","08/11/2017","Kapil Dandekar","PA","Drexel University","Standard Grant","Victor P. Piotrowski","08/31/2019","$299,888.00","Nagarajan Kandasamy, Jennifer Stanford, Pramod Abichandani, Stefan Rank","dandekar@drexel.edu","1505 Race St, 10th Floor","Philadelphia","PA","191021119","2158955849","EHR","8060","7254, 7434, 9178, 9179, SMET","$0.00","The pervasive use of wireless networks has created a demand for students who are trained to include security in the design constraints of new systems, not as an afterthought. This project from Drexel University proposes to leverage the hands-on learning opportunities offered by software defined radios (SDRs) to emphasize the interdisciplinary nature of cybersecurity and information assurance. The researchers aim to accomplish their goal by developing and offering an academic curriculum that consists of a series of 3-courses with competitions (Radio Wars) centered around various interdisciplinary degrees of freedom of a SDR. Students will be tasked to securely transmit information, while preventing others from doing so. Throughout their exposure to materials, students will start with wireless communication basics and dive into adding encryption, authentication, and power management modules to their radios. The researchers will use assessment techniques focused on understanding whether the curriculum provides students with a learning experience that is authentic to the work of the discipline and promotes development of content knowledge and skills relating to excelling in the cybersecurity field. The project aims to have broader impacts in preparing cybersecurity individuals for the workforce by leveraging connections with the NSA as well as offering learning opportunities to high school students, which will expose them early on to cybersecurity, engineering and STEM fields. Finally, the team plans to maximize their impacts by disseminating the course materials designed for other researchers to be able to adopt them. <br/><br/>The Ettus USRP N210 SDR platform provides the flexibility and ease of use needed to implement Radio Wars and will thus serve as the platform for the proposed project. The project will leverage the ceiling mounted SDR grid network at Drexel University as the ""battleground"". A visual scoreboard system will be implemented for real-time feedback for student progress. This system will require specific API calls to be used by students. The first year of the project will focus on developing the curriculum and the hardware/software backbone using GNU Radio, UHD, and Python programming. The second year of the project will be when the Radio Wars courses will be offered. Students will be asked to implement various encryption (AES, TLS, IPSec, WEP and WPA2) and authentication techniques to maximize their score. Each action taken by student teams during the competition will be logged for scoring. The project hopes to develop an educational suite that will begin to do for cybersecurity and information assurance education what ""Battlebots"" does for robotics and mechanical engineering education."
"1550967","An International Network to Consider the Ethical Use of Emerging Technologies","SMA","CROSS-DIRECTORATE  ACTIV PROGR, Science of Learning Activities, Science Across Virtual Instits","09/15/2015","08/04/2017","Andrea Chiba","CA","University of California-San Diego","Standard Grant","Soo-Siang Lim","08/31/2019","$304,550.00","Terrence Sejnowski, Patricia Smith Churchland, Roger Bingham","chiba@cogsci.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","SBE","1397, 7704, 8077","059Z, 5912, 5921, 5927, 7916, 8058","$0.00","The global acceleration in technological innovation and transformation is incidentally leading to a scientific culture in which technology is often designed and launched without providing ethical guidelines for its use. Thus, the mere pace of technology mandates an urgent need for establishing ethical guidelines as part of the natural course of science. Ultimately, a sustainable landscape of innovation will include a culture of partnership between the scientific community and ethicists, allowing capitalization on the benefits of discovery while mitigating the liabilities to society. This movement must be driven as a team effort at the outset. Thus, a primary purpose of this proposal is to formulate a cross-disciplinary team of scientists and ethicists to consider the ethical use of a select set of emerging technologies for application to the science of learning, education, rehabilitation, medicine, and augmented humans.  <br/><br/>At the outset, a team of engineers, cognitive scientists, psychologists and educators will work alongside ethicists with expertise in the ethics of virtual reality, neurorehabilitation, robotics, wearable sensors, and augmented humans through a workshop-style forum, set at the University of Queensland, Australia, in order to forge a path for establishing ethical guidelines as part of the scientific process. A virtual organization will be formed to sustain these efforts and to create a secure forum for continual interaction between scientists and relevant ethicists and policy makers. The international component of this grant is absolutely essential not only to the training of a diversity of students who will be trained to lead sustainable science in the future, but also to balance the venture as an international problem worthy of coordination and international collaboration at the outset. Both the international component and the virtual forum also establish the fact that ethical guidelines and policy need to be an inherent component of STEM education. Educational activities for graduate students are an inherent component of each goal of the grant and programs for recruitment and inclusion of under-represented students are embedded in the plan. Additional STEM education materials, and established routes for broader dissemination to under-represented students, will be produced as a byproduct of the high level scientific program. The activities will conclude with a fully articulated process for establishing ethical guidelines as an integral part of technology development."
"1801123","Consortium for Advanced Manufacturing of Cell and Tissue-Based Products","DUE","ADVANCED TECH EDUCATION PROG","09/01/2018","04/09/2018","Thomas Tubon","WI","Madison Area Technical College","Standard Grant","Rupa Iyer","08/31/2021","$570,200.00","James DeKloe, Bryan Woodhouse, Lisa Seidman, Jeanette Mowery","tubon@madisoncollege.edu","1701 Wright Street","Madison","WI","537042599","6082466676","EHR","7412","1032, 9178, SMET","$0.00","This project aims to coordinate a network of stakeholders that will promote economic growth through workforce development in Advanced Manufacturing of Cell and Tissue-based Products (AMCTP). AMCTP requires a new kind of manufacturing that uses robotics, microfluidics, 3-D printing, computational modeling, and novel types of engineering to construct biologically relevant products composed of living cells in combination with natural or synthetic materials. The field is built upon advances in stem cell biology, genome editing, synthetic biology, computational modeling, micro- and nano-fabrication, tissue engineering, and 3-D additive manufacturing. The products of AMCTP have the potential to extend our understanding of disorders and may provide effective methods for treating conditions such as Parkinson's disease, spinal cord injury, macular degeneration, diabetes, and heart disease. There are expanding career opportunities in this field, as well as unmet needs to develop a workforce that has the required skills. By creating a network of stakeholders from education, government, and industry, the goal of the Coordination Network is to develop a skilled, diverse workforce for AMCTP and inform the public about AMCTP.<br/> <br/>This coordination network will use the experience, expertise, and perspectives of diverse stakeholders to unify efforts and scale up the progress in preparation of entry, middle-skill, and senior level career tracks in AMCTP.  Madison area Technical College will work with stakeholders to ensure that project activities include principles of inclusion, equity, equality, and diversity. The lessons learned in this project have the potential to serve as a model for similar efforts in other emerging technology areas. The project aims to accomplish four objectives:  (i) establish a national consortium and a system of governance based on shared interest and public-private partnerships to enable workforce development for AMCTP; (ii) conduct annual meetings of the AMCTP consortium and focused Special Interest Group meetings; (iii) identify/develop/disseminate industry-based AMCTP core competencies and identify and disseminate information about relevant workforce education/training options; and (iv) create a structure for sustainability based on public-private partnerships, investments, and commitments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1663227","Probabilistic Design of Systems of Cyber-Physical Systems","CMMI","ENGINEERING DESIGN AND INNOVAT, Systems Science (SYS)","05/15/2017","05/19/2017","Yan Wang","GA","Georgia Tech Research Corporation","Standard Grant","Richard Malak","04/30/2020","$375,000.00","","yan.wang@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","1464, 8085","067E, 068E, 073E, 8024, 8043","$0.00","Cyber-physical systems are engineered systems that rely on a tight integration of computational algorithms and physical components. Such systems are becoming increasingly important in modern society. Examples include smart home and office appliances, robotics, modern manufacturing equipment, medical devices, and automobiles. In many cases, these systems are connected to Internet and form an interconnected system, often referred to as the Internet of Things, with advanced capabilities to sense the environment, exchange information, and interact with humans. Given the rising importance of systems of cyber-physical systems in engineering, business, and social environments, improvements in their design can have major impacts on society. One challenge in designing such systems is to ensure the system is resilient, meaning that it can recover from major disruptions when a portion of the system fails to function or communicate. Another challenge is how to take social behaviors into consideration in their design so that people will feel comfortable to use such systems because they constantly collect and share our information. The goal of this research is to understand how to systematically design networked systems of cyber-physical systems such that they are resilient and trustable. This will include new techniques for measuring key properties of complex systems as well as techniques to design them with better performance. Results will be shared, in part, through open-source software created during this research to help engineers design better systems. Web-based learning modules about cyber-physical systems intended for the general public also will be created and shared broadly.<br/><br/>The objective of this project is to create and demonstrate a probabilistic design methodology for networked and deeply interdependent cyber-physical systems that incorporates meta-modeling and discrete-event fine-grained modeling. The methodology will enable the design of system-of-system architecture that addresses functionalities of information gathering and exchange under the challenges of resiliency, adaptability, and trust. An information-based quantitative performance measure for resilience will be created. Mathematical models will be formulated to analyze the information interdependency between individuals. Quantitative measures of trustworthiness will be developed to support trust-based strategic network design and optimization. These novel approaches will be demonstrated and evaluated in a design study of highly networked manufacturing machines in supply chains."
"1717154","AF:   Small:   Collaborative Research:   Distributed Quasi-Newton Methods for Nonsmooth Optimization","CCF","ALGORITHMIC FOUNDATIONS","09/01/2017","08/30/2017","Petros Voulgaris","IL","University of Illinois at Urbana-Champaign","Standard Grant","Balasubramanian Kalyanasundaram","08/31/2020","$137,000.00","","voulgari@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","7796","7923, 7933","$0.00","Optimization, which finds the inputs to a mathematical function that produce the minimum output, is a workhorse algorithm behind many of the advances in smart devices or applications in the cloud. As data gets larger and more distributed, new ideas are needed to maintain the speed and accuracy of optimization. Operator splitting, which expresses the function to minimize as the sum of two convex functions, one of which is smooth and the other non-differentiable, is an idea that has produced to new first-order optimization methods.  This project explores operator splitting with second-order optimization methods, which have faster convergence to the minimum.  The focus is on large, distributed, and streaming data sets, so that the resulting general-purpose numerical solvers and embedded systems implementations can support optimization in cyberphysical systems and the Internet-of-Things.   The project has as priority the active engagement and training of students and researchers, with specific emphasis on the inclusion of women and under-represented minority groups. This project not only involves collaboration across three top-tier American universities, but also with European research institute, KU Leuven. <br/><br/>In specific, this research project seeks to interpret existing methods for structured convex optimization (such as the celebrated ADMM algorithm) as gradient methods applied to specific functions arising from the original problem formulation, and  interpret of operator-splitting techniques as fixed point iterations for appropriately selected operators.  A key theoretical foundation is the introduction of new envelope functions (smooth upper approximations possessing the same sets of solutions) that can be used as merit functions for variable-metric backtracking line-search. To conclude, a principal focus of the project is to design distributed asynchronous methods applicable to large-scale multi-agent cyberphysical systems that involve big data and impose stringent real-time constraints for decision-making. In this purview, the goal is to deliver methods that will outperform current state-of-the-art in terms of (a) speed of computations, (b) scalability with big data sizes, (c) robustness to various types of uncertainty, and, most topically, (d) distributed asynchronous implementation over networks in real-time. The merits will be illustrated in the context of applications in signal processing, control, machine learning and robotics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1527193","AF: Small: Subdivision Methods: Correctness and Complexity","CCF","ALGORITHMIC FOUNDATIONS","09/01/2015","08/20/2015","Michael Burr","SC","Clemson University","Standard Grant","Balasubramanian Kalyanasundaram","08/31/2019","$246,411.00","","burr2@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","CSE","7796","7923, 7933, 9150","$0.00","Subdivision-based algorithms can solve problems from a wide variety of applications in mathematics, computer science, and the sciences.  For example, these types of algorithms are used in computer graphics, mathematical biology, computational geometry, mathematical modeling, robotics, machine learning, and mathematical computation.  Subdivision-based algorithms are popular because they are relatively easy to describe and implement on a computer, and they are often efficient in practice.  The work in this project is to quantify and improve the effectiveness of these types of algorithms.  By studying the efficiency and providing algorithms to approximate solutions to problems which are typically considered intractable, the results of this project provide techniques which can be applied to practical problems throughout the sciences.<br/><br/>Subdivision-based algorithms recursively and adaptively subdivide a given domain into smaller regions until, in each smaller region, the behavior of a problem-specific feature can be determined.  Subdivision-based algorithms are frequently used because they are parallelizable, recursive, and adaptive.  More precisely, they use weak local tests and perform more subdivisions only near difficult features.  These features that make subdivision-based algorithms practical, however, also make them challenging to study.  For example, local tests make global topological correctness difficult and adaptive (non-uniform) subdivisions make the number of subdivisions difficult to bound.  This project addresses both of the important questions of complexity and correctness for subdivision-based algorithms in the following two ways: (1) Using continuous amortization as a uniform method to compute the complexity of subdivision-based algorithms.  (2) Developing topologically certified subdivision-based algorithms for geometric applications on algebraic varieties.  This project extends the technique of continuous amortization to many different types of algorithms including iterative and two-dimensional subdivisions; additionally, the project develops subdivision-based algorithms to approximate previously intractable problems such as the medial axis and intersections of surfaces."
"1840446","Planning Grant: Engineering Research Center for Augmentation Systems and Intelligent Support Technologies for Aging (ASISTa-ERC)","EEC","ENGINEERING RESEARCH CENTERS","09/01/2018","08/29/2018","Gregory Hager","MD","Johns Hopkins University","Standard Grant","Dana Denick","08/31/2019","$100,000.00","Elizabeth Mynatt, Wendy Rogers, Sarah Szanton","hager@cs.jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","ENG","1480","124E, 1480","$0.00","The Planning Grants for Engineering Research Centers competition was run as a pilot solicitation within the ERC program.  Planning grants are not required as part of the full ERC competition, but intended to build capacity among teams to plan for convergent, center-scale engineering research.<br/><br/>The objective of this planning grant is to further develop the goals and organization of the proposed ASISTa-ERC. The ASISTa-ERC will explore the use of technology to enhance the lives of the growing population of older adults and their caregivers. To do so, it will leverage advances in artificial intelligence, robotics, human-computer interaction, and mobile sensing and computing to create intelligent environments that augment cognitive ability, support physical activities, and amplify social and emotional support for aging individuals, their support network, and their caregivers. These environments will be designed to track individuals over time and adapt to changes in their daily life and their evolving healthcare needs. By enhancing and supporting the growing population of older adults and their caregivers, the work of the ASISTa-ERC will create significant economic and social benefits for older adults and their families. It will also create a new platform to support a rapidly growing workforce devoted to care for aging adults, and a unified framework for new commercial innovations.<br/><br/>The planning activities will refine the research, workforce development, culture of inclusion, and innovation programs of the ASISTa-ERC through a series of three meetings. These meetings will explore three cross-cutting themes: physical support, cognitive support, and social support. They will develop a strategy for creating systems addressing these opportunities that have three key properties: intelligence, interactivity, and individualization (I3). Intelligent systems employ models that can classify and anticipate patterns of activity, and respond to those patterns in ways that most enhance the quality of life of the individual. Interactive systems exploit advanced sensing and human-computer interaction to observe, engage and respond in an appropriate manner. Individualized systems adapt the blend of cognitive, social, and physical support to each unique life situation, and evolve that blend of support as the individual ages and life circumstances change.  All development efforts will be user-centered and user-informed to increase acceptance and adoption by the target populations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1817212","AF: Small: A New Approach to Analysis and Design of Algorithms for Stochastic Control and Optimization","CCF","ALGORITHMIC FOUNDATIONS","10/01/2018","08/23/2018","Rahul Jain","CA","University of Southern California","Standard Grant","Balasubramanian Kalyanasundaram","09/30/2021","$399,999.00","","rahul.jain@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7796","7923, 7926, 7933","$0.00","Randomized algorithms for stochastic optimization and control underpin many developing technologies such as Artificial Intelligence (AI), Autonomous Robotics, and Big Data Analytics. Their development is hampered by a lack of suitable mathematical tools. In many cases, current mathematical techniques such as those based on Stochastic Lyapunov theory are rather difficult to use, thus necessitating invention of customized techniques for algorithm design for each problem and its analysis. This project will develop a new class of mathematical techniques, called probabilistic contraction analysis, that are easier to use, and more broadly applicable. The project's aim is not just analysis of existing algorithms, but development of analysis tools with an eye on design. The project outcomes can accelerate development of new algorithms for stochastic control and optimization problems that arise in many important application fields such as AI, Autonomy, Big Data Analytics, etc. The project will train under-represented and/or female PhD students and postdocs, as well as high school students and teachers.<br/><br/>Given a randomized algorithm for stochastic optimization and control, this project views each iteration as applying a random operator, and develops new ""probabilistic contraction"" analysis techniques, created by the investigator, that use stochastic dominance arguments to show convergence to probabilistic fixed points. Specifically, the investigator will develop empirically-inspired algorithms for optimal control of continuous state and action space Markov decision processes, and unconstrained and constrained stochastic optimization problems. The techniques to be developed may be useful for a broader class of stochastic iterative algorithms, and lead to development of a probabilistic fixed point theory of random operators on Banach spaces.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1608886","RET Site: Incorporating Engineering Design and Manufacturing into High School Curriculum","EEC","RES EXP FOR TEACHERS(RET)-SITE, HUMAN RESOURCES DEVELOPMENT","09/01/2016","08/17/2018","Xinyu Liu","TX","Lamar University Beaumont","Standard Grant","Mary Poats","08/31/2019","$555,380.00","Xuejun Fan","xinyu.liu@lamar.edu","4400 Port Arthur Road","Beaumont","TX","777055748","4098807670","ENG","1359, 1360","115E, 116E, 9177, 9178, 9251","$0.00","This Research Experiences for Teachers (RET) in Engineering and Computer Science Site, entitled, Incorporating Engineering Design and Manufacturing into High School Curriculum, at Lamar University (LU) Beaumont, will provide opportunities for STEM high school teachers from underserved school districts in Southeast Texas to engage in cutting-edge advanced engineering design and manufacturing research and develop curriculum modules based on their research. Advanced design and manufacturing is an industry with growing opportunities for creating the next generation workforce. Given the many petrochemical, manufacturing and military operations in the Beaumont-Port Arthur area the research topic is of high economic impact to the region. LU is uniquely located amongst the local manufacturing and petrochemical industry in the Beaumont-Port Arthur area and it is anticipated that the project will help strengthen education in design and manufacturing, and ultimately help the workforce to be more competitive. Research projects include: advanced design and manufacturing, including computer-aided design and manufacturing, computer-numerically controlled machining, 3D printing, laser marking and micro-machining; sustainable microelectronics manufacturing and design; intelligent sensor technology in building materials design; computational fluid dynamics (CFD) assisted design in industrial applications; and synthesis, simulation, and manufacturing of legged robotics. This research experience will help teachers to develop and implement innovative curriculum by translating cutting-edge research in advanced design and manufacturing into high school classrooms, strengthen education in design and manufacturing, enrich the professional development of future leaders in STEM education, result in innovative STEM curriculum and stimulate the interest of high school students in scientific inquiry and engineering.  The project will positively influence the learning and career paths of young students, especially those from underserved districts and underrepresented groups in Southeast Texas for years to come and contribute to a technology-savvy workforce. <br/> <br/>Over a three-year period, this RET Site will offer an intensive 6-week summer research program to a total of 36 STEM high school teachers.  They will join faculty mentors and their research teams in performing cutting-edge advanced engineering design and manufacturing research and developing and implementing innovative high school curriculum based on their research that meets Texas Essential Knowledge and Skills (TEKS) standards. The RET Site program will also include workshops, seminars, field trips to local industry, teacher project and course module presentations and extensive follow-up activities during the academic year.  Dissemination of the project outcomes will be through LU's RET website, conference and journal papers, TeachEngineering.org and alumni and  students in the largest domestic online Masters Program of Educational Leadership at LU."
"1536406","Collaborative Research: Dynamics and Propagation of Surface Instabilities in Soft Materials","CMMI","Dynamics, Control and System D","09/01/2015","05/01/2017","Nicholas Boechler","WA","University of Washington","Standard Grant","Irina Dolinskaya","08/31/2019","$279,192.00","","boechler@uw.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","ENG","7569","030E, 031E, 032E, 033E, 034E, 035E, 099E, 116E, 8024, 9178, 9231, 9251","$0.00","When soft materials are compressed, their surface often spontaneously forms wrinkles, creases, ridges, or folds with periodic patterns. These patterns are called 'surface instabilities'. Over the past several years, there has been significant interest in understanding how surface instabilities form, as they are ubiquitous in biological systems and have found wide use in engineering applications ranging from microfabrication to soft robotics. However, nearly all of the past studies have focused on understanding how surface instabilities form under very slow compression, or have neglected the dynamics leading to this event. This award will investigate how surface instabilities form and propagate across the surface of the material as a result of fast compression or impacts. The speed of the event causing the instability is critical as it yields fundamentally unique phenomena, which are prevalent in most physical systems, but still not well understood. The improved understanding gained as part of this fundamental research will impact a broad range of applications. For example, because of the role of surface instabilities in friction, this research will positively affect engineering applications with moving soft materials in contact. It will also lead to improved understanding of the dynamics of sandwich beam composites, and to improved impact absorbers, shock protective systems, and novel soft electronics devices. In addition to the research goals, this project has a significant education and outreach component that will positively affect students from K-12 through graduate levels, and will increase the involvement of underrepresented students in STEM fields.<br/><br/>The research objective of this multidisciplinary, collaborative project is to investigate the initiation and propagation of surface instabilities in soft materials under dynamic loading, using a combined theoretical, computational, and experimental approach. Experimental characterization will be conducted using a combination of drop tower, high-speed video, and laser ultrasonic test methods. Dynamic surface instability propagation will be modeled analytically, and computationally using nonlinear finite element techniques. This project will provide significant intellectual contribution by answering open questions including: What are the conditions for initiating the propagation of surface instabilities, and how do they propagate? How does the propagation of surface instabilities lead to material failure? And how can the propagation of surface instabilities be manipulated? More generally, as there have been almost no investigations into the dynamics of propagating surface instabilities, this investigation will open a new class of instability-based surface waves and provide an improved understanding of dynamic phenomena in soft materials."
"1836572","Second Trans-Atlantic Symposium on Information and Communication Technology (ICT),To Be Held at the Woodrow Wilson Center for Scholars, in Washington DC, June 18-19, 2018.","ECCS","S&CC: Smart & Connected Commun, ENERGY,POWER,ADAPTIVE SYS, SOFTWARE & HARDWARE FOUNDATION","09/01/2018","08/29/2018","Anne Bowser","DC","Woodrow Wilson International Center for Scholars","Standard Grant","Radhakisan S. Baheti","08/31/2019","$44,954.00","Tariq Samad","anne.bowser@wilsoncenter.org","1300 Pennsylvania Ave., NW","Washington","DC","200043027","2026914200","ENG","033Y, 7607, 7798","042Z, 092E, 7556, 7918","$0.00","New and emerging Information and Communications Technologies (ICT) developments have the potential to accelerate scientific discovery and industrial growth with positive social impacts. However, big picture assessments of new and emerging ICT are often lacking, particularly from an international perspective. The European Commission, under its Horizon 2020 program, launched a 2016 project on ICT Policy, Research and Innovation for a Smart Society: Towards New Avenues in EU-US ICT Collaboration (the PICASSO project). Under this proposal, NSF will provide co-funding for US researchers to participate in a PICASSO project symposium focused on exploring emerging areas of ICT relevant to cooperation between researchers in the US and EU. This workshop, the 2nd Trans-Atlantic Symposium on ICT Technology and Policy, will be held at the Woodrow Wilson International Center for Scholars (the Wilson Center) in Washington, DC, on June 18-19, 2018.  The symposium will result in greater awareness of shared US/EU priorities and needs in ICT technology and policy and in enhanced collaborations. Attendance of approximately 100 is anticipated, with outreach designed to facilitate participation from groups that are historically under-represented in STEM.<br/><br/>Pervasive sensing and connectivity, large-scale secure data repositories, high-performance analytics in distributed and cloud platforms, real-time closed-loop applications, and robotics all offer individual advances in research and application areas, and will enable social, environmental, and economic benefits on unprecedented levels as the impacts of these technologies converge. Taking an international perspective, the goal of this workshop is to convene representatives from academia, industry, and government seeking to identify and advance collaborative research in new and emerging ICT areas. Specific thematic areas to be explored include Cyber Physical Systems (CPS), Internet of Things (IoT), big data, 5G and beyond, the future of automation, and cyber-resiliency, all of which are a high priority for the US and EU. The symposium will predominately feature a mix of keynote speeches and plenary panel discussions, through breakout sessions on the second day will allow researchers to discuss key technical aspects of different thematic areas in detail. This workshop will provide inputs to help define opportunities for US/ EU collaboration from a high-level road-mapping perspective. A final report will be prepared for NSF and the European Commission, and a version of this report will also be made publically available on websites of the Wilson Center and PICASSO project. The symposium will also identify opportunities for and advance collaborative research through networking participants from the US and EU.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1715475","RI: Small: Integrating Flexible Normalization Models of Visual Cortex into Deep Neural Networks","IIS","ROBUST INTELLIGENCE","09/01/2017","08/17/2017","Odelia Schwartz","FL","University of Miami","Standard Grant","Kenneth C. Whang","08/31/2020","$349,996.00","","odelia@cs.miami.edu","1320 S. Dixie Highway Suite 650","CORAL GABLES","FL","331462926","3052843924","CSE","7495","7495, 7923, 8089","$0.00","Recent advances in artificial intelligence models of deep neural networks have led to tremendous progress in artificial systems that recognize objects in scenes, and in a host of other applications such as speech recognition, and robotics. Although deep neural networks often incorporate computations inspired by the brain, these have typically been applied in a fairly simple and restrictive manner, rather than based on more principled models of neural processing in the brain. Using vision as a paradigmatic example, this project proposes that artificial systems can benefit from integrating approaches that have been developed in biological models of neural processing of scenes. The biological models make use of contextual flexibility, whereby neurons are influenced in a rich way by the image structure that spatially surrounds a given object or feature. This flexibility is expected to improve task performance in deep neural networks, and to impact development of artificial systems that are more compatible with human cognition. The resulting framework, with its deep architecture spanning multiple layers of processing, will, in turn, make predictions about neural processing in the brain, which will impact the neuroscience and cognitive science communities. <br/><br/>This project focuses specifically on normalization, a nonlinear computation that is ubiquitous in the brain, and that has been shown to benefit task performance in deep neural networks. The project will develop more principled strategies for determining normalization in deep convolutional neural networks. The main focus will be on learning a form of flexible normalization based on scene statistics models of visual cortex. In this framework, normalization is recruited only to the degree that a visual input is inferred to contain statistical dependencies across space. Performance will be tested for classification and segmentation on large-scale image databases, and will also target tasks more suited to mid-level vision such as figure/ground judgment. This will result in better understanding of normalization nonlinearities in deep convolutional networks, and the implications of flexible normalization for task performance and generalization compared to other forms of normalization. Biologically, normalization is poorly understood beyond primary visual cortex. The models developed will help shed light on the equivalence of this inference for middle cortical areas, and make predictions about what image structure leads to recruitment of normalization. This project will also include launching of an interdisciplinary Deep Learning Discussion Group."
"1717391","AF:  Small:  Collaborative Research:  Distributed Quasi-Newton Methods for Nonsmooth Optimization","CCF","ALGORITHMIC FOUNDATIONS","09/01/2017","08/30/2017","Angelia Nedich","AZ","Arizona State University","Standard Grant","Balasubramanian Kalyanasundaram","08/31/2020","$199,840.00","","Angelia.Nedich@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7796","7923, 7933, 9102","$0.00","Optimization, which finds the inputs to a mathematical function that produce the minimum output, is a workhorse algorithm behind many of the advances in smart devices or applications in the cloud. As data gets larger and more distributed, new ideas are needed to maintain the speed and accuracy of optimization. Operator splitting, which expresses the function to minimize as the sum of two convex functions, one of which is smooth and the other non-differentiable, is an idea that has produced to new first-order optimization methods.  This project explores operator splitting with second-order optimization methods, which have faster convergence to the minimum.  The focus is on large, distributed, and streaming data sets, so that the resulting general-purpose numerical solvers and embedded systems implementations can support optimization in cyberphysical systems and the Internet-of-Things.   The project has as priority the active engagement and training of students and researchers, with specific emphasis on the inclusion of women and under-represented minority groups. This project not only involves collaboration across three top-tier American universities, but also with European research institute, KU Leuven. <br/><br/>In specific, this research project seeks to interpret existing methods for structured convex optimization (such as the celebrated ADMM algorithm) as gradient methods applied to specific functions arising from the original problem formulation, and  interpret of operator-splitting techniques as fixed point iterations for appropriately selected operators.  A key theoretical foundation is the introduction of new envelope functions (smooth upper approximations possessing the same sets of solutions) that can be used as merit functions for variable-metric backtracking line-search. To conclude, a principal focus of the project is to design distributed asynchronous methods applicable to large-scale multi-agent cyberphysical systems that involve big data and impose stringent real-time constraints for decision-making. In this purview, the goal is to deliver methods that will outperform current state-of-the-art in terms of (a) speed of computations, (b) scalability with big data sizes, (c) robustness to various types of uncertainty, and, most topically, (d) distributed asynchronous implementation over networks in real-time. The merits will be illustrated in the context of applications in signal processing, control, machine learning and robotics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1726925","MRI: Acquisition of a high speed multiphoton laser-scanning microscope for research and training at UNLV","DBI","MAJOR RESEARCH INSTRUMENTATION","09/01/2017","08/23/2017","Laurel Raftery","NV","University of Nevada Las Vegas","Standard Grant","Robert Fleischmann","08/31/2020","$998,614.00","Boo Shan Tseng, Andrew Andres, Hong Sun, Ai-Sun Tseng","laurel.raftery@unlv.edu","4505 MARYLAND PARKWAY","Las Vegas","NV","891541055","7028951357","BIO","1189","9150","$0.00","An award is made to the University of Nevada, Las Vegas (UNLV) to acquire a high-speed multiphoton laser scanning microscope system to view the behaviors of cells in living tissues with time-lapse images. UNLV is the only research-intensive university in southern Nevada, and the largest in the state. Expansion of the scope and impact of UNLV research activities is a high priority for the State of Nevada, and part of its plan to diversify the economy beyond the gaming and tourism industries. The UNLV Confocal and Biological Imaging Core provides training and support for laser-scanning fluorescence microscopy in a wide array of biological, environmental, and engineering applications. Graduate students from across UNLV and nearby post-graduate professional universities receive basic and advanced training in quantitative fluorescence microscopy techniques, advancing the national goal of developing a diverse STEM workforce. Graduate students use the majority of Core instrument time, and are assisted by collaborating undergraduate researchers. In additional, other undergraduate UNLV students will experience the new multiphoton technology through modules in advanced laboratory coursework. In 2015, UNLV was ranked as one of the 10-most diverse public universities in the US. UNLV is also a Minority-Serving Institution for Native American and Pacific Islander students and an emerging Hispanic Serving Institution. Tours and demonstrations will be provided to students from nearby high schools and two-year and four-year colleges through outreach activities. To further recruit a diverse range of students to STEM disciplines, videos showing the inner workings of plant and animal tissues will be developed and presented in Clark County K-12 classrooms. Similar presentations for Science Caf Las Vegas will enhance scientific literacy by introducing the lay public to the fascinating behaviors of cells within living tissues. <br/><br/>The newly acquired multiphoton laser scanning microscope provides advanced technology to obtain images from living tissues to depths of 1 mm. This instrument will be located in the UNLV Confocal and Biological Imaging Core, so that it will be available on a first-come, first-served basis to scientists and students across Nevada. Availability of this instrument eliminates the barrier of transporting samples to other states, and enables Nevada researchers to study living systems at new levels of sensitivity and depth. The high-speed imaging technology decreases tissue damage and increases sensitivity, allowing detection of fast-changing processes over periods of seconds to hours. This type of imaging is driving unexpected discoveries about the brain and how cells work together to build the architecture of many other organs. The advanced capabilities of multiphoton laser scanning microscopy will be used to study a wide range of biological and engineering systems, such as hormonal control of gland secretion, electrical oscillations in living mouse brain slices, repair and regeneration of eye tissues, organization of bio-fouling bacteria, and electrical activity of polymers for robotics and nanotechnology."
"1312333","Scaling Up Success: Using MATE's ROV Competitions to Build a Collaborative Learning Community that Fuels the Ocean STEM Workforce Pipeline","DRL","ITEST","09/15/2013","09/10/2013","Jill Zande","CA","Monterey Peninsula College","Standard Grant","Monya Ruffin","08/31/2019","$1,999,011.00","Deidre Sullivan, Candiya Mann","jzande@marinetech.org","980 Fremont","Monterey","CA","939404704","8316463081","EHR","7227","9177, SMET","$0.00","The Marine Advanced Technology Education (MATE) Center at the Monterey Community College in collaboration with Washington State University is engaging in a scale-up study of the remote operated vehicle (ROV) program to new audiences of middle and high school students and teachers. Using a train the trainers approach, the MATE ROV project is conducting at least 45 regional professional development workshops in 15 regions for a total of 500 teachers. Scaling-up the project also includes the development of regional teacher leaders who have the resources developed from previous funding and the support from MATE through materials, administrative processes, and professional development to expand the implementation of the MATE ROV competitions. The project outcomes include increased student interest in STEM and STEM careers as well as increasing their knowledge of STEM content and how engineering and science work together to solve real-world problems. Additional outcomes include increasing parental involvement to support and encourage students to continue with STEM studies and careers and the implementation of professional development, instructional resources and mentoring to increase teacher capacity to engage students in the MATE ROV competitions.<br/><br/>The project is expanding the focus of the MATE ROV from an after school program to connect the robotics focus of the program to the Next Generation Science Standards and create a series of curricula experiences across the middle grades complete with instructional videos. An online resource for parents is one mechanism that the project is developing to support parental involvement, and the structuring of regional parental advisory boards is a second. The project is conducting a longitudinal study of the students who participate in the MATE ROV competitions. The project is connecting the MATE ROV AlumniWeb to the National Student Clearinghouse to track students from the secondary experiences with the program into their college majors and matriculation. The project is also studying the ways that the variation of the MATE ROV professional development is evident throughout the 15 regional hubs of the project to provide a better understanding of how a technology-rich program moves to scale."
"1741960","Spokane Falls Community College Engineering Scholarship Project","DUE","S-STEM:SCHLR SCI TECH ENG&MATH","11/15/2017","10/30/2017","Mark Gorski","WA","Spokane Falls Community College","Standard Grant","Alexandra Medina-Borja","10/31/2022","$649,790.00","Greg Cripe, Sabrina Robinson","mark.gorski@sfcc.spokane.edu","501 N. Riverpoint Blvd., Suite 1","Spokane","WA","992176000","5094345160","EHR","1536","9178, SMET","$0.00","Spokane Falls Community College (SFCC) will pursue the ""Engineering Scholarship Project"" to provide 36 undergraduate engineering students with scholarships and supporting activities that promote academic success. The project includes a collaboration with Eastern Washington University, which will recruit upper-class engineering students to serve as peer mentors for first-year community college students within the context of a year-long robotics design activity. Targeted scholarships integrated with a program of structured mentoring and student support activities aim to increase the number of students who persist and complete an engineering transfer degree at SFCC, and successfully transfer to a four-year institution. The project has the potential increase the diversity and availability of qualified engineers to meet regional workforce needs. <br/><br/>The project will generate new knowledge regarding evidence-based approaches to improving outcomes in community college engineering student persistence, completion, and transfer to baccalaureate-granting institutions. The Engineering Scholarship Project will develop and apply methods of systematic outreach to high schools to recruit academically motivated students and encourage them to enter undergraduate engineering programs at SFCC. Student cohorts will be supported for four years: they will complete their two-year engineering degree at SFCC and transfer to a four-year institution, where they will complete the additional requirements needed to earn a baccalaureate engineering degree.  Student success will be supported through curriculum pathways, faculty advising, peer student mentors, and supportive co-curricular activities. Evaluation results will be used to drive changes in practice and institutional culture that improve SFCC's future success in recruiting student in STEM, as well as support successful two-year degree completion and transfer."
"1266183","I/UCRC:  Identification Technology Research (CITeR) - UB Site","CNS","INDUSTRY/UNIV COOP RES CENTERS, , , , , ","06/01/2013","08/27/2018","Venugopal Govindaraju","NY","SUNY at Buffalo","Continuing grant","Dmitri Perkins","05/31/2019","$407,852.00","Srirangaraj Setlur, Ifeoma Nwogu","govind@buffalo.edu","520 Lee Entrance","Amherst","NY","142282567","7166452634","CSE","5761, N510, O317, O530, Q287, R321","170E, 5761, 8039, 8237","$0.00","Center for Identification Technology Research (CITeR) <br/><br/>1266183 SUNY at Buffalo; Venugopal Govindaraju <br/><br/>The proposed site, SUNY at Buffalo, requests funding to establish a partner site of the Center for Identification Research (CITeR) currently comprised of the Clarkson University (lead institution), West Virginia University and the University of Arizona as research partners. <br/><br/>The proposed site will advance the science of biometric technologies for both civilian and homeland security applications by integrating pattern recognition and machine learning algorithms with sensors technology. SUNY at Buffalo site will bring together faculty expertise, not only in core biometric modalities such as fingerprints and face recognition, and soft biometrics such as gender, age, mannerisms, and emotion, but also in related areas such as advanced computer vision, robotics, cryptography, and theoretical computer science that will allow CITeR to pursue research in the development of innovative biometric applications. CITeR affiliates will also benefit from being able to benchmark and assess the effectiveness of various hard and soft biometric technologies in real applications. The proposed site's faculty strength in Chemistry, Physics and Optics will also help CITeR pursue novel modulaties such as odor biometrics and better sensors to assist in identification technologies. <br/><br/>The proposed site will further CITeR's objective to serve as a comprehensive academic center serving the growing identification technology research, undergraduate and graduate education, and outreach needs of the public and private sectors. This will be accomplished by providing a mechanism for the funding of pooled interdisciplinary faculty and student talent to address the challenges in identification technology. Under the auspices of BEAM (Buffalo Area Engineering Awareness for Minorities) the proposed site plans to attract the participation of local high school and undergraduate students using innovative events built around biometrics applications that incorporate treasure hunts and other fun elements to educate and interest them in STEM areas. The faculty at SUNY Buffalo are members of the NSF-AGEP (The Alliance for Graduate Education and the Professoriate) program whose goal is to significantly increase the number of underrepresented minorities obtaining graduate degrees in STEM areas. CITeR meetings will also serve as an excellent opportunity for students to interact with potential employers to understand challenges in the field."
"1501044","Biologically-Inspired Robust Adaptive Dynamic Programming for Continuous-Time Stochastic Systems","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/01/2015","07/05/2016","Zhong-Ping Jiang","NY","New York University","Standard Grant","Anil Pahwa","07/31/2019","$300,619.00","","zjiang@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","ENG","7607","030E, 1653, 9102, 9251","$0.00","The project aims to develop tools and methods, inspired by neurobiology, for addressing the need in building brain-like reinforcement learning systems and, ultimately, contributing to the understanding of brain functions. The project seeks to address fundamentally challenging issues arising from the robust optimal management of large complex systems subject to stochastic effects, nonlinearity, and dynamic uncertainties.  Research findings from this project will contribute new solutions to emerging engineering applications such as the smart electricity grid, robotics, and intelligent transportation systems. The proposed research will have a substantial direct impact upon education at the PI's institution. The interdisciplinary nature of the project should appeal to students from several departments.<br/><br/>The project team will work on stochastic variants of adaptive dynamic programming (ADP) for continuous-time systems subject to stochastic and dynamic disturbances. ADP is a practically sound data-driven, non-model based approach for optimal control design in complex systems. ADP has been extensively studied for Markov decision processes, focusing mostly on discrete and finite state-space, and for deterministic (discrete- and continuous-time) dynamic systems. Stability and robustness issues in the presence of dynamic uncertainties are seldom addressed systematically. For problems involving complex modern engineering systems or biological systems, for which stability is an important concern, straightforward application of the existing ADP results does not seem productive or even likely to be successful. Hence, it is necessary to develop novel tools and methods for ADP design of general stochastic systems in continuous-time and continuous state-space, with rigorous stability and convergence analysis. The novelty of the proposed research consists of application and extension of techniques from reinforcement learning, stochastic systems theory, and nonlinear control theory.  The specific goals of the proposal are the development of tools and methods for stochastic adaptive dynamic programming for linear and nonlinear stochastic systems, stochastic adaptive optimal control with robustness to dynamic uncertainties, and application to human motor systems. Rigorous stability proofs, convergence analysis of learning algorithms, and robustness analysis will be pursued. Important classes of continuous-time linear and nonlinear models with multiplicative and additive noise will be studied, along with non-model based, stochastic optimal controller designs. Beyond engineering applications, it is believed that bringing together ADP and research in computational neuroscience may yield new methodologies for the diagnosis and treatment of neurodegenerative genetic disorders that affect muscle coordination. One such medical condition is Parkinson's disease, which affects approximately seven million people globally, and one million in the United States. Generalizing the PI's recent work in linear stochastic variants of robust adaptive dynamic programming can lead to a potentially new computational mechanism for human motor control."
"1527050","CSR: Small: A Separation Kernel for Mixed Criticality Systems","CNS","Computer Systems Research (CSR","10/01/2015","08/18/2015","Richard West","MA","Trustees of Boston University","Standard Grant","M. Mimi McClure","09/30/2019","$450,000.00","","richwest@cs.bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","CSE","7354","7923","$0.00","This project will develop a new operating system for mixed criticality embedded systems, such as those found in avionics, automotive, robotics, factory automation and healthcare domains. In mixed criticality systems, there is a combination of application and system components with different safety, importance and timing requirements. For example, in an avionics system, the in-flight entertainment system is considered less critical than that of the flight control system. Security is also a key factor in the design of mixed criticality systems.  Security measures should be taken to enforce data confidentiality and system integrity even in the presence of untrusted users. Preventing malicious attacks from compromising the behavior or accessing the data of highly-critical services is an important security concern. <br/><br/>A major challenge to mixed criticality systems is the safe, predictable and secure isolation of separate components with different levels of criticality. Less critical tasks should not be allowed to interfere with the timing and otherwise correct operation of mission critical tasks. <br/>Safety guarantees should be met to ensure software and hardware failures do not compromise highly critical task operation. Failure of highly critical tasks or services can have devastating consequences.<br/><br/>Multi- and many-core processors are being increasingly used in mixed criticality embedded systems, due in part to their power, performance and price benefits. Many such processors also support hardware virtualization, including Intel VT-x, AMD-V and certain ARM Cortex processors.  This research project will leverage the combination of multiple cores and hardware virtualization features on emerging processors, to develop a separation kernel for mixed criticality systems. Tasks and services of different criticality levels will be separated into different isolated ""sandboxes"", each responsible for a collection of hardware processing cores, memory and I/O devices. This work builds on an earlier prototype system, called ""Quest-V"". Quest-V allows sandboxed services to directly access available resources without involving a heavyweight hypervisor, as is the case in traditional virtual machine systems. Most existing virtual machine systems have been designed for server class computing. So, investigating techniques to build safe, secure and predictable mixed criticality systems on emerging hardware platforms suitable for low-cost embedded computing applications will be an important component of this project.<br/><br/>This award will extend Quest-V to support novel real-time fault detection and recovery strategies not be possible with traditional system approaches. We also hope to gain a greater understanding of the hardware features needed to support secure and predictable partitioning of machine resources in mixed criticality systems. The outcomes of this work will lead to a new system design with the potential to have impact on many areas of computing where lives, money and security concerns are at stake."
"1761243","Active Dynamic Granular Metamaterial through Controlled Jamming-Unjammming Transitions","CMMI","SPECIAL INITIATIVES","09/01/2018","08/23/2018","Philippe Geubelle","IL","University of Illinois at Urbana-Champaign","Standard Grant","Siddiq Qidwai","08/31/2021","$381,840.00","John Lambros","geubelle@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","1642","022E, 024E, 9161","$0.00","Granular media have a unique ability to transition from a free-flowing fluid-like response in the so-called unjammed state to a rigid solid-like response in the jammed state. Because of the importance of granular media in a variety of natural phenomena and industrial processes, the quasi-static (slow rate of deformation) response of granular media has been the focus of numerous studies, with emphasis on characterizing the transition between unjammed and jammed states. In this project, an integrated experimental and computational approach will be used to conduct research on a novel dynamic granular metamaterial (engineered materials system with hierarchy of structures) consisting of metallic spherical grains encapsulated in a flexible membrane. Jammed-unjammed switching in material response will be achieved with the help of a confining external pressure, to create an active metamaterial for impact protection applications that will combine the shape adaptivity of unjammed granular media with the rigid-like response of the jammed metallic grains. The successful development of the active dynamic metamaterial will lead to a range of applications, especially in the field of transportation, robotics, and manufacturing, that require both stiff and compliant behaviors, or shape adaptivity and morphing. Thus, the project will promote the progress of science related to granular mechanics and advance the national health, prosperity, and welfare through potential applications. Additionally, undergraduate researchers will be recruited and outreach to K-12 students will be performed to achieve broader impact. Underrepresented groups will be specifically targeted in these activities.<br/> <br/>This collaborative experimental and computational project will shed light on the fundamental understanding of the unjammed-to-jammed transition of granular media under dynamic loading conditions. In particular, it will focus on the two key energy dissipation mechanisms involved: friction and plasticity. In the first phase of the project, the effects of parameters such as packing fraction, particle constitutive response, and particle size distribution on the dynamic transition between unjammed and jammed states will be investigated. The second part of the project will focus on the ?passive? tailoring of this transition through pre-conditioning (i.e., pre-yielding) of the spheres or through the combination of stiff (elastic) and compliant (elasto-plastic) particles encapsulated in the deformable membrane, and on the ?active control? of the transition through the confining pressure applied on the encapsulated granular medium. The project will involve a combination of computational analysis based on a discrete element modeling of the impact response of the granular medium, and experiments involving a variety of 2D and 3D configurations of the confined and unconfined granular medium subjected to dynamic loading created with a Split Hopkinson pressure bar system.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1422840","AF: Small: Programmable Nanowalkers:Models and Simulations","CCF","SOFTWARE & HARDWARE FOUNDATION","07/01/2014","05/18/2016","Darko Stefanovic","NM","University of New Mexico","Continuing grant","Mitra Basu","06/30/2019","$400,000.00","","darko@cs.unm.edu","1700 Lomas Blvd. NE, Suite 2200","Albuquerque","NM","871310001","5052774186","CSE","7798","7923, 7946, 9150","$0.00","All nanoscale devices are subject to random diffusive forces that lead to slow, uncontrollable transport of materials and information.  Synthetic nanoscale systems designed for computational  and self-assembly tasks, require more precise control over energy- and information-carrying molecules.  Such systems include nanoscale devices currently being developed for delivery of diagnostic logic circuits to cells, querying the state of health of specific cells or subcellular structures, and conditional release of therapeutic cargo molecules. Ideally, such systems could employ programmable synthetic molecular motors to ferry information and materials in directed motion over a complex network of tracks, analogous to natural molecular motors in living cells, thus enabling behaviors otherwise not possible in a purely diffusion-driven environment. In this project computational models, simulation algorithms, and data visualization tools will be developed that will help synthetic chemists build the next generation of nanoscale walker systems. In the project, students at all levels (high-school to postdoctoral) will be trained in interdisciplinary research. High-school students will be engaged on the project through already established, tracked science involvement programs that emphasize participation of traditionally underrepresented groups. In the context of the project, a regular seminar will be developed on nanoscale technology, molecular computing, and molecular robotics within the biomedical engineering degree program, to educate future generations of students (undergraduate and graduate) in this emerging field of science.<br/><br/>Previous work has shown that simple DNA-enzyme driven synthetic walkers can move superdiffusively along nanoscale tracks, and can do mechanical work. In this project more advanced walker designs with large, complex body shapes and heterogeneity in their interactions with other walkers and molecules in their environment will be modeled and simulated.  This class of structured walker scaffolds will exhibit modes of motion not available in symmetrical walkers, e.g., rotational persistence, orientation-aware sorting, chiral walker-walker and walker-track interactions.  These features will be used to break symmetries in the walker's local environment, leading to stronger directional biases and more efficient directional transport. <br/><br/>The goal of the project is to understand the algorithmic basis of how a walker's shape and structure affect its motion, and how these features can be composed, modularly, into larger nanoscale transportation systems with programmable control, to achieve directed transport even under the randomizing and disorienting influence of Brownian motion. The models developed will enable more complex nano systems to be engineered to take advantage of programmable nanoscale transport.<br/><br/>The approach taken in the project is computational. Walker motion is treated as a continuous-time Markov process, at a level of abstraction that balances physical detail and computational tractability.  A hierarchy of Monte Carlo simulations will be developed to approximate physical and chemical processes at the appropriate relative scales, while maintaining computational tractability."
"1839567","ATE 2.0: Preparing Technicians for the Future of Work","DUE","ADVANCED TECH EDUCATION PROG","09/01/2018","08/23/2018","Ann-Claire Anderson","TX","CORD","Standard Grant","V. Celeste  Carter","08/31/2022","$3,471,157.00","Richard Gilbert, Michael Lesiecki, Hope Cotner","anderson@cord.org","4901 Bosque Boulevard","Waco","TX","767105841","2547418334","EHR","7412","1032, 9178, SMET","$0.00","The workplace of today is undergoing a major transformation driven by machine learning, artificial intelligence, the internet-of-things, robotics, and systems-integrated process control. NSF's focus on the Future of Work at the Human Technology Frontier recognizes that technology advances are changing industries at an unprecedented pace.  These technological advances promise benefits to the nation by creating new enterprises, occupations, and opportunities for innovation and global leadership while drastically altering the workplace as we know it.  As technology evolves, so will tasks and occupations, creating a demand for an expanding array of knowledge, skills, and services. The demand for positions involving tasks that can be automated will decline and, in some cases, disappear, while entirely new occupations will emerge. This transformation is already affecting America's technicians. This project proposes strategies and collaborative regional activities with industry that will enable the NSF-ATE community to prepare technicians for the changing workplace by transforming technician education at the secondary and post-secondary educational levels.<br/><br/>This project will convene academic partners, industry leaders, and economic development professionals.  These individuals will serve as collaborative thought partners in framing, testing, refining, and supporting strategies that transform technician education to assure regional competitiveness in the evolving workplace. Technological education today generally focuses on industry segments and single sectors. Yet, soon technicians will need skill sets that cross industries and support both core and advanced STEM skills. This project will identify key cross-disciplinary and new disciplinary knowledge and skills needed by technicians in industries that are responding to the changing workplace. Regional networks of academic partners will actively collaborate with industry to strengthen ATE efforts to improve technician education across the US. It is expected that bringing the relevant stakeholders together will facilitate the needed paradigm shift in technician education, and coalesce support around industry expectations for technician education.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1828010","NRT: Citizen-Centered Smart Cities and Smart Living","DGE","GCR-Growing Convergence Resear, NSF Research Traineeship (NRT), AISL, PROGRAM EVALUATION","09/01/2018","08/22/2018","Sethuraman Panchanathan","AZ","Arizona State University","Standard Grant","Laura Regassa","08/31/2023","$2,999,997.00","Ann McKenna, Gail-Joon Ahn, Ram Pendyala, Cynthia Selin","panch@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","EHR","062Y, 1997, 7259, 7261","8244, 9179, SMET","$0.00","Cities are facing new demands as their urban populations rapidly grow. Smart City initiatives are being developed to address issues of mobility, infrastructure, security, and safety, while enhancing the quality of life of citizens. One-size-fits-all solutions are not viable.  Instead, the diversity of a city's residents, including life experiences, cultural backgrounds, needs, and behaviors, must be taken into account to achieve transformative, citizen-centered solutions. Engineers, scientists, policy makers, entrepreneurs, and thought leaders must be prepared to tackle future Smart City challenges, and address knowledge barriers in understanding the needs of citizens across age, occupation, financial standing, disability, and technology savviness. This National Science Foundation Research Traineeship (NRT) award to the Arizona State University addresses this need by training the next generation of MS and PhD students for careers in Smart Cities-related fields. The project anticipates training thirty-eight (38) MS and PhD students, including twenty-four (24) funded trainees, from the following degree programs: Human and Social Dimensions of Science and Technology; Public Affairs; Computer Science; Civil, Environmental, and Sustainable Engineering; Mechanical & Aerospace Engineering; and Applied Engineering Programs. In addition to trainees, it is envisioned that over 300 other MS and PhD students in STEM disciplines will participate in opportunities made available through this traineeship. The knowledge and technologies developed from this project will contribute toward improving the quality of life for all of society through interdisciplinary, citizen-centered Smart City solutions.<br/><br/>An integrated education-research-practice model focused on the technological, societal, and environmental research aspects of citizen-centered solutions for Smart Cities will be employed to instill trainees with transdisciplinary skills and knowledge through cross-disciplinary courses; experience with leading collaborative, use-inspired research projects; applied learning through internships with partners and teaching opportunities; research experiences through service learning and leadership; and entrepreneurial education. Trainees will pursue research thrusts in Citizen-Centered Design; Smart City Infrastructure and Dynamics; and Socio-Environmental Practices and Policies. These thrusts are embedded in integrative priority application areas of Transportation and Accessibility; Safety, Security, and Risk Reduction; and Engagement and Education. Research efforts will significantly advance data-enabled citizen engagement; urban informatics; Internet-of-Things technologies; inclusion and accessibility; urban infrastructure; transportation systems; cybersecurity; swarm robotics; urban sustainability; quality of life and equity for citizens; hazards management and risk reduction; and societal concerns and ethics of emerging Smart City technologies. Focused efforts will be made to recruit underrepresented minorities, women, and individuals with disabilities, in order to tap underutilized talent, equip them to address the needs of their communities, and increase involvement of these groups in Smart Cities-related fields.<br/><br/>The NSF Research Traineeship (NRT) Program is designed to encourage the development and implementation of bold, new potentially transformative models for STEM graduate education training. The program is dedicated to effective training of STEM graduate students in high priority interdisciplinary research areas through comprehensive traineeship models that are innovative, evidence-based, and aligned with changing workforce and research needs.  This project was co-funded by the Advancing Informal STEM Learning (AISL) program.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1711625","Collaborative Research:   Wideband Multi-Beam Antenna Arrays: Low-Complexity Algorithms and Analog-CMOS Implementations","ECCS","COMMS, CIRCUITS & SENS SYS","07/01/2017","07/20/2017","Habarakada Madanayake","OH","University of Akron","Standard Grant","Jenshan Lin","06/30/2020","$224,975.00","Sirani Mututhanthrige-Perera","amadanay@fiu.edu","302 Buchtel Common","Akron","OH","443250001","3309722760","ENG","7564","105E","$0.00","The Federal Communications Commission recognizes the need for the wireless industry to explore the 28-95 GHz millimeter-wave (mm-wave) bands where wider bandwidth is available, and future allocations may reach above 100 GHz. This explosion of mm-wave bandwidth opens up applications in 5G wireless systems spanning communications, localization, imaging, and radar. This project addresses fundamental scientific and engineering challenges in generating multiple parallel radio ""beams"" at mm-wave frequencies. A radio beam refers to a directional channel that establishes point-to-point contact for wireless communications and remote sensing. The ability to form a large number of such radio beams with high bandwidths will tremendously improve the performance for next-generation wireless systems. For example, multiple beams are essential for achieving the orders-of-magnitude increases in capacity, data rate, and geographical penetration required by the explosive growth in wireless applications. Moreover, they are important for both transmitters and receivers.  The project will draw on an analogy between the spatial Fourier transform and a thin optical lens to obtain multiple wideband beams. Unlike lens-antenna-based approaches in the literature, this project will use a planar aperture antenna in conjunction with analog integrated circuits to generate many wideband mm-wave beams subject to power and size constraints. The proposed highly integrated approach is attractive for mobile applications including 5G smart devices, the internet of things, mobile robotics, and unmanned aerial vehicles, and other emerging applications focused on mm-waves. In addition to scientific research, the project will ensure that both minority students and female students will be mentored towards careers in mathematics, communications, as well as microwave circuits and systems. Educational materials will be developed for teaching array signal processing, microwave integrated circuit (IC) design, and ultra-high-speed analog signal processing. Principal Investigators (PIs) Madanayake and Mandal will organize a mini-conference to enhance microwave and mm-wave research activities at nearby universities in northeast Ohio. PI Madanayake will collaborate with co-PIs towards mentoring underrepresented students towards careers in Science, Technology, Engineering, and Math (STEM).  The proposal team is uniquely placed to promote STEM topics spanning both electrical engineering and mathematics domains. The project will lead to education of the wider community on the importance of cross-disciplinary collaboration. Further, the team will strive to show the importance of learning deeper math topics towards success in technology and engineering careers.<br/><br/><br/>A multi-beam array receiver is deeply difficult to realize in IC form due to the underlying complexity of its signal flow graph. In this work, mathematical methods based on the theories of i) sparse factorization of structured complex matrices, and ii) approximate transforms are proposed to solve this problem. The resulting matrices are realized with multi-GHz bandwidths using analog ICs. One of the intellectual contributions is the development of efficient wideband beamformers based on sparse factorizations of delay Vandermonde matrices (DVM). This DVM algorithm solves the longstanding ""beam squint"" problem, i.e., the fact that the beam direction changes with input frequency, making true wideband operation impossible. Another is the derivation of transform matrices with specified properties that approximate the discrete Fourier transform (DFT). Such approximate transforms are not subjected to the known computational complexity bounds of the exact DFT, and approximate-DFT-based multi-beamformers can in fact be efficiently implemented using current-mode analog ICs. Finally, precision circuit design, digital calibration, built-in self-test, and other methods will be explored for efficiently realizing the proposed multi-beamforming networks in analog IC form."
"1603526","Research at the Interface of Algebraic Geometry and String Theory","DMS","ALGEBRA,NUMBER THEORY,AND COM","07/01/2016","08/22/2018","Ron Donagi","PA","University of Pennsylvania","Continuing grant","Timothy Hodges","06/30/2020","$375,000.00","","donagi@math.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","MPS","1264","","$0.00","The award supports the principal investigator's research at the interface of algebraic geometry and string theory. Algebraic geometry is the mathematical study of spaces described by arbitrary algebraic equations. Fundamental investigation of such diverse scientific disciplines as high energy physics, cryptography, phylogenetics, robotics, or control theory, often reveals that key concepts of the discipline can be encoded in terms of such geometric spaces. In some cases, such interactions suggest deep new problems in algebraic geometry whose solution is necessary for further progress. In other instances, the scientific intuition actually suggests new methods for solving old problems in algebraic geometry that were otherwise inaccessible. String theory and quantum field theory (QFT) explore physics at the smallest length scales, or correspondingly at the highest energy levels. Exploration of the interactions of these physical theories with algebraic geometry has been extremely productive for both math and physics, and the power of this combination of tools and approaches only seems to strengthen with time.<br/><br/>The goal of this project is to explore and push forward the interface of algebraic geometry with string theory. This will be done by focusing on a number specific research directions, each representing a major open problem in math and/or in physics, whose solution will make a major contribution to the field, and is likely to benefit from the application of techniques of the opposite discipline. Specifically, the principal investigator proposes to explore the extension of the classical theory of curves and their moduli to super Riemann surfaces, with a view towards establishing the foundations of perturbative superstring theories and studying the superstring measure; to prove the geometric Langlands conjecture via non abelian Hodge theory, and explore its relation to QFT and to mirror symmetry; to extend his construction of Calabi-Yau integrable systems realizing Hitchin's system to meromorphic and parabolic versions, and explore the physical applications; to use his new parametrization of the moduli space of 6 dimensional principally polarized abelian varieties to analyze this space and  determine its Kodaira dimension; and to explore further aspects of F theory and attempt to establish its mathematical foundations."
"1617861","CHS: Small: Data-Driven Material Understanding and Decomposition","IIS","Cyber-Human Systems (CHS)","07/01/2016","08/13/2017","Kavita Bala","NY","Cornell University","Continuing grant","Ephraim P. Glinert","06/30/2019","$494,212.00","","kb@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7367","7367, 7923","$0.00","We are in daily contact with a rich range of materials (metals, woods, fabrics, granites, etc.) that contribute to how we understand the world.  Recognizing and modeling real-world materials have long been core challenges in computer vision and graphics.  Recently, scene understanding has experienced an explosion of research activity driven by deep learning models trained on large-scale datasets.  But the focus has mainly been on objects; materials have received less attention, and it has predominantly focused on careful measurements in laboratory settings.  Of course, there is a large gap between materials in the real world and these laboratory settings.  The PI's goal is to bridge that gap, to enable material understanding ""in the wild.""  Toward this end, her group recently released large-scale crowdsourced datasets (OpenSurfaces, Intrinsic Images in the Wild, MINC) that are already being used extensively in the research community.  Using this data to develop new material segmentations and recognition algorithms, the PI's team has produced state-of-the-art methods which open up new possibilities for data-driven material understanding that will impact a wide range of applications such as interior design, material editing, visual search, and robotics.  Project outcomes (including new datasets, annotations, and code) will be made fully open and public.  The PI actively mentors underrepresented minorities at Cornell, and is working with Women in Computing at Cornell (WICC) and Girls Who Code (GWC) to reach middle and high school students.  This research will build prototypes of the annotation tools, and integrate them into summer workshops at Cornell aimed at high school minority students.  The PI's group will also organize a Material Understanding Competition (MUC) to drive innovation in material recognition and segmentation, and intrinsic image decomposition.<br/><br/>This project includes two major technical thrusts in material understanding:<br/><br/>1.  Intrinsic images for material understanding.  Intrinsic image decomposition aims to decompose images into intrinsic properties such as material and illumination.  This decomposition is ill-posed and challenging for images in the wild.  This work will collect new pairwise shading and depth annotations for intrinsic image decomposition; introduce a new perceptual metric to evaluate algorithms; solve for joint material recognition and intrinsic decomposition; and develop proof-of-concept applications for image-based editing using intrinsic image decomposition.<br/><br/>2.  Material recognition for semantic understanding.  Recognizing materials in the wild is extremely challenging.  This work will collect large-scale material annotations with ""click"" data and train weakly supervised recognition algorithms; collect fine-grained material data for subcategories like wood and metal; develop new algorithms for coarse and fine-grain recognition; and develop proof-of-concept applications for intelligent material search, and material assignment to shapes."
"1601865","Commutative Algebra: Set-Theoretic Complete Intersections, Local Cohomology, Free Resolutions, and Rees Rings","DMS","ALGEBRA,NUMBER THEORY,AND COM","09/15/2016","08/21/2018","Claudia Polini","IN","University of Notre Dame","Continuing grant","Timothy Hodges","08/31/2019","$262,000.00","","cpolini@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1264","","$0.00","This research project concerns commutative algebra with a view towards algebraic geometry. Often, the most effective method to solve a problem is to create a mathematical model. Frequently, such models involve unknown parameters related by several equations that are often impossible to solve exactly. Commutative algebra is the qualitative study of such systems of polynomial equations. Its applications are far-reaching and include diverse fields such as computer science, cryptography, coding theory, robotics, pattern recognition, and theoretical physics. One can study the sets of solutions of these systems either geometrically or algebraically. This project deals with the algebraic approach. One of the goals of the project is to understand the smallest number of equations needed to describe a geometric object like a curve or surface. Another is to construct the system of equations defining a given geometric object. A third goal is the study of the relations among a given set of polynomial equations, the relations among the relations, and so on. The project involves undergraduate students, graduate students, and postdoctoral fellows in the research. <br/><br/>This research project has three main themes. The first is to develop criteria for a variety in projective space to be a set-theoretic complete intersection. A fundamental tool to solve this problem is the theory of local cohomology modules. Local cohomology modules encode the algebraic and topological structure of an algebraic variety. As modules over the ring, local cohomology modules are huge (neither finitely generated nor Artinian), hence intractable. However, as modules over the Weil algebra they can be filtered by simple objects and become manageable. Hence an important task is to understand the D-module structure of local cohomology modules. The second theme is the study of local rings using the notion of distance. This notion was introduced in recent work of the investigator and collaborators to understand the integral closure of ideals. The idea is to use distance as a substitute for shifts in homogeneous resolutions and for the Castelnuovo-Mumford regularity of graded modules. The main goal is to prove general results that are inspired by statements in the graded case. The last theme is to study the implicit equations defining the graph and the image of rational maps between projective spaces. This is a classical problem in elimination theory, commutative algebra, and algebraic geometry with applications, for instance, in geometric modeling."
"1629856","CI-SUSTAIN: Collaborative Research: Extending a Large Multimodal Corpus of Spontaneous Behavior for Automated Emotion Analysis","CNS","SPECIAL PROJECTS - CISE, COMPUTING RES INFRASTRUCTURE","09/01/2016","05/05/2017","Qiang Ji","NY","Rensselaer Polytechnic Institute","Standard Grant","Dan Cosley","08/31/2019","$223,426.00","","qji@ecse.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","1714, 7359","7359, 9251","$0.00","This project will extend and sustain a widely-used data infrastructure for studying human emotion, hosted at the lead investigator's university and available to the research community.  The first two versions of the dataset (BP4D and BP4D+) contain videos of people reacting to varied emotion-eliciting situations, their self-reported emotion, and expert annotations of their facial expression. Version 1, BP4D (n=41), has been used by over 100 research groups and supported a successful community competition around recognizing emotion.  The second version (BP4D+) adds participants (n = 140), thermal imaging, and measures of peripheral physiology.  The current project greatly broadens and extends this corpus to produce a new dataset (BP4D++) that enables deep-learning approaches, increases generalizability, and builds research infrastructure and community in computer and behavioral science.  The collaborators will (1) increase participant diversity; 2) add videos of pairs of people interacting to the current mix of individual and interviewer-mediated video; 3) increase the number of participants to meet the demands of recent advances in ""big data"" approaches to machine learning; and 4) expand the size and scope of annotations in the videos. They will also involve the community through an oversight and coordinating consortium that includes researchers in computer vision, biometrics, robotics, and cognitive and behavioral science. The consortium will be composed of special interest groups that focus on various aspects of the corpus, including groups responsible for completing the needed annotations, generating meta-data, and expanding the database application scope.  Having an infrastructure to support emotion recognition research matters because computer systems that interact with people (such as phone assistants or characters in virtual reality environments) will be more useful if they react appropriately to what people are doing, thinking, and feeling.  <br/><br/>The team will triple the number of participants in the combined corpora to 540.  They will develop a dyadic interaction task and capture data from 100 interacting dyads to support dynamic modeling of interpersonal influence across expressive behavior and physiology, as well as analysis of emotional synchrony.  They will increase the density of facial annotations to about 15 million frames in total, allowing the database to become sufficiently large to support deep-learning approaches to multimodal emotion detection. These annotations will be accomplished through a hybrid approach that combines expert coding using the Facial Action Coding System, automated face analysis, and crowdsourcing with expert input from the research community.  Finally, the recorded data will be augmented with a wide range of meta-data derived from 2D videos, 3D videos, thermal videos, and physiological signals.  To ensure the community is involved in sustaining the infrastructure, in addition to the governance consortium described above, the investigators will involve the community in jointly building both APIs that allow adding meta-data and annotations and tools to support the submission and evaluation of new recognition algorithms, then organizing community-wide competitions using those tools.  The research team will also reach out to new research communities around health computing, biometrics, and affective computing to widen the utility of the enhanced infrastructure, grow the community of expert annotators through training workshops, and build an educational community around the infrastructure that facilitates the development and sharing of course materials that use it.  Long-term, the infrastructure will be funded through a combination of commercial licensing and support from the lead university's system administration group."
"1601619","Asymptotic Commutative Algebra and Multigraded Syzygies","DMS","ALGEBRA,NUMBER THEORY,AND COM","08/01/2016","08/20/2018","Daniel Erman","WI","University of Wisconsin-Madison","Continuing grant","Timothy Hodges","07/31/2019","$204,605.00","","derman@math.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","MPS","1264","","$0.00","This research project concerns commutative algebra, which provides the foundation for a broad range of mathematics, including algebraic geometry and algebraic number theory. Commutative algebra finds application in many fields of science and engineering, including computer science, cryptography, coding theory, robotics, pattern recognition, and theoretical physics.  Part of the work in this project aims to connect the Kakeya needle problem, a classical analysis problem about the amount of space needed to turn a needle in a full circle, with modern ideas from commutative algebra. Another part of the project will use commutative algebra to design new algorithms for performing geometric computations about a class of shapes with extraordinary symmetries, among other applications. <br/><br/>This research will build new frontiers between commutative algebra and other fields. The first project connects commutative algebra with harmonic analysis. The Kakeya conjecture is a central problem in harmonic analysis that has spawned a parallel literature over finite fields. The project aims to expand this parallel to the p-adic integers, yielding closer connections with the original analytic questions. The second project develops homological algebra methods for new geometric settings. For a variety embedded in something other than projective space, free resolutions often fail to provide sharp connections with geometry; this project will develop homological machinery better suited to toric geometry. This multifaceted project offers an array of potential applications: splitting theorems for vector bundles on toric varieties, rationality proofs for Hurwitz spaces, and new sheaf cohomology algorithms."
"1544173","CPS: TTP Option: Synergy: Collaborative Research: Certifiable, Scalable, and Attack-resilient Submodular Control Framework for Smart Grid Stability","CNS","SPECIAL PROJECTS - CISE, CYBER-PHYSICAL SYSTEMS (CPS), ","10/01/2015","09/13/2016","Linda Bushnell","WA","University of Washington","Continuing grant","David Corman","09/30/2019","$893,643.00","Radha Poovendran, Daniel Kirschen","lb2@uw.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","1714, 7918, P342","7918, 8235, 8237, 9102","$0.00","Exploiting inherent physical structure of the CPS domains can lead to economically viable and efficient novel algorithms for providing performance, control, synchronization and an alternate approach to CPS security that does not rely solely on cryptography. In each of these systems, regardless of the current state of the network, in the presence of disturbances or adversarial inputs, there is a need to bring the system to desired state for performance and control of the network. <br/><br/>This project presents one such novel approach by observing that the CPS applications including smartgrid, coordinating robotics, formation flights in UAV, and synchronization of biological systems including brain networks all exhibit a special physical structure, namely submodularity, with respect to the set of control actions. Submodularity is a diminishing returns property that enables the development of efficient algorithms with provable optimality guarantees and in many cases distributed versions that are locally implementable, and hence scalable. While it has been widely used in the machine learning and discrete optimization communities, the use of submodularity in the context of CPS is a fertile research area.  This project initially applies submodularity in the context of smart grid and show how it can lead to greater system stability and attack resilience. By defining suitable metrics that capture the submodular structures underlying the physical dynamics, the researchers develop algorithms that eliminate the time-consuming and computationally expensive verification of control actions through simulation. The fundamental properties of synchronization, convergence, robustness, and attack-resilience considered in this effort have crosscutting applications to multiple CPS domains, which will benefit from the submodular approach that we will research and develop."
"1435999","DMREF/Collaborative Research: Graphene Based Origami and Kirigami Metamaterials","DMR","DMREF","09/01/2014","08/21/2018","David Nelson","MA","Harvard University","Standard Grant","John Schlueter","08/31/2019","$359,999.00","","nelson@physics.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","MPS","8292","054Z, 8400, 9177","$0.00","Graphene-Based Origami and Kirigami Metamaterials<br/><br/>Non-Technical Description: The paper arts of origami and kirigami ('ori' = fold, 'kiri' = cut) provide a powerful framework to design responsive and tunable new materials. For example, a simple series of cuts can turn a sheet of paper into an accordion-like spring, or a sequence of folds can convert it into a swan. Indeed, many biological tissues develop folds and cuts reminiscent of origami and kirigami that endow them with distinct and useful mechanical properties. The seemingly limitless number of forms that can be created speaks to the potential of exploiting such design principles for materials beyond paper. This project will extend these design ideas to the microscale using graphene, an atomically thin two dimensional material, as the nanoscale paper foundation. Lithographic techniques borrowed from the semiconductor industry will be used to pattern the graphene, and a variety of approaches will be employed to create folds, all chosen to realize a specific mechanical property. The focus is on creating mechanical 'metamaterials' - materials whose properties reflect the patterns of folds and cuts rather than the properties of the underlying paper.  With room temperature applications in mind, the theoretical effort will focus on the crucial role of thermally-activated Brownian motion in determining the material properties of graphene monolayers with cuts and folds. This paper-arts-inspired strategy has the potential to fundamentally transform the way materials are designed for the micro-world and could find applications in areas ranging from micro-robotics to mechanical sensors and actuators that mimic biologically 'active' tissues.<br/><br/>Technical Description: Using lithographic techniques, graphene sheets will be perforated and cut to create modules with prescribed mechanical properties. These modules will be assembled to create mechanical meta-materials whose response to applied stresses, temperature, and other environmental signals can be tailored. The project focuses on the following interrelated goals: (a) Experimentally testing current predictions for graphene's thermomechanical properties and their dependence on geometry and boundary conditions; (b) Creating a library of mechanically programmable modular units out of cut graphene sheets; (c) Designing meta-materials assembled out of the basic graphene kirigami and origami modules to achieve a particular function; (d)  Creating a theory of thermally excited atomically thin membranes with cuts and folds, to guide experiments and improve understanding of the basic principles. These goals will form the cornerstone for building a general-purpose open source design tool that can be used by engineers to assemble materials out of the origami and kirigami based modules, simulate their mechanical properties, and allow for iterative design work flows. This tool will be used to promote rapid materials discovery, development, and property optimization of atomic membrane origami and kirigami metamaterials."
"1304843","Understanding, Supporting, and Creating Curriculum Pathways for Industrial Automation Careers","DUE","ADVANCED TECH EDUCATION PROG, Jobs Council","09/01/2013","08/17/2018","Sheng-Jen Hsieh","TX","Texas A&M Engineering Experiment Station","Continuing grant","Heather Watson","08/31/2019","$949,999.00","","hsieh@tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","EHR","7412, 8281","1032, 9178, SMET","$0.00","This project is supporting and creating curriculum pathways to increase the number of qualified technicians in the areas of operation, troubleshooting, design and integration of automated manufacturing systems (industrial automation). The curriculum pathways include a series of courses and learning experiences that equip students for a successful career in automated systems and industrial automation. The project is developing career pathways that lead from high school to the workforce, using web technologies to make industrial automation education more accessible. <br/><br/>Intellectual Merit:<br/>Many curriculum articulation efforts have focused on establishing dual credit programs for general academic subjects or on particular types of technology, such as mechatronics and robotics. There has been relatively little emphasis on automated systems education or establishing dual credit programs in industrial automation that begin at the high school level. To overcome this shortcoming the project is: 1) assessing industry workforce needs and skill sets in the area of industrial automation, 2) identifying gaps and inefficiencies that affect students' ability to smoothly transition from high school to two or four-year college to jobs in industry, 3) developing curriculum pathways and articulation agreements to efficiently prepare students to enter the workforce, 4) developing tools (e.g., web-accessible automated systems and virtual learning environments) to make hands-on learning experiences more accessible to learners with limited instructional resources, and 5) pilot-testing the tools within three clusters consisting of (at least) one high school, one two-year college, and one four-year college.<br/><br/>Broader Impacts:<br/>The project is helping provide U.S. companies with technicians and engineers who have a deeper understanding of industrial automation concepts, and who are better prepared to adapt to changes in production goals, automation processes and organizational restructuring. The partnering institutions are working with a significant number of underrepresented minority students and the propagation plans are providing further opportunities for students from all backgrounds to learn the concepts associated with system integration. <br/><br/>The project is further contributing to rural technician education, by engaging two-year college participants from west Texas to work in the wind and solar energy industries. Since there has been relatively little emphasis on automated systems workforce preparation, the project is creating model career pathways from high school to the workforce and using web technologies to make industrial automation education more accessible to all. The project's focus on automated manufacturing to benefit the energy industry is helping address the global priority on the critical shortage of highly qualified workers to positively impact the nation and its related economy."
"1502046","Marine Advanced Technology Education Support Center","DUE","ADVANCED TECH EDUCATION PROG","07/15/2015","07/15/2015","Deidre Sullivan","CA","Monterey Peninsula College","Standard Grant","V. Celeste  Carter","06/30/2020","$1,599,212.00","Michael Gilmartin, Jill Zande, Scott Fraser","dsullivan@mpc.edu","980 Fremont","Monterey","CA","939404704","8316463081","EHR","7412","1032, 9178, SMET","$0.00","Marine technology is vital to many aspects of our national economy. This project characterizes and researches trends in the ocean workforce, identifies the knowledge and skills this workforce needs, places this information in the hands of educational institutions at all levels, and works to ensure that curricula and programs are appropriately preparing students for the workplace. MATE's programs represent unique approaches to engaging students in science, technology, engineering, and math (STEM) learning experiences and developing the capacity for increasing the nation's technological workforce.  <br/><br/>As a Support Center for marine technology education, the MATE Center will: <br/>1. Expand and strengthen partnerships with academic institutions, employers, and professional societies to better prepare students for the ocean workforce. <br/>2. Develop an international remotely operated vehicle (ROV) technician competency and assessment program endorsed by industry. <br/>3. Continue to improve student learning in STEM through activities such as regional and international underwater robotics (ROV) competitions that simulate the high performance workplace and build academic and industry partnerships. <br/>4. Offer faculty professional development institutes that focus on marine technology, create an awareness of ocean-related careers, and empower instructors to deliver interdisciplinary, technology-rich learning experiences to their students. <br/>5. Continue the MATE at-sea technical internship program and increase the numbers of underrepresented students participating in the program. <br/>6. Disseminate MATE products, including curricula, textbooks, occupational guidelines, competencies, and procedural guides, in both traditional formats and electronically through the Center's web sites www.marinetech.org and www.OceanCareers.com.<br/> <br/>The MATE Center's breadth of academic, industry, and professional society partnerships support the development, testing, and widespread implementation of exceptional marine technical education programs, instructional materials, activities, and the dissemination of these innovative resources. This, in turn, strengthens linkages between educational programs; catalyzes other activities that provide students with additional educational opportunities and pathways to careers; and helps to address both regional and national marine technical workforce needs. These efforts will prepare a diverse workforce that will help ensure U.S. competitiveness in a global economy that is currently, and increasingly, dependent on ocean activities."
"1844818","NSF Student Travel Grant for DNA24: The 24th International Conference on DNA Computing and Molecular Programming","CCF","COMPUTATIONAL BIOLOGY","10/01/2018","08/16/2018","Erik Winfree","CA","California Institute of Technology","Standard Grant","Mitra Basu","09/30/2019","$15,000.00","","winfree@caltech.edu","1200 E California Blvd","PASADENA","CA","911250600","6263956219","CSE","7931","7556, 7946","$0.00","With a vision to establish novel molecular programming rules for engineering for developing synthetic systems inside or outside of living cells, the annual International Conference on DNA Computing and Molecular Programming has been one of the premier interdisciplinary forums where scientists with diverse backgrounds (e.g., in computer science, physics, chemistry, biology and mathematics) come together to present their highest quality research and discuss new ideas.  This proposal aims to provide student travel support for the 24th International Conference on DNA Computing and Molecular Programming (DNA24), to be held at Jinan, China during October 8-12, 2018.  By funding travel for U.S.-based students, the organizers are actively encouraging and incentivizing a new generation of researchers to benefit from participating in the conference, fostering the development of the next generation of molecular programmers, by encouraging students to attend, present their work, and interact with other important players in the field. Up to 15 successful student applicants will be supported, by providing assistance to women and underrepresented minorities who are delivering oral or poster presentations at the conference, and to graduate students who are otherwise unable to afford attending this conference.  The availability of the awards to US citizens and students at US institutions will be included in conference announcements, soliciting applications.  <br/><br/>This highly interdisciplinary conference emphasizes topics that bridge computation, biology, and nanotechnology and attracts researchers in the fields of computer science, mathematics, chemistry, molecular biology, and nanotechnology. The scope includes control of molecular folding and self-assembly to construct nanostructures; demonstration of switches, gates, devices, and circuits with biomolecules; molecular motors and molecular robotics; computational processes in vitro and in vivo; studies of fault-tolerance and error correction; synthetic biology and in vitro evolution; software tools for analysis, simulation, and design; a range of applications in engineering, physics, chemistry, biology, and medicine.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1708990","Rational Design of High Dielectric Constant and Low Loss Dipolar Glass Polymers with Enhanced Orientational Polarization","DMR","POLYMERS","07/01/2017","03/06/2017","Lei Zhu","OH","Case Western Reserve University","Standard Grant","Andrew J. Lovinger","06/30/2020","$465,000.00","Philip Taylor","lei.zhu2@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","MPS","1773","054Z, 8037","$0.00","NON-TECHNICAL SUMMARY:<br/><br/>Numerous applications have been found for flexible hybrid electronics, including human performance monitoring, wearable medical sensors, information storage, and soft robotics. An indispensable component for flexible electronics is the printable dielectric layer, which regulates the electric current in the semiconductor. In response to this demand, this project is aimed at the design and development of novel printable high-performance dielectric polymers. In this project, a polymer theoretician will use advanced computer simulation to design and predict the dielectric properties for these new materials. A polymer chemist will synthesize the designed dielectric polymers, whose various properties and performance will be characterized by a polymer physicist (who will also be coordinating the research).  A close loop among theoretical prediction, chemical synthesis, and polymer characterization will be built in the project to accelerate the progress. If successful, not only will our knowledge on polymer dielectric phenomena be advanced, but also new printable dielectric materials could ensue for future flexible electronics and energy-related applications. In addition to its industrial relevance, this project will also provide a comprehensive platform for education and outreach on science, technology, engineering, and mathematics (STEM). The project is aimed to include undergraduates and high-school students in research and to enhance diversity. It will also benefit an undergraduate/graduate course on Advanced Polymer Engineering which will include electrical properties of polymers for practical applications. Students will be encouraged to present their findings at local and major national meetings.<br/><br/><br/><br/>TECHNICAL SUMMARY:<br/><br/>A high-performance printable gate dielectric is an important component for future flexible field-effect transistors (FETs). To enhance the performance, past research has focused on decreasing the thickness of the gate dielectric, e.g., via self-assembled monolayers. Although high capacitance density can be achieved using ultrathin dielectrics, manufacturability has been challenging due to the susceptibility of ultrathin films to intrinsic defects, such as pinholes and grain boundaries. To circumvent this manufacturing challenge, the dielectric constant of printable gate dielectrics has to be substantially increased while keeping the dielectric loss low. In addition, gate dielectrics should have good mechanical stability and good response to external fields in a wide range of frequencies. To realize reliable printable/flexible FETs, this project aims to design and develop novel high-dielectric-constant and low-loss dipolar glass polymers with intrinsic microporosity (DG-PIMs). First, theoretical analysis and computer simulation using mixed full atomistic and coarse-grained molecular dynamics will guide the design and synthesis of DG-PIMs. Post-modifications will be employed to convert conventional PIMs into novel DG polymers. Both structural and dielectric properties will be characterized, and computer simulation studies will be refined on the basis of the experimental results. Through this cycle of computer simulation, polymer synthesis, structure/property characterization, and feedback, enhanced orientational polarization in the proposed DG-PIMs will be fully explored and improved new materials produced."
"1435794","DMREF/Collaborative Research: Graphene Based Origami and Kirigami Metamaterials","DMR","DMREF","09/01/2014","08/17/2018","Mark Bowick","NY","Syracuse University","Standard Grant","John Schlueter","02/28/2019","$359,999.00","","bowick@physics.syr.edu","OFFICE OF SPONSORED PROGRAMS","SYRACUSE","NY","132441200","3154432807","MPS","8292","054Z, 8400, 9177","$0.00","Graphene-Based Origami and Kirigami Metamaterials<br/><br/>Non-Technical Description: The paper arts of origami and kirigami ('ori' = fold, 'kiri' = cut) provide a powerful framework to design responsive and tunable new materials. For example, a simple series of cuts can turn a sheet of paper into an accordion-like spring, or a sequence of folds can convert it into a swan. Indeed, many biological tissues develop folds and cuts reminiscent of origami and kirigami that endow them with distinct and useful mechanical properties. The seemingly limitless number of forms that can be created speaks to the potential of exploiting such design principles for materials beyond paper. This project will extend these design ideas to the microscale using graphene, an atomically thin two dimensional material, as the nanoscale paper foundation. Lithographic techniques borrowed from the semiconductor industry will be used to pattern the graphene, and a variety of approaches will be employed to create folds, all chosen to realize a specific mechanical property. The focus is on creating mechanical 'metamaterials' - materials whose properties reflect the patterns of folds and cuts rather than the properties of the underlying paper.  With room temperature applications in mind, the theoretical effort will focus on the crucial role of thermally-activated Brownian motion in determining the material properties of graphene monolayers with cuts and folds. This paper-arts-inspired strategy has the potential to fundamentally transform the way materials are designed for the micro-world and could find applications in areas ranging from micro-robotics to mechanical sensors and actuators that mimic biologically 'active' tissues.<br/><br/>Technical Description: Using lithographic techniques, graphene sheets will be perforated and cut to create modules with prescribed mechanical properties. These modules will be assembled to create mechanical meta-materials whose response to applied stresses, temperature, and other environmental signals can be tailored. The project focuses on the following interrelated goals: (a) Experimentally testing current predictions for graphene's thermomechanical properties and their dependence on geometry and boundary conditions; (b) Creating a library of mechanically programmable modular units out of cut graphene sheets; (c) Designing meta-materials assembled out of the basic graphene kirigami and origami modules to achieve a particular function; (d)  Creating a theory of thermally excited atomically thin membranes with cuts and folds, to guide experiments and improve understanding of the basic principles. These goals will form the cornerstone for building a general-purpose open source design tool that can be used by engineers to assemble materials out of the origami and kirigami based modules, simulate their mechanical properties, and allow for iterative design work flows. This tool will be used to promote rapid materials discovery, development, and property optimization of atomic membrane origami and kirigami metamaterials."
"1750731","CAREER: The Future of Work in Health Analytics and Automation: Investigating the Communication that Builds Human-Technology Partnerships","SES","CROSS-DIRECTORATE  ACTIV PROGR, Science of Organizations","09/01/2018","08/15/2018","Joshua Barbour","TX","University of Texas at Austin","Continuing grant","Georgia Chao","08/31/2023","$204,471.00","","barbourjosh@utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","SBE","1397, 8031","063Z, 1045","$0.00","Advances in technologies such as the internet of things, robotics, and artificial intelligence are transforming work through data-intensive automation, which may eliminate jobs without creating new ones or deskill and diminish existing work. This project will investigate how work is automated to encourage forms that benefit work and workers. The project will expand knowledge about the everyday conversations that shape the implementation of automation, and how leaders make choices about how to have those conversations in the first place. The project will focus on health and healthcare work, with is a context likely to be affected by datafication and automation and likely to provide STEM-related careers for individuals who have the right skills. In healthcare, automation may help providers prevent medical errors, lower the costs of caregiving, and augment or create new forms of work, but the success of such systems depends on how they are designed and implemented. By focusing on the actual communication involved in automation, the project will generate theoretical insights and practical recommendations for leaders in health and analytics organizations, regarding (a) what makes the communication involved in data-intensive automation effective or not, and (b) how to structure and facilitate that communication. The research will be used to create short films and a learning module for students making key career decisions. The films and module will be designed to reach groups underrepresented in STEM and to provide information about STEM careers affected by automation and STEM-related, communication competencies. The project will help students at community colleges and universities understand and prepare for the opportunities and challenges of automation.<br/><br/>Recent research has demonstrated that automation is determined not merely by the features of new technology or pressures to make work more efficient, but by a complex, communicatively-negotiated mix of workers' and managers' ideas about factors such as market forces, professional standards, regulation, industry knowledge, and human and technology workflows. Automation involves intertwined changes in the technologies and organization of work. These changes unfold in and through everyday communication about how work is and ought to be accomplished. Using a combination of interview and observational methods, the project will investigate two theoretically and practically important contexts: (1) Healthcare organizations that develop and implement technologies such as automated metrics dashboards and clinical decisions support systems, and (2) Quantified Self communities where practitioners of personal analytics are creating new human-technology partnerships, new forms of work and play, through automation. Insights from this project will advance research on automation, data-intensive work, communication design, and organizational and technological change.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1546882","RESEARCH-PGR: Dissecting the Genetic Networks Underlying Kranz Anatomy in C4 Grasses","MCB","PLANT GENOME RESEARCH PROJECT","08/15/2016","07/16/2018","Thomas Brutnell","MO","Donald Danforth Plant Science Center","Standard Grant","Karen C. Cone","07/31/2019","$1,664,589.00","Todd Mockler, Joyce Van Eck, Christopher Myers, Doris Wagner, Kimberly Gallagher","tbrutnell@danforthcenter.org","975 N. Warson Rd.","St. Louis","MO","631322918","3145871041","BIO","1329","7577, 9109, 9150, 9179, BIOT","$0.00","PI: Thomas Brutnell [Donald Danforth Plant Science Center, (DDPSC)]<br/><br/>CoPIs: Elizabeth Kellogg and Todd Mockler (DDPSC), Kimberly Gallagher (University of Pennsylvania), Chris Myers (Cornell University) and Joyce Van Eck (Boyce Thompson Institute for Plant Science)<br/><br/>Senior Personnel: Robert Turgeon, Qi Sun, and Klaas van Wijk (Cornell University)<br/><br/>Declining yields, increasing population growth and shifting climates are converging to create a perfect storm for agriculture. The looming threats to food security demand transformative innovations in agriculture that will drive the second green revolution. Maize is the most economically important crop in the U.S providing food, feed and bioenergy to the global economy. It is also one of the most photosynthetically productive plants on the planet. This productivity is driven by biochemical and anatomical adaptations associated with C4 photosynthesis. One proposed grand challenge is to introduce C4 traits into C3 crops such as rice and many temperate grasses. A major conceptual breakthrough in the understanding of the development of C4 photosynthesis was realized through the discovery that a root endodermal cell fate module was co-opted to drive a leaf specific cellular differentiation program. Importantly, a prediction from this model suggests that a limited number of changes in genes could lead to a major reprogramming of leaf cell fates.  This project will test this prediction and expand on our understanding of the gene regulatory networks that drive both biochemical and anatomical innovations associated with C4 photosynthesis. The results of these studies will not only provide candidate genes for engineering C4 traits into C3 crops, but also provide novel targets for improvement of existing C4 crops such as maize, sugarcane and sorghum. With regard to training and outreach, the project will continue to expand on the MutantMillets outreach program at the DDPSC. MutantMillets provides teaching modules and teaching resources with hands-on activities in the plant sciences to engage high school students in the St. Louis metropolitan region. Importantly, all resources developed through this program will be portable to other school systems through the project website and through the educational networks established by the Education and Outreach Center at the DDPSC.<br/> <br/><br/>Grasses that utilize C4 photosynthesis include maize, sorghum, sugarcane and Miscanthus.  C4 grasses use two distinct cell types to create a CO2 pump that elevates the levels of CO2 in the vicinity of the enzyme Rubisco, effectively eliminating wasteful photorespiration. Under hot, dry conditions C4 systems display significantly increased productivity relative to C3 crops such as rice and wheat. This project aims to identify the foundational genetic and regulatory networks that control the differentiation of the two photosynthetic cell types in maize - the bundle sheath (BS) and mesophyll (M). This work expands on recent discoveries that has linked the SHR/SCR/IDD regulatory module to the differentiation of the BS and M cells of maize and provides new opportunities to more fully explore the function of this regulatory network in C4 grasses through an integrated systems biology approach. These studies will include the development and implementation of several emerging technologies including cell-type specific proteomics, CRISPR/Cas9 gene editing technologies, robotics-based yeast one hybrid screens, ChIP-seq, translatomics, X-ray computed tomography, novel informatics/network analysis algorithms, and modeling of both developmental phenotypes and mechanistic regulatory networks. All data and resources generated in this project will be made accessible to the public through the project website and through long-term repositories."
"1822201","Phase II IUCRC at Colorado School of Mines:  Center for Manufacturing & Materials Joining Innovation Center (Ma2JIC)","IIP","INDUSTRY/UNIV COOP RES CENTERS","08/15/2018","08/16/2018","Stephen Liu","CO","Colorado School of Mines","Continuing grant","Andre Marshall","07/31/2020","$100,000.00","Vilem Petr, Xiaoli Zhang, Zhenzhen Yu, Juan Carlos Madeni","sliu@mines.edu","1500 Illinois","Golden","CO","804011887","3032733000","ENG","5761","5761","$0.00","The Manufacturing and Materials Joining Innovation Center (Ma2JIC) addresses the question of infrastructure rebuilding and innovative materials application in modern manufacturing which are of national interest. The Ma2JIC Center establishes an environment between universities and industrial partners that promotes the development and application of fundamental knowledge in the areas of materials joining and additive manufacturing and provides a platform for the education of the next generation of scientists and engineers. As one of the sites since its inception, the Colorado School of Mines (CSM) Site has complemented the Center with its unique expertise and laboratory facilities in the design and manufacturing of innovative welding materials, welding and joining process innovation, welding materials characterization, and additive manufacturing for the energy, aerospace, oil and gas, and manufacturing industries. The CSM Site will seek to intensify its collaborations with the other Center Sites to jointly develop collaborations with the welding, joining and manufacturing industries, large and small, national laboratories and government agencies. The strength of the Center is the ability of the group to close the gap between materials development and weldability for materials used in the manufacturing industry, with ultimate societal gain from all these amazing synergies.<br/><br/>The Ma2JIC Center research thrusts of Process Innovation, Materials Performance, Additive Manufacturing, Weldability Testing and Evaluation will develop fundamental understanding as described by the materials tetrahedron - ""Processing-Microstructure-Properties-Performance"".  CSM Site researchers are examining the fundamental aspects of GTA and Laser weldability of Laser-Powder bed fusion AM built products, solidification behavior of Laser-Powder bed fusion and Directed Energy Deposition AM products, and filler metal development for microstructural optimization in Electron Beam Freeform Fabrication products, including metal matrix composites. The incorporation of Reaction Synthesis powder into tubular wires for both laser-based and electron beam-based additive manufacturing is being attempted. The effect of surface tension on AM deposits will be fully characterized and understood for process control.  Another research focus addresses the design and manufacture of thermal spray coatings with enhanced wear and fracture resistance for oil and gas drilling operations. The CSM Site will continue to study and design low transformation temperature welding (LTTW) consumables for distortion control and residual stress mitigation control. These programs are expected to lead to the development of fundamental knowledge as well as practical technology. The CSM Site is also pursuing cross university and multi-industry collaboration on intelligent welding, friction stir processing, robotics, advanced neutron and X-rays characterization, and data-driven modeling.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822186","Phase II IUCRC at University of Tennessee, Knoxville (UTK):  Manufacturing and Materials Joining Innovation Center (Ma2JIC)","IIP","INDUSTRY/UNIV COOP RES CENTERS","08/15/2018","08/15/2018","Claudia Rawn","TN","University of Tennessee Knoxville","Continuing grant","Andre Marshall","07/31/2020","$100,000.00","William Hamel, Dayakar Penumadu, Sudarsanam Babu, Stephanie TerMaath","crawn@utk.edu","1 CIRCLE PARK","KNOXVILLE","TN","379960003","8659743466","ENG","5761","5761","$0.00","The Manufacturing and Materials Joining Innovation Center (Ma2JIC) research aims to close the gap between materials development and weldability by developing scientifically based methodologies for assessing weldability and joinability that span length scales over a wide variety of materials.  The University of Tennessee, Knoxville (UTK) site strengths include materials development, crosscutting capabilities including multi-scale characterization and modeling, and metal additive manufacturing (AM).  AM technologies have the potential to benefit society in a multitude of ways including reducing scarce and dwindling raw materials and producing unique parts for variety of applications associated with aerospace, infrastructure, energy, and automotive industries. Equally important is educating and developing a new generation of materials joining engineers and scientists. Engineers will design by building layer-by-layer and parts can feature unlimited possibilities in design complexity. During Phase I the UTK site of Ma2JIC established collaborative research with small-, medium- and large-scale industries and national laboratories and began shaping and refining a research agenda based on industrial needs.  During Phase II the Ma2JIC UTK site seeks to continue to grow these collaborations along with research relevant to future and existing manufacturing industries, establishing new collaborations, and initiating projects that will strengthen collaborations with the other Ma2JIC sites.<br/><br/>Technical efforts of the Ma2JIC UTK site promote innovations in welding, materials joining, and additive manufacturing technologies through interdisciplinary research bringing together design, robotics and automation, process innovation/control, materials science, advanced characterization and high-performance computational modeling. The research portfolio of the UTK site brings capabilities in the area of large-scale additive metal manufacturing and characterization techniques, especially using radiation based scattering and imaging using neutrons and X-rays. The end results of the projects will be focused on promoting higher yields and scale-up of proven laboratory developments relevant to aerospace, infrastructure, energy, and automotive applications. The research promotes scientific discoveries related to the thermo-mechanical-chemical properties of new and existing materials consolidated and joined using traditional and new techniques. Complementary computational and experimental characterization techniques, including in situ and ex situ conditions, will be applied to understand issues such as cyclic thermal and stress loading, residual stress development, and microstructural evolution. The UTK site will produce fundamental research techniques and students versed in these techniques at the crossroads of joining and additive manufacturing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1826135","Cell-Cell Adhesion Mechanics and Mechanotransduction at the Single Cell Level","CMMI","Biomechanics & Mechanobiology","09/15/2018","08/14/2018","Ruiguo Yang","NE","University of Nebraska-Lincoln","Standard Grant","Michele Grimm","08/31/2021","$439,584.00","Jung Yul Lim","ryang6@unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","ENG","7479","027E, 028E, 070Z, 9150","$0.00","For cells to remain attached to their neighbors, there are cell-cell 'adhesion complexes.' These complexes are parts of the cell surface made up of very large adhesive molecules that transfer forces between the cells and hold them together.  Mechanical coupling at adhesion complexes is necessary for many of the healthy behaviors of cells.  Changes in the structure of the adhesion complex or of how the molecules change shape during stretching can cause diseases of the heart, joints (arthritis), and is part of the cellular story in cancer. The cell-cell junctions also are part of the cell's ability to detect how large the forces are on the tissue (mechanotransduction).  One type of these junctions between cells, the 'desmosome', connects to the fiber network inside the cell to transmit forces and is not understood very well since most previous adhesion complex research has been done on the 'adherens' junction, which has different molecules and is associated with different diseases.  This research project will reduce the huge knowledge gap about desmosomes with respect to their potential roles in mechanotransduction and disease control.  The research will further the goals of the United States in developing the basic knowledge needed to understand and eventually treat medical conditions that are caused by failure of the desmosome to properly function. The research study will be integrated with existing University of Nebraska educational programs to offer undergraduate students experiences in mechanics, robotics, and cell biology. The PIs will also translate the research methodologies into a new course, ""Cell Mechanics"", in order to bring bioengineering-intensive knowledge into the current curriculum.<br/><br/>Data from the PI's group have demonstrated the role of the desmosome-intermediate filament linkage in regulating cell mechanics, a role that has long been regarded to belong solely to the adherens junction. The research will determine the role that desmosomes play in cell-cell adhesion mechanics and in mechanotransduction. To achieve this goal, a novel device will be developed to provide in situ stimulation and interrogation of cell-cell junctions through defined mechanical tension. The platform will be able to stretch the mutual junction of a single pair of cells and simultaneously perform mechanical measurement, which will address the current challenge in interrogating cell-cell adhesion (i.e., difficulties in applying defined mechanical stimuli and conducting mechanical measurements at the same time). More importantly, integrated within an imaging system, the effect of mechanical stimuli on mechanotransduction pathways at the cell-cell junction can be monitored in real-time under applied load. With the platform, two fundamental scientific questions will be answered: (1) what is the contribution of desmosome and its link to intermediate filaments in maintaining cell-cell adhesion strength and (2) does the desmosome junction include mechanosensors that convert applied mechanical cues into biochemical signals to regulate cell behavior?<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1726512","MRI: SEANet: Development of a Software-Defined Networking Testbed for the Internet of Underwater Things","CNS","MAJOR RESEARCH INSTRUMENTATION, SPECIAL PROJECTS - CISE, Networking Technology and Syst","10/01/2017","02/13/2018","Tommaso Melodia","MA","Northeastern University","Standard Grant","Rita V. Rodriguez","09/30/2020","$1,107,999.00","Milica Stojanovic, Stefano Basagni, Matteo Rinaldi","melodia@ece.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","1189, 1714, 7363","1189, 9251","$0.00","This project, developing SEANet, a new-generation software-defined underwater acoustic modem and a networking testbed, enables a leap forward in underwater communication. The SEANet testbed constitutes a game-changing development in the field, as it provides:<br/>- Fully reconfigurable modems with much higher data rates and flexibility than currently available and<br/>- Sophisticated communication and networking primitives unavailable with the current technology.<br/>Although underwater acoustic networking technology has become key to most commercial and military activities at sea, currently it can only support mostly point-to-point, low-data-rate, delay-tolerant applications. Hence this technology remains in its infancy. Commercial acoustic modems use signaling schemes that often achieve < 20 kilobit/s with a link distance of one km over horizontal links. <br/><br/>The instrument under development would be composed of SEANet modems interconnected with terrestrial Internet through the NU-MONET network at the NEU Marine Science Center. Unlike existing commercial modems that are inherently based on fixed and inflexible hardware, <br/>- SEANet will be built around a new-generation Zynq System-on-Chip architecture board, with reconfigurable design supporting fully software-defined communication & networking functionalities, overcoming the lack of flexibility that limits the capabilities of existing commercial & experimental platforms in the fast-varying underwater acoustic channel; <br/>- SEANet will provide a set of newly-developed cross-layer platform-independent protocol development abstractions to be used by students and researchers to rapidly prototype new protocols and transmission schemes; <br/>- Networking protocols and transmission schemes will be software-defined based on abstractions discussed above, but hardware-executed by reconfigurable flexible processing hardware at runtime; <br/>- SEANet will be endowed with custom-designed ultra-wide band micro-electromechanical (MEMS) transducers that will allow the modem to transmit over much wider acoustic bandwidths (i.e., >= 2 MHz) than currently available existing modems. <br/>As a result SEANet will be able to operate at lower power consumption than achievable state-of-the-art bulk piezoelectric transducers used in current commercial and experiment platforms, and reach rates in the order of 500 kilobit/s over 200 in range links and Mbit/s rates shorter range links (~ 50 m). <br/><br/>Broader Impacts: <br/>The instrumentation provides the university and overall research community with unique capabilities for data collection in field installations. It also provides the underwater research community with an experimental platform that will be instrumental in advancing research activities in underwater networking. This development directly supports the research activities in communications, networking, security, robotics, and marine science at the institution. The platform will be broadly advertised and made available to the US academic community. The testbed will become a unique research and training facility for undergraduate and graduate students, offering to train minority scientists and professionals with system design skills in underwater signal processing, communications, networking, and system design."
"1800188","Collaboration Of Midwest Professionals for Logistics Engineering Technology Education Project","DUE","ADVANCED TECH EDUCATION PROG","10/01/2018","08/14/2018","Jeremy Banta","OH","Columbus State Community College","Standard Grant","Heather Watson","09/30/2021","$268,000.00","","jbanta1@cscc.edu","550 East Spring Street","Columbus","OH","432151722","6142872639","EHR","7412","1032, 9178, SMET","$0.00","The supply chain, or logistics, industry continues to grow in the Midwest region of the United States. Jobs in this industry are also becoming more dependent on technologies such as predictive analytics, artificial intelligence, and robotics. Nearly 15,000 transportation and warehousing businesses are located across the cities of Columbus, Ohio; Dayton, Ohio; and Chicago, Illinois. The ongoing growth helps support and strengthen the logistics industry in this regional economy. As a result, there is an increasing need for logistics engineering technicians in the region. In this project, a grouping of community colleges who are leaders in the logistics field in this Midwest region will be formed. The project will be led by Columbus State Community College, Oakton Community College, and Sinclair Community College. It will seek to build career pathways in logistics engineering technology for students, encourage more students to complete degrees in this field, develop faculty experience on the latest technologies, and improve the technical skills of graduates. The goal will be to provide highly-skilled logistics engineering technicians to support the regional and national needs of the supply chain sector. <br/><br/>The project will aim to improve technician education to support the increasingly complex technology needs of the supply chain sector while connecting graduates to employment opportunities in a variety of logistics industries. This project will work with employers, industry experts, and colleges to establish an innovation network. The network of partners will identify and create educational resources for emerging skills and technologies within the sector. The existing logistics curriculum at Columbus State Community College combines technology applications with engineering systems and integrates them with supply chain operations. This curriculum will be enhanced to integrate new topics in data-driven analytics and networking systems. The adapted curriculum will also be implemented and tested at the partnering institutions. The network infrastructure will inform and regularly evaluate efforts in curriculum and career pathway development; in providing professional development material and trainings for high school and college faculty; and on the use of prior learning assessments for adult and returning learners, particularly veterans and recent graduates in need of new skills for the ever-changing logistics job market. Results will be widely disseminated through an interactive project website, through publications, and at regional and national conferences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1800186","Collaboration Of Midwest Professionals for Logistics Engineering Technology Education Project","DUE","ADVANCED TECH EDUCATION PROG","10/01/2018","08/14/2018","Robert Sompolski","IL","Oakton Community College","Standard Grant","Heather Watson","09/30/2021","$149,998.00","","somplski@oakton.edu","1600 East Golf Road","Des Plaines","IL","600161234","8473767099","EHR","7412","1032, 9178, SMET","$0.00","The supply chain, or logistics, industry continues to grow in the Midwest region of the United States. Jobs in this industry are also becoming more dependent on technologies such as predictive analytics, artificial intelligence, and robotics. Nearly 15,000 transportation and warehousing businesses are located across the cities of Columbus, Ohio; Dayton, Ohio; and Chicago, Illinois. The ongoing growth helps support and strengthen the logistics industry in this regional economy. As a result, there is an increasing need for logistics engineering technicians in the region. In this project, a grouping of community colleges who are leaders in the logistics field in this Midwest region will be formed. The project will be led by Columbus State Community College, Oakton Community College, and Sinclair Community College. It will seek to build career pathways in logistics engineering technology for students, encourage more students to complete degrees in this field, develop faculty experience on the latest technologies, and improve the technical skills of graduates. The goal will be to provide highly-skilled logistics engineering technicians to support the regional and national needs of the supply chain sector. <br/><br/>The project will aim to improve technician education to support the increasingly complex technology needs of the supply chain sector while connecting graduates to employment opportunities in a variety of logistics industries. This project will work with employers, industry experts, and colleges to establish an innovation network. The network of partners will identify and create educational resources for emerging skills and technologies within the sector. The existing logistics curriculum at Columbus State Community College combines technology applications with engineering systems and integrates them with supply chain operations. This curriculum will be enhanced to integrate new topics in data-driven analytics and networking systems. The adapted curriculum will also be implemented and tested at the partnering institutions. The network infrastructure will inform and regularly evaluate efforts in curriculum and career pathway development; in providing professional development material and trainings for high school and college faculty; and on the use of prior learning assessments for adult and returning learners, particularly veterans and recent graduates in need of new skills for the ever-changing logistics job market. Results will be widely disseminated through an interactive project website, through publications, and at regional and national conferences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1800182","Collaboration Of Midwest Professionals for Logistics Engineering Technology Education Project","DUE","ADVANCED TECH EDUCATION PROG","10/01/2018","08/14/2018","Ned Young","OH","Sinclair Community College","Standard Grant","Heather Watson","09/30/2021","$152,000.00","","ned.young@sinclair.edu","444 West Third Street","Dayton","OH","454021460","9375124573","EHR","7412","1032, 9178, SMET","$0.00","The supply chain, or logistics, industry continues to grow in the Midwest region of the United States. Jobs in this industry are also becoming more dependent on technologies such as predictive analytics, artificial intelligence, and robotics. Nearly 15,000 transportation and warehousing businesses are located across the cities of Columbus, Ohio; Dayton, Ohio; and Chicago, Illinois. The ongoing growth helps support and strengthen the logistics industry in this regional economy. As a result, there is an increasing need for logistics engineering technicians in the region. In this project, a grouping of community colleges who are leaders in the logistics field in this Midwest region will be formed. The project will be led by Columbus State Community College, Oakton Community College, and Sinclair Community College. It will seek to build career pathways in logistics engineering technology for students, encourage more students to complete degrees in this field, develop faculty experience on the latest technologies, and improve the technical skills of graduates. The goal will be to provide highly-skilled logistics engineering technicians to support the regional and national needs of the supply chain sector. <br/><br/>The project will aim to improve technician education to support the increasingly complex technology needs of the supply chain sector while connecting graduates to employment opportunities in a variety of logistics industries. This project will work with employers, industry experts, and colleges to establish an innovation network. The network of partners will identify and create educational resources for emerging skills and technologies within the sector. The existing logistics curriculum at Columbus State Community College combines technology applications with engineering systems and integrates them with supply chain operations. This curriculum will be enhanced to integrate new topics in data-driven analytics and networking systems. The adapted curriculum will also be implemented and tested at the partnering institutions. The network infrastructure will inform and regularly evaluate efforts in curriculum and career pathway development; in providing professional development material and trainings for high school and college faculty; and on the use of prior learning assessments for adult and returning learners, particularly veterans and recent graduates in need of new skills for the ever-changing logistics job market. Results will be widely disseminated through an interactive project website, through publications, and at regional and national conferences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1700535","Smart Manufacturing and Resources for Transforming the Future","DUE","ADVANCED TECH EDUCATION PROG","07/01/2017","06/06/2017","Shamus Funk","WI","Chippewa Valley Technical College","Standard Grant","Heather Watson","06/30/2020","$899,993.00","Greg Slupe, Jim Kroehn, Tim Tewalt","sfunk1@cvtc.edu","620 W Clairemont Avenue","Eau Claire","WI","547016162","7158336419","EHR","7412","1032, 9178, SMET","$0.00","Smart Manufacturing and Resources for Transforming the Future (SMART Future) is promoting STEM exploration and education while strengthening the economies of rural areas through training in new manufacturing technologies. By preparing rural high school students for careers in high-growth fields like manufacturing and information technology, SMART Future is advancing new and innovative methods for producing goods, meeting the nation's changing employment needs, and improving educational and earning opportunities for teachers and youth in rural areas.<br/><br/>Through its use of a Mobile Simulation Laboratory, SMART Future is preparing technicians for industrial automation and technology careers and increasing the capacity of rural secondary teachers to provide education in the context of the emerging Industrial Internet of Things (IIoT) and Industry 4.0. The project goals are to expand STEM opportunities and prepare technicians for manufacturing and engineering careers through applied education of IIoT and Industry 4.0 concepts; and increase the capacity of rural secondary teachers to provide instruction in industrial automation. Drawing on industry expertise, SMART Future is providing dual credit for learning STEM principles in industrial automation, including programmable logic controllers (PLCs), microcontrollers, robotics, automated processes, machine-to-machine learning, computer networking and programming, applied mathematics, engineering design, precision measurement, physics, and mathematical logic."
"1407828","Statistical Methodology and Applications to Engineering and Economics","DMS","STATISTICS","08/15/2014","06/09/2017","Tze Lai","CA","Stanford University","Continuing grant","Gabor J. Szekely","07/31/2019","$399,663.00","","lait@leland.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","MPS","1269","","$0.00","The past three years witnessed the beginning of a new era in financial markets and in the US health care system, following the health care and financial reform legislation in 2010. A long-term objective of the research is to develop innovative statistical methodologies and to combine them with advances in high-performance computing and communication networks for addressing the challenges in quantitative finance and health care in this new era. The research will lead to advances and innovations in statistical methods in biomedicine, economics and engineering, paving the way for timely applications to clinical and translational medical research, health care, homeland security, environmental change, and risk management. A broader impact of this research is the training of the next generation of scientists in academia, industry, and government, by involving graduate students in all phases of the research, and by developing new course material built around the research and its applications.<br/><br/>The research projects can be broadly divided into four areas. The first is multi-arm bandits with covariates, also called ""contextual bandits"" in machine learning, and their applications to personalized strategies in medicine and electronic business, in particular, to genomic-guided personalized cancer treatments and biomarker- guided treatments for depression in neuroscience. The second area is fault detection and surveillance in network models for manufacturing systems, for systemic risk in financial markets, for homeland security, and for environment or global change. The third area is the development of efficient adaptive particle filters in nonlinear state-space models that have far-ranging applications in engineering and economics, with robotics and stochastic adaptive control as the main focus in this research. The fourth area includes dynamic empirical Bayes modeling of joint default risk for multiple firms in credit markets, of loan loss risk in retail banking and of insurance claims, macroeconomic time series modeling and forecasting, and data analytics for health care cost and preventive management."
"1434819","Analysis and Design of Robust Control Schemes for Networks of Non-Uniform Infrastructure Responding to Aggregated User Demand","CMMI","Dynamics, Control and System D","11/01/2014","08/07/2014","Sonia Martinez","CA","University of California-San Diego","Standard Grant","Irina Dolinskaya","10/31/2018","$300,000.00","","soniamd@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","ENG","7569","030E, 031E, 034E, 9102","$0.00","As sensing and communication technologies become faster, smaller and cheaper, they become ever more integrated with common infrastructure and utilities in our world. Widely available to the public, the new technology can be leveraged to create more advanced systems where smart devices are linked with users and operators by real-time communication networks. Modern examples include traffic systems, the power grid, smart buildings, and automated factory environments. The coordination between users and operators can dramatically expand the efficiency of these networked infrastructure systems, while reducing problems of congestion and high demand. This award supports fundamental research to provide needed knowledge and techniques for the development of automatic control algorithms that can meet these goals with guaranteed performance.  The coordination of multiple users and operators is very challenging as interactions occur only locally, user/operator needs can quickly change due to unpredicted events, the potential limitations of service over periods of high demand, and the unreliability of the smart device operation. This research will bridge existing theoretical tools and develop new ones that can be used to guide the design of novel robust algorithms.  Therefore, results from this research will benefit the U.S. economy and society. This research involves several disciplines including control theory, distributed computation, optimization, and robotics. The multi-disciplinary approach will help broaden participation of underrepresented groups in research and positively impact engineering education.<br/><br/>This project's research objectives are the design of distributed coordination and re-routing algorithms for the control networked systems subject to constraints in a wide variety of scenarios. The research plan is articulated along the following thrusts: (i) The design of aggregation-based robust demand-response algorithms for load shifting: While aggregation can help achieve load-shifting objectives, it is key to understand its robustness properties with respect to noise, time-varying interactions, and delays.  (ii) The design of distributed load re-balancing and re-routing algorithms: Heterogeneous constraints can have a dramatic impact on distributed algorithm behavior, breaking the natural multi-agent interaction flow and leading to congestion. We aim to study how re-distribution can help alleviate congestion. (iii) The integration of demand-response algorithms with distributed routing and balancing algorithms. Nonlinear stability tools will be used to analyze the robustness of the algorithms by bridging existing gaps between the smooth theory of height Lyapunov functions, set-valued map theory, and contractive analysis."
"1719336","ICN-WEN: Collaborative Research: Light-Speed Networking (LSN): Refactoring the Wireless Network Stack to Dramatically Reduce Information Response Time","CNS","INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE","09/01/2017","07/21/2017","Suman Banerjee","WI","University of Wisconsin-Madison","Continuing grant","Darleen L. Fisher","08/31/2020","$626,776.00","Srinivasa Akella, Younghyun Kim","suman@cs.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","1640, 1714","021Z, 7363","$0.00","A key hurdle for next-generation mobile and wireless applications such as autonomous vehicle safety, tactile Internet, virtual/augmented reality, industrial robotics, and tele-surgery is ultra-low information response time (IRT), since these applications continue to see significant improvement in user-perceived experience all the way down to an IRT as low as a millisecond. Unfortunately, today's Internet protocol stack, despite the rather ambitious projections of emerging wireless communications standards, is unable to achieve a 1 millisecond common-case IRT in wireless environments. A fundamental bottleneck for reducing IRT is propagation delays limited by the speed of light as well as a variety of factors across the protocol stack. This project is investigating the design, implementation, and evaluation of a ""light-speed networking"" (LSN) architecture seeking to dramatically reduce IRT in wireless edge networks by incorporating an information-centric approach holistically across the different layers of the network protocol stack. This project will also develop novel curricula and dissemination materials aimed at education a new generation of workforce in information-aware networking principles are going to be the foundation of future communication networks.<br/><br/>The LSN project will enable the network to automatically migrate a remote service endpoint close to the end-user, for example, on to a nano-cloud on a virtualized base station, thereby cutting down propagation delays limited by the speed of light. LSN combines this capability with several other novel ideas including information-value-awareness: enabling different layers to leverage application-level knowledge about the value and semantics of the data; private information retrieval: enabling users to access information without revealing to the network what they are accessing; radio polymorphism: enabling intelligent use of different radios based on information value; access-point-centric security and privacy enhancements;  etc. LSN builds upon key ideas from recent next-generation Internet architecture projects including MobilityFirst and XIA."
"1813709","RI: Small: Learning Dynamics and Evolution towards Cognitive Understanding of Videos","IIS","ROBUST INTELLIGENCE","09/01/2018","08/11/2018","Chenliang Xu","NY","University of Rochester","Standard Grant","Jie Yang","08/31/2021","$449,990.00","Jiebo Luo","chenliang.xu@rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","CSE","7495","075Z, 7495, 7923","$0.00","A fundamental capability of human intelligence is being able to learn to act by watching instructional videos. Such capability is reflected in abstraction and summarization of the instructional procedures as well as in answering questions such as ""why"" and ""how"" something happened in the video. This project aims to build computational models that are able to perform well in above tasks, which require, beyond the conventional recognition of objects, actions and attributes in the scene, the higher-order inference of any relations therein. Here, the higher-order inference refers to inference that cannot be answered immediately by direct observations and thus requires stronger semantics. The developed technology will enable many applications in other fields, e.g., multimedia (video indexing and retrieval), robotics (reasoning capability of why and how questions), and healthcare (assistive devices for visually impaired people). In addition, the project will contribute to education and diversity by involving underrepresented groups in research activities, integrating research results into teaching curriculum, and conducting outreach activities to local K-12 communities. <br/><br/>The research will develop a framework to perform higher-order inference in understanding web instructional videos, such that models devised in this framework are capable of not only discovering and captioning procedures that constitute the instructional event but also answering questions such as why and how something happened. The framework is built on a video story graph that models the dynamics (the composition of actions at different scales) and evolution (the change in object states and attributes), and it supports higher-order inference upon deep learning units and incorporation of external knowledge graph in a unified framework. Methodologies to extract such video story graphs and use them to discover, caption procedures and perform question-answering will be explored. Expected outcomes of this project include: a software package for constructing and performing inference on video story graphs and incorporating external knowledge; a web-deployed system to process user-uploaded instructional videos; and a large video dataset with procedure and question-answering annotations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1265480","CAREER: The neural mechanisms underlying visual target and task switching","BCS","COGNEURO","08/01/2013","08/05/2016","Nicole Rust","PA","University of Pennsylvania","Continuing grant","Uri Hasson","07/31/2019","$497,890.00","","nrust@sas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","SBE","1699","1045, 1699","$0.00","One of the hallmarks of human intelligence is our ability to flexibly adapt our thinking and behavior based on the overall context of a situation, a trait known as ""cognitive flexibility."" Among the simplest behavioral tasks that require cognitive flexibility are visual ""target switching"" paradigms that involve viewing the same visual stimuli in the context of searching for different targets. As an extension, ""task switching"" paradigms often involve searching for a target based on one stimulus property (e.g., match the shape regardless of color) followed by searching for a different property (e.g., match the color regardless of shape). While interactions between brain areas that lie in the visual, temporal and frontal lobes are thought to play important roles in flexibly switching between targets and tasks, the specific neural mechanisms that allow for cognitive flexibility remain little-understood. Understanding these neural mechanisms has proven to be a considerable challenge, at least in part because the neural activity in the brain areas involved reflect heterogeneous and difficult-to-understand mixtures of different types of information.  With support from the National Science Foundation, Dr. Nicole Rust and colleagues will record neural signals as subjects perform target and task switching paradigms and they will then use newly-developed computational data analysis techniques to tease apart the neural mechanisms that the brain uses to flexibly switch between targets and tasks.  <br/><br/>An array of disorders including obsessive compulsive disorder and autism have been linked to deficits in the mechanisms underlying cognitive flexibility, thus developing a basic understanding of how these mechanisms function is likely to be important for developing treatments to address the disorders that arise when these mechanisms go awry. Additionally, a basic understanding of the neural mechanisms underlying cognitive flexibility has the potential to benefit the robotics and computer vision communities interested in constructing artificial systems that can flexibly switch between targets and tasks to assist humans.  Motivated by the notion that the experience of scientific discovery is one that cannot be fathomed through classroom experiences alone, the results of this project will also be incorporated into an undergraduate educational course focused on analyzing neural data.  Finally, Dr. Rust will participate in the big data effort by making the data available to support other coordinated NSF efforts that aim to make use of real data in the teaching of STEM related courses and to enable participation in discovery science by those who would otherwise have no access to such data."
"1810282","PIC: Hybrid Silicon Electronic-Photonic Integrated Neuromorphic Networks","ECCS","ELECT, PHOTONICS, & MAG DEVICE","09/01/2018","06/14/2018","Stefan Preble","NY","Rochester Institute of Tech","Standard Grant","Dominique M. Dagenais","08/31/2021","$422,733.00","Dhireesha Kudithipudi","sfpeen@rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757987","ENG","1517","094E, 095E","$0.00","Neuromorphic computing is a sub-field of artificial intelligence that implements physical architectures inspired by the learning processes in the brain.  There have been significant efforts to realize neural network architectures using electronic integrated circuit technology.  However, electronic-only hardware is not suitable for high bandwidth applications critical to a modern information world. In contrast, the internet is powered by photonic technologies (lasers, electro-optic modulator and photodetectors) because of light's high bandwidth, speed and low energy consumption. Consequently, this project aims to realize high performance neural networks that utilize light. These photonic neural networks will be integrated on a photonic chip in order to realize scalable and efficient architectures.  However, in order to build neural networks that transcend today's state-of-art, it is necessary to also leverage electronics due to the challenges surrounding photonic memory and amplification, both of which are key to realizing a general purpose neural network. This hybrid approach, where electronics and photonics would be integrated together,  enables the investigation of the broadest class of problems.  In addition to these research aims, this project is an interdisciplinary activity that will provide technical training for future science and engineering professionals.  There will be outreach activities that bring the research to  K-12, undergraduate, and graduate students. Students from underrepresented backgrounds will be actively engaged by providing lab visits with hands-on activities.  Lastly, the education initiatives of AIM Photonics Academy will be leveraged to disseminate the research in the project. Overall this project will impact the broader community with applications in autonomous systems, vision systems, information networks, cybersecurity, robotics and other high bandwidth applications.<br/><br/><br/>This project aims to address two fundamental questions, i) How can photonics maximize functionality in the compute domains?, ii) What neuromorphic algorithms can solve a broad class of problems using photonics?<br/>The overall goal of this project is to demonstrate hybrid silicon electronic-photonic integrated neuromorphic networks. The proposed paradigm leverages the power of optical interference to realize high performance neuromorphic computing networks. Photonic implementations of neural networks offer the inherent advantage that light can easily perform computational tasks that are traditionally challenging to do in electronic-only implementations  (e.g. a Fourier transform can be done optically by simply passing light through a lens). The underlying integrated photonic-electronic network proposed here utilizes a Multimode interference coupler as a neural core (Neuro-MMI) in order to realize interference between multiple inputs and outputs in a compact footprint. The principal investigators propose to realize reconfigurability of the weights in the neural network wrapped around the MMI core. The Neuro-MMI core will be integrated with optoelectronic nonlinear thresholding circuits (along with electronic memory) to realize different classes of neural networks (feed forward neural networks and recurrent neural networks).  Active Neuro-MMI's will be studied to realize on-chip learning and new learning rules will be investigated that are inherent for these topologies. Furthermore, the use of wavelength division multiplexing will be explored  to achieve  dense connectivity and parallelism in order to maximize the performance of the networks. One unique feature of the proposed hybrid photonic-electronic network is the reconfigurability to switch between feed forward and recurrent neural networks on a single chip.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1716114","Collective Dynamics of Particles at Fluid Interfaces","DMS","APPLIED MATHEMATICS","07/01/2017","06/26/2017","Michael Miksis","IL","Northwestern University","Standard Grant","Pedro Embid","06/30/2020","$480,000.00","David Chopp, Petia Vlahovska","miksis@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","MPS","1266","","$0.00","This project is concerned with an interdisciplinary and multifaceted investigation of the dynamics of particles confined to a fluid interface.  Specifically, our proposal considers surface-trapped particles on a drop in an applied flow field and seeks to determine the flow-driven particle organization. These are mathematically challenging multiphase problems with application to the study of emulsions and the development of new novel materials with designed properties.  Specific examples include emulsions with effective viscosity tunable by an electric field, the fabrication of colloidal photonic crystals, or the fabrication of ""digital colloids"" in soft robotics.  <br/><br/>The primary focus will be on investigating the dynamics of particle-laden drops at medium to low surface coverage in applied flow fields.  The PIs will develop mathematical models, analytical solutions, and accurate and efficient computational solutions of the dynamics of many particles on a moving drop interface. This is a complex free boundary problem that presents several challenges:  the dynamics of the three-phase contact line, the curvature and deformability of the interface, and the many-body hydrodynamic interactions mediated by the fluids embedding the interface.  The PIs plan to develop a multifaceted approach where analytical solutions using asymptotic methods will be sought for the dynamics of a single particle, a novel numerical approach using chimera grids and level set methods to determine the full-range dynamics of the particle-fluid system, and a point-particle method that efficiently simulates the collective dynamics of large numbers of particles."
"1734206","NRI: FND: COLLAB: Drones and the Design of Public Outdoor Spaces","IIS","National Robotics Initiative","10/01/2017","09/14/2017","Mary Cummings","NC","Duke University","Standard Grant","Ralph Wachter","09/30/2020","$450,045.00","","m.cummings@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","8013","8086","$0.00","With recent regulatory changes allowing for the commercial use of unmanned aerial vehicles, aka drones, many new opportunities are emerging for public engagement, especially in areas like filming live music events, coverage of sporting events, and creating powerful imagery of landmarks or monuments. However, these technology advancements have also led to a proliferation of hobbyist drones. As a result, there are increasing reports of illegal drones flying in these same spaces, which present a risk to people on the ground or to those commercial drones legitimately flying in the spaces. Outdoor public space managers could benefit from design guidelines and technology recommendations for systems that could detect and potentially mitigate unwanted drone incursions into their spaces while protecting both people on the ground and legitimate drones. There is a need to explore passive approaches to drone detection and mitigation for public areas that attract small to medium sized crowds, particularly those approaches that are affordable and safe.<br/><br/>Through assembling a multidisciplinary team of engineers and landscape architects, Duke University and Clemson University researchers take a systems-theoretic approach to analyzing and addressing this problem. Such a problem is multidimensional with multiple stakeholders, including venue managers, the general public, and legitimate drone operators contracted by the venues for services. Involving critical stakeholders at all points in the process, a model of those variables that interrelate in the design of passive drone detection and mitigation systems will be developed, including operating environments, physical and cost constraints, and security and aesthetic considerations. Design prototypes will be built and tested. A set of formal guidelines and a design trade space that reflects costs and capabilities for a range of passive technologies will also be developed that can be used by designers and mangers of outdoor public spaces, who will be increasingly struggling with this problem."
"1762661","Collaborative Research: Interfacial Self-healing of Nanocomposite Hydrogels","CMMI","Mechanics of Materials and Str","08/15/2018","08/09/2018","Ying Li","CT","University of Connecticut","Standard Grant","Siddiq Qidwai","07/31/2021","$233,649.00","","yingli@engr.uconn.edu","438 Whitney Road Ext.","Storrs","CT","062691133","8604863622","ENG","1630","013E, 022E, 024E, 026E, 027E, 9161, AMPP","$0.00","Self-healing polymers are synthetic materials capable of autonomously repairing damages without human intervention. They have shown great potentials for sustainable technologies in diverse engineering applications, including artificial muscles and skins, flexible electronics, soft robotics and many others. Nevertheless, the state-of-the-art design of self-healing polymers remains at the trial-and-error stage with insufficient theoretical guidance. This award supports fundamental research to elucidate the self-healing mechanics of nanocomposite hydrogels that consist of water-mediated polymer networks crosslinked by nanoparticles. The knowledge obtained from this project will provide mechanistic insights into self-healing polymers that are able to restore their functionality after damage. The research will not only promote the fundamental science of self-healing mechanics, but also advance the national health, prosperity, and welfare through further development and enhancement of soft-materials based sustainable technologies. This project will also train a diverse group of students in the areas of solid mechanics, polymer science, mechanical engineering, and high-performance computing for next-generation workforce development. The educational objectives of the project will be realized through curriculum development, undergraduate research opportunities, summer research program for high school students, research experience for K-12 teachers program, and K-12 outreach program. Special efforts will be made to involve underrepresented students in this project. <br/><br/>Despite extensive studies in the syntheses and applications of self-healing polymers, constructing the mechanistic relationship between self-healing properties and material/healing settings remains challenging. The key technical barrier is how to physically model the microstructure evolution of the polymer networks during the self-healing process. The central hypothesis of this project is that the self-healing strength of nanocomposite hydrogel is governed by the diffusion of polymer chains across the fractured interface and subsequent crosslinks formed with nanoparticles. To test this hypothesis, the project integrates molecular dynamics simulations and analytical theories to study microscopic diffusion-reaction behaviors of polymer chains during self-healing process and macroscopic interfacial strengths after self-healing. The computational and theoretical predictions will be systematically validated with experimental studies of nanocomposite hydrogels composed of several material compositions, such as particle concentration, particle size, and water fraction, and under various external healing controls, such as temperature and delaying time. The interdisciplinary effort will open promising avenues for quantitatively understanding the multiscale mechanics of self-healing polymers and providing fundamental design principles of high-performance self-healing polymers.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1331133","BSF:201229:Efficient Algorithms for Geometric Optimization","CCF","SPECIAL PROJECTS - CCF","09/01/2013","09/11/2013","Pankaj Agarwal","NC","Duke University","Standard Grant","Tracy J. Kimbrel","08/31/2019","$32,843.00","","pankaj@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","2878","2878, 7796","$0.00","This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program.  Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers.<br/><br/>This collaborative reserach project between Duke University and Tel Aviv University aims to study several topics in geometric optimization and related problems that arise in the processing of geometric data in a variety of application areas, such as sensor networks, imaging, surveillance, navigation, geographic information systems, modeling and animation, meshing, computer graphics and vision, bioinformatics, robotics and manufacturing.  Processing geometric data in these applications is challenging, because this data is typically huge, measured with uncertainty, obtained in a distributed manner (e.g., in sensor networks), or in an online manner (e.g., in streaming applications), and may involve moving points (e.g., in imaging, animation and modeling).  All these traits make the processing a rather demanding task, and call for the design of novel algorithmic techniques for handling it efficiently.  For many of these problems, exact algorithms, even polynomial in the input size, are impractical, and approximation algorithms are needed. Even then, making these algorithms depend efficiently on the error parameter is often a difficult and challenging task.<br/><br/>The project addresses the above challenges by developing general algorithmic techniques such as computing geometric summaries (including coresets and random samples), handling noisy geometric data under various probabilistic models of uncertainty, handling online data, and handling kinetic data (involving moving objects). Some of the specific problems that are targeted include shape matching, clustering, and geometric searching. Each of these topics raises interesting algorithmic questions, both theoretical and practical, and the project will address as many of them as possible."
"1629898","CI-SUSTAIN: Collaborative Research: Extending a Large Multimodal Corpus of Spontaneous Behavior for Automated Emotion Analysis","CNS","SPECIAL PROJECTS - CISE, COMPUTING RES INFRASTRUCTURE","09/01/2016","05/05/2017","Lijun Yin","NY","SUNY at Binghamton","Standard Grant","Dan Cosley","08/31/2019","$491,581.00","","lijun@cs.binghamton.edu","4400 VESTAL PKWY E","BINGHAMTON","NY","139026000","6077776136","CSE","1714, 7359","7359, 9251","$0.00","This project will extend and sustain a widely-used data infrastructure for studying human emotion, hosted at the lead investigator's university and available to the research community.  The first two versions of the dataset (BP4D and BP4D+) contain videos of people reacting to varied emotion-eliciting situations, their self-reported emotion, and expert annotations of their facial expression. Version 1, BP4D (n=41), has been used by over 100 research groups and supported a successful community competition around recognizing emotion.  The second version (BP4D+) adds participants (n = 140), thermal imaging, and measures of peripheral physiology.  The current project greatly broadens and extends this corpus to produce a new dataset (BP4D++) that enables deep-learning approaches, increases generalizability, and builds research infrastructure and community in computer and behavioral science.  The collaborators will (1) increase participant diversity; 2) add videos of pairs of people interacting to the current mix of individual and interviewer-mediated video; 3) increase the number of participants to meet the demands of recent advances in ""big data"" approaches to machine learning; and 4) expand the size and scope of annotations in the videos. They will also involve the community through an oversight and coordinating consortium that includes researchers in computer vision, biometrics, robotics, and cognitive and behavioral science. The consortium will be composed of special interest groups that focus on various aspects of the corpus, including groups responsible for completing the needed annotations, generating meta-data, and expanding the database application scope.  Having an infrastructure to support emotion recognition research matters because computer systems that interact with people (such as phone assistants or characters in virtual reality environments) will be more useful if they react appropriately to what people are doing, thinking, and feeling.  <br/><br/>The team will triple the number of participants in the combined corpora to 540.  They will develop a dyadic interaction task and capture data from 100 interacting dyads to support dynamic modeling of interpersonal influence across expressive behavior and physiology, as well as analysis of emotional synchrony.  They will increase the density of facial annotations to about 15 million frames in total, allowing the database to become sufficiently large to support deep-learning approaches to multimodal emotion detection. These annotations will be accomplished through a hybrid approach that combines expert coding using the Facial Action Coding System, automated face analysis, and crowdsourcing with expert input from the research community.  Finally, the recorded data will be augmented with a wide range of meta-data derived from 2D videos, 3D videos, thermal videos, and physiological signals.  To ensure the community is involved in sustaining the infrastructure, in addition to the governance consortium described above, the investigators will involve the community in jointly building both APIs that allow adding meta-data and annotations and tools to support the submission and evaluation of new recognition algorithms, then organizing community-wide competitions using those tools.  The research team will also reach out to new research communities around health computing, biometrics, and affective computing to widen the utility of the enhanced infrastructure, grow the community of expert annotators through training workshops, and build an educational community around the infrastructure that facilitates the development and sharing of course materials that use it.  Long-term, the infrastructure will be funded through a combination of commercial licensing and support from the lead university's system administration group."
"1629716","CI-SUSTAIN: Collaborative Research: Extending a Large Multimodal Corpus of Spontaneous Behavior for Automated Emotion Analysis","CNS","COMPUTING RES INFRASTRUCTURE","09/01/2016","07/25/2016","Jeffrey Cohn","PA","University of Pittsburgh","Standard Grant","Dan Cosley","08/31/2019","$300,955.00","","jeffcohn@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","CSE","7359","7359","$0.00","This project will extend and sustain a widely-used data infrastructure for studying human emotion, hosted at the lead investigator's university and available to the research community.  The first two versions of the dataset (BP4D and BP4D+) contain videos of people reacting to varied emotion-eliciting situations, their self-reported emotion, and expert annotations of their facial expression. Version 1, BP4D (n=41), has been used by over 100 research groups and supported a successful community competition around recognizing emotion.  The second version (BP4D+) adds participants (n = 140), thermal imaging, and measures of peripheral physiology.  The current project greatly broadens and extends this corpus to produce a new dataset (BP4D++) that enables deep-learning approaches, increases generalizability, and builds research infrastructure and community in computer and behavioral science.  The collaborators will (1) increase participant diversity; 2) add videos of pairs of people interacting to the current mix of individual and interviewer-mediated video; 3) increase the number of participants to meet the demands of recent advances in ""big data"" approaches to machine learning; and 4) expand the size and scope of annotations in the videos. They will also involve the community through an oversight and coordinating consortium that includes researchers in computer vision, biometrics, robotics, and cognitive and behavioral science. The consortium will be composed of special interest groups that focus on various aspects of the corpus, including groups responsible for completing the needed annotations, generating meta-data, and expanding the database application scope.  Having an infrastructure to support emotion recognition research matters because computer systems that interact with people (such as phone assistants or characters in virtual reality environments) will be more useful if they react appropriately to what people are doing, thinking, and feeling.  <br/><br/>The team will triple the number of participants in the combined corpora to 540.  They will develop a dyadic interaction task and capture data from 100 interacting dyads to support dynamic modeling of interpersonal influence across expressive behavior and physiology, as well as analysis of emotional synchrony.  They will increase the density of facial annotations to about 15 million frames in total, allowing the database to become sufficiently large to support deep-learning approaches to multimodal emotion detection. These annotations will be accomplished through a hybrid approach that combines expert coding using the Facial Action Coding System, automated face analysis, and crowdsourcing with expert input from the research community.  Finally, the recorded data will be augmented with a wide range of meta-data derived from 2D videos, 3D videos, thermal videos, and physiological signals.  To ensure the community is involved in sustaining the infrastructure, in addition to the governance consortium described above, the investigators will involve the community in jointly building both APIs that allow adding meta-data and annotations and tools to support the submission and evaluation of new recognition algorithms, then organizing community-wide competitions using those tools.  The research team will also reach out to new research communities around health computing, biometrics, and affective computing to widen the utility of the enhanced infrastructure, grow the community of expert annotators through training workshops, and build an educational community around the infrastructure that facilitates the development and sharing of course materials that use it.  Long-term, the infrastructure will be funded through a combination of commercial licensing and support from the lead university's system administration group."
"1762567","Collaborative Research: Interfacial Self-healing of Nanocomposite Hydrogels","CMMI","Mechanics of Materials and Str","08/15/2018","08/09/2018","Qiming Wang","CA","University of Southern California","Standard Grant","Siddiq Qidwai","07/31/2021","$270,354.00","","qimingw@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","ENG","1630","013E, 022E, 024E, 026E, 027E, 9161, AMPP","$0.00","Self-healing polymers are synthetic materials capable of autonomously repairing damages without human intervention. They have shown great potentials for sustainable technologies in diverse engineering applications, including artificial muscles and skins, flexible electronics, soft robotics and many others. Nevertheless, the state-of-the-art design of self-healing polymers remains at the trial-and-error stage with insufficient theoretical guidance. This award supports fundamental research to elucidate the self-healing mechanics of nanocomposite hydrogels that consist of water-mediated polymer networks crosslinked by nanoparticles. The knowledge obtained from this project will provide mechanistic insights into self-healing polymers that are able to restore their functionality after damage. The research will not only promote the fundamental science of self-healing mechanics, but also advance the national health, prosperity, and welfare through further development and enhancement of soft-materials based sustainable technologies. This project will also train a diverse group of students in the areas of solid mechanics, polymer science, mechanical engineering, and high-performance computing for next-generation workforce development. The educational objectives of the project will be realized through curriculum development, undergraduate research opportunities, summer research program for high school students, research experience for K-12 teachers program, and K-12 outreach program. Special efforts will be made to involve underrepresented students in this project. <br/><br/>Despite extensive studies in the syntheses and applications of self-healing polymers, constructing the mechanistic relationship between self-healing properties and material/healing settings remains challenging. The key technical barrier is how to physically model the microstructure evolution of the polymer networks during the self-healing process. The central hypothesis of this project is that the self-healing strength of nanocomposite hydrogel is governed by the diffusion of polymer chains across the fractured interface and subsequent crosslinks formed with nanoparticles. To test this hypothesis, the project integrates molecular dynamics simulations and analytical theories to study microscopic diffusion-reaction behaviors of polymer chains during self-healing process and macroscopic interfacial strengths after self-healing. The computational and theoretical predictions will be systematically validated with experimental studies of nanocomposite hydrogels composed of several material compositions, such as particle concentration, particle size, and water fraction, and under various external healing controls, such as temperature and delaying time. The interdisciplinary effort will open promising avenues for quantitatively understanding the multiscale mechanics of self-healing polymers and providing fundamental design principles of high-performance self-healing polymers.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1753387","CAREER: Hybrid protein-DNA nanostructures and devices","DMR","BIOMATERIALS PROGRAM","07/01/2018","06/19/2018","Nicholas Stephanopoulos","AZ","Arizona State University","Continuing grant","Mohan Srinivasarao","06/30/2023","$102,464.00","","nstepha1@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","MPS","7623","1045, 7237, 7573, 8614","$0.00","Non-technical Summary:<br/>One of the greatest challenges for science is to create materials that can interact with, and influence, biological systems in order to treat disease, regrow damaged tissues, or elucidate fundamental scientific mechanisms. This proposal aims to develop new methods for building these materials, relying on the smart, programmable assembly of molecules like proteins or DNA. In particular, the PI aims to develop: (1) nanofibers (similar to those in tissue) composed of DNA elements linked by proteins; (2) three-dimensional cages mimicking viruses from both protein building blocks and DNA scaffolds; (3) mechanical elements like hinges or boxes with latches that are activated by proteins. The use of proteins will allow for stability, control over structure, and interaction with cells that is not possible with DNA alone, whereas the DNA components will permit for complex designs that are difficult to make with proteins alone. The final materials will be useful as gels for stimulating cell repair, cages that can selectively target therapeutics to diseased cells, and nano-machines that can probe fundamental biological processes. The materials developed will also serve as a modular toolkit that can be used by scientists in a range of disciplines to create new materials for applications beyond biology and medicine, such as energy applications or nano-scale factories that mimic cells.<br/>In addition, the PI will develop an integrated training program for undergraduate and graduate students to introduce them to cutting-edge research in bio-nanotechnology, as well as outreach programs to middle and high school students to help demonstrate the beauty of nanotechnology and its great potential to make a difference to human health.<br/><br/><br/>Technical Summary:<br/>The goal of this proposal is to develop functional nanomaterials that combine the structural programmability of DNA nanotechnology with the functional diversity of proteins. DNA is unparalleled as a building block for complex, self-assembled structures, but these assemblies are limited to the physical and chemical properties of oligonucleotides. The PI proposes to build DNA nanostructures that incorporate proteins in controlled locations and orientations on DNA scaffolds, to serve as both structural components and functional elements, with a particular emphasis on dynamic responsiveness to stimuli such as light or temperature. Two key Research Directions will be explored, each with several synthetic targets: <br/><br/>1) The first Research Direction involves creating hybrid nanostructures integrating DNA and protein self-assembly, specifically one-dimensional nanofibers and three-dimensional cages. The nanofibers will be constructed using protein-protein interactions such as that between a nanobody and its target. The protein interaction will drive hierarchical assembly of rigid DNA elements, which can be tuned in geometry and valence to obtain branched fibers or even hydrogels. The cages will be constructed using a trimeric protein building block modified with DNA, which will be integrated with programmable DNA components to create three-dimensional polyhedra with various geometries.<br/><br/>2) The second Research Direction aims to create dynamic DNA nanostructures driven by light or heat, using stimulus-responsive proteins, specifically latches for 3D cages and hinge elements for rigid tweezers. For this purpose, photoswitchable proteins that can reversibly associate with light and thermally responsive proteins that reversibly aggregate with heat will be used as actuation elements. Both projects will require integrating proteins in controlled orientations on DNA scaffolds through site-specific bioconjugation chemistry of multiple oligonucleotide handles. For this purpose, the PI will develop novel strategies for synthesizing seamless protein-DNA hybrid materials.<br/><br/>The final materials will enable nano-devices with applications in drug delivery, sensing, catalysis, molecular robotics, and biomaterials for regenerative medicine and tissue engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1724526","CAREER: Bioinspired Adaptively Reconfigurable Material Systems  for Programmable and Autonomous Metal Ion Separations","CBET","Process Separations","01/01/2017","05/23/2018","Ximin He","CA","University of California-Los Angeles","Standard Grant","Christina Payne","06/30/2021","$517,962.00","","ximinhe@ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","ENG","1417","1045, 9102, 9251","$0.00","CAREER 1552690 - He<br/><br/>The efficient extraction of molecules from fluid mixtures is vital for applications ranging from chemical analysis in water treatment to toxic or rare metal removal and recovery. Current methods for this rely on multi-step and high energy consumption operations. Inspired by the efficiency of biological separation processes that seamlessly capture and transport selective biomolecules, this project seeks to achieve a concerted ""catch and release"" of target molecules from a liquid mixture using responsive polymer-based material systems. The innovation arises from the programmed one-step sorting with low turnaround times. The modular design of the hybrid material system is highly customizable owing to its broad choice of chemistries, tunable mechanics, and physical simplicity. This project's career development plan provides the foundation for a long-term research program in highly efficient capture and isolation of molecules in flowing fluids. Ultimately, this technology platform may lead to the next-generation in-line separation, sensing, and monitoring technologies and be translated into broader areas of smart technology, robotics, bioengineering, and other autonomous systems. A variety of integrated research and educational activities are planned to develop bioinspired engineering curriculum by integrating the research and online media at the K-12, undergraduate, and graduate levels and to increase public awareness of bioinspired technologies and their societal impacts.<br/><br/>The goal of this research is to apply the bioinspired strategy that seamlessly separates biomolecules in a single step to innovate adaptively reconfigurable material systems based on stimuli-responsive hydrogels and to realize continuous ""catch and release"" of target molecules from a liquid mixture. This research explores fundamental questions of molecular binding affinity in different chemical environments that would facilitate the discovery of new adsorbents. To assess the separation performance of the system, quantitative sorting efficiency evaluation, system robustness examination with amenability to multiple separation cycles, and optimization will be conducted. Practically, the systems encompass significant modularity and design flexibility to permit integration and upscaling for broad applications. This research integrates the disciplines of chemistry, materials, and chemical engineering. Diverse education and outreach activities are planned to promote research, education, and awareness related to bioinspired engineering and separation research fields. These include the development of a bioinspired engineering course on campus integrated with an online channel, and female undergraduate,  graduate, and K-12 students participation in the research project, using existing infrastructure in the ASU High School Summer Academy, the Fulton Undergraduate Research Initiative program, and public media."
"1842198","Networked Multi-Agent Systems: Coping with Adversarial Agents and Links","ECCS","ENERGY,POWER,ADAPTIVE SYS","07/01/2018","08/08/2018","Nitin Vaidya","DC","Georgetown University","Standard Grant","Radhakisan S. Baheti","08/31/2019","$303,663.00","","nhv@illinois.edu","37th & O St N W","Washington","DC","200571789","2026250100","ENG","7607","092E","$0.00","Networked multi-agent systems consist of a group of participants, referred to as agents,that interact over a network to collectively perform collaborative tasks. Networked multi-agent systems are useful in many application domains, including distributed robotics, sensor networks, and smart grids. Due to their many potential applications, networked multi-agent systems have been a focus of intense research activity over the past several decades. Much of the past work on networked multi-agent systems assumes that the agents, and network links over which they communicate, are both reliable. In practical multi-agent systems, some of the system components may fail or may be compromised by an adversary. Faulty agents may behave incorrectly or in an adversarial manner, and similarly, faulty or compromised network links may deliver messages incorrectly. This project addresses the design and analysis of distributed algorithms for multi-agent systems that are robust to adversarial behavior of agents and links, which may result from failures or attacks. The project focusses on two important classes of problems in multi-agent systems, namely, distributed optimization and distributed hypothesis testing. Robust solutions to these problems may be used to obtain robust solutions to other related problems in multi-agent systems. Thus, the project has the potential to yield solutions that improve robustness of practical multi-agent systems. The project scope includes design of robust algorithms, their theoretical analysis, as well as development of a software tool to evaluate these algorithms. The educational component of the project includes participation of undergraduate and graduate students in project activities, and incorporation of project research outcomes into a related graduate course.<br/><br/>The project aims to develop multi-agent algorithms that can tolerate Byzantine failures. The Byzantine fault model captures arbitrary behavior that may be exhibited by faulty or compromised agents or links. A Byzantine faulty agent may be adversarial in nature, and may behave arbitrarily. Possible misbehaviors of a faulty agent include performing computations incorrectly, and sending incorrect or inconsistent messages to other agents. Similarly, a Byzantine faulty link can result in tampering of messages sent over the link. Multi-agent algorithms that can tolerate Byzantine failures are also robust in presence of a wide range of faulty behaviors possible in a practical system. In the context of multi-agent optimization and multi-agent hypothesis testing, the project explores many research challenges, including the following: (i) identifying network properties that are necessary and sufficient to tolerate Byzantine agent or link failures, while achieving desirable properties for the distributed computation, (ii) evaluating the impact of multi-hop forwarding of messages on the multi-agent computation, (iii) mechanisms for network adaptation to improve performance, and (iv) analysis of algorithm behavior in large-scale networks.  Through the work on these issues, the project aims to develop fundamental principles that can guide the design of robust fault-tolerant algorithms for different types of distributed computations. The tools used for evaluating the algorithms include mathematical analysis as well as simulation-based experimentation."
"1760943","Establishing a Design Framework for Multi-functional composites by Leveraging Kirigami Cutting, Multi-stability, and Multi-level Optimization","CMMI","EDSE-Engineering Design and Sy","09/15/2018","08/07/2018","Suyi Li","SC","Clemson University","Standard Grant","Richard Malak","08/31/2021","$715,182.00","Oliver Myers, Georges Fadel","suyil@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","ENG","072Y","067E, 073E, 9150","$0.00","This award supports fundamental research to establish a design methodology for composite structures by taking advantage of Kirigami cutting principles and snap-through multi-stability.  Composite structures combine multiple materials to achieve desirable properties and are vital for many engineering systems. Snap-through multi-stable structures can quickly transition from one stable state to another. They can bear weight and perform other functions such as shape morphing, vibration control, and energy harvesting.  However, the current-state-of-art in multi-stable composites is limited in terms of the achievable shapes and functionalities.  This research uses Kirigami cutting principles to fundamentally expand the performance space of multi-stable composites. The design methodology synergizes with advanced layer-by-layer manufacturing technology, enabling a two-dimensional build to transform into a complex three-dimensional structure through the optimal design of fiber ply properties and Kirigami-inspired cutting patterns. This will lead to novel structural designs that offer sophisticated functionalities, such as shape reconfiguration and on-demand mechanical property programming. These structures can benefit a number of industries, including aerospace, automotive, and robotics, by enhancing system performance and sustainability.  This award will also support efforts to enhance educational activities at Clemson University and nearby communities in South Carolina. Research results will be used in existing outreach networks like Clemson EMAG!NE to inspire the public via combining engineering and the art of Kirigami paper cutting.<br/><br/>This research will, for the first time, systematically incorporate the Kirigami cutting principle in an engineering-relevant optimal design framework.  It is expected to create significant leaps in adaptive composites, Kirigami applications, and multi-level, multi-objective design optimization.  The research goals will be achieved by 1) deriving mathematical linkages between design variables and performance outputs via a new reduced-order mechanics model using F?ppl-von K?rm?n (FvK) shell theory and customized shape functions; 2) developing practical design guidelines and constraints via extensive experimental testing; and 3) deriving multi-disciplinary synthesis method based on bi-level optimization.  Results of the three tasks will be integrated into the design framework.  Throughout the course of this project, the research team will address many technical challenges with broad relevance, including the complex non-free boundaries between composite patches, fabrication uncertainties, and robustness in multi-level design optimization.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1761918","Transient Network Theory: Bridging Molecular Mechanisms to the  Viscoelasticity of Soft Polymers","CMMI","Mechanics of Materials and Str","09/01/2018","08/07/2018","Franck Vernerey","CO","University of Colorado at Boulder","Standard Grant","Siddiq Qidwai","08/31/2021","$398,937.00","","franck.vernerey@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","ENG","1630","013E, 022E, 024E, 9161, 9263, AMPP","$0.00","The ability to organize large populations of molecules into materials can open the door to making dynamic materials or soft machines, thus advancing the national health, prosperity, and welfare; and even securing the national defense by facilitating the emerging area of soft robotics. Such materials are often found in nature in the form of transient polymeric networks which are at the source of muscle contraction as well as self-healing and adaptation in biological tissues. Although similar molecular networks can be synthesized in the laboratory, their performance still lags far behind their biological counterparts; raising the need for a better theoretical understanding and experimental control. This project will provide a route to fundamentally understand how the organization and dynamics of such polymer networks can lead to a well-targeted emerging response. It will promote the progress of soft matter science by bridging the gap between our understanding of the behavior of a single molecule and that of an entire network, not only enabling a fundamental understanding of bio-polymers, but also in improving our ability to control synthetic materials. The project will also develop an educational program around the concept of ""materials of the future and bio-inspiration"" in high-schools, the enhancement of undergraduate curriculum, and dissemination of scientific knowledge through social media.<br/><br/>From a fundamental viewpoint, this project will support the development of a transient network theory that will describe, in a statistical sense, the time evolution of a transient polymer network based on molecular processes such as chain detachment, reputation, or diffusion. Going beyond phenomenological viscoelastic models, key concepts in statistical mechanics will be used to obtain a clearer connection between transient molecular interactions between many polymer chains and the time-dependent response of the network. The project brings three key contributions: (a) a new fundamental understanding of the relation between molecular processes and rheology, elasticity and energy dissipation; (b) the ability to generate new hypotheses regarding dynamic polymers and explore their macroscopic outcome in terms of growth, fracture resistance, and self-healing, and (c) a new continuum framework to describe the extreme deformation of soft materials whose behavior lies between that of solids and fluids. A computational methodology based on finite elements will be introduced to solve the research theory and used to study and characterize the viscoelastic response of synthetic and biopolymers in terms of their inner structure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1610543","Networked Multi-Agent Systems: Coping with Adversarial Agents and Links","ECCS","ENERGY,POWER,ADAPTIVE SYS","09/01/2016","08/10/2016","Nitin Vaidya","IL","University of Illinois at Urbana-Champaign","Standard Grant","Radhakisan S. Baheti","09/30/2018","$358,650.00","","nhv@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","7607","092E","$0.00","Networked multi-agent systems consist of a group of participants, referred to as agents,that interact over a network to collectively perform collaborative tasks. Networked multi-agent systems are useful in many application domains, including distributed robotics, sensor networks, and smart grids. Due to their many potential applications, networked multi-agent systems have been a focus of intense research activity over the past several decades. Much of the past work on networked multi-agent systems assumes that the agents, and network links over which they communicate, are both reliable. In practical multi-agent systems, some of the system components may fail or may be compromised by an adversary. Faulty agents may behave incorrectly or in an adversarial manner, and similarly, faulty or compromised network links may deliver messages incorrectly. This project addresses the design and analysis of distributed algorithms for multi-agent systems that are robust to adversarial behavior of agents and links, which may result from failures or attacks. The project focusses on two important classes of problems in multi-agent systems, namely, distributed optimization and distributed hypothesis testing. Robust solutions to these problems may be used to obtain robust solutions to other related problems in multi-agent systems. Thus, the project has the potential to yield solutions that improve robustness of practical multi-agent systems. The project scope includes design of robust algorithms, their theoretical analysis, as well as development of a software tool to evaluate these algorithms. The educational component of the project includes participation of undergraduate and graduate students in project activities, and incorporation of project research outcomes into a related graduate course.<br/><br/>The project aims to develop multi-agent algorithms that can tolerate Byzantine failures. The Byzantine fault model captures arbitrary behavior that may be exhibited by faulty or compromised agents or links. A Byzantine faulty agent may be adversarial in nature, and may behave arbitrarily. Possible misbehaviors of a faulty agent include performing computations incorrectly, and sending incorrect or inconsistent messages to other agents. Similarly, a Byzantine faulty link can result in tampering of messages sent over the link. Multi-agent algorithms that can tolerate Byzantine failures are also robust in presence of a wide range of faulty behaviors possible in a practical system. In the context of multi-agent optimization and multi-agent hypothesis testing, the project explores many research challenges, including the following: (i) identifying network properties that are necessary and sufficient to tolerate Byzantine agent or link failures, while achieving desirable properties for the distributed computation, (ii) evaluating the impact of multi-hop forwarding of messages on the multi-agent computation, (iii) mechanisms for network adaptation to improve performance, and (iv) analysis of algorithm behavior in large-scale networks.  Through the work on these issues, the project aims to develop fundamental principles that can guide the design of robust fault-tolerant algorithms for different types of distributed computations. The tools used for evaluating the algorithms include mathematical analysis as well as simulation-based experimentation."
"1617917","RI: Small: Texture2Text: Rich Language-Based Understanding of Textures for Recognition and Synthesis","IIS","ROBUST INTELLIGENCE, Unallocated Program Costs","09/01/2016","09/22/2016","Subhransu Maji","MA","University of Massachusetts Amherst","Continuing grant","Jie Yang","08/31/2019","$450,000.00","","smaji@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","7495, 9199","7495, 7923","$0.00","This project develops techniques at the interface of vision and natural language to understand and synthesize textures. For example, given a texture the project develops techniques that provide a description of the pattern (e.g., ""the surface is slippery"", ""red polka-dots on a white background""). Techniques for semantic understanding of textures benefit a large number of applications ranging from robotics where understanding material properties of surfaces is key to interaction, to analysis of various forms of imagery for meteorology, oceanography, conservation, geology, and forestry. In addition, the project develops techniques that allow modification and synthesis of textures based on natural language descriptions (e.g., ""make the wallpaper more zig-zagged"", ""create a honeycombed pattern""), enabling new human-centric tools for creating textures. In addition to the numerous applications enabled by this project, the broader impacts of the work include: the development of new benchmarks and software for computer vision and language communities, undergraduate research and outreach, and collaboration with researchers and citizen scientists in areas of conservation.<br/><br/>This research maps visual textures to natural language descriptions and vice versa. The research advances computer vision by providing texture representations that are robust to realistic imaging conditions, clutter, and occlusions in natural scenes; content retrieval by providing new ways to search and retrieve textures using descriptions; and image manipulation by providing new ways to create and modify textures using descriptions. The main technical contributions of the project are: (1) principled architectures that combine aspects of texture models with deep learning to enable end-to-end learning of texture representations; (2) techniques for understanding the properties of these representations through visualizations; (3) a large-scale benchmark to evaluate techniques for language-based texture understanding; (4) new models for texture captioning; (5) applications of texture representations for fine-grained recognition and semantic segmentation; and (6) techniques for retrieving and creating textures using natural language descriptions."
"1514406","CSR:Medium:Collaborative Research: SparseKaffe: high-performance, auto-tuned, energy-aware algorithms for sparse direct methods on modern heterogeneous architectures","CNS","Computer Systems Research (CSR","09/01/2015","09/01/2017","Timothy Davis","TX","Texas A&M Engineering Experiment Station","Continuing grant","M. Mimi McClure","08/31/2019","$400,000.00","","davis@tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","CSE","7354","7924","$0.00","The use of sparse direct methods in computational science is ubiquitous. Direct methods can be used to find solutions to many numerical algebra applications, including sparse linear systems, sparse linear least squares, and eigenvalue problems; consequently they form the backbone of a broad spectrum of large scale applications.  In the widely used and actively growing University of Florida Sparse Matrix Collection, there are problems from structural engineering, computational fluid dynamics (CFD), computer graphics/vision, robotics/kinematics, theoretical and quantum chemistry, power networks, social networks, document networks, among others.<br/> <br/>The SparseKaffe project team will develop algorithms and software for high-performance parallel sparse direct methods with irregular and hierarchical structure that can exploit clusters of Hybrid Multicore Processors to achieve orders of magnitude gains in computational performance, while also paying careful attention to the energy requirements.  This requires the development of novel and innovative algorithms for scheduling, energy minimization, and memory management; development of novel user-guided autotuning algorithms that exploit different hardware characteristics; and designing a common infrastructure for creating auto-tuned software.<br/> <br/>The use of sparse direct methods is extensive, with many of the relevant science and engineering application areas being pushed to run at ever higher scales.  The team expects SparseKaffe solvers to be able deliver not only high performance to the applications that use them, but also the energy efficiency that they will increasingly demand. The team will also create a course, and a corresponding set of course modules, to teach students how to develop algorithms and software that deliver orders of magnitude gains in performance on clusters of hybrid multicore processors."
"1832282","Building Capacity: Institute for Interdisciplinary Science:  Preparing Students for the 4th Industrial Revolution","DUE","HSI-Hispanic Serving Instituti","10/01/2018","08/07/2018","Andrea Holgado","TX","Saint Edward's University","Standard Grant","Ellen Carpenter","09/30/2023","$1,499,950.00","Charles Hauser, Laura J Baker, Paul Walter, Raychelle Burks","aholgado@stedwards.edu","3001 South Congress Ave","Austin","TX","787046489","5124442621","EHR","077Y","8209, 9178","$0.00","The Improving Undergraduate STEM Education: Hispanic-Serving Institutions Program (HSI Program) aims to enhance undergraduate STEM education and build capacity at HSIs. Projects supported by the HSI program will also generate new knowledge about how to achieve these aims. This project at St. Edward's University in Austin, Texas aims to create the Institute for Interdisciplinary Science.  The Institute will support student workforce training, cross-sector cooperation, and interdisciplinary activities that can prepare faculty and students for opportunities in the 4th Industrial Revolution.  This revolution is predicted to produce a virtually-connected world in which digital, physical, and biological domains are intertwined.  It is a world of smart homes, cloud computing, big data analytics, e-commerce, robotics, and artificial intelligence. As the 4th Industrial Revolution unfolds, collaborations between industry and higher education become critical to ensure that graduates have the knowledge and skills to be successful in the new workplace. The Institute will facilitate these collaborations by developing mutually beneficial industry-academia partnerships, providing professional development and research opportunities, and facilitating networking for exchange of new directions and ideas. The Institute's partnerships with companies will offer summer internships, which can provide economic support and encouragement to students pursuing STEM degrees, and support eventual entry into STEM careers.  In turn, students will contribute to research and development in the digital era, furthering the objectives of the companies where they work.  This project has the potential to serve as a model for other institutions, especially HSIs and other Minority-Serving Institutions (MSIs), to develop programs with similar goals, thus broadening participation and increasing diversity in the STEM workforce.<br/><br/>This project will support efforts of the School of Natural Sciences at St. Edward's University to build capacity in interdisciplinary sciences, informatics, and emerging technologies and to increase students' readiness for the 4th Industrial Revolution. The Institute aims to establish an educational and professional framework that will facilitate cross-sector partnerships and interdisciplinary collaborations. The Institute will: (i) coordinate on-campus interdisciplinary seminars and experiential learning events that will challenge faculty and students to explore complicated problems with cross-disciplinary approaches; (ii) organize cross-sector cooperative agreements with public and private entities around the Austin, Texas area and beyond; (iii) expose STEM majors to postgraduate opportunities by connecting them with employers and graduate programs through guaranteed internships; (iv) finance faculty and student professional development by offering awards to faculty and micro-credentialing scholarships to students; and (v) catalyze faculty advancement, interdisciplinary collaborations, and innovative research by offering research opportunity awards.   The project's research questions will focus on effects of the interventions on student persistence and on whether faculty professional development grants and research opportunity awards are a means to enhance student success.  Together, these activities are designed to improve student access and success in the emerging 4th Industrial Revolution.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1730574","Collaborative Research: Computational Photo-Scatterography: Unraveling Scattered Photons for Bio-Imaging","IIS","ROBUST INTELLIGENCE, EXPERIMENTAL EXPEDITIONS","03/01/2018","08/06/2018","Ashutosh Sabharwal","TX","William Marsh Rice University","Continuing grant","Jie Yang","02/28/2023","$1,949,348.00","Rebecca Richards-Kortum, Richard Baraniuk, Lin Zhong, Ashok Veeraraghavan","ashu@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","CSE","7495, 7723","7723, 9251","$0.00","Much of the success of today's healthcare is due to rapid advances in our ability to collect and analyze high-resolution data about the human body. However, current methods to achieve cellular resolution are invasive (e.g., blood test or tissue biopsy), and non-invasive imaging modalities do not achieve cellular resolution. The principal goal of this Expeditions project is to develop computational imaging systems for non-invasive bio-imaging, deep beneath the skin, and at cellular-level resolutions. This project has the potential to fundamentally impact healthcare and medicine, by enabling live views of cross sections of human anatomy, simply by pointing a camera at any part of the body. This would put individual users at the center of their healthcare experience and make them true partners in their healthcare delivery. The health imaging devices that result from this project will act as an important pillar in the personalized medicine revolution. This research expedition also holds the potential to launch new healthcare paradigms for chronic disease management, pediatrics, low-resource healthcare, and disaster medical care. Beyond healthcare, making progress on the problem of cellular-scale deep-tissue imaging using light will push the frontiers of the fundamental problem of inverse scattering, which impacts numerous areas of science and engineering. The order of magnitude advances made in inverse scattering and imaging through scattering media will have significant cross-cutting applications in diverse areas such as basic science, consumer imaging, automotive navigation, robotics, surveillance, atmospheric science, and material science. Finally, projects with a single, easy-to-appreciate, and high-impact goal have the potential to inspire the next generation of scientists, attract diverse set of students driven by humanitarian and social causes, and become a platform for inclusion and innovation.<br/><br/>The overarching goal of this project is to develop, test, and validate new computational imaging systems, to non-invasively image below the skin at tunable depths, in highly portable form-factors such as wearables or point-of-care devices. The main challenge is that light scatters as it travels through the human body, and in this process, the spatial information from different points within the body gets mixed up. A new concept, Computational Photo-Scatterography (CPS), is being applied in this project in order to computationally unravel the scattered photons in an imaging system, and allow creation of sharp images and accurate inferences. Recognizing that the brute-force complexity of unraveling scattered photons is prohibitively high, the project uses a computational co-design framework that leverages advances by team members from multiple domains: programmable illumination and optics, image sensors, machine learning, inverse graphics, and hybrid analog-digital computing.  The project will use machine learning (ML) instead of physics-based de-scattering to speed up the solution of the underlying inverse problem. A combination of physics-based inverse graphics algorithms, and ML algorithms combining deep learning and generative modeling will be used to estimate tissue scattering parameters -  motion due to blood flow induces time-variation in tissue parameters, which makes solving the inverse scattering problem more difficult. The project will use ML to create fast but approximate estimators, which will serve as accelerators for inverse scattering. The development of new sensors, able to capture the data necessary to reconstruct the structure of the tissue deep below the skin, constitutes the most important contribution of the project. These systems and algorithms will have the potential to break the current resolution limits of noninvasive bio-imaging by nearly two orders of magnitude, enabling cellular-level imaging at depths far beyond currently possible.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1532035","MRI:  Offshore Earthquake Monitoring at Subduction Zones Using Autonomous Underwater Vehicles and High-Speed Optical Telemetry For Data Retrieval","OCE","MAJOR RESEARCH INSTRUMENTATION, OCEAN TECH & INTERDISC COORDIN","08/15/2015","08/11/2015","John Collins","MA","Woods Hole Oceanographic Institution","Standard Grant","Kandace S. Binkley","07/31/2019","$923,217.00","Jeffrey McGuire, Michael Purcell, Jonathan Ware, Norman Farr","jcollins@whoi.edu","183 OYSTER POND ROAD","WOODS HOLE","MA","025431041","5082893542","GEO","1189, 1680","","$0.00","The earth's subduction zones, where one tectonic plate overrides another, are the sites of the planet's largest and most dangerous earthquakes. Recent examples are the 2004 magnitude 9.1 Sumatra and the 2010 magnitude 9 Tohoku, Japan earthquakes. In addition to massive destruction brought about by ground shaking, both of these earthquakes generated devastating tsunamis. These events are a reminder that fault motion in our planet's largest earthquakes happens offshore under the continental shelf, a region that is challenging to monitor. The scarcity of seismic instrumentation in the source regions of these great earthquakes has limited the seismological community's ability to answer fundamental scientific questions and to evaluate hazards in real-time. Sustained offshore monitoring of subduction zones would not only lead to improved understanding of these faults but also potentially allow the identification of increased short-term risk. Extensive foreshock sequences located far offshore preceded both the 2010 Tohoku event and the recent 2014 magnitude 9 Pisagua Chile earthquake. These sequences demonstrated that there are detectable time periods on the scale of weeks when subduction zones are more likely to produce a large rupture. To fully understand this basic fault behavior and possibly utilize an understanding of it to reduce risk, rapid access to high quality seismic data from offshore directly above the great earthquakes is needed. <br/> <br/>The seismological community routinely deploys seismographs offshore, but data access requires ship-based instrument recovery, a lengthy and expensive task that may not be possible or desirable during a potential foreshock sequence. Seismology is a fast moving science: earthquakes are detected within seconds, magnitude estimates are tweeted within minutes, fault planes are determined within hours, and research articles are often submitted within weeks of a major earthquake.  The full potential of offshore seismic data can only be realized if these data are rapidly ingested into data centers. Recent advances at Woods Hole Oceanographic Institution in optical telemetry and marine robotics, coupled with the availability of commercial off-the-shelf low-power seismic sensors, data loggers and atomic clocks offer the capability for multi-year deployments of arrays of ocean-bottom seismographs (OBS) that are capable of delivering high-frequency, accurately-timed seismic data to shore with data latencies of hours to days without OBS recovery. This project will develop such a system by integrating a WHOI-designed optical modem capable of telemetry rates of 20 Mbits/second with an OBS and with a long-range (up to 286 nautical miles) REMUS Autonomous Underwater Vehicle (AUV). These proven rates allow telemetry of a week of high-rate (100 Hz) seismic data on 4 channels (ground motion and pressure) in minutes (or a year of data in less than 2 hours). Moreover, accurate timing is critical for earthquake location but OBS lack the benefit of GPS timing. The optical link will also allow measurement of the offset of the OBS clock relative to a GPS-synchronized time signal carried by the AUV to a precision of ~1 microsecond. These technologies will make possible multi-year deployments of OBS arrays with on-demand data offload and clock-check without the need for annual recovery/re-deployment cruises, saving hundreds of thousands of dollars per experiment. This capability will be particularly suitable for the dense near-shore arrays needed to monitor subduction zones."
"1822169","Planning IUCRC Arizona State University: Center for Networked Embedded, Smart and Trusted Things NESTT","CNS","INDUSTRY/UNIV COOP RES CENTERS","08/01/2018","08/04/2018","Sarma Vrudhula","AZ","Arizona State University","Standard Grant","Dmitri Perkins","07/31/2019","$14,999.00","","vrudhula@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","5761","5761","$0.00","Arizona State University will collaborate with The University of Arizona, University of Southern California, Southern Illinois University Carbondale and the University of Connecticut to plan for the formation of a new Industry University Cooperative Research Center (IUCRC), called Center for Networked Embedded, Smart and Trusted Things (NESTT).  Companies from a wide spectrum of industries will be recruited and will work jointly with faculty to create a portfolio of industry-ranked, multi-disciplinary research projects to develop innovative solutions to fundamental technological and societal challenges posed by Internet of Things (IoT). The outcome will be a proposal to establish NESTT as an IUCRC. <br/><br/>ASU will work with its partners to organize workshops involving industry leaders and academic researchers to draft the research agenda for NESTT, aimed at accelerating IoT technology development and transfer to industry, and make opportunities from the IoT equitable, safe and secure for all. ASU expertise will include edge and Fog computing; safe and secure cyber-physical systems; machine learning, data analytics; trustworthy, networked embedded systems; robotics and industrial IoT; smart cities and transportation systems; sensors and wearable electronics; IoT governance, technology-related law and ethics, and business models. NESTT at ASU will further the participation of underrepresented students in STEM disciplines.  <br/><br/>The IoT will become the foundational technology for every major industry.  NESTT?s technological innovations and holistic multi-disciplinary design will lower the barriers to the adoption IoT technologies which will accelerate the delivery of significant economic, societal and environmental returns. The enormous wealth of data generated from such IoT systems will also lead to new discoveries and inventions in many scientific disciplines as scientific communities further embrace data-driven research.  The planning for NESTT will include working with industry partners to develop innovative ways for recruiting (in industry and academia) underrepresented students in STEM disciplines. <br/><br/>The agenda and documentation of activities for the NESTT IUCRC planning meetings will be made available on ASU's website for the Center for Embedded Systems (https://embedded.asu.edu ). It will be maintained until the establishment of NESTT, and then merged with the NESTT site.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1811941","Mapping Class Groups and Polynomials","DMS","TOPOLOGY","08/01/2018","08/03/2018","Dan Margalit","GA","Georgia Tech Research Corporation","Standard Grant","Christopher W. Stark","07/31/2021","$202,999.00","","margalit@math.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","MPS","1267","","$0.00","The main goal of this project is to study surfaces and their symmetries.  A surface is a two-dimensional space, in other words, a two-dimensional version of the world we live in.  Surfaces come in many shapes (for instance the surface of a ball is different from the surface of a doughnut) and they arise in many varied contexts, from physics to robotics to data analysis to quantum field theory.  The symmetries of a surface form a beautiful and rich theory that has been the focus of intense study over the past century.  The close connection between those symmetries and hyperbolic geometry facilitates the investigation of some questions that are not obviously geometric, such as algorithms for working with these groups.<br/><br/>The mapping class group of a surface is the group of homotopy classes of orientation-preserving homeomorphisms of the surface.  Among other things, the mapping class group encodes the outer automorphism group of the surface fundamental group, the (orbifold) fundamental group of the moduli space of the surface, and the isomorphism types of surface bundles over arbitrary spaces.  The mapping class group also has connections to many, many areas of mathematics, including dynamics, group theory, number theory, quantum field theory, representation theory, and algebraic geometry, just to name a few. Goals of this research program include these: (1) Establish a quadratic-time algorithm for the conjugacy problem in the mapping class group.  Work done under prior NSF support developed a quadratic-time algorithm for the Nielsen-Thurston type of a mapping class, and an extension of that theory is expected to give similar speed for the conjugacy problem. (2) Understand polynomials from the point of view of mapping class groups, including a new approach to the question of which branched covers of surfaces come from polynomials. (3) Describe the structure of an arbitrary normal subgroup of the mapping class group.  For instance, descriptions are available of the normal closures of many types of elements, and new examples have been found of finitely generated right-angled Artin subgroups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1755701","CRII: RI: Learning with Low-Quality Visual Data: Handling Both Passive and Active Degradations","IIS","ROBUST INTELLIGENCE","08/15/2018","08/03/2018","Zhangyang Wang","TX","Texas A&M Engineering Experiment Station","Standard Grant","Jie Yang","07/31/2020","$173,043.00","","atlaswang@tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","CSE","7495","7495, 8228","$0.00","This project is focused on effectively and robustly exploiting low-quality (LQ) visual data for computer vision tasks. While most current computer vision systems are designed for high-quality visual data, collected from ""clear"" environments where subjects are well observable without significant attenuation or alteration, a dependable vision system must reckon with the entire spectrum of degradations from unconstrained environments. With various degradations arising from the visual data acquisition and processing pipeline, the ubiquitous LQ visual data can dramatically deteriorate the model performance in practice. The project outcome can broadly benefit a variety of real-world applications, such as video surveillance, autonomous/assisted driving, robotics and medical image analysis, where LQ visual data has constituted major performance and reliability bottlenecks. <br/><br/>This research categorizes common degradations into the two types: ""passive degradations"" that are caused by uncontrollable environment factors (such as bad weather and low light); and ""active degradations"" that are intentionally introduced in a controllable way to meet certain budget requirements (such as lossy compression). The project will mainly addresses two important technical questions: i) how to overcome passive degradations and achieve more robust high-level task performance on LQ video data, using end-to-end deep learning models; and ii) how to properly introduce and control active degradations to generate the desired form of LQ data, that both satisfies certain budget requirements and maintains the target task utility, using deep adversarial learning models. The resulting new techniques are to be verified on application examples such as video recognition, video annotation, video compression, and de-identified video data sharing for recognition purpose.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1458840","Bilateral BBSRC-NSF/BIO: Collaborative Research: ABI Development: Seamless Integration of Neuroscience Models and Tools with HPC - Easy Path to Supercomputing for Neuroscience","DBI","ADVANCES IN BIO INFORMATICS, CYBERINFRASTRUCTURE, CROSS-EF ACTIVITIES","08/01/2015","07/23/2015","Amitava Majumdar","CA","University of California-San Diego","Standard Grant","Peter H. McCartney","07/31/2019","$774,000.00","Subhashini Sivagnanam","majumdar@sdsc.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","BIO","1165, 7231, 7275","8089, 8091","$0.00","This project is a collaboration between the University of California San Diego and Yale University to develop a science gateway for the computational neuroscience community. A gateway  such as this helps  improve our understanding of how the brain works by making it easier for neuroscientists to use complex digital models of brain cells and circuits in their research. Powerful software has been developed for building and using models, and on-line resources such as Open Source Brain (OSB), ModelDB, Neuroscience Information Framework (NIF), and OpenWorm have been created to help neuroscientists find existing models, collaborate in developing new ones, and share the results of their work with others. However, models are becoming too complex for the computer hardware that is available to most neuroscientists, resulting in a critical need to use high performance computing resources (HPC). This work extends an existing Neuroscience Gateway (NSG), which was developed with support from NSF to eliminate or reduce many of the technical and administrative difficulties that previously limited neuroscientists' access to HPC (http://www.nsgportal.org/). That said, NSG users must still log in, upload models, launch simulations, and download results--a process that involves many time-consuming, error-prone steps. The expanded NSG-R will eliminate these steps by enabling on-demand, automated communication between itself and familiar working environments including resources like OSB and others mentioned above, and even with neural simulation software running on neuroscientists' own laptop and desktop computers. <br/><br/>This seamless access to HPC is implemented in NSG-R by a software infrastructure that uses REpresentational State Transfer (""REST"", the R in NSG-R). NSG-R utilizes set of web services which expose the capabilities of NSG for access via publicly available application programmer interfaces. This will allow users of neuroscience resources such as OSB, ModelDB, NIF and OpenWorm to readily access HPC from their respective websites via NSG-R. This enhances the usefulness of NSG-R, other neuroscience resources like OSB, and widely used neural simulators such as NEURON, GENESIS, PyNN, NEST, Brian and MOOSE. It also results in greater research productivity and enables wider use of large scale computational modeling by scientists and students. NSG-R will accelerate progress in brain science, and have far-reaching beneficial effects on related fields such as robotics and engineering of adaptive and learning systems. It will widen opportunities for educational and career advancement in neuroscience and engineering. Furthermore, by removing barriers that traditionally have limited access to HPC, NSG-R levels the playing field for all students and researchers regardless of their institutional affiliation. NSG-R, a free and open neuroscience gateway infrastructure, will naturally be a ready entry point for students and researchers from historically underrepresented schools and colleges. NSG-R workshops will be hosted at minority serving institutions (MSI) and opportunities for students to do internships with the NSG-R team at the University of California San Diego will be provided."
"1624497","Phase II I/UCRC Florida Atlantic University Site: Center for Health Organization Transformation.","IIP","INDUSTRY/UNIV COOP RES CENTERS","07/15/2016","07/06/2016","Ankur Agarwal","FL","Florida Atlantic University","Continuing grant","Prakash Balan","06/30/2019","$200,000.00","Hanqi Zhuang, Ravi Behara, Gulcin Gumus, Lynne Dunphy","ankur@cse.fau.edu","777 GLADES RD","BOCA RATON","FL","334316424","5612970777","ENG","5761","5761, 8042, 9102","$0.00","Phase II I/UCRC Florida Atlantic University Site: Center for Health Organization Transformation<br/><br/>The proposal requests Phase II funding for the Florida Atlantic University (FAU) to establish a site for the Texas A&M University led Center for Health Organization Transformation (CHOT). The research agenda proposed by FAU site coincides with the most expansive changes in the healthcare industry in the U.S. Recent changes in healthcare system have introduced a series of changes in the healthcare industry, including the creation of new healthcare organizations such as Accountable Care Organizations (ACOs) and new programs to improve healthcare quality, safety, and efficiency through the promotion of healthcare information technology. There is also an increased focus on disease prevention and wellness/health promotion. These changes necessitate new research on healthcare processes, patient centered healthcare delivery, and alternative payment models. The FAU site will build upon the already established CHOT partnerships and provide further complementary expertise. FAU?s proposed site will complement existing CHOT strengths by contributing expertise from the domains of engineering, business, medicine and nursing. The FAU site offers an interdisciplinary team of researchers to conduct research in the areas of (1) patient centered care delivery (e.g. patient satisfaction, community health, care coordination, wellness and preventative care and transition of care, (2) healthcare information technology (e.g., clinical decision support systems, health information systems, big data analytics, health applications, home health solutions), (3) medical technology (e.g., medical devices, user-centered health devices, healthcare digital infrastructure, sensors and robotics in healthcare), and (4) healthcare delivery systems (e.g., economic and policy evaluation, alternative payments, population health, vulnerable populations). The FAU site will create synergies with existing CHOT sites and attract additional industry partners, expanding CHOT?s collaborations between academic research and health-industry leaders.<br/><br/>The FAU site broadens participation of underrepresented groups in several ways. FAU has a large Hispanic population with more than 48% of undergraduate students currently enrolled in FAU?s College of Engineering and Computer Science (CECS) are from underrepresented populations. The project team will actively engage students in research that enable research performed by the graduate and undergraduate students to be shared with other students; the Center will expand opportunities of mentoring and graduating students from multiple disciplines such as engineering, nursing and business from under-represented populations at the BS, MS, and PhD levels."
"1622515","SCH: INT: Collaborative Research: Computer Guided Laparoscopy Training","IIS","Smart and Connected Health","08/01/2016","08/01/2016","Henry Fuchs","NC","University of North Carolina at Chapel Hill","Standard Grant","Wendy Nilsen","07/31/2020","$769,382.00","","fuchs@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","8018","8018, 8062","$0.00","IIS-1622589 SCH: INT: Collaborative Research: Computer Guided Laparoscopy Training<br/><br/><br/>Laparoscopic surgery, when performed by a well-trained surgeon, is a remarkably effective procedure that minimizes complications associated with open incisions, blood loss and post-operative pain. It also reduces recovery time. However, the procedure is more challenging than conventional surgery due to restricted vision, hand-eye coordination problems, limited working space, and lack of tactile sensation. Therefore, effective training and guidance methods are needed to minimize the potential risks inherent in such procedures. The goal of this project is to develop and validate techniques for computer-guided laparoscopic surgical training in a simulated, non-patient based environment. A computer-aided surgical trainer (CAST) will physically guide trainees' instruments during surgical skills practice sessions by utilizing assistive force with augmented reality displays. Guided training will be validated through a pilot experimental study, in which the expertise of computer-guided trainees will be compared to that of instructor-guided trainees. Data such as the time it takes a trainee to execute a particular surgical task, how accurate he or she is, etc., will be collected to analyze task performance precisely and objectively. New scientific methods for motion trajectory planning and path following using assistive force and augmented reality techniques will result from this work. It is anticipated that computer-guided practice will speed up learning and reinforce appropriate techniques, ultimately, leading to better surgical outcomes and improved patient safety. The CAST system should serve as a sophisticated, yet still low-cost, training solution for fundamental medical skills training.  <br/><br/>The specific objectives are a) to refine and implement a memory- and time-efficient hybrid offline-online optimal path planner for computer-guided training of basic laparoscopic skills. In this task, collision-free trajectory planning methods (such as those used in robotics) will be generated by incorporating offline-online hybrid techniques with memory and computational time efficient path repository. Thus, basic laparoscopic tasks can be planned and guided automatically, using haptic force and augmented reality visualization; b) to design and implement an intelligent, adaptive guidance controller for surgical space navigation, where a fuzzy logic and machine learning-based methods will be developed that will take into account trainees' skill levels so that optimal amount of training assistance can be provided in mastering surgical tasks; c) to design and implement visual guidance techniques through augmented reality overlays that provide 'navigational' cues, supplementing force-based control of surgical instruments; and d) to validate guided training through a pilot study. In this task, trainees' performance using computer guidance methods will be compared, using statistical analysis, to that of unguided trainees. The principal investigators will aim to increase the participation of undergraduate students, and in particular of underrepresented groups, through collaboration with the well-established programs at both PIs'  institutions and through sponsorship of senior projects and independent study courses."
"1534745","SBIR Phase II:  Three-Dimensional Computational Optical Imaging Sensor","IIP","SMALL BUSINESS PHASE II","09/15/2015","08/03/2018","Anurag Agrawal","CO","Double Helix LLC","Standard Grant","Muralidharan S. Nair","06/30/2019","$941,437.00","","anurag@doublehelixoptics.com","1815 BLUEBELL AVE","BOULDER","CO","803028021","3035887769","ENG","5373","1185, 165E, 5373, 8035, 8240, 9139, HPCC","$0.00","The broader impact/commercial potential of this project stems from the possibility of<br/>obtaining real-time precise 3D depth information using a miniature robust sensor system<br/>opening up a myriad of opportunities for commercial application. Imaging sensors are<br/>now widespread and inexpensive, as is computing power, already an integral part of<br/>most cameras. The 3D imaging sensor to be developed enables disruptive applications<br/>for manufacturing, robotics, human-machine interfaces, unmanned aerial vehicles, and<br/>emerging 3D scanners.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project is focused on the<br/>design, development, and testing of a miniature, robust, low-cost optical imaging sensor<br/>system capable of acquiring three-dimensional (3D) information from a scene with high<br/>precision and accuracy, overcoming current state-of-the-art technologies. The sensor<br/>provides, from a single shot, an image and a depth map; associating each object<br/>feature with its precise 3D location. With the advances in sensing technology, 3D<br/>information is increasingly incorporated into real-world applications?from<br/>manufacturing to entertainment and security. The proposed sensor provides<br/>improvements in depth resolution while being fast, compact, lightweight, and amenable<br/>for mass production at low cost."
"1539070","RII Track-2 FEC: Unmanned Aircraft System for Atmospheric Physics","OIA","EPSCoR Research Infrastructure","08/01/2015","09/14/2017","Jamey Jacob","OK","Oklahoma State University","Cooperative Agreement","Timothy VanReken","07/31/2019","$5,995,869.00","Suzanne Smith, Phillip Chilson, Adam Houston","jdjacob@okstate.edu","101 WHITEHURST HALL","Stillwater","OK","740781011","4057449995","O/D","7217","9150","$0.00","Non-technical description<br/>This Research Infrastructure Improvement Track-2 Focused EPSCoR* Collaboration (RII Track-2 FEC) involves researchers from three jurisdictions: Oklahoma (OK), Nebraska (NE), and Kentucky (KY). The research team will study atmospheric physics using small unmanned airborne systems (UAS). Oklahoma State University, the project lead, is collaborating with the University of Oklahoma, the University of Nebraska, and the University of Kentucky. The interdisciplinary project team includes researchers with expertise in robotics, autonomous control, unmanned aircraft systems, atmospheric physics, and numerical weather prediction. Education, outreach, and workforce development activities include public education about UAS technology and its policy implications, educational workshops on locally specific applications of UAS technology, and rapid dissemination tools for communicating and responding to severe weather threats and hazards. The project will support interdisciplinary collaborations among early career faculty in the three jurisdictions.<br/>  <br/>Technical description<br/>This RII Track-2 FEC collaborative research team will develop and test easily-deployable UAS-based remote sensing systems to characterize the Earth?s lower atmospheric boundary layer. Research topics include meteorological convection, storm-scale microphysics, airborne sensing of soil hydrology, infrasonic sensing of environmental phenomena, and local-scale temporal and spatial climate variation. The research team will also investigate cooperative control of UAS formations, spatially distributed data from moving sensor platforms, and heterogeneous autonomous systems. Expected outcomes from this project include complete UAS system packages suitable for measuring wind, atmospheric chemistry, soil moisture, and thermodynamic parameters. <br/><br/>*Experimental Program to Stimulate Competitive Research"
"1421521","RI: Small: Recovering Object 3D Shape and Material from Isolated Images","IIS","ROBUST INTELLIGENCE","08/01/2014","08/31/2015","Derek Hoiem","IL","University of Illinois at Urbana-Champaign","Continuing grant","Jie Yang","07/31/2019","$476,569.00","David Forsyth","dhoiem@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","7495","7495, 7923","$0.00","This project improves a computer's ability to interpret the shape and material of objects from visual sensors.  The research hypothesizes that full 3D object shape can be estimated by matching visual features from an observed object to an object of known shape from a dataset, transferring the known shape, and deforming the 3D shape to better account for spatial correspondences of matched features.  The research represents materials at multiple scales, separately encoding little bumps and grooves from the patterns of material categories.  Because image properties arise from the combination of shape, material, and illumination, the research also involves developing algorithms to jointly estimate. The developed technologies can be applied to automated systems, personal and industrial robotics, surveillance and security, transportation, image retrieval, image editing and manipulation, and content creation. The project contributes to education through student projects, course development, and workshops and tutorials involving a broader audience. <br/><br/>The research investigates improved representations of 3D shape and material and methods to recover them from one image. Rather than aiming for veridical models, such as precise surface normals or BRDF parameters, the research team recovers approximate models that are useful for object recognition, content creation, and other tasks.  The work on 3D object shape focuses on labeling object boundaries as occlusions, folds, or texture/albedo and using these boundaries as part of a data-driven approach to recover full 3D models of the objects.  The research involves studying methods to recover rich, multiscale representations of the materials that compose objects.  These methods exploit approximate shape representations and approximate representations of the illumination to recover estimates of radiometric properties of the object at a point.  The algorithms build maps of these material properties to model spatial variation in albedo and complex phenomena like veins in marble.  The research also involves extending these methods to report spatially varying normal maps that capture shape textures like the bark of trees.  Finally, the research investigates how to incorporate image-centered maps to capture more random, spatially localized phenomena like the pits in orange peel."
"1730326","Collaborative Research: Computational Photo-Scatterography: Unraveling Scattered Photons for Bio-Imaging","IIS","ROBUST INTELLIGENCE, EXPERIMENTAL EXPEDITIONS","03/01/2018","08/01/2018","Latanya Sweeney","MA","Harvard University","Continuing grant","Jie Yang","02/28/2023","$288,000.00","","latanya@fas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","7495, 7723","7723, 9251","$0.00","Much of the success of today's healthcare is due to rapid advances in our ability to collect and analyze high-resolution data about the human body. However, current methods to achieve cellular resolution are invasive (e.g., blood test or tissue biopsy), and non-invasive imaging modalities do not achieve cellular resolution. The principal goal of this Expeditions project is to develop computational imaging systems for non-invasive bio-imaging, deep beneath the skin, and at cellular-level resolutions. This project has the potential to fundamentally impact healthcare and medicine, by enabling live views of cross sections of human anatomy, simply by pointing a camera at any part of the body. This would put individual users at the center of their healthcare experience and make them true partners in their healthcare delivery. The health imaging devices that result from this project will act as an important pillar in the personalized medicine revolution. This research expedition also holds the potential to launch new healthcare paradigms for chronic disease management, pediatrics, low-resource healthcare, and disaster medical care. Beyond healthcare, making progress on the problem of cellular-scale deep-tissue imaging using light will push the frontiers of the fundamental problem of inverse scattering, which impacts numerous areas of science and engineering. The order of magnitude advances made in inverse scattering and imaging through scattering media will have significant cross-cutting applications in diverse areas such as basic science, consumer imaging, automotive navigation, robotics, surveillance, atmospheric science, and material science. Finally, projects with a single, easy-to-appreciate, and high-impact goal have the potential to inspire the next generation of scientists, attract diverse set of students driven by humanitarian and social causes, and become a platform for inclusion and innovation.<br/><br/>The overarching goal of this project is to develop, test, and validate new computational imaging systems, to non-invasively image below the skin at tunable depths, in highly portable form-factors such as wearables or point-of-care devices. The main challenge is that light scatters as it travels through the human body, and in this process, the spatial information from different points within the body gets mixed up. A new concept, Computational Photo-Scatterography (CPS), is being applied in this project in order to computationally unravel the scattered photons in an imaging system, and allow creation of sharp images and accurate inferences. Recognizing that the brute-force complexity of unraveling scattered photons is prohibitively high, the project uses a computational co-design framework that leverages advances by team members from multiple domains: programmable illumination and optics, image sensors, machine learning, inverse graphics, and hybrid analog-digital computing.  The project will use machine learning (ML) instead of physics-based de-scattering to speed up the solution of the underlying inverse problem. A combination of physics-based inverse graphics algorithms, and ML algorithms combining deep learning and generative modeling will be used to estimate tissue scattering parameters -  motion due to blood flow induces time-variation in tissue parameters, which makes solving the inverse scattering problem more difficult. The project will use ML to create fast but approximate estimators, which will serve as accelerators for inverse scattering. The development of new sensors, able to capture the data necessary to reconstruct the structure of the tissue deep below the skin, constitutes the most important contribution of the project. These systems and algorithms will have the potential to break the current resolution limits of noninvasive bio-imaging by nearly two orders of magnitude, enabling cellular-level imaging at depths far beyond currently possible.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1730202","Collaborative Research: Computational Photo-Scatterography: Unraveling Scattered Photons for Bio-Imaging","IIS","SPECIAL PROJECTS - CCF, EXPERIMENTAL EXPEDITIONS","03/01/2018","08/01/2018","Alyosha Molnar","NY","Cornell University","Continuing grant","Jie Yang","02/28/2023","$328,000.00","","am699@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","2878, 7723","7723, 9251","$0.00","Much of the success of today's healthcare is due to rapid advances in our ability to collect and analyze high-resolution data about the human body. However, current methods to achieve cellular resolution are invasive (e.g., blood test or tissue biopsy), and non-invasive imaging modalities do not achieve cellular resolution. The principal goal of this Expeditions project is to develop computational imaging systems for non-invasive bio-imaging, deep beneath the skin, and at cellular-level resolutions. This project has the potential to fundamentally impact healthcare and medicine, by enabling live views of cross sections of human anatomy, simply by pointing a camera at any part of the body. This would put individual users at the center of their healthcare experience and make them true partners in their healthcare delivery. The health imaging devices that result from this project will act as an important pillar in the personalized medicine revolution. This research expedition also holds the potential to launch new healthcare paradigms for chronic disease management, pediatrics, low-resource healthcare, and disaster medical care. Beyond healthcare, making progress on the problem of cellular-scale deep-tissue imaging using light will push the frontiers of the fundamental problem of inverse scattering, which impacts numerous areas of science and engineering. The order of magnitude advances made in inverse scattering and imaging through scattering media will have significant cross-cutting applications in diverse areas such as basic science, consumer imaging, automotive navigation, robotics, surveillance, atmospheric science, and material science. Finally, projects with a single, easy-to-appreciate, and high-impact goal have the potential to inspire the next generation of scientists, attract diverse set of students driven by humanitarian and social causes, and become a platform for inclusion and innovation.<br/><br/>The overarching goal of this project is to develop, test, and validate new computational imaging systems, to non-invasively image below the skin at tunable depths, in highly portable form-factors such as wearables or point-of-care devices. The main challenge is that light scatters as it travels through the human body, and in this process, the spatial information from different points within the body gets mixed up. A new concept, Computational Photo-Scatterography (CPS), is being applied in this project in order to computationally unravel the scattered photons in an imaging system, and allow creation of sharp images and accurate inferences. Recognizing that the brute-force complexity of unraveling scattered photons is prohibitively high, the project uses a computational co-design framework that leverages advances by team members from multiple domains: programmable illumination and optics, image sensors, machine learning, inverse graphics, and hybrid analog-digital computing.  The project will use machine learning (ML) instead of physics-based de-scattering to speed up the solution of the underlying inverse problem. A combination of physics-based inverse graphics algorithms, and ML algorithms combining deep learning and generative modeling will be used to estimate tissue scattering parameters -  motion due to blood flow induces time-variation in tissue parameters, which makes solving the inverse scattering problem more difficult. The project will use ML to create fast but approximate estimators, which will serve as accelerators for inverse scattering. The development of new sensors, able to capture the data necessary to reconstruct the structure of the tissue deep below the skin, constitutes the most important contribution of the project. These systems and algorithms will have the potential to break the current resolution limits of noninvasive bio-imaging by nearly two orders of magnitude, enabling cellular-level imaging at depths far beyond currently possible.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1514765","RCN: The Coordinated Plant Science Research and Education Network","IOS","PLANT GENOME RESEARCH PROJECT, NSF Research Traineeship (NRT)","08/01/2015","08/25/2017","David Stern","NY","Boyce Thompson Institute Plant Research","Standard Grant","Clifford Weil","07/31/2020","$901,935.00","Crispin Taylor","ds28@cornell.edu","533 Tower Road","Ithaca","NY","148531801","6072541248","BIO","1329, 1997","1228, 1664, 7556, 9109, 9179, BIOT, SMET","$0.00","Plants provide us with food, feed, fiber, medicines, fuel and other bioproducts, and in so doing sequester carbon dioxide, create habitat, stabilize landscapes and encompass an extraordinary biodiversity. Both environmental preservation and human uses of plants require knowledge of plant form and function, from the molecular to ecosystem perspectives, and spanning single-celled, aquatic organisms to domesticated agricultural species and their wild relatives, to the tallest trees. Plant research underpinned the Green Revolution, and is now being called upon to address a range of challenges in food, health and the environment. Because of the breadth of plant science and its associated experimental technologies, the field faces significant headwinds to address multilateral, multidisciplinary experimental questions. This project will form the Coordinated Plant Science Research and Education Network, a network of research and education societies with involvement in plant science research that continues and amplifies a successful effort to unite a broad spectrum of plant scientists around a strategic plan called the Decadal Vision that was published in 2013. The Network has two major goals: (1) to catalyze interdisciplinary training and research by encouraging and facilitating information exchange among its six founding member societies, a number intended to grow; and (2) to use dedicated workshops to seek novel solutions to broaden participation in plant sciences, and to re-examine how postdoctoral fellows should be trained in the plant sciences. Improved cross-talk between different stripes of experimental plant scientists, and with those contributing enabling technologies from imaging to robotics to informatics, promises to enrich and enliven the plant community, while leading to exciting and empowering fundamental discoveries about the wonders of plants. <br/><br/>By serving as a forum through which plant science constituencies coordinate their efforts to advance plant science research, education, and innovation, the Coordinated Plant Science Research and Education Network will coordinate and facilitate a successful effort by the broader plant community to establish a consensus-driven set of priorities which culminated in the 2013 publication of ""Unleashing a Decade of Innovation in Plant Science: A vision for 2015-2025"". The founding members of the Network are the American Society of Plant Biologists, the Alliance of Crop, Soil and Environmental Science Societies, the American Phytopathological Society, the American Society for Horticultural Science, the Botanical Society of America, the Genetics Society of America, and the Council on Undergraduate Research. The Network will be open to any interested scientific professional associations and will proactively engage other organizations with an interest in the study of plants. One of the main goals of the Network is to serve as a clearinghouse for the research, education and outreach activities and opportunities for its members and the wider plant science community. Expected outcomes include new collaborations among societies and scientists, including new interdisciplinary collaborative research projects that will advance the frontiers of plant sciences, and innovative recruitment and training strategies for the next generation of scientists required for excellence in U.S. plant science research. The Network will also convene two workshops, on broadening participation and postdoctoral training that aim to catalyze career building and diversification within the plant science workforce. To communicate the wonder and importance of plant research, the Network will develop a shared set of consistent messages to the public, including authoritative, science-based information on key societally relevant topics. Internal and external communication for the Network will be through Plantae.org, a modular web interface custom designed to serve the needs of the Network and members of the broader plant science community."
"1729931","Collaborative Research: Computational Photo-Scatterography: Unraveling Scattered Photons for Bio-Imaging","IIS","EXPERIMENTAL EXPEDITIONS","03/01/2018","08/01/2018","Ramesh Raskar","MA","Massachusetts Institute of Technology","Continuing grant","Jie Yang","02/28/2023","$280,000.00","","raskar@media.mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7723","7723","$0.00","Much of the success of today's healthcare is due to rapid advances in our ability to collect and analyze high-resolution data about the human body. However, current methods to achieve cellular resolution are invasive (e.g., blood test or tissue biopsy), and non-invasive imaging modalities do not achieve cellular resolution. The principal goal of this Expeditions project is to develop computational imaging systems for non-invasive bio-imaging, deep beneath the skin, and at cellular-level resolutions. This project has the potential to fundamentally impact healthcare and medicine, by enabling live views of cross sections of human anatomy, simply by pointing a camera at any part of the body. This would put individual users at the center of their healthcare experience and make them true partners in their healthcare delivery. The health imaging devices that result from this project will act as an important pillar in the personalized medicine revolution. This research expedition also holds the potential to launch new healthcare paradigms for chronic disease management, pediatrics, low-resource healthcare, and disaster medical care. Beyond healthcare, making progress on the problem of cellular-scale deep-tissue imaging using light will push the frontiers of the fundamental problem of inverse scattering, which impacts numerous areas of science and engineering. The order of magnitude advances made in inverse scattering and imaging through scattering media will have significant cross-cutting applications in diverse areas such as basic science, consumer imaging, automotive navigation, robotics, surveillance, atmospheric science, and material science. Finally, projects with a single, easy-to-appreciate, and high-impact goal have the potential to inspire the next generation of scientists, attract diverse set of students driven by humanitarian and social causes, and become a platform for inclusion and innovation.<br/><br/>The overarching goal of this project is to develop, test, and validate new computational imaging systems, to non-invasively image below the skin at tunable depths, in highly portable form-factors such as wearables or point-of-care devices. The main challenge is that light scatters as it travels through the human body, and in this process, the spatial information from different points within the body gets mixed up. A new concept, Computational Photo-Scatterography (CPS), is being applied in this project in order to computationally unravel the scattered photons in an imaging system, and allow creation of sharp images and accurate inferences. Recognizing that the brute-force complexity of unraveling scattered photons is prohibitively high, the project uses a computational co-design framework that leverages advances by team members from multiple domains: programmable illumination and optics, image sensors, machine learning, inverse graphics, and hybrid analog-digital computing.  The project will use machine learning (ML) instead of physics-based de-scattering to speed up the solution of the underlying inverse problem. A combination of physics-based inverse graphics algorithms, and ML algorithms combining deep learning and generative modeling will be used to estimate tissue scattering parameters -  motion due to blood flow induces time-variation in tissue parameters, which makes solving the inverse scattering problem more difficult. The project will use ML to create fast but approximate estimators, which will serve as accelerators for inverse scattering. The development of new sensors, able to capture the data necessary to reconstruct the structure of the tissue deep below the skin, constitutes the most important contribution of the project. These systems and algorithms will have the potential to break the current resolution limits of noninvasive bio-imaging by nearly two orders of magnitude, enabling cellular-level imaging at depths far beyond currently possible.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1501147","Engineered for Success: Engineering Technician Training for Rural Arizona","DUE","ADVANCED TECH EDUCATION PROG","06/15/2016","04/04/2017","John Morgan","AZ","Yavapai College","Standard Grant","Heather Watson","05/31/2019","$855,350.00","Tom Hughes","John.Morgan@yc.edu","1100 East Sheldon","Prescott","AZ","863013220","9287762021","EHR","7412","1032, 9178, SMET","$0.00","Through its project, Engineered for Success: Engineering Technician Training for Rural Arizona, Yavapai College (YC) will implement enhancements to its Applied Pre-engineering Program to increase capacity, improve student learning, and respond to industry's need for highly-skilled engineering technicians. As indicated by the project title, the focus will be on improving opportunities for students in rural Arizona communities.  A new pathway leading to certification as an Integrated Systems Engineering Technician will be incorporated into an existing Applied Pre-engineering Program. The new pathway will help students gain a deeper understanding of complex systems and how they are connected and work together. The introduction of problem-based learning (PBL) pedagogy will help students connect diverse knowledge from multiple courses to solve real-world challenges.  New internship opportunities will give students exposure to the actual work environment. Nine stackable industry-recognized credentials, three certificates and two Associates Degrees will give students options for employment in middle skills jobs or additional postsecondary education.  Outreach events targeting rural high school students will be expanded and a summer Robotics Camp for middle school girls will be instituted with the aim of increasing enrollment of female students in the program. A marketing campaign will improve parents', teachers' and students' access to information about science, technology, engineering, and mathematics (STEM) careers and training programs. The improved Applied Pre-engineering Program, which will include an early college program for high school students, will incorporate best practice student support strategies, such as on-site tutoring and expanded access to applied learning using modern equipment.  The actions to be undertaken in this project were determined as a result of a preliminary assessment of the YC Applied Pre-engineering Program that was developed and implemented based upon the STEM Pathways Guide, which was developed by Science Foundation Arizona (SFAz).<br/><br/>The overarching goals of the Engineered for Success: Engineering Technician Training for Rural Arizona project are to: 1) produce more qualified engineering technicians to meet workforce demands, and 2) improve engineering technician education.  Strategies for accomplishing these broad goals include, but are not limited to, assuring technician training meets industry needs by engaging an Industry Advisory Council, increasing enrollment and course capacity, raising awareness and interest through targeted outreach efforts, and improving teaching to more strongly demonstrate relevance and practical industry applications.  Attainment of anticipated outcomes will be assessed using institutional data to measure quantitative impacts of the project (e.g. enrollment, degrees/certificates completed, demographic changes, etc.) and surveys to gauge  qualitative impacts (e.g. changes in teaching practices, student attitudes/perceptions).  As a member of Science Foundation Arizona's STEM Pathways Network, YC will seek to demonstrate the applicability of and expand knowledge about the organization's STEM Pathways Model through this project."
"1254262","CAREER: Electroelastic Dynamics of Flexible Piezoelectric Composites for Enhanced Biomimetic Locomotion and Energy Harvesting","CMMI","DYNAMICAL SYSTEMS, Dynamics, Control and System D","08/01/2013","02/21/2018","Alper Erturk","GA","Georgia Tech Research Corporation","Standard Grant","Irina Dolinskaya","07/31/2019","$427,000.00","","alper.erturk@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","7478, 7569","034E, 035E, 1045, 116E, 8024, 9178, 9231, 9251","$0.00","The research objective of this Faculty Early Career Development (CAREER) Program award is to understand and leverage the electroelastic dynamics of flexible piezoelectric composites for next-generation biomimetic locomotion and energy harvesting. Due to their robustness, structural flexibility, high energy density, and well-balanced force-deflection capabilities, fiber-based piezoelectric composites with interdigitated electrodes can be employed in various applications ranging from structural sensors/actuators and energy harvesters to bio-inspired aquatic and aerial vehicles. This research will establish a unified mathematical framework with experimental validations for complex dynamics of fiber-based piezoelectric composites for low-to-high mechanical and electrical excitation levels in the presence of two-way coupling. The technical approach is based on the synthesis of materially and geometrically nonlinear non-conservative electroelastic structural dynamic models with controlled experiments to explore and understand the effects of various parameters on the coupled system dynamics. Specifically, this research will lead to an unprecedented multifunctional nonlinear dynamical system platform that combines biomimetic locomotion and energy harvesting. <br/><br/>If successful, this project will result in electroelastic models and structural concepts that can be exploited in various applications, ranging from structural shape control and adaptive stiffness change to bio-inspired aquatic/aerial robotics as well as energy harvesting from deterministic and stochastic dynamical systems. Potential high-impact applications of enhanced aquatic locomotion and vibrational energy harvesting span from sustainability in marine environments and effective drug delivery to battery-less medical implants and energy-autonomous wireless sensor networks in structural health monitoring. This project will also reach and inspire a large number of underrepresented and minority K-12 students and their teachers through a complementary and engaging educational plan, prepared in collaboration with the Center for Education Integrating Science, Mathematics, and Computing (CEISMC) at Georgia Tech. The educational and outreach activities include the hosting of Georgia Intern-Fellowship Teachers (GIFT) and high school students for research on dynamical systems involving smart structures, aquatic locomotion, and energy harvesting."
"1240483","EFRI-ODISSEI: Synthesizing Ccomplex Structures from Programmable Self-Folding Active Materials","EFMA","EFRI RESEARCH PROJECTS, , ","08/01/2012","06/23/2017","Daniel McAdams","TX","Texas A&M University Main Campus","Standard Grant","Garie Fordyce","07/31/2019","$2,398,106.00","Nancy Amato, Ergun Akleman, Darren Hartl, Dimitris Lagoudas, Daniel McAdams","dmcadams@tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","ENG","7633, L563, P433","067E, 068E, 1444, 7573, 7633, 8021, AMPP","$0.00","The research objective of this Emerging Frontiers in Research and Innovation (EFRI) Origami Design for the Integration of Self-assembling Systems for Engineering Innovation (ODISSEI) award is to discover new techniques for synthesizing complex 3D structures from programmable, self-folding 2D elements. Elements will be massively foldable, meaning fold characteristics and locations will be of near-infinite variety and not limited to pre-engineered folds or joints. This will be made possible by the incorporation of active shape memory layers that provide actuation capabilities. Elements will be programmed by specifying the locations and sequences of localized folding operations. Multiple elements will connect to form larger and more complex 3D structures. The research team will create new theories and methods for (a) multi-scale and multidisciplinary systems analysis and optimization; (b) active materials modeling and structural analyses; (c) computational folding algorithms for design synthesis; (d) geometric modeling, visualization, and fine art; and (e) bio-inspired folding-based design synthesis methods. Deliverables include simulation models of the self-folding material elements, experimental studies validating the simulation models, and a demonstration of the overall synthesis framework.<br/><br/>If successful, the results of this research will constitute a substantial leap forward in engineering technology and knowledge, allowing engineers to design complex systems in fundamentally new ways. The capability to program a material element to fold, un-fold, and re-fold in different ways will have a long-term impact on several areas of national need, including significant challenges in space missions, sustainability, and defense. Research results will be disseminated broadly. Graduate and undergraduate engineering students will benefit through classroom instruction and direct involvement in the research. Underrepresented students from the 6th-12th grade levels will learn about science, technology, engineering and mathematics (STEM) topics through a robotics competition organized in partnership with National Instruments. In partnership with the Center for Puppetry Arts in Atlanta, GA, the research team will produce origami-themed lessons about STEM subjects that will reach over 10,000 elementary-age school children annually.<br/><br/>This project is supported in part by funds from the Air Force Office of Scientific Research."
"1730147","Collaborative Research: Computational Photo-Scatterography: Unraveling Scattered Photons for Bio-Imaging","IIS","SPECIAL PROJECTS - CCF, EXPERIMENTAL EXPEDITIONS","03/01/2018","08/01/2018","Srinivasa Narasimhan","PA","Carnegie-Mellon University","Continuing grant","Jie Yang","02/28/2023","$1,179,899.00","Artur Dubrawski, Ioannis Gkioulekas","srinivas@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","2878, 7723","7723, 9251","$0.00","Much of the success of today's healthcare is due to rapid advances in our ability to collect and analyze high-resolution data about the human body. However, current methods to achieve cellular resolution are invasive (e.g., blood test or tissue biopsy), and non-invasive imaging modalities do not achieve cellular resolution. The principal goal of this Expeditions project is to develop computational imaging systems for non-invasive bio-imaging, deep beneath the skin, and at cellular-level resolutions. This project has the potential to fundamentally impact healthcare and medicine, by enabling live views of cross sections of human anatomy, simply by pointing a camera at any part of the body. This would put individual users at the center of their healthcare experience and make them true partners in their healthcare delivery. The health imaging devices that result from this project will act as an important pillar in the personalized medicine revolution. This research expedition also holds the potential to launch new healthcare paradigms for chronic disease management, pediatrics, low-resource healthcare, and disaster medical care. Beyond healthcare, making progress on the problem of cellular-scale deep-tissue imaging using light will push the frontiers of the fundamental problem of inverse scattering, which impacts numerous areas of science and engineering. The order of magnitude advances made in inverse scattering and imaging through scattering media will have significant cross-cutting applications in diverse areas such as basic science, consumer imaging, automotive navigation, robotics, surveillance, atmospheric science, and material science. Finally, projects with a single, easy-to-appreciate, and high-impact goal have the potential to inspire the next generation of scientists, attract diverse set of students driven by humanitarian and social causes, and become a platform for inclusion and innovation.<br/><br/>The overarching goal of this project is to develop, test, and validate new computational imaging systems, to non-invasively image below the skin at tunable depths, in highly portable form-factors such as wearables or point-of-care devices. The main challenge is that light scatters as it travels through the human body, and in this process, the spatial information from different points within the body gets mixed up. A new concept, Computational Photo-Scatterography (CPS), is being applied in this project in order to computationally unravel the scattered photons in an imaging system, and allow creation of sharp images and accurate inferences. Recognizing that the brute-force complexity of unraveling scattered photons is prohibitively high, the project uses a computational co-design framework that leverages advances by team members from multiple domains: programmable illumination and optics, image sensors, machine learning, inverse graphics, and hybrid analog-digital computing.  The project will use machine learning (ML) instead of physics-based de-scattering to speed up the solution of the underlying inverse problem. A combination of physics-based inverse graphics algorithms, and ML algorithms combining deep learning and generative modeling will be used to estimate tissue scattering parameters -  motion due to blood flow induces time-variation in tissue parameters, which makes solving the inverse scattering problem more difficult. The project will use ML to create fast but approximate estimators, which will serve as accelerators for inverse scattering. The development of new sensors, able to capture the data necessary to reconstruct the structure of the tissue deep below the skin, constitutes the most important contribution of the project. These systems and algorithms will have the potential to break the current resolution limits of noninvasive bio-imaging by nearly two orders of magnitude, enabling cellular-level imaging at depths far beyond currently possible.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1635004","Using Mixed Discrete-Continuum Representations to Characterize the Dynamics of Large Many-Body Dynamics Problems","CMMI","Dynamics, Control and System D","09/01/2016","07/17/2016","Dan Negrut","WI","University of Wisconsin-Madison","Standard Grant","Irina Dolinskaya","08/31/2019","$399,960.00","Radu Serban","negrut@wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","ENG","7569","030E, 031E, 032E, 033E, 034E, 035E, 039E, 040E, 099E, 1059, 7234, 8024","$0.00","The goal of this project is to understand how computer simulation can be used to predict the motion of large systems of bodies interacting with each other through friction and contact. Studying these so-called ""many-body dynamics problems"" has theoretical and practical relevance in several disciplines (physics, chemistry, astronomy, geomechanics), industries (pharmaceuticals, food processing, farming, manufacturing, construction, mining), and engineering applications (additive manufacturing, nanoparticle self-assembly, robotics, ground vehicle mobility). In terms of educational and outreach impact, initiatives undertaken as part of this project will (i) promote the discipline of Computational Science at middle and high-school levels via a ""The Science Behind Video Gaming"" short course and a residential summer program, respectively; (ii) update and expand curricula in two graduate courses on high performance computing and advanced computational dynamics; (iii) expand a biannual advanced computing forum that facilitates transfer of technology; and, (iv) provide training via a Master of Engineering distance learning program for practitioners who need to analyze, process, and solve problems using information generated by the growing use of data collection in engineering design and industrial operations.<br/><br/>The research effort will focus on investigating techniques that facilitate a discrete-continuum dual representation in the simulation of many-body dynamics problems. The fundamental question answered is how should one handle parts of a many-body dynamics problem using a continuum formalism so that the new mixed discrete-continuum representation manages to preserve the dynamics of the original problem? Also, how should a continuum representation be fine-grained into a discrete one, and conversely, what techniques should be used to coarse-grain a discrete representation into a continuous one? Mechanical engineering expertise (dynamics of many-body systems, solid mechanics, plasticity), applied math techniques (meshless methods for solving partial differential equations, optimization methods), and computer science components (machine learning, software engineering) will combine in a coordinated effort to solve the stated problem. In this context, the goal of this project is to (a) establish a systematic methodology for producing rheologies that, when embedded in a continuum mechanics model, produce a solution that is close to that of a large discrete many-body dynamics problem; and (b) use this methodology to understand whether there are rheologies that have a universal attribute; i.e., that are applicable to all, or a large spectrum of, many-body dynamics problems. In this context, a rheology is regarded as a methodology that ties at microscale the dynamics/flow of a continuum to the forces acting on it. The research plan is built around the idea of augmenting physical insights with a machine learning process that uses large amounts of data generated by fully-resolved, many-body dynamics solutions to produce rheology candidates."
"1815275","RI: SMALL: Robust Reinforcement Learning Using Bayesian Models","IIS","ROBUST INTELLIGENCE","08/15/2018","07/31/2018","Marek Petrik","NH","University of New Hampshire","Standard Grant","Weng-keen Wong","07/31/2021","$437,753.00","","mpetrik@cs.unh.edu","51 COLLEGE RD SERVICE BLDG 107","Durham","NH","038243585","6038622172","CSE","7495","075Z, 7495, 7923","$0.00","Basing decisions on data is preferable to relying on heuristics or rules of thumb. Using data effectively, however, can be challenging. In domains like agriculture or medicine, datasets are usually small, biased, and noisy. For instance, the full effects of reduced pesticide applications depend on the weather and the impacts on yield may not be known until the harvest. Reducing pesticide applications reduces costs and provides ecological and consumer benefits, but using too little of it can easily cause a crop failure and significant financial losses. These dual problems of limited data availability and a high cost of failure are also common in manufacturing, maintenance, and even robotics. Because most existing reinforcement learning methods assume large datasets, stakeholders often dismiss data-driven methods and rely on heuristics to make decisions that are apparently safe but quite sub-optimal. This research develops new robust methods for data-driven decision making that can recommend good actions that are also safe even when data is limited. The new reinforcement learning methods use prior domain knowledge to estimate the confidence in possible outcomes to prevent catastrophic failure when predictions are incorrect. The practical viability of these methods is tested on the problem of using historical data to recommending improved pesticide schedules for fruit orchards and is disseminated to practitioners.<br/><br/>This research targets reinforcement learning problems with 1) limited or expensive data and 2) a high cost of failure. When bad decisions cause large losses, injury, or death, then having confidence in a policy's quality is more important than its optimality gap. Computing high-confidence policies in reinforcement learning is difficult. Even small errors can quickly accumulate through positive feedback loops and covariate shift. Therefore, more robust methods are needed to convince practitioners to benefit from data instead of relying on heuristics. The project combines robust optimization with model-based reinforcement learning to compute good policies that are resistant to data errors. Robust optimization has achieved successes in many areas but can be difficult to use with reinforcement learning. It requires a model of plausible uncertainty levels, so-called ambiguity sets, to properly balance solution?s quality and confidence. Constructing good ambiguity sets manually in sequential decision problems is very difficult even for robust optimization experts. This research investigates a new data-driven Bayesian approach to robust reinforcement learning. It combines hierarchical Bayesian models with robust optimization to leverage powerful hierarchical modeling techniques while avoiding the computational complexity often associated with Bayesian reinforcement learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1735260","Type I: An NSF ICORP Site Program for Northeastern University","IIP","I-Corps - Sites","09/01/2017","07/31/2018","Marc Meyer","MA","Northeastern University","Continuing grant","Anita J. LaSalle","08/31/2022","$138,514.00","Paul Croke, Kevin Scanlon","mhm@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","ENG","8046","","$0.00","This project creates an NSF I-Corps Site at Northeastern University.<br/><br/>NSF Innovation Corps (I-Corps) Sites are NSF-funded entities established at universities whose purpose is to nurture and support multiple, local teams to transition their technology concepts into the marketplace. Sites provide infrastructure, advice, resources, networking opportunities, training and modest funding to enable groups to transition their work into the marketplace or into becoming I-Corps Team applicants. I-Corps Sites also strengthen innovation locally and regionally and contribute to the National Innovation Network of mentors, researchers, entrepreneurs and investors.<br/><br/>This Site leverages Northeastern's entrepreneurship ecosystem as well as that of the larger Boston innovation ecosystem. The foundation for the program is a growing body of funded research which offers untapped opportunities for commercialization. To facilitate entrepreneurship, Northeastern created a series of entrepreneurship courses for undergraduate and graduate students, as well as an on-campus incubator feeding ventures into the local investment community.<br/><br/>The Northeastern I-Corps Site program substantially increases both the quantity and quality of STEM-related ventures founded through its Site. The I-Corps Site program also leverage Northeastern's technology licensing office as well as its Mentor and Investors Networks in support of Site teams. There are 280 active individual Mentors supporting Northeastern's startups, as well as a variety of angel and venture capital investors who regularly assess Northeastern ventures, fifty of which have garnered $70 million in venture finance over the past three years. <br/><br/>Northeastern University's entrepreneurship system is based on the meta-process of Educate, Incubate, and Launch. The I-Corp Site program is a highly focused way to a) better recruit a specific graduate, postdoc, and faculty population of potential technological entrepreneurs, and b) provide initial entrepreneurship and innovation education and training for them. Northeastern is also conducting research to more clearly understand the effect of entrepreneurial learning for first time entrepreneurs in its own incubator, focusing on the specific areas of developing customer insight, new product and service solutions, and business models. Several I-Corp ventures are already part of this study.<br/><br/>Northeastern's Site goals are to increase the number and quality of technology ventures emerging from laboratories and to feed new ventures into the I-Corps National program. Another important impact is that I-Corps offers a complementary pathway for early stage ventures to pursue initial funding through I-Corps Node and SBIR/STTR programs. Another potential impact is the expansion of this program in subsequent years to early stage entrepreneurs working in the numerous research environments within one mile of the Northeastern campus. These institutions include the medical schools and hospitals affiliated with Harvard, Tufts, and Boston University, as well as organizations pursuing research in robotics, cybersecurity, and IoT among other STEM areas."
"1619362","RI: AF: Small: Deep Learning Theory","IIS","ROBUST INTELLIGENCE, ALGORITHMIC FOUNDATIONS","07/01/2016","06/10/2016","Peter Bartlett","CA","University of California-Berkeley","Standard Grant","Weng-keen Wong","06/30/2019","$490,000.00","","bartlett@stat.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495, 7796","7495, 7923, 7926","$0.00","Deep learning has recently emerged as a major advance in machine learning and AI.  This technology for learning from data has provided field-changing performance improvements in image classification and speech recognition, it has displayed impressive performance across a large variety of areas (including natural language processing, robotics, audio processing, and computational chemistry), and it has become a central ingredient in AI systems.  But despite these successes, our understanding of these methods is incomplete. The broad goal of this research project is to address this grand challenge: to develop analysis techniques that enable us to understand when and why deep learning methods will be successful, and to design effective methods with explicit performance guarantees.  Successful research outcomes have a significant potential for practical impact in the large and growing set of application areas where these methods are used.<br/><br/>The project aims to understand the performance of deep learning methods - in particular to elucidate what aspects are essential for their success - and hence to develop principled design techniques and performance guarantees.  The objectives are: to characterize the performance impacts of the critical features of current neural network architectures: scale, depth, nonlinearities, and regularization; to develop analysis techniques that facilitate our understanding of the approximation and estimation properties of deep architectures; to identify the boundary between easy and hard learning problems for deep networks; and to develop methods with explicit performance guarantees for optimization in deep neural networks.  Successful research outcomes are likely to increase our understanding of deep learning methods, to provide performance guarantees for these methods, and to facilitate the principled design of novel deep learning methods."
"1753915","Reciprocal effects of adaptation in the brain's motor and sensory systems","BCS","PERCEPTION, ACTION & COGNITION","05/01/2018","07/30/2018","Hannah Block","IN","Indiana University","Continuing grant","Betty H. Tuller","04/30/2021","$549,519.00","","hjblock@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","SBE","7252","7252","$0.00","This project will investigate the complex interactions between how we perceive the world around us and how we move within that world. The researchers will test how learning a new skill affects the information picked up from the world and how that information, in turn, affects motor learning. Understanding the relationship between perception and movement control is fundamental for many fields. Results could contribute to innovations in motor skill training, including rehabilitation of sensorimotor disorders after stroke and development of prostheses, as well as to ergonomics, brain-machine interfaces, robotics, and tele-operations.  The project will advance the NSF's educational goals by encouraging underrepresented students to consider STEM career paths. Five undergraduates per year will be involved in all aspects of the research, including at least three women and minorities through partnerships with programs at Indiana University. The project will also support the expansion of a neuroscience summer camp developed by the study team for Indiana high school girls.  <br/><br/>To execute a voluntary movement, such as reaching out to pick up a pencil, the brain must plan motor parameters such as movement direction and extent. Importantly, the hand's movement will not be correct unless the brain accurately perceives hand position, obtained through an integration of visual information, body position sense (proprioception), touch, etc. This ""multisensory integration"" is flexible and can change with learning, just like motor control, but it is not known whether or how these processes interact. The project will address this question at both the behavioral and neural levels and asks whether multisensory integration and motor control share a common sensorimotor map (a model relating motor commands to sensory consequences). A combination of psychophysics and reaching tasks will indicate whether multisensory integration and motor learning affect each other at the behavioral level. Using transcranial magnetic stimulation (TMS), the researchers will examine whether connections between sensory and motor areas of the brain change in strength when subjects learn a new spatial relationship between vision and proprioception; this would suggest a shared sensorimotor map at the neural level. Results will inform a theoretical framework of sensorimotor control that accounts for both multisensory integration and motor learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1560478","Research Experience for Undergraduates in UAV Technologies","EEC","","08/01/2016","07/21/2016","Subodh Bhandari","CA","Cal Poly Pomona Foundation, Inc.","Standard Grant","Mary Poats","07/31/2019","$380,001.00","Fang Tang","sbhandari@cpp.edu","3801 West Temple, Bldg 55","Pomona","CA","917682557","9098692948","ENG","P226","7736, 9250","$0.00","This Research Experiences for Undergraduates (REU) Site program at California State Polytechnic University, Pomona (CPP), offers state-of-the-art, multi-disciplinary research experiences in unmanned aerial vehicles (UAV) technologies, engineering, and computer science to diverse and talented cohorts of undergraduates, particularly women and Hispanic students, from 2 and 4 year institutions with limited or no research opportunities. UAV's have the potential of replacing manned aircraft for dull, dirty, and dangerous missions. In addition, UAV's are less expensive than manned aircraft and pose no risk to human operators. Military applications include intelligence, surveillance, and reconnaissance (ISR), battlefield damage assessment, and force protection.  Civilian applications include remote sensing, scientific research, search and rescue missions, border patrol, surveillance of disaster-affected areas, aerial photography, aerial mapping for geotechnical survey, vegetation growth analysis, crop dusting, and precision agriculture.  The UAV industry is the fastest growing sector of the aerospace industry.  However, there is a lack of professionals entering the workforce for UAV related jobs.  This REU program is designed to increase students' interest in UAV technologies by means of first-hand experience on UAV research with direct mentorship by faculty advisors from various departments within the CPP Colleges of Engineering and Science.  <br/><br/>This REU Site offers undergraduates, in collaboration with CPP faculty and graduate students, opportunities to conduct research during a 10-week summer program, on state-of-the-art technologies and advanced research projects in UAV flight dynamic and control, computer vision, artificial intelligence, embedded systems, and robotics. In addition to their research, students will participate in weekly research seminars, research meetings, and professional development seminars. The seminars will include topics such as literature review, writing a scientific paper, improving written and oral communication skills, technical presentations, graduate education, career paths, resume building, and ethics in science and engineering. The 10-week program will also include outreach activity. The students will give presentations on UAV technologies, engineering, and computer science to K-12 students at local schools. This will enhance students' communication skills, allow them to see the broader implications of their research, and see how they can positively impact society through research. The discoveries made during these collaborations will be communicated to the broader scientific community via publications and presentations. <br/><br/>This site is supported by the Department of Defense in partnership with the NSF REU program."
"1763689","RI: Medium: Light Responsive Polymer Magnetic Microrobots with Dual Mode Sensing for Biomedical and Advanced Manufacturing Applications","IIS","ROBUST INTELLIGENCE, National Robotics Initiative","09/01/2018","07/29/2018","David Cappelleri","IN","Purdue University","Standard Grant","Reid Simmons","08/31/2022","$1,000,000.00","Song Zhang","dcappell@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7495, 8013","7495, 7924, 8086","$0.00","Microrobots have many potential applications in applications as diverse as biomedical and advanced manufacturing.  While current microrobots can navigate using externally applied magnetic fields, their lack of sensing and manipulation limit their capabilities.  In particular, micro-force information is essential for safe biomanipulation, sensing biological processes, and performing microassembly tasks in advanced manufacturing applications.  In addition, mobile microrobots that can sense electrical potentials and connections of cells will enable the characterization and study of therapeutic strategies, assisting in the treatment of various cancers.  As part of the planned outreach activities, researchers will develop STEM outreach programs with Deaf Kids CODE to help empower deaf/hard of hearing K-12 students.<br/><br/>To this end, the project will create a new class of light responsive polymer magnetic microrobots (LRPMMs) with active end-effectors and dual-mode sensing capabilities.  An embedded magnetic body will enable the use of external magnetic fields to control microrobots to navigate in the workspace.  The active end-effectors will be made from responsive polymers and actuated by structured light patterns. The polymer structures will be calibrated so vision-based force-sensing techniques can be applied. Additionally, electrochromic properties will be embedded into the polymers to enable detection of electrical potential levels in the environment through their change in color. The proposed research tasks include the design and fabrication of the LRPMMs; optical system development for structured light actuation, sensing, and tracking; and control and experimental validation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819248","SBIR Phase I:  Analysis of Progress Photos for Indoor Construction Progress Monitoring","IIP","SMALL BUSINESS PHASE I","06/15/2018","06/15/2018","Derek Hoiem","IL","RECONSTRUCT INC","Standard Grant","Peter Atherton","11/30/2018","$224,996.00","","dhoiem@illinois.edu","60 Hazelwood Dr","Champaign","IL","618207460","4129526964","ENG","5371","5371, 8033","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is that it will save billions of dollars by anticipating construction delays and streamlining coordination to prevent them. Lower costs will help upgrade our nation's infrastructure, which is a critical national priority. Many construction companies strongly want a solution to indoor progress monitoring. Laser scanning is too expensive and slow, and photography services can cost hundreds of thousands of dollars for large projects and introduce logistical challenges. The proposed research would simplify the workflow for progress monitoring of interiors by automatically registering 360 degree photos and video and aligning them to building information models (BIM), providing a cheap, quick, and effective solution for daily progress monitoring.<br/><br/>This Small Business Innovation Research (SBIR) Phase I project aims to localize images, reconstruct 3D models, align them to floorplans or 3D BIM, and use the aligned models to provide actionable data to construction managers. A main challenge is to robustly solve for camera pose using structure-from-motion in indoor scenes that are unfinished and contain textureless and reflective surfaces. A second challenge is to automatically or semi-automatically register the models to 2D or 3D plans, made more difficult by the fact that the site is incomplete and constantly changing. A third challenge is to create interfaces that project personnel can use to perform visual inspection, progress monitoring, requests for information, and other supervision and coordination tasks. The project will investigate the use of tags (i.e., markers) to improve robustness of 3D reconstruction and to perform registration without requiring the 3D positions of tags to be known in advance. Thus, the project addresses major unsolved problems in computer vision, robotics, and their application to construction management.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1809841","Photoresponsive Bond Exchange in Liquid Crystalline Polymer Networks: A Route to Complex and Controllable Shape Shifting Materials","DMR","POLYMERS","06/01/2018","02/28/2018","Christopher Bowman","CO","University of Colorado at Boulder","Standard Grant","Andrew J. Lovinger","05/31/2021","$371,666.00","","christopher.bowman@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","MPS","1773","8037","$0.00","NON-TECHNICAL SUMMARY:<br/><br/>Smart materials are those that are capable of responding to their conditions so as to change their behavior in a desired manner.  One class of these is shape-shifting materials that have the capacity to alter their shape in a desired manner.  Such shape-shifting materials have the potential for implementation in the fields of artificial muscles, soft robotics, self-deploying devices, smart windows, self-healing materials, adhesives, and many other areas.  The materials developed here combine the benefits of (a) liquid crystalline elastomers (which are highly deformable polymeric materials that reversibly change shape upon heating) and (b)light-activated chemical changes in the material that enable it to be reshaped, healed, and realigned at will.  The overall scope of the project seeks to understand the underlying relationships between the molecular structure of the materials and their remarkable properties and performance, and subsequently use that knowledge to design improved approaches and molecular structures for such smart materials.   In addition to advances in technology, this project will also contribute to the development of a ""bootcamp"" in the recently formed PhD degree program in Materials Science and Engineering at the University of Colorado with the express goal of bringing in students from diverse backgrounds that would not otherwise consider or be ready to enter a PhD program in materials science.  This program aims to recruit and train diverse personnel, comprising a large number of undergraduate and graduate students, in a powerful combination of chemical synthesis, materials science, and polymer chemistry.<br/><br/><br/>TECHNICAL SUMMARY:<br/><br/>Programming fully reversible, shape-shifting polymers presents a special challenge despite a large amount of promising work in this area. Liquid crystalline networks (LCNs) represent one of the most capable polymeric materials because they offer thermoreversible strain, programmable simply by directing molecular-scale alignment. Although the polymer network enables the translation of molecular order to shape, it is also inherently limiting when trying to program new or complex alignment. Here, light will be used as a stimulus for radical-mediated addition-fragmentation chain transfer (AFT) that causes a cascading dynamic covalent-bond exchange reaction to occur within the network.  Using this chemistry, readily reprogrammable shape-shifting materials will be explored with independent control over the LC phase shape, disordered shape, and the switching temperature.  <br/>  The overall objective of this work is to further the understanding, accessibility, and implementation of AFT-based LCNs through chemical design in coordination with programming conditions to develop versatile, readily reprogrammable shape-shifting materials.  This work will focus on fundamental understanding of these smart materials and their design at both the macro- and nano-scale, including: i) determining fundamental formation-structure-property-programming relationships that will be used to develop a library of photopolymerizable, programmable LCNs,  ii) combining disparate material compositions, alignments and structures in macroscale materials to understand the impact of interfaces and gradients in composition and structure on the material actuation and response, and   iii) forming nano-scale structures through imprinting and holography to determine and understand the effects of feature size as compared to LC domain size on the bond-exchange process, its effectiveness, and the LC alignment. Each scientific direction is coupled to education and training of a diverse group of undergraduate and graduate students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1750789","CAREER: Towards an Intermittent Learning Framework for Smart and Efficient Cyber-Physical Autonomy","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","05/01/2018","04/10/2018","Kyriakos G Vamvoudakis","VA","Virginia Polytechnic Institute and State University","Continuing grant","Jonathan Sprinkle","04/30/2023","$89,442.00","","kyriakos@gatech.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7918","1045","$0.00","This project expands how reinforcement learning frameworks can be used for Cyber-Physical Systems (CPS) for autonomy. The research utilizes intermittent reinforcement, where a reward is not given every time the desired response is performed. This differs from traditional reinforcement learning mechanisms, in which a reward is given for each point during online training. What is novel in this framework is that it can demonstrate how reinforcement learning can be used when rare events, or noisy and adversarial data, can affect the training and performance of these algorithms. The work will be validated on collaborative road freight transport and collaborative robotics testbeds, through international partnerships with Sweden and the United Kingdom. The project includes activities that integrate high-school students into challenging problems in machine learning areas, motivated through drone racing competitions.<br/><br/>The goal of this research is to expand foundational knowledge through deepened ties between the learning, control, game theory, and CPS communities. The approach is to, (i) unify new perspectives of learning in engineering with respect to resiliency, bandwidth efficiency, robustness, and other aspects that cannot be achieved with the state-of-the-art approaches; (ii) develop intermittent deep learning methods for CPS that can mitigate sensor attacks and can handle cases of limited sensing capabilities; (iii) incorporate nonequilibrium game-theoretic learning in CPS with components whose decision-making, rationality, and information usage are fundamentally different; and (iv) investigate ways to transfer learning to new platforms. The project's education and outreach component includes internships that will lead to technology transfer, summer camps with a special focus on reaching out to underrepresented minorities and women, and collaboration with institutions in Sweden and the United Kingdom through student exchange programs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1329481","CPS: Synergy: Smart Flexible Camera Sheet: Ultra-Thin Semantic-Guided Cooperative Micro-Camera Array","CNS","INFORMATION TECHNOLOGY RESEARC","10/01/2013","07/16/2014","Hongrui Jiang","WI","University of Wisconsin-Madison","Standard Grant","David Corman","09/30/2019","$1,000,000.00","Li Zhang, Yu Hen Hu","hongrui@engr.wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","CSE","1640","7918","$0.00","This highly interdisciplinary research addresses two fundamental challenges in image sensing and image understanding: 1) versatile camera systems in a small form factor, and 2) 3-dimensional scene and object recognition from 2-dimensional photos.  These fundamental challenges are tackled together by developing a cyber-physical imaging system, called smart flexible camera sheet, which integrates an array of many micro-cameras (millimeters in size each) onto a thin substrate.  The substrate has flexible geometric shape and the orientation of each camera is individually adjusted and controlled in real time via intelligent algorithms.  The overall imaging system is ultra-thin and space-efficient, and can be easily mounted onto or embedded into any planar or curved surface.  Hence it opens up a plethora of new civilian and military applications where surveillance and visual monitoring are required, thus bearing great commercialization potential.  Example applications are: smart vehicles, smart transportation, highway safety, smart civil infrastructure, manufacturing lines, battlefield surveillance and reconnaissance, sensor networks, mobile robotics, medical facilities, and patient care. <br/><br/>Broader Impact: This project generates new educational opportunities for students at all levels, leading to curricular development in electrical engineering, applied physics, materials science and engineering, and computer science.  An important component of the project is a strong dissemination and outreach program to reach other universities, K-12 students, teachers, parents and the general public."
"1835944","2019 GRC Complex Active and Adaptive Material Systems: Exploiting the Functionality of Soft Materials","DMR","CONDENSED MATTER PHYSICS, POLYMERS, BIOMATERIALS PROGRAM","09/01/2018","06/28/2018","Richard Vaia","RI","Gordon Research Conferences","Standard Grant","Andrew J. Lovinger","06/30/2019","$10,420.00","","richard.vaia@us.af.mil","512 Liberty Lane","West Kingston","RI","028921502","4017834011","MPS","1710, 1773, 7623","7556, 9150","$0.00","NON-TECHNICAL AND TECHNICAL ABSTRACT: <br/><br/>This award provides partial support for participants to the 2019 GRC/GRS conference on ""Complex Active and Adaptive Material Systems: Exploiting the Functionality of Soft Materials"", to be held January 26-27 (GRS) and January 27-February 1st  (GRC) in Ventura, CA. The aim of the GRC is to stimulate the soft-materials community to discuss ideas from nature (materials occurring in nature), and state-of the-art soft-materials science and technologies that can be used to design new materials for a broad range of applications such as soft robotics, sensors, smart materials, and adaptive surfaces. These discussions are intended to lead to the exploration of transformative concepts in a range of fields encompassing materials science and engineering (soft matter, biomaterials, biophysics, chemical engineering), as well as theoretical and computational modeling.  An overall intended hallmark of this GRC  is to address the barriers to practical applications of exotic and complex materials, including consideration and adoption of nature-inspired self-assembly processes apparent in many biological systems.  The themed GRC technical sessions will cover the following areas: Building with structured fluids; Self-assembling complex materials; The cellular machine; Taming active matter; Structured surfaces; Responsive materials; Biomimetics: exploiting evolution; and Soft machines.  The GRS organized by graduate students and postdocs will be held the weekend prior to the GRC when talks based on selected submitted abstracts will be delivered by the graduate students and postdocs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1624770","I/UCRC for Advanced Electronics through Machine Learning (CAEML)","CNS","SPECIAL PROJECTS - CISE, INDUSTRY/UNIV COOP RES CENTERS","08/01/2016","07/07/2018","Paul Franzon","NC","North Carolina State University","Continuing grant","Dmitri Perkins","07/31/2021","$458,000.00","Elyse Rosenbaum","paulf@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","1714, 5761","1800, 5761","$0.00","The semiconductor industry is perennially one of America's top exporters. Worldwide semiconductor sales for 2014 reached $335.8 billion, and the number of U.S. jobs in this sector was estimated to be around 250,000 in 2013. More broadly, the U.S. tech industry, which depends on semiconductor innovation to spur new products and applications, is itself estimated to represent no less than 5.7% of the entire U.S. private sector workforce (at nearly 6.5 million jobs), and with a tech industry payroll of $654 billion in 2014, it accounted for over 11% of all U.S. private sector payroll. Yet despite its success, the industry must continue to innovate if the U.S. is to retain global leadership in this highly competitive area. The complexity of modern microelectronic products necessitates the use of computer tools to formulate and verify product designs prior to manufacturing. When a product doesn't operate as intended or suffers early failures, this can often be attributed to inadequacy of the models used during the design process. In fact, the shortcomings of existing approaches for system component modeling have become a serious impediment to continued innovation.<br/><br/>The Center for Advanced Electronics through Machine Learning (CAEML) proposes to create machine-learning algorithms to derive models used for electronic design automation with the objective of enabling fast, accurate design of microelectronic circuits and systems. Success will make it much easier and cheaper to optimize a system design, allowing the industry to produce lower-power and lower-cost electronic systems without sacrificing functionality. The eventual result will be significant growth in capabilities that will drive innovation throughout the electronics industry, leading to new devices and applications, continued entrepreneurial leadership, and economic growth.<br/><br/>While achieving those goals, CAEML will also focus on diversifying the undergraduate engineering student body and improving the undergraduate experience. Students from groups traditionally underrepresented in engineering will be targeted for recruitment as undergraduate research assistants. Member companies will provide internships and mentors for participating students, and the diverse graduate and undergraduate student researchers in CAEML will receive hands-on multidisciplinary education. CAEML will also participate in all three site universities? existing avenues for student and faculty engagement with local youth. In particular, university-based summer camps are a tried and tested method of making high-school students familiar with and comfortable on our campuses. NCSU runs engineering summer camps for high-school students, with the Electrical and Computer Engineering department providing an autonomous robotics workshop. CAEML undergraduate and graduate students can serve as counselors or instructors for camps; the CAEML team proposes to develop new activities and workshops for high-school campers on all three sites' campuses. In addition, the MISO program (Maximizing the Impact of STEM Outreach) at NCSU is a campus-wide program funded by NSF that provides an innovative approach to evaluation across NC State's K-12 STEM education outreach programs<br/><br/><br/><br/>The Center for Advanced Electronics through Machine Learning (CAEML) will create machine-learning algorithms to derive models used for electronic design automation, with the objective of enabling fast, accurate design of microelectronic circuits and systems. The electronics industry's continued ability to innovate requires the creation of optimization methodologies that result in low-power integrated systems that meet performance specifications, despite being composed of components whose characteristics exhibit variability and that operate in different physical or signal domains. Today, shortcomings in accuracy and comprehensiveness of component-level behavioral models impede the advancement of computer-aided electronic system design optimization. The model accuracy also impacts system verification. Ultimately, the proper functionality of an electronic system is verified through testing of a representative sample. However, modern electronic systems are so complex that it is unthinkable to bring one to the manufacturing stage without first verifying its operation using simulation. Today, simulation generally does not ensure that an integrated circuit or electronic system will pass qualification testing the first time, and failures are often attributed to insufficiency of the simulation models. With an improved modeling capability, one could achieve better design efficiency, and also perform design optimization. For system simulation, behavioral models of the components' terminal responses are desired for both computational tractability and protection of intellectual property. Despite many years of significant effort by the electronic design automation community, there is not a general, systematic method to generate accurate and comprehensive behavioral models, in part because of the nonlinear, complex, and multi-port nature of the components being modeled.<br/><br/>CAEML will pioneer the use of machine-learning methods to extract behavioral models of electronic components and subsystems from simulation waveforms and/or measurement data. The Center will make 2 primary contributions to the field of machine learning: it will demonstrate the application of machine learning to electronics modeling, and develop the entire machine-learning pipeline. Historically, machine-learning theorists have focused on the model learning and evaluation tasks, but CAEML will focus on end-to-end performance of the pipeline, including data acquisition, selection and filtering, as well as cost function specification. CAEML will develop a methodology to use prior knowledge, i.e., physical constraints and the domain knowledge provided by designers, to speed up the learning process. Novel methods of incorporating component variability, including that due to semiconductor process variations, will be developed. The intended end-users are electronic design automation (EDA) tool developers, IC design houses, and system design and manufacturing companies.<br/><br/>CAEML consists of 3 sites: Illinois, Georgia Tech, and NC State. The scope of research at each site encompasses both algorithm development and the application of the derived models to a variety of IC and system design tasks. Investigators at all 3 university sites have unique skills and expertise while sharing interests in electronic design automation, IC design, system-level signal integrity, and power distribution. To leverage the cross-campus expertise, many of the Center's proposed projects involve investigators from more than one site. The NCSU investigators have special expertise in RFIC and digital design, process design kits, and circuit-level surrogate modeling. All three sites have strong research records in the fields of signal integrity analysis and electronic design automation."
"1514253","RI: Medium: Sentential Decision Diagrams","IIS","ROBUST INTELLIGENCE, Unallocated Program Costs","07/01/2015","05/15/2018","Adnan Darwiche","CA","University of California-Los Angeles","Continuing grant","James Donlon","06/30/2019","$705,865.00","","darwiche@cs.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","CSE","7495, 9199","7495, 7924, 9251","$0.00","Logical and probabilistic reasoning are now routinely used in various fields of computer science and engineering, including artificial intelligence in particular. These modes of reasoning currently underlie systems that perform automated diagnosis, planning, software and hardware verification, web information extraction, bioinformatics, vision and robotics. This project aims at advancing the state of the art in logical and probabilistic reasoning, to allow scientists and engineers to learn and reason with much larger models than is currently possible. The project is based on a particular computational paradigm, known as knowledge compilation, which transforms knowledge into forms that facilitate their efficient processing by reasoning and learning algorithms. The results expected from this project will provide domain-independent, highly scalable, tools and techniques for addressing computational problems that arise in healthcare, industrial automation, and information management. The project will also provide a context for training graduate students in the computational paradigm of knowledge compilation, and will target the integration of this paradigm into computer science curricula.<br/><br/>More specifically, the project aims to develop a new framework for knowledge compilation based on the recently discovered Sentential Decision Diagram (SDD). The SDD is a target compilation language, which generalizes the Ordered Binary Decision Diagram (OBDD) that has been quite influential in many areas of computer science and engineering. This project has two parts. The first part is concerned with developing the SDD compilation language further, both theoretically and practically. On the theoretical side, there is a number of pending of questions relating to lower and upper bounds on SDDs, in addition to questions that must be answered to fully understand their relation to OBDDs. On the practical side, the SDD package needs to be extended to enhance its scalability and to provide new functionality that is needed for fully exploiting SDDs in a wider spectrum of applications. The second part of the project is concerned with a more recent discovery: The probabilistic SDD (PSDD). This compilation language aims at inducing probability distributions over propositional theories, in a very principled and efficient manner. Our objective here is to develop PSDDs into a mature tool, with a corresponding public package, for learning tractable probabilistic models under massive logical constraints, and for compiling probabilistic graphical models into PSDDs for the purpose of more scalable probabilistic reasoning.<br/>"
"1835539","CRII: RI: Multi-Source Domain Generalization Approaches to Visual Attribute Detection","IIS","CRII CISE Research Initiation","12/23/2017","06/11/2018","Boqing Gong","CA","International Computer Science Institute","Continuing grant","Jie Yang","04/30/2019","$40,778.00","","bgong@icsi.berkeley.edu","1947 CENTER ST STE 600","Berkeley","CA","947044115","5106662900","CSE","026Y","7495, 8228","$0.00","This project investigates how to accurately and robustly detect attributes from images (videos, and 3D data), with the goal of developing and publicly providing effective attribute detection tools. Visual attributes refer to human-namable and machine-detectable inherent characteristics of visual content from objects, scenes, and activities (e.g., four-legged, outdoor, and crowded). They possess versatile properties and application potentials by offering a natural human-computer interaction channel for involving humans in the loop of machine vision algorithms, serving as basic building blocks for one to compose categories and describe instances, and bringing rich prior knowledge and regularization to statistical learning models, to name a few. The project advances the long-standing pursuit of utilizing attributes for a wide variety of visual recognition and search tasks. The project also actively engages graduate and undergraduate students, and outreaches local high-school students. The research results from this project can impact several related communities such as NLP, speech, and robotics, etc.. <br/> <br/>This research explicitly tackles the need that attribute detectors should generalize well across different categories, including those previously unseen ones. The research team approaches the problem based on multi-source domain generalization by taking each category as a domain. In particular, this project develops new feature extraction tools tailored to account for the middle-level attributes, as opposed to the traditional features primarily designed and tested for high-level visual recognition. The project consists of three major thrusts hinging on the key motivation of the analogy between attribute detection and domain generalization. It begins by learning a fine-grained ""shallow"" feature mapping (Thrust I) to distill attribute-discriminative signals that are category-invariant, and then investigates ""deeper"" into the feature extraction frameworks - Fisher vectors (Thrust II) and convolutional neural networks (Thrust III)-to revise them for the purpose of attribute detection."
"1510055","Topics in Geometrical Dynamics and Applications","DMS","APPLIED MATHEMATICS","09/01/2015","08/20/2015","Serge Tabachnikov","PA","Pennsylvania State Univ University Park","Standard Grant","Victor Roytburd","08/31/2019","$213,000.00","","tabachni@math.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","MPS","1266","","$0.00","This research project studies vehicle kinematics and related problems. The project focuses on a number of carefully selected concrete problems with applications in areas including pursuit problems, geometrical robotics, flotation theory, and fluid motion. The mathematical results of the research will have an impact on the study of fundamental differential equations (Hill's equation) that describe numerous natural phenomena, from planetary motion to the motion of electron. The investigator will actively involve undergraduate and graduate students in this research program.<br/><br/>The unifying theme of this project is the monodromy of the related continuous and discrete systems and a strong connection with finite- and infinite-dimensional completely integrable systems. In particular, the investigator will study connections of vehicle kinematics with the filament (binormal, local induction, smoke ring) equation, one of the most studied completely integrable partial differential equations of soliton type, and its discretizations. The research will contribute to the emerging areas of discrete differential geometry and discrete completely integrable systems."
"1838902","Workshop on Future Trends and Opportunities for Power Electronics in an Electrified Transportation Industry, Held at Univ. of Maryland, College Park MD, August 17-18, 2018. MD","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/01/2018","07/27/2018","Babak Fahimi","TX","University of Texas at Dallas","Standard Grant","Radhakisan S. Baheti","07/31/2019","$49,000.00","","bxf102000@utdallas.edu","800 W. Campbell Rd., AD15","Richardson","TX","750803021","9728832313","ENG","7607","155E, 7556","$0.00","Abstract: <br/>An electrified transportation industry will transform mobility, energy independence, power grid operation, and connectivity in a profound and substantially positive way. The cultural, economic, environmental, and industrial outcomes of this disruptive trend will have a global impact. This transformation will open new opportunities for fusing industries such as communication, energy, electric power, and robotics to name a few. Scientific and technological leadership in this growing trend plays a pivotal role in long term economic prosperity, energy independence, and creation of new jobs in the United States and around the world. Power electronics, as an enabling technology, plays a key role in ultimate success of this transformation. The workshop on future trends and opportunities for power electronics in an electrified transportation industry aims to identify the most challenging and needed technological advances in the area of power converter, electric motors, wireless charging, and autonomous vehicle design.<br/><br/>This workshop brings leaders from the academia, industry, and government together within a two days program to discuss and exchange ideas related to the role of power electronics in electrification of the transportation industry. A series of keynote speeches by experts followed by task specific group discussions will take place on August 17-18, 2018. The main technical focus of the workshop will be on electric drive requirements, charging and energy storage management, and autonomous operation and connectivity of electric vehicles. The final outcome of this gathering will be a set of recommendations to outline the most needed short term and long term technology advances in the area of power electronics and energy conversion to cope with the anticipated rate of growth in electrification of the automotive, aerospace, and marine industries. The requested funds will be used to cover the travel expenses of the invitees to the workshop and meals during the event.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1827831","MRI: Acquisition of an Integrated Bionanomaterials Characterization and Imaging System for Research and Education Initiatives in Bioengineering","CBET","MAJOR RESEARCH INSTRUMENTATION","08/01/2018","07/26/2018","MinJun Kim","TX","Southern Methodist University","Standard Grant","Song-Charng Kong","07/31/2019","$351,687.00","Duncan MacFarlane, Ali Beskok, Alexander Lippert","mjkim@lyle.smu.edu","6425 BOAZ","Dallas","TX","752750302","2147682030","ENG","1189","1189","$0.00","This award is to purchase a bio/nanomaterials characterization and imaging system, which will be used by seven North Texas academic research institutions. The proposed instrument offers multi-functional capabilities by integrating a confocal laser scanning microscope (CLSM), atomic force microscope (AFM), and digital light processing (DLP). This new system will enable 20 research groups to perform material imaging, manipulation, and property measurements of synthetic and biological nano/microstructures with optical, electrical, mechanical, and thermal stimulations in both ambient air and liquid environments. The equipment will be housed at the Biological, Actuation, Sensing, and Transport Laboratory on Southern Methodist University campus, a centralized location in the Dallas-Fort Worth Metroplex. Graduate and undergraduate students will be trained in this state-of-the-art facility, allowing students to build a rich foundation for studying biological cells and organic/inorganic nano/microstructures. <br/><br/>The proposed imaging instrument will benefit a number of ongoing research projects. The DLP system will provide fully controllable patterns of light, where the CLSM-AFM system will improve the capability of property measurement of biological and synthetic materials. The use of the CLSM-AFM-DLP will broaden the capability of research in molecular dynamics, bacterial swarms, flagellar mechanics, biologically-inspired robotics, determination of dielectric and mechanical properties of biological cells and materials, laser-assisted micro/nanofabrication, and imaging reactive oxygen, nitrogen and sulfur species. This instrument can lead to important findings for nature-inspired technology and enable future research in various areas: 1) advanced imaging and property measurement of organic/inorganic nano/microstructures, 2) spatial light modulated techniques for live cell imaging, 3) thermal transport and wettability of some low energy surfaces at the liquid-solid interface, and 4) electrical investigation of bio-templated advanced nanostructures.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1302327","SHF: Medium: Collaborative Research:   FRP for Real","CCF","SOFTWARE & HARDWARE FOUNDATION, PROGRAMMING LANGUAGES","10/01/2013","06/19/2015","Ruzica Piskac","CT","Yale University","Standard Grant","Anindya Banerjee","09/30/2019","$866,000.00","","ruzica.piskac@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","CSE","7798, 7943","7924, 7943, 9251","$0.00","Functional Reactive Programming, or FRP, is a declarative programming paradigm based on two fundamental abstractions: a continuous (functional) modeling of time-varying behaviors, and a discrete (reactive) calculus of user and process interaction.  FRP provides a novel and effective approach to solving problems in which there is a combination of both continuous and discrete entities such as found in computer animation, robotics, control systems, GUIs, and interactive multimedia.  FRP?s broader impact is seen in its adoption by several other research projects, and its use in several applications different from those at Yale.  The proposed work will strengthen these existing projects, and further broaden the applicability of FRP.  The proposed improvements in implementation will make FRP more suitable for compute-intensive applications, such as interactive 3D graphics and real-time audio processing.  It will also benefit the modeling and simulation community, which often uses declarative approaches to specifying and solving problems.<br/> <br/>Previous research at Yale helped to establish the foundations of FRP, and demonstrated its utility in several application domains.  Despite this preliminary success, more work is needed to make ""FRP for real.""  That is, to develop a system that facilitates writing natural and concise descriptions of reactive behaviors, responds well enough to satisfy most common real-time constraints, reifies real-world objects as first-class signal functions, runs efficiently through program optimization and parallel execution on multicore architectures, and has been validated in a real-world application domain, specifically audio signal processing.  The proposed research will advance the overall FRP methodology in three areas: Language Design (type system extensions to capture resource constraints, a redesign of the mediation between the discrete and continuous, and a better syntax to capture the essence of FRP); Language Implementation (program optimizations, multicore execution, asynchronous sub-processes); and Validation and Testing (with a focus on real-time audio signal processing)."
"1563727","RI: Medium: Collaborative Research: Text-to-Image Reference Resolution for Image Understanding and Manipulation","IIS","ROBUST INTELLIGENCE","06/01/2016","09/01/2017","Svetlana Lazebnik","IL","University of Illinois at Urbana-Champaign","Continuing grant","Jie Yang","05/31/2019","$550,000.00","Julia Hockenmaier","slazebni@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","7495","7495, 7924","$0.00","This project develops new technologies at the interface of computer vision and natural language processing to understand text-to-image relationships. For example, given a captioned image, the project develops techniques which determine which words (e.g. ""woman talking on phone"", ""The farther vehicle"") correspond to which image parts. From robotics to human-computer interaction, there are numerous real-world tasks that benefit from practical systems to identify objects in scenes based on language and understand language based on visual context. In particular, the project develops the first language-based image authoring tool which allows users to edit or synthesize realistic imagery using only natural language (e.g. ""delete the garbage truck from this photo"" or ""make an image with three boys chasing a shaggy dog""). Beyond the immediate impact of creating new ways for users to access and author digital images, the broader impacts of this work include three focus areas: the development of new benchmarks for the vision and language communities, outreach and undergraduate research, and leadership in promoting diversity. <br/><br/>At the core of the project are new techniques for large-scale text-to-image reference resolution (TIRR) that enable systems to automatically identify the image regions that depict entities described in natural language sentences or commands. These techniques advance image interpretation by enabling systems to perform partial matching between images and sentences, referring expression understanding, and image-based question answering. They also advance image manipulation by enabling systems that can synthesize images starting from a textual description, or modify images based on natural language commands. The main technical contributions of the project are:  (1) benchmark datasets for TIRR with comprehensive large-scale gold standard annotations that will make TIRR a standard task for recognition; (2) principled new representations for text-to-image annotations that expose the compositional nature of language using the formalism of the denotation graph; (3) new models for TIRR that perform an explicit alignment (grounding) of words and phrases to image regions guided by the structure of the denotation graph; (4) applications of TIRR methods to referring expression understanding and visual question answering; and (5) applications of TIRR to image creation and manipulation based on natural language input."
"1802242","BPS Geometry, Singularities, and String Theory","DMS","ALGEBRA,NUMBER THEORY,AND COM","05/15/2018","04/20/2018","Sheldon Katz","IL","University of Illinois at Urbana-Champaign","Continuing grant","Timothy Hodges","04/30/2021","$106,263.00","","katz@math.uiuc.edu","1901 South First Street","Champaign","IL","618207406","2173332187","MPS","1264","","$0.00","This award supports the continuing research of the Principal Investigator at the interface of algebraic geometry in mathematics and string theory in theoretical physics.  Algebraic geometry is the investigation of algebraic solutions of polynomial equations, the geometry of the graphs of these solutions, and the theoretical structure describing their properties.  It has numerous applications in science and engineering, including geometric modeling, robotics, control theory, coding theory, phylogenetics, as well as the application to string theory being advanced in this project.  String theory is a physical theory which provides a framework for a unified field theory incorporating all of the forces and particles found in nature.  String theory has found wide application beyond unified field theory, including condensed matter physics, black hole physics, and the application to mathematics being advanced in this project.  The Principal Investigator will involve graduate students and postdocs in aspects of the project, assisting their professional development and contributing to the development of the scientific workforce.<br/><br/>In more technical terms, the project will concern itself with three interrelated areas: BPS Geometry, Singularities, and String Theory.  BPS states are certain supersymmetric states which play a fundamental role in many supersymmetric physical theories.  Geometric techniques will be applied to advance the theory of the associated BPS invariants and their refinements, including orientations on the derived category of coherent sheaves on a Calabi-Yau threefold, Fourier-Mukai transforms as global symmetries of physical theories, a new theory of log BPS invariants, and advancing the connection between Bridgeland stability in mathematics and Pi-stability in physics.   The geometric study of singularities is incorporated into this project in at least two ways: canonical threefold singularities can be used to engineer 5 dimensional superconformal field theories, and certain codimension 2 singularities can be used to engineer gauge theories analogous to the Hitchin system.    Proposed research in string theory proper includes a more careful analysis of the holomorphic anomaly equation with particular attention to the Principal Investigator's earlier work on BPS invariants of elliptic fibrations and Jacobi forms.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1421918","NeTS: Small: Impact of Wireless Network Characteristics on Distributed Computation","CNS","Networking Technology and Syst","10/01/2014","07/07/2018","Haitham Hassanieh","IL","University of Illinois at Urbana-Champaign","Standard Grant","Thyagarajan Nandagopal","09/30/2019","$474,680.00","","haitham@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","7363","7923","$0.00","Wireless networks have current and future applications in many domains, including emergency response and rescue, monitoring and surveillance, distributed sensing, swarm robotics, and smart grids. In such distributed systems, wireless networks are useful to allow the different agents in the system to communicate and jointly coordinate their activities. This project investigates design of efficient algorithms for implementing the distributed primitives while taking into account the properties of the communication network. Coordination primitives of interest include consensus, fault-tolerant broadcast, and distributed optimization. For instance, the consensus primitive allows the different agents to agree on a common course of action, as a function of potentially different actions suggested by different agents. <br/><br/>The scope of this project is at the intersection of communication and computing. The project investigates the impact of wireless network characteristics such as error-prone links, dynamic topology, broadcast medium, and capacity constraints, on the design and performance of algorithms for important distributed computation problems. Two classes of algorithms are of interest, namely, iterative algorithms and unconstrained algorithms. Iterative algorithms have a simple iterative structure, and they maintain a small amount of state and require only limited information about the underlying network topology. Unconstrained algorithms utilize more information about the network, and can achieve better performance. Thus, iterative and unconstrained algorithms achieve different trade-offs between complexity and performance. The goals of the project include investigation of the impact of topology control, resource management, and dynamic adaptation on the performance of the distributed algorithms. The project will improve the understanding of how robust distributed algorithms can be designed for practical wireless networks. The project will involve undergraduate and graduate students. The students will gain valuable experience working on distributed computing problems that are relevant in a variety of applications."
"1653118","CAREER: Integrated Design of Intelligent Structures with Tailored Distributed Damping","CMMI","EDSE-Engineering Design and Sy, CAREER: FACULTY EARLY CAR DEV, ENGINEERING DESIGN AND INNOVAT","05/01/2017","06/26/2018","James Allison","IL","University of Illinois at Urbana-Champaign","Standard Grant","Richard Malak","04/30/2022","$516,000.00","","jtalliso@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","072Y, 1045, 1464","067E, 068E, 073E, 1045, 116E, 9178, 9231, 9251","$0.00","This Faculty Early Career Development (CAREER) Program research project aims to investigate a fundamentally new approach for designing intelligent structures for vibration and motion control, create new numerical design strategies, and to generate a foundational understanding for how best to design this new class of intelligent structures. Existing intelligent structures use integrated sensors and actuators, such as piezoelectric materials, distributed across the surface or interior of a flexible elastic material to control dynamic behavior. Here embedded viscoelastic materials (VEMs) are introduced to overcome current performance limitations. Incorporating VEMs is challenging because 1) engineers cannot rely on past experience to design this unprecedented system, and 2) accurate VEM models are computationally expensive. Here new integrated design optimization strategies will be used to accelerate generation of design knowledge for this new type of intelligent structure, and to reduce computational expense. Numerical and physical experiments will center on application to precision pointing for space-based telescopes. More precise pointing has the potential to enhance significantly scientific data gathering, including search for exoplanets. These advances also have potential to advance other domains where ultra-quiet structural stability or precision motion control is critical (e.g., manufacturing, robotics, and defense). Education and outreach components of this CAREER project involve the creation of unique hands-on activities that allow K-12 and undergraduate students to experience the value of design automation tools. These are enhanced by collaborations with the ""Girls do Science"" program at the Orpheum Children's Museum and a CubeSat project with NASA's Jet Propulsion Laboratory.<br/><br/>Intelligent structures (IS) have been studied extensively, but primarily for active damping as opposed to motion control, and have largely avoided incorporation of spatially distributed VEMs for damping. Inclusion of VEMs and extension to motion control could help achieve new performance levels, but introduces a profound design challenge as no design history, validated design guidelines, or expert intuition exist. Current IS technology utilizes spatially distributed control actuation to tailor dynamic behavior. Recent work has combined control tailoring with distributed geometric elastic substructure design. A remaining obstacle is control of high-order structural modes in practical implementations, and is addressed here via strategically distributed VEMs to damp high-order modes passively. VEM distribution can be varied spatially to synergize with elastic material and control distribution. This enhances design flexibility, but this adds a new level of complexity. A new concept for integrated dynamic system design optimization where surrogate models of the state space derivative function are constructed and improved adaptively is planned. This capitalizes on the intrinsic properties of dynamic systems for numerical efficiency. VEMs can be modeled accurately, but with great computational expense, using high-order ordinary differential equation (ODE) approximations. The new derivative function surrogate modeling (DFSM) strategy is posited to produce high-accuracy VEM modeling using efficient low-order ODEs with state-dependent parameters. DFSM adjusts parameter mappings adaptively to improve accuracy, which supports efficient low-order computation. After thorough study of DFSM for damped IS design, DFSM will then be used for rapid design exploration and systematic generation of design data. Machine learning strategies will then be used to identify patterns and relationships within this data. An iterative inductive process will be used to identify possible design guidelines from these results, such as preferred distributed shape relationships or sensor/actuator/VEM placement guidelines. Additional numerical design studies will be used to validate/refine design guidelines."
"1600650","Mappings and Measures in Sub-Riemannian and Metric Spaces","DMS","GEOMETRIC ANALYSIS, ANALYSIS PROGRAM","07/01/2016","05/29/2018","Jeremy Tyson","IL","University of Illinois at Urbana-Champaign","Continuing grant","Edward Taylor","06/30/2019","$269,784.00","","tyson@math.uiuc.edu","1901 South First Street","Champaign","IL","618207406","2173332187","MPS","1265, 1281","","$0.00","The goal of this project is to investigate geometry and analysis in spaces with rough or fractal structure.  The project focuses especially on spaces which are poorly described by classical Euclidean language, such as fractals and sub-Riemannian spaces.  The latter occur as mathematical models for problems in robotics, neurobiology, celestial mechanics and other physical systems.  In each of these models, the underlying geometry is inherently nonsmooth. The proposed research will consequently contribute to developing the mathematical framework which simultaneously underlies a variety of physical applications. On the geometric side, nonsmooth notions of curvature will be studied.  Curvature is a fundamental concept in modern geometry.  For instance, general relativity predicts that curvature is the primary geometric feature of space responsible for gravity.  Nonsmooth generalizations of curvature and their relationship to the structure of measures will also be studied.  Measure theory is a wide-ranging mathematical generalization of fundamental concepts of length, area, and volume.  Finally, analysis refers to the dynamic properties of transformations acting between spaces. Since the classical Newton--Leibniz theory of the derivative is not well-adapted to transformations of nonsmooth spaces, there is currently significant interest in developing a new analytic toolkit to extend the machinery of calculus beyond its usual context.  The principle investigator will continue to train graduate students, postdocs and early-career researchers.  Results of this research program will be disseminated via talks at conferences and workshops, publication of journal articles, and exposition for a general mathematical audience.  The PI is currently coauthoring a graduate textbook on analysis in nonsmooth spaces.  The ongoing preparation of this book will be coordinated with advances in the field, including those obtained as part of this research program.<br/><br/>The project concerns the geometry of measures and submanifolds in, and mappings between, sub-Riemannian manifolds.  Three coordinating themes will be considered.  The first set of problems concerns density of measures and the geometry of submanifolds.  The main goal is a sub-Riemannian analog of a celebrated theorem of David Preiss characterizing rectifiability (a measure-theoretic notion of smoothness) via densities.  This line of investigation will extend to the sub-Riemannian setting some fundamental aspects of Euclidean geometric measure theory tied to notions of curvature for submanifolds.  The primary methodology for this investigation involves the approximation of sub-Riemannian spaces by Riemannian spaces, and an analysis of the limiting behavior of geometric quantities in the Riemannian approximations.  The second theme concerns iteration of conformal and quasiregular mappings.  Such iterative schemes provide a basic combinatorial model for fractal objects. They arise naturally in both hyperbolic geometry and number theory.  Building on his previous work for similarity mappings, the principle investigator will extend the analysis to conformal mappings.  The goal is a detailed description of the geometry of self-conformal limit sets in sub-Riemannian spaces and natural measures on such sets. Finally, the principle investigator will study the type problem for sub-Riemannian quasiregular mappings. The goal here is to understand both the flexibility of quasiregular mappings as well as inherent geometric obstructions to their construction.  The principle investigator will also investigate new constructions of Sobolev mappings inducing optimal measure and dimension distortion, as well as criteria for the density of Lipschitz mappings in spaces of Sobolev mappings with sub-Riemannian targets.  The principle investigator will take advantage of his prior expertise in all of the aforementioned areas, as well as the latest advances in related fields, to pursue answers to the proposed problems.  The proposed research will have a broad impact; it addresses a wide range of questions at the intersection of different mathematical areas. The principle investigator will use this broad framework to identify specific problems suitable for beginning graduate students and postdocs."
"1526960","NRI: Active Tendon-Driven Orthosis for Prehensile Manipulation After Stroke","IIS","National Robotics Initiative","08/01/2015","08/12/2015","Matei Ciocarlie","NY","Columbia University","Standard Grant","Reid Simmons","07/31/2019","$599,386.00","Joel Stein","mtc2103@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","8013","8086","$0.00","This project develops wearable and functional hand orthoses for stroke survivors, to act as both assistive and training devices. For daily living, such a device could provide assistance with manipulation tasks, increasing the sense of control and the ability to live independently. For rehabilitation, a wearable orthosis could enable functional training on real-world manipulation tasks, extend training beyond the small number of sessions performed in a clinical setting, and provide distributed training during the course of daily activities rather than block training in designated therapeutic sessions. From a healthcare perspective, this work will enable a shift from devices used in a clinic under medical supervision towards unobtrusive functional orthoses used during daily life. From an engineering perspective, it will advance towards a new class of active wearable systems, controllable by natural movement or similarly intuitive interfaces. <br/><br/>New approaches will be required to build a device that is simultaneously dexterous (for complex manipulation), non-intrusive (for daily living) and intuitive to control. To achieve this, we investigate ways to assist joint movement using a network of artificial tendons routed on the surface of the hand and arm, without adding large structural components such as an exoskeleton. A key tenet of our approach is that a hand orthosis can provide meaningful assistance with daily manipulation tasks even when using a number of actuators far smaller than the number of joints in the hand. We will also investigate multiple control methods, including unimanual operation (where endogenous movement of the paretic limb is detected and enhanced) and bilateral operation (where movement of the less affected limb is used to generate control signals for the paretic one)."
"1409658","Programmable and Emergent Structures in Soft Matter: Chirality, Polarity, and Auto-Origami","DMR","CONDENSED MATTER & MAT THEORY","09/01/2014","07/18/2016","Robin Selinger","OH","Kent State University","Continuing grant","Daryl W. Hess","08/31/2019","$375,000.00","Jonathan Selinger","rselinge@kent.edu","OFFICE OF THE COMPTROLLER","KENT","OH","442420001","3306722070","MPS","1765","7433, 7573, 9216","$0.00","Non-technical Summary:<br/>This award provides support for theoretical studies of responsive liquid crystal polymers, a form of plastic that spontaneously changes shape under heating or cooling. Rod-shaped liquid crystal molecules bonded to the polymer's main chains are disordered in orientation at high temperature but align at low temperature, inducing the polymer chains to extend in a parallel direction, and as a result the material stretches when cooled. Some materials containing light-sensitive dyes also change shape in response to illumination. A sample prepared with a non-uniform imposed pattern of local molecular orientation, a process known as blueprinting, shows complex shape evolution as the induced stress/strain is not uniform. The blueprinted pattern thus encodes a complex trajectory of movement from an initial state, e.g. a flat thin film, to a final state that is folded, curved, or twisted, a form of programmed auto-origami. Computer simulation studies of this process will explore the mathematical relationship between blueprinted structures and the resulting shape change. These materials have potential application in robotics, light-driven mechanical devices, touch displays, biomedical devices, and switchable surface textures. Related studies will examine shape change, pattern formation, and phase behavior in lipid membranes and liquid crystals. Outreach efforts, including research internships for 60+ high school students and annual science fair for six school districts, attract students to STEM careers and aim to improve the diversity of the STEM workforce.<br/><br/>Technical Summary:<br/>This award supports theoretical/computational research and education in soft matter physics. It combines computer simulation and fundamental theory to investigate mechanisms of microstructural/shape evolution and pattern formation in soft matter. The proposed theory/modeling studies of orientationally ordered lipid membranes and nematic solids are united by themes of differential geometry, curvature, topological defects, complex ordering and response, topology, and self-assembly. The principal problems to be investigated are: (1) Auto-origami: nematic solids as programmable, stimuli-responsive materials; (2) Lipid membranes: coupling of topological defects and curvature; (3) Phase transitions in liquid-crystal elastomers: kinetic evolution of polydomain structures; (4) Flexoelectricity in liquid crystals: formation of complex modulated phases. In all of these cases, the PI's will collaborate with experimental scientists to compare predictions with experiments on physical and biological systems.<br/><br/>This research is connected to fundamental problems in self-assembly, nonlinear elasticity, topological defects, and differential geometry.  Potential applications of outcome of this research could include soft actuators, shape control of lipid vesicles for drug delivery, self-assembly of vesicles for photonic crystals, and new liquid-crystal display technologies and switchable surface textures."
"1664218","Theoretical Investigations of Dynamic Aspects of Protein-DNA Interactions","CHE","Molecular Biophysics, Theory, Models, Comput. Method","08/01/2017","07/25/2018","Anatoly Kolomeisky","TX","William Marsh Rice University","Standard Grant","Susan Atlas","07/31/2020","$458,475.00","","tolya@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","MPS","1144, 6881","5905, 5918, 5946, 7433, 7465, 8007, 9216, 9263","$0.00","Anatoly Kolomeisky of William Marsh Rice University is supported by an award from the Chemical Theory, Models and Computational Methods Program in the Chemistry Division to theoretically investigate interactions between two major classes of biological molecules: DNA and proteins. This project is co-funded by the Molecular Biophysics Program in the Molecular and Cellular Biosciences Division.  DNA encodes the genetic plans for all living organisms. Proteins read this information and implement it in the cell. Proper timing is a key aspect of protein-DNA interactions due to the dynamic nature of living cells. If the proper interactions do not occur at the right time, the entire biological system can fail catastrophically. Understanding protein-DNA interactions can lead to new insights for drug discovery and contribute to technological breakthroughs such as bio-inspired or biomimetic materials. Professor Kolomeisky is combining theoretical modeling, simulation, and bioinformatics to understand the molecular foundations of the temporal dependence and efficiency of protein-DNA interactions. Specific questions include: how proteins identify the correct DNA binding sites in performing their functions; the effects of DNA loop formation on multi-site proteins that can bind at different DNA sites; mechanisms of DNA editing using the newly-discovered CRISPR associated protein technology; and understanding the tradeoff between strong binding and fast recognition in determining how proteins bind to DNA. Close collaborations with experimental and theoretical groups will enable testing of the new models, and promote a deeper understanding of these complex natural processes.  Professor Kolomeisky is providing opportunities for high school and undergraduate students from underrepresented groups to participate in this research and gain valuable training and experience for their future careers. Outreach activities include a high-school scientific projects competition, co-organization of an undergraduate chemistry research symposium, public lectures delivered at venues such as the Rice Science Caf, and continued collaboration with the Rice robotics systems lab to create online games based on the results of this research.<br/><br/>This project focuses on developing a theoretical program to analyze the temporal dependence of protein-DNA interactions. These fundamental interactions are analyzed using a variety of theoretical tools including discrete-state stochastic models, first-passage analysis, bioinformatics methods and extensive Monte Carlo computer simulations. The advantage of this multiscale approach is that it takes into account in a consistent manner the major physical and chemical properties of DNA and proteins interacting in the complex cellular environment. In collaboration with experimental research groups, theoretical predictions are tested using various techniques, including single-molecule spectroscopy, chemical kinetics, and bioinformatic analysis. An outreach program developed by Professor Kolomeisky provides the opportunity for local high-school students and undergraduate students from underrepresented minority groups to participate in scientific research in an academic setting. The project also highlights the benefits of science for society by directly presenting scientific findings to the local community in the informal setting of caf discussions, as well as communicating with science writers in local newspapers and participating in scientific Internet blog discussions. The broader impacts of this project include a multidisciplinary training program for young researchers of different levels that will prepare them better for future technological and industrial challenges."
"1514116","CSR: Medium: Collaborative Research: SparseKaffe: high-performance, auto-tuned, energy-aware algorithms for sparse direct methods on modern heterogeneous architectures","CNS","Computer Systems Research (CSR","09/01/2015","09/01/2017","Sanjay Ranka","FL","University of Florida","Continuing grant","M. Mimi McClure","08/31/2019","$395,454.00","","ranka@cise.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","7354","7924","$0.00","The use of sparse direct methods in computational science is ubiquitous. Direct methods can be used to find solutions to many numerical algebra applications, including sparse linear systems, sparse linear least squares, and eigenvalue problems; consequently they form the backbone of a broad spectrum of large scale applications.  In the widely used and actively growing University of Florida Sparse Matrix Collection, there are problems from structural engineering, computational fluid dynamics (CFD), computer graphics/vision, robotics/kinematics, theoretical and quantum chemistry, power networks, social networks, document networks, among others.<br/> <br/>The SparseKaffe project team will develop algorithms and software for high-performance parallel sparse direct methods with irregular and hierarchical structure that can exploit clusters of Hybrid Multicore Processors to achieve orders of magnitude gains in computational performance, while also paying careful attention to the energy requirements.  This requires the development of novel and innovative algorithms for scheduling, energy minimization, and memory management; development of novel user-guided autotuning algorithms that exploit different hardware characteristics; and designing a common infrastructure for creating auto-tuned software.<br/> <br/>The use of sparse direct methods is extensive, with many of the relevant science and engineering application areas being pushed to run at ever higher scales.  The team expects SparseKaffe solvers to be able deliver not only high performance to the applications that use them, but also the energy efficiency that they will increasingly demand. The team will also create a course, and a corresponding set of course modules, to teach students how to develop algorithms and software that deliver orders of magnitude gains in performance on clusters of hybrid multicore processors."
"1454276","CAREER: A Design Methodology for Bio-Inspired Soft Mechanical Systems","CMMI","ENGINEERING DESIGN AND INNOVAT","02/01/2015","01/09/2015","Girish Krishnan","IL","University of Illinois at Urbana-Champaign","Standard Grant","Richard Malak","01/31/2020","$500,000.00","","gkrishna@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","1464","067E, 068E, 1045, 8024, 8043","$0.00","This Faculty Early Career Development (CAREER) Program grant will pioneer a systematic synthesis, analysis and manufacturing framework to realize soft mechanical systems. Soft mechanical systems are static and dynamic structural embodiments that do not contain rigid components made of metals or plastics, conventional actuators such as motors, or interfaces such as joints and couplings. They are instead made up of stretchable skins, tissue-like appendages, fibers and fluids, and are inspired by around 90% of nature's animal species that lack a rigid backbone, such as an octopus arm. The unique feature of these systems is that they are flexible yet strong enough to bear large loads. Unfortunately, these systems have so far not been widely used, because a systematic design framework that can guide their physical realization does currently not exist. This award supports fundamental research that enables such a design framework, in which a soft mechanical system can be synthesized through a systematic combination of simple building blocks with pre-determined attributes. The resulting devices are adaptive, lightweight, energy-efficient and inherently safe for human interaction. They will directly impact the emerging fields of rehabilitation robotics, manufacturing automation, space exploration, and surgery. Furthermore, the award will build on the overarching theme of drawing analogies between nature and engineering to increase creative thinking and enhance problem solving abilities in future engineers, while emphasizing broadening participation of underrepresented groups in research.<br/><br/>The key challenge in formulating a generalized design framework for soft mechanical systems involves negotiating the coupled nonlinear interactions among its structural constituents, namely, fluids, stretchable envelopes, and reinforced fibers. The design framework relies on reduced order models to capture these interactions and characterize the kinematic and kinemato-static behavior of a generalized soft mechanical building block. The models can be extended to any structure or mechanism under quasistatic interaction with enclosed fluids. Using these models, a design framework will be developed to synthesize a system, where several building blocks with varying attributes are combined in a series or parallel architecture based on rules and guidelines adapted from traditional machine design, such as constraint matching and geometrically exact kinematics. The design framework will also incorporate optimization methods to refine the system based on novel robustness metrics. Successful realization of the design framework will lead to a reconfigurable stiffness system for use in orthotic braces and a self-knotting active rope for use in surgical suturing and active tethering applications."
"1740248","E2CDA: Type I: Collaborative Research: Energy-efficient analog computing with emerging memory devices","CCF","Energy Efficient Computing: fr, SOFTWARE & HARDWARE FOUNDATION","09/15/2017","06/27/2018","Qiangfei Xia","MA","University of Massachusetts Amherst","Continuing grant","Sankar Basu","08/31/2020","$230,025.00","","qxia@umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","015Y, 7798","7798, 7945, 8089, 9251","$0.00","The main goal of this project is to develop analog computing circuits that will greatly exceed their digital counterparts in energy-efficiency, speed, and density by employing emerging nonvolatile memory devices. Though analog circuits have been around for a long time, their applications in computing have been rather limited, largely due to the lack of efficient implementations of analog weights. This impediment could be overcome now due to the rapid progress in the emerging nonvolatile memory devices, such as metal-oxide memristors, which are the focus in this project. The analog memory functionality of memristors, combined with high retention and sub-10-nm scaling prospects, might for the first time enable extremely fast and energy-efficient analog implementations of many core operations, such as vector-by-matrix multiplication, which are central to many existing and emerging future applications such as internet-of-the-things and sensor networks, robotics, and energy efficient neuromorphic systems.  The results of the proposed research will be integrated into educational curriculum and will help to train material science and electrical engineering students of all levels in this exciting field.<br/><br/>The main caveat of the considered analog circuits is their limited operation accuracy, primarily due to the noise and variability in memory devices. The mitigation of this challenge by several means will be one of the main focuses of the project, and will be addressed with highly-interconnected research effort across device, circuit, and architectural layers. At the device level, detailed electrical characterization of analog operation and ways to improve it via material engineering, optimization of electrical stress, and development of efficient tuning algorithms to cope with device variations will be explored. Guided by experimentally-verified device models, the design of several representative analog computing circuits will be optimized. Circuit modeling tools will be developed to capture rich design trade offs in area, speed, energy efficiency, and precision, calibrated on experimental results from wafer-scale integrated memristor circuits, and used for detailed comparison with state-of-the-art digital counterparts. Finally, accurate circuit models will guide exploration of circuit architectures that mitigate limitations of analog computing and assist with detailed system level simulations."
"1724282","S&AS: INT: Inference, Reasoning, and Learning for Robust Autonomous Driving","IIS","S&AS - Smart & Autonomous Syst","09/01/2017","07/27/2017","Mark Campbell","NY","Cornell University","Standard Grant","David Corman","08/31/2021","$1,398,587.00","Kilian Weinberger","mc288@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","039Y","046Z","$0.00","While research in autonomous driving has made great strides in recent years, fully autonomous cars are still a distant goal, primarily because of a lack of robustness. Current autonomous cars cannot drive on new roads, or roads that have changed substantially (such as after an earthquake), or when there is a GPS or data outage such as in parking garages, urban cities and tunnels. Importantly, humans are good at all of this: Humans can drive without detailed maps or high precision GPS/IMU sensors, and typically require only a small amount of sparse information for guidance, and their performance typically gets better over time through learning. Using the ""intelligent"" human driver as a guide, the planned research will develop algorithms that can perceive and make predictions about a scene in real time with measurable confidence, particularly as the scene is closer to the car. New robustness characteristics will be achieved through the ability to detect and overcome mistakes, both in the near term (real time) and long term (learning). The planned algorithms will be designed and validated in a way to enable an inherent robustness not currently available in autonomous driving, and fast adoption by the community. This project is aligned with NSF's Intelligent Physical Systems (IPS) because the algorithms will require cognizant and reflective capabilities in a knowledge-rich environment. Additionally, outputs of this project will impact robotics, machine learning and cyber-physical systems. Educationally, data logs will be disseminated to enable open ended student projects in the community, and undergrad and high school students will collaborate with the research team to integrate sensors, perform experiments and data collection, and disseminate data logs to the community. <br/><br/>Led by researchers in Mechanical and Aerospace Engineering, and Computer Science at Cornell University, the goal of this research is to develop, integrate and validate theory and algorithms to enable robust and persistent autonomous driving. This project is aligned with NSF's Intelligent Physical Systems (IPS) because the algorithms will require cognizant and reflective capabilities in a knowledge-rich environment. The technical approach will develop a robust perceptual pipeline for detection, scene estimation, prediction, and anomaly/mistake detection and learning; integrate the algorithms into Cornell's autonomous car software framework and validate the components and system in a series of experimental scenarios to enable their faster adoption by the community. Key component level algorithms to be developed include anytime deep learning detectors with quantifiable performance; multiple hypothesis reasoning with memory attributes; generalized probabilistic anticipation algorithms to mimic a human's mental model of a dynamic scene; and anomaly/mistake detection coupled with online learning. Outcomes will include open source algorithms and data logs; publications, conferences, workshops; data logs for open ended projects in courses and across the community; and undergrad and high school education and diversity programs in the interdisciplinary area of autonomous driving."
"1730158","CI-New: Cognitive Hardware and Software Ecosystem Community Infrastructure (CHASE-CI)","CNS","Computer Systems Research (CSR, COMPUTING RES INFRASTRUCTURE","10/01/2017","05/31/2018","Larry Smarr","CA","University of California-San Diego","Standard Grant","Sandip Kundu","09/30/2020","$1,199,998.00","Tajana Rosing, Ilkay Altintas, Thomas DeFanti, Kenneth Kreutz-Delgado","lsmarr@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","CSE","7354, 7359","7354, 7359","$0.00","This project, called the Cognitive Hardware And Software Ecosystem Community Infrastructure (CHASE-CI), will build a cloud of hundreds of affordable Graphics Processing Units (GPUs), networked together with a variety of neural network machines to facilitate development of next generation cognitive computing. This cloud will be accessible by 30 researchers assembled from 10 universities via the NSF-funded Pacific Research Platform. These researchers will investigate a range of problems from image and video recognition, computer vision, contextual robotics to cognitive neurosciences using the cloud to be purpose-built in this project. <br/><br/>Training of neural network with large data-sets is best performed on GPUs. Lack of availability of affordable GPUs and lack of easy access to the new generation of Non-von Neumann (NvN) machines with embedded neural networks impede research in cognitive computing. The purpose-built cloud will be available over the network to address this bottleneck. PIs will study various Deep Neural Network, Recurrent Neural Network, and Reinforcement Learning Algorithms on this platform."
"1664865","Combinatorics, Algebra, and Topology of Stanley-Reisner Rings","DMS","Combinatorics","07/01/2017","06/06/2018","Isabella Novik","WA","University of Washington","Continuing grant","Tomek Bartoszynski","06/30/2020","$206,096.00","","novik@math.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","MPS","7970","","$0.00","Algebraic and geometric combinatorics, and, in particular, the study of discrete objects that approximate high-dimensional shapes, is a rapidly developing field that has close connections to optimization, computer science, engineering, statistics, and mathematical biology. For instance, in engineering and computer science, e.g., robotics, one often needs to describe a space of ""allowed motions."" This space can usually be approximated by a collection of points, segments, triangles, pyramids, and higher dimensional analogs of pyramids nicely glued together -- an object known as a simplicial complex. A simplicial complex, in turn, can be encoded in a certain algebraic structure that involves polynomials. Study of this algebraic structure led to several spectacular developments in the field. This research project aims to deepen understanding of various aspects of simplicial complexes and the corresponding algebraic structures. <br/><br/>The project aims to deepen our understanding of algebraic, combinatorial, and topological invariants of simplicial complexes through the study of their face numbers and Stanley-Reisner rings. Specifically, research on this project will attack fundamental questions related to (1) tracing various topological invariants (beyond the usual simplicial homology) in the Stanley-Reisner rings, (2) extending results on face numbers and Stanley-Reisner rings of triangulations of manifolds to the setting of normal pseudomanifolds, and (3) studying face numbers of simplicial complexes with an additional structure such as balancedness or symmetry. Thus, this project seeks to vastly improve our understanding of Stanley-Reisner rings (and modules) of complexes, especially when they are not Cohen-Macaulay or even not Buchsbaum. Consequently, it is expected that results of the project will impact not only algebraic and geometric combinatorics, but also commutative algebra, discrete geometry, and potentially even algebraic topology."
"1711395","Collaborative Research:   Wideband Multi-Beam Antenna Arrays: Low-Complexity Algorithms and Analog-CMOS Implementations","ECCS","COMMS, CIRCUITS & SENS SYS","07/01/2017","06/21/2017","Soumyajit Mandal","OH","Case Western Reserve University","Standard Grant","Jenshan Lin","06/30/2020","$175,025.00","","sxm833@case.edu","Nord Hall, Suite 615","CLEVELAND","OH","441064901","2163684510","ENG","7564","105E","$0.00","The Federal Communications Commission recognizes the need for the wireless industry to explore the 28-95 GHz millimeter-wave (mm-wave) bands where wider bandwidth is available, and future allocations may reach above 100 GHz. This explosion of mm-wave bandwidth opens up applications in 5G wireless systems spanning communications, localization, imaging, and radar. This project addresses fundamental scientific and engineering challenges in generating multiple parallel radio ""beams"" at mm-wave frequencies. A radio beam refers to a directional channel that establishes point-to-point contact for wireless communications and remote sensing. The ability to form a large number of such radio beams with high bandwidths will tremendously improve the performance for next-generation wireless systems. For example, multiple beams are essential for achieving the orders-of-magnitude increases in capacity, data rate, and geographical penetration required by the explosive growth in wireless applications. Moreover, they are important for both transmitters and receivers.  The project will draw on an analogy between the spatial Fourier transform and a thin optical lens to obtain multiple wideband beams. Unlike lens-antenna-based approaches in the literature, this project will use a planar aperture antenna in conjunction with analog integrated circuits to generate many wideband mm-wave beams subject to power and size constraints. The proposed highly integrated approach is attractive for mobile applications including 5G smart devices, the internet of things, mobile robotics, and unmanned aerial vehicles, and other emerging applications focused on mm-waves. In addition to scientific research, the project will ensure that both minority students and female students will be mentored towards careers in mathematics, communications, as well as microwave circuits and systems. Educational materials will be developed for teaching array signal processing, microwave integrated circuit (IC) design, and ultra-high-speed analog signal processing. Principal Investigators (PIs) Madanayake and Mandal will organize a mini-conference to enhance microwave and mm-wave research activities at nearby universities in northeast Ohio. PI Madanayake will collaborate with co-PIs towards mentoring underrepresented students towards careers in Science, Technology, Engineering, and Math (STEM).  The proposal team is uniquely placed to promote STEM topics spanning both electrical engineering and mathematics domains. The project will lead to education of the wider community on the importance of cross-disciplinary collaboration. Further, the team will strive to show the importance of learning deeper math topics towards success in technology and engineering careers.<br/><br/><br/>A multi-beam array receiver is deeply difficult to realize in IC form due to the underlying complexity of its signal flow graph. In this work, mathematical methods based on the theories of i) sparse factorization of structured complex matrices, and ii) approximate transforms are proposed to solve this problem. The resulting matrices are realized with multi-GHz bandwidths using analog ICs. One of the intellectual contributions is the development of efficient wideband beamformers based on sparse factorizations of delay Vandermonde matrices (DVM). This DVM algorithm solves the longstanding ""beam squint"" problem, i.e., the fact that the beam direction changes with input frequency, making true wideband operation impossible. Another is the derivation of transform matrices with specified properties that approximate the discrete Fourier transform (DFT). Such approximate transforms are not subjected to the known computational complexity bounds of the exact DFT, and approximate-DFT-based multi-beamformers can in fact be efficiently implemented using current-mode analog ICs. Finally, precision circuit design, digital calibration, built-in self-test, and other methods will be explored for efficiently realizing the proposed multi-beamforming networks in analog IC form."
"1632211","EarthCube RCN IS-GEO: Intelligent Systems Research to Support Geosciences","ICER","ROBUST INTELLIGENCE, EarthCube","08/15/2016","08/23/2016","Suzanne Pierce","TX","University of Texas at Austin","Standard Grant","Eva E. Zanzerkia","07/31/2019","$299,998.00","","spierce@tacc.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","GEO","7495, 8074","7433","$0.00","This project will foster collaborations between computer scientists and geoscientists that will advance research in both areas.  Geoscience problems are complex and often involve data that changes across space and time. Frequently geoscience knowledge and understanding provides valuable information and insight for problems related to energy, water, climate, agriculture, mineral resources, and our understanding of how the Earth evolves through time. Simultaneously, many grand challenges in the geosciences cannot be addressed without the aid of computational support and innovations. Intelligent and Information Systems (IS) research in computer science includes a broad range of topics and computational methods such as knowledge representation, information integration, machine learning, robotics, adaptive sensors, and intelligent interfaces. IS research has an important role to play in accelerating the speed of scientific discovery in geosciences and thus in solving challenges that cannot be addressed by other means. Similarly, many aspects of Geosciences (GEO) research pose novel large-scale problems for IS researchers to improve and validate their methods. Intelligent Systems for Geosciences (IS-GEO) represent an emerging community of interdisciplinary researchers producing fundamental new capabilities for understanding Earth systems and how the application of IS technologies can cultivate key new developments in both fields.<br/><br/>The EarthCube Research Coordination Network for Intelligent Systems for Geosciences (IS-GEO RCN) will catalyze collaborations to enable advances in our understanding of Earth systems through innovative applications of intelligent and information systems to fundamental geosciences problems. The goal of the IS-GEO RCN is to leverage expertise and generate interactions between both the geosciences and computing sciences communities to provide advanced scientific capabilities. To enable the network, the IS-GEO RCN will host meetings and other activities that: (1) foster an active and broad-based community across GEO and IIS areas; (2) identify barriers to research, such as terminology differences among the disciplines involved and highlight knowledge gaps that hinder collaboration across the disciplines; (3) establish and enhance communication channels between GEO and IS researchers; (4) defining grand challenges in geosciences that are well suited to IS techniques; and (5) encourage robust, long-term collaborations.  Furthermore, the educational component aims to identify new approaches to teaching students in this new interdisciplinary area, seeking to raise a new generation of scientists that are better able to apply IS methods and tools to geoscience challenges of the future. By providing avenues for IS and GEO researchers to work together the IS-GEO RCN will serve as both a point of contact, as well as an avenue for educational outreach across the disciplines for the nascent community of research and practice.<br/> <br/>The initial efforts are focused on connecting the communities in ways that help researchers understand opportunities and challenges that can benefit from IS-GEO collaborations. The uncertain, heterogeneous and disparate nature of geoscience data paired with recent IS advances and increases in observational data offer unique opportunities for new approaches and discoveries through joint efforts. The IS-GEO RCN will jumpstart interdisciplinary research collaborations in this emerging new area so that progress across both disciplines can be accelerated."
"1719558","Collaborative Research: Tractable Non-Convex Optimization","DMS","COMPUTATIONAL MATHEMATICS","07/01/2017","07/20/2018","Nicolas Boumal","NJ","Princeton University","Continuing grant","Leland M. Jameson","06/30/2020","$113,048.00","","nboumal@math.princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","MPS","1271","9263","$0.00","Practitioners in most fields of science and engineering invest a substantial amount of time developing appropriate mathematical models for the complex questions they set out to answer. A model is deemed appropriate for a given task if it meets two potentially conflicting criteria simultaneously. On the one hand, it must be sufficiently faithful to reality (and as such, sufficiently complex) so as to capture the essential properties of the object of study. On the other hand, the model must be simple enough that it can be practically used to answer relevant questions. This second requirement is computational in nature. In effect, the modeler aims to reduce a particular question to a mathematical problem known to be practically solvable, or tractable.  For the most part, tractability ensures that the problem can be solved using known algorithms, and as a result the status quo has been that problems that are not tractable should be avoided for applications. Yet, scores of problems in science and engineering are most naturally modeled within a framework that has been previously determined to be non-tractable. This research project aims to develop theory and algorithms to identify and solve non-convex optimization problems, typically regarded as non-tractable. The goal is to provide practitioners with an extended modeling toolbox, allowing them to capture key aspects of our complex reality.<br/><br/>This project targets optimization problems that are tractable despite non-convexity. This can come about in a number of ways. The non-convexity may be structurally benign, in that the problem actually does not have local optima at all. This project explores such structural effects in the context of Burer-Monteiro relaxations. Alternatively, the problem may present numerous local optima in some instances, yet present only good quality ones on instances of the problem encountered in practice. This motivates the analysis of non-convex optimization problems in a non-adversarial setting, in many cases more relevant to practice than classical adversarial analyses. This project investigates some model problems of this nature. Here too, salvation can come in different forms: It is possible that when data is good enough (for example, if the signal to noise ratio is sufficient), local optima cannot exist; or, it is possible to initialize the algorithms close enough to the global optimum so that convergence to it is assured; or, even local optima are satisfactory to answer the underlying question. This project explores such situations through applications in community detection in large networks and through phase synchronization, as model problems for understanding challenges in a more general class of problems including, but not limited to, electron cryomicroscopy from structural biology and simultaneous localization and mapping in robotics. A common feature of many tractable non-convex optimization is that they are naturally posed on smooth nonlinear spaces called Riemannian manifolds. As a result, important algorithmic aspects of this project involve developing theory, algorithms, and software for optimization on Riemannian manifolds."
"1656995","CRII: CHS: Investigation of Computer-Mediated Compression as a New Paradigm for Remote Interaction","IIS","CRII CISE Research Initiation","08/15/2017","02/28/2017","Bradley Holschuh","MN","University of Minnesota-Twin Cities","Standard Grant","Ephraim P. Glinert","07/31/2019","$175,000.00","","bth@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","026Y","7367, 8228","$0.00","The focus of this research is on expanding our understanding of, and our ability to enable, remote human-human interaction through novel application of advanced technology, in order to enrich the lives of those with disabilities through computer-mediated devices.  Namely, the functionality and efficacy of computer-mediated compression, a new paradigm of human-human and human-computer interaction, will be explored and evaluated.  Recent advances in compression garment technology have produced dynamic, low-mass, highly mobile, controllable compression garments capable of interfacing wirelessly with remote users.  This technology has the potential to enable new modes of interaction between users separated from one another but who seek to physically interact.  Project outcomes will include: empirical knowledge of the user experience of computer-mediated compression; an assessment of the efficacy of compression as a mode of remote interaction; insights into the usefulness of wearable technology and remote-controlled compression systems in real-world applications; and the creation of multiple functional and remotely controllable garment prototypes, thereby advancing the state of the art in soft-robotics, wearable actuated systems, and functional clothing.  The work has the potential to greatly improve the lives of individuals who use compression as a form of treatment (e.g., those with Sensory Processing Disorder or SPD).  Additionally, the project will be conducted in the Wearable Technology Laboratory at the University of Minnesota, which is primarily comprised of female Apparel Design students; thus, the project will promote interdisciplinary STEM skills in these students while also serving as the basis of a new UMN graduate course on wearable technology.<br/><br/>This investigation will focus on two research topics:  compression as a novel haptic modality or interface, and compression as a mechanism to remotely persuade or physically affect the user (in a positive manner).  The study will proceed in three phases: technology development to produce wirelessly controllable compression garments (e.g., arm band and/or vest) using active materials based on the current state of the art; user testing incorporating bio-signal monitoring, interviews and questionnaires to assess the physical and subjective experience of remotely administered compression; and an application-driven case study based on measured system performance, such as examining computer-mediated compression as a behavioral intervention for individuals with SPD or as a medical tool for enhanced tele-rehabilitation or compression-based treatment."
"1753968","CAREER: Efficient Learning of Personalized Strategies","IIS","ROBUST INTELLIGENCE","08/01/2017","11/01/2017","Emma Brunskill","CA","Stanford University","Standard Grant","James Donlon","05/31/2019","$295,195.00","","ebrun@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","1045, 7495, 9251","$0.00","Online retailers frequently provide tailored product or movie recommendations. But the power of automated personalization, driven by data and statistics, could be far greater: imagine the impact on poverty reduction if all children had a personalized, self-improving tutoring system as part of their education. To realize this vision requires personalization systems that reason about both the immediate impact of a recommended item (e.g. will a learner immediately learn from a video lecture) as well as its longer term impact. For example, a recommended item or intervention may cause a user to change his/her preferences, state of knowledge, or reveal information about the user that was previously unknown. This requires methods for creating personalized strategies: adaptive rules about what decisions to make (whether or which ad to show, which pedagogical activity to provide) in which circumstances to maximize for long term outcomes. <br/><br/>This research involves developing new data-driven, machine learning approaches to construct such personalized strategies for related individuals, and using them towards improving the effectiveness of online mathematics educational systems.  The project frames personalized strategy creation as sequential decision making under uncertainty research. Though there have been many advances in sequential decision making under uncertainty, existing approaches have focused primarily on other application areas, like robotics, and fail to account or leverage for some of the special features that arise when interacting with people. These include that accurate simulation of people is difficult but prior data is often available, and that individuals are often related. This project contributes algorithms for mining existing datasets to create and precisely bound the expected performance of new high-quality strategies and for online policy learning across a series of similar sequential decision making tasks."
"1740352","E2CDA: Type I: Collaborative Research: Energy-efficient analog computing with emerging memory devices","CCF","Energy Efficient Computing: fr","09/15/2017","07/18/2018","Dmitri Strukov","CA","University of California-Santa Barbara","Continuing grant","Sankar Basu","08/31/2020","$640,000.00","Timothy Sherwood, Yuan Xie","strukov@ece.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","CSE","015Y","7945, 8089","$0.00","The main goal of this project is to develop analog computing circuits that will greatly exceed their digital counterparts in energy-efficiency, speed, and density by employing emerging nonvolatile memory devices. Though analog circuits have been around for a long time, their applications in computing have been rather limited, largely due to the lack of efficient implementations of analog weights. This impediment could be overcome now due to the rapid progress in the emerging nonvolatile memory devices, such as metal-oxide memristors, which are the focus in this project. The analog memory functionality of memristors, combined with high retention and sub-10-nm scaling prospects, might for the first time enable extremely fast and energy-efficient analog implementations of many core operations, such as vector-by-matrix multiplication, which are central to many existing and emerging future applications such as internet-of-the-things and sensor networks, robotics, and energy efficient neuromorphic systems.  The results of the proposed research will be integrated into educational curriculum and will help to train material science and electrical engineering students of all levels in this exciting field.<br/><br/>The main caveat of the considered analog circuits is their limited operation accuracy, primarily due to the noise and variability in memory devices. The mitigation of this challenge by several means will be one of the main focuses of the project, and will be addressed with highly-interconnected research effort across device, circuit, and architectural layers. At the device level, detailed electrical characterization of analog operation and ways to improve it via material engineering, optimization of electrical stress, and development of efficient tuning algorithms to cope with device variations will be explored. Guided by experimentally-verified device models, the design of several representative analog computing circuits will be optimized. Circuit modeling tools will be developed to capture rich design trade offs in area, speed, energy efficiency, and precision, calibrated on experimental results from wafer-scale integrated memristor circuits, and used for detailed comparison with state-of-the-art digital counterparts. Finally, accurate circuit models will guide exploration of circuit architectures that mitigate limitations of analog computing and assist with detailed system level simulations."
"1655113","RUI, ABR:  Olfactory Compensatory Plasticity","IOS","ACTIVATION","04/01/2017","03/31/2017","David Coppola","VA","Randolph-Macon College","Standard Grant","Edda (Floh) Thiels","03/31/2021","$452,225.00","","dcoppola@rmc.edu","310 N. Center Street","Ashland","VA","230051502","8047527268","BIO","7713","1228, 9178, 9229","$0.00","The ability of the nervous system to change in response to experience, i.e., to exhibit 'plasticity', is a long-standing topic of inquiry in neuroscience. In particular, the role of ongoing sensory stimulation for the normal development and maintenance of sensory systems is a perennial area of interest.  Knowledge about these processes for the sense of smell lags behind the other senses, not least because of the difficulty in physically controlling an odor stimulus. This project advances our understanding of stimulus-induced changes olfactory processing and other mechanisms of smell, as well as sheds light on the tendency of physiological systems, like olfaction, to operate in a relatively stable equilibrium between interdependent elements, the process known as homeostasis.  The olfactory periphery affords an excellent model where all components of a homeostatic system can be ascertained. Besides advancing our understanding of the sense of smell and sensory plasticity, the studies may suggest design elements for incorporation into chemical detection devices ('electronic noses') with applications in robotics, disease diagnosis, and bomb detection. Integrated with the research project is student-mentoring, participation-broadening, and public outreach through active involvement of undergraduates, including members of underrepresented groups, and the development of an exhibit at a local children's museum. These aspects of the project improve human resources in Science, Technology, Engineering, and Mathematics, and, via the museum, may engage thousands of school students annually. <br/><br/>This project addresses the universal problem of how our senses adjust to long-term changes in the stimulus environment. Such adaptability allows sensory systems to match the dynamic range of their receptors to the array of stimuli in the environment, which can vary dramatically in time and space. Little is known about the cellular mechanisms of these homeostasis-like processes. The Investigator and his colleagues have discovered a phenomenon in the olfactory periphery termed compensatory plasticity that has the signature of such a process. In the olfactory epithelium, odor deprivation causes an up-regulation of the transduction cascade and enhancement of physiological responses that seemingly compensate in low stimulus environments.  The previous work allowed only binary control of the odor environment (i.e., deprivation or no deprivation). In the current project, the responses of the olfactory system to odor stimulation history is examined using olfactometric methods that allow broader control of odor environments, including the type, complexity, concentration, and timing of odor exposure.  The dependent measures include transcriptomic, histological, physiological, and behavior endpoints, allowing a holistic analysis of compensatory plasticity that lays the groundwork for a mechanistic understanding of this process.  Results from these studies advance our understanding of olfactory plasticity as well as illuminate mechanisms of neural plasticity and homeostasis"
"1527232","NRI: Deep Learning Unmanned Aircraft Systems for High-Throughput Agricultural Disease Phenotyping","IIS","National Robotics Initiative","08/01/2015","10/20/2015","Hod Lipson","NY","Cornell University","Standard Grant","Reid Simmons","07/31/2019","$1,149,273.00","Michael Gore, Rebecca Nelson","hod.lipson@columbia.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","8013","8086","$0.00","An estimated 13% of crops are lost globally to plant diseases. Disease detection, identification, and tracking is performed today by crop scouts, a process that is expensive, slow and difficult, and is impractical to expand to cover all crops. The project involves developing AI-drones that work side-by-side with farmers and identify specific diseases and assess their progress.  The use of intelligent drones for crop monitoring will allow farmers to respond quickly to emergent diseases, nutrient stress, and other potentially devastating damages without the prohibitive expense of hiring a crop scout. This ability could increase productivity, and may also help predict, track and respond to epidemics for national and global food security. In addition, this technology will also be used for ongoing collection of precise plant performance data for breeding resistance.<br/><br/>The central hypothesis of this proposal is that drones equipped with trained Convolutional Neural Networks can provide a transformative increase in actionable crop disease identification. A secondary hypothesis is that the proposed phenotyping at the individual plant level will also provide unprecedented resolution of data for future modeling, breeding, and data-driven yield optimization. In order to test this hypothesis, we will develop a UAS platform to collect images over university owned experimental crops, and aim to develop AI to identify pathologies at an accuracy that is on par with human experts. The UASs will consult human experts in ambiguous cases and gradually learn to make decisions autonomously. The key challenge will be development of AI that can reliably diagnose disease with a good accuracy of detection to false alarms. Automatic identification of disease is a challenging machine vision task given the complexity of images, exacerbated by variable lighting and weather conditions, and navigation/stability control."
"1821029","International Workshop on Bio-Inspired Geotechnics; Pacific Grove, California; May 19-22, 2019","CMMI","ECI-Engineering for Civil Infr","08/01/2018","07/23/2018","Alejandro Martinez","CA","University of California-Davis","Standard Grant","Richard J. Fragaszy","01/31/2020","$90,125.00","Jason DeJong","amart@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","ENG","073Y","036E, 037E, 038E, 1057, 172E, 7556, 9102, CVIS","$0.00","This award funds a workshop on Bio-inspired technologies in the general field of geotechnical engineering.  The workshop will be held in Pacific Grove, California, on May 19-22, 2019. The rapidly emerging discipline of biogeotechnics is comprised of both bio-mediated and bio-inspired technologies.  Bio-mediated technologies, such as microbially induced calcite precipitation (MICP) to cement sands, have been the primary focus over the past decade and have seen exponential growth.  Active research in the field now exists in more than 15 countries, companies have been founded, and national research centers have been established.  A new workforce has been created, with graduates working in the biogeotechnics field in both and industry.  Bio-inspired geotechnics, the complimentary aspect of biogeotechnics, however, is in its infancy.  This field is at a critical, formative stage.  The basal definition and scope of the field is being defined. Specific areas that hold exceptional promise for research are being identified.   Understanding and filtering through the broader field of bio-inspired engineering and design (or biomimicry), which itself has largely become established in only the last decade, is underway. Conversations with the geotechnical industry regarding what might be practically possible are just beginning.  The bio-inspired geotechnics field is at a time when an international, interdisciplinary workshop could accelerate growth and define future directions.  Therefore, the objectives of the workshop are to begin building interdisciplinary collaborations, identify research priorities and possible funding sources, engage with industry regarding implementability, and identify and address the educational needs of researchers entering the field and engineers entering the workforce.  <br/><br/>This workshop will bring together approximately 55 individual experts from academia and industry who are technically and demographically diverse, and collectively cover expertise in fields from geotechnical engineering to biology to soft robotics.  The workshop participants will include established senior investigators through assistant professors and underrepresented graduate students.  The workshop will be held over a period of three days at an inclusive meeting facility that will facilitate continuous planned formal workshop activities as well as informal interactions.  The workshop has been carefully designed in a structure that will scaffold, or gradually build, from developing a mutual foundation of discipline understanding, to sharing current research and brainstorming new opportunities, to identifying the necessary ""action items"" or developmental steps required to mature this field.  An informal environment that fosters discussion, brainstorming, free sharing of ideas, and development of collaboration relationships has been incorporated into the workshop agenda.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1622589","SCH: INT: Collaborative Research: Computer Guided Laparoscopy Training","IIS","Smart and Connected Health","08/01/2016","08/01/2016","Jerzy Rozenblit","AZ","University of Arizona","Standard Grant","Wendy Nilsen","07/31/2020","$1,118,923.00","Allan Hamilton","jr@ece.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","CSE","8018","8018, 8062","$0.00","Laparoscopic surgery, when performed by a well-trained surgeon, is a remarkably effective procedure that minimizes complications associated with open incisions, blood loss and post-operative pain. It also reduces recovery time. However, the procedure is more challenging than conventional surgery due to restricted vision, hand-eye coordination problems, limited working space, and lack of tactile sensation. Therefore, effective training and guidance methods are needed to minimize the potential risks inherent in such procedures. The goal of this project is to develop and validate techniques for computer-guided laparoscopic surgical training in a simulated, non-patient based environment. A computer-aided surgical trainer (CAST) will physically guide trainees' instruments during surgical skills practice sessions by utilizing assistive force with augmented reality displays. Guided training will be validated through a pilot experimental study, in which the expertise of computer-guided trainees will be compared to that of instructor-guided trainees. Data such as the time it takes a trainee to execute a particular surgical task, how accurate he or she is, etc., will be collected to analyze task performance precisely and objectively. New scientific methods for motion trajectory planning and path following using assistive force and augmented reality techniques will result from this work. It is anticipated that computer-guided practice will speed up learning and reinforce appropriate techniques, ultimately, leading to better surgical outcomes and improved patient safety. The CAST system should serve as a sophisticated, yet still low-cost, training solution for fundamental medical skills training.  <br/><br/>The specific objectives are a) to refine and implement a memory- and time-efficient hybrid offline-online optimal path planner for computer-guided training of basic laparoscopic skills. In this task, collision-free trajectory planning methods (such as those used in robotics) will be generated by incorporating offline-online hybrid techniques with memory and computational time efficient path repository. Thus, basic laparoscopic tasks can be planned and guided automatically, using haptic force and augmented reality visualization; b) to design and implement an intelligent, adaptive guidance controller for surgical space navigation, where a fuzzy logic and machine learning-based methods will be developed that will take into account trainees' skill levels so that optimal amount of training assistance can be provided in mastering surgical tasks; c) to design and implement visual guidance techniques through augmented reality overlays that provide 'navigational' cues, supplementing force-based control of surgical instruments; and d) to validate guided training through a pilot study. In this task, trainees' performance using computer guidance methods will be compared, using statistical analysis, to that of unguided trainees. The principal investigators will aim to increase the participation of undergraduate students, and in particular of underrepresented groups, through collaboration with the well-established programs at both PIs'  institutions and through sponsorship of senior projects and independent study courses."
"1832295","WORKSHOP:  Doctoral Consortium at the International Conference on Pervasive Technologies Related to Assistive Environments (PETRA 2018)","IIS","Cyber-Human Systems (CHS)","05/01/2018","03/21/2018","Fillia Makedon","TX","University of Texas at Arlington","Standard Grant","Ephraim P. Glinert","04/30/2019","$27,040.00","","makedon@cse.uta.edu","701 S Nedderman Dr, Box 19145","Arlington","TX","760190145","8172722105","CSE","7367","7367, 7556","$0.00","This is funding to support a Doctoral Consortium (workshop) of approximately 10 promising graduate students from U.S. institutions of higher learning, along with at least 3 distinguished research faculty as mentors, to be held in conjunction with the Eleventh International Conference on Pervasive Technologies Related to Assistive Environments (PETRA 2018), which will take place June 26-29 on the island of Corfu, Greece.  The PETRA mission is to promote interdisciplinary research on ways to use pervasive ambient intelligent environments to improve the quality of life and enhance human performance with greater capabilities.  It is the only annual conference that brings together theoreticians and practitioners from a wide variety of disciplines to focus on the application of pervasive technologies to assistive environments.  Outcomes of this conference have a broad impact in diverse application areas such as manufacturing, transportation, energy systems, security and safety, robotics, healthcare, biomedicine, environment and conservation.  PETRA brings together very different types of technologies to also address important social and healthcare issues for sensitive populations, such as the elderly, or persons suffering from chronic conditions such as Alzheimer's, Parkinson's, Cerebral Palsy and other disabilities or traumas.  The PETRA proceedings are published in the ACM Digital Library, and the authors of the best papers are invited to submit to special journal issues after the end of the conference.  More information about the conference may be found online at http://www.petrae.org.  The PETRA 2018 Doctoral Consortium will afford student authors of papers accepted for presentation at the conference a unique opportunity to gain additional exposure for their innovative ideas while also receiving reinforcement for the importance and value of conducting research with societal impact.  The workshop will allow the junior participants to create a social network both among themselves and with senior colleagues. The organizing committee will make a concerted effort to attract participants who are women, members of under-represented minorities, and persons with disabilities; to further assure diversity, NSF funds will be used to support no more than 2 student participants from any one institution, and if 2 students are supported, one of them must be a minority or person with disability.  <br/><br/>The goals of the Doctoral Consortium, which will consist of special sessions at the beginning, during, and at the end of the conference, are to increase the exposure and visibility of the participants' work within the community, to help establish a sense of community among this next generation of researchers, and to help foster their research efforts by providing substantive feedback and guidance in a supportive and interactive environment from a group of senior researchers.  The special program organized for the students includes sessions between the doctoral students and the faculty mentors, in which the students will discuss their work and ask questions; the faculty mentors will provide constructive comments on the students' work and address their questions.  Students will participate in small group breakout sessions to discuss their work, and the faculty mentors will provide guidance on how to proceed for further journal publication.  Students will also have the option to submit a poster paper and to attend conference workshops on special topics.  Short papers on the participants' work will be published in the conference proceedings, and a summary report on the event will be posted on the conference website.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1630047","Symposium on Combinatorial Search, SoCS-2016","IIS","ROBUST INTELLIGENCE","07/01/2016","06/17/2016","Richard Korf","CA","University of California-Los Angeles","Standard Grant","James Donlon","06/30/2019","$7,000.00","","korf@cs.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","CSE","7495","7495, 7556","$0.00","This grant is to provide partial support for U.S.-based graduate and undergraduate students to attend the Ninth Symposium on Combinatorial Search (SoCS-2016), a scientific conference to be held at Tarrytown, NY from July 6-8, 2016. Combinatorial search is an area of artificial intelligence that deals with systematic trial-and-error exploration of a very large number of alternative solutions to a problem.   NSF funding is crucial to support students who would otherwise not be able to attend the symposium.  Attending such meetings and presenting their research is an important part of the professional development of students, addressing a critical shortage of highly-skilled computer scientists in the U.S.<br/><br/>SOCS brings together researchers in heuristic search and combinatorial optimization from all areas of artificial intelligence, planning, robotics, constraint programming, operations research, and bioinformatics.  The intellectual merit of this activity stems from bringing together in one place at one time researchers from otherwise diverse areas of computer science that both advance the state of the art in heuristic search and/or combinatorial optimization, and also use these tools in their research.  The broader impacts come from cross-fertilization of different fields that advance and/or use these tools, by promoting research in this area by providing a small intimate meeting on these topics, a forum for presenting such work, and archival proceedings for publishing work in this area.  These latter goals are instrumental to training new researchers in this area."
"1743637","Symposium on Combinatorial Search - 2017","IIS","ROBUST INTELLIGENCE","05/15/2017","06/05/2017","Nathan Sturtevant","CO","University of Denver","Standard Grant","James Donlon","04/30/2019","$10,000.00","","sturtevant@cs.du.edu","2199 S. University Blvd.","Denver","CO","802104711","3038712000","CSE","7495","7495, 7556","$0.00","This grant supports student travel for select students and post-doctoral researchers to participate in the Symposium on Combinatorial Search (SoCS-2017) June 16-17 in Pittsburgh, PA.  SoCS is an annual event that brings together researchers in heuristic search and combinatorial optimization drawing from diverse areas of artificial intelligence, planning, robotics, constraint programming, operations research, bioinformatics, and computer games. This consortium is oriented on research and career development for students who have identified their PhD topics and are just embarking on that independent research.  <br/><br/>Sponsoring student travel to SoCS fosters a community of researchers from otherwise diverse areas of computer science to both advance the state of the art in heuristic search and/or combinatorial optimization, and also use these tools in their research.  Students participating in this symposium are also more likely to take full advantage of the top-tier conference in the International Conference on Automated Planning and Scheduling (ICAPS) 2017 taking place immediately prior to this symposium, and co-located with it.  The entire event provides an opportunity for students to engage in discussion with scientists from around the world and to explore new research directions and topics."
"1516684","Increasing Learning and Efficacy about Emerging Technologies through Transmedia Engagement by the Public in Science-in-Society Activities","DRL","AISL","08/01/2015","07/19/2018","Edward Finn","AZ","Arizona State University","Continuing grant","Alphonse T. DeSena","07/31/2019","$2,999,999.00","Steve Gano, Ruth Wylie, Rae Ostman, David Guston","edfinn@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","EHR","7259","8244","$0.00","The range of contemporary ""emerging"" technologies with far-reaching implications for society (economic, social, ethical, etc.) is vast, encompassing such areas as bioengineering, robotics and artificial intelligence, genetics, neuro and cognitive sciences, and synthetic biology. The pace of development of these technologies is in full gear, where the need for public understanding, engagement and active participation in decision-making is great. The primary goal of this four-year project is to create, distribute and study a set of three integrated activities that involve current and enduring science-in-society themes, building on these themes as first presented in Mary Shelley's novel, Frankenstein, which will be celebrating in 2018 the 200th anniversary of its publication in 1818. The three public deliverables are: 1) an online digital museum with active co-creation and curation of its content by the public; 2) activities kits for table-top programming; and 3) a set of Making activities.  The project will also produce professional development deliverables: workshops and associated materials to increase practitioners' capacity to engage multiple and diverse publics in science-in-society issues.  The initiative is funded by the Advancing Informal STEM Learning (AISL) program, which seeks to advance new approaches to, and evidence-based understanding of, the design and development of STEM learning in informal environments. This includes providing multiple pathways for broadening access to and engagement in STEM learning experiences, advancing innovative research on and assessment of STEM learning in informal environments, and developing understandings of deeper learning by participants.<br/><br/>This project by Arizona State University and their museum and library collaborators around the country will examine the hypothesis that exposing publics to opportunities for interactive, creative, and extensive engagement within an integrated transmedia environment will foster their interest in science, technology, engineering and mathematics (STEM), develop their 21st century skills with digital tools, and increase their understanding, ability, and feelings of efficacy around issues in science-in-society.  These three distinct yet interlocking modes of interaction provide opportunities for qualitative and quantitative, mixed-methods research on the potential of transmedia environments to increase the ability of publics to work individually and collectively to become interested in and involved with science-in-society issues."
"1510556","Group Theoretical, Combinatorial, and Dynamical Aspects of Mapping Class Groups","DMS","TOPOLOGY","09/01/2015","07/08/2016","Dan Margalit","GA","Georgia Tech Research Corporation","Standard Grant","Christopher W. Stark","08/31/2019","$259,000.00","","margalit@math.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","MPS","1267","1045, 7556, 9178, 9251","$0.00","Abstract<br/><br/>Award: DMS 1510556, Principal Investigator: Dan Margalit<br/><br/>The main goal of this project is to study surfaces and their symmetries.  A surface is a two-dimensional space, in other words, a two-dimensional version of the world we live in.  Surfaces come in many shapes (for instance the surface of a ball is different from the surface of a doughnut) and they arise in many varied contexts, from physics to robotics to data analysis to quantum field theory.  The symmetries of a surface form a beautiful and rich theory that has been the focus of intense study over the past century.  One surprising phenomenon is that there are combinatorial objects called curve complexes - looking nothing themselves like a surface - that have the same symmetries as a surface.  Many such objects have been discovered in the past twenty years.  The first goal of this project is to give (essentially) a complete list of such curve complexes.  This will be a capstone in the well-studied theory of symmetries of curve complexes.  The second project is to study a certain centrally important subset of the set of symmetries of a surface - the so-called Torelli group.  These symmetries are significant because of their strong connections to algebraic geometry and representation theory.  Basic properties of the Torelli group are unknown, despite the fact that this group has been studied heavily for fifty years.  This project aims to understand the basic finiteness properties of the Torelli group - for instance finite presentability.  This is one of the main open problems in the theory of surfaces.  Using a computer-aided search,  new footholds have been found into this problem.  The third project is a proposed algorithm for quickly computing the basic properties of a single symmetry  of a surface. For instance, this algorithm computes the entropy, which is the amount of mixing being achieved on the surface.  Other such algorithms exist, but ours is much faster.  For instance, using an appropriate notion of size (called word length), the existing algorithms can handle symmetries of size 30 (or so) and our algorithm can very easily handle symmetries of size upwards of 30,000.  In conjunction with these projects, the principal investigator will also be completing a textbook for undergraduates on a related subject, called Office Hours with a Geometric Group Theorist, and also will continue to run a professional development workshop for graduate students, the Topology Students Workshop.<br/><br/>The mapping class group of a surface is the group of homotopy classes of orientation-preserving homeomorphisms of the surface.  Among other things, the mapping class group encodes the outer automorphism group of the surface fundamental group, the (orbifold) fundamental group of the moduli space of the surface, and the isomorphism types of surface bundles over arbitrary spaces.  The mapping class group also has connections to many, many areas of mathematics, including dynamics, group theory, number theory, quantum field theory, representation theory, and algebraic geometry, just to name a few. The goals laid out in this project are threefold: (1) find a general theory for when a combinatorial, algebraic, or geometric object associated to a surface has the extended mapping class group as its group of automorphisms; (2) determine the finiteness properties of the Torelli subgroup of the mapping class group, specifically whether or not the Torelli group is finitely presented; and (3) establish a polynomial-time algorithm to compute the conjugacy invariants for a pseudo-Anosov mapping class.  Problem (1) was conceived by Ivanov; with Brendle, the PI has made substantial progress on this question.  Problem (2) is one of the most important open problems in the theory of mapping class groups.  It is a very hard question going back to the work of Dehn and Nielsen in the 1920s.  Bestvina, Lucarelli, Vogtmann, and the PI are making significant progress by performing a computer-aided search.  Various algorithms for Problem (3) are known, most notably the Bestvina-Handel algorithm.  With Yurttas the PI has a new algorithm for computing train tracks that works in quadratic time; in practice it is much quicker than the Bestvina-Handel algorithm (which we conjecture to be doubly exponential).  All three projects address fundamental questions in the theory of mapping class groups and in all three cases the PI and his collaborators have already made significant headway. In addition to these research goals, the PI also proposes to continue work on two major projects that have direct impact on graduate and undergraduate students.  The first is the Topology Students Workshop, a conference that serves both as a research conference in topology for graduate students as well as a professional development workshop.  The second is Office Hours with a Geometric Group Theorist, an introductory text on Geometric Group Theory for undergraduates."
"1823148","CRI:CI:SUSTAIN: Next-Generation, Sustainable Infrastructure for the RF-Powered Computing Community","CNS","COMPUTING RES INFRASTRUCTURE","10/01/2018","07/17/2018","Joshua Smith","WA","University of Washington","Standard Grant","Monisha Ghosh","09/30/2021","$979,997.00","Shyamnath Gollakota","jrs@cs.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","7359","7359","$0.00","The energy efficiency of microelectronics has been improving exponentially for decades. It is becoming possible to operate low power sensing, computing and communication platforms in a perpetual, battery-free fashion, with all power provided by Radio Frequency (RF) signals or other energy harvesting.  The Wireless Identification and Sensing Platform (WISP) is an open source battery-free platform that the present investigators originally introduced in 2006.  Hundreds of WISPs have been manufactured and distributed to researchers around the world.  This infrastructure has enabled research in diverse areas of computer science, including networking, Human-Computer Interaction, Ubiquitous Computing, Robotics, and other areas.  The present proposal will allow the researchers to integrate the latest research results, such as Ambient Backscatter Communication, into the WISP family, and also to reap the benefits of the most recent improvements in low power microelectronics.  The proposal will allow us to produce a new generation of the infrastructure and mature it to the point that it becomes self sustaining, via sales of hardware or other means. We expect that the sustained infrastructure will support research in backscatter communication, low power systems and networking, and applications of ultra-low-power platforms.  Battery-free sensing systems are expected to enable a wide array of new capabilities, which will generate substantial commercial impact in a wide variety of markets.<br/><br/>Computing is becoming connected more and more deeply to the physical world, a transformation that can enable smart environments, better medical care, more efficient manufacturing, and more. However, the need to power physically embedded microelectronic systems is a key challenge. This project will allow us to sustain the WISP infrastructure for battery-free, RF-powered computing and communication.  The infrastructure will enable research in several areas. In recent years, the PI and co-PI introduced Ambient Backscatter Communication, and backscatter-based WISP cameras, which have been widely recognized in the research community. Making these tools widely available will enable research on topics such as (ambient) backscatter networking, applications of battery-free cameras, and algorithms for interactive compression and computer vision in battery-free camera systems. This research would likely remain inaccessible for a long time to many computer and information science and engineering researchers, since there are no widely accessible platforms that support research on these topics. The sustained infrastructure will also enable novel application research, in areas such as improved human activity detection systems, battery-free input devices, and also research on body-implanted electronics, and long term structural health monitoring.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1557669","Collaborative Research: Hydrodynamic and Muscular Mechanical Investigation of Maneuverability in Cephalopods throughout Ontogeny","IOS","Physiolg Mechansms&Biomechancs","08/01/2016","07/05/2016","Ian Bartol","VA","Old Dominion University Research Foundation","Standard Grant","Emily Carrington","07/31/2020","$364,634.00","","ibartol@odu.edu","4111 Monarch Way","Norfolk","VA","235082561","7576834293","BIO","7658","9179","$0.00","Squids and cuttlefishes are impressive swimmers, having the ability to hover, change direction rapidly, and even swim forward and backward with ease.  The key to their locomotive prowess is coordination among their pulsed jet, flapping fins, and flexible arms, but little is presently known about how these units work together throughout these animals' lives as they encounter different physical environments, change developmentally, and experience dissimilar ecosystems. This project focuses on understanding how the jet, fins, and arms operate in concert to produce the necessary forces for exceptional turning, both in terms of muscle capabilities and hydrodynamics, in squid and cuttlefish of different developmental stages (hatchlings to adults).  This work will involve cutting edge 3D flow visualization approaches, high-speed video analysis, and advanced mathematical tools that highlight the essential components of high-performance turns.  This project promises to (1) advance our understanding of how highly maneuverable marine animals navigate through their complex habitats and (2) reveal key performance characteristics, structures, and behaviors that can be integrated potentially into the design of mechanical bio-inspired systems, such as autonomous underwater vehicles, to improve their turning/docking capabilities.  This project incorporates a number of outreach projects, including demonstrations in local schools, participation in robotics competitions, development of web-based tutorials and summer camps, and presentations at aquariums and museums. <br/><br/>Maneuvering in the aquatic environment is a significant component of routine swimming, with proficient maneuvering being essential for predator avoidance, prey capture, and navigation.  Despite its importance, understanding of the biomechanics of maneuvering behaviors is limited.  An investigation of maneuvering performance in three morphologically distinct species of cephalopods is proposed here.  The investigation explores three broad questions: (1) how are the fins, arms, and funnel-jet complex used in concert to maximize turning performance in adult cephalopods; (2) do the relative importance of turning rate and turning radius change over ontogeny and are fewer turning modes observed in young cephalopods; and (3) do fin, arm, and funnel musculoskeletal mechanics change over ontogeny and are such changes associated with differences in maneuvering? These questions will be addressed by collecting measurements of 3D high-speed kinematics and 2D/3D hydrodynamics of wake flows; performing mathematical analyses to quantitatively identify and categorize turning patterns; and measuring both the dynamic passive and active length-force relationship and maximum shortening velocity of muscle fibers that drive the movements used during turning and jet vectoring.  The proposed work will: (1) provide data on how an ecologically important marine animal coordinates its novel dual-mode system (jet and fins) and arms to achieve high turning performance, (2) highlight the essential kinematic and hydrodynamic elements of turns, (3) offer insights into how maneuvering capabilities change over a broad ontogenetic range, and (4) provide novel data on the muscle properties of muscular hydrostatic organs and their role in turning."
"1557698","Collaborative Research: Hydrodynamic and Muscular Mechanical Investigation of Maneuverability in Cephalopods throughout Ontogeny","IOS","Physiolg Mechansms&Biomechancs","08/01/2016","07/05/2016","Paul Krueger","TX","Southern Methodist University","Standard Grant","Emily Carrington","07/31/2020","$363,172.00","","pkrueger@engr.smu.edu","6425 BOAZ","Dallas","TX","752750302","2147682030","BIO","7658","9179","$0.00","Squids and cuttlefishes are impressive swimmers, having the ability to hover, change direction rapidly, and even swim forward and backward with ease.  The key to their locomotive prowess is coordination among their pulsed jet, flapping fins, and flexible arms, but little is presently known about how these units work together throughout these animals' lives as they encounter different physical environments, change developmentally, and experience dissimilar ecosystems. This project focuses on understanding how the jet, fins, and arms operate in concert to produce the necessary forces for exceptional turning, both in terms of muscle capabilities and hydrodynamics, in squid and cuttlefish of different developmental stages (hatchlings to adults).  This work will involve cutting edge 3D flow visualization approaches, high-speed video analysis, and advanced mathematical tools that highlight the essential components of high-performance turns.  This project promises to (1) advance our understanding of how highly maneuverable marine animals navigate through their complex habitats and (2) reveal key performance characteristics, structures, and behaviors that can be integrated potentially into the design of mechanical bio-inspired systems, such as autonomous underwater vehicles, to improve their turning/docking capabilities.  This project incorporates a number of outreach projects, including demonstrations in local schools, participation in robotics competitions, development of web-based tutorials and summer camps, and presentations at aquariums and museums. <br/><br/>Maneuvering in the aquatic environment is a significant component of routine swimming, with proficient maneuvering being essential for predator avoidance, prey capture, and navigation.  Despite its importance, understanding of the biomechanics of maneuvering behaviors is limited.  An investigation of maneuvering performance in three morphologically distinct species of cephalopods is proposed here.  The investigation explores three broad questions: (1) how are the fins, arms, and funnel-jet complex used in concert to maximize turning performance in adult cephalopods; (2) do the relative importance of turning rate and turning radius change over ontogeny and are fewer turning modes observed in young cephalopods; and (3) do fin, arm, and funnel musculoskeletal mechanics change over ontogeny and are such changes associated with differences in maneuvering? These questions will be addressed by collecting measurements of 3D high-speed kinematics and 2D/3D hydrodynamics of wake flows; performing mathematical analyses to quantitatively identify and categorize turning patterns; and measuring both the dynamic passive and active length-force relationship and maximum shortening velocity of muscle fibers that drive the movements used during turning and jet vectoring.  The proposed work will: (1) provide data on how an ecologically important marine animal coordinates its novel dual-mode system (jet and fins) and arms to achieve high turning performance, (2) highlight the essential kinematic and hydrodynamic elements of turns, (3) offer insights into how maneuvering capabilities change over a broad ontogenetic range, and (4) provide novel data on the muscle properties of muscular hydrostatic organs and their role in turning."
"1617698","NeTS: Small: Collaborative Research: Enabling Application-Level Performance Predictability in Public Clouds","CNS","Networking Technology and Syst","10/01/2016","08/29/2016","Zhenhua Liu","NY","SUNY at Stony Brook","Standard Grant","John Brassil","09/30/2019","$211,500.00","","zhenhua.liu@stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","CSE","7363","7923","$0.00","State-of-the-art resource sharing mechanisms in today's datacenters and compute clouds are agnostic to application-level performance requirements, resulting in unpredictable performance. This is especially true for the network. Unlike, CPU, memory, or disk, cloud operators do not provide any guarantees for the network. Many tenants rely on over-provisioning and static allocation for performance isolation, which results in low utilization and increased cost and environmental impacts. This project aims to build a set of solutions to achieve short- and long-term performance predictability with high resource utilization. The goal is to enable coexisting applications from different tenants to meet a variety of performance objectives including obtaining timely responses and minimizing variance of successive responses, while adhering to organizational hierarchies of individual tenants. The key technical challenges in this project include developing short- and long-term resource allocation algorithms, accurate demand estimation, as well as fast and efficient enforcement, all of which are compounded by the multi-resource and shared nature of the network. Two key techniques guide the proposed work: (i) temporal scheduling ensures predictable performance through short- and long-term performance isolation, and (ii) spatial placement ensures higher utilization through initial placement and periodic migration of tenants' virtual machines. <br/><br/><br/>Predictable, efficient data analytics will have significant socio-economic ramifications. It will also enable mission-critical applications, e.g., anomaly detection, fraud protection, autonomous vehicles, and robotics-- that require a highly consistent and reliable level of performance to coexist with the less sensitive ones. Algorithms and software from the project will be incorporated into existing open-source big data stacks for public reuse. By leveraging ongoing relationships with the industry, artifacts from this project will be converted from research into practice in a fast manner. The project has significant educational and outreach components, which include introducing new courses at both graduate and undergraduate levels based on the outcomes of this project as well as arranging cloud computing boot camps aimed at students from high schools and involving women and under-represented minorities."
"1601024","Symbolic Powers, Configurations of Linear Spaces, and Applications","DMS","ALGEBRA,NUMBER THEORY,AND COM, EPSCoR Co-Funding","09/01/2016","08/19/2016","Alexandra Seceleanu","NE","University of Nebraska-Lincoln","Standard Grant","Timothy Hodges","08/31/2019","$131,062.00","","aseceleanu@unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","MPS","1264, 9150","9150","$0.00","This research project is in the area of commutative algebra, with connections to algebraic geometry and computational algebra. Commutative algebra has applications in a range of areas, from statistics to game theory, from robotics to string theory.  The main theme of this project is the study of configurations of linear subspaces, such as finite collections of lines in the plane. These problems are classically motivated by algebraic geometry and have received renewed interest in the last fifteen years. Despite a rapidly growing body of work, there is still much progress needed to understand the subtle behavior of these configurations. This research program aims to take advantage of the combinatorial structure inherently present in this context. The project will also study potential applications of this work to coding theory.<br/><br/>The common thread for the investigations in this project concerns the asymptotic properties of symbolic powers. One goal of the project is the determination of certain invariants that measure these asymptotic properties (resurgence, Waldschmidt constants). Another goal is to characterize families of ideals that display extremal behavior with respect to the containment between ordinary and symbolic powers. Among the tools to be employed are methods involving the study of Rees algebras, minimal free resolutions, and local cohomology for powers of ideals. Another line of inquiry will consider the symbolic powers for singular loci of line arrangements, or more generally hyperplane arrangements, with special emphasis on reflection arrangements because of their additional structure. Despite their undoubted theoretical significance, not much is known about the practical applications of symbolic powers. The investigator and collaborators plan to start an investigation on the implications of this recent progress on symbolic powers from the point of view of applied algebraic geometry. Some computational tools in the form of scripts for the computer algebra system Macaulay will be developed to aid with the inquiry."
"1458495","Bilateral BBSRC-NSF/BIO: Collaborative Research: ABI Development: Seamless Integration of Neuroscience Models and Tools with HPC - Easy Path to Supercomputing for Neuroscience","DBI","ADVANCES IN BIO INFORMATICS, CYBERINFRASTRUCTURE, CROSS-EF ACTIVITIES","08/01/2015","09/14/2015","Nicholas Carnevale","CT","Yale University","Standard Grant","Peter H. McCartney","11/30/2018","$129,624.00","","ted.carnevale@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","BIO","1165, 7231, 7275","8089, 8091","$0.00","This project is a collaboration between the University of California San Diego and Yale University to develop a science gateway for the computational neuroscience community. A gateway  such as this helps  improve our understanding of how the brain works by making it easier for neuroscientists to use complex digital models of brain cells and circuits in their research. Powerful software has been developed for building and using models, and on-line resources such as Open Source Brain (OSB), ModelDB, Neuroscience Information Framework (NIF), and OpenWorm have been created to help neuroscientists find existing models, collaborate in developing new ones, and share the results of their work with others. However, models are becoming too complex for the computer hardware that is available to most neuroscientists, resulting in a critical need to use high performance computing resources (HPC). This work extends an existing Neuroscience Gateway (NSG), which was developed with support from NSF to eliminate or reduce many of the technical and administrative difficulties that previously limited neuroscientists' access to HPC (http://www.nsgportal.org/). That said, NSG users must still log in, upload models, launch simulations, and download results--a process that involves many time-consuming, error-prone steps. The expanded NSG-R will eliminate these steps by enabling on-demand, automated communication between itself and familiar working environments including resources like OSB and others mentioned above, and even with neural simulation software running on neuroscientists' own laptop and desktop computers. <br/><br/>This seamless access to HPC is implemented in NSG-R by a software infrastructure that uses REpresentational State Transfer (""REST"", the R in NSG-R). NSG-R utilizes set of web services which expose the capabilities of NSG for access via publicly available application programmer interfaces. This will allow users of neuroscience resources such as OSB, ModelDB, NIF and OpenWorm to readily access HPC from their respective websites via NSG-R. This enhances the usefulness of NSG-R, other neuroscience resources like OSB, and widely used neural simulators such as NEURON, GENESIS, PyNN, NEST, Brian and MOOSE. It also results in greater research productivity and enables wider use of large scale computational modeling by scientists and students. NSG-R will accelerate progress in brain science, and have far-reaching beneficial effects on related fields such as robotics and engineering of adaptive and learning systems. It will widen opportunities for educational and career advancement in neuroscience and engineering. Furthermore, by removing barriers that traditionally have limited access to HPC, NSG-R levels the playing field for all students and researchers regardless of their institutional affiliation. NSG-R, a free and open neuroscience gateway infrastructure, will naturally be a ready entry point for students and researchers from historically underrepresented schools and colleges. NSG-R workshops will be hosted at minority serving institutions (MSI) and opportunities for students to do internships with the NSG-R team at the University of California San Diego will be provided."
"1464542","Collaborative Research:  I/UCRC Phase II:  Center for Resource Recovery & Recycling","IIP","INDUSTRY/UNIV COOP RES CENTERS","07/01/2015","07/10/2018","Brajendra Mishra","CO","Colorado School of Mines","Continuing grant","Prakash Balan","12/31/2018","$135,000.00","Patrick Taylor, Corby Anderson","bmishra@wpi.edu","1500 Illinois","Golden","CO","804011887","3032733000","ENG","5761","5761, 8040","$0.00","Materials resource recovery and recycling is a critical need for sustainable development in the 21st Century. Materials are not renewable and yet they have major impacts in every industry and product area important to the national and global economy.  The industries that carry out resource recovery and recycling as well as supply equipment and technologies for it comprise a broad range of companies, a large fraction of which are small and medium enterprises. Over 56,000 such companies, engaged in some aspect of resource recovery and recycling, produce $236 billion in goods, and employ 1.21 million in primary and downstream industries. It is the purpose of the Center for Resource Recovery and Recycling (CR3) to address these opportunities through cross-sector engagement in the resource recovery and recycling value chain. Resource recovery and recycling technologies have widespread applications impacting all materials manufacturing, including, metals, plastics, paper, electronics, glass, organics, polymers & chemicals, etc. <br/><br/>There are a number of key industry challenges in the area of resource recovery and recycling. Specifically: <br/>* Scarcity of feed stock materials and increasing cost of material resources<br/>* Increasing amounts of waste from industrial processes as well as end-of-life products<br/>* Need for solutions for resource recovery, reuse, and recycling of critical materials<br/>* Need for energetically favorable, environmentally compatible and economically viable industrial processes<br/><br/>The increasingly rapid development of new technologies in areas such as sensors, computational modeling, simulation and visualization, big data and analytics, advanced materials, automation, and robotics offers potentially significant impacts that could greatly expand the capabilities as well as increase the efficiency of materials resource recovery and recycling and benefit the industries involved in addition to development of physical and chemical processes for sortation, beneficiation and concentration as well as value-extraction. The industries comprising the resource and recovery area tend to be disaggregated based on the type of materials recovery and recycling they carry out, and are predominantly small and medium enterprises. Therefore they not only often lack the resources to carry out the needed R&D but also those advanced manufacturing technologies that are available do not have a natural route to implementation in industry. CR3 brings together key constituencies in the resource recovery and recycling area to develop comprehensive technology transfer pathways to industry. The primary focus of CR3 is on key sectors of iron and steel, non-ferrous structural metals, light metals, rare-earths and photovoltaic metals, high-value refractory metals and electronic materials where technology development will address the product manufacturing wastes, post-consumer wastes, instrumentation, sensors and controls, design for disassembly and conversion of trash to treasure."
"1558068","The Vibrissotactile Natural Scene","IOS","ACTIVATION","07/15/2016","07/05/2016","Mitra Hartmann","IL","Northwestern University","Standard Grant","Sridhar Raghavachari","06/30/2019","$525,983.00","Sara Solla","m-hartmann@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","BIO","7713","1096, 9178, 9179, 9251","$0.00","In humans, the sense of touch is closely linked with hand movements. An open question in neuroscience is how the brain combines touch signals (sensory) with hand movements (motor) to create a unified tactile perception of an object. Because of difficulties in studying how the human brain combines these cues, researchers study rats, which use ~60 whiskers to tactually explore the environment. The whisker system is an excellent model to investigate how neurons represent and unify touch and movement, but neuroscientists currently struggle to stimulate the whiskers in a way that imitates the signals obtained during natural exploratory behavior. In this proposal, the investigators will characterize naturalistic patterns of tactile input that the rat's brain evolved to process, and will develop new mathematical tools to describe the environmental features that the rat experiences. The proposed work is scientifically important for two reasons. First, because rodents are the most commonly used animals in neuroscience, these experiments will aid researchers studying many parts of the brain involved with touch and movement. Second, these new mathematical tools will help quantify the sense of touch across species, including humans. The proposed work will have significant broader impacts on science and mathematics education and public outreach. Undergraduate students will contribute to the work, and the investigators will lead Northwestern's Robotics Club to explore engineering applications of whisker-based tactile sensing. The investigators will also continue outreach efforts through the Society of Hispanic Professional Engineers, the Society of Women Engineers, and Chicago's Museum of Science and Industry. <br/><br/>In the fields of vision and audition, the receptive fields of central neurons are tuned to the statistics of the ""natural scenes,- to those properties of the stimuli that the animal is likely to encounter in its natural environment. In the field of somatosensation it is challenging to quantify the natural tactile scene, in part because somatosensory signals are tightly linked to the animal's movements. The proposed work aims to begin to quantify the natural tactile scene for the rat vibrissal system by combining careful behavioral monitoring and simulations of rat head and whisker movements. The project has two major goals. The first is to characterize the statistics of the environments that the rat naturally inhabits. In Bayesian terms, this statistical distribution is called the ""prior,"" because it describes the environment's geometrical features, unbiased by the tactile sampling choices of the animal. The second is to quantify the statistics of the environment sampled by the rat, given its choices of head motions and whisk cycle. In Bayesian terms, this statistical distribution is called the ""posterior,"" because it incorporates the bias of the rat when preferentially sampling the tactile scene. This work is one of the first attempts to quantify the statistics of active touch, and it aims to make specific predictions for the receptive field properties that enable spatiotemporal integration. Equally important, this work will develop an appropriate mathematical framework for characterizing the geometry of natural scenes, an essential step towards describing active somatosensation using information theoretic measures."
"1607616","Automorphism Groups and Morse Boundaries","DMS","TOPOLOGY","09/01/2016","07/11/2018","Ruth Charney","MA","Brandeis University","Continuing grant","Christopher W. Stark","08/31/2019","$408,740.00","","charney@brandeis.edu","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024532728","7817362121","MPS","1267","","$0.00","Abstract<br/><br/>Award: DMS 1607616, Principal Investigator: Ruth Charney<br/><br/>Mathematics is used to model physical systems and to analyze data sets.  Increasingly, these models take the form of geometric objects. This project focuses on a class of geometric objects that arise as models in a number of contexts, including robotics and genetics. Geometric properties of these models and their symmetry groups are reflected in properties of the physical systems. Questions may involve either local geometry (what happens near a particular point) or large-scale geometry (the structure of the object viewed from a distance). This project concerns large-scale geometry.  By introducing a new notion of a ""boundary"" for the geometries in question, we are able to identify and quantify certain types of behavior, known as hyperbolic behavior.  The study of these boundaries, and their implications for the geometry and symmetry of the objects in question, is the main theme of this project.<br/><br/>Boundaries of geodesic metric spaces have played an important role in the study of hyperbolic groups, for example in proving rigidity theorems and dynamical properties.  Boundaries can also be defined for CAT(0) spaces, however they are not quasi-isometry invariant, hence do not give a well-defined boundary for a CAT(0) group.  In recent work, the principal investigator and Sultan introduced a new boundary, called the Morse boundary, for CAT(0) spaces which is quasi-isometry invariant and behaves more like the boundary of a hyperbolic space. Subsequently, Cordes generalized this construction to obtain a Morse boundary for any proper geodesic metric space.  This offers a potentially powerful new tool for studying large classes of groups, such as acylindrically hyperbolic groups.  The first part of this project will investigate properties of these boundaries and their implications for the groups in question.  The second part of the project concerns automorphism groups of right-angled Artin groups (RAAGs).  Automorphism groups of free groups, mapping class groups, and linear groups have many properties in common.  Automorphism groups of RAAGs give a context in which to study these commonalities.  As Teichmuller space has been central to the study of mapping class groups, Culler and Vogtmann's Outer space has been a fundamental tool in the study of automorphism groups of free groups.  Similarly, analogues of the curve complex of a surface have been introduced for free groups and shown to be hyperbolic.  The second part of this project seeks to find an analogous Outer Space for RAAGs and to study generalizations of the free factor and free splitting complexes for all RAAGs."
"1514286","CSR:Medium:Collaborative Research: SparseKaffe: high-performance, auto-tuned, energy-aware algorithms for sparse direct methods on modern heterogeneous architectures","CNS","Computer Systems Research (CSR","09/01/2015","09/01/2017","Jack Dongarra","TN","University of Tennessee Knoxville","Continuing grant","M. Mimi McClure","08/31/2019","$399,993.00","","dongarra@icl.utk.edu","1 CIRCLE PARK","KNOXVILLE","TN","379960003","8659743466","CSE","7354","7924","$0.00","The use of sparse direct methods in computational science is ubiquitous. Direct methods can be used to find solutions to many numerical algebra applications, including sparse linear systems, sparse linear least squares, and eigenvalue problems; consequently they form the backbone of a broad spectrum of large scale applications.  In the widely used and actively growing University of Florida Sparse Matrix Collection, there are problems from structural engineering, computational fluid dynamics (CFD), computer graphics/vision, robotics/kinematics, theoretical and quantum chemistry, power networks, social networks, document networks, among others.<br/> <br/>The SparseKaffe project team will develop algorithms and software for high-performance parallel sparse direct methods with irregular and hierarchical structure that can exploit clusters of Hybrid Multicore Processors to achieve orders of magnitude gains in computational performance, while also paying careful attention to the energy requirements.  This requires the development of novel and innovative algorithms for scheduling, energy minimization, and memory management; development of novel user-guided autotuning algorithms that exploit different hardware characteristics; and designing a common infrastructure for creating auto-tuned software.<br/> <br/>The use of sparse direct methods is extensive, with many of the relevant science and engineering application areas being pushed to run at ever higher scales.  The team expects SparseKaffe solvers to be able deliver not only high performance to the applications that use them, but also the energy efficiency that they will increasingly demand. The team will also create a course, and a corresponding set of course modules, to teach students how to develop algorithms and software that deliver orders of magnitude gains in performance on clusters of hybrid multicore processors."
"1801062","Engaging Students From Classrooms and Camps to College and Advanced Technological Careers","DUE","ADVANCED TECH EDUCATION PROG","09/01/2018","07/06/2018","Sharon Gusky","CT","Northwestern Connecticut Community College","Standard Grant","V. Celeste  Carter","08/31/2021","$599,877.00","Tara Holmberg, Lisa Dubany, Bridget Brody, Christine Gamari","sgusky@nwcc.commnet.edu","Park Place","Winsted","CT","060981710","2033798543","EHR","7412","1032, 9178, SMET","$0.00","The forty manufacturers in the Torrington area of Northwestern Connecticut include smaller, local companies, as well as national and global companies such as Wittmann Battenfeld and Altek Electronics. In addition, Jackson Laboratory, the leading bioscience company in the area, is located twenty miles away. These companies need employees at all levels of skills and knowledge, from technicians to engineers and research scientists. They rely on an educational infrastructure to provide a capable, industry-ready workforce. However, there is a gap between the industry demand and availability of skilled workers, and neither the technical high school nor the college is currently meeting these needs. For example, in the robotics and automation areas, industry need exceeds the trained workforce by almost 68%. According to the 2016 Chamber of Commerce Survey of Northwest Connecticut, maintaining and growing manufacturing was one of the highest priorities in the region and the lack of skilled applicants was cited as being the biggest barrier. This project, Engaging Students from Classrooms and Camps to College and Careers, brings 7th-12th grade teachers, community college faculty, students, and industry members together to develop a strong technical workforce. <br/><br/>This project aims to increase the STEM interest and skills attainment of underrepresented and socioeconomically disadvantaged students in the Torrington School District. It will engage forty-four middle and high school STEM teachers and their students, using innovative activities to introduce students to careers as technicians. Teachers will participate in industry-based externships and professional development workshops.  These activities are designed to help teachers better understand the roles of technicians. Students will participate in college visits and summer camps, designed to help them understand career opportunities for technicians. Community college students will learn about careers as technicians by participating in externships in industry, and will refine their knowledge and skills by serving as teaching assistants in camps and classrooms, and as mentors for the middle and high school students. Through this program, the community college plans to increase the number of dual enrollment college courses for high school students. The program will establish a support system for teachers through the formation of a STEM Community of Practice that includes teachers, college faculty, and industry members. The project activities are expected to support pathways for students to careers in the advanced technological industries in the region.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1701107","PFI: AIR-TT: Commercializing a new genre of Intelligent Science Stations for informal and formal learning","IIP","Accelerating Innovation Rsrch","07/15/2017","07/17/2017","Ken Koedinger","PA","Carnegie-Mellon University","Standard Grant","Jesus Soriano Molla","12/31/2018","$200,000.00","Nesra Yannier","Koedinger@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","8019","8019","$0.00","This PFI: AIR Technology Translation project aims to build and commercialize a reusable mixed-reality platform that engages children in scientific experimentation and uses computer vision and automated feedback to help them effectively learn scientific principles. The project focuses on translating prior science and technology research that produced the first Intelligent Science Station, called EarthShake.  EarthShake is a mixed-reality educational game in which children discover physical properties of balance by running experiments with block towers on a simulated earthquake table. This project has the potential to have substantial societal, commercial and educational impacts. It aims to impact millions of children and families that spend time in Children's and Science Museums, libraries, schools, and indoor play spaces. It will transform traditional hands-on exhibits and play spaces into intelligent learning environments that foster children's curiosity and improve their learning in an engaging and collaborative way. It will also help to transform the traditional educational system in schools, introducing an interactive, engaging, mixed-reality system that can help students understand the underlying evidence for scientific principles, not just memorize them.  With over 270 Children's and Science Museums in the US alone, over 800 malls with play spaces for children, 100s of indoor play/learning spaces, over 4,000 clubs and after-school programs, 119,487 libraries, 36,767 private and charter elementary schools and 103,460 elementary schools, this project can have a commercial impact in addition to societal and educational benefit.<br/><br/>The system uses computer vision to follow children's progress and provide intelligent guidance in a predict-observe-explain scientific inquiry process. Experiments demonstrate that grades K to 3 children learn much more from EarthShake than from an otherwise identical flatscreen tablet or laptop implementation showing as much as a 5 times greater pre to post increase on tests of prediction, explanation, and stable tower building.  The initial prototype will be translated into a reusable platform for Intelligent Science Stations and demonstrated in scalable development of multiple instances of three games, EarthShake, RaceCars, and BalloonScale. The technical challenges are to generalize the vision algorithm to work across the variety of objects and configurations in these games and create modular hardware components that provide for scale in development, distribution, and new products. This project draws on technical expertise in computer vision/AI, mechatronics, tangible interfaces, physical computing, human/child-computer interaction, and educational technology.<br/><br/>Intelligent Science Stations bridge the advantages of physical and virtual worlds to improve children's science and inquiry learning in an enjoyable and collaborative way and can be commercialized to do so in various settings, indoor play spaces, museums, libraries, and schools. The project contributes to the general robotics challenge by creating an automated intelligent tutoring system operating in the physical 3D world, incorporating sensors and perceptual algorithms to track what learners are doing, actuators to manipulate the scientific apparatus, and an intelligent dialogue system to orchestrate interaction.  It addresses technical challenges of creating a generalizable vision algorithm and a modular physical hardware platform that allows customers to easily switch between different applications. It will create new knowledge about how to develop a general and reusable mixed-reality platform that integrates scientific apparatus including mechatronic components (e.g,. sensors, actuators, servo motors, physical experimental set-up) with an intelligent tracking system (including hardware and software components with an AI vision algorithm)."
"1565352","Singularities and Moduli Theory","DMS","ALGEBRA,NUMBER THEORY,AND COM","07/01/2016","06/21/2018","Sandor Kovacs","WA","University of Washington","Continuing grant","Timothy Hodges","06/30/2021","$294,000.00","","kovacs@math.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","MPS","1264","","$0.00","This research project is in the field of algebraic geometry, one of the oldest parts of modern mathematics, but one that blossomed to the point where it has solved problems that have stood for centuries. In its simplest form it treats figures defined in the plane by polynomials. Today, the field uses methods not only from algebra, but also from analysis and topology, and conversely it is extensively used in those fields. Moreover it has proved itself useful in fields as diverse as physics, theoretical computer science, cryptography, coding theory, and robotics. A central problem in algebraic geometry is the classification of all geometric objects. In turn, an important part of classification theory is the theory of moduli. The latter's core idea is that one does not only want to understand these objects, but also understand the way they can be deformed. Moduli spaces play a very important role in theoretical physics: studying curves on moduli spaces provides information on how an object is changing in space-time. One of the foci of this project is on compact moduli spaces, which give additional information about singular deformations, ones that are essentially different from others.  The investigator is also involved in promoting mathematics to high school students; he and fellow directors of the Summer Institute for Mathematics at the University of Washington make special efforts to involve women at all levels of the program, from students through teaching assistants to instructors, to reinforce their leadership roles in mathematics.<br/><br/>This project concerns several topics in higher dimensional algebraic geometry, especially moduli theory and singularities. The overarching theme of the research is centered on compact moduli spaces of stable log varieties, an important area that is still in the developmental stage. In particular, even the correct moduli functor needs to be identified, and most of the research is motivated by understanding the basic properties of these moduli spaces. This involves understanding the singularities that can occur on stable log varieties. Important classes of singularities in this regard are that of rational singularities and other singularities of the minimal model program. The investigator will work on advancing our currently very limited understanding of these singularities in arbitrary characteristic. The project also aims to develop cohomological methods to deal with rational pairs and thrifty resolutions in arbitrary characteristic. In particular, the investigator will study logarithmic versions of Hodge cohomology and of Grothendieck's fundamental class. Also stemming from the moduli project, the investigator plans to study properties of Du Bois singularities and Du Bois pairs. The main objectives of this part of the project are to develop a definition of these singularities that makes sense in arbitrary characteristic and to prove a subadjunction theorem for rational and Du Bois pairs."
"1558448","Sustained measurements of Southern Ocean air-sea coupling from a mobile autonomous platform","OCE","PHYSICAL OCEANOGRAPHY, ANTARCTIC OCEAN & ATMOSPH SCI","05/01/2016","04/20/2016","James Girton","WA","University of Washington","Standard Grant","Baris M. Uz","04/30/2019","$919,417.00","James Thomson","girton@apl.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","GEO","1610, 5113","4444, 7398","$0.00","The coupled air-sea dynamics of the Southern Ocean play a critical role in the ocean?s transport and storage of heat and carbon dioxide and the response of these processes to climate change.  This project advances our capability to observe air-sea dynamics under winds through a 6-month deployment of a wave glider.  The wave glider has been adequately demonstrated as a robust high-endurance platform for open-ocean work and has begun to demonstrate its capability for research-quality measurements. This project will advance that capability by increasing our understanding of vehicle and sensor performance and suitability for measuring air?sea fluxes of momentum, moisture, and heat. Simultaneously, the vehicle will be used to study critical scientific questions on air-sea interactions. The project will include graduate and undergraduate student training and outreach activities through local schools, the Seattle Aquarium, and the Pacific Science Center.<br/><br/>The main research topics addressed in this project are the spatial structure of winds and surface properties in the Southern Ocean, the influence of surface wave Stokes drift on Ekman transport in the upper ocean, wave modulation of wind stress, near-inertial wind energy input into the ocean, and the coupling between winds and sea surface temperature. The observations will be taken by a Liquid Robotics Wave Glider SV3 autonomous surface vehicle instrumented for measurements of surface waves, temperature and salinity, upper-ocean currents, barometric pressure, and winds. Deployment and recovery will exploit planned cruises maintaining the Ocean Observatories Initiative Southern Ocean array and re-supplying the US Antarctic Program's Palmer Station. The sampling plan consists of (1) three months near the Ocean Observatories Initiative air-sea interactions buoy to study spatial structure and allow cross-calibration of the various sensors and their responses to vehicle heading and wind and wave conditions; (2) two months conducting a downstream grid survey across the Antarctic Circumpolar Current towards Drake Passage; and (3) a month-long timeseries in southern Drake Passage in the weak-current region between the Polar Front and the Southern ACC Front before recovery from the R/V Laurence M. Gould."
"1337218","XPS: FP: Real-Time Scheduling of Parallel Tasks","CCF","INFORMATION TECHNOLOGY RESEARC, ALGORITHMIC FOUNDATIONS","09/01/2013","05/20/2014","Kunal Agrawal","MO","Washington University","Standard Grant","Tracy J. Kimbrel","08/31/2019","$765,950.00","Christopher Gill, Chenyang Lu","kunal@cse.wustl.edu","CAMPUS BOX 1054","Saint Louis","MO","631304862","3147474134","CSE","1640, 7796","7926, 7934, 9251","$0.00","Tasks which must complete by specific deadlines (known as real-time tasks) appear in many systems where computers interact with humans or the physical environment such as autonomous vehicles, traffic management, robotics, industrial process management, video surveillance, radar tracking, and hybrid structural testing. With a growing number of application domains where this kind of interaction occurs, there is an increasing need for systems that can run complex tasks within stringent timing constraints. In a separate, but related trend, processor clock speeds have largely stagnated, and most modern computers are parallel computers with multiple cores or processors on each platform. Both to keep up with the demands of emerging embedded systems, and to exploit the capacity of multicore computers effectively, real-time applications must harness parallelism more effectively than has been possible to date. This research will enable these important applications by conducting both theoretical and empirical research on how to implement and execute parallel real-time tasks efficiently.<br/><br/>This research intends to develop provably good algorithms for parallel real-time tasks. These algorithms must provide guarantees of both correctness and performance. The research focuses on three specific directions: (1) Scheduling foundations: Design and analysis of efficient scheduling algorithms for parallel real time tasks that take the complex characteristics of modern parallel platforms into consideration. (2) Synchronization mechanisms: Design of effective synchronization techniques in order to allow coordination and resource sharing between different tasks as well as different threads of the same parallel task. (3) Concurrency platform: Implementation of a modular and extensible concurrency platform for real-time parallel tasks that will be used to develop, test and validate the scheduling and synchronization mechanisms required to run these tasks. This platform will be made available under a maximally permissible open source license to practitioners who wish to parallelize their real-time applications or to extend the platform itself to validate their own scheduling solutions. "
"1266260","I/UCRC:  Collaborative Research: Full Center Grant: I/UCRC for Cyber-Physical Systems for the Hospital Operating Room","CNS","INDUSTRY/UNIV COOP RES CENTERS","04/15/2013","09/14/2016","Scott Berceli","FL","University of Florida","Continuing grant","Dmitri Perkins","03/31/2019","$300,000.00","","scott.berceli@surgery.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","5761","5371, 5761, 8039","$0.00","The proposed center seeks to establish a new Industry/University Cooperative Research Center (I/UCRC) addressing the research of cyber-physical systems for use in the hospital and operating room environments. The center will focus on computational science and technologies to advance, develop and promote research into the principles and technology of computational surgery science.  This will be achieved through research, development, education, and technology exchange among academic, industry, hospitals and government entities via the I/UCRC framework.  <br/><br/>The new center seeks to address an interdisciplinary area of central national economic importance. The center will endeavor to create a confluence of computational science, robotics, biomedical engineering, and medical expertise to positively impact the delivery of quality procedural and surgical interventions.  The proposed center has the potential to bring together a diverse set of member companies and academics to achieve its goals as well as spawn new start-ups.  The center plans to leverage an international network and new curriculum in computational surgery in order to achieve research and student impact. <br/>"
"1816591","SaTC: CORE: Small: Online Malicious Intent Inference for Safe CPS Operations under Cyber-attacks","CNS","Secure &Trustworthy Cyberspace","09/01/2018","07/03/2018","Nicola Bezzo","VA","University of Virginia Main Campus","Standard Grant","Phillip Regalia","08/31/2021","$290,642.00","","nb6be@virginia.edu","P.O.  BOX 400195","CHARLOTTESVILLE","VA","229044195","4349244270","CSE","8060","025Z, 7434, 7923","$0.00","Modern autonomous vehicles are not built with security in mind. The increased sensing, computation, control capabilities, and task complexity have introduced security concerns beyond traditional cyber-attacks. By injecting malformed data, by spoofing sensors, by tampering with controllers, and even by manipulating the environment, an attacker can compromise the integrity and even take control over the functionality of such cyber-physical systems. Examples of attacks have recently been demonstrated on a variety of systems which include the rerouting of drones, the hijacking of vessels by Global Positioning System (GPS) spoofing, and the use of wireless connectivity to take over the steering and brakes of automobiles. Several solutions have been pursued in recent years to solve this problem, yet the bulk of cyber-physical system security literature is focused on the detection and estimation of malicious attacks without considering the context, risk or consequences, much less the intent of the attack. Predicting the intention, by contrast, may yield more information about the attack and thus offer defense mechanisms. This research focuses on the development of techniques to identify, predict, and mitigate malicious intentions of autonomous vehicles, seeking to develop fundamental methods for estimating risk and consequences of malicious attacks, identifying malicious intent, and defending, controlling, and reconfiguring the compromised system.<br/><br/>This project will provide fundamental approaches to increase resiliency in autonomous vehicles. Specifically, the proposed research includes: 1) new techniques to estimate risk and consequences of attacks, leveraging knowledge about the system model and reachability-based analysis; 2) machine learning-based and control-level intent inference methods; and 3) the development of policies for resilient planning and control to ensure continuous operation of the system with closed-loop performance guarantees. To better develop and assess the security techniques proposed in this work, realistic case studies will be implemented using state-of-the-art unmanned aerial and ground vehicles with different sensing, computation, and communication capabilities to facilitate their transition into practice. The proposed research is also applicable to cyber-physical systems broadly and will contribute directly to the development of safe autonomous systems. Additionally, as part of this project, a major emphasis will be given to education and outreach including the development of novel curriculum activities centered on the topic of resiliency in robotics, involvement of undergraduate and graduate students in research, and collaborations with industry to train the next generation workforce on cyber-physical system security problems and mitigation schemes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1657438","Scaling up an innovative STEAM (Science, Technology, Engineering, Arts, & Mathematics) learning environment through two partnership models with industry and schools","DRL","ITEST","04/01/2017","01/11/2018","Reed Stevens","IL","Northwestern University","Standard Grant","Robert Russell","03/31/2020","$1,899,781.00","","reed-stevens@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","EHR","7227","8244","$0.00","This project will advance efforts of the Innovative Technology Experiences for Students and Teachers (ITEST) program to better understand and promote practices that increase students' motivations and capacities to pursue careers in fields of science, technology, engineering, or mathematics (STEM).  The project will foster and research the broad implementation of an integrated suite of science, technology, engineering, arts/design, and mathematics (STEAM) learning innovations into schools called FUSE Studios. FUSE is a new kind of interest-driven learning experience that engages pre-teens and teens in learning technical, STEM workforce relevant skills and trans-disciplinary skills-often called 21st century skills, such as self-regulation, persistence, leadership, and critical thinking skills. The core activities in FUSE are a set of challenges. Each challenge uses a leveling up model from gaming and is carefully designed to engage participants in different STEAM topics and skill sets. FUSE currently has several dozen challenges areas such as robotics, electronics, biotechnology, graphic design, Android app development, 3D printing and more. Current project research demonstrates that FUSE is sparking and developing student interest in STEAM and information and communications technology (ICT) fields, especially among students who have not previously considered these career directions. The insights generated by this project will aid school leaders and teachers in adopting and organizing experiences for their students that emphasize youth interests, choice, diverse modes of interaction with knowledgeable others, and a wide range of innovative and heterogeneous learning opportunities in STEAM and ICT. Over the course of this project, FUSE Studios will double its current active reach by expanding to 40 new schools, with 160 new FUSE studios, and reach 16,000-21,400 new students, particularly underrepresented, minority students in under-resourced schools.<br/><br/>The project will research two distinct but complementary strategies, for significantly broadening the implementation of FUSE. These two strategies are called the direct district engagement model and the industry partnership model. The research will focus on how these strategies are successful (or not) in leading to sustainable adoption and spread. Each strategy is designed to respond to distinct organizational conditions found in local schools and districts.  The proposed project will investigate three distinct but related aspects of spreading a successful intervention: (a) the process of spreading FUSE project through the two strategies noted above, (b) the life cycle of an intervention (getting in, getting rooted, and spread) and, (c) the ways in which the project is adopted and adapted in different settings (nature of modifications and their impact on integrity of the program). The project will use the concept of a ""tracer"" from biological research as an analytic device to systematically follow how different institutions adopt, adapt and sustain the innovation (i.e., the FUSE model).  In brief, the research will follow how FUSE gets rooted and spreads when it is introduced to the different schools and districts.  The research will be guided by the Actor theory Network (ACT), which provides a set of empirical heuristics and concepts for tracing how ideas, practices and artifacts move and become progressively stabilized within social contexts. Studying the broad implementation of FUSE Studios will produce generalizable understandings of how innovative educational, workforce-related, technology experiences can be brought into schools in impactful and sustainable ways on a large scale. This research will make valuable contributions to the important and understudied question of how learning innovations are effectively scaled up."
"1719545","Collaborative Research:  Tractable Non-Convex Optimization","DMS","COMPUTATIONAL MATHEMATICS","07/01/2017","07/02/2018","Afonso Bandeira","NY","New York University","Continuing grant","Leland M. Jameson","06/30/2020","$82,203.00","","bandeira@cims.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","MPS","1271","9263","$0.00","Practitioners in most fields of science and engineering invest a substantial amount of time developing appropriate mathematical models for the complex questions they set out to answer. A model is deemed appropriate for a given task if it meets two potentially conflicting criteria simultaneously. On the one hand, it must be sufficiently faithful to reality (and as such, sufficiently complex) so as to capture the essential properties of the object of study. On the other hand, the model must be simple enough that it can be practically used to answer relevant questions. This second requirement is computational in nature. In effect, the modeler aims to reduce a particular question to a mathematical problem known to be practically solvable, or tractable.  For the most part, tractability ensures that the problem can be solved using known algorithms, and as a result the status quo has been that problems that are not tractable should be avoided for applications. Yet, scores of problems in science and engineering are most naturally modeled within a framework that has been previously determined to be non-tractable. This research project aims to develop theory and algorithms to identify and solve non-convex optimization problems, typically regarded as non-tractable. The goal is to provide practitioners with an extended modeling toolbox, allowing them to capture key aspects of our complex reality.<br/><br/>This project targets optimization problems that are tractable despite non-convexity. This can come about in a number of ways. The non-convexity may be structurally benign, in that the problem actually does not have local optima at all. This project explores such structural effects in the context of Burer-Monteiro relaxations. Alternatively, the problem may present numerous local optima in some instances, yet present only good quality ones on instances of the problem encountered in practice. This motivates the analysis of non-convex optimization problems in a non-adversarial setting, in many cases more relevant to practice than classical adversarial analyses. This project investigates some model problems of this nature. Here too, salvation can come in different forms: It is possible that when data is good enough (for example, if the signal to noise ratio is sufficient), local optima cannot exist; or, it is possible to initialize the algorithms close enough to the global optimum so that convergence to it is assured; or, even local optima are satisfactory to answer the underlying question. This project explores such situations through applications in community detection in large networks and through phase synchronization, as model problems for understanding challenges in a more general class of problems including, but not limited to, electron cryomicroscopy from structural biology and simultaneous localization and mapping in robotics. A common feature of many tractable non-convex optimization is that they are naturally posed on smooth nonlinear spaces called Riemannian manifolds. As a result, important algorithmic aspects of this project involve developing theory, algorithms, and software for optimization on Riemannian manifolds."
"1427193","NRI: Collaborative Research: Optimal Interaction Design Framework for Powered Lower-Extremity Exoskeletons","IIS","COLLABORATIVE RESEARCH, IIS SPECIAL PROJECTS, National Robotics Initiative","09/01/2014","06/05/2015","Joo Kim","NY","New York University","Standard Grant","Ephraim P. Glinert","08/31/2019","$597,176.00","","joo.h.kim@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7298, 7484, 8013","5952, 8086, 9251","$0.00","The goal of this project is to establish a user-centered optimal design framework for customized lower-extremity exoskeletons, in which human-exoskeleton physical interactions and dynamics can be predicted and optimized to provide design requirements.  The objectives are to establish: (1) mathematical models of disability parameters, performance indices, and desired/task-failure motions; (2) formulations for constraint status, contact load, and coupled dynamics; (3) optimization method of contact load distribution; (4) sensor integration for required data and experimental validation; and (5) prototype design modification, fabrication, and usability tests.  This research will open a new paradigm for systematic characterization of disability parameters and the desired motions from engineering perspectives, leading to user-specific mathematical models.  The potential to reduce the need for involving human subjects as part of the design iteration loop will result in accelerated development and better performing assistive devices at reduced cost.  Given the growing number of individuals who would benefit from customized exoskeletons as assistive devices, this project will have broad social impact by resolving major hurdles to their widespread use.  This research will be integrated into comprehensive education and outreach plans for minority students and individuals with disabilities.<br/><br/>The algorithm with controlled infeasibility will provide physically valid solutions of task failure as well as desired motions for integrated human-exoskeleton systems.  The concurrent formulations for constraint status/loads and coupled dynamics will resolve the problems of incorporating physical interactions into optimal motions.  As a novel design method, this project will introduce optimal contact load distribution subject to exoskeleton dynamics and transformation of a complex design into a dynamically equivalent model.  The feedback loops in the design framework will serve as self-evaluation/contingency plans.  This research will transform exoskeleton technologies through user-centered design and predictive evaluations by systematically considering end-user requirements and limitations right from the beginning and at each stage of design.  Project outcomes will represent a significant breakthrough that will bring exoskeleton technologies to the next level by (a) functioning as a central hub that systematically connects and integrates relevant disciplines; and (b) providing customized design, reduced design cycle, optimized systems with light weight and natural motion, and improved user comfort and safety."
"1505664","Breakthrough: CPS-Security: Towards Provably Correct Distributed Attack-Resilient Control of Unmanned-Vehicle-Operator Networks","CNS","CYBER-PHYSICAL SYSTEMS (CPS), Secure &Trustworthy Cyberspace","07/15/2015","07/20/2015","Minghui Zhu","PA","Pennsylvania State Univ University Park","Standard Grant","Ralph Wachter","06/30/2019","$500,000.00","Peng Liu","muz16@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7918, 8060","7434, 8225, 8234","$0.00","Inherent vulnerabilities of information and communication technology systems to cyber-attacks (e.g., malware) impose significant security risks to Cyber-Physical Systems (CPS). This is evidenced by a number of recent accidents. Noticeably, current distributed control of CPS is not really attack-resilient (ensuring task completion despite attacks). Although provable resilience would significantly lift the trustworthiness of CPS, existing defenses are rather ad-hoc and mainly focus on attack detection. In addition, while network attacks have been extensively studied, resilient-to-malware distributed control has been rarely investigated.<br/><br/>This project aims to bridge the gap. It aims to investigate provably correct distributed attack-resilient control of CPS. The project will focus on a representative class of CPS, namely unmanned-vehicle-operator networks, and its four main research thrusts are: (1) The development of a distributed attack-resilient control framework to ensure task completion of multiple vehicles despite network attacks and malware attacks, (2) The synthesis of novel distributed attack-resilient control algorithms to deal with network attacks, (3) The design of estimation algorithms to detect malware attacks on vehicles, and computationally efficient algorithms which allow clean vehicles to avoid the collision with the vehicles compromised by malware, and (4) The validation of the cost-effectiveness of the proposed distributed attack-resilient control framework via a principled systematic evaluation plan.<br/><br/>The research findings profoundly impact CPS security of a variety of engineering disciplines beyond unmanned-vehicle-operator networks, including smart grid, smart buildings and intelligent transportation systems. The proposed research is interdisciplinary and involves interactions among security, control, distributed algorithms and robotics. This will lead to educational and training opportunities that cross traditional disciplinary boundaries for high-school, undergraduate and graduate students in STEM."
"1749566","EAGER: Understanding the Impact of Making on Veterans in Pursuing STEM Degrees","DRL","ITEST","02/15/2018","02/06/2018","Anthony Dean","VA","Old Dominion University Research Foundation","Standard Grant","Robert Russell","01/31/2019","$99,000.00","Karina Arcaute, Otilia Popescu, Vukica Jovanovic, Krishnanand Kaipa","adean@odu.edu","4111 Monarch Way","Norfolk","VA","235082561","7576834293","EHR","7227","058Z, 7916, 8212","$0.00","This project will use Maker pedagogy to develop workshops to test its potential for improving the effectiveness of learning pathways in STEM disciplines for military veterans. The workshops will provide training and educational awareness in engineering topics and will include computer-aided design (CAD), rapid prototyping, 3D printing, fundamentals of bio-inspired robotics, and additive manufacturing technologies. The project will address the nation's need for workforce to learn the most current and emerging skill sets.  The workshops will be held at Old Dominion University in the Hampton Roads area of Southeastern Virginia, which serves a wide population of women, underrepresented minorities, and veterans entering into the engineering and technology workforce. <br/><br/>The research team will develop and deliver two Maker Workshops serving military veterans to foster their STEM knowledge and careers and to develop their interest and introduce the skills needed for opportunities in advanced manufacturing.  The project will carry out formative and summative evaluation that will support the development of an educational model that can be implemented in different institutions across the country with veteran or adult student learner populations. Evaluation will focus on veteran workshop participants' attitudes, behaviors, and skills, using observations from data collected through surveys and instruments, and teaching related activities.  Project results and resources will be disseminated through conferences held by a wide range of Veterans' organizations and the American Society of Engineering Education, as well through relevant educational and professional journals."
"1345163","CSUSB Center for Materials Science","HRD","CENTERS FOR RSCH EXCELL IN S&T","02/01/2014","07/06/2017","Timothy Usher","CA","University Enterprises Corporation at CSUSB","Continuing grant","Victor A. Santiago","01/31/2019","$5,295,321.00","Kimberley Cousins, Paul Dixon, Douglas Smith, Renwu Zhang","tusher@csusb.edu","5500 University Parkway","San Bernardino","CA","924072397","9095375929","EHR","9131","9131, 9179, SMET","$0.00","With National Science Foundation support and in response to the Materials Genome Initiative for Global Competitiveness, California State University San Bernardino will establish a Center for Materials Science to develop and study new organic ferroelectric materials. Although inorganic and organic polymeric ferroelectric materials are widely used, organic single molecule ferroelectrics have untapped potential for environmentally friendly materials with superior activity. Many of the known ferroelectrics have shortcomings with regard to applications, such as cost, toxicity, or limited electronic properties. While applications are not the main goal of the Center project, the computational models and experimental results should prove to be valuable tools in designing materials with desirable properties.<br/><br/>Scientific Merit: The Center consists of a disciplinarily diverse research team whose collective goals are to develop and study new organic ferroelectric materials, while at the same time strengthening active research collaborations and personnel exchange between partner institutions. The Center's systematic search for new organic ferroelectrics relies on subproject teams in three distinct areas: (1) Theory and Computation; (2) Synthesis and Structure; and (3) Experimental Investigation. In the theory/computation subproject, crystallographic databases, first principles computations, and experience-based intuition will be used to predict likely candidates. The synthesis/structure team will prepare organic compounds, grow thin films, and explore polymorphic behavior of the crystalline materials.  The experimental investigation team will then determine ferroelectric and related piezoelectric properties experimentally, as a function of temperature, pressure, film thickness, and composition, as appropriate. These results will be utilized in subsequent iterations to predict the next set of ferroelectric candidates. <br/><br/>Broader Impact<br/>Ferroelectricity and the closely related properties piezoelectricity, pyroelectricity, non-linear and high dielectric constant properties of materials have broad impacts on an extremely large range of areas. These include: scientific instrumentation, consumer products, national defense, medical devices, energy harvesting, energy storage, robotics, and aerospace. These applications represent billions of dollars to the economy and many high tech jobs. With its numerous applications, this research provides an excellent entry point to attract, then retain, encourage and motivate students, including underrepresented students. The potential for replacing environmentally unfriendly materials such as one of the leading piezoelectric, lead zirconium titanate, with more environmentally friendly organic materials should be particularly appealing. Students will receive a wide range of training on research grade instrumentation, experience with specific computational packages, and gain hands-on experience in synthetic organic chemistry and general laboratory techniques and procedures. The proposed research collaborations will further enhance the professional development of faculty at CSUSB and the partner community colleges."
"1557838","Collaborative Research: Hydrodynamic and Muscular Mechanical Investigation of Maneuverability in Cephalopods throughout Ontogeny","IOS","Physiolg Mechansms&Biomechancs","08/01/2016","07/05/2016","Joseph Thompson","PA","Franklin and Marshall College","Standard Grant","Emily Carrington","07/31/2020","$273,039.00","","joseph.thompson@fandm.edu","Office of the Provost","Lancaster","PA","176043003","7173584517","BIO","7658","9178, 9179","$0.00","Squids and cuttlefishes are impressive swimmers, having the ability to hover, change direction rapidly, and even swim forward and backward with ease.  The key to their locomotive prowess is coordination among their pulsed jet, flapping fins, and flexible arms, but little is presently known about how these units work together throughout these animals' lives as they encounter different physical environments, change developmentally, and experience dissimilar ecosystems. This project focuses on understanding how the jet, fins, and arms operate in concert to produce the necessary forces for exceptional turning, both in terms of muscle capabilities and hydrodynamics, in squid and cuttlefish of different developmental stages (hatchlings to adults).  This work will involve cutting edge 3D flow visualization approaches, high-speed video analysis, and advanced mathematical tools that highlight the essential components of high-performance turns.  This project promises to (1) advance our understanding of how highly maneuverable marine animals navigate through their complex habitats and (2) reveal key performance characteristics, structures, and behaviors that can be integrated potentially into the design of mechanical bio-inspired systems, such as autonomous underwater vehicles, to improve their turning/docking capabilities.  This project incorporates a number of outreach projects, including demonstrations in local schools, participation in robotics competitions, development of web-based tutorials and summer camps, and presentations at aquariums and museums. <br/><br/>Maneuvering in the aquatic environment is a significant component of routine swimming, with proficient maneuvering being essential for predator avoidance, prey capture, and navigation.  Despite its importance, understanding of the biomechanics of maneuvering behaviors is limited.  An investigation of maneuvering performance in three morphologically distinct species of cephalopods is proposed here.  The investigation explores three broad questions: (1) how are the fins, arms, and funnel-jet complex used in concert to maximize turning performance in adult cephalopods; (2) do the relative importance of turning rate and turning radius change over ontogeny and are fewer turning modes observed in young cephalopods; and (3) do fin, arm, and funnel musculoskeletal mechanics change over ontogeny and are such changes associated with differences in maneuvering? These questions will be addressed by collecting measurements of 3D high-speed kinematics and 2D/3D hydrodynamics of wake flows; performing mathematical analyses to quantitatively identify and categorize turning patterns; and measuring both the dynamic passive and active length-force relationship and maximum shortening velocity of muscle fibers that drive the movements used during turning and jet vectoring.  The proposed work will: (1) provide data on how an ecologically important marine animal coordinates its novel dual-mode system (jet and fins) and arms to achieve high turning performance, (2) highlight the essential kinematic and hydrodynamic elements of turns, (3) offer insights into how maneuvering capabilities change over a broad ontogenetic range, and (4) provide novel data on the muscle properties of muscular hydrostatic organs and their role in turning."
"1657550","I/UCRC:  Full Center Grant: I/UCRC for Cyber-Physical Systems for the Hospital Operating Room","CNS","INDUSTRY/UNIV COOP RES CENTERS","10/01/2015","02/09/2017","Marc Garbey","TX","The Methodist Hospital Research Institute","Continuing grant","Dmitri Perkins","12/31/2018","$674,995.00","","mgarbey2@houstonmethodist.org","6565 Fannin","Houston","TX","770302703","7134417885","CSE","5761","5371, 5761, 8039","$0.00","The proposed center seeks to establish a new Industry/University Cooperative Research Center (I/UCRC) addressing the research of cyber-physical systems for use in the hospital and operating room environments. The center will focus on computational science and technologies to advance, develop and promote research into the principles and technology of computational surgery science.  This will be achieved through research, development, education, and technology exchange among academic, industry, hospitals and government entities via the I/UCRC framework.  <br/><br/>The new center seeks to address an interdisciplinary area of central national economic importance. The center will endeavor to create a confluence of computational science, robotics, biomedical engineering, and medical expertise to positively impact the delivery of quality procedural and surgical interventions.  The proposed center has the potential to bring together a diverse set of member companies and academics to achieve its goals as well as spawn new start-ups.  The center plans to leverage an international network and new curriculum in computational surgery in order to achieve research and student impact."
"1238335","I/UCRC:  Center for e-Design","CNS","INDUSTRY/UNIV COOP RES CENTERS, ","09/01/2012","03/09/2017","Janis Terpenny","IA","Iowa State University","Continuing grant","Dmitri Perkins","08/31/2019","$1,109,090.00","Seda McKilligan, Judy Vance, Gul Okudan Kremer","jpt5311@psu.edu","1138 Pearson","AMES","IA","500112207","5152945225","CSE","5761, N113","1049, 170E, 5761, 8039, 8043, 9150","$0.00","The proposed planning activity seeks to establish a new Industry/University Cooperative Research Center (I/UCRC) site at Iowa State University of the existing Center for e-Design. The center currently involves six universities -Virginia Tech as lead, the University of Massachusetts Amherst, the University of Central Florida, Carnegie Mellon University, University of Buffalo, and Brigham Young University. The specific needs within the Center to be met by Iowa State University are focused in the following areas: 1) information technology strategies and optimization of products and systems, 2) design education and training, 3) early stage design theories and methodologies, 4) robotics and sensor integration, 5) materials, manufacturing and design, and 6) design for sustainability.<br/><br/>The proposed new site, in combination with the existing center plans to build innovation capacity by developing methods and tools that support the realization of new virtual simulation and design paradigms for development of new engineered products and systems.   The outcomes from the center have the potential to broadly impact the public and private sectors through impact on manufacturing. The site plans to have a significant impact on students via a broad range of mechanism from curriculum to design experiences.  The PI and other Iowa State faculty have a documented history of recruiting women and minority graduate and undergraduate students. Research and educational findings will be disseminated nationally and have significant broader impact through industrial collaboration and technology transfer.   <br/>"
"1528175","III: Small: Knowledge Graph Query Processing and Benchmarking","IIS","INFO INTEGRATION & INFORMATICS","10/01/2015","08/27/2015","Xifeng Yan","CA","University of California-Santa Barbara","Standard Grant","Maria Zemankova","09/30/2019","$499,978.00","","xyan@cs.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","CSE","7364","7364, 7923","$0.00","Today, if a user has a question, using Google or Bing, she still has to read through multiple web pages to find answers. This paradigm is now changing due to the rise of mobile devices. Over the last decade, it was witnessed that many systems aim to answer queries directly, e.g., using knowledge graphs collected from the Internet or through crowdsourcing.  A real sea change in information search is coming!  A broad range of new applications are emerging in intelligent policing, personal assistance, individualized healthcare, legal services, scientific literature search, and recently robotics. This project will serve these applications and make fundamental advances in querying heterogeneous knowledge graphs, which are ubiquitous. It is going to significantly ease query formulation and improve search quality/speed in these applications.<br/><br/>Given the high data heterogeneity in knowledge graphs, writing structured queries that fully comply with data specification is extremely hard for ordinary users, while keyword queries can be too ambiguous to reflect user search intent. The situation becomes even worse when there are various representations for the same entity or relation. It is expected that a sophisticated query system shall be able to support different concept representations  without forcing users to use very controlled vocabulary. It shall provide simple mechanisms to users so that they can quickly come up with a right query either explicitly or implicitly (e.g., via relevance feedback).  This proposal is going to develop such system, make it user-friendly and scalable. The proposed research includes a plan to build a flexible query benchmark that is able to cope with heterogeneous, large-scale knowledge graphs, as well as user specified configurations and performance metrics.  Benchmarks are indispensable for rapid development of database research.  There were many successful examples of how robust and meaningful benchmarks can greatly expedite the development of a research area. The query benchmark proposed in this project is very needed. It is going to (1) provide a standardized way to fairly and comprehensively evaluate different knowledge graph query algorithms, (2) improve the understanding of the existing query engines, and (3) advance the area by getting researchers involved in the same play ground for building better, faster, and more intelligent methods.<br/><br/>For further information see the project web site at: http://www.cs.ucsb.edu/~xyan/kg.html"
"1620337","Regularization of Hypersensitive Problems for Numerical Computation with Empirical Data","DMS","COMPUTATIONAL MATHEMATICS","09/15/2016","09/09/2016","Zhonggang Zeng","IL","Northeastern Illinois University","Standard Grant","Leland M. Jameson","08/31/2019","$179,984.00","","Z-Zeng@neiu.edu","5500 N Saint Louis Avenue","Chicago","IL","606254669","7734424670","MPS","1271","9263","$0.00","The aim of this project is the development of regularization theories, robust numerical algorithms, and a software package for problems that are known to be highly sensitive to data perturbations. Some of the fundamental problems in algebraic computation that remain at the frontier in numerical analysis, and where reliable algorithms and software are in demand, are of this nature. Extending on novel theories and algorithms/software developed under previous NSF support, the PI proposes to design algorithms for defective eigenvalue problems, to develop a numerical elimination strategy for polynomial systems, to validate the regularization theories, and to produce  software, NAClab. <br/><br/>This research attempts to bridge scientific fields of numerical analysis, computer algebra, algebraic geometry, and differential topology. Hypersensitive problems are known to be formidable challenges in practical computation particularly when empirical data are inevitably used. Advances in attacking those problems will enable wide range of applications.  The intellectual merit of this project lies in an innovative geometric analysis, proven regularization theory and an effective computational methodology for striking out the dreaded hypersensitivity in fundamental algebraic problems. This project is multidisciplinary in nature along with a major outcome in a robust, blackbox-type, and publicly available software toolbox NAClab to solve highly sensitive algebraic problems arising in sciences/engineering and to serve as building blocks for future algorithmic development.  The software will supply critical tools for application areas such as robotics, molecular conformation, chemical equilibrium, Nash equilibria, automatic control, as well as other branches of mathematics such as algebraic geometry."
"1435488","GOALI/Collaborative Research: Fundamental Study of Impacts of Manufacturing Processes and Automation on Material Properties of Composite Products","CMMI","Manufacturing Machines & Equip, GRANT OPP FOR ACAD LIA W/INDUS","09/01/2014","07/21/2014","Yu Zhou","NY","SUNY Institute of Technology Utica-Rome","Standard Grant","Steven R. Schmid","08/31/2019","$100,000.00","","Yu1.Zhou@sunyit.edu","SUNYIT","Utica","NY","135021311","5184378689","ENG","1468, 1504","082E, 083E, 1468, 1504, 9102, 9146","$0.00","Fiber reinforced polymer composites, by virtue of their high stiffness and high strength-to-weight ratio, are increasingly used in a wide range of industries such as transportation, marine, wind energy, aerospace, and construction. Automation of composite laminates manufacturing is instrumental in meeting the growing demand for composites and promises to revolutionize composite-dependent industries. However, the few existing layup automation systems are prohibitively expensive and are not fully optimized for product quality. This Grant Opportunity for Academic Liaison with Industry (GOALI) research aims to establish a systematic framework that will assist in solving the critical challenges in automation, monitoring and control for composite laminates manufacturing. The framework will establish the necessary fundamental understanding of relationships among composite constituents' properties, principal composite manufacturing processes and automation, and fabricated product quality. The new knowledge will help increase productivity and quality of composite laminates manufacturing. Results from this research will assist U.S. composite manufacturers and benefit the U.S. economy and society. This GOALI research employs a multi-disciplinary approach (involving solid mechanics, composites engineering, control theory and robotics) to achieve the research objectives. In addition, it incorporates research goals with industrial needs and helps broaden the participation of underrepresented groups in research and enhance engineering education. <br/><br/>This research will fill the knowledge gap in the complex interactions between fabrication parameters and laminas' temperature- and time- dependent properties (viscoelasticity and tackiness) and their impact on the properties of composite laminates (i.e., a stack of multi-directional laminas arranged to exhibit specific mechanical properties). The research team will (1) create multi-physics manufacturing process models to predict impacts of process parameters on manufacturing induced defects and final product quality, and conduct experiments to verify the models; (2) gain an understanding on the roles of quality inspection and optimal control in increasing productivity through manufacturing dynamics simulations; and (3) obtain the knowledge on how to control the physical process to ensure the product quality as a guideline for manufacturing practices."
"1502236","Problems in Higher Dimensional Algebraic Geometry","DMS","ALGEBRA,NUMBER THEORY,AND COM","08/15/2015","04/27/2017","Zsolt Patakfalvi","NJ","Princeton University","Standard Grant","Timothy Hodges","07/31/2019","$162,000.00","","pzs@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","MPS","1264","","$0.00","As a link between algebra and geometry, the main goal of algebraic geometry is to understand geometrically certain objects called algebraic varieties (i.e., common zero sets of multivariable polynomials). These very natural and fundamental algebraic objects appear frequently in many branches of mathematics and science. Hence, algebraic geometry sees many applications in other parts of mathematics such as number theory or complex geometry, and also in other scientific or engineering disciplines such as physics, coding theory, robotics, and computational biology. In particular, any general structure theory of these algebraic objects can be very useful in many fields of study. The part of algebraic geometry devoted to this structure theory is called higher dimensional algebraic geometry and it is the main subject of this research project. The project aims to further develop the theory of higher dimensional algebraic geometry. <br/><br/>For studying varieties over a field of characteristic zero and of positive characteristic, there are very different tools available. Examples of the former are Hodge theory and the related vanishing theorems, while examples for the latter are Frobenius lifting techniques or quotients by p-closed foliations. In particular, the above dichotomy yields two remarkably different cases to most conjectures of higher dimensional algebraic geometry. The particular flavor of this project is that it concerns standard topics and conjectures of higher dimensional algebraic geometry both in characteristic zero and in positive characteristic, such as higher dimensional moduli spaces, minimal model program, subadditivity of Kodaira dimension, and Shafarevich type hyperbolicity conjectures."
"1427213","NRI: Collaborative Research: Optimal Interaction Design Framework for Powered Lower-Extremity Exoskeletons","IIS","National Robotics Initiative","09/01/2014","09/05/2014","Peter Neuhaus","FL","Florida Institute for Human and Machine Cognition, Inc.","Standard Grant","Ephraim P. Glinert","08/31/2019","$458,431.00","","pneuhaus@ihmc.us","40 S. Alcaniz St.","Pensacola","FL","325026008","8502024473","CSE","8013","8086","$0.00","The goal of this project is to establish a user-centered optimal design framework for customized lower-extremity exoskeletons, in which human-exoskeleton physical interactions and dynamics can be predicted and optimized to provide design requirements.  The objectives are to establish: (1) mathematical models of disability parameters, performance indices, and desired/task-failure motions; (2) formulations for constraint status, contact load, and coupled dynamics; (3) optimization method of contact load distribution; (4) sensor integration for required data and experimental validation; and (5) prototype design modification, fabrication, and usability tests.  This research will open a new paradigm for systematic characterization of disability parameters and the desired motions from engineering perspectives, leading to user-specific mathematical models.  The potential to reduce the need for involving human subjects as part of the design iteration loop will result in accelerated development and better performing assistive devices at reduced cost.  Given the growing number of individuals who would benefit from customized exoskeletons as assistive devices, this project will have broad social impact by resolving major hurdles to their widespread use.  This research will be integrated into comprehensive education and outreach plans for minority students and individuals with disabilities.<br/><br/>The algorithm with controlled infeasibility will provide physically valid solutions of task failure as well as desired motions for integrated human-exoskeleton systems.  The concurrent formulations for constraint status/loads and coupled dynamics will resolve the problems of incorporating physical interactions into optimal motions.  As a novel design method, this project will introduce optimal contact load distribution subject to exoskeleton dynamics and transformation of a complex design into a dynamically equivalent model.  The feedback loops in the design framework will serve as self-evaluation/contingency plans.  This research will transform exoskeleton technologies through user-centered design and predictive evaluations by systematically considering end-user requirements and limitations right from the beginning and at each stage of design.  Project outcomes will represent a significant breakthrough that will bring exoskeleton technologies to the next level by (a) functioning as a central hub that systematically connects and integrates relevant disciplines; and (b) providing customized design, reduced design cycle, optimized systems with light weight and natural motion, and improved user comfort and safety."
"1539014","VEC: Small: Collaborative Research: Scene Understanding from RGB-D Images","IIS","INFORMATION TECHNOLOGY RESEARC","09/01/2015","05/26/2016","Thomas Funkhouser","NJ","Princeton University","Continuing grant","Jie Yang","08/31/2019","$135,000.00","Thomas Funkhouser","funk@cs.princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","CSE","1640","002Z","$0.00","This project exploits the benefits of RGB-D (color and depth) image collections with extra depth information to significantly advance the state-of-the-art in visual scene understanding, and makes computer vision techniques become usable in practical applications. Recent advance in affordable depth sensors has made depth acquisition significantly easier for ordinary users. These depth cameras are becoming very common in digital devices and help automatic scene understanding. The research team develops technologies to take advantage of depth information. Besides the published research results, the research team plans to distribute source code and benchmark data sets that could benefit researchers in a variety of disciplines. This project is integrated with educational programs, such as interdisciplinary workshops and courses at the graduate, undergraduate, and professional levels and diversity enhancement programs that promote opportunities for disadvantaged groups. The research team is closely collaborating with the industrial partner (Intel), involving interns and technology transfer in real products. The project is also applying the developed algorithms to the assistive technology for the blind and visually impaired.<br/><br/>This research develops algorithms required to perform real-time segmentation, labeling, and recognition of RGB-D images, videos, and 3D scans of indoor environments. Specifically, the PIs develop methods to: (1) acquire large labeled RGB-D datasets for training and evaluation, (2) study algorithms to recognize objects and estimate detailed 3D knowledge about the scene, (3) exploit the object-to-object contextual relationships in 3D, and (4) demonstrate applications to benefit the general public, including household robotics and assistive technologies for the blind."
"1657015","Science Technology Engineering and Math: Developing Education and Career Opportunity Systems","DRL","ITEST","04/01/2017","04/30/2017","Lauren Lindstrom","OR","University of Oregon Eugene","Standard Grant","David Haury","03/31/2020","$1,111,721.00","Laura McCoid","lindstrm@uoregon.edu","5219 UNIVERSITY OF OREGON","Eugene","OR","974035219","5413465131","EHR","7227","","$0.00","This project will advance efforts of the Innovative Technology Experiences for Students and Teachers (ITEST) program to better understand and promote practices that increase student motivations and capacities to pursue careers in fields of science, technology, engineering, or mathematics (STEM) by developing, testing, and disseminating tools and strategies for increasing awareness of STEM-related careers among high school students with disabilities.  Participants in the project will include students having learning, emotional, developmental, or physical disabilities who are eligible for special education services under the Individuals With Disabilities Education Act of 2004, and their teachers.  During the three-year project, investigators will: a) Study the effects of project activities on participants' confidence, interests, and efficacy in STEM learning and occupations; b) Develop local STEM Teams that each include STEM and special education teachers, industry professionals, and transition specialists in four Oregon communities; c) Provide professional development opportunities and facilitate a process for the STEM teams to build capacity to create and implement action plans to increase STEM learning experiences for students with disabilities in their schools and communities; and d) Engage 160 students with disabilities in experiential learning and career exploration using online tools, school sponsored activities such as science fairs and robotics clubs, and community experiences such as field trips and job shadowing.  The project aims to improve employment outcomes for students with disabilities, and to advance knowledge of the contexts and conditions that influence their access to high school STEM learning pathways.  Special emphasis will be given to STEM fields related to regional economic initiatives and local community resources, including advanced manufacturing, agriculture, engineering, environmental sciences, health sciences, marine biology, and natural resources.<br/> <br/>The project will test an ecological model of community, school, and individual factors thought to influence participation and interests in STEM career pathways among students with disabilities.  During year one, the project will establish a Project Design Team and four STEM Teams--one for each of four different communities in Oregon--that will work with the project's research team to develop online career exploration content and tools using an existing Career Information System that is used in over 80% of Oregon school districts and across 16 other states. The project will develop and incorporate six new STEM and disability-specific tools: a) A STEM Crosswalk of Occupations component that identifies occupations that require STEM knowledge, but less than a four-year college degree; b) An Inverse Report for Career Assessment that identifies STEM-related occupations that correlate to a students' interests, skills, and values; c) Profiles of individuals with disabilities working in STEM-related fields; d) Lessons on disability awareness, disclosure, and accommodations; e) A Resources component to foster awareness of scholarships, summer internships, and other resources to help students with disabilities succeed; and f) An interactive  Postsecondary Transition Map that can be used to visually map and manipulate a postsecondary transition plan.  The model to be implemented and tested is grounded in the findings of previous projects focusing on the creation of career development resources and implementation of collaborative school-to-work transition programs.  Following a one-year development phase, the project will conduct a design experiment with 80 students with disabilities, making revisions as needed.  The project will conclude in year three with a pilot test of the revised model.  The revised model is expected to promote specific outcomes at three levels:  a) Increased STEM efficacy, participation, and interest in STEM careers among students; b) Increased knowledge and self-efficacy in STEM and disability content and STEM career awareness among teachers; and c) Increased capacity to provide STEM learning for students with disabilities among participating schools.  A design-based implementation research approach will be used to empirically design, develop, and test the program model using a variety of standard measures as pretests and posttests, a range of usage analytics, and custom reports to measure project progress and impact."
"1619630","Feature-Based Data Assimilation and Uncertainty Quantification for Complex Systems in Science and Engineering","DMS","COMPUTATIONAL MATHEMATICS","08/01/2016","06/19/2018","Matthias Morzfeld","AZ","University of Arizona","Continuing grant","Leland M. Jameson","07/31/2019","$249,999.00","","mmo@math.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","MPS","1271","1303, 8396, 8399, 9263","$0.00","The basic idea of data assimilation is to update a computational model with information from sparse and noisy data so that the updated model can be used for predictions. Data assimilation is at the core of computational geophysics, most notably in numerical weather prediction, oceanography, and geomagnetism, and is used widely in engineering applications, ranging from robotics to reservoir modeling. In the usual approach one attempts to refine a computational model such that its outputs match data. However, matching model outputs directly to data is often unnecessary or even undesirable. In this project, data assimilation is extended so that computational models can be updated based on features in the data, rather than the raw data themselves. The feature approach reduces an intrinsic dimension and is applicable to large scale problems in geosciences and engineering, with specific applications in geomagnetic dipole reversals, cloud modeling, and uncertainty quantification for solar cells.<br/><br/>The primary technical aim of this project is to extend data assimilation such that computational models can be calibrated against features observed in the data, rather than the raw data. This can be achieved within a Bayesian framework by replacing the data with a suitable low-dimensional feature, computed from the data. The resulting feature-based likelihood can be used to assimilate selected aspects of fine-scale data into coarse, low-dimensional models. More generally, the use of features reduces the dimension of the likelihood, which in turn reduces the computational requirements of feature-based data assimilation by Monte Carlo methods. The mathematical foundations of the feature-based approach will be explored by rigorous analysis. New computational methods for feature-based data assimilation will be created, which combine machine learning techniques with Monte Carlo sampling. The efficiency of these methods will be assessed by interdisciplinary collaboration with scientists in geosciences and engineering in three specific applications. Specifically, feature-based data assimilation algorithms will be developed for the study of superchrons of Earth's magnetic dipole field, to determine the geophysical relevance of low-dimensional cloud models, and for uncertainty quantification of thin-film polymeric reflectors for solar power generation. These applications will collaboratively connect scientists (faculty, postdocs and students) across several disciplines (geosciences, engineering, mathematics). Undergraduate and graduate students at the University of Arizona will be trained as part of the project and will aid in producing and disseminating key results. The research activities will be accompanied by an outreach plan, implemented as part of the G-Teams program within the Department of Mathematics at the University of Arizona. A central outreach theme is to demonstrate, for K-12 teachers and their students, mathematics ""in action"" by applying mathematical concepts to problems relevant to our society."
"1815337","RI: Small: Expressive Reasoning and Learning about Actions under Uncertainty via Probabilistic Extension of Action Language","IIS","ROBUST INTELLIGENCE","08/01/2018","06/18/2018","Joohyung Lee","AZ","Arizona State University","Standard Grant","James Donlon","07/31/2021","$363,799.00","","joolee@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7495","7495, 7923","$0.00","Automated reasoning about dynamic worlds is an important capability for robust intelligent systems.  Action languages allow for the description of actions and their effects in dynamic domains in a way that is based on natural language but sufficiently formal for modeling in knowledge-based systems. Today's action languages do not easily allow such systems to account for the probability and uncertainty necessary to model human-like commonsense reasoning.  Existing action languages also assume full specification of a system in advance of one-shot execution of the logic program, which does not easily operate with continuous streams of data.  This project will develop an action language based on the mathematical foundation that combines logic and probability.  The research will join the representation and reasoning advantages of logical AI to the advantages in statistical AI to compute and learn quantitative specifications from data. The new action language will jointly address commonsense reasoning and learning about actions in uncertain dynamic domains.  Such a system allows us to scrutinize and understand the system behavior, which is vital to the design of systems that are explainable and interpretable.<br/><br/>The project is to design and implement a novel action language that is highly expressive for modeling various aspects of dynamic systems under uncertainty and which applies to knowledge-rich diagnosis and stream reasoning. The formalism will be built upon a recent probabilistic extension of answer set programs, called LPMLN, which incorporates the weight scheme of Markov Logic into the language of answer set programming. The formalism will enable probabilistic diagnostic reasoning and counterfactual reasoning about dynamic domains. Inference and learning methods for the probabilistic action language will be derived from the methods in logic programming and statistical relational learning. The framework will be further extended to integrate reasoning over observations given as streams of data. The methods produced will be useful for several applications that require integration of knowledge representation and other areas, such as robotics and autonomous systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1455983","BCSP: The Emergence of Inactivity: Adaptive Task Allocation in Complex Distributed Systems, or Why Are There so Many Lazy Ants?","IOS","ANIMAL BEHAVIOR","06/01/2015","05/26/2017","Anna Dornhaus","AZ","University of Arizona","Continuing grant","Michelle M. Elekonich","05/31/2019","$695,000.00","Nancy Lynch","dornhaus@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","BIO","7659","1228, 9179","$0.00","One of the most important, perhaps the biggest unanswered question in biology is how a collection of relatively simple parts can form structures that are organized, effective and often beautiful. This occurs in the origin of life, where clusters of molecules form cells; in development, where initially unspecialized cells form an embryo; and in many other systems, including insect colonies, where an aggregation of small insects generates adaptive group behavior. The same phenomenon also affects humans more directly, where computer clusters, power grids, and people in organizations display unforeseen group-level behavior. This project specifically investigates the behavioral rules that individual units in such groups may use to divide up tasks. Division of labor plays an important role in many collective systems and a systematic understanding of how best to achieve it is lacking. This project will make substantive contributions to the fields of Animal Behavior, Computer Science and Engineering.  Ants will be used as an empirical study system and mathematical models will be developed to generalize findings to a variety of questions, particularly in engineering. Results from this project will be used as a stepping-stone to applied software development. An interdisciplinary teaching program will be developed to train a new generation of biologists and engineers who can make use of insights from both of these fields. Short film documentaries and other teaching tools will engage the general public.<br/><br/>This project aims to provide both detailed empirical data on how social insect colonies generate an efficient and robust division of labor and a broader theoretical framework that will deliver insights on optimized, self-organized task allocation that applies widely across complex systems. Individually marked ants and a semi-automated tracking system will facilitate comprehensive data collection. For example, do fluctuations in the need for work drive changing activity levels? This will show whether the many apparently inactive ants found in colonies are necessary reserves and how flexible task allocation strategies are. The effect of task allocation on insect colony fitness will be directly measured. The development models will be used to predict how inactivity may result from particular strategies and how alternative strategies perform in terms of accuracy, flexibility, robustness and specialization. In distributed computing theory, this work will push the envelope by providing more powerful models that take into account a combination of discrete, continuous, dynamic and probabilistic behavior. The investigators will also hold an annual workshop on Biological Distributed Algorithms, bringing together top researchers in biology, computing and robotics."
"1820462","SBIR Phase I:  Low-cost real-time perception system for self-driving consumer cars","IIP","SMALL BUSINESS PHASE I","06/15/2018","06/15/2018","Koji Seto","CA","Apollo AI Inc.","Standard Grant","Muralidharan S. Nair","05/31/2019","$225,000.00","","kojiseto@apolloaisystems.com","1267 Willis Street, STE 200","Redding","CA","960010400","4087581593","ENG","5371","5371, 8034","$0.00","The broader impact/commercial potential of this project is the practical deployment of a low-cost and low-power real-time perception system in self-driving consumer cars. This edge computing functionality in sensors enables higher reliability and lower cost of overall sensing and computing needed for truly autonomous self-driving. Such innovation will contribute significantly to the early and widespread availability of safety and convenience benefits to consumers. Furthermore, the advanced perception system will have a potential long-term impact on robotics in general, which can lead to creation of new markets and new lifestyles.<br/><br/>This Small Business Innovation Research (SBIR) Phase I project aims to develop efficient algorithms and software implementation of a real-time perception system to enable the use of low-cost computing systems for self-driving cars. The algorithms provide a novel way of using image features to perform simultaneous localization and mapping (SLAM) with 100 times less computational costs than the existing algorithms. They also include a truly novel neural network to fuse the image feature and light detection and ranging (LiDAR) features and perform object detection, which has 100 times less complexity compared to the state-of-the-art method. These reduced-complexity algorithms can be implemented on low-power and low-cost SoC processors.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1820469","SBIR Phase I:  A CVML platform for intelligent machines","IIP","SMALL BUSINESS PHASE I","06/15/2018","06/15/2018","BINU MATHEW","CA","KRAENION LABS LLC","Standard Grant","Peter Atherton","11/30/2018","$224,996.00","","BINU@SATVAD.COM","17094 LON RD","LOS GATOS","CA","950330000","6502839142","ENG","5371","5371, 8033","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is that it will enable small and mid-size robotics and industrial vehicle manufacturers to rapidly deploy computer vision and machine learning in their products and make their machines competitive in the global market place. The project will create a multi-vendor real-time vision stack for industrial machines that enables multiple types of machines to be developed using a uniform software interface. Combined with an app store model, such interfaces will enable a developer community to create application-specific solutions with ease, add features to machines via software and essentially create a new market. When deployed by equipment manufacturers, it will have societal impact by reducing the number of forklift and other industrial and construction machine related accidents, deaths and property damage. There are secondary benefits such as reducing the amount spent on worker compensation. The scientific impact will be the enhanced understanding of principled approaches to stereoscopic depth estimation combined with machine learning based object detectors to create integrated vision systems that function in real-time on commodity hardware.<br/><br/>This Small Business Innovation Research (SBIR) Phase I project addresses the fact that current solutions for autonomous vehicles and machines use expensive LIDARs and RADARs in conjunction with cameras. Such systems are cost-prohibitive and ill-suited for industrial applications that operate in structured warehouse and manufacturing environments rather than highways. Manufacturers can benefit from a cheaper integrated vision-based system where all the necessary algorithms, software and hardware engineering has already been done for them. The intellectual merit of the project lies in achieving the following research goals. 1) Develop an algorithmic approach to stereoscopic depth estimation that combines quick-to-generate classic features (e.g., edges and corners) with machine learning. 2) Combine machine learning based object detectors with stereoscopic depth to create an integrated vision pipeline that functions in real-time on commodity hardware. 3) Devise methods to train the system more easily by relying on depth and motion features. 4) Address critical operational design considerations such as thermal and power management and understand requirements to maintain mechanical and structural integrity through periods of intense use.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1525855","CSR: Small: Scaling the Real-time Capabilities of Powertrain Controller in Automotive Systems","CNS","Computer Systems Research (CSR","10/01/2015","08/18/2015","Aviral Shrivastava","AZ","Arizona State University","Standard Grant","M. Mimi McClure","09/30/2018","$449,506.00","","aviral.shrivastava@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7354","7923","$0.00","CSR: Small: Scaling the Real-time Capabilities of Powertrain Controllers in Automotive Systems<br/><br/>ScratchPad Memory(SPM)-based many-core architecture is a promising concept to improve the real-time capability of computing systems required in safety-critical applications. Demonstrating the proposed approach for powertrain controllers is just the first step and has the potential to enable the rapidly increasing fields of internet-of-things (IoT), avionics, robotics, cyber-infrastructure, and much more. An open-source cycle-accurate simulator of the SPM-based many-core processor, and a low level virtual machine (llvm) compiler will be developed as the outcome of this research significantly advancing this technology. <br/><br/>This project will develop architecture, compilation, scheduling techniques, and real- time analysis to scale up the real-time capabilities of powertrain controllers of automotive systems. Powertrain controller is a safety-critical, hard-real-time controller in modern automobiles, directly responsible for the operation of the engine and transmission. The complexity of powertrain control applications is rapidly increasing in a quest to fulfill increasingly stringent regulations on the fuel- efficiency and emissions. To meet this demand, the real-time capability of powertrain engine control units (ECU) must also improve. Real-time capability of a processor is essentially a measure of how many/complex/frequent tasks can be guaranteed to finish in given deadlines. The challenge is that the real-time capability of a processor cannot be improved by traditional performance enhancing techniques, e.g., increasing frequency, adding more on-chip memory, or by adding caches. This research will employ (SPMs) instead of caches to improve the real-time capability of powertrain ECUs.  SPM partitioning, mapping/scheduling, SPM management techniques and real-time analyses for SPM-based many-core architecture (in which each core has an SPM instead of a cache) will be developed. This will be done for two data management schemes: one for task-level management, where all the code and data of the task are brought into the SPM at the beginning of the task and the other for function-level management, which enables executing applications on processors with much smaller SPM sizes, and can still be efficient through various compiler optimizations."
"1736087","RI: Small: Collaborative Research: Cooperative Autonomous Vehicle Routing under Resource and Localization Constraints","IIS","ROBUST INTELLIGENCE","01/01/2017","03/06/2017","Rajnikant Sharma","OH","University of Cincinnati Main Campus","Standard Grant","Reid Simmons","08/31/2019","$215,523.00","","rajnikant.sharma@uc.edu","University Hall, Suite 530","Cincinnati","OH","452210222","5135564358","CSE","7495","7495, 7923","$0.00","This project aims to develop novel algorithms required to deploy Unmanned Vehicle (UV) networks with resource constraints in Global Positioning System (GPS) denied environments. The methods developed in this project will be useful in a wide variety of applications of national importance such as disaster management, border surveillance, monitoring of civilian infrastructure including oil pipelines, power grids, harbors, inland waterways, and intelligent transportation systems where GPS signals can be easily jammed either intentionally or unintentionally. The proposed research spans several areas including control, estimation, sensing, robotics and optimization. This project provides a rich opportunity for involving undergraduate and graduate students in the development of vehicle platforms, sensor networks, and in the implementation of the control and optimization algorithms. This project engages minority students in small research projects to motivate their interest in engineering and science. Enabling autonomous unmanned vehicles with a capability of navigating in GPS denied environments can aid in effectively monitoring large infrastructure systems, protect their structural integrity and functional reliability as well as provide ecological, societal and economic benefits, including better preservation of natural resources, reduced property damage and reduced loss of life.<br/><br/>This proposal addresses the following fundamental problem that arises while deploying unmanned vehicles in GPS-denied environments: Given a set of vehicles and targets to visit, find a path for each vehicle such that each target is visited at least once by some vehicle, the error in the position estimate of each vehicle at any time instant is within a given bound and an objective which depends on the travel and sensing costs is minimized. The specific technical objectives of this project are to: determine the minimal set of requirements that would render the system of vehicles observable over a time period, develop novel approximation and exact algorithms using cutting plane, rounding and Lagrangian dual methods for the optimization problems, and experimentally corroborate the performance of the proposed algorithms using large scale and hardware-in-the-loop simulations, and field demonstrations. It is anticipated that this project will significantly advance the state of art in the area of observability analysis for a team of cooperatively localizing vehicles, and in the area of tractable, approximation and exact algorithms for vehicle placement and path planning problems with resource and localization constraints. Novel cutting plane, rounding, and Lagrangian dual methods are expected to provide new insights into efficient ways of decomposing the difficulties in the vehicle placement and path planning problems, and will lead to good feasible solutions with approximation bounds. The proposed large scale simulation and experimental results will provide a new understanding of the influence of the different parameters (number of landmarks/vehicles/targets, bounds on acceptable position errors, onboard sensor type, different operational environments, and the speed of each vehicle) on the performance of the vehicle localization/path planning system."
"1609076","Development and Study of Structurally-Dynamic Covalent Polymers","DMR","POLYMERS","07/01/2016","03/15/2016","Stuart Rowan","IL","University of Chicago","Standard Grant","Andrew J. Lovinger","06/30/2019","$434,441.00","","stuartrowan@uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","MPS","1773","","$0.00","PART 1:   NON-TECHNICAL SUMMARY<br/><br/>Traditional polymers or plastics have been designed to minimize degradation (e.g. by breaking of covalent bonds) and as such maintain their mechanical properties over their lifetime. This has led to a wide range of very useful materials (such as fibers, plastics and adhesives) that are ubiquitous in our daily lives. One issue with such materials is that when they break or degrade it can be difficult and/or not cost effective to repair or recycle them. What if plastics could be accessed that would allow them to either heal scratches or deformations or to be more efficiently recycled. One way to achieve this is to design into the polymer structure reversible bonds that can be broken and remade upon application of a relatively small amount of heat or light. With this NSF funding the Rowan group is working on a range of different stimuli-responsive reversible bonds that will be incorporated into polymers and used to access new classes of responsive/adaptive materials. A key component of these systems is the ability to systematically control the stimulus required to access the reversible character of the bond which in turn allows them to be tailored for different applications. With these materials the Rowan group will focus on the development of (1) new soft actuators that act like 'polymeric muscles' and offer applications to (soft) robotics, (2) materials that exhibit both scratch-healing characteristics as well as enhanced toughness to extend their useful operational lifetime, and (3) on-demand reversible glues and adhesives. This project involves graduate and undergraduate students, students from local high schools, including students from underserved and predominately minority neighborhoods of Chicago. The integrated approach of this project provides students at all levels with an exciting learning environment and broad research experiences. In addition, Prof. Rowan and his research group will design new hands-on demonstrations for a Museum outreach program entitled ""Nature's Materials"", which is part of the Cleveland Museum of Natural History's ""Winter Discovery Day"" on Dr. Martin Luther King Jr. Day.  This program aims (i) to expose the local community to polymers and how Nature's materials can help us create a sustainable planet, and (ii) to train current graduate students on how to communicate to and educate the general public and younger students about science and technology.<br/><br/><br/>PART 2:   TECHNICAL SUMMARY<br/><br/>The introduction of dynamic bonds (that can undergo reversible exchange) into a polymer network imparts new adaptive properties onto the materials. The adaptive properties come from the network's ability to alter its architecture (and/or composition) through dynamic bond exchange and as such have been termed structurally-dynamic polymers. Depending on the specific type, placement and amount of the dynamic bond incorporated into the network the resulting films will have the ability to be re-processable/re-moldable, exhibit healing and/or shape-memory properties, and even open the door to materials that have enhanced toughness, stress relaxation, and/or adaptive adhesion capabilities. This proposal outlines the synthetic as well as structural (via NMR, MALDI-MS, FT-IR, UV, POM and WAXS/SAXS) and mechanical (rheology, tensile testing, and dynamic mechanical thermal analysis) studies on three different classes of structurally-dynamic polymers, focusing not only on investigating the basic science of these systems but also on targeting specific applications that suit the specific dynamic behavior of the film's chemistry. Specifically, the Rowan group will focus on the synthesis, characterization, and investigation of (1) poly(disulfides), (2) thia-Michael adduct-containing polymers and (3) poly(alkylureas). While poly(disulfides) networks are known and have been investigated as healable materials, their use to access photo-adaptive liquid crystalline elastomers is new.  Specific interest is in accessing 3D actuating films with this class of material. The thia-Michael reaction can be dynamic at room temperature, but to date, this class of dynamic bond has received little attention in the polymer field. The advantage of this bond is that both its exchange thermodynamics and kinetics can be systematically altered by changing the electronics of the alkene (Michael acceptor). The final class of dynamic bond the PI will investigate is the most commercially relevant and is based on bulky alkylureas. Alkylureas are used as blocked (protected) isocyanates in the polyurethane industry that deblock at temperatures >100C. The PI will target/develop alkylureas and derivatives that can deblock at lower temperatures. The goal for these last two classes of materials is to develop structure/property relationships focusing on their solid state mechanical and adaptive properties."
"1562098","RI: Medium: Collaborative Research: Text-to-Image Reference Resolution for Image Understanding and Manipulation","IIS","ROBUST INTELLIGENCE","06/01/2016","09/14/2017","Tamara Berg","NC","University of North Carolina at Chapel Hill","Continuing grant","Jie Yang","05/31/2019","$275,000.00","","tlberg@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7495","7495, 7924","$0.00","This project develops new technologies at the interface of computer vision and natural language processing to understand text-to-image relationships. For example, given a captioned image, the project develops techniques which determine which words (e.g. ""woman talking on phone"", ""The farther vehicle"") correspond to which image parts. From robotics to human-computer interaction, there are numerous real-world tasks that benefit from practical systems to identify objects in scenes based on language and understand language based on visual context. In particular, the project develops the first language-based image authoring tool which allows users to edit or synthesize realistic imagery using only natural language (e.g. ""delete the garbage truck from this photo"" or ""make an image with three boys chasing a shaggy dog""). Beyond the immediate impact of creating new ways for users to access and author digital images, the broader impacts of this work include three focus areas: the development of new benchmarks for the vision and language communities, outreach and undergraduate research, and leadership in promoting diversity. <br/><br/>At the core of the project are new techniques for large-scale text-to-image reference resolution (TIRR) that enable systems to automatically identify the image regions that depict entities described in natural language sentences or commands. These techniques advance image interpretation by enabling systems to perform partial matching between images and sentences, referring expression understanding, and image-based question answering. They also advance image manipulation by enabling systems that can synthesize images starting from a textual description, or modify images based on natural language commands. The main technical contributions of the project are:  (1) benchmark datasets for TIRR with comprehensive large-scale gold standard annotations that will make TIRR a standard task for recognition; (2) principled new representations for text-to-image annotations that expose the compositional nature of language using the formalism of the denotation graph; (3) new models for TIRR that perform an explicit alignment (grounding) of words and phrases to image regions guided by the structure of the denotation graph; (4) applications of TIRR methods to referring expression understanding and visual question answering; and (5) applications of TIRR to image creation and manipulation based on natural language input."
"1819203","Computational Filtering Methods for Time-Varying Parameter Estimation in Nonlinear Systems","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/07/2018","Andrea Arnold","MA","Worcester Polytechnic Institute","Standard Grant","Matthias Gobbert","06/30/2021","$220,458.00","","anarnold@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","MPS","1271","9263","$0.00","Many applications in modern science involve unknown system parameters that must be estimated using little to no prior information.  In mathematical models to analyze and predict the behavior of such systems, the problem of estimating and quantifying uncertainty in model parameters remains a challenge.  This is particularly true for systems where knowledge of parameter values is critical in obtaining trustworthy model output, as in patient-specific models for personalized medicine, for example.  A subset of these problems includes parameters of the type that are known to vary with time but do not have known evolution models.  Examples include the seasonal transmission parameter in modeling the spread of infectious diseases and the external voltage parameter in modeling the spiking dynamics of neurons.  In certain cases, the parameters may have some known structural characteristics (such as periodicity) that can be utilized in and maintained throughout the estimation process. However, the main challenge in estimating time-varying parameters lies in accurately accounting for their time evolution without detailed information regarding their temporal dynamics.  The goal of this project is to design and analyze novel computational methods for estimating such time-varying parameters.<br/><br/>The aim of this study is to design and analyze novel computational methods for estimating time-varying parameters through use of nonlinear filtering.  Leveraging the strengths of the Bayesian statistical filtering framework, where prior beliefs are naturally incorporated, this work will involve developing models for parameter evolution that take into account prior knowledge relating to the structure or behavior of the parameter over time without defining explicit functions to describe the dynamics.  Methods will also be developed for more difficult problems where there may not be any parameter structural characteristics known a priori.  The algorithms and computational tools developed in this study will be applied to data for a variety of nonlinear systems, which may further inspire new directions for methodological advancement.  Specific areas of application include engineering and the life sciences, with particular application to surgical robotics involving tissue thermal response to laser-based microsurgery.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1352073","CAREER: Nonnegative Polynomials, Sums of Squares and Real Symmetric Tensor Decompositions","DMS","ALGEBRA,NUMBER THEORY,AND COM, Division Co-Funding: CAREER","05/15/2014","06/06/2018","Grigoriy Blekherman","GA","Georgia Tech Research Corporation","Continuing grant","Matthew  Douglass","04/30/2019","$400,000.00","","greg@math.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","MPS","1264, 8048","1045","$0.00","This project investigates links between optimization problems arising in applications and the classical mathematical area of real algebraic geometry. Nonnegative polynomials and sums of squares are the key objects linking optimization and algebraic geometry. The PI will carry out research that sheds light on the computational quality of sums-of-squares methods while building new connections with algebraic geometry. Such connections between mathematics, engineering, and natural sciences enrich mathematics by bringing new types of questions, new perspectives, and new directions of research. The PI will also organize two summer workshops for graduate students centered around student presentations on applications of algebraic geometry. The participating students will be exposed during their graduate studies to perspectives from several different scientific fields, while learning from their own peers.<br/><br/>The PI will investigate the connection between nonnegative polynomials and sums of squares in all of its aspects: algebraic, algorithmic, analytical. The PI will also study the closely related topic of real symmetric tensor decompositions. Understanding nonnegativity and its relation with sums of squares is one of the basic challenges of real algebraic geometry. Sums of squares methods have applications in diverse areas such as control and optimization, robotics, and complexity theory. Nonnegativity and sums of squares also have intrinsic connections to classical topics in algebraic geometry. The fundamental research that PI will carry out will lead to furthering these connections, while also improving the understanding of the computational quality of sums of squares algorithms. The PI will also research fundamental geometric aspects of real symmetric tensor decomposition, which are not nearly as well understood as for complex tensors."
"1566248","CRII: RI: Towards Large-Scale Recognition and Fine-Grain Analysis of Human Actions: Pulling Actions Out of Context","IIS","CRII CISE Research Initiation","08/01/2016","06/02/2017","Minh Hoai Nguyen","NY","SUNY at Stony Brook","Continuing grant","Jie Yang","07/31/2019","$174,855.00","","minhhoai@cs.stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","CSE","026Y","7495, 8228","$0.00","This project investigates problems of human action recognition in video. A human action does not occur in isolation, and it is not the only thing recorded in a video sequence. A video clip of a human action also contains many other components, including the background scene, the interacting objects, the camera motion, and the activity of other people. Some of these components are contextual elements that frequently co-occur with the category of action in consideration. The project develops technologies that separated human actions from co-occurring factors for large-scale recognition and fine-grain visual interpretation of human actions. The developed technologies can have many practical applications in a wide range of fields, ranging from human computer interaction and robotics to security and health-care. <br/> <br/>This research develops an approach to human action recognition by explicitly factorizing human actions from context. The key idea is to exploit the benefits of the information from conjugate samples of human actions. A conjugate sample is defined as a video clip that is contextually similar to an action sample, but does not contain the action. For instance, a conjugate sample of a handshake sample can be the video sequence showing two people approaching each other prior to the handshake. The handshake clip and the video sequence preceding it have many similar or even the same contextual elements, including the people, the background scene, the camera angle, and the lighting condition. The only thing that sets these two video clips apart is the actual human action itself. A conjugate sample provides complementary information to the action sample; it can be used to suppress contextual irrelevance and magnify the action signal. The specific research objectives of this project include: (1) collecting human action samples for many action classes; (2) developing algorithms to mine and extract conjugate human action samples; and (3) developing a framework that utilizes the benefits of conjugate samples for separating actions from context to learn classifiers for large-scale recognition and fine-grain understanding of human actions."
"1749833","CAREER:Towards Perceptual Agents That See and Reason Like Humans","IIS","ROBUST INTELLIGENCE","06/01/2018","06/01/2018","Subhransu Maji","MA","University of Massachusetts Amherst","Standard Grant","Jie Yang","05/31/2023","$545,586.00","","smaji@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","7495","075Z, 1045, 7495","$0.00","Recent advancements in computer vision systems have enabled their widespread deployment in areas like social media, healthcare, robotics, and ecology, among many others. While such applications hold exceptional promise for improving our well-being and advancing scientific discovery, the ubiquity of these intelligent systems presents new technical, social, and cultural challenges for their wide-scale adoption. This project leads an integrated effort of research, teaching, and outreach to address some of these challenges. The project develops architectures that are substantially more accurate and capable of extracting detailed information from perceptual data across different modalities. An emphasis of this work is to develop computer vision systems that can reason about data in ways that are interpretable by humans. This project also promotes diversity, engages high school, undergraduate, and graduate students in research activities, and fosters collaborations with industry and researchers in areas such as ecology and biology through workshops.<br/><br/>This research explores new directions that improve the capabilities of visual perception and reasoning systems for analyzing image data, spatio-temporal data, and depth data. The research develops a novel class of graph-based and factorized architectures for 3D shape and spatio-temporal analysis that provide better tradeoffs between computational cost, memory overhead, and accuracy than existing models. The research develops weakly supervised techniques for learning shape and motion representations from large amounts of unlabeled data. The research also develops a novel class of techniques for transforming visual data to semantic representations such as attributes, natural language, and symbolic programs. These techniques will improve the interpretability of machine learning models and enable collaborative learning and inference between humans and AI agents.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1566545","Manufacturing Certifications for Rural High School Students through Community College Dual Enrollment","DUE","ADVANCED TECH EDUCATION PROG","06/01/2016","08/10/2016","David Dunkle","FL","North Florida Community College","Standard Grant","Elizabeth Teles","05/31/2019","$187,267.00","Nancy Lillis, William Eustace","dunkled@nfcc.edu","325 NW Turner Davis Dr.","Madison","FL","323401611","8509731661","EHR","7412","1032, 9178, SMET","$0.00","North Florida, like other rural areas, must adequately prepare the next generation of skilled technicians in the sector of advanced manufacturing because local manufacturing companies require highly qualified and skilled manufacturing and engineering technicians with appropriate soft skills to be successful. Participants who secure high-paying jobs can support themselves and contribute to the growth and prosperity of the community. This project at North Florida Community College (NFCC) is designed to develop an advanced manufacturing dual enrollment project with Madison County high school students. The project will result in career pathways leading from two local high schools to the community college to employment as technicians. This project will include dual enrollment (DE), career and technical education (CTE), industry partnerships, and soft skills development. This unique combination of project components is designed to meet the specific needs of rural high school students and rural manufacturing companies. Project findings will be widely disseminated throughout Florida and can serve as a model for other rural communities throughout the United States. A comprehensive evaluation will be conducted to document successes and guide project development. <br/><br/>The goal of the project is to recruit and educate underrepresented (rural, first-generation in college, minority) high school students who will graduate with strong soft skills and successful completion of the Automation and Production Technology (APT) course including the Manufacturing Skill Standards Council (MSSC) Certified Production Technician (CPT) credential. The APT program is comprised of four components and the project participants will complete each of the four components during subsequent semesters.The college plans to use summer hands-on workshops in robotics, 3D printing, and SolidWorks to introduce the project to potential students. Central to the project will be the development of employer-sought soft skills including team-building and problem-solving. Project participants will be involved in scenarios that require them to solve unfamiliar problems, communicate effectively, assume leadership or follower roles, work collaboratively, and think critically. Industry partners will interact with students through classroom visits and facility tours. NFCC has the commitment of industry partners to provide program support including tours of manufacturing facilities, guest speakers and content lecturers, mock interviews, and hiring opportunities to students who successfully complete the program. Secondary-postsecondary team teaching will provide professional development to expose all instructors to both high school and college environments. The professional development component, during which high school and college faculty team teach, will strengthen the bond between these two sectors of the educational community as well as model the skills essential for collaborative work. The MSSC CPT certification will translate into 15 credit hours toward the newly developed AS Degree in Engineering Technology at the college or elsewhere in the Florida College System. This will provide a pathway to a baccalaureate degree and higher skilled employment for students."
"1752125","CAREER:  Dynamic Decision-Making Under Uncertainty via Distributionally Robust Optimization","ECCS","ENERGY,POWER,ADAPTIVE SYS","03/15/2018","03/09/2018","Grani Adiwena Hanasusanto","TX","University of Texas at Austin","Standard Grant","Radhakisan S. Baheti","02/28/2023","$500,000.00","","grani.hanasusanto@utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","ENG","7607","092E, 1045","$0.00","A wide spectrum of decision problems arising in process control, energy systems operation, supply chain management, investment planning, project management, engineering, economics, etc., involve uncertain parameters whose values are unknown to the decision maker when the decisions are made. Ignoring this uncertainty typically leads to inferior solutions that perform poorly in practice due to the notorious flaw of averages, whereby plans based on the assumption that average conditions pre-vail are usually wrong. These decision problems are often also dynamic in nature they span across multiple time stages and involve high dimensional non-anticipative recourse decisions which further increase the problem complexity. Thus, effective and efficient solution schemes for these decision problems are highly desirable. Traditional solution schemes, however, suffer from the curse of dimensionality and are extremely challenging to solve. Recent advances in distributionally robust optimization (DRO) have been successful in mitigating the intractability of various single-stage decision problems under uncertainty. In DRO, we seek a decision that performs best in view of the most adverse distribution of uncertain parameters that is consistent with the available statistical and structural information. Thus, DRO not only improves computational tractability but also alleviates the overfitting effects characteristic of the traditional solution schemes. By leveraging and inventing new techniques in DRO, the proposed research work aims to significantly advance the state-of-the-art methodologies for addressing the challenges of dynamic decision problems and to initiate the effort for industrial-size applications. The research outputs of this work will have a significant and immediate practical impact on important applications in energy, engineering, machine learning, operations management, finance, etc., and on learning problems in robotics and automatic control. This CAREER work will also advance the state of pedagogy by developing an integrated curriculum that bridges the gap between the deep theory of decision-making under uncertainty and the real-life practice. The proposed curriculum is aimed at future practitioners and researchers, and is designed to equip these experts with the analytical skills and tools to deal with real-life decision-making problems under uncertainty.<br/><br/>The proposed research work is aimed at addressing a major gap in the theory and practice of decision-making under uncertainty. It concentrates on four main research thrusts: 1) Derive exact mixed-integer conic programming (MICP) reformulations for convex dynamic problems as well as for dynamic problems with discrete decisions 2) Deal with the case of endogenous uncertainty whose representation depends explicitly on the chosen decisions 3) Systematically integrate data into the description of uncertainty. Obtain provable out-of-sample performance guarantees from the resulting data-driven DRO models 4) Derive exact MICP reformulations for inverse optimization problems in the dynamic setting. The proposed research effort endeavors to develop more powerful solution schemes which leverage standard off-the-shelf MICP solvers for various intractable decision-making problems under uncertainty. The work will establish a new connection between generic dynamic DRO models and renowned classes of mixed-integer conic programs. The resulting connection will give us a better understanding of the inherent difficulty of the decision problems and enable us to derive attractive performance guarantees for the new solution schemes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1824329","Meeting: 13th International Congress of Neuroethology, Brisbane, Australia, July 15 through July 20, 2018","IOS","ACTIVATION","06/01/2018","05/14/2018","Harold Zakon","TX","University of Texas at Austin","Standard Grant","Sridhar Raghavachari","05/31/2019","$20,000.00","","h.zakon@mail.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","BIO","7713","1096, 7556, 9179","$0.00","This award will provide support to US-based students and post-doctoral fellows and junior scientists to attend the 2018 International Congress on Neuroethology. This five-day conference is recognized as the major, mid-size meeting in Neuroethology, bringing together outstanding senior and junior scientists for discussions of the recent advances in the field. Invited speakers across many areas of neuroethology, will present their findings on how the activity of animal brains give rise to natural behaviors. The comparative approach that is at the heart of neuroethology, facilitates the identification of common principles of brain organization as well as detecting mechanisms that enhance behavioral performance, which can then be implemented computationally or technologically. The meeting features sessions that will showcase how biological solutions inform new conceptual and technological advances in bio-inspired robotics, smart machines and neural modeling. The results presented at the meeting will have the potential to guide future developments in multiple areas, including neurally inspired design of engineered systems that will have considerable societal benefits. <br/><br/>The intellectual merit of this meeting derives from its small size, which promotes interactions between participants, and the assembly of many top scientists whose research spans neurobiology, engineering and neuropathology. It spans a wide variety of experimental systems and focuses on areas of exceptional activity or promise. This combination leads to fruitful comparative analyses, raises new questions about underlying mechanisms and often leads to new collaborations. By maximizing both formal discussion and informal interactions, the International Conference on Neuroethology will highlight exciting new developments in neuroethology and engineering approaches in neurobiology. With respect to broader impacts, this meeting will benefit the larger community in multiple ways. First, it will help train and inspire the next generation of scientists, by exposing students and postdoctoral fellows to exciting science and scientists. Second, mentoring sessions, both formal and informal, will be organized for the benefit of junior researchers to help them make informed choices about scientific careers in academia and beyond. Finally, a concerted effort will be made to recruit scientists from under-represented groups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1552766","CAREER:   Higher Brauer Groups and Topological Azumaya Algebras","DMS","ALGEBRA,NUMBER THEORY,AND COM, TOPOLOGY, Division Co-Funding: CAREER","06/01/2016","06/01/2018","David Antieau","IL","University of Illinois at Chicago","Continuing grant","Christopher W. Stark","05/31/2021","$286,220.00","","benjamin.antieau@gmail.com","809 S. Marshfield Avenue","CHICAGO","IL","606124305","3129962862","MPS","1264, 1267, 8048","1045","$0.00","This award is focused on algebraic geometry and algebraic topology, two areas of modern mathematics. Algebraic geometry has ancient origins with many connections to real-world problems. Its goal is to understand the geometry of solutions sets of polynomial equations, equations of central importance in various disciplines, such as theoretical physics, cryptography, and number theory. Algebraic topology on the other hand developed more recently, in the 19th century, and aims to study a general notion of shape, less rigid than the idea of shape studied in geometry. It has found striking applications in the last decade, for instance to robotics and to the analysis of large data sets, and a recent revolution in the foundations of algebraic topology has broadened its applicability to other fields of pure mathematics. The proposal of the PI will bring the considerable machinery and insight of algebraic topology to bear on several well-known questions and conjectures in algebraic geometry. Some of these questions will be investigated jointly with students as part of undergraduate research projects in the Mathematical Computing Laboratory at UIC, which the PI founded in 2015 with David Dumas and Jan Verschelde. This integration will provide valuable opportunities for students to engage in research and impact ongoing research.<br/><br/>The PI will work on several projects at the border of algebraic geometry and algebraic topology. Three projects aim to use various topological methods to understand the Brauer group and Azumaya algebras as well as the role of higher algebraic structures in algebraic geometry. (1) The PI will study (higher) algebraic representatives of tale cohomology classes, generalizing the connection between the Picard and Brauer groups and low-degree cohomology groups. (2) The PI will explore separate applications of motivic homotopy theory and persistent homology to the period-index conjecture with the aim of finding algebraic counterexamples to the conjecture. (3) The PI will explore the Hochschild-Kostant-Rosenberg theorem in characteristic p, specifically focusing on the question of whether or not the local-global spectral sequence for Hochschild homology degenerates at the E_2-page for smooth projective surfaces in characteristic 2."
"1734532","NRI: FND: Using Template Models to Identify Exoskeleton User Intent","IIS","National Robotics Initiative","09/01/2017","05/29/2018","James Schmiedeler","IN","University of Notre Dame","Standard Grant","Irene Sattler","08/31/2020","$753,811.00","Patrick Wensing","schmiedeler.4@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","CSE","8013","8086, 9251","$0.00","Exoskeletons have great potential to restore mobility and improve quality of life for individuals with locomotor impairments due to neurotrauma such as spinal cord injury (SCI) and stroke. For several years, clinical exoskeleton use has accelerated gait retraining by enabling patients to take more steps per session, practice more repeatable gait patterns, and have their progress more closely monitored. Today, the technology has matured to the point that multiple systems with FDA approval are commercially available. Still, broader exoskeleton adoption, both in the clinic and for personal use, is needed for the technology to achieve its full potential to impact daily life. The key barrier to such adoption is the lack of a fluent and transparent interface to determine how the user intends to move in conjunction with the exoskeleton. This project seeks to enable exoskeleton use in the diverse scenarios of daily life by developing a robust approach to determine a user's intent. Since the fundamental mechanics of walking are truly universal, the approach is to leverage relatively simple template models of walking that encode these mechanics within algorithms that more reliably identify user intent. Activities of interest include starting from rest, changing walking speed, direction, and cadence, stair ascent/descent, and stopping. The models will be applied to both healthy subjects and individuals with spinal cord injury to identify commonality and critical differences. Beyond the benefits to exoskeleton end-users, the project will facilitate outreach to both K-12 teachers and middle school students to promote education in the STEM disciplines by highlighting how engineering can directly improve quality of life. <br/><br/>This project aims to improve human machine interface technologies for lower-body exoskeletons by using simple template models of locomotion to more effectively capture user intent. In most existing approaches, mapping sensor data to the user's state/activity is treated as a black-box pattern recognition problem. In contrast, reduced order models or templates are low-dimensional dynamical systems that capture the fundamental mechanics of walking, upon which more complex behaviors play out. The project will investigate physics-based template models to augment inference of exoskeleton user intent for small changes to nominal walking gait (speed, direction, and cadence). Leveraging bio-inspired template control algorithms, extended Kalman filtering and non-parameteric Bayesian approaches will be investigated to solve a stochastic intent observer problem. Next, the work will be extended to detect transitions in user intent for starting, stopping, and gait progression to/from stairs. Throughout, parallel analysis will study customization of the methodology, including the use of entirely different template models, for exoskeleton users with locomotor impairments. Data-driven Floquet analysis will be applied for translation of data from healthy users to augment intent recognition in users with spinal cord injury. Experiments with the new intent recognition will be incorporated into the control system of an FDA-approved exoskeleton that will be used to assess recognition delay and generalization performance of the methods relative to existing techniques. These experiments will be conducted first with healthy subjects and subsequently with individuals with incomplete spinal cord injury. Ultimately, the project has the potential to improve the impact of exoskeletons in areas spanning rehabilitation, search-and-rescue, military, and industrial applications by more effectively capturing user intent."
"1454109","CAREER: Reversible plasticity in nanocrystalline metals and alloys for shape memory applications","DMR","METAL & METALLIC NANOSTRUCTURE","06/01/2015","05/31/2018","Jagannathan Rajagopalan","AZ","Arizona State University","Continuing grant","Gary Shiflet","05/31/2020","$410,128.00","","Jagannathan.Rajagopalan@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","MPS","1771","1045, 7237","$0.00","NON-TECHNICAL DESCRIPTION: Nanocrystalline materials are composed of crystallites (grains) that have an average size of about 100 nanometers or less. The small grain size leads to very high strength, which has led to significant interest in using these materials for structural applications. But in addition to their exceptional strength, nanocrystalline materials also exhibit several intriguing properties including the ability to recover plastic deformation, which is typically considered to be irrecoverable. This CAREER award supports fundamental research that aims to exploit this unusual deformation recovery in nanocrystalline metals and alloys for shape memory related applications. In essence, the project lays the foundation to employ nanocrystalline metals and alloys as smart, functional materials that have applications in aerospace, medicine and robotics. The research activity is integrated with a broad effort to promote materials science education at multiple levels. These education and outreach efforts include a new mentoring program and scientific demonstrations for high school students, teacher workshops, course enhancements, and training of undergraduate and graduate students in multidisciplinary materials research. <br/><br/>TECHNICAL DESCRIPTION: Conventionally, plastic deformation is considered to be permanent. However, nanocrystalline materials can recover a large fraction of plastic strain after unloading by thermal activation. This project explores the fundamental aspects of this unusual strain recovery and seeks to determine whether complete strain recovery can be repeatedly obtained in nanocrystalline metals and alloys by controlling their microstructure. The research efforts are directed towards two distinct goals: 1) Characterizing the repeatability and temperature dependence of strain recovery in nanocrystalline face centered cubic metals and alloys over multiple cycles and 2) Understanding how the interplay between material properties (elastic and plastic anisotropy, stacking fault energy) and microstructural heterogeneity (variation in size and orientation of grains) affects the strain recovery characteristics and mechanisms. These goals are pursued using novel, micro-electro-mechanical systems based thermomechanical testing and in situ transmission electron microscopy straining experiments on nanocrystalline metal and alloy films with controlled microstructures."
"1700383","Bridging the Gap in Automated and Connected Vehicle Technology Education","DUE","ADVANCED TECH EDUCATION PROG","04/15/2017","04/21/2017","Justin Morgan","OH","Sinclair Community College","Standard Grant","Heather Watson","03/31/2020","$752,980.00","James Truxal, Thomas Freels","justin.morgan8747@sinclair.edu","444 West Third Street","Dayton","OH","454021460","9375124573","EHR","7412","1032, 9178, SMET","$0.00","Profound developments in research and resources are feeding technological advancements that will soon make self-driving vehicles commonplace. Today's leading-edge, semi-autonomous connected vehicles utilize technology that includes radars, cameras, lidar, multi-domain controllers, wireless vehicle-to-vehicle communications, and software applications, to name a few. The proposed postsecondary faculty professional development project, focused on automated and connected vehicle technology, will serve the NSF's mission of promoting the progress of science by creating industry-supported workshops and college-level educational resources to academically strengthen postsecondary automotive technician degree programs. Project activities such as summer institutes and professional development webinars for faculty will be designed to advance the field of vehicle technology education across the country by informing the educators of future technicians about the new generation of vehicles that are radically changing the automotive and transportation industries. In addition to professional development, the autonomous vehicles and other materials purchased through the grant will also be used to provide outreach activities in secondary schools, including creating a toolkit comprised of interactive demonstrations designed to orient secondary school students, teachers, and counselors to automotive technician educational pathways and careers. <br/><br/>Auto technician education must keep pace with the complexity of vehicles that incorporate aspects of robotics, machine learning, computer vision, and mechanical engineering. The goal of the proposed project is to increase the autonomous vehicle technology experience and knowledge of automotive technology educators throughout the nation and address the growing need for qualified, knowledgeable technicians with capacity to maintain and repair autonomous vehicles. The project will provide a week-long professional development session, webinars, and other learning events for 40 community college faculty annually. The project will also conduct outreach activities in secondary schools to impart information about the high wage, high-tech nature of the work of automotive technicians, important since many secondary school students skilled in science, math, and technology are not choosing automotive technician careers due in part to their misconceptions about what the work entails. The project will also monitor and document the skills and knowledge needed by the future automotive technician who will repair and maintain vehicles using a new set of skills not taught today. The project outcomes will be useful to other institutions with automotive technician education programs that need to update their curriculum to meet the changing needs in the industry or are struggling to diversify their student population interested in automotive technology careers."
"1136993","The Computing Community Consortium II","CCF","INFORMATION TECHNOLOGY RESEARC","10/01/2012","05/24/2017","Edward Lazowska","DC","Computing Research Association","Cooperative Agreement","Nina Amla","09/30/2018","$8,274,862.00","Susan Graham, Ann Drobnis, Andrew Bernat, Elizabeth Mynatt, Fred Schneider, Anita Jones, Edward Lazowska","lazowska@cs.washington.edu","1828 L St., NW","Washington","DC","200360000","2022662949","CSE","1640","1640, 9218, HPCC","$0.00","The Computing Community Consortium (CCC) is a catalyst and enabler for the computing research community. Its various activities strive to unite the community to contribute to shaping the future of the field; provide leadership for the community, facilitating revolutionary, high-impact research; encourage the alignment of computing research with pressing national priorities and national challenges (many of which cross disciplines); give voice to the community, communicating to a broad audience the myriad ways in which advances in computing will create a brighter future; and grow new leaders for the field as a whole. The CCC operates under a Cooperative Agreement between the National Science Foundation and the Computing Research Association (CRA), a membership organization of over 200 computing research entities in academia, industry, and government.<br/><br/>During the founding years of its existence, the activities of the CCC had a significant impact on the status, direction, and prospects of the computing research community, catalyzing new Federal initiatives in robotics and big data to name a few. Opportunities during this second phase of the CCC are every bit as great. The CCC is an investment that promises to pay off in important ways for the field and for the nation."
"1458272","IRES: Avatar-based Adaptive Context System","OISE","IRES Track I: IRES Sites (IS)","06/15/2015","06/03/2015","Avelino Gonzalez","FL","University of Central Florida","Standard Grant","Charles H. Estabrook","05/31/2019","$231,974.00","","gonzalez@ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","O/D","7727","5936, 5980, 7727","$0.00","Part 1<br/>This interdisciplinary partnership between the University of Central Florida and the Fraunhofer Institute for Digital Media Technology (FIDMT) in Ilmenau, Germany is focused on adaptive conversational avatars, the rapidly emerging field crossing computer engineering, computer science, education, communications, and social science.  Immediate applications of this research field include artificial intellegence and national security (including cyber-security), interactive robotics, improvement of quality of life for disbaled, and health and caretaking for children and elderly.<br/>This project will place students from the University of Central Florida under the mentorship of the PI (Dr. A. J. Gonzalez) and of Dr. Klaus Jantke, the counterpart at FIDMT in Ilmenau, Germany. Dr. Jantke is the director of the Children's Media Department of FIDMT located in Erfurt, Germany and has a long and illustrious history in research in computing media. The international aspect of innovative and advanced research is essential in modern research hence the PIs will work with three cohorts of students, one during each year of the project's existence. Each cohort will include one graduate student and either two undergraduates (the first year) or four (in each of the subsequent years).  The research period for each cohort will be 16 weeks - eight weeks in the US and eight weeks in Germany for each year of the grant period.<br/>This research project is motivated by an ancient art of storytelling. In our pursuit of an artificially intelligent computer agent, the IRES project seeks to build a capability to autonomously synthesize possible scenarios for the system development and to modify them dynamically upon listener request. More specifically, the topic of the research in this project is the creation of an avatar-based system that can synthesize and adapt a scenario according to the user's request in real time and without any pre-scripted pathways. Good storytellers were treasured in medieval times, given the lack of other media through which to relate a story to a mostly illiterate population. Therefore, the project seeks to embody the storyteller in a lifelike avatar that resembles an actual person. This avatar will tell the story to the listener in spoken natural language, and interact with her/him when the latter requests changes to the story. <br/><br/>Part 2<br/>Storytelling media have evolved over time, from oral stories to modern E-books. Since the development of the computer, storytelling systems have become a science of their own, and have evolved from simple systems that can only generate a single short story to systems that respond to the listener's actions by modifying the story dynamically in real time. Digital storytelling has therefore become a growing field within artificial intelligence. The project seeks to take this evolution of storytelling media one step further by doing research to create a virtual storyteller who tells a dynamic story. The story is modifiable through a request by the listener (typically a child, a student, or an elderly person), yet will seek to remain realistic as well as interesting. Every story has a story space. That is, only so many things can happen in a story. We use contextual reasoning to represent the story space. In the real world, courses of action are influenced by the current context, making some conversational avatars very attractive while others unattractive when addressing the current situation within the story space. In a similar manner, the situation faced by the protagonist in the dynamic scenario will limit the choices of actions that he/she would otherwise have, thereby taking the story in various directions, none of which need be specifically pre-scripted.  The PIs base the proposed research on the use of formal methods to manipulate the story space within the main theme of the story. By formal methods the PIs mean that one represents the story knowledge formally in terms of strings, interaction sequences such as storyboards and graphs, formulas (for conditions), and the like. Formal methods, therefore, will give the ability to reason with formal methods (string comparison, unification, anti-unification and the like) in the story space. Formal methods have been used in the literature to manipulate contextual information."
"1212948","RI: Large: Collaborative Research: Reconstructive recognition: Uniting statistical scene understanding and physics-based visual reasoning","IIS","ROBUST INTELLIGENCE","10/01/2012","01/08/2014","Marshall Tappen","FL","University of Central Florida","Standard Grant","Jie Yang","09/30/2018","$545,454.00","Hassan Foroosh","mtappen@cs.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","CSE","7495","7925","$0.00","This project is creating a novel paradigm for computer vision, termed ""reconstructive recognition"", that incorporates the strongest elements of previous machine learning-based recognition efforts and the strongest elements of previous reconstruction efforts based on radiometric reasoning. The goal is to provide a new foundation for machine perception, and the potential for a transformative advance in applications of computer vision. The project seeks novel physics-based methods for recognition as well as novel learning-based methods for interpreting pixel values in terms of the physics of a scene. The agenda is structured around four aims: Aim I develops generalized reconstructive processes that unify the recovery of shape, materials, motion and illumination. Aim II focuses on supervised visual learning methods that exploit such reconstructive image representations. Aim III pursues unsupervised discovery of reconstructive representations that converge to be similar to the engineered models of Aim I. Finally, Aim IV introduces well-defined challenge problems that focus the field and serve as measurable proxies for progress in computer vision applications that have high potential impact on society. <br/><br/>There is a significant broader impact to this project, not least being the improvement in computer vision pedagogy that ensues from a reunification of the currently divergent recognition and reconstruction views of the field. More broadly, this project pursues critical steps toward a future where machines can see, a future that will bring changes to robotics, human-computer interfaces, security, and autonomous navigation, to name a few."
"1801513","RET Site: Research Experiences for Teachers in Big Data and Data Science","CNS","RES EXP FOR TEACHERS(RET)-SITE","02/15/2018","02/08/2018","Olfa Nasraoui","KY","University of Louisville Research Foundation Inc","Standard Grant","Harriet G. Taylor","01/31/2021","$598,128.00","Stephanie Philipp","olfa.nasraoui@louisville.edu","The Nucleus","Louisville","KY","402021959","5028523788","CSE","1359","1359, 9150","$0.00","This award creates a new Research Experiences for Teachers (RET) Site focused on Big Data and data science at the University of Louisville. Each summer, ten high school Science/Technology/Engineering/Mathematics (STEM) teachers will participate in research activities with faculty in labs at the University of Louisville.  The teachers will be recruited from Jefferson County Public Schools and the Ohio Valley Education Consortium.  Teachers in this site will apply fundamental data science techniques and learn Big Data principles while investigating real world problems with social relevance. The fast pace of low-cost technological innovation and data-centered operations have led to an explosion of data that can be used to solve problems and provide new insights for the future. This includes projects involving areas such as human welfare, healthcare, smart cities, and robotics. The participating teachers will translate their research experiences and knowledge into classroom practice by developing instructional modules and course materials that they will introduce in their classrooms and share with other teachers in their school districts. These activities all contribute to the formation of a community of practice in partnership with the University of Louisville faculty mentors that has the potential to significantly enhance STEM education in the participating school districts.<br/><br/>RET Site participants will participate in cutting-edge research projects with state-of-the-art data science tools and techniques. The RET Site features a unique combination of faculty mentors from the Department of Computer Engineering and Computer Science who have experience in both hardware and software, which is a synergistic combination in the field of Big Data.  The goals include: providing  quality research experiences in Big Data and data science for the high school teachers; strengthening the connection between the computing faculty and the school districts;  enhancing high school teachers' understanding of engineering research design and the principles of Big Data;  enhancing high school teachers' abilities to teach engineering and computer science concepts in a compelling way; and preparing engineering graduate students and university faculty to assist and support the high school teachers and their students. As Big Data permeates all sectors of society, Big Data problems often arise in diverse disciplines, not just the computing field.  The data-enabled approach is revolutionizing the way scientists and engineers in many fields practice, understand, and make discoveries.  Thus, Big Data can impact all STEM subjects and may become fundamental to a quality high school STEM education.  This project will help develop a core group of teachers who can bring Big Data principles and methods into their classrooms and excite high school students about the potential of Big Data and data science and its relevance to many possible career paths of the future."
"1802383","Implicitization, Residual Intersections, and Differential Methods in Commutative Algebra","DMS","ALGEBRA,NUMBER THEORY,AND COM","06/01/2018","04/19/2018","Bernd Ulrich","IN","Purdue University","Continuing grant","Timothy Hodges","05/31/2021","$109,227.00","","ulrich@math.purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","MPS","1264","","$0.00","This award funds research in Commutative Algebra, the study of systems of polynomial equations in several unknowns. To this end, one considers the collection of all solutions of a system of equations as a geometric object and investigates the functions defined on this object. Reversing the perspective leads to the implicitization problem, which the investigator plans to work on: Given a geometric object, such as a curve or a surface, one wishes to construct a system of polynomial equations that has the geometric object as its solution set. Once the system of polynomial equations is known, it becomes much easier, for instance, to decide whether a specific point lies on the surface or whether the surface is smooth at one of its points. The implicitization problem is difficult and requires advanced techniques from pure mathematics, but its solution even in particular cases has numerous applications, for instance in computer aided design, robotics, and other areas of engineering.<br/> <br/><br/>This project addresses several topics in Commutative Algebra that have close connections with Algebraic and Analytic Geometry and with Elimination Theory. They include the implicitization problem for Rees algebras and rational maps, equisingularity theory, the Poincare problem for plane foliations, and residual intersection theory. Determining the implicit equations of graphs and images of rational maps is a classical, but open problem in elimination theory, which amounts to finding defining ideals of Rees algebras. Previously, the PI and his collaborators solved this problem for Rees algebras of codimension three Gorenstein ideals, under the additional assumption that the entries of a syzygy matrix of the ideal generate a complete intersection. Now the PI intends to remove this crucial hypothesis. The PI also plans to investigate Rees algebras of more general ideals, with the aim to obtain at least qualitative statements and bounds for the implicit equations. A goal in equisingularity theory is to devise fiberwise numerical criteria for when a family of analytic spaces is topologically trivial. An important intermediate step are numerical characterizations of integral dependence of modules. The PI intends to prove such a characterization using a notion of multiplicity that is inspired by intersection theory. Poincare had asked how to decide whether a singular algebraic foliation of the complex plane has an algebraic curve as a leaf. In more recent times, this question has often been treated as a problem about relating invariants of a vector field to invariants of curves or varieties that are left invariant by the vector field. The PI will investigate this problem, using his expertise from prior work on algebraic differentials and Castelnuovo-Mumford regularity. The notion of residual intersection, a generalization of linkage or liaison, is ubiquitous and appears naturally in intersection theory and in the study of Rees algebras, for instance. Of central importance are the Cohen-Macaulayness and duality properties of residual intersections. Based on partial results and experimental evidence, David Eisenbud and the PI have observed that, unexpectedly, many residual intersections, even when they fail to be Cohen-Macaulay, admit maximal Cohen-Macaulay modules of rank one that are self-dual. The PI and his collaborators intend to give a proof of this unusual phenomenon.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1561968","RI: Medium: Collaborative Research: Text-to-Image Reference Resolution for Image Understanding and Manipulation","IIS","ROBUST INTELLIGENCE","06/01/2016","09/01/2017","James Hays","GA","Georgia Tech Research Corporation","Continuing grant","Jie Yang","05/31/2019","$275,000.00","","hays@gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7495, 7924","$0.00","This project develops new technologies at the interface of computer vision and natural language processing to understand text-to-image relationships. For example, given a captioned image, the project develops techniques which determine which words (e.g. ""woman talking on phone"", ""The farther vehicle"") correspond to which image parts. From robotics to human-computer interaction, there are numerous real-world tasks that benefit from practical systems to identify objects in scenes based on language and understand language based on visual context. In particular, the project develops the first language-based image authoring tool which allows users to edit or synthesize realistic imagery using only natural language (e.g. ""delete the garbage truck from this photo"" or ""make an image with three boys chasing a shaggy dog""). Beyond the immediate impact of creating new ways for users to access and author digital images, the broader impacts of this work include three focus areas: the development of new benchmarks for the vision and language communities, outreach and undergraduate research, and leadership in promoting diversity. <br/><br/>At the core of the project are new techniques for large-scale text-to-image reference resolution (TIRR) that enable systems to automatically identify the image regions that depict entities described in natural language sentences or commands. These techniques advance image interpretation by enabling systems to perform partial matching between images and sentences, referring expression understanding, and image-based question answering. They also advance image manipulation by enabling systems that can synthesize images starting from a textual description, or modify images based on natural language commands. The main technical contributions of the project are:  (1) benchmark datasets for TIRR with comprehensive large-scale gold standard annotations that will make TIRR a standard task for recognition; (2) principled new representations for text-to-image annotations that expose the compositional nature of language using the formalism of the denotation graph; (3) new models for TIRR that perform an explicit alignment (grounding) of words and phrases to image regions guided by the structure of the denotation graph; (4) applications of TIRR methods to referring expression understanding and visual question answering; and (5) applications of TIRR to image creation and manipulation based on natural language input."
"1502190","Commutative Algebra and Algebraic Geometry","DMS","ALGEBRA,NUMBER THEORY,AND COM","07/01/2015","05/17/2018","David Eisenbud","CA","University of California-Berkeley","Continuing grant","Timothy Hodges","06/30/2020","$425,544.00","","de@msri.org","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","MPS","1264","","$0.00","Algebraic geometry is the study of the qualitative properties of forms described by polynomial equations. The questions it addresses arise in many areas of science and mathematics, from statistical sampling to robotics and mathematical physics. This research project concerns the study of aspects of algebraic geometry related to syzygy theory, a sort of microscope that allows one to see details of polynomial equations that are not apparent from the equations themselves.<br/><br/>The investigator will work on problems in commutative algebra, algebraic geometry and computational methods for these fields. He will focus on four areas:  1) Cohen-Macaulay and Ulrich complexity of hypersurfaces: A central problem is to describe the minimal size of a non-free maximal Cohen-Macaulay module over a hypersurface, in particular over the permanent hypersurfaces.  2) The structure of high syzygies over complete intersections: Central problems are to give criteria for a module over a complete intersection to be a ""high syzygy"" in the sense of Eisenbud and Peeva; and to understand the relations between the even and odd parts of the infinite minimal free resolutions of modules over a complete intersection. 3) Duality for residual intersections: The central remaining open problem is to prove and extend a conjecture of van Straten and Warmt on the socle of a particular representation of the canonical module of a 0-dimensional residual intersection.  4) Tate resolutions for complexes of sheaves on a toric variety: The central problem is to define and compute a good analogue for toric varieties of the Tate resolution of a sheaf or a complex of sheaves on a projective space."
"1609566","Quality of Life Technology Research Experience for Teachers","EEC","RES EXP FOR TEACHERS(RET)-SITE","07/01/2016","06/23/2016","Mary Goldberg","PA","University of Pittsburgh","Standard Grant","Mary Poats","06/30/2019","$599,931.00","Jonathan Pearlman","mrh35@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","ENG","1359","115E, 9177","$0.00","The overarching theme of this Research Experiences for Teachers (RET) in Engineering and Computer Science Site at the University of Pittsburgh, entitled, ""Quality of Life Technology (QoLT) Research Experience for Teachers,"" is related to the development of products and processes that transform lives in a growing segment of the population-people with reduced functional capabilities due to aging or disability. QoLT is a natural fit for this site because the Pittsburgh region is presently a world leader in research and development related to the aging and disability communities; therefore a high density of rewarding research opportunities are available for RET participants.  All of these opportunities are grounded within a common QoLT research focus, through collaborations between University of Pittsburgh's Department of Rehabilitation Science and Technology (RST) Human Engineering Research Laboratories (HERL) and Carnegie Mellon University (CMU) Human Computer Interaction (HCII) and Robotics Institutes (RI). The research and development projects will build upon recent advances in QoLT that enable people with disabilities to live more independently in their homes and maximize their community participation.  This site builds on previously successful RET programs at the University of Pittsburgh with the core objective of improving the STEM capacity of the nation's students by using product innovation techniques to provide applied outlets for teachers and their students.  The RET research focus is of social significance and will contribute towards the development of technologies that will increase persons with disabilities' independence. <br/><br/>Over three years, 30 STEM high school teachers, from high need urban high schools in Pittsburgh comprised of minority and low socio-economic status students, will take part in a 14-week research experience, including a product innovation course in the fall and a 4-week curriculum development experience over the summer.  This RET Site retains a QoLT engineering research theme and a focus on math through product development economics, while adding a focus on design and peer assessment pedagogy. The site will continue to integrate military veterans with disabilities transitioning to college into project teams, allowing for cross-mentorship and a personal connection to the research.  The site's approach involves a seamless transition between the research experience and teaching via a common product innovation focus, drawing upon institutional strengths in the research and innovation of HERL and curriculum reform expertise from the Learning Research and Development Center (LRDC). This RET will become a vehicle to develop and strengthen teachers' skills in design based learning (DBL) through unique peer assessment approaches that can reduce burden and increase students' learning outcomes.  The unique approach of incorporating flipped classroom modules for the innovation course and an online high school student design competition promotes scalability through potential adoption of the program's methods throughout the full RET network and other interested teachers throughout Pittsburgh and the nation."
"1554293","CAREER: High-Frequency Power Electronics for Wireless Power Transfer Systems","ECCS","ENERGY,POWER,ADAPTIVE SYS","03/01/2016","01/19/2016","Khurram Afridi","CO","University of Colorado at Boulder","Standard Grant","Anil Pahwa","02/28/2021","$500,000.00","","khurram.afridi@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","ENG","7607","1045, 7423","$0.00","Wireless power transfer (WPT) has the potential to address critical energy issues and improve human quality of life by enabling autonomous charging in applications ranging from electric vehicles (EVs) and robotics to portable electronics and biomedical implants. For example, efficient, small, cost-effective, and safe WPT can drastically reduce the need for expensive and bulky on-board batteries, extend range, and accelerate EV penetration. With road transportation accounting for 22% of the nation's total energy consumption, and EVs having roughly twice the well-to-wheel efficiency of gasoline vehicles, even a 10% EV penetration (versus 0.1% currently) can reduce total U.S. energy consumption by over 1%. Likewise, effective WPT can enable artificial heart pumps without abdominal-wall-penetrating electric cords, avoiding discomfort and potential infections for the 5.1 million people in the U.S. suffering from heart failure. Furthermore, WPT could eliminate the need for cardiac pacemaker battery replacement surgeries for nearly 40,000 people each year. However, for WPT systems to be widely adopted, considerable improvements are needed in their performance, cost, and safety. This integrated research and education career development proposal aims to make fundamental advancements in high frequency (1-100 MHz) power electronics technologies, and leverage exciting WPT applications to ignite the imagination of future engineers. The program's broader educational goals include the training of graduate research students and undergraduates participating through the University of Colorado's (CU) Discovery Learning Apprenticeship Program. Incorporating the research findings into the CU Boulder curriculum and disseminating the findings more broadly through a free online course will enhance the education of students at CU Boulder, community colleges, and elsewhere. The special outreach program for K-12 students, involving them in the development of educational videos, will expose them to the role of power electronics and WPT in improving energy efficiency and quality of life and attract them to pursue STEM careers. <br/><br/><br/>To achieve the goal of WPT systems with efficiencies, sizes, and safety comparable to their wired counterparts, the research objectives of this CAREER proposal are to: (i) generalize the new step-superposition (S2) analysis technique introduced by the PI, and use it to better model and optimize high-order resonant converters with multiple inverters and/or rectifiers; (ii) innovate and employ high-order resonant converter topologies with appropriately controlled multiple inverters and rectifiers in inductive and capacitive WPT systems to compensate for changes in coupling and achieve higher efficiency and reduced size, then validate these advantages through a series of experimental prototypes; and (iii) demonstrate feasibility of near-field focusing and enhanced safety through distributed WPT architectures by measuring the reduction in fringing fields in prototypes with different coupler geometries and configurations. This effort enables important innovations and fundamental advances. The step-superposition analysis technique developed here will enable accurate modeling and optimization of high-order resonant converters for WPT applications, as well as other power electronic and complex system applications. Having demonstrated high-order multi-inverter/rectifier resonant converters to provide efficiency benefits in grid-interfaced power electronics, the PI's research will introduce advanced variants that effectively compensate for variations in coupling in WPT systems, while operating at fixed frequency within ISM (i.e., industrial, scientific and medical) frequency bands. The research will also yield a better understanding of near-field phased-array field focusing through distributed couplers designed for field cancellation, and enable dramatic advances in power transfer densities and safety."
"1750263","CAREER: D3: Addressing Emerging Data-Induced Challenges in Embedded and Real-Time Systems","CNS","Computer Systems Research (CSR","01/15/2018","01/10/2018","Cong Liu","TX","University of Texas at Dallas","Continuing grant","Matt Mutka","12/31/2022","$128,824.00","","cong@utdallas.edu","800 W. Campbell Rd., AD15","Richardson","TX","750803021","9728832313","CSE","7354","1045","$0.00","Data-driven embedded systems are here. The ability to create algorithms that process massive amounts of real-time sensor-captured data is enabling designers in many industries to develop intelligent embedded systems that automate actions and decisions, e.g., self-driving vehicles. This emerging data-intensive embedded computing paradigm brings a new set of data-induced challenges around guaranteeing timing predictability and enabling latency constraints to be analytically validated at design time. The goal of this research is to overcome challenges due to real-time processing of massive data in embedded systems in order to guarantee timing predictability. <br/><br/>D3, a comprehensive resource management ecosystem with the capability of predictably processing massive real-time data-intensive workloads, is implemented in the operating system. D3 brings in a novel set of fundamental system-level techniques, which enable smart data filtering and characterization, transparent and supervised streaming for execution concurrency optimization, and predictable memory management under heterogeneous architectures. The hard algorithmic challenges due to co-scheduling memory and highly heterogeneous computing resources such that analytical guarantees on timing predictability become quantifiable will be addressed. <br/><br/>Developing a comprehensive heterogeneous resource management ecosystem for predictably processing massive real-time data-intensive workloads would be a significant result for many application domains, such as transportation and robotics. The next-generation automotive system is a good example that could greatly benefit from the proposed research. The outcome of this project will pave the way to certifiability of safety-critical autonomous vehicles based on heterogeneous platforms. An innovative undergraduate research project to develop an educational tool that uses real-time data-driven system design concepts as its foundation assists in realizing the educational objectives. <br/><br/>All source code and evaluation data will be freely available for direct download from public web servers maintained by the University of Texas at Dallas (UTD) Computer Science Department under an open source Gnu Public License. Additional case-study test programs and scripts will be freely available under the open source BSD license and directly downloadable from public web servers maintained by the UTD Computer Science Department. All data products produced in this project will also be archived in the UTD computer science computing repository for permanent storage. The repository is available at www.utdallas.edu/~cong/CareerRepo."
"1718538","CSR: Small: Evolution of Computer Vision for Low Power Devices, Breaking its Power Wall and Computational Complexity","CNS","Computer Systems Research (CSR, COMPUTING RES INFRASTRUCTURE","10/01/2017","08/16/2017","Avesta Sasan","VA","George Mason University","Standard Grant","Sandip Kundu","09/30/2020","$499,792.00","Houman Homayoun","asasan@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7354, 7359","7923","$0.00","The accuracy of computer vision for object recognition and classification has surpassed human capabilities. Adoption of brain-inspired Convolutional Neural Network (CNN) models and the ability to train and execute these complex networks by modern graphical processing units (GPUs) are the backbone of this progress. However, in terms of computational requirement, memory usage, and power consumption, the CNN solutions are extremely demanding. Meanwhile, many interesting applications of computer vision - such as small robotics, a wide range of Cyber-Physical Systems, and many smart devices on the Internet of Things - are resource constrained. This project aims to substantially lower the computational complexity, the average-case classification power and the latency of CNN-based vision, enabling its deployment to a much wider range of platforms. From a societal viewpoint, this study enhances the research, education, and diversity at George Mason University (GMU) by involving graduate, undergraduate, minority and female students, and enriches several courses that are offered at GMU.<br/><br/>The goals of this research project are as follows: (1) Reformulating the CNN-based learning model into an Iterative Convolutional Neural Network (ICNN) learning model that allows early classification and permits early termination via various thresholding mechanisms and developing a framework to use the contextual knowledge that could be extracted from earlier iterations to guide and reduce the computation of future iterations. (2) Developing an approximate ICNN coprocessor that supports approximation in memory and logic by exploring new approximation opportunities created by ICNN, and enhancing the ICNN to adjust and learn the approximate hardware behavior in addition to its intended functionality."
"1527748","RI: Small: Collaborative Research: Cooperative Autonomous Vehicle Routing under Resource and Localization Constraints","IIS","ROBUST INTELLIGENCE","09/01/2015","07/30/2015","Sivakumar Rathinam","TX","Texas A&M Engineering Experiment Station","Standard Grant","Reid Simmons","08/31/2019","$241,292.00","","srathinam@tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","CSE","7495","7495, 7923","$0.00","This project aims to develop novel algorithms required to deploy Unmanned Vehicle (UV) networks with resource constraints in Global Positioning System (GPS) denied environments. The methods developed in this project will be useful in a wide variety of applications of national importance such as disaster management, border surveillance, monitoring of civilian infrastructure including oil pipelines, power grids, harbors, inland waterways, and intelligent transportation systems where GPS signals can be easily jammed either intentionally or unintentionally. The proposed research spans several areas including control, estimation, sensing, robotics and optimization. This project provides a rich opportunity for involving undergraduate and graduate students in the development of vehicle platforms, sensor networks, and in the implementation of the control and optimization algorithms. This project engages minority students in small research projects to motivate their interest in engineering and science. Enabling autonomous unmanned vehicles with a capability of navigating in GPS denied environments can aid in effectively monitoring large infrastructure systems, protect their structural integrity and functional reliability as well as provide ecological, societal and economic benefits, including better preservation of natural resources, reduced property damage and reduced loss of life.<br/><br/>This proposal addresses the following fundamental problem that arises while deploying unmanned vehicles in GPS-denied environments: Given a set of vehicles and targets to visit, find a path for each vehicle such that each target is visited at least once by some vehicle, the error in the position estimate of each vehicle at any time instant is within a given bound and an objective which depends on the travel and sensing costs is minimized. The specific technical objectives of this project are to: determine the minimal set of requirements that would render the system of vehicles observable over a time period, develop novel approximation and exact algorithms using cutting plane, rounding and Lagrangian dual methods for the optimization problems, and experimentally corroborate the performance of the proposed algorithms using large scale and hardware-in-the-loop simulations, and field demonstrations. It is anticipated that this project will significantly advance the state of art in the area of observability analysis for a team of cooperatively localizing vehicles, and in the area of tractable, approximation and exact algorithms for vehicle placement and path planning problems with resource and localization constraints. Novel cutting plane, rounding, and Lagrangian dual methods are expected to provide new insights into efficient ways of decomposing the difficulties in the vehicle placement and path planning problems, and will lead to good feasible solutions with approximation bounds. The proposed large scale simulation and experimental results will provide a new understanding of the influence of the different parameters (number of landmarks/vehicles/targets, bounds on acceptable position errors, onboard sensor type, different operational environments, and the speed of each vehicle) on the performance of the vehicle localization/path planning system."
"1566129","CRII: RI: Secure Consistent MAV Navigation","IIS","CRII CISE Research Initiation","04/01/2016","03/21/2016","Guoquan Huang","DE","University of Delaware","Standard Grant","Reid Simmons","09/30/2018","$166,214.00","","ghuang@udel.edu","210 Hullihen Hall","Newark","DE","197162553","3028312136","CSE","026Y","7495, 8228, 9150","$0.00","Micro aerial vehicles (MAVs) have gained importance in a wide range of applications over the last decade, such as search and rescue, reconnaissance and surveillance, asset inspection, and delivery services. The economic impact of integrating unmanned aircraft systems into the national airspace is predicted to be significant. By providing rigorous theoretical analysis and solid design tools for securing consistent MAV navigation, this research has the potential to significantly impact our lives, from pushing our knowledge boundary of scientific understanding to protecting people from malicious attacks.<br/><br/>This research project advances science at the intersection of (nonlinear) estimation consistency and security under resource constraints and seeks to design resource-aware, attack-resilient, consistent MAV navigation. To that end, an analytical study of the effects of sensor system properties such as noise characteristics and sensing frequency on the attainable estimation performance is being conducted to determine the best sensing parameters to use. The integrated outreach program attracts underrepresented minority students to STEM through comprehensive, innovative hands-on teaching and learning of robotics programming for K-12 students."
"1453106","CAREER: The Multi-functional Foot and its Role in Locomotor Control Across a Range of Complex Media","IOS","ADVANCES IN BIO INFORMATICS, FLUID DYNAMICS, CROSS-EF ACTIVITIES, Physiolg Mechansms&Biomechancs","09/01/2015","08/19/2015","Shi-Tong Hsieh","PA","Temple University","Standard Grant","Emily Carrington","08/31/2020","$991,873.00","","sthsieh@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","BIO","1165, 1443, 7275, 7658","058E, 1045, 8007, 9178","$0.00","Nature is filled with surfaces that deform and flow in unexpected ways upon impact. How an animal interacts with these surfaces during locomotion can be critical to its survival. Research by the PI over the last decade reveals that the feet of running lizards are surprisingly multi-functional and that the relationship between foot-surface dynamics and the control of movement are more complicated than currently appreciated. This award will support studies to explore how kinematics and passive properties of the feet affect interactions with the ground when running across a range of materials. The research will generate fundamental knowledge about the role of active and passive control mechanisms in tuning foot-substrate interactions on complex media. The outcome of the studies will impact the way researchers view the role of the feet during legged locomotion. This research provides an excellent starting-point from which to engage children and the public in complex concepts that integrate biology, physics, and materials sciences. The educational objective of this award is to increase engagement of middle school students in science through the development and dissemination of research-driven curricula based on results from the proposed research studies, and by training current and future science teachers in inquiry-based pedagogical techniques. Finally, the research findings from these studies will have impacts reaching beyond biology, including the design and actuation of mobile robotics and robust prosthetic design.<br/><br/>The research objective of this award is to determine how foot morphology and impact kinematics affect foot-ground interactions. Specifically, the studies will: (1) characterize the kinematic patterns associated with running across different surface types; (2) quantify the patterns of foot-ground interactions in complex media; and (3) determine how changes in foot flexibility, geometry, and kinematics affect foot-ground interactions. By using a combination of biological and physical experimental techniques, the results from these studies will address general principles of foot intrusion dynamics that are broadly applicable across diverse taxa. Consequently, our findings will stimulate research that explores the evolutionary basis of foot morphology conservation and diversification, and the dynamics of foot-surface interactions, linking biology with materials science.  A range of experimental approaches, including X-Ray PIV, physical and mathematical modeling, and high-speed videography will be employed over the course of the studies.  Results from the research will be disseminated through publications in peer-reviewed journals and through presentations at scientific meetings."
"1351487","CAREER/CDS&E: Advanced, 3D Infrastructure Information Modeling Using Lidar","CMMI","CDS&E","04/01/2014","02/06/2014","Michael Olsen","OR","Oregon State University","Standard Grant","Joanne D. Culbertson","03/31/2019","$400,000.00","","michael.olsen@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","ENG","8084","032E, 033E, 099E, 1045","$0.00","The primary research focus of this Faculty Early Career Development (CAREER) Program award is to efficiently identify and extract meaningful information from three-dimensional, geospatial models of transportation infrastructure in a holistic, automated framework, enabling broader application. Advanced mapping technologies such as laser scanning produce three-dimensional maps, creating highly detailed scenes that can be virtually explored and queried for a diverse range of purposes including infrastructure management, digital terrain modeling, cultural heritage, flood plain delineation, and landslide detection. However, tradeoffs exist between the detail and scale provided by these technologies and the immense size of the resulting datasets. This complexity can strain the most powerful computational resources and require a steep learning curve to exploit the data.  While recent tools have made significant progress, only a small and piece-meal portion of information can be automatically extracted from these rich datasets compared to what is actually available. Key scientific questions to be addressed through this research include (1) What inherent attributes of an object and associated representation in laser scan data and supporting imagery are most beneficial to accurately identifying and extracting an object?, (2) How can neighboring features and context of an object help with rapidly identifying it within geospatial data?, and (3) How can an abridged framework be developed to improve information extraction from laser scan data to consider the broad range of transportation objects?  This overarching framework will consider a broad range of object types, incorporate advanced system information and data structuring, function in noisy, real-world environments, and focus on datasets covering large spatial scales consistent with transportation infrastructure management. Products resulting from this framework include a transportation infrastructure object properties database, fully-classified benchmark datasets, new algorithms, and supporting code, which will be made publicly available.   <br/>   <br/>Well-maintained transportation infrastructure is vital to our economy as well as public safety.  Most transportation agencies charged with maintaining infrastructure are trying to develop a comprehensive methodology for inventory, maintenance and management of their immense assets.  In many cases, the available resources are reduced while maintenance demands still increase.  This research will provide timely solutions to map and digitally manage these assets more efficiently and cost-effectively than current practices. Although primarily focused on transportation, the computational methods and techniques will be applicable and extendable to a wide range of other applications such as land management, urban mapping, and robotics.  This project also will provide students with multi-disciplinary education and training in geospatial analysis, computer science, transportation, and engineering.  Despite the high demand for geospatial expertise today, educational opportunities are limited and challenging because of the rapid evolution of the supporting technologies.  As a result, the U.S. has an insufficient number of geospatially-trained students entering the workforce to meet the ever-increasing demand utilizing geospatial information throughout society. This project will enhance geospatial education through activities ranging from exposure at public events to training camps for high school age students to creation of a model civil engineering geomatics graduate program."
"1149633","CAREER: Non-Parametric Image Parsing","IIS","ROBUST INTELLIGENCE","03/01/2012","04/23/2015","Robert Fergus","NY","New York University","Continuing grant","Jie Yang","02/28/2019","$499,999.00","","fergus@cs.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7495","1045","$0.00","This project develops new techniques for visually interpreting an image in a way that specifically leverages large image collections, now common on the web and elsewhere. The research team uses an approach whose performance directly scales with the size of the dataset, unlike many existing approaches to image understanding. The basic approach is to build a copy of a query image by assembling pieces of image from a large set of training images, in the manner of a jigsaw. Each region in the query is classified by copying labels from the matched regions. The larger the training set, the more jigsaw pieces there are to choose from, thus the more accurate the match.<br/><br/>The initial work of the project focuses on developing efficient methods for performing the matching that allow the incorporating of various desirable constraints. The approach is then extended to handle training data with incomplete labels -- important since few datasets have labels for every region. The research plan also includes building better embeddings for the regions which place semantically similar regions closer together than current representations do, and developing efficient binary matching schemes along with further work on the region embeddings. <br/><br/>Robust techniques for visual recognition have widespread applicability, in such areas as image search, robotics and surveillance. The project also involves extensive outreach activities, including high-school internships and the organization of a NY-area vision day for students and researchers"
"1642045","Collaborative Research: Hawaii PEEC II","HRD","TRIBAL COLLEGE & UNIVERS PROGR","10/01/2016","09/17/2017","Charles Sasaki","HI","University of Hawaii","Continuing grant","Lura J. Chase","09/30/2019","$494,922.00","Joseph Ciotti","sasakich@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","EHR","1744","9150","$0.00","A goal of the Tribal Colleges and Universities Program (TCUP) is to increase the science, technology, engineering and mathematics (STEM) instructional and research capacities of specific institutions of higher education that serve the Nation's indigenous students. The PEEC-II track provides support for studies or educational research conducted by institutions that have had earlier Pre-Engineering Education Collaborative (PEEC) awards.  The intent of PEEC-II is to capture, analyze, and disseminate the impact of these awards on the participating institutions, faculty, or students, and their communities. PEEC and PEEC-II are partnerships between TCUP and the Directorate for Engineering.<br/><br/>Kapiolani Community College (KCC), as the lead institution of a University of Hawaii (UH) System collaboration that includes Honolulu Community College (HCC), Leeward Community College (LCC), Maui College (MC), and Windward Community College (WCC) and University of Hawaii Manoa (UHM), proposes to build on the foundation of their PEEC award which created pre-engineering tracks and transfer agreements between the colleges and UHM as well as instituted student support activities.  The Hawaii PEEC II goals are: 1) to build capacity at Native Hawaiian-serving institutions to prepare students for engineering degree completion, seamless transfer to a four-year institution, and entry into the workforce; and 2) to implement, investigate, and evaluate the effect of discipline-specific undergraduate research on student success. <br/><br/>Along with expanding the sense of place for Native Hawaiian students on each campus through facilities and resources that support the community, the project will contribute to a better understanding of retention and student success in formal pre-engineering programs especially for Native Hawaiian students. The project will investigate the effect of undergraduate research on student success and the utility of vertically-integrated projects for university and community college students around the themes of robotics, space & astronomy, maker, and sustainability. PEEC II will provide evidenced-based practices to help resolve a major national problem for community colleges attempting to develop effective engineering transfer pathways to universities for students underrepresented in STEM."
"1350337","CAREER: Active Learning through Rich and Transparent Interactions","IIS","INFO INTEGRATION & INFORMATICS","05/01/2014","04/30/2018","Mustafa Bilgic","IL","Illinois Institute of Technology","Continuing grant","Sylvia J. Spengler","04/30/2019","$549,863.00","","mbilgic@iit.edu","10 West 35th Street","Chicago","IL","606163717","3125673035","CSE","7364","1045, 7364","$0.00","Machine learning models are trained on data that are annotated (labeled) by humans.  The accuracy of the trained models generally improves with the number of annotated data examples. Yet, annotating takes time, money, and effort.  Active learning aims to minimize the costs by determining which exemples are most informative and directing the human labeler to them.  Improvements in active learning will lower the costs associated with data annotation and lead to faster implementations of intelligent systems for a range of applications including robotics, speech technology, error and anomaly detection (for example in medicine, financial fraud, and condition-based maintenance of infrastructure), targeted advertising, human-computer interfaces, and bioinformatics.<br/><br/>In traditional active learning approaches, algorithms are limited in the types of information they can acquire, and they often do not provide any rationale to the user as to why a particular exemplar is chosen for annotation.  This CAREER project develops a new paradigm dubbed ""rich and transparent active learning.""  This new paradigm opens a communication channel between algorithms and users whereby they can exchange a rich set of queries, answers, and explanations.  By using rich feedback from users the algorithms will be able to learn the target concept more economically, reducing the resources required to build an accurate predictive model.  By explaining their reasoning, these algorithms will achieve transparency, build trust, and open themselves to scrutiny. <br/>  <br/>Towards that end, the project develops methods that allow algorithms to use a rich set of queries for resource-efficient model training, and generate explanations that are informative but not overwhelming for the users.  The methods developed build on expected loss minimization, information theory, and principles from human-computer interaction.  Approaches are evaluated using publicly available datasets and user studies carried out as part of the project.  The project develops case studies on two high-impact real-world problems: detecting fraudulent health-care claims, and identifying patients at risk of disease.<br/><br/>The rich and transparent active learning paradigm provides unique educational opportunities.  In contrast to standard machine learning algorithms, operated as black boxes, interactive and transparent machine learning is expected to raise students' interest and motivation for data science.  Two PhD and several undergraduate and high school students are being trained under this award.  A new graduate course on interactive machine learning is being developed.  Finally the PI ensures effective outreach to under-represented groups by partnering with a Chicago public high school whose student population includes 90% minorities."
"1563591","Fundamental Study of Friction with Hierarchically Ruga-controlled Surfaces","CMMI","Mechanics of Materials and Str","03/01/2016","03/02/2016","Kyung-Suk Kim","RI","Brown University","Standard Grant","Siddiq Qidwai","02/28/2019","$375,000.00","","kyung-suk_kim@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","ENG","1630","022E, 024E, 9161, 9263, AMPP","$0.00","This award supports fundamental research on the mechanics of friction applicable to modern nanotechnology as well as geotechnical science and engineering. Since the time of Leonardo da Vinci, friction - sliding resistance between two objects - has been one of the most challenging subjects still incomplete in understanding but crucial in advancement of modern science and technology. For example, it is critical in controlling sliding mechanisms in nano-manipulators as well as in measuring and predicting forces building up at tectonic fault lines. Here, the principal investigator plans to develop an innovative mechanics framework - renormalization of friction, i.e. successive evaluation of larger length scale friction with smaller length scale friction behavior, and verify it with controlled experiments. The fundamental studies of this project will establish a systematic framework for regulating nanoscale friction to control macroscopic friction. The multi-scale framework of friction will be essential for developing not only nano-mechanical device technology but also friction-control technology in robotics and bio-medical device engineering, as well as for solving scientific problems in geology. It will also advance computational modeling and design capabilities for manufacturing processes sensitive to friction control, widely encountered in production industries. In addition, under this project, the principal investigator will develop an outreach program at Brown, to educate underrepresented students through summer internship programs, and to develop new course material.<br/><br/>Over the past two and half decades, research on multi-scale frictional processes has been very active to uncover the molecular origin of these processes and to bridge understanding of the phenomena at different length scales. Recently the principal investigator's group revealed that renormalization softening/strengthening of friction develops depending on the reduction of molecular adhesive friction stress, scale-dependent flattening of asperities or stiffening of the surface. This unique scheme of friction renormalization is very powerful in investigating multi-scale friction processes of rough surfaces. With this award, the principal investigator will study (i) renormalization strengthening in rough-surface friction; (ii) Ruga (surface corrugation) control of hierarchical roughness to study renormalization of friction; (iii) evolution of roughness spectra and friction due to asperity plasticity and wear."
"1554212","CAREER: Experimental and Theoretical Studies of Mechanics Interacting with Electric/Optical Fields in Liquid Crystal Elastomers","CMMI","CAREER: FACULTY EARLY CAR DEV, Mechanics of Materials and Str","04/01/2016","01/06/2016","Shengqiang Cai","CA","University of California-San Diego","Standard Grant","Siddiq Qidwai","03/31/2021","$500,000.00","","s3cai@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","ENG","1045, 1630","022E, 024E, 027E, 1045, 1630","$0.00","This Faculty Early Career Development (CAREER) project will investigate coupling phenomena in liquid crystal elastomers, a combination of liquid crystal molecules and polymer networks. Liquid crystal elastomers have many special properties which have led to diverse applications ranging from artificial muscles to stretchable optical devices. Because of the complex molecular structure, many phenomena observed in liquid crystal elastomers are still elusive and the unique properties of liquid crystal elastomers have not been fully explored. This research will develop an innovative and robust technique to fabricate liquid crystal elastomers with desired properties. The PI will also formulate a mechanics theory of liquid crystal elastomers with large deformations that may be triggered by various external stimuli. The results from the project will promote further development of liquid crystal elastomers for a wide range of applications, such as responsive elements used in soft robotics, active materials used in energy harvesting/conversion systems and soft materials used in various actuators or sensors. Moreover, the impact of the project will be broadened via the integrated education and outreach programs including course development, a mini summer camp and outreach to high school students.<br/><br/>The research objective of this multidisciplinary project is to investigate multi-field coupling phenomena in liquid crystal elastomers, using a using a combined theoretical, computational, and experimental approach. We will develop a strain-engineering technique to apply predesigned inhomogeneous strain fields onto a lightly-crosslinked liquid crystal elastomer film during its second-step crosslinking reaction so as to obtain patterned molecular orientations in the material. Combining experiments and theoretical studies, we will further explore the interplay between mechanics and electrical/optical field in liquid crystal elastomers with the target of realizing diverse voltage or light-induced deformation modes in the material. As a result, this research project will result in a better understanding of the behaviors of liquid crystal elastomers, provide mechanistic insights into the dynamic behaviors of biological materials with similar molecular structures and promote new engineering applications of the special material."
"1351665","CAREER:Toward Grid-Interactive Converters with Diagnostic, Remedial, and Lifetime Prognostic Features for the Next Generation of Power Grids","ECCS","ENERGY,POWER,ADAPTIVE SYS","02/15/2014","08/09/2016","Behrooz Mirafzal","KS","Kansas State University","Standard Grant","Radhakisan S. Baheti","01/31/2020","$405,250.00","","mirafzal@ksu.edu","2 FAIRCHILD HALL","Manhattan","KS","665061100","7855326804","ENG","7607","099E, 1045, 155E, 1653, 9150","$0.00","Recent investments in sustainable energy resource integration with the energy infrastructure are invariably resulting in the adoption of additional solid-state converters in the power grid. These converters have short operational lifespans compared to other power grid components, but they possess attractive unrealized capabilities for the smart grid concept, including real-time diagnosis and self-healing, which is a long-term research plan of U.S. energy sectors. Thus, basic research to (i) advance reliability and availability of sustainable energy conversion systems and (ii) realize real-time diagnosis and self-healing features are timely topics. Meanwhile, as the power grid begins to adopt more solid-state converters, the nexus between power electronics and power system classes in power engineering curriculum is desired to address the power industry's urgent need for a highly educated workforce.<br/><br/>The objectives of this CAREER proposal are to: (i) create intelligent-reconfigurable grid-interactive solid-state converters as smart elements for the smart grid concept, (ii) advance availability and reliability of solid-state converters in wind and solar energy conversion systems, and (iii) impart required knowledge and skills of practical problems of sustainable energy systems to the next generation of U.S. power engineers.<br/><br/>The intellectual merit of this research includes the filling of crucial gaps in the literature regarding smart grid-interactive converters for wind and solar energy systems. This work offers the following advantages: (i) the formation of an innovate family of solid-state-based power converters with diagnostic, healing, and lifetime prognostic features, (ii) the improvement of grid-interactive converter reliability by preventing catastrophic failures and mitigating stress on vulnerable components, (iii) the reduction of overall system downtime and maintenance costs, and (iv) the facilitation of movement toward the next generation of power grid (smart grid). The broader impacts of this research include: (i) the provision of quality-integrated education, research, and engineering to adequately equip the emerging workforce and the U.S. energy industry needs, and (ii) research findings that are readily extendable to other critical technologies, such as flexible power transmission lines, electric hybrid vehicles, mechatronics, robotics, etc."
"1755895","CRII: RI: Towards Learning Skills from First Person Demonstrations","IIS","ROBUST INTELLIGENCE","03/15/2018","03/30/2018","Hyun Soo Park","MN","University of Minnesota-Twin Cities","Standard Grant","Jie Yang","02/29/2020","$175,000.00","","hspark@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","7495, 8228","$0.00","Humans learn a skill from an expert's demonstrations such as playing tennis, which requires understanding subtle details of sequential actions, e.g., eye-hand coordination across swing motion. This project develops technologies to learn such skills by observing demonstrations from first-person videos. The first-person videos are highly dynamic, local, and person-biased due to severe head movements, which generates a larger variation of visual data. Analyzing the videos produced by the head-mounted camera system is challenging because state-of-the-art computer vision systems built upon third-person videos cannot be directly applied. The research team addresses these challenges by developing both hardware and computational models. The principal investigator of the project will integrate the research results into a sequence of newly designed computer vision courses in the University of Minnesota. The research team will publicly share the dataset, representation, and trained models, and organize workshops and tutorials to broader audiences in computer vision and robotics.<br/><br/>This research investigates problems in learning skills from first person demonstrations. This project designs a head-mounted camera system composed of a first-person camera and multiple proxemic cameras that can fully cover the space of interactions. The project also develops a new representation specific to the head-mounted camera system, called proxemic affordance map, to efficiently represent visual scene and action in 3D. The proxemic affordance map encodes 3D visual semantics in a form of 3D depth map, visual attention, and body pose, which enables measuring the correlation between action and its surroundings. This allows learning the dynamics of proxemic affordance map to model diverse physical activities, e.g., how an action will change the state of its surrounding contexts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1402558","NSF Postdoctoral Fellowship in Biology FY 2014","DBI","Broadening Participation of Gr","01/01/2015","07/12/2014","Sharri Zamore","WA","Zamore                  Sharri","Fellowship","Daniel Marenda","09/30/2018","$207,000.00","","","","Seattle","WA","981053617","","BIO","1157","1036, 7137","$0.00","NSF Postdoctoral Fellowships in Biology combine research and training components to prepare young scientists for careers in biology and require a plan to broaden participation of groups under-represented in science and engineering.  The fellowships advance NSF efforts to diversify the STEM workforce now and in the future.  This fellowship to Sharri Zamore supports research to understand neural control of aerodynamic stability in flying snakes.  The host institution is Virginia Tech, and the sponsoring scientist is Dr. Jake Socha.  In addition to a new understanding of a unique form of animal flight, this research promises to contribute to other fields beyond biology, such as bio-inspired robotics.  The fellowship includes a teaching plan for creating a new course in neural control and dynamics and focuses on outreach, particularly via social media. This research offers an opportunity for working with students of all ages and backgrounds and has great potential far-reaching impact through new developments of educational material.  Research training objectives include mastering techniques of computational modeling, development and implementation of wireless sensors, and reconstruction and analysis of 3-D trajectories.<br/><br/>Flying snakes (Chrysopelea sp.) are capable of gliding despite having a cylindrical shape and no specialized appendages (such as flaps or wings), and therefore offer a unique window into understanding the mechanics of gliding flight. During glides, these snakes undulate in a complex three-dimensional pattern, which suggests that gliding stability may require integration of sensory input (such as vision and balance) and muscular output for control. This research examines responses to unexpected disturbances in vision and displacement using air gusts. How these disturbances affect glide performance enables the prediction of how stability of a gliding cylindrical body can be achieved. This research provides the first insights into the sensorimotor control mechanisms that enable stable gliding by flying snakes."
"1755844","CRII: RI: Towards Human-Level Assessment of Speech Quality and Intelligibility in Real-World Environments","IIS","ROBUST INTELLIGENCE","06/01/2018","04/13/2018","Donald Williamson","IN","Indiana University","Standard Grant","Tatiana D. Korelsky","05/31/2020","$174,995.00","","williads@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","7495","7495, 8228","$0.00","Separating speech from background noise is crucial for many speech-based applications, including hearing prostheses, robotics, and multimedia communication. Many speech separation algorithms perform reasonably well when they are tested in simulated environments, but this level of performance does not always carry over to real environments that are more nuanced. For example, a common complaint of many hearing aid users is that their hearing aid is not effective in noisy environments such as restaurants. Current computational measures do not enable practical or convenient speech assessment in everyday environments, and this is a major hurdle for improving real-world separation performance. In addition, the end-user has largely been left out of the development and evaluation process, which is not ideal since an approach's usefulness is ultimately determined by people. The objective of this project is to develop computational evaluation algorithms to better assess speech quality and intelligibility in real environments. <br/><br/>A key area of research focuses on developing novel, data-driven assessment algorithms that use deep learning to predict human assessment scores, which enables testing in real environments.  Considering the recent success that deep learning has had in speech processing, this new assessment approach is promising and offers substantial differences from prior approaches. The relationship between spectral-temporal speech attributes and human assessment scores are determined as a result of this project. Quantifying this relationship ensures that assessment algorithms are accurate and have strong agreement with human evaluations. An effective integration of human assessment in speech separation algorithm development should result in improved separation algorithms, which ultimately benefits users and applications. This is expected since accurate assessment enables researchers to more easily identify and correct weaknesses based on real-world environmental factors. The research activities lay the foundation for the emerging research area of improving realism in speech processing applications and offer key insights on human perception to the larger scientific community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1659777","REU Site: Undergraduate Research Opportunities in Biomedical Devices at the University of Nebraska-Lincoln","EEC","HUMAN RESOURCES DEVELOPMENT","05/15/2017","05/02/2017","Gregory Bashford","NE","University of Nebraska-Lincoln","Standard Grant","Mary Poats","04/30/2020","$364,006.00","Carl Nelson","gbashford2@unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","ENG","1360","116E, 9150, 9178, 9250","$0.00","This three year renewal Research Experiences for Undergraduates (REU) Site: Undergraduate Research Opportunities in Biomedical Devices at the University of Nebraska-Lincoln (UNL), will provide an intensive research experience for undergraduate students in carefully prepared research projects with topics such as robotics, medical instrument design, implanted devices, biomedical imaging, tissue engineering, and related biomedical engineering device areas.  This research experience offers two emphasis areas - devices for diagnostics and sensing and devices for therapeutics and intervention. Targeted student participants include science/engineering majors, especially underrepresented students, from institutions across the nation that lack strong research opportunities. Biomedical engineering research is seen as a growth area for scientific and technological discovery nationally. To attract and retain the next generation of diverse, talented engineers, it is critical to provide undergraduates with research experiences that tie together the elements of STEM - fundamentally based in science and math, using technology tools to achieve engineering solutions - in a context demonstrating societal impact. This is particularly important in the engineering field, where a complementary balance exists between traditional undergraduate training, which focuses on producing applied results, and the academic rigor of hypothesis-driven or needs-based research required to generate breakthroughs. The growing field of biomedical engineering (BME) provides an appropriate and effective framework in which to implement a high-impact undergraduate research program addressing this need. <br/><br/>UNL will host nine REU students over a 10-week summer program. The objectives of the proposed project are to: 1) provide interdisciplinary research experiences to undergraduates in the area of biomedical devices; 2) give participants confidence to become independent researchers by providing systematic instruction in research methodology; 3) provide participants with a broader view of research and development activities in academia and industry; and 4) expand participants' skills and knowledge regarding academic-industry partnerships, such as technology transfer and entrepreneurship. Structured research activities will be complemented by professional development activities including undergraduate research symposia, designed to prepare participants for STEM careers. It is expected that REU participants will publish research results as lead or co-authors, and project outcomes will be disseminated in engineering education journals for the benefit of other institutions."
"1801154","Scaling Up Utah's Automated Manufacturing Technician Pipeline","DUE","ADVANCED TECH EDUCATION PROG","05/01/2018","03/27/2018","Mason Lefler","UT","Bridgerland Applied Technology College","Standard Grant","Elizabeth Teles","04/30/2021","$225,000.00","Scott Danielson, Matt Fuller","mlefler@btech.edu","1301 North 600 West","Logan","UT","843212292","4357503126","EHR","7412","1032, 9178, SMET","$0.00","Utah is experiencing a critical shortage of skilled technicians in advanced manufacturing due, in part, to the abundance of large and small industries which continue to automate their facilitates statewide. Furthermore, there are a limited number of advanced manufacturing programs which are able to adequately educate and prepare future technicians for the workforce. In addition to creating an innovative pipeline of high school students into advanced manufacturing to support the economy, this project will provide a refined prepackaged curriculum and programmatic resources that could be easily shared anywhere across the state or nation. The project will serve as a model on how applied technical colleges and secondary schools can collaborate through learning management systems to simultaneously prepare participants with high paying jobs and/or a pathway to college. A professional development model will also be developed and implemented to best serve high school and college faculty as they adapt the advanced manufacturing program at their own institutions. It is anticipated that the expected outcomes and findings will offer the educational community an insight as to how to build blended learning environments comprised of learning management systems with high levels of hands-on training.<br/><br/>This project will make a significant impact on the capacity and quality of advanced manufacturing technicians statewide by directly impacting high school and college students, Bridgerland Technical College, the Utah System of Technical Colleges, and our industry partners. The benefits to students will be: (1) improved curriculum, (2) higher retention rates, (3) access to a pathway into a career into automated manufacturing and robotics, and (4) strong connections to local industry leaders. The benefits to the College will be: (1) improved curriculum, (2) new branding of recruitment strategies, (3) enhanced tracking/retention, (4) advanced leadership development in project management/grant writing, and (5) a pathway for the College to become a regional training leader in automated manufacturing. The benefits to the Utah System of Technical Colleges will be: (1) a pilot of curriculum development and collaboration across technical colleges, and (2) a mechanism of how to share and scale best practices across the State of Utah. The benefits to industry partners will be: (1) growing number of students pursuing careers in automated manufacturing, and (2) a curriculum more reflective of industry needs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1801057","Leveraging Supply Chain and Logistics Emerging Technologies to Serve Industry Needs","DUE","ADVANCED TECH EDUCATION PROG","09/01/2018","03/30/2018","Ronnie Brannon","TX","Palo Alto College","Standard Grant","Elizabeth Teles","08/31/2021","$224,997.00","William Cook, Monica Ayala Jimenez","rbrannon@alamo.edu","1400 W. Villaret Blvd.","San Antonio","TX","782240000","2104863941","EHR","7412","1032, 9178, SMET","$0.00","Logistics and Supply Chain (L/SC) professionals find sources of and distribute both raw materials and finished products.  A shortage of qualified L/SC technicians has resulted in a growing workforce gap of six available jobs for every currently employed skilled worker. Industry officials have linked the workforce shortage to five key factors: increasing demand for new L/SC talent, L/SC talent gaps, changing dynamics of supply chains, limited capacity to educate and train new talent, and the poor image of the profession with the millennial workforce. To meet industry needs, community colleges must work collaboratively with industry partners to revise current L/SC programs or develop new programs that prepare the next generation of L/SC professionals. This project at Palo Alto College (San Antonio, Texas) aims to better serve the specific L/SC workforce education needs of regional businesses and industries.  The program aims to: increase the science, technology, engineering and mathematics content and technical training in its L/SC programs; increase L/SC student enrollment; improve L/SC student technical skills and STEM knowledge; and improve L/SC educational and workforce pipelines. The project will combine an L/SC industry workforce assessment with research on the career expectations of millennial students. By appealing to the millennials' interest in new technologies and leveraging the evolving technological landscape of supply chains, the project has the potential to change the perception of L/SC careers among millennial students.  As a result, a new generation of workers can be recruited into an industry with national and global importance. Because Palo Alto College is a Hispanic Serving Institution and the dual credit partner school districts have a majority Hispanic student population, an additional outcome of this project is the potential to diversify the L/SC industry.  It also will serve a student group that is typically underrepresented in STEM education and training. The program will include hands-on technology-based lesson modules, mini-case competitions, recruitment efforts, industry internships, and development of an active student organization.  <br/><br/>The overall objective of the project is to create a high school to two-year to four-year L/SC educational pipeline, while incorporating robotics and other emerging supply chain technologies into the program curriculum. The project aims to educate and train more qualified (L/SC) technicians to meet workforce needs by: (1) conducting an industry review of the college Logistics associate degree and certificates, (2) creating four L/SC emerging technology course modules; (3) establishing a dual credit programs with three high schools (Southside, Southwest Legacy, and Veterans Memorial) where students can earn an L/SC associate degree; (4) conducting targeted recruitment activities to educate students about L/SC careers; (5) creating a Discover Logistics training module for secondary school educators; and (6) establishing a transfer agreement between Palo Alto College and the Texas A&M San Antonio (TAMUSA) four-year L/SC program. The project also plans to create and host an annual L/SC mini-case competition for partner high schools. STEM-based recruitment activities will strive to serve more than 1,000 high school students, while the dual credit program and course modules will aim to serve an estimated 150 high school students and 100 L/SC college students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1711917","RET Site: Enhancing Teacher Knowledge & Skills in Modern Manufacturing","EEC","RES EXP FOR TEACHERS(RET)-SITE","05/15/2018","08/24/2017","Nguyen Hung","TX","Texas A&M Engineering Experiment Station","Standard Grant","Mary Poats","04/30/2021","$554,678.00","Mathew Kuttolamadom","hung@tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","ENG","1359","115E, 9177","$0.00","This new three-year Research Experiences for Teachers (RET) Site Program, Enhancing Teacher Knowledge and Skills in Modern Manufacturing, at Texas A&M University (TAMU) will enhance the knowledge and skill-level of a diverse cohort of middle and high school teachers with limited access to research opportunities, in both traditional and advanced manufacturing. Though Texas had a manufacturing output of $232.2B or 15.2% of the gross state product (in 2014), it had only 7.6% of its workforce in manufacturing. Advanced manufacturing development is facing a serious shortage of qualified personnel stemming from a lack of student interest. Many middle/high schools are limited in their growth of technology, robotics, or SkillsUSA programs due to budget constraints and/or lack of technical expertise among teachers. It is necessary to reverse this trend by providing infrastructure and manufacturing expertise to teachers, so that young students are inspired to join engineering and technology programs and choose STEM careers. This site is a direct response to such concerns, generating a motivated workforce well-rooted in manufacturing knowledge/skills, fuse research with education activities at the middle and high schools, motivate students for higher education, and build long-term collaborative partnerships in the region.<br/><br/>Each summer, a group of 12 teachers (a total of 36 teachers over 3-years) will be hosted at TAMU for 6 weeks, where they will immerse in hands-on research experiences in both traditional and advanced manufacturing, specifically in the areas of (i) processes, (ii) materials, and (iii) metrology techniques. The on-site experience will be supplemented with integration and follow-up visits at their respective home institutions, as well as regular status updates. While at TAMU, these teachers will take part in capsulated technical sessions, complementary lab practice, field tours, research seminars, and guided research projects. Deliverables will include an implementation lesson and lab plan, as well as dissemination of the developed curriculum at annual teacher summits. The target school districts are near TAMU, focusing on those in rural areas, or those with a large number of under-represented students. This program is supported by local, state, and national-level industries and professional societies. The expected outcomes of this program will be the transfer of knowledge and skills to excite, empower, and educate students through new class/lab activities. This will enable and inspire students to effectively participate in science/engineering projects and pursue STEM/manufacturing careers.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1752096","EAGER:Identifying and Disseminating Transformative Professional Development of Engineering Undergraduates Who Perform Outreach","EEC","ENGINEERING EDUCATION","10/01/2017","09/08/2017","Karen Thole","PA","Pennsylvania State Univ University Park","Standard Grant","Julie Martin","09/30/2019","$299,999.00","Michael Alley","kat18@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","ENG","1340","110E, 1340, 7916","$0.00","Undergraduates in science, technology, engineering, and math not only need to enter the workforce with strong technical skills, but also with strong professional skills such as writing, presenting, and working in teams. Unfortunately, many leaders in industry report that the professional skills of these students are not strong enough. Therefore, colleges and universities are looking for new ways to strengthen these skills. Adding additional course content to existing courses or creating new courses to teach this content is often not feasible due to already crowded curricula. Outside of courses, one opportunity for undergraduates in technical fields to learn professional skills is through outreach activities. In these activities, undergraduates reach out to younger students in elementary, middle, and high schools and communicate what occurs in their respective fields. For example, outreach could include hosting a summer camp for middle school students on robotics or visiting a high school to give an electrical engineering demonstration. Not only do undergraduates receive training for these outreach activities, but they have the opportunity to practice what was learned multiple times. Recently, one outreach program, the Engineering Ambassadors Network, discovered that one of their particular training-and-practice sequences led the participating undergraduates to dramatically improve their presentation skills. Because scores of outreach programs exist around the country, the question arises: Do other outreach programs have training-and-practice sequences that lead undergraduates to greatly improve other professional skills?<br/><br/>This project seeks to determine which outreach programs in the United States provide the most transformative professional development of the participating undergraduates from engineering. To accomplish this goal, we have identified four tasks: (i) perform a systematic review of existing outreach programs involving engineering undergraduates; (ii) convene a workshop with outreach advisors to establish a network and thematic strands of common practices; (iii) synthesize the data obtained from the workshops to identify transformative practices of professional development; and (iv) convene two national training workshops to disseminate the practices to engineering undergraduates who perform outreach. An advisory board, composed of a number of stakeholders, provides guidance for this project. To disseminate the project's results, we are using a number of venues and a range of communication methods.  In particular, we are targeting the many programs that conduct organized outreach performed by engineering undergraduates.  Specifically, dissemination is occurring through the two national workshops mentioned above, academic papers, an online report targeting a wide audience, and online tutorials for the transformative practices of professional development."
"1651135","CAREER: Online Learning-based Underwater Acoustic Communications and Networking","ECCS","COMMS, CIRCUITS & SENS SYS","02/15/2017","02/09/2017","Zhaohui Wang","MI","Michigan Technological University","Standard Grant","Jenshan Lin","01/31/2022","$500,000.00","","zhaohuiw@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","ENG","7564","1045, 153E","$0.00","Underwater acoustic communication networks are the enabling technologies for unmanned, in situ, and real-time aquatic monitoring in a wide range of applications, such as scientific studies, pollution detection, offshore exploration, and tactical surveillance. The lifespan of underwater systems varies from a few years to decades, while the spatiotemporal dynamics of underwater acoustic environments at multiple scales pose grand challenges to efficient and reliable acoustic data transmission. The objective of this project is to develop a fundamental and systematic online-learning-based framework for underwater acoustic communications and networking, where the underwater acoustic system 1) models and predicts the long-term dynamics of the acoustic environment, and 2) proactively adapts its communication and networking strategy to the dynamics of the environment, thereby maximizing the long-term system performance in the aspects of energy efficiency, spectrum efficiency, and transmission reliability. Through explicit learning about its environment, the proposed framework will allow harmonious co-existence with other acoustic systems, including marine animals, to achieve eco-friendly operation. This project's research will be integrated with education through summer youth K-12 outreach, curriculum development, undergraduate and graduate student training that will be particularly tailored to females and underrepresented minorities, and collaboration with an underwater robotics team from the local Dollar Bay High School. These activities are designed to motivate and better train rural, female, minority, and economically disadvantaged students to pursue STEM careers.<br/><br/><br/>This project tackles fundamental challenges in online-learning-based underwater acoustic communications and networking by innovating across three interrelated domains. First, novel signal processing and sparse learning techniques will be developed to model and predict the large-scale dynamics and the statistical distribution of small-scale fading of underwater acoustic environments, including the acoustic transmission loss, ambient soundscape, and statistical characterization of external (anthropogenic and marine animal) acoustic sources. Second, an optimization framework will be developed, based on the acoustic environment prediction, for joint transmission power control, link scheduling, node-cooperative routing, and autonomous vehicle mobility control to achieve high network utility and harmonious coexistence with other acoustic systems. Third, the acoustic environment exploration-exploitation tradeoff will be tackled in the Bayesian reinforcement learning framework, which will provide a principled approach to weighing the immediate reward of a communication and networking strategy and its associated long-term benefit of revealing the environment's dynamics. Leveraging the geographic advantage of Michigan Tech and the state-of-the-art facilities of Michigan Tech's Great Lakes Research Center, extensive field experiments will be conducted for acoustic measurement collection and for offline and online algorithm evaluation in a software-defined networking architecture. The methodologies and crosscutting techniques developed in this project can be applied to the design of intelligent radio-frequency communication networks."
"1710892","Analysis and design of decentralized control systems in the presence of uncertain latency or system parameters","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/01/2017","07/25/2017","Laurent Lessard","WI","University of Wisconsin-Madison","Standard Grant","Radhakisan S. Baheti","07/31/2020","$380,000.00","","laurent.lessard@wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","ENG","7607","092E","$0.00","This research addresses the analysis and design of decentralized feedback control systems. Such systems include: the power grid, wireless networks, and medical tele-robotics. In these applications, distributed information-gathering is taking place but decision-making is often made locally using small subsets of the total information. The emphasis of this research is on controlling decentralized systems in the presence of uncertainty, which can be uncertainty in inter-subsystem communication latency or uncertainty in the dynamics or parameters of the subsystems themselves. The intellectual merits of this project are to advance foundational knowledge in the science of decentralized control and to produce computationally efficient control algorithms. This research has the potential to impact several different application areas and to serve as a guide to practice for engineers and system designers.<br/><br/>Optimal decentralized control is generally intractable, yet certain broad classes of problems can be efficiently solved. This project will leverage recent structural results for these tractable instances with the goal of elucidating universal architectures that allow for simple adaptations in the face of uncertainty in the subsystems or latency in their communication. To achieve this goal, the project will bring to bear tools and insights from the fields of optimal control, robust and nonlinear control, delayed systems, and decentralized control."
"1757025","EAGER: Fundamental Considerations in Using Non-Hermitian Microscale Resonant Optical Structures for Rotation Sensing","ECCS","ELECT, PHOTONICS, & MAG DEVICE","09/15/2017","09/07/2017","Mercedeh Khajavikhan","FL","University of Central Florida","Standard Grant","Dominique M. Dagenais","02/28/2019","$200,000.00","","mercedeh@creol.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","ENG","1517","094E, 7916","$0.00","Measuring rotation rate is of utmost importance in a number of existing and emerging areas of science and technology, from general relativity, to robotics, medical-imaging, virtual reality, computer games, unmanned aerial vehicles (drones), and driverless cars. Over the years, various physical phenomena have been utilized for measuring rotation rates. In optics, the Sagnac effect has been employed to develop some of the finest and most accurate tools for determining rotational speeds. In fact, as of now, free-space ring laser gyroscopes (RLG) and passive fiber optic gyroscopes are among the most sensitive rotational sensors built to date. However, despite their superior performance in terms of resilience to shock and vibration, ring laser gyroscopes are not readily scalable and therefore cannot be integrated on chip. Recently, a technique based on differential gain architecture was proposed to significantly increase the sensitivity of RLGs. The goal of the proposed effort is to investigate the fundamental limitations of this technique and to pave the way towards the development of ultrasensitive ring laser gyroscopes on chip. The project will provide scientific training for students.<br/><br/>Recent studies suggest that non-Hermitian degeneracies can significantly enhance the sensitivity of photonic resonant structures. One area where such sensitivity enhancement can become very useful is in ring laser gyroscopes (RLGs). In standard optical gyroscopes, sensitivity increases with the square root of the enclosed area. This behavior results in a fundamental trade-off between size and sensitivity. However, the use of non-Hermitian degeneracies or exceptional points for sensitivity enhancement raises several fundamental questions in terms of quantum noise, detection limit, measurement stability, and signal to noise ratio. The proposal aims to address these issues in an analytical and conclusive way and to determine the performance metrics for non-Hermitian gyroscopes. In addition, the design and fabrication of some of the constituent parts of the gyroscope will be considered. The proposed research may not only impact the technology of chip-scale gyroscopes, but will also advance the science of non-Hermitian physics."
"1730655","CyberTraining: DSE: Self-Service Training Modules for Data-Intensive Neuroscience Learning and Research","OAC","CyberTraining - Training-based","09/01/2017","07/12/2017","Satish Nair","MO","University of Missouri-Columbia","Standard Grant","Sushil Prasad","08/31/2020","$494,651.00","Amitava Majumdar, Prasad Calyam, David Bergin","nairs@missouri.edu","115 Business Loop 70 W","COLUMBIA","MO","652110001","5738827560","CSE","044Y","026Z, 7361, 9150","$0.00","This project will develop cyberinfrastructure-based training modules that advance the existing training methods used for learning and research in data-intensive neuroscience communities.  The project outcomes will enhance research into our understanding of both normal and abnormal brains, contributing to NSF's mission of advancing progress in both science and health.  The project activities will address important gaps in existing training methods that arise because neuroscience research and education activities are increasingly becoming data-intensive.  There is a growing need to integrate and analyze voluminous data being generated at multiple levels to explore the functioning of normal and abnormal brains.  Consequently, research and training in the area now necessitates access to distributed resources, including multiple software packages, high-performance computing with large numbers of cores, virtual desktops with data sharing/collaboration capabilities, neuro-data archives, and also requires multi-disciplinary expertise (e.g., engineering, biology, psychology).  Computational neuroscience researchers, undergraduate and graduate students and teachers (three targeted communities in this project) face challenges in accessing such resources and expertise in a scalable and extensive manner.  Further, they lack the necessary training in the use of advanced cyberinfrastructure (CI) technologies and distributed resources to improve their scientific productivity and to pursue large-scale data-enabled investigations.<br/>    <br/>The transformative nature of project's training modules is in the ""self-service"" nature planned for the modules that make them accessible to neuroscience users in an ""on-demand"" and ""personalized"" manner.  The training modules development will be based on survey of training needs, and will be focused on having students/teachers/multi-disciplinary researchers use, apply and create hands-on laboratory exercises and tools that can be deployed locally (i.e., within institutional CI) and be supplemented with publicly accessible national resources such as the NSF-funded Neuroscience Gateway (NSG).  The training modules will considerably enhance existing traditional neuroscience courses covering foundational concepts at undergraduate, graduate and teacher-training levels with hands-on laboratory exercises related to managing scientific workflows, CI middleware and application programming interfaces (APIs) to integrate geographically distributed resources.  The proposed activities will leverage existing active training programs in cloud computing and in neuroscience, and will use NSF-supported advanced CI resources that are available locally at University of Missouri and at NSG.  Project outcomes will be integrated into on-going courses (with its 50+ neuroscience faculty spanning 10 departments, and 5 colleges), into on-going NSF and NIH summer training programs, which recruit diverse participants including under-served and under-represented students, and into an on-going K-12 outreach program in neuro-robotics. The summer trainees that are being recruited in this project include over 50 students, neuroscience faculty and cyberinfrastructure engineers interested in advanced cyberinfrastructure capabilities for diverse research and education efforts.  In addition, over 80 students will benefit from the training modules within formal classroom courses in existing neuroscience and cyberinfrastructure courses at the University of Missouri, and over 150 students will benefit from outreach activities that include webinars and tutorials at conferences."
"1652866","CAREER: Designing Ultra-Energy-Efficient Intelligent Hardware with On-Chip Learning, Attention, and Inference","CCF","SOFTWARE & HARDWARE FOUNDATION","03/15/2017","03/22/2018","Jae-sun Seo","AZ","Arizona State University","Continuing grant","Sankar Basu","02/28/2022","$181,241.00","","jaesun.seo@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7798","1045, 7945, 8089","$0.00","Building intelligent computers that can perform cognitive tasks (e.g., learning, recognition) as well as humans do has been a long-standing goal of computing research. State-of-the-art deep learning and neuromorphic algorithms have recently advanced the software performance for cognitive applications. However, such algorithms are computation-memory-communication intensive, which makes the hardware design challenging to perform low-power real-time training and classification on portable platforms. Furthermore, to optimize system-level power, efficient power delivery and supply voltage regulation of such large-scale hardware systems also becomes a critical concern. This project will address these challenges across multiple disciplines of hardware and software design, towards the overarching goal of building brain-inspired intelligent computing systems that are ultra-energy-efficient for various cognitive tasks in computer vision, speech, robotics and biomedical applications. The success of this research is likely to impact many user-centric computing systems in  society and industry, including wearable, mobile, and edge computing. This project also entails integrative education and outreach plans through a new interdisciplinary coursework development, undergraduate/graduate student training, and a summer outreach program for high school students.<br/><br/>In this project, energy-efficient circuits, architectures and algorithms will be designed to incorporate learning, attention and inference computations in area-/power-constrained mobile/wearable hardware platforms. The particular technologies that will be developed to achieve large improvement in energy-efficiency include: (1) computation redundancy minimization of state-of-the-art deep learning algorithms with bio-inspired attention models, (2) novel memory compression schemes that apply to both software and hardware implementation, (3) real-time on-chip learning methods that consume low power on mobile/wearable devices, (4) efficient on-chip voltage regulators that can adapt to abrupt changes in cognitive workloads, and (5) cross-layer optimization of circuit, architecture and algorithm. The outcomes of this research will feature new very-large-scale integration (VLSI) systems that can learn and perform cognitive tasks in real-time with superior power efficiency, opening up possibilities for ubiquitous intelligence in small-form-factor devices."
"1642044","Collaborative Research: Hawaii PEEC II","HRD","TRIBAL COLLEGE & UNIVERS PROGR","10/01/2016","03/20/2018","Michael Ferguson","HI","University of Hawaii","Standard Grant","Lura J. Chase","09/30/2019","$494,994.00","Jennifer Higa-King, Marcia Roberts-Deutsch","mferguso@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","EHR","1744","9150","$0.00","A goal of the Tribal Colleges and Universities Program (TCUP) is to increase the science, technology, engineering and mathematics (STEM) instructional and research capacities of specific institutions of higher education that serve the Nation's indigenous students. The PEEC-II track provides support for studies or educational research conducted by institutions that have had earlier Pre-Engineering Education Collaborative (PEEC) awards.  The intent of PEEC-II is to capture, analyze, and disseminate the impact of these awards on the participating institutions, faculty, or students, and their communities. PEEC and PEEC-II are partnerships between TCUP and the Directorate for Engineering.<br/><br/>Kapiolani Community College (KCC), as the lead institution of a University of Hawaii (UH) System collaboration that includes Honolulu Community College (HCC), Leeward Community College (LCC), Maui College (MC), and Windward Community College (WCC) and University of Hawaii Manoa (UHM), proposes to build on the foundation of their PEEC award which created pre-engineering tracks and transfer agreements between the colleges and UHM as well as instituted student support activities.  The Hawaii PEEC II goals are: 1) to build capacity at Native Hawaiian-serving institutions to prepare students for engineering degree completion, seamless transfer to a four-year institution, and entry into the workforce; and 2) to implement, investigate, and evaluate the effect of discipline-specific undergraduate research on student success. <br/><br/>Along with expanding the sense of place for Native Hawaiian students on each campus through facilities and resources that support the community, the project will contribute to a better understanding of retention and student success in formal pre-engineering programs especially for Native Hawaiian students. The project will investigate the effect of undergraduate research on student success and the utility of vertically-integrated projects for university and community college students around the themes of robotics, space & astronomy, maker, and sustainability. PEEC II will provide evidenced-based practices to help resolve a major national problem for community colleges attempting to develop effective engineering transfer pathways to universities for students underrepresented in STEM."
"1755419","Systematizing Connective Labor","SES","SOCIOLOGY","02/15/2018","02/13/2018","Allison Pugh","VA","University of Virginia Main Campus","Standard Grant","Toby Parcel","01/31/2020","$205,000.00","","apugh@virginia.edu","P.O.  BOX 400195","CHARLOTTESVILLE","VA","229044195","4349244270","SBE","1331","1331","$0.00","This research investigates connective labor, a novel concept of service work, and examines the impact of contemporary trends in standardization and automation. Some jobs have relationships with people at the core of their work where these relationships require an emotional connection between workers and their charges.  Teachers, therapists, primary care physicians, even prison guards each depend on relationships in service to a larger goal: children learning, patients healing, prisons secure. Connective labor captures the relational work between practitioner and recipient, using their emotional connection to produce an outcome.  Existing research documents the importance of work involving relationships for valuable outcomes in arenas from schools to hospitals; these proven impacts of connective labor make its scarcity, uneven distribution or unreliable performance a social problem. Yet its emotional nature resists efforts to make it more systematic or automated. This research will provide new information to policymakers and the public about connective labor: its variation, its value, and the costs and benefits of making it more systematic, scaling it up, or delivering it by non-human agents. The project will also contribute to ongoing public debates and policy deliberations about automation and work involving relationships, by providing a new visibility for connective labor and the kind of standards and technology that support its excellence. <br/><br/>The goals of the project are: to distill the common practices and principles that comprise connective labor, for practitioners as well as the program administrators and artificial intelligence (AI) engineers who would systematize their work; investigate how workers experience different kinds of systematization, from checklists to robotics; and evaluate how such systematization affects connective labor. Research includes 95 in-depth interviews and ethnographic observations with connective laborers in fields focused on security and/or control, e.g. police; with low-wage workers in home health care; and with what might be called systematizers, e.g., administrators. The results of the study will document characteristics of different kinds of connective labor, outline the risks and rewards of the various ways these are systematized, and explain differing stances towards this work."
"1652210","CAREER: Perceptually Guided Hand Motion Synthesis","IIS","Cyber-Human Systems (CHS)","02/01/2017","03/06/2018","Sophie Joerg","SC","Clemson University","Continuing grant","Ephraim P. Glinert","01/31/2022","$205,354.00","","sjoerg@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","CSE","7367","1045, 7367, 9150, 9251","$0.00","This research will explore ways to automatically synthesize hand and finger animation for virtual characters that exploit human perception as an inherent part of the algorithm.   In recent years, character animation has taken tremendous strides towards realistic virtual agents, with increasingly better solutions for body motion capture, for achieving highly realistic facial animation, and for simulating cloth and hair.  With these key components in place, the need to create plausible hand and finger motions has become important because these play a crucial role in communicating information while also allowing us to conduct basic tasks and to handle complex tools.  But the differences in size and complexity of hand motions compared to body motions make it difficult to capture or synthesize both at the same time.  Therefore, finger motions are typically still animated manually, which is a cumbersome process.  Taking advantage of perceptual findings could enable the creation of new algorithms to accomplish this task (e.g., by suggesting new methods and by aiding in algorithm parameter adjustment).  The ultimate goal of this research is to merge character animation and motion perception into an interdisciplinary field that yields new insights and approaches to finger and hand movement synthesis as well as a better understanding of how we communicate.    If successful, the work will significantly advance the way we design algorithms to bring virtual characters to life, and project outcomes will have broad impact not only in computer graphics but also in applications such as virtual reality, robotics and prosthetics.  The project includes integrated educational and outreach activities for K-12, undergraduate, and graduate students.  <br/><br/>This research will initiate a fundamental transformation of how we design algorithms for character animation by coupling perceptual experiments with computer animation algorithm development for hand and finger motion synthesis.  Several approaches and devices have been suggested for hand and finger animation, each with their own drawbacks. Some of these approaches show promise and could be improved or combined, but the options are many and a more systematic approach is required.  This work will focus on two applications: data-driven hand motion synthesis for virtual characters, and hand motions for interaction and communication in virtual reality.  The plan is to develop an algorithm for hand motion synthesis based on segment and pose matching, on perceptual insights on the relevance of finger poses and dynamics, and on the perception of collisions, to support real-time interaction in virtual reality."
"1817257","Integrating Science Needs with Advanced Seafloor Sensor Engineering to Provide Early Warning of Geohazards: Visioning Workshop and Roadmap for the Future","OCE","OCEAN TECH & INTERDISC COORDIN","04/01/2018","03/05/2018","Christopher Parrish","OR","Oregon State University","Standard Grant","Kandace S. Binkley","03/31/2019","$50,000.00","John Selker, H. Benjamin Mason, Geoffrey Hollinger, Anne Trehu","christopher.parrish@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","GEO","1680","7556","$0.00","The PIs request funding to support a workshop focused on understanding current seafloor and subseafloor sensing, and future needs for instrumenting the seafloor to provide real-time data and engineering needs for geohazards and early warning. They propose a two-day workshop is Seaside, Oregon. The proposed workshop will bring together leading science and engineering experts within the fields of marine geology and geophysics, oceanography, sensors, communications, visualization, computer science, robotics, geotechnical engineering, and marine geomatics from the academic, government, and private sectors to develop a robust plan for addressing seafloor sensor challenges. The final deliverables will include a final report and a paper for submission to the American Geophysical Union's EOS journal.<br/><br/>Specific topics to be addressed include engineering needs for geohazards and early warning, development of sensors to measure seafloor deformation and temperature and fluid flow with high resolution over a large area. Strategies for transmitting data from the sensors to land quickly and efficiently (including advanced in situ data processing and data compression algorithms) will also be considered as well as methods for powering the stations using energy derived from the environment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1659805","REU Site: Harvey Mudd REU Site in Computer Systems","CNS","RSCH EXPER FOR UNDERGRAD SITES","03/01/2017","12/28/2016","Zachary Dodds","CA","Harvey Mudd College","Standard Grant","Jonathan Sprinkle","02/29/2020","$353,571.00","Julie Medero","dodds@cs.hmc.edu","301 Platt Boulevard","CLAREMONT","CA","917115901","9096218121","CSE","1139","9250","$0.00","This award renews a highly successful CISE Research Experiences for Undergraduates (REU) Site at Harvey Mudd College. A team of computer science faculty mentors have designed a 10 week summer REU program in the broad area of computer systems. The summer research activity gives students a taste of the most compelling parts of a graduate school experience as well as an immersive experience in the field of computer science. The student research projects cover a breadth of areas in computing science. The students will gain experience in all aspects of the process of conducting research. The site will target students from 2-year schools and students early in their undergraduate studies.  The faculty is committed to engaging students from groups traditionally under-represented in computing. The program features individual and group activities that create a strong common-cohort experience for students for whom the REU experience should be transformative. The program develops research ability, improves presentation and communications skills, and nurtures student interest in research-related careers.<br/><br/>The intellectual merit of the project revolves around the variety of systems projects through which students will be exposed to all aspects of the research process. The research focus areas include text simplification, robotics, domain-specific programming languages and systems, and active transportation planning. Each project connects with the systems theme, building atop existing platforms, melding theory and practice, and implementing designs to mitigate complexity.  The projects are designed to be accessible to students early in their undergraduate careers and share principles of low-cost and overhead, external accessibility of deliverables, and narrowness of focus.  The students engage in projects that are exciting, current, and externally relevant and that have clear applications. Students actively pursue the entire research process including literature search, digesting prior work, formulating new problems, designing and conducting investigations, and preparing presentations and publications of results.  The REU cohorts will regularly share their work with each other and meet daily with faculty mentors. The project activities will permit students to acquire valuable professional development skills, gain a broader and deeper understanding of research, and develop greater confidence in their abilities as future computing professionals and researchers."
"1823471","Student Support for the 2018 International Conference on Automated Planning and Scheduling (ICAPS 2018)","IIS","ROBUST INTELLIGENCE","04/01/2018","02/13/2018","William Yeoh","MO","Washington University","Standard Grant","James Donlon","03/31/2019","$16,000.00","","wyeoh@wustl.edu","CAMPUS BOX 1054","Saint Louis","MO","631304862","3147474134","CSE","7495","7495, 7556, 9150","$0.00","This grant supports student travel for select students participating in the Doctoral Mentoring Consortium (DMC) at the International Conference on Automated Planning and Scheduling (ICAPS 2018), to be held in Delft, The Netherlands, June 2018. This is the premier international conference for researchers in automated planning and scheduling research and applications across a fully international research community. This activity will bring together a broad community of researchers in the field of AI, and support junior researchers at this critical early-career stage. These events combine to provide educational opportunities for students and experienced researchers alike, and are extremely popular among conference participants. ICAPS is the major international conference that will figure prominently in the research careers of students who remain involved in planning and scheduling. Students will gain valuable research insights from the exchange of technical ideas in this broader venue. In the process, they are likely to make valuable connections with potential collaborators from around the world. As intelligent software and embodies systems become more prevalent, it is clear that advances in planning and scheduling will have significant impact in virtually any domain imaginable, including transportation, logistics, robotics, and remote sensing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1212928","RI: Large: Collaborative Research: Reconstructive recognition: Uniting statistical scene understanding and physics-based visual reasoning","IIS","ROBUST INTELLIGENCE","10/01/2012","05/05/2017","Todd Zickler","MA","Harvard University","Standard Grant","Jie Yang","09/30/2018","$1,090,910.00","Kate Saenko","zickler@eecs.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","7495","7925","$0.00","This project is creating a novel paradigm for computer vision, termed ""reconstructive recognition"", that incorporates the strongest elements of previous machine learning-based recognition efforts and the strongest elements of previous reconstruction efforts based on radiometric reasoning. The goal is to provide a new foundation for machine perception, and the potential for a transformative advance in applications of computer vision. The project seeks novel physics-based methods for recognition as well as novel learning-based methods for interpreting pixel values in terms of the physics of a scene. The agenda is structured around four aims: Aim I develops generalized reconstructive processes that unify the recovery of shape, materials, motion and illumination. Aim II focuses on supervised visual learning methods that exploit such reconstructive image representations. Aim III pursues unsupervised discovery of reconstructive representations that converge to be similar to the engineered models of Aim I. Finally, Aim IV introduces well-defined challenge problems that focus the field and serve as measurable proxies for progress in computer vision applications that have high potential impact on society. <br/><br/>There is a significant broader impact to this project, not least being the improvement in computer vision pedagogy that ensues from a reunification of the currently divergent recognition and reconstruction views of the field. More broadly, this project pursues critical steps toward a future where machines can see, a future that will bring changes to robotics, human-computer interfaces, security, and autonomous navigation, to name a few."
"1611114","RET Site in Engineering and Computer Science: Digital Signal Processing in Radio Astronomy","EEC","RES EXP FOR TEACHERS(RET)-SITE, EPSCoR Co-Funding","01/01/2017","08/26/2016","Natalia Schmid","WV","West Virginia University Research Corporation","Standard Grant","Mary Poats","12/31/2019","$577,815.00","Kevin Bandura","Natalia.Schmid@mail.wvu.edu","P.O. Box 6845","Morgantown","WV","265066845","3042933998","ENG","1359, 9150","115E, 1359, 9150, 9177","$0.00","This Research Experiences for Teachers (RET) in Engineering and Computer Science Site, entitled Digital Signal Processing in Radio Astronomy (DSPIRA) at West Virginia University (WVU) Lane Department of Computer Sciences and Electrical Engineering, the WVU Center for Gravitational Waves and Cosmology, and the National Radio Astronomy Observatory, (NRAO) in Green Bank, WV, will expose high school STEM teachers from West Virginia school districts, to hands-on research experiences in the engineering method, via involvement in the research, design, development, and prototyping of digital signal processing (DSP) techniques and applications targeted for the next generation of radio telescopes.  Radio Astronomy is undergoing a revolution as major new telescopes come on line. This next generation of telescopes requires exceptionally sophisticated signal processing algorithms running in high throughput, heterogeneous computing environments. Implementation of these algorithms and hardware is pushing the state of the art of current DSP techniques.   Advanced DSP algorithms running in commodity devices are a fundamental part of modern life. The signal processing techniques being developed here are also becoming vital across a wide range of areas, including vision-based navigation, remote sensing, robotics, mechatronics, computerized tomography, biomedical engineering, radar and sonar, and signal processing for security.  The experiences gained by the teachers will give them, and through them their own students, insight into the design, development, and implementation of such devices. DSPIRA addresses a confluence of three needs: an industry need for greater public understanding of a widely used technology; science and industry's need to have cross-curricular problem solvers; and the K-12 world's need to integrate engineering principles into their new science standards.    <br/><br/>Over a three-year period this RET Site will offer an intensive six week summer research program and academic year follow-up to a total of 30 STEM high school teachers who will join research teams led by engineers at WVU and NRAO who will provide the RET teachers the opportunity to make meaningful contributions, with authentic involvement, in these engineering research areas. With the recent advances in open source Software Defined Radio (SDR) tools, teachers will be able to learn core concepts and explore implementation strategies in an extremely accessible software/hardware environment (a laptop and RTL-SDR device running GNU Radio software) and take these back to their institutions. The research experience will also include RET teachers working with project staff to develop classroom projects that involve an entire classroom of students in DSP activities.  in addition to dissemination of the results of RET participants' research projects, through poster sessions and national conferences such as NSTA and ASEE, the PIs will share all educational and research material developed over the period of this project both in state and nationally through the Teach Engineering Digital Library."
"1609339","RET Site: Smart Sensors and Sensing Systems","CNS","RES EXP FOR TEACHERS(RET)-SITE","02/15/2016","02/23/2016","Wen Li","MI","Michigan State University","Standard Grant","Harriet G. Taylor","01/31/2019","$600,000.00","Andrew Kim","wenli@egr.msu.edu","Office of Sponsored Programs","East Lansing","MI","488242600","5173555040","CSE","1359","1359","$0.00","This award renews an exemplary Research Experiences for Teachers (RET) Site focusing on smart sensors and sensing systems at Michigan State University (MSU).  The RET Site will continue to develop a strong partnership between MSU and schools in the greater Lansing-Detroit area to advance pre-college science and engineering education by training a cadre of leaders of middle and high school teachers in the areas of Science, Technology, Engineering, and Mathematics (STEM). The RET site will expose teachers to leading engineering research spanning biological and chemical sensors, robotics sensors, micro and nano-electro mechanical sensors, microelectronic sensing circuitry, human-computer interaction, biomechanics, innovative sensing materials and manufacturing techniques, and  will connect them to the profound changes that sensors and sensing technologies are having on the daily lives and quality of life of all citizens. The interdisciplinary nature of the research theme will provide a fertile ground for developing creative and appealing middle and high school lessons and teaching activities in biology, physics, chemistry, and technology that align with state and national curricular standards. <br/><br/>RET participants will attend a 6-week summer institute to participate in cutting-edge research projects with mentoring from engineering faculty who lead vibrant sensor and sensing related research programs. Working with principal investigators, faculty mentors, and a curriculum development specialist, teachers will develop innovative, standards-compliant curriculum modules and participate in a number of professional development activities. The teacher-created modules and lessons will be disseminated nationally through TeachEngineering.org, a nationally recognized repository for searchable, standards-based engineering curricula.   Extensive follow-up activities are planned throughout the academic year to ensure the translation of lab experience into classroom practice, and to foster and strengthen long-term partnership between engineering faculty and the local school districts. A third-party professional program evaluator will track and evaluate the program and provide feedback for improvement. The evaluator will also conduct longitudinal studies on participants to assess the longer-term impact of the RET program."
"1149397","CAREER: Securing Mobile Cyber-Physical Systems (CPSs) Against Stealthy Attacks","CNS","Secure &Trustworthy Cyberspace","01/15/2012","01/21/2016","Mina Guirguis","TX","Texas State University - San Marcos","Continuing grant","Dan Cosley","12/31/2018","$458,047.00","","msg@txstate.edu","601 University Drive","San Marcos","TX","786664616","5122452314","CSE","8060","1045, 7795","$0.00","As Cyber-Physical Systems (CPSs) employing mobile nodes continue to integrate into the physical world, ensuring their safety and security become crucial goals. Due to their mobility, real-time, energy and safety constraints, coupled by their reliance on communication mediums that are subject to interference and intentional jamming, the projected complexities in Mobile CPSs will far exceed those of traditional computing systems. Such increase in complexity widens the malicious opportunities for adversaries and with many components interacting together, distinguishing between normal and abnormal behaviors becomes quite challenging.<br/><br/>The research work in this project falls along two main thrusts: (1) identifying stealthy attacks and (2) developing defense mechanisms. Along the first thrust, a unifying theoretical framework is developed to uncover attacks in a systematic manner whereby an adversary solves Markovian Decision Processes problems to identify optimal and suboptimal attack policies. The effects of the attacks are assessed through different instantiations of damage and cost metrics. Along the second thrust, novel randomization controllers and randomization-aware anomaly detection mechanisms are developed to prevent, detect and mitigate stealthy attacks.<br/><br/>The outcomes of this CAREER project will ultimately provide concrete foundations to build more secure systems in the areas of robotics, autonomous vehicles, and intelligent transportation systems. The educational activities--as in curriculum development and hands-on laboratory experiences--will provide students with the essential skills to build dependable and trustworthy systems, while ensuring the participation of undergraduates, women and underrepresented minorities. The outreach activities will expose high school students to Computer Science education and scientific research.<br/>"
"1619433","RI: Small: Speedup Learning for Online Planning Under Uncertainty","IIS","ROBUST INTELLIGENCE","09/01/2016","06/20/2016","Alan Fern","OR","Oregon State University","Standard Grant","Jie Yang","08/31/2019","$450,000.00","Prasad Tadepalli","afern@eecs.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7495","7495, 7923","$0.00","Many complex stochastic planning domains such as logistics,<br/>emergency response, resilient power grids, and robotics require the<br/>ability to make high-quality decisions under tight time<br/>constraints. This project addresses the need for high-quality, but<br/>computationally efficient, decision making via new theory and<br/>algorithms for speedup learning, which will enable planners to<br/>learn to speedup their performance based on prior planning<br/>experience. This speedup-learning approach is loosely inspired by<br/>the fact that humans routinely learn to speedup their reasoning<br/>processes with experience, without sacrificing decision quality.<br/>Similarly, through speedup learning, an inefficient planner that<br/>produces high-quality decisions will be transformed into a much<br/>faster planner with little loss in decision quality.<br/><br/>The project involves advancing speedup learning for online planning<br/>under uncertainty on four fronts. First, the speedup-learning<br/>problem is formalized by introducing the canonical problem of<br/>Primitive Speedup Learning (PSL) and studying how PSL can be used<br/>to solve various speedup objectives. Second, a novel online<br/>planning framework, which subsumes many existing frameworks and<br/>enables many potential speedup opportunities, is being designed and<br/>developed. Third, the project is producing new speedup learning<br/>algorithms for the new framework, which learn various types of<br/>knowledge and that can exploit deep neural network (DNN)<br/>techniques. Finally, the research is producing extensive empirical<br/>evaluations including applications to the important problems of<br/>power grid control, municipal emergency response, and benchmark<br/>planning domains. The project has the potential for significant broader impact on<br/>applications where time-sensitive decisions must be made within<br/>stochastic environments. It will directly contribute to advances in<br/>two applications in particular: remedial action control in<br/>electrical grids to minimize cascading power outages, and planning<br/>for municipal emergencies such as fire and rescue operations in<br/>cities. The project will also serve to advance graduate education<br/>through research assistantships and undergraduate education through<br/>summer and academic term research experiences for undergraduates. A<br/>special topics graduate course will be taught on the area of<br/>planning and learning at Oregon State University and all course<br/>materials will be open access."
"1458839","Promoting Retention and Completion with STEM Research and Design Cohorts at Linn-Benton Community College","DUE","S-STEM:SCHLR SCI TECH ENG&MATH","10/01/2015","09/22/2015","Gregory Mulder","OR","Linn Benton Community College","Standard Grant","Abiodun Ilumoka","09/30/2020","$616,800.00","David Kidd, Andrew Feldman, Marci Moling, Parker Swanson","mulderg@linnbenton.edu","6500 S W Pacific Blvd","Albany","OR","973213755","5419174999","EHR","1536","9178, SMET","$0.00","The Linn-Benton Community College's (LBCC's) ""Promoting Retention and Completion with STEM Research and Design Cohorts"" Scholarships in Science, Technology, Engineering, and Mathematics (S-STEM) project will annually provide approximately 21 scholarships to academically talented LBCC STEM majors with financial need. Because this project builds upon and expands prior successful S-STEM efforts (Tech Scholars Program, TSP-I and TSP-II), participants will be referred to as TSP-III Scholars.  Chemistry, physics, geology, engineering, math, computer science, and biology will be the target majors for the scholarships. Students will engage in research and/or design project experiences as part of one of several possible Research and Design Cohorts (RDCs). This will be accomplished through a one-credit course called ""Destination Graduation,"" which is an institutional requirement; a STEM-centered version of this course will be available to S-STEM scholars.  Further, students will have the opportunity to engage in additional optional RDC activities with faculty members after completion of this course.  Scholars will be recruited primarily through targeted outreach to four groups: (1) Oregon Marine Advanced Technology Education (MATE) Remotely Operated Vehicle (ROV) program, (2) Linn and Benton Counties' 5th Year High School Students, (3) College Assistance Migrant Program (CAMP), and (4) For Inspiration and Recognition of Science and Technology (FIRST) Robotics.  Targeting these groups for recruitment is expected to yield a pool of applicants who not only have the academic talent or potential to succeed in STEM disciplines, but also financial need, as many students engaged in some of the programs are low-income, first generation college students.  Additionally, the MATE ROV teams in Oregon are roughly 50% female, thus lending to the possibility of broadening participation of women in STEM fields.<br/><br/>Expected short-term outcomes of the project are: (1) to provide significant financial relief for the students; (2) to foster an environment where students feel supported by the program and the college to stay in school, have a sense of community at the college, achieve academic success, and transition successfully to a four year program; (3) to engage faculty in a system that assesses outcomes and makes changes when appropriate to improve student learning and retention.  The Colorado Learning Attitudes about Science Survey (CLASS) will be used to determine whether or not the students who receive the scholarships indeed face reduced financial strain compared to non S-STEM students, including non-STEM majors.  This survey will be issued several times throughout each year allowing for a comprehensive measure of how the scholarships impact financial stability and ability to concentrate on learning.  Intermediate expected outcomes are that TSP-III scholars will: (1) be retained and perform well academically compared to their non S-STEM counterparts; and (2) transfer successfully to a four-year institution and feel a continued sense of peer group support at those institutions.  Data reflecting student retention and success will be provided by LBCC's Office of Institutional Research to track student performance each quarter allowing faculty, advisors, and project staff to intervene early if problems are identified.  The National Student Clearinghouse will be used to track the number and percent of TSP-III Scholars who transfer successfully. In collaboration with partners such as California State University at Fullerton and Oregon State University, a follow-up survey will be administered to obtain feedback on the scholars' experience, progress, and preparedness for the four-year program as well as the extent of peer support received."
"1642046","Collaborative Research: Hawaii PEEC II","HRD","TRIBAL COLLEGE & UNIVERS PROGR","10/01/2016","09/17/2016","Jonathon V. McKee","HI","University of Hawaii","Standard Grant","Lura J. Chase","09/30/2019","$494,268.00","Mark Hoffman","jvmckee@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","EHR","1744","9150","$0.00","A goal of the Tribal Colleges and Universities Program (TCUP) is to increase the science, technology, engineering and mathematics (STEM) instructional and research capacities of specific institutions of higher education that serve the Nation's indigenous students. The PEEC-II track provides support for studies or educational research conducted by institutions that have had earlier Pre-Engineering Education Collaborative (PEEC) awards.  The intent of PEEC-II is to capture, analyze, and disseminate the impact of these awards on the participating institutions, faculty, or students, and their communities. PEEC and PEEC-II are partnerships between TCUP and the Directorate for Engineering.<br/><br/>Kapiolani Community College (KCC), as the lead institution of a University of Hawaii (UH) System collaboration that includes Honolulu Community College (HCC), Leeward Community College (LCC), Maui College (MC), and Windward Community College (WCC) and University of Hawaii Manoa (UHM), proposes to build on the foundation of their PEEC award which created pre-engineering tracks and transfer agreements between the colleges and UHM as well as instituted student support activities.  The Hawaii PEEC II goals are: 1) to build capacity at Native Hawaiian-serving institutions to prepare students for engineering degree completion, seamless transfer to a four-year institution, and entry into the workforce; and 2) to implement, investigate, and evaluate the effect of discipline-specific undergraduate research on student success. <br/><br/>Along with expanding the sense of place for Native Hawaiian students on each campus through facilities and resources that support the community, the project will contribute to a better understanding of retention and student success in formal pre-engineering programs especially for Native Hawaiian students. The project will investigate the effect of undergraduate research on student success and the utility of vertically-integrated projects for university and community college students around the themes of robotics, space & astronomy, maker, and sustainability. PEEC II will provide evidenced-based practices to help resolve a major national problem for community colleges attempting to develop effective engineering transfer pathways to universities for students underrepresented in STEM."
"1642028","Collaborative Research: Hawaii PEEC II","HRD","ENG DIVERSITY ACTIVITIES, ALLIANCES-MINORITY PARTICIPAT.","10/01/2016","05/15/2017","Peter Crouch","HI","University of Hawaii","Standard Grant","Lura J. Chase","09/30/2019","$494,802.00","","peter.crouch@uta.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","EHR","7680, 9133","110E, 7680, 9150","$0.00","A goal of the Tribal Colleges and Universities Program (TCUP) is to increase the science, technology, engineering and mathematics (STEM) instructional and research capacities of specific institutions of higher education that serve the Nation's indigenous students. The PEEC-II track provides support for studies or educational research conducted by institutions that have had earlier Pre-Engineering Education Collaborative (PEEC) awards.  The intent of PEEC-II is to capture, analyze, and disseminate the impact of these awards on the participating institutions, faculty, or students, and their communities. PEEC and PEEC-II are partnerships between TCUP and the Directorate for Engineering.<br/><br/>Kapiolani Community College (KCC), as the lead institution of a University of Hawaii (UH) System collaboration that includes Honolulu Community College (HCC), Leeward Community College (LCC), Maui College (MC), and Windward Community College (WCC) and University of Hawaii Manoa (UHM), proposes to build on the foundation of their PEEC award which created pre-engineering tracks and transfer agreements between the colleges and UHM as well as instituted student support activities.  The Hawaii PEEC II goals are: 1) to build capacity at Native Hawaiian-serving institutions to prepare students for engineering degree completion, seamless transfer to a four-year institution, and entry into the workforce; and 2) to implement, investigate, and evaluate the effect of discipline-specific undergraduate research on student success. <br/><br/>Along with expanding the sense of place for Native Hawaiian students on each campus through facilities and resources that support the community, the project will contribute to a better understanding of retention and student success in formal pre-engineering programs especially for Native Hawaiian students. The project will investigate the effect of undergraduate research on student success and the utility of vertically-integrated projects for university and community college students around the themes of robotics, space & astronomy, maker, and sustainability. PEEC II will provide evidenced-based practices to help resolve a major national problem for community colleges attempting to develop effective engineering transfer pathways to universities for students underrepresented in STEM."
"1642042","Collaborative Research: Hawaii PEEC II","HRD","TRIBAL COLLEGE & UNIVERS PROGR","10/01/2016","09/17/2016","Louise Pagotto","HI","University of Hawaii","Standard Grant","Lura J. Chase","09/30/2019","$494,973.00","","pagotto@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","EHR","1744","9150","$0.00","A goal of the Tribal Colleges and Universities Program (TCUP) is to increase the science, technology, engineering and mathematics (STEM) instructional and research capacities of specific institutions of higher education that serve the Nation's indigenous students. The PEEC-II track provides support for studies or educational research conducted by institutions that have had earlier Pre-Engineering Education Collaborative (PEEC) awards.  The intent of PEEC-II is to capture, analyze, and disseminate the impact of these awards on the participating institutions, faculty, or students, and their communities. PEEC and PEEC-II are partnerships between TCUP and the Directorate for Engineering.<br/><br/>Kapiolani Community College (KCC), as the lead institution of a University of Hawaii (UH) System collaboration that includes Honolulu Community College (HCC), Leeward Community College (LCC), Maui College (MC), and Windward Community College (WCC) and University of Hawaii Manoa (UHM), proposes to build on the foundation of their PEEC award which created pre-engineering tracks and transfer agreements between the colleges and UHM as well as instituted student support activities.  The Hawaii PEEC II goals are: 1) to build capacity at Native Hawaiian-serving institutions to prepare students for engineering degree completion, seamless transfer to a four-year institution, and entry into the workforce; and 2) to implement, investigate, and evaluate the effect of discipline-specific undergraduate research on student success. <br/><br/>Along with expanding the sense of place for Native Hawaiian students on each campus through facilities and resources that support the community, the project will contribute to a better understanding of retention and student success in formal pre-engineering programs especially for Native Hawaiian students. The project will investigate the effect of undergraduate research on student success and the utility of vertically-integrated projects for university and community college students around the themes of robotics, space & astronomy, maker, and sustainability. PEEC II will provide evidenced-based practices to help resolve a major national problem for community colleges attempting to develop effective engineering transfer pathways to universities for students underrepresented in STEM."
"1642043","Collaborative Research: Hawaii PEEC II","HRD","TRIBAL COLLEGE & UNIVERS PROGR","10/01/2016","09/17/2016","James Goodman","HI","University of Hawaii","Standard Grant","Lura J. Chase","09/30/2019","$495,000.00","Bryson Padasdao","goodmanj@hawaii.edu","2440 Campus Road, Box 368","HONOLULU","HI","968222234","8089567800","EHR","1744","9150","$0.00","A goal of the Tribal Colleges and Universities Program (TCUP) is to increase the science, technology, engineering and mathematics (STEM) instructional and research capacities of specific institutions of higher education that serve the Nation's indigenous students. The PEEC-II track provides support for studies or educational research conducted by institutions that have had earlier Pre-Engineering Education Collaborative (PEEC) awards.  The intent of PEEC-II is to capture, analyze, and disseminate the impact of these awards on the participating institutions, faculty, or students, and their communities. PEEC and PEEC-II are partnerships between TCUP and the Directorate for Engineering.<br/><br/>Kapiolani Community College (KCC), as the lead institution of a University of Hawaii (UH) System collaboration that includes Honolulu Community College (HCC), Leeward Community College (LCC), Maui College (MC), and Windward Community College (WCC) and University of Hawaii Manoa (UHM), proposes to build on the foundation of their PEEC award which created pre-engineering tracks and transfer agreements between the colleges and UHM as well as instituted student support activities.  The Hawaii PEEC II goals are: 1) to build capacity at Native Hawaiian-serving institutions to prepare students for engineering degree completion, seamless transfer to a four-year institution, and entry into the workforce; and 2) to implement, investigate, and evaluate the effect of discipline-specific undergraduate research on student success. <br/><br/>Along with expanding the sense of place for Native Hawaiian students on each campus through facilities and resources that support the community, the project will contribute to a better understanding of retention and student success in formal pre-engineering programs especially for Native Hawaiian students. The project will investigate the effect of undergraduate research on student success and the utility of vertically-integrated projects for university and community college students around the themes of robotics, space & astronomy, maker, and sustainability. PEEC II will provide evidenced-based practices to help resolve a major national problem for community colleges attempting to develop effective engineering transfer pathways to universities for students underrepresented in STEM."
"1762137","RAPID: Collaborative Research: Unmanned Aerial System Datasets from Hurricanes Harvey and Irma","CNS","Hurricane Harvey 2017","10/01/2017","09/20/2017","Robin Murphy","TX","Texas A&M Engineering Experiment Station","Standard Grant","Jonathan Sprinkle","09/30/2018","$17,780.00","","murphy@cse.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","CSE","071Y","7914, 9102","$0.00","This 12-month RAPID project will organize unmanned aerial system (UAS) data from 119 flights at Hurricane Harvey and 247 at Hurricane Irma, in order to make the data available to researchers. The project will (1) screen for personal privacy identification and applicable state laws, and make available to researchers, (2) host a virtual workshop to introduce the dataset and access procedures for researchers, and (3) host a follow up workshop at the 2018 IEEE International Symposium on Safety Security and Rescue Robotics to discuss the results by researchers using the datasets and how to acquire datasets in the future.<br/><br/>The datasets were collected by the Texas A&M Engineering Experiment Station and Florida State University who co-deployed to Fort Bend County, Texas, and Putnam and Collier Counties, Florida. They are unique because they (1) reflect the largest number of flights for public officials; (2) represent a diversity of UAS platforms (10 different models) flying at different altitudes and for eight distinctly different missions; (3) consist of video, still imagery, and photogrammetric data products based on mission; and (4) include flights before the event, during the response phase, and through the restoration phase. However, the datasets require some additional work to screen content for privacy, to complete meta-data, to be consistent in naming conventions in order to facilitate access by external researchers, and to set up controlled access. The datasets are ephemeral because the missing meta-data of pilots, platforms, and flight times for each mission will be lost in the memory of the pilots and because the datasets are needed to enable other researchers in computing and engineering use the data."
"1502037","Aerospace Career Education","DUE","S-STEM:SCHLR SCI TECH ENG&MATH, ADVANCED TECH EDUCATION PROG","10/01/2015","09/09/2015","Patrick Pritchard","WA","Green River Community College","Standard Grant","Heather Watson","09/30/2018","$891,186.00","David Bilyeu","ppritchard@greenriver.edu","12401 SE 320th St.","Auburn","WA","980923622","2538339111","EHR","1536, 7412","1032, 9178, SMET","$0.00","Aerospace Career Education (ACE) will create a diverse, world-class STEM workforce by educating students for high-wage, high-demand technical careers in Maintenance Mechatronics (MTX). Project ACE addresses a growing shortage of qualified aerospace technicians with interdisciplinary skills. The project will generate useful data and practices for high schools and colleges to recruit and prepare a larger and more diverse body of students for STEM careers. Its collaboration between Green River Community College, the local K-12 school district, a global aerospace company (Boeing), statewide Center of Excellence, a national dual-enrollment accrediting body, and cooperation with the Advancing Technological Education Center for Aerospace Technical Education (SpaceTEC) will enable wide dissemination. Project ACE will prepare more than 80 diverse high school students for college-level work through hands-on, industry-based, dual-enrollment courses. Students will earn both high school and college credit. Coursework will be complemented by paid summer internships in the aerospace industry and participation on robotics competition teams. Courses and activities will form a progressive career pathway from high school to a postsecondary MTX certificate and two-year degree.  Project ACE will help our nation reach new heights in scientific innovation and economic productivity.<br/><br/>Project ACE reflects contemporary research evidence on effective practices and models.  Courses will be co-taught by college and high school instructors using a ""flipped"" hybrid online/classroom structure. The project will advance scientific understanding by producing a diverse body of well-educated and skilled graduates, increasing the breadth of perspectives and backgrounds in our STEM workforce. It will use innovative industry practices to increase the effectiveness and sustainability of instruction. It will also improve the technical skills and general STEM preparation of high school educators. The project will advance understanding of how long-term degree pathways and industry-based practices can broaden access to STEM careers for low-income and under-represented students. Its evaluation plan includes quantitative and qualitative measures for assessing its impact upon students and teachers.  Evaluation will use a combination of original instruments developed for the project, and standardized instruments. The evaluator will create a survey that will be administered at the beginning and end of the course sequence to track changes in students' educational and career aspirations.  The project will administer two standardized instruments to participating students using a ""pre-post"" design. These instruments are: (1) the Developmental Asset Profile by the Search Institute, measuring growth in students' internal and external developmental assets believed to support resilience  and growth and assessments for their National Career Readiness Certificate (NCRC), measuring skill growth in in the areas of applied mathematics, locating information, and reading for information.  Project materials will be rigorously evaluated and regularly updated using real-time labor market data. Educational, labor, government, and industry representatives will inform the project and engage their peers to ensure its long-term sustainability."
"1717355","RI: Small: Low Cost Technologies to Improve the Quality of 3D Scanning","IIS","ROBUST INTELLIGENCE","09/01/2017","08/17/2017","Gabriel Taubin","RI","Brown University","Standard Grant","Jie Yang","08/31/2020","$449,994.00","","taubin@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","CSE","7495","7495, 7923, 9150","$0.00","This project develops a new mathematical framework, algorithms, and optical designs to increase the resolution and precision of line and area 3D scanners, and to minimize the hardware cost.  Combining simple optical design techniques and novel mathematical formulations, this project builds the next generation of low cost high resolution 3D scanner systems based on active illumination and 3D triangulation.  The project designs, fabricates, and demonstrates prototype 3D scanners based on the new technologies. The project integrates research with education. Courses taught by the principal investigator on a regular basis provide the necessary mathematics, software, and practical details to design and build 3D scanners using off-the-shelf low cost semiconductor lasers, small LED projectors, and web-cams, as well as digital geometry processing software. Undergraduate and graduate students learn in these courses to design and build low cost 3D scanners based on the technologies being developed in this project. By significantly lowering the cost of high resolution 3D scanning systems, the technology, software and methods being developed in this project have significant impact in the multiple applications in computer vision, computer graphics, and robotics.  <br/><br/>The research studies a new mathematical formulation for 3D optical triangulation based on interval arithmetic, where 3D points are only determined within certain bounds along the camera rays, and multiple measurements are used to tighten these bounds.  The project introduces the ""Line Segment Cloud"" as an alternative surface representation, and as a tool to visualize the measurement errors within the proposed framework.  The project develops new variational surface reconstruction methods with line segment constraints tailored to line segment clouds.  Enabled by the new formulation, the project is constructing: 1) novel laser line and structured light super-resolution 3D scanners, where the projectors are mounted on small displacement motion platforms; 2) structured light area 3D scanners where the different 3D patterns are projected by fixed non-coaxial LED slide projectors, and neither DLP or LCD projector engines are used; and 3) super-resolution 3D scanners based on volume carving, optimized for existing line and area based 3D scanners, where camera and projector are rigidly mounted with respect to each other.  The project is also developing techniques to design laser line projectors optimized for optical triangulation using inexpensive optical components, where the thickness of the projected line is significantly reduced and the depth of field is increased. The project develops new calibration methods and performance metrics to evaluate these technologies."
"1718384","RI: Small: A New Approach to Integrating Graphical Models in Decision-Theoretic Planning","IIS","ROBUST INTELLIGENCE","08/15/2017","07/25/2017","Eric Hansen","MS","Mississippi State University","Standard Grant","James Donlon","07/31/2020","$427,000.00","","hansen@cse.msstate.edu","PO Box 6156","MISSISSIPPI STATE","MS","397629662","6623257404","CSE","7495","7495, 7923, 9150","$0.00","This project addresses one of the central problems of research in Artificial Intelligence: the problem of planning, or sequential decision making, under uncertainty and imperfect information. Planning algorithms are widely-used for control and decision-making problems in engineering and business, with many practical applications in robotics, process control, logistics, user-adaptive systems, resource management, and related problems where automation of decision making is useful. This project considers two widely-used decision-theoretic frameworks for planning under uncertainty and imperfect information, which are partially observable Markov decision processes and influence diagrams, and integrates these two frameworks in a novel way that leverages their complementary advantages. <br/><br/>The project integrates these two frameworks by showing how to generalize algorithms for solving influence diagrams, especially classic variable elimination algorithms, so that they use algorithmic techniques for solving partially observable Markov decision processes (POMDPs) to improve scalability, as well as to represent plans and strategies more compactly. The generalized variable elimination algorithms developed in this project can behave like traditional algorithms for solving influence diagrams, or like traditional algorithms for solving POMDPs, depending on the order in which variables are eliminated. From this perspective, algorithms for influence diagrams and POMDPs that once appeared dissimilar can be viewed as special cases of the same, more general algorithm. More importantly, this perspective allows these complementary algorithmic techniques to be combined in new ways, leading to planning algorithms with improved performance, wider applicability, and easier-to-interpret results.  The project focuses on several related research problems that will extend this approach and make it more useful in practice, including the development of new heuristics for variable elimination ordering, the development of approaches to improving planner performance by leveraging problem structure, including context-specific independence, and the development of an integrated approach to bounded-error approximation that will allow tradeoffs between plan quality and computation time. Although the project focuses on finite-horizon planning problems, the integrated approach may also be used in solving infinite-horizon planning problems with non-Markovian structure. In addition to the intellectual impact of this research, the project will contribute to education, student mentoring, and outreach."
"1212798","RI: Large: Collaborative Research: Reconstructive recognition: Uniting statistical scene understanding and physics-based visual reasoning","IIS","ROBUST INTELLIGENCE","10/01/2012","09/12/2012","Trevor Darrell","CA","University of California-Berkeley","Standard Grant","Jie Yang","09/30/2018","$818,181.00","Jitendra Malik","trevor@eecs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7495","7925","$0.00","This project is creating a novel paradigm for computer vision, termed ""reconstructive recognition"", that incorporates the strongest elements of previous machine learning-based recognition efforts and the strongest elements of previous reconstruction efforts based on radiometric reasoning. The goal is to provide a new foundation for machine perception, and the potential for a transformative advance in applications of computer vision. The project seeks novel physics-based methods for recognition as well as novel learning-based methods for interpreting pixel values in terms of the physics of a scene. The agenda is structured around four aims: Aim I develops generalized reconstructive processes that unify the recovery of shape, materials, motion and illumination. Aim II focuses on supervised visual learning methods that exploit such reconstructive image representations. Aim III pursues unsupervised discovery of reconstructive representations that converge to be similar to the engineered models of Aim I. Finally, Aim IV introduces well-defined challenge problems that focus the field and serve as measurable proxies for progress in computer vision applications that have high potential impact on society. <br/><br/>There is a significant broader impact to this project, not least being the improvement in computer vision pedagogy that ensues from a reunification of the currently divergent recognition and reconstruction views of the field. More broadly, this project pursues critical steps toward a future where machines can see, a future that will bring changes to robotics, human-computer interfaces, security, and autonomous navigation, to name a few."
"1747275","SBIR Phase I:  Low-Cost 2D and 3D Millimeter Wave Image Sensors","IIP","SMALL BUSINESS PHASE I","01/01/2018","12/21/2017","CLAIRE WATTS","WA","Thruwave LLC","Standard Grant","Muralidharan S. Nair","12/31/2018","$224,957.00","","claire.marie.watts@gmail.com","3000 Mason Rd","Seattle","WA","981950001","6179539597","ENG","5371","5371, 8034","$0.00","The broader impact/commercial potential of this project includes a new, low-cost approach to 3D millimeter wave image sensors enabling non-destructive evaluation in construction, as well as other fields such as robotics, security, and quality control. Millimeter wave imaging uses human-safe, radio frequency signals to make high resolution images of objects that cannot be seen with conventional optical sensors. Because of their long wavelength, millimeter waves pass through many materials that are opaque to visible light, including common construction materials such as drywall, brick, tile, cement, and wood. For example, in the construction market, dramatic cost savings and faster, safer, and more accurate construction work could be achieved using millimeter wave imaging for structural evaluation as well as observing hidden utilities such as wiring and plumbing that should be avoided while drilling, and detecting hazards such as water leaks behind wall surfaces. This project will also provide entrepreneurial opportunity to a new generation of scholars/innovators as the technology matures toward commercial practice.<br/><br/>This Small Business Innovation Research (SBIR) Phase I project aims to advance the state of the art in millimeter wave imaging and enable low-cost, standalone 3D millimeter wave imagers. Prior work in a laboratory environment has demonstrated the promise of millimeter wave imaging for applications such as structural analysis in construction, however commercialization requires an image sensor that is fast, portable, low power, and low cost. This project will enable low cost hardware/software platforms for millimeter wave imaging using commercial chipsets with novel general purpose graphics processing unit (GPGPU)-accelerated image reconstruction algorithms."
"1717178","CHS: Small: Physically-Based Simulation of Strand-Liquid Interaction","IIS","Cyber-Human Systems (CHS)","09/01/2017","08/17/2017","Eitan Grinspun","NY","Columbia University","Standard Grant","Ephraim P. Glinert","08/31/2020","$353,995.00","Changxi Zheng","eitan@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7367","7367, 7923","$0.00","This project develops algorithms that predict the dynamics of liquids interacting with thin flexible strands.  The interaction of strands with each other, and with liquids, is a fundamental physical consideration in myriad contexts.  Therefore, the development of computer algorithms that can predict the physics of liquid-strand interaction has the potential to spur advances in many important scientific and engineering fields of investigation.  New algorithms are needed to improve realism in virtual reality, one of the grand challenges in engineering as recognized by the National Academy of Engineering, and also to advance important problems in biology, transoceanic communications, robotics, graphical animation, and industrial product design.  A fundamental challenge addressed by this project is accounting for the many ways in which liquids and strands interact.  These interactions involve numerous physical ingredients at distinct spatiotemporal scales.  Efficient integration of these components in numerical algorithms remains an important and challenging problem.  Solving this problem will involve development of algorithms that model complex, multi-scale, multi-physics systems.  The process of designing such algorithms will itself produce new insights transferrable across scientific, engineering, and creative disciplines.  Students trained by this project will become highly skilled in developing, extending, and harnessing numerical and graphical algorithms for applications spanning the natural sciences and engineering.  The investigators will encourage participation from underrepresented groups at the doctoral, masters, and undergraduate levels.<br/><br/>The research studies numerical modeling of liquid-strand interactions involving the consideration of multiple physical ingredients, including strand elasticity, liquid inertia, capillary action, wetting-induced tribological changes, inter-strand contact and friction, as external forces like gravity, and dimensionless groups, at multiple spatiotemporal scales, and over transient periods.  Unlike existing methods that model certain specific processes in isolation, this project emphasizes broad-purpose simulation of liquid-strand interaction.  This focus requires thoughtful selection of a computer model for each physical ingredient, as well as special attention to compatibility between choices, so that reconciliation of all the ingredients in different combinations becomes tractable.  In particular, this project will be carried out with two major thrusts, namely, the numerical modeling of strands interacting with Newtonian and Non-Newtonian fluids.  These thrusts will also crosscut research on robust simulation of hair contacts and performance acceleration for interactive simulation."
"1758077","SHF: Medium: Collaborative Research: FRP for Real","CCF","PROGRAMMING LANGUAGES","07/01/2017","08/31/2017","Ruzica Piskac","CT","Yale University","Standard Grant","Anindya Banerjee","09/30/2018","$27,716.00","","ruzica.piskac@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","CSE","7943","7924, 7943","$0.00","Functional Reactive Programming, or FRP, is a declarative programming paradigm based on two fundamental abstractions: a continuous (functional) modeling of time-varying behaviors, and a discrete (reactive) calculus of user and process interaction.  FRP provides a novel and effective approach to solving problems in which there is a combination of both continuous and discrete entities such as found in computer animation, robotics, control systems, GUIs, and interactive multimedia.  FRP's broader impact is seen in its adoption by several other research projects, and its use in several applications different from those at Yale.  The proposed work will strengthen these existing projects, and further broaden the applicability of FRP.  The proposed improvements in implementation will make FRP more suitable for compute-intensive applications, such as interactive 3D graphics and real-time audio processing.  It will also benefit the modeling and simulation community, which often uses declarative approaches to specifying and solving problems.<br/> <br/>Previous research at Yale helped to establish the foundations of FRP, and demonstrated its utility in several application domains.  Despite this preliminary success, more work is needed to make ""FRP for real.""  That is, to develop a system that facilitates writing natural and concise descriptions of reactive behaviors, responds well enough to satisfy most common real-time constraints, reifies real-world objects as first-class signal functions, runs efficiently through program optimization and parallel execution on multicore architectures, and has been validated in a real-world application domain, specifically audio signal processing.  The proposed research will advance the overall FRP methodology in three areas: Language Design (type system extensions to capture resource constraints, a redesign of the mediation between the discrete and continuous, and a better syntax to capture the essence of FRP); Language Implementation (program optimizations, multicore execution, asynchronous sub-processes); and Validation and Testing (with a focus on real-time audio signal processing)."
"1718012","RI: Small: Depth from Differential Defocus","IIS","ROBUST INTELLIGENCE","08/01/2017","07/25/2017","Todd Zickler","MA","Harvard University","Standard Grant","Jie Yang","07/31/2020","$449,999.00","","zickler@eecs.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","7495","7495, 7923","$0.00","This project will explore a new class of depth sensors. The new sensors operate by observing small changes in optical defocus through a single lens, and they require very small amounts of digital computation. The distinguishing feature of these sensors is that they can be much smaller and lower power than existing depth sensor technologies. By enabling depth sensing capabilities on smaller platforms, they help accelerate the creation of smart micro-scale systems and an effective Internet of things. Depth sensors produce two-dimensional images where each pixel's value is the distance to a scene point along a corresponding ray. A variety of these sensors exist, and they are already fueling advances in autonomous navigation, gesture-driven interfaces, robotics, and more.<br/><br/>This research will develop sensors based on a new visual cue called differential defocus. Like the well-known passive depth cues of stereo and depth-from-defocus, this new cue avoids spending power on broadcasting light. But unlike the existing passive cues, it calculates depth using simple analytic expressions that are easy to compute. To establish differential defocus as a new way to sense depth, this project aims to discover a complete stack of knowledge, from mathematical foundations to algorithms and hardware prototypes. The mathematical foundations include a catalog of depth constraints that correspond to many forms of differential defocus, such as differential camera motion, sensor motion, change of focal length, and change of aperture. At the hardware level, the project will pursue both single-shot and multi-shot designs that incorporate deformable lenses and customized photosensors. Algorithmically, the project will explore methods for using back-propagation to fine-tune the parameters of depth computations. Going further, it will explore back-propagation into the optical dimension, in order to enable the optimization of optical and computational parameters together, in a synergistic manner."
"1734220","CompCog: Bridging the gap between behavioral and neural correlates of attention using a computational model of neural mechanisms","BCS","PERCEPTION, ACTION & COGNITION","08/01/2017","06/21/2017","Bradley Wyble","PA","Pennsylvania State Univ University Park","Standard Grant","Lawrence Gottlob","07/31/2020","$390,711.00","","bpw10@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","SBE","7252","7252","$0.00","A challenge for our visual system is being able to focus on information important for our current task, while also being responsive to unexpected events.  For example, when driving, if one is looking carefully for a street sign, one should also be able to stop to avoid a car pulling out from a side street. To address this challenge, our brain uses an attentional system that monitors the environment for important information and decides what should be focused at each moment in time. The proposed research will investigate this attentional system, using experiments that examine behaviors and brain activity, as well as with a computer model that integrates other findings from many different labs. This model will help researchers to better understand how brainwaves are related to both the activity of brain cells and behavior when visual attention is engaged. The model will be made publicly available in a format that anyone can run on their own computer, so that other researchers can use it to help advance our understanding in many important areas, such as how cars and other automated systems will be able to navigate and interact safely with the world. Finally, this work supports educational efforts aimed at engaging undergraduate students with a highly technical approach to scientific investigation and funds outreach efforts in high schools to give students the opportunity to develop a greater interest in neuroscience and robotics.<br/><br/>This work builds on decades of research into the nature of visual attention, which has generated a large volume of data about how the brain processes information. Based on this work, the researchers have created a computational model of attention that attempts to simulate how the brain chooses which pieces of information to attend. To validate this model, they will conduct a series of eight new experiments that test specific predictions of the model. These tests will provide information about how the different layers of neurons in the model should communicate to most closely approximate the human brain's attentional system. The final model will be compiled into a version that can be downloaded by other researchers or educators. This model will provide a polished graphical user interface, allowing novice users to explore how the simulated attention system works, and how brainwaves are generated. A further objective will be to develop a new kind of experiment that tests the delay between vision and attention. The data from this paradigm will give scientists crucial details about how the human visual system temporarily holds information while determining what to do with it."
"1762139","RAPID: Collaborative Research: Unmanned Aerial System Datasets from Hurricanes Harvey and Irma","CNS","Hurricane Harvey 2017","10/01/2017","09/20/2017","David Merrick","FL","Florida State University","Standard Grant","Jonathan Sprinkle","09/30/2018","$11,740.00","","dmerrick@fsu.edu","874 Traditions Way, 3rd Floor","TALLAHASSEE","FL","323064166","8506445260","CSE","071Y","7914","$0.00","This 12-month RAPID project will organize unmanned aerial system (UAS) data from 119 flights at Hurricane Harvey and 247 at Hurricane Irma, in order to make the data available to researchers. The project will (1) screen for personal privacy identification and applicable state laws, and make available to researchers, (2) host a virtual workshop to introduce the dataset and access procedures for researchers, and (3) host a follow up workshop at the 2018 IEEE International Symposium on Safety Security and Rescue Robotics to discuss the results by researchers using the datasets and how to acquire datasets in the future.<br/><br/>The datasets were collected by the Texas A&M Engineering Experiment Station and Florida State University who co-deployed to Fort Bend County, Texas, and Putnam and Collier Counties, Florida. They are unique because they (1) reflect the largest number of flights for public officials; (2) represent a diversity of UAS platforms (10 different models) flying at different altitudes and for eight distinctly different missions; (3) consist of video, still imagery, and photogrammetric data products based on mission; and (4) include flights before the event, during the response phase, and through the restoration phase. However, the datasets require some additional work to screen content for privacy, to complete meta-data, to be consistent in naming conventions in order to facilitate access by external researchers, and to set up controlled access. The datasets are ephemeral because the missing meta-data of pilots, platforms, and flight times for each mission will be lost in the memory of the pilots and because the datasets are needed to enable other researchers in computing and engineering use the data."
"1338042","MRI: Development of an Instrument that Monitors Behaviors Associated with Obsessive-Compulsive Behaviors and Schizophrenia","CNS","SPECIAL PROJECTS - CISE, INDUSTRY/UNIV COOP RES CENTERS, National Robotics Initiative","10/01/2013","08/22/2018","Nikolaos Papanikolopoulos","MN","University of Minnesota-Twin Cities","Standard Grant","Rita V. Rodriguez","09/30/2019","$630,000.00","Kelvin Lim, Gail Bernstein, Tasoulla Hadjiyanni, Arindam Banerjee","npapas@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","1714, 5761, 8013","1189, 1714, 9178, 9251","$0.00","Proposal #: 13-38042<br/>PI(s):  Papanikolopoulos, Nikolaos<br/>  Banerjee, Arindam; Bernstein, Gail; Hadjiyanni, Tassoulla; Lim, Kelvin, K.<br/>Institution: University of Minnesota-Twin Cities<br/>Title:   MRI/Dev.: Instrument that Monitors Behaviors Associated with OCD and Schizophrenia <br/>Project Proposed:<br/>This project, developing a new instrument to facilitate data collection associated with clinical assessment of complex mental health disorders such as obsessive-compulsive behaviors (known as OCD), aims to enable long-term research advances in computer vision, activity recognition and tridimensional reconstruction algorithms to automate the identification of behaviors typical of OCD subjects. The immersion of selected subjects in a virtual reality room (CAVE) is used to trigger specific behaviors to be captured and analyzed. The sophisticated sensor system under development will serve to collect these data and provide intelligent data processing capabilities that would enable future exploration and testing of new diagnostic and therapeutic protocols, leading to the establishment of the basis for, and utility in, seeking early at-risk markers in children and adolescents. This instrument initiative is based on the premise that expertise can accurately identify useful diagnostic markers and on the belief that technologies can now be developed to collect massive behavioral data in ways not previously done and discover behavioral patterns.<br/>The instrument is expected to<br/>- Provide extensive data collection associated with subjects diagnosed with the respective disorders (data useful not only to clinicians but also to computer vision and machine learning researchers among others),<br/>- Capture interactions, behaviors, and physiological reactions to real and/or synthetic multimodal stimuli (optical, acoustical, etc.),<br/>- Allow computer and information scientists to develop computational tools and algorithms to generate quantitative, adequate, and cost-effective norms for screening a broad population, <br/>- Enhance Cognitive Behavior Therapy (CBT) procedures and diagnostic protocols by integration of technologies that can excite or inhibit triggers for schizophrenic or OCD episodes,<br/>- Assess particular Augmented and Virtual Environments (AE/VEs) and social media devices (smart phones and tablets) and their impacts on the cognitive presence of normal versus afflicted subjects, and<br/>- Evaluate whether an enhanced cognitive presence via an AE/VE can increase or suppress (habituate) the intensity of behavioral symptoms detectable by sensors. <br/>Broader Impacts: Among these we have:<br/>- Creation of large and complex datasets that will enable computer scientists to apply the newest computational tools on them,<br/>Development of a potentially transformative technology-driven instrument for detecting early risk markers of OCD,<br/>- Exploration of a platform well-suited to new directions for a better characterization of mental disorders,<br/>- Systematic database development of quantified, multimodal data and a sounder and more precise basis for earlier detection,<br/>- Reduction of overall costs and a parallelizing reduction in the long-term costs due to previously delayed or incorrect diagnoses,<br/>- Reduction of anxiety, disruption, stress, and sometimes real tragedy on patients and their families, <br/>- Earlier detection and reduced need for drug-based, later stage interventions enabled by the ease of testing, and associated societal benefits, and<br/>- Student education and training in the use of the instrument."
"1724248","S&AS: FND: Safe Task-Aware Autonomous Resilient Systems (STAARS)","IIS","S&AS - Smart & Autonomous Syst, National Robotics Initiative","09/01/2017","07/27/2017","Atilla Dogan","TX","University of Texas at Arlington","Standard Grant","James Donlon","08/31/2020","$549,836.00","Yan Wan, Kamesh Subbarao, Manfred Huber, Brian Huff","dogan@uta.edu","701 S Nedderman Dr, Box 19145","Arlington","TX","760190145","8172722105","CSE","039Y, 8013","046Z, 9102","$0.00","Realizing the full potential of unmanned aerial systems (UAS) for commercial and societal benefits will call for autonomous UAS that must operate around people, especially urban/suburban areas, and respect safety, privacy, and regulatory concerns. This project will quantify the operations of UAS executing a task in urban/suburban environment as ""risk"" to these considerations, then develop dynamic risk assessment and guidance algorithms to compute least risky trajectories for the UAS to follow while executing a task.  The project will produce knowledge on the proper autonomy level of UAS in urban operations, and will benefit FAA (Federal Aviation Administration) in UAS regulatory issues. The technological advances in this project will also contribute to multiple fields including autonomy, mobile networking, and intelligent control. The task & risk-aware decision-making framework developed in this project can be applied not only to UAS, but also to other unmanned systems on the ground and in/under water, with broad applications in smart health, transportation, and manufacturing domains. The PIs also expect that successful demonstrations of ""safe"" UAS operation in various risk conditions will increase the public's acceptance of UAS technology, and benefit broad commercial UAS use and job market. The project will also produce exciting learning and training opportunities for students and the community at large to learn UAS technologies.<br/><br/>The project will use two raster maps to quantify risk:  (1) PREM (Probability Risk Exposure Map) defines the risk of exposure of people and property on the ground to the presence of a UAS in the air as a function of position and time.  (2) PURM (Probabilistic UAS Reachability Map) is the probability that the UAS can reach a position on the ground from its current position, computed based on the vehicle's capability (both nominal and diminished by possible failures) and environmental conditions such as wind.  Defining the PURM by joint probability of reachability domains for nominal and all failure cases results in a resilient system, since decisions are made considering all possible operational modes. Trajectory planning in the PURM will use a modified, bidirectional, probabilistic RRT (Rapidly Expanding Random Tree) to efficiently, incrementally plan a set of trajectories that minimizes the overall risk. An autonomous decision algorithm then can keep the risk below an acceptable level as it guides the UAS in the successful completion of a given task. Because the safe operation of UAS also highly relies on effective communication among UAS and between UAS and a Command and Control Center, the project will also develop a decentralized dynamic communication schemes under different risk levels and mobility constraints."
"1456352","SBIR Phase II:  4D scanner for image guided interventions","IIP","SMALL BUSINESS PHASE II","04/15/2015","08/20/2018","Cristian Atria","UT","nView medical Inc.","Standard Grant","Muralidharan S. Nair","09/30/2020","$1,615,512.00","","cristian.atria@nviewmed.com","1350 S Colonial Dr","Salt Lake City","UT","841082204","9787128742","ENG","5373","116E, 1367, 165E, 166E, 168E, 169E, 4096, 5373, 6840, 8240, 9150, 9251, HPCC","$0.00","The broader impact/commercial potential of this project is the significant improvement of<br/>surgical accuracy, which will dramatically reduce surgical errors, improve outcomes and<br/>reduce healthcare costs. In spine surgery alone, there are more than 500,000<br/>procedures every year in the US utilizing implants such as screws. In 4% to 11% of<br/>these surgeries, the implant placement is inaccurate. For the patient this translates into<br/>longer recoveries - from days to weeks - and in many cases into a second revision<br/>surgery. The patient is non-productive, unable to carry out their daily routines for weeks,<br/>while the healthcare system has to absorb the costs of the longer recovery as well as<br/>the revision surgeries. For both the healthcare and economic systems these are<br/>avoidable costs. The medical imaging technology being developed in this project has<br/>the potential to eliminate surgical inaccuracies across the $2.4B market of image<br/>guidance, improving clinical applications that range from orthopedic surgery to minimally<br/>invasive vascular interventions, to cancer diagnosis and treatments.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project will demonstrate a<br/>novel imaging modality, which provides near-real-time 3D live imaging - 4D - during<br/>surgery. This novel system will provide surgical imaging at a lower x-ray dose than<br/>fluoroscopy (current standard), with a geometry that allows concurrent imaging with<br/>surgery. This 4D technology has the potential to significantly reduce surgical<br/>inaccuracies, improve outcomes and reduce costs. Phase 1 successfully demonstrated<br/>the feasibility of the reconstruction algorithm used by the proposed imaging modality by<br/>showing its potential of higher surgical accuracy in a single spinal screw insertion. This<br/>Phase 2 project will I) prove the robustness of the reconstruction algorithm across a<br/>variety of use-cases, II) demonstrate the clinical usability of the 4D scanner, and III)<br/>confirm the clinical utility of the scanner. The clinical usability will be studied with an<br/>ergonomic model in a surgical setting. The clinical utility will be proven by building a<br/>system prototype and performing image quality and x-ray dose comparisons versus<br/>fluoroscopy and 3D in a realistic surgical setting. Preliminary results show that these<br/>objectives are achievable. This research is readying the technology for clinical research,<br/>regulatory clearance and commercialization."
"1632565","SBIR Phase II:  High-Speed TV-Band White Space Networks with Many-Antenna Multi-User Beamforming","IIP","SMALL BUSINESS PHASE II","09/01/2016","08/17/2018","Ryan Guerra","TX","Skylark Wireless LLC","Standard Grant","Muralidharan S. Nair","05/31/2019","$909,999.00","","ryan@skylarkwireless.com","1953 Richmond Ave","Houston","TX","770983401","8329302148","ENG","5373","169E, 4096, 5373, 6840, 8035, 8240, 9150, HPCC","$0.00","The broader impact/commercial potential of this project is to provide wireless technology for economic high-speed internet connectivity in under-served rural regions, addressing the needs of 40 million Americans and over 50% of the global population. The technological developments in this project will pave the way for adoption of Massive, or Many-Antenna MIMO technologies in next-generation wireless systems by addressing scalability bottlenecks with innovative hardware and protocol design. The result of this project will be a revolutionary new wireless system for internet service providers addressing an $80 billion fixed wireless systems market and connecting under-served global communities to high-speed internet commerce, communications, education, and entertainment.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project will develop a production-ready Television White Space (TVWS) Massive MU-MIMO wireless system for IP data traffic, then use it to characterize for the first time diverse, large-scale multi-user TVWS channels. This project will demonstrate the first economically-viable Massive MIMO system, as well as the first point-to-multipoint wireless system capable of non-line-of-sight ranges over 10s of miles with over 2 Gbps of aggregate capacity. The system will be used to measure and characterize TVWS channels at scale in various rural environments, with large beamforming arrays serving tens of clients tens of miles away. In particular, these measurements will explore the effect of range, environment, user separation, and polarization on real-world achievable capacity. The results will be used to guide the design, optimization, and deployment of rural TVWS broadband networks across the world."
"1632274","SBIR Phase II:  Touch and Feel a Virtual Object with Life-like Realism","IIP","SMALL BUSINESS PHASE II","09/01/2016","08/17/2018","Steven Domenikos","MA","TACTAI","Standard Grant","Muralidharan S. Nair","02/29/2020","$1,110,430.00","","sdomenikos@tactai.com","225 Wyman Street","Waltham","MA","024511209","6173917915","ENG","5373","165E, 169E, 4096, 5373, 6840, 8035, HPCC","$0.00","The broader impact/commercial potential of this project is to create a suite of consumer hardware and software products that provide realistic tactile feedback to users who are touching objects in virtual reality (VR) and augmented reality (AR). As evidenced by the current proliferation of low-cost head-mounted displays and motion tracking systems, three-dimensional interaction technologies are revolutionizing how people interact with computers, media, and each other. Since they are currently limited to vision and audio, endowing consumer-level human-computer interfaces with high-fidelity tactile feedback will vastly increase user immersion, making games more fun, online interactions more effective, and tools more efficient. Consequently, this project has the potential to expand the commercial reach of the burgeoning VR/AR market, opening up myriad opportunities for companies particularly in the gaming, entertainment, and e-commerce sectors. The innovation of this project also promises to enhance scientific and technological understanding of haptic human-computer interaction by establishing a new paradigm that blends minimal wearable hardware with sophisticated software algorithms. Finally, commercializing novel interactive technology also has the potential to help inspire a diverse array of young people to pursue a career in the critical areas of science, technology, engineering, and math.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project aims to advance knowledge of low-cost technology that can provide realistic tactile feedback to a user touching objects in VR or AR: the project?s intellectual merits center on testing a new approach that combines minimal haptic hardware and sophisticated software algorithms. The research objective is to create a fully functional industrial prototype of a wearable fingertip thimble and custom software that embody the proposed approach. When the user's finger moves to touch a virtual object, a platform inside the thimble will initiate contact with the fingerpad and press with a force that varies with penetration distance, to render surface softness. A thermal actuator will convey the object?s thermal conductivity and temperature. When the finger slides along a virtual object, the user will feel its texture via carefully designed platform vibrations. Specific research tasks to be addressed include exploring haptic actuator options, building a library of haptic object properties (HOPs) that can be applied to virtual objects, and creating a communication protocol for exchanging haptic signals among devices. This project is expected to yield a fully functional industrial prototype and developer kits for the wearable fingertip thimble."
"1758678","STTR Phase II:  Autonomous Landing of Small Unmanned Aircraft Systems onto Moving Platforms","IIP","STTR PHASE II","03/15/2018","08/15/2018","Gaemus Collins","CA","Planck Aerosystems Inc","Standard Grant","Muralidharan S. Nair","08/31/2020","$898,447.00","Timothy McLain","gaemus@planckaero.com","710 13th St Unit 307","San Diego","CA","921017351","6192305049","ENG","1591","1591, 169E, 6840, 8034, 8035, HPCC","$0.00","The broader impact/commercial potential of this project will enable Unmanned Aerial Systems<br/>(UAS or drones) to safely and reliably operate from moving vehicles and moving vessels at sea.<br/>There is an immediate need for this capability in many industries. In commercial fishing, drones<br/>will replace manned aircraft for fish-finding operations, radically reducing cost and risk. In maritime<br/>security, drones will provide surveillance around ships, including locating a ?man-overboard? in<br/>time to save the person?s life. In the oil and gas industry, drones will provide rapid-response to oil<br/>spills by mapping the location and extent of the oil slick, limiting the environmental and economic<br/>damage. In hydrographic surveying, drones will identify and geo-locate navigation aids, at a<br/>fraction of the time and cost of current survey methods. In commercial shipping, drones will<br/>inspect and protect shipping vessels while they are underway. In the transport industry, drones<br/>will delivery packages the ?last mile? from a delivery truck to a customer?s door. In law enforcement<br/>and border security, drones will operate from moving patrol vehicles while officers remain safe<br/>and mobile in the vehicle. These applications are currently difficult or impossible, but will become<br/>radically safer and easier with the proposed technology.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project will advance the current state<br/>of the art in UAS/drone autonomy, to enable reliable drone operations from moving vehicles and<br/>moving vessels at sea. Shipboard landing is extremely difficult, due to the heaving and rolling of<br/>the ship deck, potential high winds, and the high precision control required during landing. Current<br/>drone technology does not facilitate landing on moving platforms; this prevents their use in<br/>maritime operations, and has become the main barrier to commercialization in this sector. The<br/>proposed research will develop a vision-aided relative navigation system that combines precise<br/>air-to-ship observations with onboard sensor measurements to accurately estimate the relative<br/>state between the drone and the ship. These relative state estimates will be used to dynamically<br/>route and control the drone safely on to the ship deck. Technical feasibility of this approach has<br/>been demonstrated during the Phase I project, which included demonstration of the technology<br/>in a relevant environment. The primary goals of the Phase 2 project are to improve system<br/>reliability, expand the operational envelope, and productize our system. The plan to achieve these<br/>goals includes scientific development paired with extensive testing, validation, and demonstration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1463523","Mechanobiological Regulation of Cortical Bone in Vertebrates","CMMI","Biomechanics & Mechanobiology","06/01/2015","03/28/2018","Russell Main","IN","Purdue University","Standard Grant","Michele Grimm","05/31/2019","$421,665.00","Eric Nauman, James DeWoody, Sandra San Miguel (Amass)","rmain@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","ENG","7479","024E, 027E, 028E, 036E, 070Z, 1057, 8086, CVIS","$0.00","Diversity in skeletal form amongst vertebrate animals results from a combination of genetic and environmental influences during growth and aging. Mechanical stimuli, caused by physical activity, represent a potent environmental influence that regulates bone growth and remodeling. ""Warm-blooded"" mammals and birds may be able to maintain relatively light skeletons compared to ""cold-blooded"" reptiles and amphibians because their bone cells are inherently more responsive to mechanical loading. However, it is unclear if the differences in skeletal response are caused by differences in the bone cells, differences in the metabolic rate of ""cold"" and ""warm"" blooded animals, or a combination of both. The award will investigate the relative adaptive potential of the skeleton among different terrestrial vertebrates and determine the underlying physiological, anatomical, and genetic regulatory factors influencing adaptive bone formation. This work will be critical for understanding evolutionary diversity in skeletal form among mammals and birds and the relative conservation of skeletal structure in modern ""cold-blooded"" vertebrates compared to ancient (fossil) examples. Novel molecules regulating bone formation, which could have important biomedical applications for treating bone loss, will be measured. The results of this work will be presented to the public through lectures, university websites, and through learning modules to teach local elementary and junior high school students science and engineering concepts.<br/><br/>The objective of this research is to relate regulation of the mechanosensitive Sost-Wnt/beta-catenin pathway, specific to osteocyte-induced skeletal anabolism, to the bone tissue response to physical stimuli in the skeletons of four species from three terrestrial vertebrate groups (reptiles, birds, mammals) under artificial tibial loading. The multi-scale gene- to tissue-level approach used here will utilize in vivo bone functional adaptation models, in vitro bone tissue organ culture models, 3D confocal microscopy, and transcriptomic analyses to establish a comparative understanding of molecular and cellular mechanobiological mechanisms in the vertebrate skeleton, the influence of animal metabolism on organismal response to environmental challenges, and factors influencing structural diversity across different vertebrate groups."
"1632498","SBIR Phase II:  Cognitive Radio Small Cell for Pervasive Coverage and Sustained","IIP","SMALL BUSINESS PHASE II","09/01/2016","07/24/2018","Kamil Agi","NM","K&A Wireless, LLC","Standard Grant","Muralidharan S. Nair","02/28/2019","$908,893.00","","kagi@ka-wireless.com","2350 Alamo Ave. SE","ALBUQUERQUE","NM","871063225","5053382380","ENG","5373","169E, 4096, 5373, 6840, 8035, 8240, 9150, HPCC","$0.00","The broader impact/commercial potential of this project includes: 1) Training of graduate students on complex research & development as well as enabling student understanding of service and hardware business models, 2) A potential economic impact that is between $0.9T and S1.7T (trillion) according to a McKinsey study of  IoT technology in smart city applications, 3) The improvement of the stature of the countries in the world market where this advanced technology solution will be offered, such as Ibero-America, 4) A significant improvement of the ability to handle large number of devices on a network without bogging down the overall network while enabling future bandwidth intensive applications, and 5) The ability to provide low-cost Internet connectivity for underserved populations through city-wide wireless network deployments.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project seeks to complete the development of a Spectrum Intelligent IoT Gateway initiated during Phase I. The key innovation of this system is a proprietary Spectrum Intelligence capability used to identify spectrum occupancy in the vicinity and modify transmission parameters in the network. The Intellectual Merits of this project include: 1) Implementing and testing a novel IoT Gateway with autonomous channel selection capability based on spectrum occupancy information; 2) Transferring spectrum sensing algorithms into an FPGA platform for its field deployment, and as the first step towards and spectrum sensing ASIC design; 3) Obtaining a model-based design for an enterprise network architecture of IoT Gateways; and 4) Implementing and testing new adaptive OFDM approaches to optimize power and frequency usage is 4g/5G wireless communications."
"1634328","Collaborative Research: An Integrated Experimental/Computational Study of the Mechanics of Nanofiber Networks","CMMI","Mechanics of Materials and Str","08/15/2016","07/10/2016","Catalin Picu","NY","Rensselaer Polytechnic Institute","Standard Grant","Siddiq Qidwai","07/31/2019","$269,833.00","","picuc@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","ENG","1630","022E, 024E, 027E, 8086, 9161, AMPP","$0.00","This award supports research to characterize the effective mechanical strength and ductility of polymer nanofiber networks for nanofilamentous materials such as gels, rubber, tissue scaffolds, cellulose products and non-wovens. Although macroscale fiber networks are quite well understood, nanofibers behave differently from their macroscale counterparts due to the coupled effect of their outstanding ductility and strength that are not observed in microscale fibers, and the relatively strong adhesion between nanofibers. These two distinguishing features lead to currently unexplored opportunities for controlling and vastly improving the effective mechanical strength and ductility of polymer nanofiber networks. Ordered and random networks of nanofilaments composed of polymeric or biological materials are omnipresent in biological tissues, tissue scaffolds, biomedical implants, electrospun air filtration systems, cellulose products, etc. Undergraduate researchers will work with the faculty and graduate students to develop web-based, interactive educational classroom modules to introduce students to the concepts of fiber networks and design.<br/><br/>The research focuses on regular and random quasi-2D nanofiber networks with bonded and non-bonded (cohesive) interactions between polymeric nanofibers, to identify ways for constructing networks with exceptional strength and toughness. To this effect, a tightly integrated experimental/computational research program will be followed in which the mechanical response of polystyrene (PS) and polyacrylonitrile (PAN) nanofibers (100-500 nm diameter), and the strength of bonded fiber interactions and adhesive PS-PS and PAN-PAN fiber contacts will be determined using novel experiments. The data will be employed to calibrate a computational model for the network mechanics, which will account for bonded, adhesive and topological interactions of nanofibers and will be used to determine the relative importance of these interactions in the overall mechanical behavior of networks with various network architectures and parameter sets. The model will be validated based on targeted experiments performed on regular and random fiber networks, and will be applied to perform optimization of the network structure for enhanced strength and toughness."
"1762018","Non-Born-Oppenheimer Effects in the Framework of Multicomponent Time-Dependent Density Functional Theory","CHE","Theory, Models, Comput. Method","08/01/2018","07/26/2018","Sharon Hammes-Schiffer","CT","Yale University","Standard Grant","Evelyn M. Goldfield","07/31/2020","$320,000.00","","sharon.hammes-schiffer@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","MPS","6881","8084, 8086, 9216, 9263","$0.00","Sharon Hammes-Schiffer of Yale University is supported by an award from the Chemical Theory, Models and Computational Methods program in the Division of Chemistry to develop computational approaches to study the interaction between electrons and protons in chemical systems. The coupling between electrons and protons plays a vital role in many important biological processes such as photosynthesis and respiration.  They also play a role in technology, for example, in energy production in solar cells.  Developing computational methods to accurately describe this coupling is challenging.   Electrons and protons are so light that they must be treated quantum mechanically.    Hammes-Schiffer and her coworkers develop quantum mechanics methods that are computationally efficient. These   methods are applied to specific processes of biological and chemical relevance.  The Hammes-Schiffer research group also maintains and enhances a website containing software and educational tools related to this topic.  The computer programs, tools, demonstrations, and tutorials available on this web site will enable scientists in a broad range of fields to learn about this topic.  In addition, this project facilitates technological and biomedical advances through a better understanding of the coupling between electrons and protons.  An important example is the design of more effective solar cells and other alternative, renewable energy sources.  Another example is the design of more effective drugs through modification of enzymes that rely on the coupling between electrons and protons.<br/> <br/><br/>The objective of this project is to develop new theoretical and computational approaches that will provide insight into the underlying fundamental principles of photoinduced proton transfer and proton-coupled electron transfer (PCET) reactions, which play a vital role in a broad range of biological and chemical processes. The specific issues to be examined include the roles of nuclear quantum effects, such as proton delocalization and zero-point energy, as well as non-Born-Oppenheimer effects, which are often significant in these types of reactions.  The method development is conducted within the framework of the nuclear-electronic orbital density functional theory (NEO-DFT) approach, which treats key nuclei, such as the transferring proton(s), quantum mechanically on the same level as the electrons within the framework of DFT.  The focus is to develop the multicomponent time-dependent DFT (NEO-TDDFT) approach for calculating excited electronic, proton vibrational, and electron-proton vibronic states.  This approach is used to compute excitation energies and transition densities for photoinduced proton transfer and PCET systems.  The NEO-DFT and NEO-TDDFT approaches is being incorporated into a publicly  available electronic structure package.  In addition, tutorials are being created to explain how to perform NEO calculations and to highlight the unique capabilities of this approach.  Furthermore, a web site on PCET is being enhanced to convey useful information to the community and to provide useful tools, scripts, and programs relevant to studying PCET.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1554326","CAREER: Mechanics and Physics at the Boundary Between Solid and Fluid: Probing the Thermodynamic and Kinetic Properties of Gels","CMMI","CAREER: FACULTY EARLY CAR DEV, Mechanics of Materials and Str","02/01/2016","01/06/2016","Yuhang Hu","IL","University of Illinois at Urbana-Champaign","Standard Grant","Siddiq Qidwai","01/31/2021","$500,000.00","","yuhanghu@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","ENG","1045, 1630","022E, 024E, 027E, 1045, 1630, 8086","$0.00","This Faculty Early Career Development (CAREER) project will develop a new experimental technique to characterize the nonlinear thermodynamic and kinetic properties of gels. Defying the classical definitions of solid and fluid, gels are both solid-like and fluid-like. They are both ubiquitous components of natural organisms and important engineering materials. Despite their wide applications, the design of these materials at this stage remains mostly trial-and-error due to a lack of fundamental understanding of the complex thermodynamic and kinetic behaviors of gels. The success of this work will lead to a robust and high throughput technique capable of measuring the thermodynamic and kinetic properties of soft gels under wide range of conditions and provide a standard toolbox for engineers to realize quantitative designs based on these materials. The PI will also expand a Soft Squishy Lab to combine visual, tactile and hands-on modules to connect human perception of macroscopic properties to the underlying microstructures of soft materials at appropriate levels for K-12 students.<br/><br/>Gels are composed of crosslinked polymer network and solvent molecules. The crosslinks prevent the long polymers from dissolving in the solvent; rather the gel swells and shrinks as the small molecules migrate in and out. The solvent uptake is a two-way street: as the solvent diffuses into the network, the network deforms, leading to size and shape changes, while the deformation of the network also affects the rate and amount of solvent diffusing into or out of the network. Both the concepts and the behaviors of gels are sufficiently complex such that ample room exists for additional work to connect principles of mechanics, thermodynamics, and kinetics to experiments. The proposed study will develop a technique based on an indentation method for characterizing the nonlinear thermodynamic and kinetic properties of gels. The new technique will allow for systematic characterization of various types of stimuli-responsive gels under different environmental conditions. Based on a complete set of data from the systematic measurements, an in-depth understanding of the structure-property relations of gels can be achieved. Consequently, a physics-based constitutive model will be built."
"1636659","CAREER: Fundamental Studies on Mechanics of Three Dimensional Random Fiber Networks","CMMI","Mechanics of Materials and Str, EPSCoR Co-Funding","08/17/2015","05/06/2016","Hamed Hatami-Marbini","IL","University of Illinois at Chicago","Standard Grant","Siddiq Qidwai","03/31/2019","$373,398.00","","hatami@uic.edu","809 S. Marshfield Avenue","CHICAGO","IL","606124305","3129962862","ENG","1630, 9150","022E, 024E, 027E, 1045, 1630, 8086, 9150","$0.00","The primary research objective of this Faculty Early Career Development (CAREER) Program award is to investigate the microstructural and mechanical properties of materials composed of randomly cross-linked fibers. Fibrous materials are ubiquitous, multifunctional entities with distinctive benefits such as high specific stiffness and adjustable mechanical properties. In these materials, regardless of the intended functions, a filamentous skeleton provides the structural integrity against external forces. In this research, state-of-the-art computational models and novel analysis tools will be created to determine the underlying physical mechanisms which govern the mechanics of three dimensional fiber networks. Specifically, a multiscale model will be developed to bridge different length scales and characterize the mechanical behavior in terms of morphological and microstructural properties. This research will establish a new way of thinking about the mechanics of three-dimensional fiber networks and its relationship to the spatial distribution, assembly, and structural properties of the constituents. <br/><br/>The creation of new knowledge on the key mechanisms governing the mechanics of generic three-dimensional fiber networks is expected to carry significant potential for creating a more complete understanding of mechanical properties of biological and manmade materials such as the cell cytoskeleton, collagenous soft tissue, blood clots, battery substrates, filters, and paper products. Therefore, the outcomes of this project will be of great importance not only from a computational mechanics perspective but also as a computational framework for other scientists investigating properties of filamentous materials. A comprehensive educational plan and outreach activities are also planned to enhance the engagement of high school students in science and engineering disciplines, and to train the next generation of diverse and capable scientists and engineers. Presentations on the general topics of engineering will be given to the high school students, an engineering project based on this research will be developed for the incoming freshman students, and undergraduate and graduate students will be mentored to gain the required training for independent research in the field of mechanics of materials."
"1721266","SBIR Phase I:  Augmented Reality for Arm and Hand Rehabilitation Post-stroke","IIP","SMALL BUSINESS PHASE I","07/01/2017","07/14/2017","Omer Turkkan","CA","Motion Scientific","Standard Grant","Muralidharan S. Nair","12/31/2018","$224,916.00","","anilt@motionscientific.com","1520 Brookhollow Drive","Santa Ana","CA","927055427","7146562927","ENG","5371","5371, 6840, 8035","$0.00","The broader impact/commercial potential of this project is in line with the grand challenge of developing teaching methods that optimize learning given the diversity of individual preferences and the complexity of each human brain. Because there is a great variability in stroke-induced lesions that result in marked differences in impairment and responsiveness to motor therapy, there is even a greater need to personalize motor training in post-stroke patients. The commercial impact of the personalized e-rehabilitation system, which will be developed and tested, derives from its value for patients, clinics, and insurers. For patients, the system will provide personalized training, and, because it will encapsulate research-based principles for effective and efficient neurorehabilitation of the upper extremity, it will largely improve patients' outcomes. For clinics, the system will increase revenues by increasing the number of visits per patient due to better outcomes and compliance, as well as the number of patients trained at once in clinic gyms. For insurers, the system will generate reports showing therapy effectiveness and, thus, validate reimbursements. <br/><br/>This Small Business Innovation Research (SBIR) Phase I project is improving functions of the upper extremities following neurological disorders that affect the motor system, in particular stroke, but also Parkinson's disease and traumatic brain injury. Because therapists treating patients with these disorders only have the time to deliver about a 1/10th of the necessary dose of motor training in the clinic, patients are requested to perform most of the training at home. A novel augmented reality training system will be developed and tested. The system will automatically deliver high doses of functional tasks via presentations of virtual targets or objects in the real world. Using state-of-the-art motion sensing technology, the system will accurately and precisely measure upper body movements, including hand opening and closing. Based on these measurements, it will maximize recovery by providing adaptive training. It will maximize patient engagement and motivation by providing real-time and summary feedback for task success and improvements."
"1819302","SBIR Phase I:  Risk-Aware Motion Planning for Autonomous Vehicles","IIP","SMALL BUSINESS PHASE I","06/15/2018","06/14/2018","Peter Howard","MA","Realtime Robotics Inc","Standard Grant","Muralidharan S. Nair","11/30/2018","$225,000.00","","peter@rtr.ai","12 Channel St Ste 502","Boston","MA","022102326","7815880142","ENG","5371","5371, 8034","$0.00","The broader impact/commercial potential of this project is to enable autonomous vehicles to make risk-aware decisions at high-speed, by reasoning about the uncertain movements of the people and cars around them to anticipate risks and react defensively. This technology will make new technical approaches to safety and risk viable for the first time. It will enable autonomous cars to drive at regular speeds in dense, highly populated urban environments while reducing the likelihood of accidents - thereby resulting in faster, safer urban autonomous driving. This will increase public trust in autonomous cars and accelerate the development of a new industry which could reshape transportation, freeing people from the need to drive their own cars and increasing their free time and productivity.<br/><br/>This Small Business Innovation Research (SBIR) Phase I project aims to develop a specialized processor for risk-aware motion planning for autonomous vehicles. Motion planning is a critical problem for autonomous cars, which must decide how to move through space to reach a designated goal without colliding with a static obstacle, another vehicle, or a pedestrian. Existing approaches can only construct a few plans per second, and assume that the other road-users will continue on their current trajectories. This is acceptable for highways but not for urban driving, where distances are short and other road-users can change behavior suddenly. This project aims to develop a prototype of a specialized motion planning processor that plans in milliseconds, enabling it to consider all likely future movements of other road-users to anticipate risks and react defensively. This proposal aims to evaluate the feasibility of the processor by designing a prototype, demonstrating that it results in safer driving at normal speeds in urban environments, and quantifying its performance improvements over existing solutions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1463390","Unraveling the Structural and Biomechanical Roles of Proteoglycans in Arterial Wall","CMMI","Biomechanics & Mechanobiology","05/01/2015","05/31/2018","Katherine Y. Zhang","MA","Trustees of Boston University","Standard Grant","Michele Grimm","04/30/2019","$373,715.00","","yanhang@bu.edu","881 COMMONWEALTH AVE","BOSTON","MA","022151300","6173534365","ENG","7479","024E, 027E, 028E, 036E, 1057, 116E, 8086, 9102, 9178, 9231, 9251, CVIS","$0.00","Proteoglycans (PGs) contribute to the basic development and maintenance of arteries. While other structural molecules and cells, such as the elastic fibers, smooth muscle cells, and collagen fibers have received extensive attention, little is known about the structural and biomechanical roles of PGs in arteries. This ignorance is likely linked to the low mass fraction of PGs, and that they are thought to be most important mechanically in resisting compressive stresses.  Using natural chemicals that can dissolve away only the proteoglycans the investigators will measure the changes of artery stiffness as the proteoglycans are removed.  Also, a mathematical model will be created that includes how the proteoglycans connect between the other molecules in the tissue understand and predict how the preoteoglycan's work to create tissue stiffness.   There is a pressing need for such information in order to understand diseases of the arteries and heart. Undergraduate and graduate students who work in the project will learn to work with biology and mathematical theory to prepare them for careers in biomedical research.<br/><br/>Given the complex interactions between PGs and other structural components, the overall goal of this research is to explore how PGs contribute to the structural and biomechanical integrity of arteries through coupled mechanical testing, advanced optical imaging, and microstructure-based constitutive modeling for charged hydrated tissues. With carefully designed experiments including local extracellular matrix structural and biochemical modification, this research takes a unique approach that integrates expertise in multi-photon microscopy, biaxial tensile testing, and structure-based mixture constitutive modeling to explore the contributions of PGs to the structural and biomechanical integrity of human arteries, and to understand alterations in structural and biomechanical roles of PGs in atherosclerosis. The important interplay between PGs and other extracellular matrix constituents will be incorporated into constitutive modeling by considering key structural information and osmotic effect. Results from the research will establish a solid foundation to investigate the mechanical roles of extracellular matrix constituents in the functionality of arteries, and launch quantitative mechanobiological understandings of vascular mechanics."
"1452728","CAREER: Directing Epithelial-Mesenchymal Tissue Self-Structuring and Remodeling With Multi-scale Mechanical Interactions and Principles of Mechanobiology","CMMI","Biomechanics & Mechanobiology","02/01/2015","01/08/2015","Edward Sander","IA","University of Iowa","Standard Grant","Michele Grimm","01/31/2020","$500,000.00","","edward-sander@uiowa.edu","2 GILMORE HALL","IOWA CITY","IA","522421320","3193352123","ENG","7479","024E, 027E, 028E, 1045, 8086, 9150","$0.00","The goal of this NSF Faculty Early Career Development (CAREER) Program grant is to establish an integrated research and education program centered on understanding how physical forces contribute to the initial formation and later changes in epithelial-mesenchymal structures (EMS), such the bi-layered epidermal and dermal structure of skin. These structures are present in most body tissues and they are critical to tissue health. During the process of tissue formation, cell-to-cell and cell-to-extracellular matrix interactions combine to produce organized, functional tissues with EMS. Later in life, however, these tissues have limited capacity to regenerate themselves in response to injury, disease, or aging. Efforts to direct tissue self-structuring and remodeling for medical purposes are progressing, but they are still hampered by not knowing how the interactions between cells and matrix are coordinated biochemically and mechanically to produce a healthy tissue. These interactions are complex and produce behaviors that cannot be easily understood using a simple approach. This research will provide an essential computer model that can incorporate data and observations from different experiments into a unified picture so that basic principles of mechanobiology can be understood and used to help control tissue formation and remodeling. The project is expected to produce new discoveries and insights on the role of physical forces in epithelial-mesenchymal interactions in skin. The knowledge gained and tools developed may also be broadly applicable and useful to other parts of the body where EMS occur, such as blood vessels, lungs, intestines, and kidneys. Broader goals of the project include generating more public awareness, understanding, and excitement for how mathematics, engineering, and computer modeling can be used to simplify complex biological processes, particularly those that involve mechanical forces. Research findings from this project will be put into learning modules accessible for young students from K-12 in collaboration with the University of Iowa outreach programs. Research will also be put into undergraduate and graduate biomedical engineering courses, and into a publically accessible and freely downloadable multimedia iBook with live cell imaging and computer simulations.<br/><br/>In vitro time-lapse imaging experiments on keratinocytes and fibroblasts will be used to develop and tune a multi-scale computational model for understanding and predicting how physical forces drive self-structuring and remodeling of EMS in skin. This will be accomplished by: (1) quantifying the effect of substrate stiffness, composition, & loading environment on mechanosensing and the self-assembly process of keratinocytes; (2) developing a mechanistic network-based model of mechanosensing keratinocytes that interfaces with an existent multi-scale model; (3) testing the hypothesis that mechanical crosstalk between keratinocytes and dermal fibroblasts influences self-structuring and EMS formation in an engineered skin system; and (4) extending the cell model to include 3D fibroblast-driven remodeling."
"1463572","The Role of Mechanical Interactions in Tissue Formation and Body Axis Specification","CMMI","Biomechanics & Mechanobiology","06/01/2015","04/02/2015","Eva-Maria Collins","CA","University of California-San Diego","Standard Grant","Michele Grimm","12/31/2018","$414,575.00","","emscollins@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","ENG","7479","024E, 027E, 028E, 036E, 1057, 8086, CVIS","$0.00","Despite their remarkable diversity, all animals begin as a single, fertilized egg. How patterns are established from an initially near uniform system, the egg, is a fundamental question in biology. Mechanical interactions between cells and their environment are thought to play an important role in tissue and axis formation, but this has been difficult to dissect experimentally because of the complexity of developing embryos. The award will investigate the role of mechanical forces in the formation of body form of the Hydra from a solution of separated cells. How the tension at the cell surface and the stiffness of layers of tissue fibers that the cells secrete change how  the animal structure develops also will be measured.  This award supports fundamental research aimed at studying a simple animal that can regenerate its body after dissociation into individual cells. The core mechanical mechanisms of cell-cell interactions during body plan development are universal during early development.  Understanding how these mechanisms work in a simple organism will lead to insight into these mechanisms in more complex beings. This research may reveal general guiding principles for tissue assembly and organ formation and thus has implications for medicine in the context of engineering tissues and organs for transplantation. Understanding how an organism can emerge from an aggregation of cells sparks human imagination. Therefore this project will offer exciting research opportunities for undergraduate and graduate students. The interdisciplinary nature of the project requires the application of tools from physics, biology, engineering, and computer science, and thus will enable students from diverse backgrounds to make significant contributions.<br/><br/>It is experimentally challenging to dissect the mechanical interactions involved in animal development. A novel system which promises to allow such a dissection is the freshwater polyp Hydra, which self-organizes and regenerates after dissociation into a suspension of single cells. Because of this remarkable ability and its structural simplicity, regenerating Hydra aggregates are fully accessible to quantitative measurements and controlled perturbations while providing an in vivo environment that makes the measurements meaningful. This research will elucidate how tissue formation occurs from a cell suspension and determine the mechanisms that lead to body axis specification. For both processes, the research team will apply a multiscale approach from the molecular to the organismal level and test the importance of mechanical interactions using physical measurements, chemical manipulations, visualization of gene expression using transgenic animals and immunohistochemistry, and fluorescent time-lapse microscopy. This study will provide insight into how macroscopic organism-level patterning emerges from interactions on the cellular level."
"1351561","CAREER: Multiferroic Materials - Predictive Modeling, Multiscale Analysis, and Optimal Design","CMMI","Mechanics of Materials and Str","09/01/2014","02/04/2014","Liping Liu","NJ","Rutgers University New Brunswick","Standard Grant","Siddiq Qidwai","08/31/2019","$411,723.00","","liu.liping@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","ENG","1630","022E, 024E, 027E, 1045, 8086","$0.00","The research objective of this Faculty Early Career Development (CAREER) Program award is to establish a fundamental understanding of the mechanics and mathematics that dictates the physical behaviors of multiferroic crystals and composites, to predict and optimize the performance of existing and new multiferroic devices, and to validate the theoretical predictions and designs by experiments. By the method of Gamma convergence and homogenization analysis, the theoretical approach starts from the fundamental principles of thermodynamics, electrodynamics, frame indifference and material symmetries toward a hierarchy of self-consistent nonlinear theories for multiferroic bodies in a variety of physical and geometric limits. Based on the finite element method and multi-level-set gradient method, the numerical approach furnishes computational models and algorithms for predicting and optimizing desired properties of multiferroic materials. Through a collaborative program, the experimental approach provides validation of the predicted properties and optimal designs of multiferroic composites. <br/> <br/>Multiferroic materials can be stimulated by and respond to external magnetic, electric and elastic fields, serve multiple functions, and are broadly used in multi-actuating and multi-sensing systems. The integrated theoretical, numerical and experimental strategy will facilitate the engineering of multiferroic structures and composites with improved functionalities and stimulate the discovery of novel multiferroic materials. These progresses will offer new opportunities in areas of smart materials and intelligent systems. Collaborations with industrial partners will ensure the potential technology transfer. Broader social impact will be achieved by educational and outreach efforts that are closely tied to the research, including research opportunities for under-represented groups, high-school visits, a textbook on elasticity with modern applications in biomechanics and nanomaterials, an interactive visualization demonstrations project on multifunctional materials and optimal designs to enhance students' interest and learning experience, and dissemination of research findings in conferences and public seminars."
"1351875","CAREER: Flexoelectricity of Nanomaterials on Deformable Substrates","CMMI","Mechanics of Materials and Str","02/01/2014","01/27/2014","Nanshu Lu","TX","University of Texas at Austin","Standard Grant","Siddiq Qidwai","01/31/2019","$400,982.00","","nanshulu@utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","ENG","1630","022E, 024E, 027E, 1045, 8086, 9102","$0.00","The research objective of this Faculty Early Career Development (CAREER) Program award is to test the hypothesis that the flexoelectric response can be enhanced by controlling the morphology, the size, and the substrate-induced buckling of inorganic nanomaterials including two-dimensional (2D) atomic layers. In contrast to piezoelectricity, which describes electrical polarization induced by uniform mechanical deformation, electrical polarization induced by strain gradients known as flexoelectricity has long been overlooked due to its relative weakness in bulk ceramics which will rupture before large strain gradients are achieved. Nanomaterials, on the other hand, can survive orders of magnitude higher strain gradient generated by microscale buckling and wrinkling. Recently, enhanced electromechanical coupling at nanoscale has been discovered and was hypothetically attributed to flexoelectricity without direct experimental evidence. The project will be carried by combining experiments with modeling and simulations in four research thrusts: i) flexoelectric response of barium titanate (BaTiO3) nanowires, nanoribbons and nanomembranes on deformable substrates, ii) electromechanical coupling in atomically thin hexagonal boron nitride (h-BN) and molybdenum disulfide (MoS2) supported by deformable substrates, iii) failure mechanisms and fracture mechanics of flexoelectric nanomaterials on deformable substrates, and iv) scaled flexoelectric response by nacre-inspired multilayer stacking. <br/><br/>This research will enable rationalized design, optimization and scaleup of sensors, actuators and energy harvesters based on the principle of flexoelectricity. A central goal of this program is to promote interdisciplinary research and teaching and to expose underrepresented groups to cutting edge interdisciplinary research. The PI will initiate a school-wide interdisciplinary course on ""Mechanics and Materials of Flexible and Stretchable Electronics"". The PI will provide interdisciplinary research opportunities specifically designed for undergraduate and high-school students from minority institutes through the connections established by the Engineering Research Center (ERC) - Nanomanufacturing Systems for Mobile Computing and Mobile Energy Technologies (NASCENT) and the Women in Engineering Program (WEP) at the University of Texas at Austin. The PI and the students will also prepare demos of wearable stretchable electronics and generators for lab open houses and for university-wide outreach activities. The PI plans to distribute both her research and education outcomes globally via publications, conferences, and online Journal Clubs and videos."
"1351705","CAREER:  Systematic Understanding and Control of the Mechanical Properties of Functionalized Nanoporous Metals","CMMI","Mechanics of Materials and Str","07/01/2014","05/22/2018","Antonia Antoniou","GA","Georgia Tech Research Corporation","Standard Grant","Siddiq Qidwai","06/30/2019","$408,000.00","","antonia.antoniou@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","1630","022E, 024E, 027E, 1045, 116E, 8086, 9102, 9178, 9231, 9251","$0.00","The objective of this Faculty Early Career Development (CAREER) Program grant is to uncover physical mechanisms governing the mechanical properties of nanoporous materials for hierarchical structures where struts and joints are complex. Nanoporous metals can be thought of as a three-dimensional interconnected network of struts and joints with typical size in the range 10-100 nm. These materials possess high surface-to-volume ratios, electrical conductivity, catalytic activity, and strength. They have shown great promise in many applications, for example as high-performance catalysts or electrodes for fuel cells and batteries. The ability to design nanoporous metals with enhanced mechanical properties is crucial for all applications, yet fundamental understanding of how their internal structure influences macroscopic properties is still lacking, especially for hierarchical structures where struts and joints are themselves complex (e.g. are nanocrystalline). This project aims to uncover physical mechanisms governing the mechanical properties of such structures. This will be achieved through a comprehensive experimental campaign utilizing in-situ deformation experiments across different scales. The effects of the nanoporous metal geometrical structure will be investigated with the aid of analytical and numerical models, as well as by conducting experiments on scaled-up structures.<br/><br/>The project will generate crucial insights into the deformation mechanisms governing mechanical properties of hierarchical nanoporous metals, thus providing a basic scientific knowledge necessary for controlling and optimizing their properties and bringing closer wider adaptation of this class of materials. Research activities are closely integrated with education and outreach efforts: both graduate and undergraduate students will work on the project, thus gaining cutting-edge skills and expertise in nanotechnology and science; the PI will work with high school teachers and students in the Atlanta area through Georgia Intern Fellowship for Teachers program and through Georgia Tech's Women in Engineering summer camps; some of the results will be introduced in engineering courses at Georgia Tech as case studies; the PI will participate in Tech to Teaching program that inspires students to choose a teaching career."
"1430996","SBIR Phase II:  A Multimodal Sensor Platform for Automated Detection and Classification of Pest Insects","IIP","SMALL BUSINESS PHASE II","10/01/2014","12/10/2016","Johnny Park","IN","Spensa Technologies Inc.","Standard Grant","Muralidharan S. Nair","03/31/2019","$1,277,246.00","","johnny.park@spensatech.com","1281 Win Hentschel Blvd","West Lafayette","IN","479064182","7655883592","ENG","5373","116E, 1185, 165E, 169E, 5225, 5373, 6840, 8034, 8035, 8240, 9139, 9231, 9251, HPCC","$0.00","The broader impact/commercial potential of this project is significant. The proposed technology could drastically improve the overall effectiveness of pest management programs in various agricultural industries. The proposed system not only eliminates one of the most laborious and dreaded activities of manually inspecting insect traps, but also provides unprecedented access to accurate, real-time insect population information to make more effective pest management decisions. This leads to reduced, spatially-restricted pesticide applications, better understanding of insect pest behaviors, and enhanced biological control. The automated trap?s ability to monitor more than one species of insect not only achieves a higher level of efficiency in pest monitoring but also multiplies the technology?s value to the end users. The potential market for the proposed technology is quite broad. In fact, the technology can benefit any industry that requires regular monitoring of insect populations. Furthermore, the proposed technology could be used for various state and federal pest monitoring programs, such as the Slow the Spread (STS) Project administered by USDA to monitor gypsy moths.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project proposes to develop a multi-modal sensor platform for robust detection and classification of multiple insect pest species for automated monitoring of insect populations in production agriculture. The main goal of this project is two-fold: First is to demonstrate that bio-impedance sensor alone provides useful data to classify multiple insect species. A linear support vector machine classifier using mel-frequency cepstral coefficients extracted from bio-impedance data will be implemented on an embedded platform for detection and classification of two insect pest species. These bio-impedance based electronic traps will undergo large-scale field trials and be prepared for full commercialization. The second objective is to develop a multi-modal electronic trap with ultrasound, infrared and bio-impedance sensors that can simultaneously monitor four or more insect pest species. Measurement signals generated by the sensors will be analyzed to determine a set distinct features that can be computed on an embedded platform for real-time processing. These features will then be used in multi-modal sensor fusion algorithms for robust detection and classification. Different sensor fusion strategies will be investigated and the performance of each fusion algorithm will be evaluated both in controlled and field conditions."
"1553212","CAREER: Role of Symmetry in the Properties of Nanostructures:  A First Principles Approach","CMMI","CAREER: FACULTY EARLY CAR DEV, Mechanics of Materials and Str","08/01/2016","01/08/2016","Phanish Suryanarayana","GA","Georgia Tech Research Corporation","Standard Grant","Siddiq Qidwai","07/31/2021","$500,000.00","","phanish.suryanarayana@ce.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","1045, 1630","022E, 024E, 027E, 1045, 1630, 8086, 9263","$0.00","This Faculty Early Career Development (CAREER) program will develop an inexpensive high-fidelity computational framework for the accelerated discovery of nanostructures with unprecedented properties that can be tailored to technological applications. Nanostructures can be defined as structures which possess at least one dimension in the nanometer range. The remarkable properties displayed by such systems have resulted in the revolutionary field of nanotechnology, whose potential applications include the efficient production and storage of renewable energy; diagnosis and cure of terminal illnesses; effective purification processes; and synthesis of new materials with high strength to weight ratio. The capability to design nanostructures with enhanced properties that are well suited to such applications is of particular importance. However, the astronomically large number of nanostructure configurations and compositions makes a systematic search impractical. Therefore, current experimental and computational techniques typically rely on empirical insight, which makes the process lengthy, expensive and susceptible to failure. The integrated educational objective is to incorporate multi-disciplinary nanoscience/nanotechnology related curriculum into the K-12, undergraduate and graduate education. <br/><br/>The symmetry of nanostructures, either intact or broken, plays a key role in determining their extraordinary properties. Towards the goal of understanding and utilizing this dependence, a novel real-space, symmetry-adapted formulation and massively parallel implementation of ab-initio Density Functional Theory will be developed. The compatibility of this formulation with all the symmetry groups will result in a tremendous reduction in the computational cost, thereby enabling the accurate characterization of nanostructures that are three orders of magnitude larger in size than those currently feasible. Additionally, the developed formulation will enable the systematic discovery of new nanostructures with esoteric properties by allowing for an efficient parametrization of the configurational space of nanostructures using symmetry. The applications to be studied include nanoscale flexoelectricity, which will provide new understanding into the nature and strength of the coupling between polarization and strain gradients; phase transformation of the tail sheath in the bacteriophage T4 virus, which will provide significant insights into the structure and creation of viruses; and search for new nanostructures that display unique phenomena by virtue of a linear dispersion relation. Overall, the proposed research represents a paradigm shift from the conventional view that crystal unit cells with translational symmetry are the fundamental building blocks."
"1660022","SBIR Phase II:  A Robust State Estimator For Power Grids","IIP","SMALL BUSINESS PHASE II","03/15/2017","04/19/2018","Bei Gou","TX","Smart Electric Grid, LLC","Standard Grant","Muralidharan S. Nair","08/31/2019","$880,895.00","","bgou@smart-elecgrid.com","3009 St Martin Dr","Mansfield","TX","760634883","6824788897","ENG","5373","169E, 4080, 5373, 6840, 8035, HPCC","$0.00","The broader impact/commercial potential of this project include 1) the targeted problem (power system state estimator) is extremely critical in modern power grids or smart grids which may help prevent system-wide failures or blackouts if properly handled, 2) the certainty of commercialization of the proposed approach warranting significant NSF support because the provided solution is fast enough for real-time application and the new state estimator does not ask for additional inputs or requirements compared with existing solutions, 3) the research team is formed by technical as well as marketing personnel which ensures the success of the sales of the products, 4) the uniqueness of the proposed approach which provides competitive benefits to the market that cannot be met by alternate technologies and can attract further funding from non-SBIR sources and result in direct sales to power industry, 5) the proposed approach develops a unique formulation/solution of state estimation which very possibly leads to further innovations, 6) the new procedure of the proposed approach based on unique formulation and unique philosophy can promote teaching, training and learning in the area of state estimation.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project contains intellectual merit that lies in 1) achieving a fast and robust solution to a 40-years' open problem of robustness in power system state estimation, which is a critical and challenging problem, 2) developing a unique formulation of state estimation which easily prevents robust problems suffered by the existing approaches to state estimation and which provides advanced knowledge and understanding in the area of state estimation, 3) a well-qualified team led by the PI who has research experience in state estimation for more than 15 years and has published actively and widely in state estimation and other related areas, 4) the high originality of the proposed solution which is developed based on a completely different philosophy than the existing ones, and is innovative even in the theory of statistics, 5) reflecting state-of-the-art in the area of power system state estimation ? presently a major research activity, and 6) easy integration of synchronized phasor measurements into the proposed state estimator."
"1331108","SBIR Phase II:  Real-Time Rehab to Improve Gait Symmetry in Amputees","IIP","SMALL BUSINESS PHASE II","09/15/2013","05/19/2017","Stacy Bamberg","UT","VERISTRIDE, Inc.","Standard Grant","Muralidharan S. Nair","05/31/2019","$1,400,498.00","","stacy@veristride.com","615 Arapeen Dr","Salt Lake City","UT","841081254","8015817792","ENG","5373","165E, 169E, 5373, 6840, 8033, 8240, 9139, 9150, HPCC","$0.00","This Small Business Innovation Research (SBIR) Phase II project will advance the technology research and development necessary to bring wireless instrumentation and smartphone technology used for feedback to lower-limb amputees about their real-time performance, for rehabilitation in situ. The intellectual merit of the proposed research lies in the opportunity to transform the field of rehabilitation and to advance healthcare by enabling a fundamental shift toward low cost, ubiquitous rehabilitation that can be used away from the clinic. This proposal will research and develop the pre-market alpha- and beta-prototypes of an instrumented insole, smartphone app, and HIPAA-compliant data transfer and remote server storage and analysis system, as an essential and transformative tool utilized for physical therapy and gait training outside of the clinic. While sensors have become small, inexpensive, and highly available, many research lab applications are limited to proof-of-concept evaluations that involve tethered systems and/or post-processing of the data. This research quantifies the effect of this low-cost, personalized, wireless assistive technology that can be used away from the clinic. Ultimately, this work lays a foundation for more complex rehab feedback systems, e.g. using a smartphone to detect gait and provide feedback to an orthotic or prosthetic for muscle stimulation.<br/><br/>The broader impact/commercial potential of this project includes the focus on mobility limitations in persons with lower-limb amputations, which affect twice as many minorities as Caucasians. The commercial potential of this wireless assistive technology is vast: with diabetes as the major contributor to amputations, the number of amputees is forecast to triple to 3.6 million by 2050. The knowledge gained can be expanded to impact individuals with a wide variety of mobility limitations, e.g. stroke, Parkinson's disease, multiple sclerosis, cerebral palsy, etc. The orthopedic market ? 773,000 total hip/knee replacements performed annually in U.S. ? is also commercially relevant, as patients must affect an asymmetric gait following fracture repair or joint replacement to reduce weight-bearing on the healing limb. Another significant group are athletes seeking to improve performance or recover from injury through precision gait analysis and real-time feedback. In this Phase II proposal, this research will quantify the effect of this wireless assistive technology by enabling persons with amputations to use individualized proprioceptive feedback and to participate in the design of the personalized feedback methods. This work will enable a wealth of information collected away from the clinic, including a way to investigate how and whether patients follow treatment protocols."
"1660175","SBIR Phase II:  Neural Algorithms for Multimodal Sensory Analysis","IIP","SMALL BUSINESS PHASE II","04/01/2017","11/06/2017","Andrew Nere","WI","Thalchemy Corp","Standard Grant","Muralidharan S. Nair","03/31/2019","$744,381.00","","nere@thalchemy.com","1605, Monroe Street, Suite B","Madison","WI","537112021","6083359862","ENG","5373","5373, 6840, 8034, 8035, 8042, 8240, HPCC","$0.00","The broader impact/commercial potential of this project is to enable continuous sensing applications in a wide range of energy-constrained sensor-enabled devices. Without dramatic innovations in the development of ultralow power sensory processing, continuous and accurate sensing will remain a niche application limited to environments with a stable and plentiful power source and significant computing resources. The technology described in this proposal will demonstrate the viability and potential widespread deployment of continuous sensing devices in mobile or remote environments with strict energy constraints. An important immediate market for the proposed technology with significant customer base is the smartphone and wearables market, where many new and emerging end user applications could leverage environmental sensing to trigger context-based and anticipatory actions. The proposed technology is broadly applicable to a number of other markets and domains, including medical, health, and safety monitoring of critical patient sensors, personal fitness devices, military applications, and environmental monitors. The ability to flexibly deploy continuous sensing for these and other applications has the potential to revolutionize these markets and create entirely new and unforeseen application domains. <br/> <br/>This Small Business Innovation Research Phase 2 Project plans to research and develop algorithms based on the properties of biological spiking neurons and the sensory processing capabilities of the human brain. The human brain is truly unique in its ability to use a basic computational element, the spiking neuron, and perform a broad variety of tasks. The brain has the ability to accurately classify sensory patterns from multiple modalities (touch, sight, etc.), to interpret the outside world, and to recognize the current context. A key intellectual merit of this project is a demonstration of how these novel neural algorithms can perform accurate, robust, and low power sensory analysis across multiple sensory domains. Just as the brain is capable of processing data from very different sensors. Researching and developing these neural algorithms will provide insight as to how the human brain learns to recognize important sensory information, how it is able to integrate information from such different sense modalities, and how it is able to perform complex analysis so efficiently."
"1660096","SBIR Phase II:  Kaiser Trigger: A Nano-Watt Powered Technology for Ultra-Low Power Fatigue Crack Detection","IIP","SMALL BUSINESS PHASE II","03/01/2017","02/24/2017","Mehdi Khandani","MD","Resensys, LLC","Standard Grant","Muralidharan S. Nair","02/28/2019","$749,016.00","","mehdi@resensys.com","387 Technology Dr.","College Park","MD","207420001","3013953892","ENG","5373","1185, 5373, 6840, 8035, HPCC","$0.00","The broader impact/commercial potential of this project is the result of introducing a new generation of low-power wireless sensors for detecting Acoustic Emission events and detecting fatigue damage in structures. According to the Federal Highway Administration (FHWA), the US transportation infrastructure has 605,102 operational bridges, of which 66,561 are structurally deficient. In particular, the fatigue damage monitoring technology of the project will initially target the more than 18,000 US highway bridges that are categorized as ?fracture critical? by the Federal Highway Administration. The technique?s ultra-low energy consumption will enable its use in low-power wireless sensors and make it an ideal response to this challenging problem. The anticipated benefits and commercial applications of this project are (1) a low-cost, easy-to-use mechanism for effective monitoring, allowing for early detection and timely repair of fracture and fatigue damage in infrastructure systems such as highway bridges; (2) improved public safety, with reduced maintenance costs and extension of the service life of critical and high-valued infrastructure systems; and (3) additional commercial applications in monitoring the structural health and integrity of other structures, including aircraft, oil and gas pipelines, machinery, cargo cranes, ships, etc.<br/><br/>Small Business Innovation Research (SBIR) Phase 2 project addresses distributed structural health monitoring (SHM) of infrastructure systems, particularly highway bridges. Because the creation of fatigue cracks in a structure is accompanied by the propagation of acoustic emission (AE) waves, wireless AE sensors can be used to detect such cracks. However, a challenge of AE detection sensors is high energy consumption, significantly more than the energy available in a battery-operated wireless device. As a result, conventional AE detection methods cannot be used with low-power wireless sensors. This project uses a novel and ultra-low power technique for long term monitoring of strain.  Then, AE monitoring is activated only if history of tensile strain in the structure under monitoring suggests likelihood of fatigue damage. In addition, using history and pattern of AE events, the method estimates the severity of fatigue damage in a material. Moreover, the method uses a variety of techniques to eliminate the effects of mechanical noise on AE measurements and achieve a high reliability in fatigue damage assessment. After development, the method is planned to be evaluated on highway bridges, airframes, and pipelines."
"1660233","SBIR Phase II:  Multiplexed Smartphone-Based Handheld Sensor for Ion Contaminants Detection in Environmental Water","IIP","SMALL BUSINESS PHASE II","03/15/2017","03/17/2017","Logan Liu","CA","MOBOSENSE LLC","Standard Grant","Muralidharan S. Nair","02/28/2019","$717,250.00","","mobosens@gmail.com","172 Corliss Dr.","Moraga","CA","945561206","5106847629","ENG","5373","1185, 5373, 6840, 8035","$0.00","The broader impact/commercial potential of this project is the potential dollars saved in healthcare costs to environmental protection. The greatest overall savings cannot be judged only in dollars, but in helping to preserve human lives and end diseases and illnesses caused by problems with water. The product will provide unique opportunity to populations to test their water for safety and health benefits, in locations where good water treatment facilities do not exist. The water testing equipment market is divided into low-end, low-cost on-field test equipment (such as nitrate strip) that gives qualitative information about the analytes, and high-end testing devices used in labs (such as mass spectrometer) providing accurate quantitative information. If successful, the sensor technology will bridge the gap by providing low-cost, sensitive, accurate tools for quantitative measurement of analytes. The portable, low-cost, plug and play sensor product will cater to the needs of the water quality monitoring market. The product will also mobilize ?citizen scientist? to partake in environmental data collection and popularize sustainability education.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project is expected to lead to the development of a multiplexed, low-cost, portable instrument capable of making real time measurements of nitrate and phosphate in water and soil samples. The sensor system for this instrument will be based on the highly selective nitrate and phosphate reducing working electrodes along with reagents contained in the microfluidics to perform real-time sensing without sample preparation. As the concentrations of phosphate in solution are usually small, and since the inorganic phosphate in a water sample is changing due to biological processes, time is often a critical factor in taking measurements of phosphate. Due to these factors, there is a need for sensitive, inexpensive, and portable instruments in order to monitor the eutrophication process effectively. Currently available instruments for making phosphate measurements in the field do not adequately address these needs. Phase I development showed that disposable electrode with microfluidic integration, and smartphone app controlled sensor is capable of detecting nitrate with high sensitivity and specificity. Phase II proposal is focused on commercialization of the nitrate sensor and development of multiplexed sensor platform to detect multiple ions such as nitrate, and phosphate for larger commercial market."
"1660235","SBIR Phase II:  Quasi-Active Prosthetic Ankle System:  Dynamic Angle and Stiffness Optimizations for Multiple Gait Activities","IIP","SMALL BUSINESS PHASE II","03/01/2017","02/24/2017","Jeffrey Ward","AZ","SpringActive, Inc.","Standard Grant","Muralidharan S. Nair","02/28/2019","$749,986.00","","jeff.ward@springactive.com","2414 W 12th Street, Ste. 4","Tempe","AZ","852816955","4807043592","ENG","5373","5373, 6840, 8035, 9139, HPCC","$0.00","The broader impact/commercial potential of this project is that the proposed system will enhance the ability of the 1.3 million people currently living in the United States with a lower limb amputation to walk in unconstrained environments.  The proposed Quasi-Active Prosthetic Ankle System (QPAS) addresses the RH6: Human Assistive Technologies area.  QPAS will be lightweight, have a long battery life, and optimize the passive dynamics of amputee gait in unconstrained environments by using battery energy to tune its physical system properties, ankle equilibrium angle and torsional stiffness.  The device provides a unique set of features that do not currently exist in the market, strengthening its value proposition.  The amputee population is growing; 2,000 new lower limb amputation are performed each week.  Therefore, QPAS will have strong market potential and the significant societal impact of improving health by supporting a more active lifestyle for lower limb amputees.  This will also lead to more community and family involvement.  Additionally, because of the many possibilities to control QPAS, gait researchers will be able to study amputee compensation preferences.  A better understanding of the kinematic and kinetic preferences could lead to improvements in the design of purely passive ankle prostheses.  <br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project addresses the needs of lower limb amputees. Lower limb amputees suffer from reduced self-selected walking speed, increased metabolic cost, increased reaction loads on the sound limb, poor gait symmetry, and reduced stability with increased risk of falling.  Passive prosthetic feet are only tuned for level ground walking at one speed.  QPAS will utilize a patented compliant actuator to achieve a unique set of features: passive energy storage with an articulating ankle joint, adaptable ankle angle for slope gait, low electrical energy usage, a large range of ankle motion, adaptable stiffness to optimize variable cadence level ground and slope gait, and controlled energy delivery to ensure energy builds naturally and smoothly.  In this phase 2 SBIR, an intuitive and autonomous controller will be built for the QPAS and human subject evaluations will assist in refining the device towards commercialization. QPAS will become a successful product by focusing on improved amputee gait performance in unconstrained environments, and being simple to fit and adjust, reliable and affordable."
"1430911","SBIR Phase II:  A Highly Efficient GridBridge Grid Energy Router for Grid Modernization","IIP","SMALL BUSINESS PHASE II","09/01/2014","04/05/2018","Chad Eckhardt","NC","GridBridge, Inc","Standard Grant","Muralidharan S. Nair","02/28/2019","$1,639,703.00","","chad@grid-bridge.com","1009 Capability Drive, Suite 200","Raleigh","NC","276063901","9194139898","ENG","5373","116E, 164E, 165E, 168E, 169E, 5373, 6840, 8034, 8035, 9139, 9231, 9251, HPCC","$0.00","The broader impact/commercial potential of this project is the development of a cornerstone for reliable electricity and a modernized grid able to evolve alongside emerging customer demands. Reliable electricity is key component of an industrialized market, critical for the information age, and an enabler for non-industrialized regions evolution and eventual world economic contribution.  The societal benefit therefore of GridBridge's commercially feasible Grid Energy Router is colossal, as it is the step-function change required to truly orchestrate a grid to match this era.  This project will enable numerous hindered technologies and scientific understanding related to energy storage, photovoltaic and other renewable generation, as well as electric vehicles and their correlated fast chargers.  Energy savings are also a monumental aspect and are expected to be in the trillions of dollars.  Society needs electricity to maintain civilization and an updated grid is imperative for supplying that electricity to an evolved consumer base.  GridBridge?s Grid Energy Router will be the crucial component for the modernized grid an enabler for numerous complementary technologies.  GridBridge's GER will eventually replace millions of installed legacy grid technologies throughout the world.  Furthermore, the continued GridBridge-ERC relationship establishes FREEDM ERC's commercialization ecosystem, which includes 200 diverse students.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project combines various research aspects to commercialize the company?s third breakthrough product for electric utilities, the Grid Energy Router (GER).  GridBridge?s Grid Energy Router will be cornerstone for an evolved grid that can integrate renewables and storage, offer dynamic efficiency gains, and intelligently route power.  Although there has been early work with power electronics merely focusing in the area of high-voltage conversion, the approaches thus far limit commercialization and manufacturability.  GridBridge will combine over three years of company market research and utility voice of the customer, a unique product roadmap, and cutting edge research in the areas of feature implementation and voltage conversion.  Keeping in mind the end market, electric utility requirements have been incorporated: highly efficient, cost-competitive, manufacturable within a specific market window, and scalable both to high power and high voltage.  This project facilitates a cost-effective and electrically-efficient product design ready for industrialization and ultimately grid integration, while simultaneously incorporating valuable features that justify utility expenditure and meet a market window of need."
"1758598","SBIR Phase II:  Developing the Standalone Tongue Drive System","IIP","SMALL BUSINESS PHASE II","04/01/2018","04/04/2018","Jill Kolczynski","GA","Bionic Sciences, Inc.","Standard Grant","Muralidharan S. Nair","03/31/2020","$694,524.00","","jkolczynski@bionicsciences.com","1061 MERCER ST SE","Atlanta","GA","303162496","6056446826","ENG","5373","5373, 6840, 8034, 8035, HPCC","$0.00","The broader impact/commercial potential of this project centers on bringing enhanced independence, productivity, and quality of life for hundreds of thousands of individuals in the US who live with severe physical disability due to spinal cord injury or other debilitating neurodegenerative disorders, such as amyotrophic lateral sclerosis (ALS). Due to improvements in emergency medicine and increasing average age, these individuals represent a growing population that is underserved by current assistive technologies (ATs). The ATs being relied upon to carry out basic tasks are still primitive, offer limited versatility, and fail to meet end-user needs. Meanwhile, computers and internet play ever-growing roles in everyday life and are regarded as equalizers that allow individuals to have similar vocational, recreational, and educational opportunities. The Tongue Drive System (TDS) offers individuals with severe physical disabilities an intuitive and superior mechanism for accessing computer-based resources, wheelchairs, smartphones, smart homes, etc. TDS harnesses the power of the human tongue, which often retains full capability in these individuals despite losses of other functions, to drive human-computer interactions. TDS has the potential to revolutionize the current AT market in the US and around the world with an anticipated market size of $1B within its primary market segment.<br/><br/>This Small Business Innovation Research (SBIR) Phase-II project aims to bring this transformative and game-changing AT to market by continuing the design, development, evaluation, and expansion of a robust, reliable, and real-time TDS ecosystem. In Phase-I, the TDS hardware was redesigned and consolidated so that all signal processing functions were self-contained into a new standalone TDS (sTDS) headset system with a dual-band wireless link that can directly interface with a target peripheral by transmitting formatted user-defined commands. In Phase-II the designs for a solid and intuitive user interface, a smartphone app, and a robust and rugged powered wheelchair interface module to effectively control key target devices will be fine-tuned in the final stages of development in preparation for launch. The sTDS hardware/software/enclosure will also be tested and ready for manufacturing and meet the FDA regulatory requirements towards submission of a 510(k) premarket notification.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1632136","SBIR Phase II:  Interference Mitigation for Broadband Wireless Backhaul Systems","IIP","SMALL BUSINESS PHASE II","09/01/2016","01/08/2018","Joshua Lala","LA","Bascom Hunter Technologies","Standard Grant","Muralidharan S. Nair","02/28/2019","$881,106.00","","lala@bascomhunter.com","7117 Florida Boulevard","Baton Rouge","LA","708064549","2258027131","ENG","5373","169E, 4096, 5373, 6840, 8035, 8240, 9150, HPCC","$0.00","The broader impact/commercial potential of this project is to enable wireless industry carriers and equipment providers with an affordable technology solution to meet the continuing explosive societal/customer demands for data access. The telecommunication market sector has been increasingly consolidating to Asia and Europe where foreign governments are making strategic investments to encourage work in their respective countries. In a long-term, the proposed interference elimination technology can lead to increased investment in the telecom equipment sector and efficient use of the finite radio frequency (RF) spectrum in the United States.   The expected technical and commercial outcome from the project is an active interference mitigation capability with product features including a significantly improved quality of service, simplified network equipment design and installation, and reduced requirements for many components such as antenna and filters. This in turn will reduce the overall cost per data link, as well as reducing the size, weight, and power requirements of the system. <br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project addresses the critical need for disruptive RF interference mitigation solutions. As networks are moving toward higher performance to accommodate larger capacity than ever seen before, the network operators, industry organizations, and equipment providers are looking into innovative technologies for next generation 5G wireless networks.  There are two advantages offered by the proposed interference elimination technology. One advantage is extreme wide instantaneous bandwidth and the other is flexible tunability over GHz of operating frequency.  These advantages help to consolidate and reduce front-end hardware. The focus of this program will be first on developing an optical system-on-chip version of the interference cancellation system with monolithically photonic integrated circuits. With a complete and fully function development board, the second focus will be on demonstrating the application in in-band interference mitigation for wireless backhaul networks, and showing improvement in 2x spectral efficiency and potential 1000x increase in capacity."
"1721838","SBIR Phase I:  Haptic tactile display","IIP","SMALL BUSINESS PHASE I","07/01/2017","11/27/2017","Romaneh Jalilian","KY","Tactile Analogics LLC","Standard Grant","Muralidharan S. Nair","03/31/2019","$225,000.00","Jovan Rebolledo-Mendez","romaneh_j@yahoo.com","140 E. Maple St.","Glendale","KY","427408737","5024241606","ENG","5371","5371, 6840, 8035, 9150","$0.00","The broader impact/commercial potential of this project consists of providing a new means for visually impaired people to understand information via haptics. In order to accomplish this, the company is creating micro actuators and refreshing displays that will permit the blind to understand visual information quickly.  One major potential societal benefit will be directly related to visually impaired people and blind, who have a marked difficulty in learning geometry, algebra and calculus, and other visual disciplines.  Tactile Analogics? devices are intended to help them to understand such concepts by representing shapes/ forms in a fast-refreshing tactile way, helping to overcome that learning obstacle. Furthermore, the commercial success will be in producing and selling such devices (for different market sub-segments).  Tactile Analogics expects market adoption of 37% of USA blind students, 90% of blind educational centers, 40% of museums, and 7% of blind adults to use it in as a working tool. In collaboration with Sharp, Tactile Analogics will explore also a functional digital display with micro-valves embedded, the market will widen to give haptics experience to mobile users in a 2-sense data outputs via sight and tactile means. The company expects to generate revenues of over $200m after year five of production.  <br/> <br/><br/>This Small Business Innovation Research (SBIR) Phase I project is attacking the problem that visually impaired people have to not just learn, but to understand images and visual information, with impacts on their quality of daily life.  Current cost of producing a single pinned printed page is about $20 USD per page and takes about 2 weeks to prepare and print.  Tactile Analogics? devices will offer a rapid fast-refreshing speed of up to 30 times per second, allowing the creation of frames according to the image that they are representing.  This solution will enable blind to not depend on pinned paper to understand images or shapes. In general, this is a haptic way to retrieve information and technically not limited to blind people.  The opportunity is related with providing a new type of information retrieval where sight is not needed.  The research objectives are to overcome design problems of our proven technology of micro-valves, where Tactile Analogics would be able to offer a standard tablet-size display for an area of 15cm by 20cm (2700 pneumatic valves).  Furthermore, the air chamber and the information conversion-actuator manipulation are two other problems to overcome.  The anticipated results are the allocation of not just the 2700 pneumatic micro-valves, but also even for larger displays.  Once the technology is proven, it will allow a variety of applications across multiple industries, with the possibility of creating many commercially successful product lines."
"1555928","SBIR Phase II:  Megabit-Per-Second Underwater Wireless Communications","IIP","SMALL BUSINESS PHASE II","04/15/2016","02/23/2018","Thomas Riedl","IL","OceanComm Incorporated","Standard Grant","Muralidharan S. Nair","06/30/2019","$920,187.00","","triedl@oceancomm.co","60 Hazelwood Drive","CHAMPAIGN","IL","618200000","2178191322","ENG","5373","116E, 1367, 169E, 4096, 5373, 6840, 8035, 9139, 9231, 9251, HPCC","$0.00","The broader impact/commercial potential of this project is the introduction of high-speed<br/>wireless modems usable subsea and significant cost reduction of deep-water operations ?<br/>industry experts estimate savings of nearly 20% of deep-water operations through the<br/>availability of subsea WiFi. Today, there is no broadband wireless communication available<br/>underwater. In the deep ocean, remotely operated vehicles (ROVs) require a tether for<br/>communication and a support ship for tether management; sensors and systems must either be<br/>physically connected, or retrieved from the deep sea to exchange data. An ROV support ship<br/>costs about $120k/day leading to over $7B spent on ROV support ships in 2013. The proposed<br/>megabit-per-second technology would allow ROV manufacturers and operators to cut the<br/>tether on many of their vehicles. Wireless ROVs can move unencumbered throughout coverage<br/>area, piloted from anywhere (e.g. from Houston), without expensive surface vessels. The<br/>proposed wireless modem technology connects ROVs and machinery to wired infrastructure,<br/>enabling safe operation of heavy subsea machinery without the possibility of cables or tethers<br/>getting tangled, causing damage or worse. This project will create 10 new jobs in the next three<br/>years, with many more to be added as the production scales.<br/><br/>This Small Business Innovation Research (SBIR) Phase 2 project proposes to develop a faster<br/>and more reliable wireless communication system for the sub-sea industry. Current state of the<br/>art communication links for the deep ocean are either tethered, requiring long, bulky, and<br/>expensive cables to connect machinery and systems, or have extremely low data rates, enabling only <br/>the most rudimentary of tasks. The proposed underwater wireless communication<br/>system will provide WiFi-like data rates in the Mbps (megabits/sec) range ? 100 to 1,000 times<br/>faster than existing underwater wireless communication technologies - and enable video<br/>streaming and real-time control of subsea infrastructure, machinery, and mobile underwater<br/>vehicles. Since radio signals do not propagate far underwater, the proposed technology uses<br/>sound waves, as whales and dolphins do, for communication. The speed of sound is 200,000<br/>times slower than the speed of radio propagation, and mobile acoustic transmitters and<br/>receivers hence suffer from severe Doppler distortion. The proposed technology dynamically<br/>measures, tracks, and compensates for this distortion, to enable wireless communication at<br/>data rates never before possible underwater."
"1534010","STTR Phase II:  An Assistive Tool to Locate People and Objects with a Multimodal Thermogram Interface","IIP","STTR PHASE II","09/15/2015","11/07/2017","Brian Hanzal","MN","Moai Technologies L.L.C.","Standard Grant","Muralidharan S. Nair","02/28/2019","$890,856.00","Nicholas Giudice","moaitechnologies@gmail.com","18215 45th Ave N","Plymouth","MN","554464595","6124818723","ENG","1591","1591, 169E, 6840, 8035, 9139, HPCC","$0.00","The broader impact/commercial potential of this project is the assistive use by blind people of thermal imaging. The resulting product provides a person who is blind or visually impaired with the relevant information about the layout of an unfamiliar public space in order to assist blind users in everyday activities. Thermal imaging can differentiate people and objects from their background without the need for complex image analysis. The shape and the temperature of the human body allows the location of people to be easily determined. The societal impact will be assisting users in navigation of complex public spaces. A blind person can use a smartphone?s haptic touchscreen display to examine the thermal image to determine the location of people in front of them. Information about the layout of an unfamiliar public space can be learned from the heat and shape of materials. Examples would be locating vending machines like ATMs and train passes. The market sector for this technology will likely extend beyond assisting blind users, to include additional commercial opportunities as well.<br/><br/>This Small Business Technology Transfer Research (STTR) Phase 2 project will leverage past National Science Foundation Funded research to develop a product that a blind/low vision user can use to receive practical navigation and interaction information about their environment from a multimodal thermogram (thermal image) interface on a smartphone. There are no practical assistive technologies for blind or low vision users that allow them to locate people, objects, and the layout information of their surroundings other than exploring with a cane. This development will address the objective of creating an interface that provides both practical utility and will be accepted by the target demographic of blind users. This project represents an excellent translational path from NSF-sponsored research programs to a product that is built from the ground up on solid theoretical underpinnings and empirical findings from multimodal human information processing. This development will use thermal radiation from people, machines, lighting and heat retention differences in building materials and convert this data into a user interface to facilitate blind navigation and environment interaction. The product resulting will be a multimodal (kinesthetic, vibro-tactile, and auditory) interface for blind users of a smartphone to interpret and gain useful value from thermal image information."
"1254999","CAREER: Titanium Microelectromechanical Systems: Strength and Strengthenability","CMMI","MATERIALS AND SURFACE ENG","01/01/2013","12/18/2012","Masaru Rao","CA","University of California-Riverside","Standard Grant","Thomas F. Kuech","12/31/2018","$400,000.00","","mprao@engr.ucr.edu","Research & Economic Development","RIVERSIDE","CA","925210217","9518275535","ENG","1633","022E, 024E, 027E, 1045, 1444, 8021, 8086","$0.00","The research objectives of this Faculty Early Career Development (CAREER) Program award are: 1) to advance fundamental understanding of size-dependent plasticity in titanium-based microelectromechanical systems (Ti MEMS); and 2) to develop means for strengthening Ti MEMS in situ, after they have been fabricated. The former is motivated by the importance of such understanding in establishing guidelines for reliable design, while the latter is motivated by the limited material selection capability and poor fabrication process versatility in MEMS. To achieve the first objective, mechanical testing will be used to characterize deformation response of micromechanical structures produced using recently-developed techniques for deep reactive ion etching of Ti. To achieve the second, diffusional alloying will be used to strengthen Ti MEMS with interstitial nitrogen solute. Understanding gained in these studies will help elucidate mechanisms underlying size-dependent strength in Ti, as well as foster development of new technological capabilities with direct relevance to both conventional MEMS and emerging biomedical microdevice applications.<br/><br/>Research, teaching, and outreach efforts will be integrated to help inspire and prepare the next generation of scientists and engineers, as well as engage a local community that is rich in ethnic and socioeconomic diversity, but not well-represented in higher education. These efforts will also help support continued growth and diversification of the U.S. science and engineering (S&E) enterprise, and will leverage a new partnership with the California Science Project, a statewide network focused on enhancing science instruction. Specific activities to be undertaken will include those focused on: 1) supporting diversity in S&E higher education; 2) inspiring interest in advanced S&E studies; and 3) promoting K-12 S&E interest and awareness."
