"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1717324","RI: Small: General Intelligence through Algorithm Invention and Selection","IIS","ROBUST INTELLIGENCE","09/01/2017","07/25/2017","Julian Togelius","NY","New York University","Standard Grant","James Donlon","08/31/2020","$427,000.00","Andrew Nealen","julian.togelius@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7495","7495, 7923","$0.00","Creating better artificial intelligence has plenty of applications in different areas of society, from self-driving cars and aircraft to production planning, control of machines and music composition. Most current artificial intelligence research focuses on creating algorithms that can only do a single thing, or solve a single problem.  To achieve artificial general intelligence we must learn how to create algorithms that can solve many different problems, without a human having to adjust the algorithm for every problem. The research in this project aims to understand how such artificial general intelligence can be created. The basic idea is to build algorithms that can create their own more specific algorithms, and learn to automatically select the right algorithm for the right problem. In order to develop these algorithms, we need a large set of good problems to test them on. Games are widely used to test AI algorithms, because they model real-world problems but are fast and easy to execute. The general algorithms developed in this project will be tested on a set of classic games, and a real-time strategy game.<br/><br/>This research project aims to investigate how we can create more general artificial intelligence through online stochastic search for algorithms, combined with and informed by online selection among discovered algorithms. In other words, the project will investigate the combination of genetic programming in the space of tree search algorithms with algorithm selection, also called hyper-heuristics, for creating more general problem-solving abilities. These capabilities will be evaluated through a sequence of experiments on two different test beds.  Successful completion of the research will clarify the potential of search in algorithm space as a method for creating more general artificial intelligence, and produce a number of algorithms. This includes both the algorithms that will be designed for searching for algorithms and searching among algorithms, as well as the new algorithms that will be discovered by the search in algorithm space. The methods produced are expected to ultimately be generally applicable to a large number of problems."
"1826973","AAAI Student Outreach Workshop","IIS","ROBUST INTELLIGENCE","03/15/2018","03/15/2018","Sheila Tejada","CA","Association for the Advancement of Artificial Intelligence","Standard Grant","James Donlon","04/30/2019","$15,000.00","","sheilatejada@gmail.com","2275 E BAYSHORE RD STE 160","East Palo Alto","CA","943033224","6503283123","CSE","7495","7495, 7556","$0.00","This grant supports the participation of undergraduate students in the AAAI Student Outreach Workshop, to be held in conjunction with the AAAI (Association for the Advancement of Artificial Intelligence) and EAAI (Educational Applications of Artificial Intelligence) conferences, February 2-7, 2018 in New Orleans.  This outreach program is aimed at undergraduate students with an interest in AI or Robotics.  Through this workshop, students will work with the Cozmo robot and the Calypso robot intelligence framework to gain hands-on experience in applying artificial intelligence to a commercial robot.  <br/><br/>This activity will expose undergraduate students to practical skills and research issues involved in developing systems with robust intelligence.  The activity promotes student interest in artificial intelligence and autonomous robots for future education and development. The workshop also contributes to the development of effective methods for teaching about artificial intelligence, which has the potential to impact the computer science and engineering education community's ability to recruit future researchers and workforce more broadly.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1844514","EAGER: Collaborative Research: Type II: Data-Driven Characterization and Engineering of Protein Hydrophobicity","DMR","DMR SHORT TERM SUPPORT, CONDENSED MATTER & MAT THEORY, PROJECTS","01/01/2019","08/21/2018","Amish Patel","PA","University of Pennsylvania","Standard Grant","Daryl W. Hess","12/31/2020","$231,647.00","","amish.patel@seas.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","MPS","1712, 1765, 1978","054Z, 062Z, 7237, 7573, 7916, 7926, 9216","$0.00","NONTECHNICAL SUMMARY<br/>This EAGER award supports research and education involving a new collaboration kindled at the MATDAT18 Datathon event focused on advancing understanding of how water interacts with proteins and complex molecular assemblies. Oil and water don't mix. Examples of this common wisdom are prevalent in everyday life from the sheen formed on a rain puddle by spilled gasoline, to the separation of oil and vinegar in a bottle of salad dressing. These are large-scale examples of a physical principle known as hydrophobicity - a word derived from Ancient Greek that characterizes the ""horror for water"" experienced by particular molecules. This physical principle is also active at microscopic scales, with hydrophobicity playing an important role in controlling the structure and function of molecules in water. Of particular interest is the behavior of proteins: a class of molecules that use the hydrophobic effect to perform functions critical to life, serving as - among many other things - enzymes to help break down food, hormones to regulate physiology, and antibodies to protect against infection. Some physical forces can be described by simple and elegant equations, such as Newton's law of gravitation or Coulomb's law of electrostatics, but decades of work have shown that no such simple descriptions seem to exist for hydrophobicity. Instead, the hydrophobic interaction is a very complicated force that depends sensitively on the details of the hydrophobic molecule and its interactions with the water molecules around it. Unraveling the details of this interaction in the context of proteins is important in helping understand the fundamentals of this ubiquitous and important force, and in helping discover and design proteins to serve as new drugs or novel molecular machines.<br/><br/>How might one probe and understand the complexities of hydrophobicity? Artificial intelligence techniques are now ubiquitous in modern life, serving as recommendation engines for online shopping, automatically recognizing faces in camera phones, and enabling autonomous and assisted driving. Conventional computer programs work by executing a pre-programmed set of rules to achieve an outcome; modern artificial intelligence techniques are instead provided with a set of examples and automatically learn the rules from the data. This research project will use artificial intelligence techniques to learn the rules of hydrophobicity from computer simulations of water around proteins. Specifically, using sophisticated molecular simulations to model the interactions and dynamics of water molecules, and special tools to measure hydrophobicity, databases of the ""horror for water"" of different regions of the protein surface will be compiled. Artificial intelligence tools will then analyze these databases to find a mathematical model between hydrophobicity and the chemical composition and shape of the protein surface. The models learned in this way will help untangle the complexities of hydrophobicity, and can be used to quickly predict how proteins in water will behave. The tools will also be adapted and analyzed to provide human-interpretable explanations that help provide new understanding of hydrophobicity rather than just furnishing a complicated mathematical model.<br/><br/>These research activities will provide new models and understanding of protein hydrophobicity that can be used to search for new drug molecules and engineer proteins with new structures and functions. The simulation and artificial intelligence tools will be made broadly available to the scientific community and general public through open source molecular simulation packages, free software libraries, and through online code sharing sites. Undergraduate students will be involved in the research projects through 10-week paid summer internships to be offered in each year of the award. These research experiences will be designed according to best practices in providing authentic and valuable training experiences, and special efforts will be made to recruit students from groups traditionally underrepresented in science, technology, engineering, and math fields.<br/><br/>TECHNICAL SUMMARY<br/>This EAGER award supports research and education involving a new collaboration kindled at the MATDAT18 Datathon event focused on integrating sophisticated molecular simulation tools with machine learning techniques to understand hydrophobicity at the nanoscale. The hydrophobic effect - the tendency for non-polar moieties to cluster together and exclude water molecules in aqueous solvent - plays an important role in the interactions and assemblies of complex molecules, such as cavitands, dendrimers, and proteins. However, quantifying the hydrophobicity of such molecules, which display complex chemical and topographical patterns at the nanoscale, has proven to be an enduring and open challenge. Recent work has illuminated the failure of additive approaches that attempt to break down molecular hydrophobicity as a sum of the hydrophobicities of the constituent surface groups, and demonstrated that hydrophobicity at the nanoscale is a complex, collective, many-body response of hydration waters to chemical and topographical surface cues. This complexity not only frustrates a fundamental molecular understanding of hydrophobicity at the nanoscale, but also has important practical consequences, such as the inability to accurately screen ligands for drug discovery.<br/><br/>The overall goal of this research project is to conduct enhanced sampling molecular simulations to accurately quantify the hydrophobicity of an extensive library of nanostructured surfaces through the free energy of cavity formation, and to deploy supervised machine learning techniques to unveil new understanding of the physical, chemical, and topographical cues governing surface hydrophobicity. The central hypothesis of this project is that the application of data-centric tools can provide new understanding of the molecular determinants of hydrophobicity beyond what is possible with simple conceptual models and human intuition. The first objective of this work is to quantify the hydrophobicity of an extensive library of patterned self-assembled monolayer surfaces and proteins by estimating the free energy of interfacial cavity formation using enhanced sampling techniques. The second objective is to conduct supervised learning over the hydrophobicity libraries to construct quantitative structure property relationship models relating chemical composition and physical structure to the free energy of interfacial cavity formation. A number of machine learning techniques will be explored, including support vector machines, random forests, partial least squares regression, and artificial neural networks. The techniques will be adapted to be physics-aware by ""baking in"" the physics of hydrophobicity into the model, and to be explainable by furnishing human-interpretable understanding of their behaviors.<br/><br/>Successful completion of this research will have impacts in both materials and data science. From a materials science perspective, unveiling the molecular determinants of protein hydrophobicity - the relation between the topographical and chemical patterns displayed by the protein and the free energy of cavity formation - will shed new light on the driving force behind protein interactions and assembly, furnish precepts for rational engineering of protein structure and function, and open up applications in virtual high-throughput screening for the computational discovery of drugs, ligands, bioseparation agents, and co-solutes to modulate protein solubility. From a data science perspective, this work will establish new physics/chemistry-aware machine learning tools whose behaviors are more interpretable and comprehensible in the analysis of molecular behaviors than generic off-the-shelf techniques.<br/><br/>The Division of Materials Research and the Chemistry Division contribute funds to this award.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1844505","EAGER: Collaborative Research: Type II: Data-Driven Characterization and Engineering of Protein Hydrophobicity","DMR","DMR SHORT TERM SUPPORT, CONDENSED MATTER & MAT THEORY, PROJECTS","01/01/2019","08/21/2018","Andrew Ferguson","IL","University of Chicago","Standard Grant","Daryl W. Hess","12/31/2020","$52,982.00","","andrewferguson@uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","MPS","1712, 1765, 1978","054Z, 062Z, 7237, 7573, 7916, 7926, 9216","$0.00","NONTECHNICAL SUMMARY<br/>This EAGER award supports research and education involving a new collaboration kindled at the MATDAT18 Datathon event focused on advancing understanding of how water interacts with proteins and complex molecular assemblies. Oil and water don't mix. Examples of this common wisdom are prevalent in everyday life from the sheen formed on a rain puddle by spilled gasoline, to the separation of oil and vinegar in a bottle of salad dressing. These are large-scale examples of a physical principle known as hydrophobicity - a word derived from Ancient Greek that characterizes the ""horror for water"" experienced by particular molecules. This physical principle is also active at microscopic scales, with hydrophobicity playing an important role in controlling the structure and function of molecules in water. Of particular interest is the behavior of proteins: a class of molecules that use the hydrophobic effect to perform functions critical to life, serving as - among many other things - enzymes to help break down food, hormones to regulate physiology, and antibodies to protect against infection. Some physical forces can be described by simple and elegant equations, such as Newton's law of gravitation or Coulomb's law of electrostatics, but decades of work have shown that no such simple descriptions seem to exist for hydrophobicity. Instead, the hydrophobic interaction is a very complicated force that depends sensitively on the details of the hydrophobic molecule and its interactions with the water molecules around it. Unraveling the details of this interaction in the context of proteins is important in helping understand the fundamentals of this ubiquitous and important force, and in helping discover and design proteins to serve as new drugs or novel molecular machines.<br/><br/>How might one probe and understand the complexities of hydrophobicity? Artificial intelligence techniques are now ubiquitous in modern life, serving as recommendation engines for online shopping, automatically recognizing faces in camera phones, and enabling autonomous and assisted driving. Conventional computer programs work by executing a pre-programmed set of rules to achieve an outcome; modern artificial intelligence techniques are instead provided with a set of examples and automatically learn the rules from the data. This research project will use artificial intelligence techniques to learn the rules of hydrophobicity from computer simulations of water around proteins. Specifically, using sophisticated molecular simulations to model the interactions and dynamics of water molecules, and special tools to measure hydrophobicity, databases of the ""horror for water"" of different regions of the protein surface will be compiled. Artificial intelligence tools will then analyze these databases to find a mathematical model between hydrophobicity and the chemical composition and shape of the protein surface. The models learned in this way will help untangle the complexities of hydrophobicity, and can be used to quickly predict how proteins in water will behave. The tools will also be adapted and analyzed to provide human-interpretable explanations that help provide new understanding of hydrophobicity rather than just furnishing a complicated mathematical model.<br/><br/>These research activities will provide new models and understanding of protein hydrophobicity that can be used to search for new drug molecules and engineer proteins with new structures and functions. The simulation and artificial intelligence tools will be made broadly available to the scientific community and general public through open source molecular simulation packages, free software libraries, and through online code sharing sites. Undergraduate students will be involved in the research projects through 10-week paid summer internships to be offered in each year of the award. These research experiences will be designed according to best practices in providing authentic and valuable training experiences, and special efforts will be made to recruit students from groups traditionally underrepresented in science, technology, engineering, and math fields.<br/><br/>TECHNICAL SUMMARY<br/>This EAGER award supports research and education involving a new collaboration kindled at the MATDAT18 Datathon event focused on integrating sophisticated molecular simulation tools with machine learning techniques to understand hydrophobicity at the nanoscale. The hydrophobic effect - the tendency for non-polar moieties to cluster together and exclude water molecules in aqueous solvent - plays an important role in the interactions and assemblies of complex molecules, such as cavitands, dendrimers, and proteins. However, quantifying the hydrophobicity of such molecules, which display complex chemical and topographical patterns at the nanoscale, has proven to be an enduring and open challenge. Recent work has illuminated the failure of additive approaches that attempt to break down molecular hydrophobicity as a sum of the hydrophobicities of the constituent surface groups, and demonstrated that hydrophobicity at the nanoscale is a complex, collective, many-body response of hydration waters to chemical and topographical surface cues. This complexity not only frustrates a fundamental molecular understanding of hydrophobicity at the nanoscale, but also has important practical consequences, such as the inability to accurately screen ligands for drug discovery.<br/><br/>The overall goal of this research project is to conduct enhanced sampling molecular simulations to accurately quantify the hydrophobicity of an extensive library of nanostructured surfaces through the free energy of cavity formation, and to deploy supervised machine learning techniques to unveil new understanding of the physical, chemical, and topographical cues governing surface hydrophobicity. The central hypothesis of this project is that the application of data-centric tools can provide new understanding of the molecular determinants of hydrophobicity beyond what is possible with simple conceptual models and human intuition. The first objective of this work is to quantify the hydrophobicity of an extensive library of patterned self-assembled monolayer surfaces and proteins by estimating the free energy of interfacial cavity formation using enhanced sampling techniques. The second objective is to conduct supervised learning over the hydrophobicity libraries to construct quantitative structure property relationship models relating chemical composition and physical structure to the free energy of interfacial cavity formation. A number of machine learning techniques will be explored, including support vector machines, random forests, partial least squares regression, and artificial neural networks. The techniques will be adapted to be physics-aware by ""baking in"" the physics of hydrophobicity into the model, and to be explainable by furnishing human-interpretable understanding of their behaviors.<br/><br/>Successful completion of this research will have impacts in both materials and data science. From a materials science perspective, unveiling the molecular determinants of protein hydrophobicity - the relation between the topographical and chemical patterns displayed by the protein and the free energy of cavity formation - will shed new light on the driving force behind protein interactions and assembly, furnish precepts for rational engineering of protein structure and function, and open up applications in virtual high-throughput screening for the computational discovery of drugs, ligands, bioseparation agents, and co-solutes to modulate protein solubility. From a data science perspective, this work will establish new physics/chemistry-aware machine learning tools whose behaviors are more interpretable and comprehensible in the analysis of molecular behaviors than generic off-the-shelf techniques.<br/><br/>The Division of Materials Research and the Chemistry Division contribute funds to this award.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1832717","Workshop on Artificial Intelligence and the ""Barrier of Meaning""","IIS","ROBUST INTELLIGENCE","05/01/2018","04/13/2018","Melanie Mitchell","NM","Santa Fe Institute","Standard Grant","James Donlon","04/30/2019","$20,088.00","","mm@cs.pdx.edu","1399 HYDE PARK ROAD","SANTA FE","NM","875018943","5059462727","CSE","7495","7495, 7556, 9150","$0.00","This workshop brings together eminent scholars in the fields of computer science, psychology, biology, neuroscience, and others to address the topic of ""understanding"" in artificial intelligence.  In this activity, participants will consider what it would mean for advanced computer systems to possess human-like understanding, explore how necessary it is for intelligent systems to exhibit such understanding, and discuss approaches to imbuing these systems with such a capability.  Engagement of a multidisciplinary community will develop new and actionable insight into how we define, design, implement, and control complex systems that overcome this barrier of meaning.  The workshop will likely also lead to outcomes and follow-on activities to benefit AI education and public awareness regarding the state of current artificial intelligence, including its limitations and potential vulnerabilities.<br/><br/>The approach in this workshop is to explore how complex systems extract meaning from the information they encounter. Workshop participants will engage questions about the function and mechanisms of ""understanding"" or ""extracting meaning"" in complex systems across many disciplines, and focus specifically on the relevance of human-like understanding for creating artificial intelligence systems that are reliable, adaptable to novel situations, and robust against adversarial attacks.  Understanding the nature and necessity of understanding remains among the deepest intellectual challenges in AI research. Workshop discussions will be aimed at clarifying common questions and identifying possible novel pathways to answering these questions. Organizers will publish both technical and general-readership summaries communicating the results of the workshop discussions concerning the notions of understanding or meaning as phenomena in diverse disciplines, and how these phenomena relate to, or enable, the robustness that will be needed for safe and trustworthy AI in the real world.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822136","Use of Artificial Intelligence towards Automation of Analog Seismogram Digitization","EAR","GEOPHYSICS","08/15/2018","08/03/2018","Miaki Ishii","MA","Harvard University","Standard Grant","Paul Raterron","07/31/2020","$154,017.00","","ishii@eps.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","GEO","1574","","$0.00","Seismometers have been recording ground motion since the late 1800s, and about 100 years of the recordings are in analog form (e.g., paper recordings) that cannot be examined using modern techniques.  These data contain information about earthquakes, volcano eruptions, subsurface changes, changes in weather pattern, to name the few, and are vital for understanding various phenomena that affect the Earth and how they evolve over time.  This project aims to make a significant step forward in converting these analog data into usable digital format by introducing artificial intelligence to the conversion process.  Currently, there is a software that takes a record image and generates digital seismograms, but it requires substantial  human interaction making this process slow, impractical, or impossible.  Successful implementation of artificial intelligence will allow more data to be processed quickly for use by the scientific community, which is a significant broader impact. <br/><br/>The project will start by examining the digitized analyses to determine and build the training database to be used for the construction of the neural network. The investigators will also identify steps that will benefit most from implementation of artificial intelligence procedures to decrease human interaction and improve accuracy of the digitization of seismograms.   Neural networks for image classification and object identification are now available and will be examined to find the algorithm that is most suitable for the seismogram digitization process.  The improved digitization software will be openly available to increase users and provide a robust tool to convert analog seismogram images to research-quality digital seismograms.  It will enable the seismological community to retrieve data that for application of modern analyses, and open opportunities for new types of research to be done.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1829786","Doctoral Mentoring Consortium at International Joint Conference on Artificial Intelligence (IJCAI) 2018","IIS","ROBUST INTELLIGENCE","03/15/2018","03/13/2018","Maria Gini","MN","University of Minnesota-Twin Cities","Standard Grant","James Donlon","02/28/2019","$20,000.00","","gini@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","7495, 7556","$0.00","This grant supports student travel for select students to participate in the Doctoral Mentoring Consortium (DMC) at the International Joint Conference on Artificial Intelligence (IJCAI) that will be held in Stockholm, Sweden, July 13-19, 2018. This is the premier international conference for researchers in artificial intelligence research across a fully international research community. This activity will bring together a broad community of researchers in the field of AI, and support junior researchers at this critical early-career stage.  The DMC creates the opportunity to bring in participants who might not have attended an AI conference due to lack of resources. This is especially true for those at smaller institutions and those which have less developed AI programs. Engaging such participants has the potential to draw more talent into AI research, improve research ideas in their formative stage, and engender collaborations across the breadth of disciplines.  This event provides students with invaluable exposure to outside perspectives on their work at a critical time in their research and enables them to explore their career objectives.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1828181","MRI: Acquisition of Artificial Intelligence & Deep Learning (AIDL) Training and Research Laboratory","CNS","IIS SPECIAL PROJECTS","10/01/2018","09/08/2018","Xingquan Zhu","FL","Florida Atlantic University","Standard Grant","Rita V. Rodriguez","09/30/2021","$652,850.00","Hanqi Zhuang, Taghi Khoshgoftaar, Dimitris Pados, Laurent Cherubin","xzhu3@fau.edu","777 GLADES RD","BOCA RATON","FL","334316424","5612970777","CSE","7484","1189","$0.00","Researchers in health, biomedical science, and various engineering fields often do not receive sufficient training in using the most powerful approach to machine learning known to date, an approach called ""deep learning"", for analying their data.  Deep learning is based on simulated artificial neural networks, and for large real-world problems requires access to specialized computer hardward and software.  Such hardware and software platforms, however, are rarely part of the information technology resources available for researchers outside of the field of computer science.  This project will overcome this barrier by procurement and development of a deep learning platform at Florida Atlantic University for such research.  The project provides a training hub for industry and university to work closely on advanced artificial intelligence applications, and in turn might benefit economic growth.<br/><br/>This infrastructure project supports creation of a deep learning platform for health, biomedicine, ocean research, and related domains at Florida Atlantic University.  The platform will be shared across campus to service multiple domains. The project brings about a centralized cross campus interdisciplinary platform and augmented deep learning and related artificial intelligence tools for interdisciplinary research.  The former, jointly managed by the College of Engineering and Computer Science, and the FAU office of Information Technology, enables building upon the experience and frameworks of others that eventually results in shared infrastructure savings. The latter is likely to contribute in building/augmenting AI and DL tool kits for interdisciplinary research, including augmentation of existing common machine learning and deep learning algorithms for domain experts to carry out analysis on their data without requiring intensive programming skills. Augmented AI and DL tools should be particularly useful to ocean engineers and health sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839971","FW-HTF: Collaborative Research: Pre-Skilling Workers, Understanding Labor Force Implications and Designing Future Factory Human-Robot Workflows Using a Physical Simulation Platform","DUE","FW-HTF: Advancing Cognitive an","10/01/2018","08/22/2018","Karthik Ramani","IN","Purdue University","Standard Grant","Alexandra Medina-Borja","09/30/2022","$1,839,998.00","Thomas Redick, Shimon Nof, Alexander Quinn","ramani@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","EHR","082Y","063Z","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim.<br/><br/>This collaborative project between Purdue University, Indiana University and the Massachusetts Institute of Technology is based on the rationale that today's manufacturers, especially small and medium enterprises may struggle to keep pace with rapid changes in manufacturing. To help manufacturers thrive in a rapidly changing industry, this project aims to develop a Physical-Simulation Platform that will realistically simulate interactions between workers, robots, and machines in future factories, and at the same time, improve factory agility and productivity. This project will provide new insights into workers' spatial, multitasking, and predictive task abilities in manufacturing, and their performance in shared and smooth workflows. Those insights can then be used to shape the augmented manufacturing environment of the future by amplifying cognitive capacity and transferring some cognitive burden to artificial intelligence and smart automation.  Such changes can improve both productivity and worker experience. The project will explore the economic impact on different types of workers as well as the benefits of artificial intelligence-based augmentation technologies on human labor, factory productivity and agility. In addition, the project will contribute to workforce development by creating educational plans and outreach to prepare workers for the manufacturing workplace of the future. The researchers will directly engage underserved young people by introducing them to new toolkits and curriculum developed as part of this project.  These materials can then be adapted by educators across the country. Strong industry collaborations are present to facilitate testing and adoption of this approach. <br/><br/>The research team of mechanical and electrical engineers, psychologists, computer scientists, education researchers, and economists will work toward accomplishing five goals: (1) use Mixed Reality to capture interactions, shared workflows, and collaborative tasks as close as possible to a real manufacturing environment; (2) develop and demonstrate new types of authoring platform to program robots, internet-of-things-based machines, and humans interacting with them, with augmented reality, artificial intelligence to substantially reduce cognitive loads and enhance worker and factory overall capabilities and productivities; (3) discover, design and develop flexible representations of collaborative intelligence workflows and metrics to simulate and evaluate Humans-Robots-Machines shared work; (4) evaluate shared work economics and labor market implications of augmenting humans with robotics, augmented reality, and artificial intelligence; and (5) pre-skill the workforce and increase engagement towards the future of work at the human-technology interface.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839921","FW-HTF: Collaborative Research: Pre-Skilling Workers, Understanding Labor Force Implications and Designing Future Factory Human-Robot Workflows Using a Physical Simulation Platform","DUE","FW-HTF: Advancing Cognitive an","10/01/2018","08/22/2018","Daron Acemoglu","MA","Massachusetts Institute of Technology","Standard Grant","Alexandra Medina-Borja","09/30/2022","$360,000.00","","daron@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","EHR","082Y","063Z","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim.<br/><br/>This collaborative project between Purdue University, Indiana University and the Massachusetts Institute of Technology is based on the rationale that today's manufacturers, especially small and medium enterprises may struggle to keep pace with rapid changes in manufacturing. To help manufacturers thrive in a rapidly changing industry, this project aims to develop a Physical-Simulation Platform that will realistically simulate interactions between workers, robots, and machines in future factories, and at the same time, improve factory agility and productivity. This project will provide new insights into workers' spatial, multitasking, and predictive task abilities in manufacturing, and their performance in shared and smooth workflows. Those insights can then be used to shape the augmented manufacturing environment of the future by amplifying cognitive capacity and transferring some cognitive burden to artificial intelligence and smart automation.  Such changes can improve both productivity and worker experience. The project will explore the economic impact on different types of workers as well as the benefits of artificial intelligence-based augmentation technologies on human labor, factory productivity and agility. In addition, the project will contribute to workforce development by creating educational plans and outreach to prepare workers for the manufacturing workplace of the future. The researchers will directly engage underserved young people by introducing them to new toolkits and curriculum developed as part of this project.  These materials can then be adapted by educators across the country. Strong industry collaborations are present to facilitate testing and adoption of this approach. <br/><br/>The research team of mechanical and electrical engineers, psychologists, computer scientists, education researchers, and economists will work toward accomplishing five goals: (1) use Mixed Reality to capture interactions, shared workflows, and collaborative tasks as close as possible to a real manufacturing environment; (2) develop and demonstrate new types of authoring platform to program robots, internet-of-things-based machines, and humans interacting with them, with augmented reality, artificial intelligence to substantially reduce cognitive loads and enhance worker and factory overall capabilities and productivities; (3) discover, design and develop flexible representations of collaborative intelligence workflows and metrics to simulate and evaluate Humans-Robots-Machines shared work; (4) evaluate shared work economics and labor market implications of augmenting humans with robotics, augmented reality, and artificial intelligence; and (5) pre-skill the workforce and increase engagement towards the future of work at the human-technology interface.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839896","FW-HTF: Collaborative Research: Pre-Skilling Workers, Understanding Labor Force Implications and Designing Future Factory Human-Robot Workflows Using a Physical Simulation Platform","DUE","FW-HTF: Advancing Cognitive an","10/01/2018","08/22/2018","Kylie Peppler","IN","Indiana University","Standard Grant","Alexandra Medina-Borja","09/30/2022","$300,002.00","","kpeppler@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","EHR","082Y","063Z","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim.<br/><br/>This collaborative project between Purdue University, Indiana University and the Massachusetts Institute of Technology is based on the rationale that today's manufacturers, especially small and medium enterprises, may struggle to keep pace with rapid changes in manufacturing. To help manufacturers thrive in a rapidly changing industry, this project aims to develop a Physical-Simulation Platform that will realistically simulate interactions between workers, robots, and machines in future factories, and at the same time, improve factory agility and productivity. This project will provide new insights into workers' spatial, multitasking, and predictive task abilities in manufacturing, and their performance in shared and smooth workflows. Those insights can then be used to shape the augmented manufacturing environment of the future by amplifying cognitive capacity and transferring some cognitive burden to artificial intelligence and smart automation.  Such changes can improve both productivity and worker experience. The project will explore the economic impact on different types of workers as well as the benefits of artificial intelligence-based augmentation technologies on human labor, factory productivity and agility. In addition, the project will contribute to workforce development by creating educational plans and outreach to prepare workers for the manufacturing workplace of the future. The researchers will directly engage underserved young people by introducing them to new toolkits and curriculum developed as part of this project.  These materials can then be adapted by educators across the country. Strong industry collaborations are present to facilitate testing and adoption of this approach. <br/><br/>The research team of mechanical and electrical engineers, psychologists, computer scientists, education researchers, and economists will work toward accomplishing five goals: (1) use Mixed Reality to capture interactions, shared workflows, and collaborative tasks as close as possible to a real manufacturing environment; (2) develop and demonstrate new types of authoring platform to program robots, internet-of-things-based machines, and humans interacting with them, with augmented reality, artificial intelligence to substantially reduce cognitive loads and enhance worker and factory overall capabilities and productivities; (3) discover, design and develop flexible representations of collaborative intelligence workflows and metrics to simulate and evaluate Humans-Robots-Machines shared work; (4) evaluate shared work economics and labor market implications of augmenting humans with robotics, augmented reality, and artificial intelligence; and (5) pre-skill the workforce and increase engagement towards the future of work at the human-technology interface.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1740225","E2CDA: Type I: Collaborative Research: Energy-Efficient Artificial Intelligence with Binary RRAM and Analog Epitaxial Synaptic Arrays","CCF","Energy Efficient Computing: fr","09/15/2017","07/11/2018","Jae-sun Seo","AZ","Arizona State University","Continuing grant","Sankar Basu","08/31/2020","$386,044.00","Shimeng Yu","jaesun.seo@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","015Y","7945","$0.00","In recent years, deep learning and artificial neural networks have been very successful in large-scale recognition and classification tasks, some even surpassing human-level accuracy. However, state-of-the-art deep learning algorithms tend to present very large network models, which poses significant challenges for hardware, especially for memory. Emerging resistive devices have been proposed as an alternative solution for weight storage and parallel neural computing, but severe limitations still exist for applying resistive random access memories (RRAMs) for practical large-scale neural computing. This proposal targets on addressing limitations in resistive device based neural computing through novel device engineering, new bitcell designs, new neuron circuits, energy-aware architecture, and a new circuit-level benchmark simulator. A successful completion of this research is likely to have consequences to our society, enabling wide adoption of dense and energy-efficient intelligent hardware to power-/area-constrained local mobile/wearable devices. Furthermore, a self-learning chip that learns in near real-time and consumes very low-power can be integrated in smart biomedical devices, personalizing healthcare. This project will have a strong effort on integrating the research outcomes with education and outreach through summer outreach programs for high school students, undergraduate/graduate student training, and organization of tutorials and workshops at conferences for knowledge dissemination.<br/><br/>The proposal will perform innovative and interdisciplinary research to address many limitations in today?s resistive device based neural computing and make a leap progress towards energy-efficient intelligent computing. Severe limitations of applying resistive random access memories (RRAMs) for practical large-scale neural computing include: (1) device-level non-idealities, e.g., non-linearity, variability, selector, and endurance, (2) inefficiency in representing negative weights and neurons, and (3) limited demonstration on simpler networks, instead of cutting-edge convolutional and recurrent neural networks. To address these limitations, novel technologies from devices to architectures will be investigated. First, new bitcell circuits will be designed for today's binary resistive devices, efficiently mapping XNOR functionality with (+1, -1) weights and neurons. Second, a novel epitaxial resistive device (EpiRAM) that exhibits many idealistic properties will be investigated, including linear programming for analog weights, suppressed variability, self-selectivity, and high endurance. Third, new neuron circuits will be explored for integration with new resistive devices for feedforward/feedback deep neural networks. Finally, new data-mapping techniques that efficiently map state-of-the-art deep neural networks onto the hardware framework with RRAM arrays will be developed, and the overall energy-efficiency will be verified with a new benchmark simulator ?NeuroSim?. With vertical innovations across material, device, circuit and architecture, tremendous potential and research needs will be pursued towards energy-efficient artificial intelligence in ubiquitous resource-constrained hardware systems."
"1740184","E2CDA: Type I: Collaborative Research: Energy-Efficient Artificial Intelligence with Binary RRAM and Analog Epitaxial Synaptic Arrays","CCF","Energy Efficient Computing: fr","09/15/2017","07/11/2018","Jeehwan Kim","MA","Massachusetts Institute of Technology","Continuing grant","Sankar Basu","08/31/2020","$243,624.00","","jeehwan@MIT.EDU","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","015Y","7945","$0.00","In recent years, deep learning and artificial neural networks have been very successful in large-scale recognition and classification tasks, some even surpassing human-level accuracy. However, state-of-the-art deep learning algorithms tend to present very large network models, which poses significant challenges for hardware, especially for memory. Emerging resistive devices have been proposed as an alternative solution for weight storage and parallel neural computing, but severe limitations still exist for applying resistive random access memories (RRAMs) for practical large-scale neural computing. This proposal targets on addressing limitations in resistive device based neural computing through novel device engineering, new bitcell designs, new neuron circuits, energy-aware architecture, and a new circuit-level benchmark simulator. A successful completion of this research is likely to have consequences to our society, enabling wide adoption of dense and energy-efficient intelligent hardware to power-/area-constrained local mobile/wearable devices. Furthermore, a self-learning chip that learns in near real-time and consumes very low-power can be integrated in smart biomedical devices, personalizing healthcare. This project will have a strong effort on integrating the research outcomes with education and outreach through summer outreach programs for high school students, undergraduate/graduate student training, and organization of tutorials and workshops at conferences for knowledge dissemination.<br/><br/>The proposal will perform innovative and interdisciplinary research to address many limitations in today?s resistive device based neural computing and make a leap progress towards energy-efficient intelligent computing. Severe limitations of applying resistive random access memories (RRAMs) for practical large-scale neural computing include: (1) device-level non-idealities, e.g., non-linearity, variability, selector, and endurance, (2) inefficiency in representing negative weights and neurons, and (3) limited demonstration on simpler networks, instead of cutting-edge convolutional and recurrent neural networks. To address these limitations, novel technologies from devices to architectures will be investigated. First, new bitcell circuits will be designed for today?s binary resistive devices, efficiently mapping XNOR functionality with (+1, -1) weights and neurons. Second, a novel epitaxial resistive device (EpiRAM) that exhibits many idealistic properties will be investigated, including linear programming for analog weights, suppressed variability, self-selectivity, and high endurance. Third, new neuron circuits will be explored for integration with new resistive devices for feedforward/feedback deep neural networks. Finally, new data-mapping techniques that efficiently map state-of-the-art deep neural networks onto the hardware framework with RRAM arrays will be developed, and the overall energy-efficiency will be verified with a new benchmark simulator ?NeuroSim?. With vertical innovations across material, device, circuit and architecture, tremendous potential and research needs will be pursued towards energy-efficient artificial intelligence in ubiquitous resource-constrained hardware systems."
"1757269","CompCog: Helping people make more future-minded decisions using optimal gamification","SES","DECISION RISK & MANAGEMENT SCI, CYBERINFRASTRUCTURE, PERCEPTION, ACTION & COGNITION","08/15/2018","08/14/2018","Thomas Griffiths","CA","University of California-Berkeley","Standard Grant","Jonathan W. Leland","07/31/2021","$519,423.00","","tomg@princeton.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","SBE","1321, 7231, 7252","075Z, 7252, 9179","$0.00","Helping people, teams, and organizations achieve important goals may be one of the most effective ways to increase productivity and promote human progress. To achieve their goals, many organizations employ financial incentives or game elements, such as points, levels, and badges, to motivate employees to become more productive. This project develops a theoretical foundation and computational tools for designing better incentive structures to help people achieve their goals. The project connects the crucial challenges of goal achievement studied in psychology to the computational methods from artificial intelligence that can be used to solve them. By bridging this gap the project provides a new way for artificial intelligence to communicate with people and empowers them to overcome the motivational obstacles and cognitive limitations that might otherwise prevent them from making good decisions. <br/><br/>At the heart of this project is a mathematical theory for optimizing incentive structures to help people make better decisions in complex, partially unknown environments. This theory is used as the basis for two cognitive prostheses that leverage artificial intelligence and gamification to help people achieve their goals: an intelligent to-do list gamification system that helps people become more productive and procrastinate less and an app that reinforces good habits. Field experiments are used to evaluate whether these cognitive prostheses are effective in the real world, working towards the development of intelligent systems that can aid people in setting and achieving their goals.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816039","RI: Small: A Cognitive Framework for Technical, Hard and Explainable Question Answering (THE-QA) with respect to Combined Textual and Visual Inputs","IIS","ROBUST INTELLIGENCE","08/01/2018","06/25/2018","Chitta Baral","AZ","Arizona State University","Standard Grant","James Donlon","07/31/2021","$499,999.00","Yezhou Yang","chitta@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7495","7495, 7923","$0.00","Understanding of visual and textual inputs are important aspects of Artificial Intelligence systems. Often such inputs are presented together to instruct and explain.  As examples, an intelligent robot might learn about its tasks and environment by observing both language and gesture; and an intelligent system addressing scientific questions must interpret figures and diagrams along with text. While there has been a lot of research concerning visual understanding and textual understanding in isolation, there has been very little research that addresses them jointly. This project is developing a framework for answering hard questions about combined visual and textual inputs, and providing supporting explanations. By developing a system that integrates visual and linguistic information for this task, the project could provide the basis for automated tutoring systems in K-12 education, and interpretable interfaces for the workers operating intelligent machines. <br/><br/>The project will employ an integrated approach of deep model-based visual recognition and natural language processing, and knowledge representation and reasoning to develop a question answering engine and its components. It will create a challenge corpus that has visual and textual inputs and questions about those inputs given in natural language. It will provide a baseline for semantic image and text parsing and reasoning-based question answering systems. It will develop semantic parsing of non-continuous text items, such as figures, diagrams, and graphs. It will enhance semantic parsing to various formats of natural language text and questions. It will develop methods to acquire knowledge and reasoning with them for answering questions and providing explanations to the answers. Together these contributions of the project will advance Artificial General Intelligence and allow future service robots and personal mobile applications to understand combined visual and textual inputs. The findings from this project will advance the development of knowledge-driven, reasoning-based question answering by filling the current gap on how to efficiently conduct explainable probabilistic reasoning over deep models.  This helps to overcome the fragility of the trained visual and textual understanding models. It will also uncover the intrinsic connections between deep model-based vision and language understanding algorithms and probabilistic knowledge representation and reasoning by exploring a joint solution for answering the hard questions. In general, this project may result in advances in multiple sub-fields of Artificial Intelligence; namely, computer vision, natural language processing, and question answering; and may impact others such as robotics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1841471","Collaborative Research: Scalable CyberInfrastructure for Artificial Intelligence and Likelihood Free Inference (SCAILFIN)","OAC","CESER-Cyberinfrastructure for","10/01/2018","09/07/2018","Kyle Cranmer","NY","New York University","Standard Grant","William Miller","09/30/2020","$486,879.00","Heiko Mueller","kyle.cranmer@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7684","020Z, 062Z","$0.00","The National Science Foundation (NSF) has made significant investments in major multi-user research facilities (MMURFs), which are the foundation for a robust data-intensive science program. Extracting scientific results from these facilities involves the comparison of ""real"" data collected from the experiments with ""synthetic"" data produced from computer simulations. There is wide growing interest in using new machine learning (ML) and artificial intelligence (AI) techniques to improve the analysis of data from these facilities and improve the efficiency of the simulations. The SCAILFIN project will use recently developed algorithms and computing technologies to bring cutting-edge data analysis techniques to such facilities, starting with the data from the international Large Hadron Collider. One result of these advancements will be that research groups at smaller academic institutions will more easily be able to access to the necessary computing resources which are often only available at larger institutions. Removing access barriers to such resources democratizes them, which is key to developing a diverse workforce. This effort will also contribute to workforce development through alignment of high-energy physics data analysis tools with industry computing standards and by training students in high-value data science skills.<br/><br/>The main goal of the SCAILFIN project is to deploy artificial intelligence and likelihood-free inference (LFI) techniques and software using scalable cyberinfrastructure (CI) that is developed to be integrated into existing CI elements, such as the REANA system. The  analysis of LHC data is the project's primary science driver, yet the technology is sufficiently generic to be widely applicable. The LHC experiments generate tens of petabytes of data annually and processing, analyzing, and sharing the data with thousands of physicists around the world is an enormous challenge. To translate the observed data into insights about fundamental physics, the important quantum mechanical processes and response of the detector to them need to be simulated to a high-level of detail and accuracy. Investments in scalable CI that empower scientists to employ ML approaches to overcome the challenges inherent in data-intensive science such as simulation-informed inference will increase the discovery reach of these experiments. The development of the proposed scalable CI components will catalyze convergent research because 1) the abstract LFI problem formulation has already demonstrated itself to be the ""lingua franca"" for a diverse range of scientific problems; 2) the current tools for many tasks are limited by lack of  scalability for data-intensive problems with computationally-intensive simulators; 3) the tools the project is developing are designed to be scalable and immediately deployable on a diverse set of computing resources due to the design; and 4) the integration of additional commonly-used workflow languages to drive the optimization of ML components and to orchestrate large-scale workflows will lower the barrier-to-entry for researchers from other domains.<br/><br/>This project is supported by the Office of Advanced Cyberinfrastructure in the Directorate for Computer and Information Science and Engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1841448","Collaborative Research: Scalable CyberInfrastructure for Artificial Intelligence and Likelihood Free Inference (SCAILFIN)","OAC","CESER-Cyberinfrastructure for","10/01/2018","09/07/2018","Michael Hildreth","IN","University of Notre Dame","Standard Grant","William Miller","09/30/2020","$422,981.00","","hildreth.2@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","CSE","7684","020Z, 062Z","$0.00","The National Science Foundation (NSF) has made significant investments in major multi-user research facilities (MMURFs), which are the foundation for a robust data-intensive science program. Extracting scientific results from these facilities involves the comparison of ""real"" data collected from the experiments with ""synthetic"" data produced from computer simulations. There is wide growing interest in using new machine learning (ML) and artificial intelligence (AI) techniques to improve the analysis of data from these facilities and improve the efficiency of the simulations. The SCAILFIN project will use recently developed algorithms and computing technologies to bring cutting-edge data analysis techniques to such facilities, starting with the data from the international Large Hadron Collider. One result of these advancements will be that research groups at smaller academic institutions will more easily be able to access to the necessary computing resources which are often only available at larger institutions. Removing access barriers to such resources democratizes them, which is key to developing a diverse workforce. This effort will also contribute to workforce development through alignment of high-energy physics data analysis tools with industry computing standards and by training students in high-value data science skills.<br/><br/>The main goal of the SCAILFIN project is to deploy artificial intelligence and likelihood-free inference (LFI) techniques and software using scalable cyberinfrastructure (CI) that is developed to be integrated into existing CI elements, such as the REANA system. The  analysis of LHC data is the project's primary science driver, yet the technology is sufficiently generic to be widely applicable. The LHC experiments generate tens of petabytes of data annually and processing, analyzing, and sharing the data with thousands of physicists around the world is an enormous challenge. To translate the observed data into insights about fundamental physics, the important quantum mechanical processes and response of the detector to them need to be simulated to a high-level of detail and accuracy. Investments in scalable CI that empower scientists to employ ML approaches to overcome the challenges inherent in data-intensive science such as simulation-informed inference will increase the discovery reach of these experiments. The development of the proposed scalable CI components will catalyze convergent research because 1) the abstract LFI problem formulation has already demonstrated itself to be the ""lingua franca"" for a diverse range of scientific problems; 2) the current tools for many tasks are limited by lack of  scalability for data-intensive problems with computationally-intensive simulators; 3) the tools the project is developing are designed to be scalable and immediately deployable on a diverse set of computing resources due to the design; and 4) the integration of additional commonly-used workflow languages to drive the optimization of ML components and to orchestrate large-scale workflows will lower the barrier-to-entry for researchers from other domains.<br/><br/>This project is supported by the Office of Advanced Cyberinfrastructure in the Directorate for Computer and Information Science and Engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1841456","Collaborative Research: Scalable CyberInfrastructure for Artificial Intelligence and Likelihood Free Inference (SCAILFIN)","OAC","CESER-Cyberinfrastructure for","10/01/2018","09/07/2018","Mark Neubauer","IL","University of Illinois at Urbana-Champaign","Standard Grant","William Miller","09/30/2020","$499,872.00","Daniel Katz","msn@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","7684","020Z, 062Z","$0.00","The National Science Foundation (NSF) has made significant investments in major multi-user research facilities (MMURFs), which are the foundation for a robust data-intensive science program. Extracting scientific results from these facilities involves the comparison of ""real"" data collected from the experiments with ""synthetic"" data produced from computer simulations. There is wide growing interest in using new machine learning (ML) and artificial intelligence (AI) techniques to improve the analysis of data from these facilities and improve the efficiency of the simulations. The SCAILFIN project will use recently developed algorithms and computing technologies to bring cutting-edge data analysis techniques to such facilities, starting with the data from the international Large Hadron Collider. One result of these advancements will be that research groups at smaller academic institutions will more easily be able to access to the necessary computing resources which are often only available at larger institutions. Removing access barriers to such resources democratizes them, which is key to developing a diverse workforce. This effort will also contribute to workforce development through alignment of high-energy physics data analysis tools with industry computing standards and by training students in high-value data science skills.<br/><br/>The main goal of the SCAILFIN project is to deploy artificial intelligence and likelihood-free inference (LFI) techniques and software using scalable cyberinfrastructure (CI) that is developed to be integrated into existing CI elements, such as the REANA system. The  analysis of LHC data is the project's primary science driver, yet the technology is sufficiently generic to be widely applicable. The LHC experiments generate tens of petabytes of data annually and processing, analyzing, and sharing the data with thousands of physicists around the world is an enormous challenge. To translate the observed data into insights about fundamental physics, the important quantum mechanical processes and response of the detector to them need to be simulated to a high-level of detail and accuracy. Investments in scalable CI that empower scientists to employ ML approaches to overcome the challenges inherent in data-intensive science such as simulation-informed inference will increase the discovery reach of these experiments. The development of the proposed scalable CI components will catalyze convergent research because 1) the abstract LFI problem formulation has already demonstrated itself to be the ""lingua franca"" for a diverse range of scientific problems; 2) the current tools for many tasks are limited by lack of  scalability for data-intensive problems with computationally-intensive simulators; 3) the tools the project is developing are designed to be scalable and immediately deployable on a diverse set of computing resources due to the design; and 4) the integration of additional commonly-used workflow languages to drive the optimization of ML components and to orchestrate large-scale workflows will lower the barrier-to-entry for researchers from other domains.<br/><br/>This project is supported by the Office of Advanced Cyberinfrastructure in the Directorate for Computer and Information Science and Engineering.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1533569","Targeted Infusion Project: Development of a Knowledge-Based System for Integrating Artificial Intelligence into the Undergraduate Engineering Curriculum","HRD","HIST BLACK COLLEGES AND UNIV","08/01/2015","07/24/2015","Yachi Wanyan","TX","Texas Southern University","Standard Grant","Claudia M. Rankins","07/31/2019","$400,000.00","David Olowokere","wanyany@tsu.edu","3100 Cleburne Street","Houston","TX","770044501","7133137457","EHR","1594","9178","$0.00","The Historically Black Colleges and Universities Undergraduate Program (HBCU-UP) through Targeted Infusion Projects supports the development, implementation, and study of evidence-based innovative models and approaches for improving the preparation and success of HBCU undergraduate students so that they may pursue STEM graduate programs and/or careers. The project at Texas Southern University seeks to infuse innovative electrical and computer engineering specialized artificial intelligence (AI) tools into traditional engineering problem-solving routines with a problem-based learning approach to bridge current curricula gaps, enhance engineering students' problem-solving and critical thinking skills, expose them to new technology, prepare them for diverse and multidisciplinary workforce requirements, and attract and encourage students to pursue professional engineering licensure or post-graduate studies in engineering field. The activities and strategies are evidence-based and a strong plan for formative and summative evaluation is part of the project.<br/><br/>There are five key objectives: 1) to develop an interactive and comprehensive intelligent database to document, compare, and analyze cutting-edge AI applications in the civil engineering field and use it as the platform and educational media for curricula development and implementation; 2) to develop one new interdisciplinary course  ""AI Tools for Engineering Problem Solving"" for senior engineering students; 3) to enrich current curricula by integrating innovative AI application case studies into twelve existing civil engineering junior and senior level courses; 4) to foster an interdisciplinary academic setting by hosting a server-based intelligent database; and 5) to support undergraduate students' early involvement in research. The project activities can serve as a model for other institutions that desire to strengthen undergraduate education in their engineering and technology programs."
"1764091","RI: Medium: Collaborative Research: Developing a Uniform Meaning Representation for Natural Language Processing","IIS","ROBUST INTELLIGENCE","08/01/2018","07/23/2018","William Croft","NM","University of New Mexico","Standard Grant","Tatiana D. Korelsky","07/31/2021","$399,821.00","","wcroft@unm.edu","1700 Lomas Blvd. NE, Suite 2200","Albuquerque","NM","871310001","5052774186","CSE","7495","7495, 7924, 9150","$0.00","The use of intelligent agents that can communicate with us in human language has become an essential part of our daily lives.  Today's intelligent agents can respond appropriately to many things we say or text to them, but they cannot yet communicate fully like humans. They lack our general ability to arrive quickly at accurate and relevant interpretations of what others communicate to us and to form appropriate responses, particularly in sustained interactions.  The typical way we teach a machine to acquire such ability is to provide it with approximations of the meanings of utterances in the contexts in which they have occurred in the past.  Over the years these approximations have become increasingly rich and detailed, enabling ever more sophisticated systems for interacting with computers using natural language, such as searching for information, getting up-to-date recommendations for products and services, and translating foreign languages.  The goal of this project is to bring together linguists and computer scientists to jointly develop a practical meaning representation formalism based on these rich approximations that can be applied to a much more diverse set of languages.   This will allow us to use machine learning to develop techniques to automatically translate human utterances into our meaning formalism. In turn, this will enable intelligent agents to acquire more advanced communication capabilities, and for a wider range of languages.  The languages considered for the project include those spoken by large populations such as English, Chinese and Arabic, as well as native tongues of smaller groups such as Norwegian, and Arapaho and Kukama-Kukamira, two indigenous languages of the Americas.  As such, this project will help bring modern technology to smaller groups so that all people can benefit equally from technological advancement.  The project will also contribute to the development of the US workforce by training a new generation of researchers on cutting-edge technologies in artificial intelligence.  <br/><br/>This project brings together an interdisciplinary team of linguists and computer scientists from three institutions to jointly develop a Uniform Meaning Representation (UMR). UMR is a practical, formal, computationally tractable, and cross-linguistically valid meaning representation of natural language that can impact a wide range of downstream applications requiring deep natural language understanding (NLU).  UMR will extend existing meaning representations to include quantifier types and relations, modality, negation, tense and aspect, and be tested on a typologically diverse set of languages.  Methods and techniques for UMR annotation, parsing and generation, and evaluation will be uniform across languages.  The project will also develop novel algorithms and models for UMR-based broad-coverage and general-purpose multilingual semantic parsers.  Students participating in the project will receive training in the full cycle of conceptualizing, producing, processing, and consuming meaning representations at the sites of participating institutions.  This project will help to build a community of NLP researchers that will contribute to the development of UMR-based data and tools and advance the state of the art in Natural Language Processing (NLP) in particular, and Artificial Intelligence (AI) in general.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1763926","RI:Medium:Collaborative Research:Developing a uniform meaning representation for natural language processing","IIS","ROBUST INTELLIGENCE","08/01/2018","07/23/2018","Nianwen Xue","MA","Brandeis University","Standard Grant","Tatiana D. Korelsky","07/31/2021","$399,237.00","James Pustejovsky","xuen@cs.brandeis.edu","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024532728","7817362121","CSE","7495","7495, 7924","$0.00","The use of intelligent agents that can communicate with us in human language has become an essential part of our daily lives.  Today's intelligent agents can respond appropriately to many things we say or text to them, but they cannot yet communicate fully like humans. They lack our general ability to arrive quickly at accurate and relevant interpretations of what others communicate to us and to form appropriate responses, particularly in sustained interactions.  The typical way we teach a machine to acquire such ability is to provide it with approximations of the meanings of utterances in the contexts in which they have occurred in the past.  Over the years these approximations have become increasingly rich and detailed, enabling ever more sophisticated systems for interacting with computers using natural language, such as searching for information, getting up-to-date recommendations for products and services, and translating foreign languages.  The goal of this project is to bring together linguists and computer scientists to jointly develop a practical meaning representation formalism based on these rich approximations that can be applied to a much more diverse set of languages.   This will allow us to use machine learning to develop techniques to automatically translate human utterances into our meaning formalism. In turn, this will enable intelligent agents to acquire more advanced communication capabilities, and for a wider range of languages.  The languages considered for the project include those spoken by large populations such as English, Chinese and Arabic, as well as native tongues of smaller groups such as Norwegian, and Arapaho and Kukama-Kukamira, two indigenous languages of the Americas.  As such, this project will help bring modern technology to smaller groups so that all people can benefit equally from technological advancement.  The project will also contribute to the development of the US workforce by training a new generation of researchers on cutting-edge technologies in artificial intelligence.  <br/><br/>This project brings together an interdisciplinary team of linguists and computer scientists from three institutions to jointly develop a Uniform Meaning Representation (UMR). UMR is a practical, formal, computationally tractable, and cross-linguistically valid meaning representation of natural language that can impact a wide range of downstream applications requiring deep natural language understanding (NLU).  UMR will extend existing meaning representations to include quantifier types and relations, modality, negation, tense and aspect, and be tested on a typologically diverse set of languages.  Methods and techniques for UMR annotation, parsing and generation, and evaluation will be uniform across languages.  The project will also develop novel algorithms and models for UMR-based broad-coverage and general-purpose multilingual semantic parsers.  Students participating in the project will receive training in the full cycle of conceptualizing, producing, processing, and consuming meaning representations at the sites of participating institutions.  This project will help to build a community of NLP researchers that will contribute to the development of UMR-based data and tools and advance the state of the art in Natural Language Processing (NLP) in particular, and Artificial Intelligence (AI) in general.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1764048","RI:Medium:Collaborative Research: Developing a Uniform Meaning Representation for Natural Language Processing","IIS","ROBUST INTELLIGENCE","08/01/2018","07/23/2018","Martha Palmer","CO","University of Colorado at Boulder","Standard Grant","Tatiana D. Korelsky","07/31/2021","$399,894.00","J. Andrew Cowell, James Martin","mpalmer@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","7495","7495, 7924","$0.00","The use of intelligent agents that can communicate with us in human language has become an essential part of our daily lives.  Today's intelligent agents can respond appropriately to many things we say or text to them, but they cannot yet communicate fully like humans. They lack our general ability to arrive quickly at accurate and relevant interpretations of what others communicate to us and to form appropriate responses, particularly in sustained interactions.  The typical way we teach a machine to acquire such ability is to provide it with approximations of the meanings of utterances in the contexts in which they have occurred in the past.  Over the years these approximations have become increasingly rich and detailed, enabling ever more sophisticated systems for interacting with computers using natural language, such as searching for information, getting up-to-date recommendations for products and services, and translating foreign languages.  The goal of this project is to bring together linguists and computer scientists to jointly develop a practical meaning representation formalism based on these rich approximations that can be applied to a much more diverse set of languages.   This will allow us to use machine learning to develop techniques to automatically translate human utterances into our meaning formalism. In turn, this will enable intelligent agents to acquire more advanced communication capabilities, and for a wider range of languages.  The languages considered for the project include those spoken by large populations such as English, Chinese and Arabic, as well as native tongues of smaller groups such as Norwegian, and Arapaho and Kukama-Kukamira, two indigenous languages of the Americas.  As such, this project will help bring modern technology to smaller groups so that all people can benefit equally from technological advancement.  The project will also contribute to the development of the US workforce by training a new generation of researchers on cutting-edge technologies in artificial intelligence.  <br/><br/>This project brings together an interdisciplinary team of linguists and computer scientists from three institutions to jointly develop a Uniform Meaning Representation (UMR). UMR is a practical, formal, computationally tractable, and cross-linguistically valid meaning representation of natural language that can impact a wide range of downstream applications requiring deep natural language understanding (NLU).  UMR will extend existing meaning representations to include quantifier types and relations, modality, negation, tense and aspect, and be tested on a typologically diverse set of languages.  Methods and techniques for UMR annotation, parsing and generation, and evaluation will be uniform across languages.  The project will also develop novel algorithms and models for UMR-based broad-coverage and general-purpose multilingual semantic parsers.  Students participating in the project will receive training in the full cycle of conceptualizing, producing, processing, and consuming meaning representations at the sites of participating institutions.  This project will help to build a community of NLP researchers that will contribute to the development of UMR-based data and tools and advance the state of the art in Natural Language Processing (NLP) in particular, and Artificial Intelligence (AI) in general.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1555079","CAREER: Biologically inspired neural network models for robust speech processing","IIS","ROBUST INTELLIGENCE","06/01/2016","05/22/2018","Nima Mesgarani","NY","Columbia University","Continuing grant","Kenneth C. Whang","05/31/2021","$292,379.00","","nm2764@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495","1045, 7495, 8091","$0.00","The recent parallel breakthroughs in deep neural network models and neuroimaging techniques have significantly advanced the current state of artificial and biological computing. However, there has been little interaction between these two disciplines, resulting in simplistic models of neural systems with limited prediction, learning and generalization abilities. The goal of this project is to create a coherent theoretical and mathematical framework to understand the computational role of distinctive features of biological neural networks, their contribution to the formation of robust signal representations, and to model and integrate them into the current artificial neural networks. These new bio-inspired models and algorithms will have adaptive and cognitive abilities, will better predict experimental observations, and will advance the knowledge of how the brain processes speech. In addition, the performance of these models should approach human abilities in tasks mimicking cognitive functions, and will motivate new experiments that can further impose realistic constraints on the models. <br/><br/>This interdisciplinary project lies at the intersection of neurolinguistics, speech engineering, and machine learning, uniting the historically separated disciplines of neuroscience and engineering. The proposed innovative approach integrates methods and expertise across various disciplines, including system identification, signal processing, neurophysiology, and systems neuroscience. The aim of this proposal is to analyze and transform the artificial neural network models to accurately reflect the computational and organizational principles of biological systems through three specific objectives: I) to create analytic methods that can provide insights into the transformations that occur in artificial neural network models by examining their representational properties and feature encoding, II) to model and implement the local, bottom-up, adaptive neural mechanisms that appear ubiquitously in biological systems, and III) to model the top-down, knowledge driven abilities of cognitive systems to implement new computations in response to the task requirements. Accurate computational models of the neural transformations will have an overarching impact in many disciplines including artificial intelligence, neurolinguistics, and systems neuroscience. More realistic neural network models will not only result in human-like pattern recognition technologies and better understanding of how the brain solves speech perception, but can also help explain how these processes are impaired in people with speech and language disorders. Therefore, the proposed project will advance the state-of-the-art in multiple disciplines."
"1718550","RI: Small: CompCog: Leveraging Deep Neural Networks for Understanding Human Cognition","IIS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","08/15/2017","08/04/2017","Thomas Griffiths","CA","University of California-Berkeley","Standard Grant","Kenneth C. Whang","07/31/2020","$448,284.00","","tomg@princeton.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7252, 7495","7495, 7923, 8089","$0.00","The last few years have seen significant breakthroughs in artificial intelligence and machine learning, resulting in systems that approach or even exceed human performance in interpreting pictures and words. This project explores the implications of these breakthroughs for understanding how the human mind works. Focusing on artificial neural networks, a key technology behind many recent breakthroughs that is capable of discovering novel representations for complex stimuli, the project has two goals. First, assessing the degree of correspondence between human and machine learning by examining whether the pictures or words that are similar in the representations discovered by neural network models are also judged to be similar by people. Second, developing methods for increasing this correspondence, with the goal of being able to use neural network representations to generate good predictions about how people learn and form categories using real images or text.<br/><br/>This research project will answer basic scientific questions about how the representations discovered by contemporary neural networks relate to human cognition. It will then explore what architectures and training regimes produce representations with these properties. In addition, the project will address the methodological question of how one can modify these representations to produce better alignment with human cognition. Answering this question will lead to powerful new tools for making models of human behavior in naturalistic contexts, leveraging the latest results in machine learning to broaden the scope of experimental research in cognitive science. By building stronger links between human and machine learning, this project will have implications for both fields. Even if current neural network systems turn out to differ significantly from human learning, they provide state-of-the-art representations for images and text that can be used as a starting point for developing better accounts of human representations. By discovering the ways in which the representations learned by artificial neural networks differ from those of humans, one can identify new algorithms and training methods that will result in a closer alignment. Since human beings remain the best examples available of systems that can solve certain problems, such an alignment offers a path toward expanding the capacities of current artificial intelligence systems and making them more interpretable by people, which is critical in settings that require human-machine interaction."
"1848840","Conference on Cognitive Computational Neuroscience (CCN): September 2018, Philadelphia, PA","BCS","COGNEURO, ROBUST INTELLIGENCE","09/01/2018","08/23/2018","Alyson Fletcher","CA","University of California-Los Angeles","Standard Grant","Uri Hasson","08/31/2021","$50,000.00","Thomas Naselaris","akfletcher@ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","SBE","1699, 7495","1699, 7556, 8089, 8091","$0.00","This project will provide three-years of support for the Conference on Cognitive Computational Neuroscience (CCN). This conference provides an annual scientific meeting for neuroscientists whose goal is to develop computationally defined models of brain information processing that explain rich measurements of brain activity and behavior. Historically, different disciplines have met subsets of these goals: Cognitive science has developed computational models at the cognitive level; computational neuroscience has developed neurobiologically plausible computational models at lower levels; cognitive neuroscience has mapped processes onto brain regions; and artificial intelligence has developed synthetic systems.  CCN is unique in its focus on the intersection between these fields.  In addition to advancing research, CCN seeks to contribute to the growing commercial use of biologically inspired hardware and software in Artificial Intelligence as well as being a vehicle for broadly impacting education and society.  One particular focus of CCN is increasing the visibility of women and scientists from underrepresented populations via speaking opportunities. This award will partially support travel grants for this purpose.  The conference will also include hands-on tutorials, and materials from these will propagate to various university curricula.  The award will support video recordings of the tutorials and talks.  These recordings will be made publicly available on the website to increase the broader impact of the conference to the wider community and those unable to attend. <br/><br/>A central goal of neuroscience is to understand how vast populations of neurons give rise to complex behavior. Today, advances in various domains offer tangible possibilities to make fundamental conceptual breakthroughs. Modern neural recording technologies now provide opportunities to observe neural activity at unprecedented resolution and scale. At the same time, research in cognitive science has become increasingly sophisticated in identifying computational principles that may serve as the basis for human cognition, and machine learning and artificial intelligence have made great strides in building models to autonomously solve complex cognitive tasks. However, interactions among these distinct disciplines remain rare. This new conference may stimulate unifying frameworks that fully realize the cross-disciplinary potential of these individual advances. Concretely, the goal of CCN is to create and foster a community that will develop models of brain information processing with several key features. These models should (1) be fully computationally defined and implemented in computer simulations; (2) be neurobiologically plausible; (3) explain measurements of brain activity (and continue to do so as spatiotemporal resolution and scale improve); (4) explain behavior in the context of naturalistic stimuli and tasks; and (5) perform feats of intelligence such as recognition, internal modelling and representation of the environment, decision-making, planning, action, and motor control. Such models currently do not exist and are unlikely to emerge without greatly improved cross-disciplinary engagement.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813583","RI: Small: 3D Reconstruction via Differential Rendering and Deep Learning","IIS","ROBUST INTELLIGENCE","09/01/2018","08/08/2018","Matthias Zwicker","MD","University of Maryland College Park","Standard Grant","Jie Yang","08/31/2021","$445,000.00","","zwicker@cs.umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","CSE","7495","7495, 7923","$0.00","Digitally reconstructing the 3D shapes of real-world objects is a core technology that enables a very wide range of applications, such as autonomous robot navigation; 3D printing for personal purposes or reverse engineering; archiving and virtual heritage; creating assets for movies, games, and augmented and virtual reality; or large-scale reconstruction for geographical information systems. This project develops novel computer algorithms to reconstruct the 3D shapes of objects using digital images as inputs. It addresses significant limitations of current techniques that often lead to inaccurate results in real-life applications. To achieve this, the project follows an innovative approach leveraging artificial intelligence techniques to understand 3D shapes based on digital images. The formulation of 3D shape reconstruction using artificial intelligence methods represents an important scientific advancement that promises further advances in the research field. A student-led augmented reality (AR) and virtual reality (VR) club gains first-hand experience with state of the art research and experiments with artificial intelligence-based 3D reconstruction to design innovative AR and VR applications.<br/><br/>This research develops algorithms building on two key techniques, differentiable rendering and deep learning. Combining these two methods leads to synergies that can overcome the limitations of current algorithms. Rendering is the process of algorithmically evaluating an image formation model, which may include sophisticated light transport effects such as non-diffuse surfaces, shadows, and indirect illumination, to compute an image of a virtual 3D object or environment. Using automatic differentiation (AD), a differentiable renderer calculates the partial derivatives of pixel values of rendered images with respect to all unknown model parameters of the virtual 3D model. Leveraging the power and generality of AD and differentiable rendering allows to overcome the overly simplistic image formation models common in previous work. In addition, multi-view reconstruction is often ill-posed because of the large number of unknown parameters and the limited information present in a set of views. Therefore, strong priors and robust error metrics are required. This work obtains these error metrics and priors using large-scale shape and image databases and deep learning techniques, to capture the full complexity of real-world objects. Crucially, it connects deep learning to the unknown 3D model parameters through differentiable rendering, which makes it possible to leverage gradient-based optimization techniques to solve for the desired 3D shapes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1814056","RI: Small: Designing Preferences, Beliefs, and Identities for Artificial Intelligence","IIS","ROBUST INTELLIGENCE","09/01/2018","07/23/2018","Vincent Conitzer","NC","Duke University","Standard Grant","James Donlon","08/31/2021","$400,000.00","","conitzer@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495","7495, 7923","$0.00","Historically, AI researchers have primarily focused on developing techniques that work well for pre-specified objectives that provide a useful measure of how well the techniques are working.  This approach is perfectly sensible in a situation where the techniques are not yet ready to make their way out of the lab and into the world.  However, as AI is now being broadly deployed in the world, more thought needs to be put into the methodologies for designing the objectives of AI systems.  This is because our aim is no longer just to evaluate whether our other techniques are able to pursue a given objective well, but rather to actually have them do good in the world.  Besides the AI system's objectives, we must also specify where one part of the system ends and another begins, as well as how it models the world.  Generally, it is not possible or desirable to simply hand off the system to a customer (in the broad sense of the word) who then must somehow fill in these blanks.  AI researchers need to be involved in this process because they understand how the system works and are able to provide algorithmic support for these decisions.  But rigorous computational frameworks for these processes are lacking, and they are what this research aims to provide.<br/><br/>Specifically, existing research in artificial intelligence, mirroring frameworks in economics and other related fields, is built on a conception of AI systems as agents.  It generally proceeds from the premise that each such agent has a well-defined identity over time, well-defined preferences over the different ways in which things may proceed, and well-defined beliefs about the world as it is and how it will develop over time.  Typical research then concerns the design of algorithms under the assumption that all these aspects have already been specified (with the common exception of still needing to do some learning about the environment).   However, as we design real AI systems, we in fact need to specify where the boundaries between one agent and another in the system lie, what objective functions these agents aim to maximize, and to some extent even what belief formation processes they use.  The premise of this research is that as AI is being broadly deployed in the world, we need well-founded theories of, and methodologies and algorithms for, how to design preferences, identities, and beliefs.  Doing so in a responsible fashion will require the development and rigorous evaluation of new techniques.  The project will address these questions from a rigorous foundation in decision theory, game theory, social choice theory, mechanism design theory, and the algorithmic and computational aspects of these fields.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1724434","Doctoral Consortium at IJCAI 2017","IIS","ROBUST INTELLIGENCE","04/01/2017","03/29/2017","Maria Gini","MN","University of Minnesota-Twin Cities","Standard Grant","Reid Simmons","03/31/2019","$25,000.00","","gini@cs.umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7495","7495, 7556","$0.00","This proposal will support US-based Ph.D. students working in artificial intelligence the opportunity to share their knowledge and interact with each other and more senior researchers, to learn about different sub-fields within AI, and to be mentored in research, publication, and career opportunities. This goal will be accomplished by partially supporting the travel costs for US-based Ph.D. students to attend the International Joint Conference on Artificial Intelligence (IJCAI), which is one of the premier international conferences on research in artificial intelligence. The conference, which in 2017 will be held in Melbourne, Australia attracts an international crowd that includes academics, industry workers, entrepreneurs, and funding agency leaders."
"1350598","CAREER: A Broad Synthesis of Artificial Intelligence and Social Choice","IIS","ROBUST INTELLIGENCE, ALGORITHMIC FOUNDATIONS","02/15/2014","01/31/2018","Ariel Procaccia","PA","Carnegie-Mellon University","Continuing grant","James Donlon","01/31/2019","$548,308.00","","arielpro@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495, 7796","1045, 7495, 7796, 7932","$0.00","Social choice theory is the field that studies the aggregation of individual preferences toward a collective choice. While the artificial intelligence (AI) community has so far played a dominant role in the study of the computational aspects of social choice, the interaction between core AI paradigms and social choice theory has been surprisingly limited. <br/><br/>This project is enhancing the interaction between the two fields through a synthesis of social choice with the following AI areas: (i) decision making under uncertainty, by building on models studied in AI to create new ways to model, analyze, and make decisions in environments where preferences are dynamically changing; (ii) multiagent systems, by studying settings where agents randomly vote over multiple states, and investigating the connection between normative properties and system performance; and finally (iii) machine learning, by employing insights about strategic behavior under structured preferences, developed in the social choice literature, in order to design regression learning algorithms that discourage strategic manipulation.<br/><br/>An overarching goal of this project is to demonstrate the potential of social choice theory to AI researchers, and ultimately to establish social choice theory as a standard paradigm in AI. Equally importantly, this project is expected to increase the scope of social choice theory. Broader impacts include a new web-based voting system, which has the potential to serve and educate hundreds of thousands of users; dissemination through a new book on computational social choice; and a workshop on computational social choice, which will help set a new agenda for the field."
"1806332","SCH: EXP: Intelligent Clinical Decision Support with Probabilistic and Temporal EHR Modeling","IIS","Smart and Connected Health","08/15/2017","11/17/2017","Sriraam Natarajan","TX","University of Texas at Dallas","Standard Grant","Sylvia J. Spengler","12/31/2018","$127,346.00","","sriraam.natarajan@utdallas.edu","800 W. Campbell Rd., AD15","Richardson","TX","750803021","9728832313","CSE","8018","8018, 8061","$0.00","Clinical decision support has the potential to reduce healthcare costs and improve patient outcomes, while shedding light into policy questions surrounding healthcare costs and practices in the US.  This project aims to develop intelligent clinical decision support techniques for recommending optimal action plans - including both diagnostic tests and medical interventions - for treating chronic disease, performing multi-step and adaptive treatments, and modifying long-term health habits. In an effort to integrate evidence-driven decision-making with established clinical practices, the research will develop disease-agnostic artificial intelligence techniques that combine data from large electronic health records (EHRs) with recommendations from human experts. A prototype decision support system will be tested on three clinical settings - cardiology, clinical depression, and emergency room readmission - using existing EHR datasets and consultation with domain experts from clinical partners. Outcomes-driven and cost-driven optimized decisions will be compared to current clinical practice. This exploratory research will provide the groundwork for follow-up projects in decision support information presentation, integration with clinical workflow and IT systems, and making the transition from retrospective studies to clinical trials.  Other broader impacts include workshops for healthcare applications of AI, and women and minority students will be recruited and mentored in graduate and undergraduate computer science research.<br/><br/>The technical approach of this research builds on state-of-the-art machine learning and artificial intelligence methods to automatically learn, simulate, and reason about patient-specific treatment plans.  Such methods must be simultaneously probabilistic and temporal.  Probabilistic techniques are needed to handle significant uncertainties in clinical diagnoses and outcomes, much like a human clinician would.  Temporal techniques are needed to consider sequences of future decisions over the course of treatment, rather than decisions at single time points.  More specifically, this project will consider the use of statistical relational learning (SRL) techniques to mine for probabilistic, temporal patterns in large electronic health records, and these patterns will be used in partially-observable Markov decision processes (POMDPs) that exhaustively search for optimal treatment sequences. Recent results indicate that SRL achieves superior performance to other machine learning methods in predicting cardiac arrest from demographic and lifestyle observations, and POMDP treatment plans outperform existing fee-for-service practices by reducing costs by 50% and improving outcomes by 40% on a clinical depression dataset.  By combining SRL and POMDPs, specifically, using SRL to learn a disease progression model used by the POMDP, this project aims to achieve further improvements in recommendation quality and computational scalability for complex treatments.  Furthermore, because EHRs may suffer from limited or missing data, clinical decision support tools should follow established practices and expert knowledge when necessary.  To do so, new workflows for integrating expert knowledge into SRL and POMDPs will be explored.  Evaluation will be performed on a variety of disease scenarios in conjunction with clinical partners at Marshfield Clinic, Centerstone, Wake Forest School of Medicine, and South Bend Memorial Hospital."
"1734304","CompCog: Computational, distributed accounts of human memory: improving cognitive models","BCS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","08/01/2017","07/19/2017","David Reitter","PA","Pennsylvania State Univ University Park","Standard Grant","Lawrence Gottlob","07/31/2020","$499,969.00","","reitter@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","SBE","7252, 7495","7252, 7495","$0.00","Memory is among the most impressive aspects of human cognition, allowing us to learn new words or new ideas from just a few examples.  However, the scientific understanding of how this learning occurs is limited.  This research project focuses on how learning occurs in the context of memory for language. Within the human mind, there is something like a dictionary that tells people what words mean (semantics) and how words are combined to make grammatical sentences (syntax). How does the mind learn this dictionary from experience with a language? Computer simulations can help science better understand this learning process. This scientific understanding can, in turn, help teach languages in the classroom and aid in the early detection of language deficits, whether it be developmental deficits in children, or age-related deficits in adults. Furthermore, improving the ability of computers to simulate language learning processes can also lead to the development of better technology such as machine translation, web search, and virtual assistants.  This project considers how a better understanding of language learning can help us avoid common pitfalls of memory connected to the use of language.  For example, humans easily over-generalize and judge a ""book by its cover"", associating certain occupations or personality traits with a gender.  If we know how people come up with associations between words and concepts, we can also detect and prevent prejudices in language to help ensure that artificial intelligence applications, such as web search, do not produce prejudiced results.  The project supports an interdisciplinary and diverse team of researchers and students at Penn State, attracting college students to engage with research in cognitive science and artificial intelligence.<br/><br/>In this project, the researchers are designing a new model of human memory, the Hierarchical Holographic Model.   This computational model helps explain certain aspects of how words and languages are learned.  The model draws on the successes of artificial intelligence and deep neural networks, and applies these insights to psychology.   With this model, the researchers investigate the question of whether human memory has the ability to detect arbitrarily indirect associations between concepts.  The model uses a recursive learning process, building on previously learned knowledge to acquire new knowledge, which allows the model to learn arbitrarily indirect and abstract relationships between words. The researchers consider evidence that sensitivity to abstract relations between words improves the ability of the computer model to learn syntax, such as parts-of-speech, and to use words appropriately to construct grammatical sentences. This work will be assessed against human language data and competing computational models. The success of the computational model should provide evidence that (1) language acquisition depends on indirect associations, and (2) human memory must be able to form indirect associations to facilitate it."
"1657613","CRII: RI: Inference for Probabilistic Programs: A Symbolic Approach","IIS","CRII CISE Research Initiation","03/01/2017","02/21/2017","Guy Van den Broeck","CA","University of California-Los Angeles","Standard Grant","Weng-keen Wong","02/28/2019","$174,639.00","","guyvdb@cs.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","CSE","026Y","7495, 8228","$0.00","Probabilistic machine learning and artificial intelligence have revolutionized the world and are present in most aspects of our life. However, the tools used to develop probabilistic machine learning solutions are limited in what they can express. Moreover, they require significant expert knowledge, and are not accessible to scientists in each discipline, let alone everybody else. Probabilistic programming aims to make probabilistic machine learning accessible to all, and as easy to program as a phone application. To make this dream a reality, probabilistic program execution, making probabilistic predictions from observations, has to become as highly efficient and robust as our current non-probabilistic software tools. This project develops general-purpose algorithms to execute probabilistic programs efficiently, using advanced symbolic reasoning techniques from artificial intelligence. Moreover, it does so for probabilistic programs that are significantly more complex than the ones in use today, involving a wide range of programming language features that are both discrete and continuous. This increase in scalability and expressive power will foster novel, increasingly advanced machine learning applications. <br/><br/>More specifically, probabilistic programs subsume classical probabilistic graphical models and are additionally able to capture complex probabilistic dependencies that include arbitrary pieces of executable code. While many expressive probabilistic programming languages have been proposed in recent years, the current bottleneck and barrier to success is the lack of general-purpose reasoning algorithms to perform inference with probabilistic programs efficiently. This research tackles two key problems in probabilistic program inference. First, current sampling-based algorithms have problems reasoning about dependencies between large numbers of discrete random variables and explaining low-probability observations. In one thrust, this project develops new inference algorithms based on knowledge compilation. This technique compiles the program into a symbolic structure that is efficient for probability computation. The algorithm does not compile the entire program, which is generally intractable, but uses importance sampling on partially compiled programs to sample efficient subprograms. This combines the best of approximate program evaluation by sampling with highly efficient compilation techniques for exact inference. Second, symbolic approaches to inference are fundamentally discrete and have problems dealing with continuous and integer variables, which frequently appear in real code. Conversely, algorithms for continuous distributions cannot efficiently handle discrete program structure. In another thrust, this project studies symbolic approaches to probabilistic reasoning in programs with both types of structure, using recent breakthroughs based on satisfiability modulo theories and hashing-based sampling. This project provides a scientific leap at a fundamental level. It also provides a context for training undergraduate and graduate students in subjects spanning machine learning, artificial intelligence, statistics, and programming languages, and targets the integration of probabilistic programming into computer science curricula."
"1740197","E2CDA: Type I: Collaborative Research: Energy-Efficient Artificial Intelligence with Binary RRAM and Analog Epitaxial Synaptic Arrays","CCF","Energy Efficient Computing: fr","09/15/2017","07/23/2018","Saibal Mukhopadhyay","GA","Georgia Tech Research Corporation","Continuing grant","Sankar Basu","08/31/2020","$162,412.00","","saibal@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","015Y","7945, 8089","$0.00","In recent years, deep learning and artificial neural networks have been very successful in large-scale recognition and classification tasks, some even surpassing human-level accuracy. However, state-of-the-art deep learning algorithms tend to present very large network models, which poses significant challenges for hardware, especially for memory. Emerging resistive devices have been proposed as an alternative solution for weight storage and parallel neural computing, but severe limitations still exist for applying resistive random access memories (RRAMs) for practical large-scale neural computing. This proposal targets on addressing limitations in resistive device based neural computing through novel device engineering, new bitcell designs, new neuron circuits, energy-aware architecture, and a new circuit-level benchmark simulator. A successful completion of this research is likely to have consequences to our society, enabling wide adoption of dense and energy-efficient intelligent hardware to power-/area-constrained local mobile/wearable devices. Furthermore, a self-learning chip that learns in near real-time and consumes very low-power can be integrated in smart biomedical devices, personalizing healthcare. This project will have a strong effort on integrating the research outcomes with education and outreach through summer outreach programs for high school students, undergraduate/graduate student training, and organization of tutorials and workshops at conferences for knowledge dissemination.<br/><br/>The proposal will perform  interdisciplinary research to address many limitations in today's resistive device based neural computing and make a leap progress towards energy-efficient intelligent computing. Severe limitations of applying resistive random access memories (RRAMs) for practical large-scale neural computing include: (1) device-level non-idealities, e.g., non-linearity, variability, selector, and endurance, (2) inefficiency in representing negative weights and neurons, and (3) limited demonstration on simpler networks, instead of cutting-edge convolutional and recurrent neural networks. To address these limitations, novel technologies from devices to architectures will be investigated. First, new bitcell circuits will be designed for today's binary resistive devices, efficiently mapping XNOR functionality with (+1, -1) weights and neurons. Second, a novel epitaxial resistive device (EpiRAM) that exhibits many idealistic properties will be investigated, including linear programming for analog weights, suppressed variability, self-selectivity, and high endurance. Third, new neuron circuits will be explored for integration with new resistive devices for feedforward/feedback deep neural networks. Finally, new data-mapping techniques that efficiently map state-of-the-art deep neural networks onto the hardware framework with RRAM arrays will be developed, and the overall energy-efficiency will be verified with a new benchmark simulator ""NeuroSim"". With innovations across material, device, circuit and architecture,  research needs will be pursued towards energy-efficient processing in ubiquitous resource-constrained hardware systems."
"1840433","Planning Grant: Engineering Research Center for Infrastructure Finance through Intelligent Design and Operations (InFinIDO)","EEC","ENGINEERING RESEARCH CENTERS","09/01/2018","08/31/2018","Peter Adriaens","MI","University of Michigan Ann Arbor","Standard Grant","Eduardo A. Misawa","08/31/2019","$100,000.00","Debra Reinhart, Jerome Lynch, Liad Wagman, Matthew Dixon","adriaens@engin.umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","ENG","1480","1480","$0.00","The Planning Grants for Engineering Research Centers competition was run as a pilot solicitation within the ERC program.  Planning grants are not required as part of the full ERC competition, but intended to build capacity among teams to plan for convergent, center-scale engineering research.<br/><br/>Public infrastructure investment in the US is woefully inadequate, not only to maintain existing demands, but more importantly to meet the needs of an increasingly data-driven economy. The transition to a data-driven economy depends on so-called ?smart cities? which monitor information on city utilities and operations and can respond to changing situations.  Smart infrastructure systems are in an early development stage with rapidly developing applications across water, energy, transportation and buildings. Increasingly, the data analysis skills needed for engineering smart cities, are the same skills needed for many financial models and transactions. Evidence suggests that the very data smart cities collect can lead to new financing models that help fund their development.  The planning grant team will bring together experts in these areas, as well as policy and law.  The goal is to integrate engineering design and financial models in a decision framework that seeks to overcome technical and legal barriers for deployment of intelligent infrastructures.  The societal benefits of this transition include identifying new financial instruments and resources that impacts GDP and jobs, and improves quality of life. Collaboration with public policy experts will explore how smart infrastructures can provide equitable access across rich and poor communities.  Engagement with law school colleagues will address privacy and security concerns, and the impact of data monetization on the financial system. New educational programs such as a Masters in Engineering in Smart Infrastructure Finance will be aimed at training new engineers in the era of artificial intelligence. Training will help engineers engage with business and key civic stakeholders. The described interactions between these disciplines will result in new technologies that stimulate a vibrant innovation ecosystem and facilitate access and use of these technologies. <br/><br/>The planning grant team will explore how sensor-enabled (smart) data networks provide intelligence for the design of efficient financing mechanisms to build and operationalize smart (adaptive, resilient) infrastructure systems. The planning grant activities, including two workshops, will allow the team to engage with potential academic, business and government partners. Despite the excitement, the scalability of smart city infrastructure is hampered by limited operational benchmarking, lack of robust economic models for valuation of information, and pricing mechanisms that may attract public or private investment. The research tests the hypothesis that intelligent infrastructures generate data of sufficient scope, scale, frequency and accuracy that can be aligned with, and tested against, financial models and specifications of emerging data markets.  Through these planning workshops, the proposed Center research activities and strategies to collaborate with industry, investors and the public will be further defined. The objective is to understand how physical or operational performance measurements of smart systems not only enable performance optimization or design iterations, but bring derivative value that can be used or traded in data exchanges.  How can intelligent infrastructures be safely designed - and the IoT data tested - against financial or auction models for value optimization?  Data-driven efficient capital such as insurance and derivatives (futures, options), as well as variable rate performance bonds and smart contracts, increasingly depend on real-time IoT (Internet of Things) information.  In cooperation with industry and public partners, the ERC planning grant team will develop, test and validate engineering models, econometric and financial theory principles using sensor and financial data models in a simulation environmental, and well as based on deployed pilot smart infrastructure systems.  These include smart city components such as: (storm)water utilities, intelligent transportation (roads and bridges), energy systems, and green buildings. The proposed ERC envisions structuring three trust areas reflecting complementary disciplines: (i) Risk quantification and dynamic characterization of infrastructure system data; (ii) Financial risk modeling, pricing, and information valuation in privacy- and cyber security-constrained data markets; (iii) Decision feedback models for infrastructure design, resilience management, and new investment paradigms.  The integration of engineering design with information valuation and pricing, and policy is an emerging field of inquiry and practice with implications for future designs of smart infrastructures.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1838236","BIGDATA: IA: Collaborative Research: Intelligent Solutions for Navigating Big Data from the Arctic and Antarctic","IIS","Big Data Science &Engineering","09/01/2018","08/30/2018","John Paden","KS","University of Kansas Center for Research Inc","Standard Grant","Sylvia J. Spengler","08/31/2022","$373,338.00","","paden@ku.edu","2385 IRVING HILL RD","LAWRENCE","KS","660457568","7858643441","CSE","8083","062Z, 8083, 9150","$0.00","The objective of this research is to investigate artificial intelligence (AI) solutions for data collected by the Center for Remote Sensing of Ice Sheets (CReSIS) in order to provide an intelligent data understanding to automatically mine and analyze the heterogeneous dataset collected by CReSIS. Significant resources have been and will be spent in collecting and storing large and heterogeneous datasets from expensive Arctic and Antarctic fieldwork (e.g. through NSF Big Idea: Navigating the New Arctic). While traditional analyses provide some insight, the complexity, scale, and multidisciplinary nature of the data necessitate advanced intelligent solutions. This project will allow domain scientists to automatically answer questions about the properties of the data, including ice thickness, ice surface, ice bottom, internal layers, ice thickness prediction, and bedrock visualization. The planned approach will advance the broader big data research community by improving the efficiency of deep learning methods and in the investigation of methods to merge data-driven AI approaches with application-specific domain knowledge. Special attention will be given to women and minority involvement in the research and the project will develop new course materials for several classes in AI at a Hispanic and minority serving institute.<br/><br/>In polar radar sounder imagery, the delineation of the ice top and ice bottom and layering within the ice is essential for monitoring and modeling the growth of ice sheets and sea ice. The optimal approach to this problem should merge the radar sounder data with physical ice models and related datasets such as ice coverage and concentration maps, spatiotemporal meteorological maps, and ice velocity. Rather than directly engineering specific relations into the image analysis that require many parameters to be defined and tuned, data-dependent approaches let the machine learn these relationships. To devise intelligent solutions for navigating the big data from the Arctic and Antarctic and to scale up the current and traditional techniques to big data, this project plans several approaches for detecting ice surface, bottom, internal layers, 3D modeling of bedrock and spatial-temporal monitoring of the ice surface: 1) Devise new methodologies based on hybrid networks combining machine learning with traditional domain specific knowledge and transforming the entire deep learning network to the time-frequency domain. 2) Equip the machine with information that is not visible to the human eye or that is hard for a human operator to consider simultaneously, to be able to detect internal layers and 3D basal topography on a large scale. Using the results of the feature tracking of the ice surface in radar altimetry, the research effort will also develop new data-dependent techniques for predicting the ice thickness for following years based on deep recurrent neural networks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1840446","Planning Grant: Engineering Research Center for Augmentation Systems and Intelligent Support Technologies for Aging (ASISTa-ERC)","EEC","ENGINEERING RESEARCH CENTERS","09/01/2018","08/29/2018","Gregory Hager","MD","Johns Hopkins University","Standard Grant","Dana Denick","08/31/2019","$100,000.00","Elizabeth Mynatt, Wendy Rogers, Sarah Szanton","hager@cs.jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","ENG","1480","124E, 1480","$0.00","The Planning Grants for Engineering Research Centers competition was run as a pilot solicitation within the ERC program.  Planning grants are not required as part of the full ERC competition, but intended to build capacity among teams to plan for convergent, center-scale engineering research.<br/><br/>The objective of this planning grant is to further develop the goals and organization of the proposed ASISTa-ERC. The ASISTa-ERC will explore the use of technology to enhance the lives of the growing population of older adults and their caregivers. To do so, it will leverage advances in artificial intelligence, robotics, human-computer interaction, and mobile sensing and computing to create intelligent environments that augment cognitive ability, support physical activities, and amplify social and emotional support for aging individuals, their support network, and their caregivers. These environments will be designed to track individuals over time and adapt to changes in their daily life and their evolving healthcare needs. By enhancing and supporting the growing population of older adults and their caregivers, the work of the ASISTa-ERC will create significant economic and social benefits for older adults and their families. It will also create a new platform to support a rapidly growing workforce devoted to care for aging adults, and a unified framework for new commercial innovations.<br/><br/>The planning activities will refine the research, workforce development, culture of inclusion, and innovation programs of the ASISTa-ERC through a series of three meetings. These meetings will explore three cross-cutting themes: physical support, cognitive support, and social support. They will develop a strategy for creating systems addressing these opportunities that have three key properties: intelligence, interactivity, and individualization (I3). Intelligent systems employ models that can classify and anticipate patterns of activity, and respond to those patterns in ways that most enhance the quality of life of the individual. Interactive systems exploit advanced sensing and human-computer interaction to observe, engage and respond in an appropriate manner. Individualized systems adapt the blend of cognitive, social, and physical support to each unique life situation, and evolve that blend of support as the individual ages and life circumstances change.  All development efforts will be user-centered and user-informed to increase acceptance and adoption by the target populations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1745463","Convergence HTF: A Research Coordination Network to Converge Research on the  Socio-Technological Landscape of Work in the Age of Increased Automation","IIS","INSPIRE","01/01/2018","08/23/2017","Kevin Crowston","NY","Syracuse University","Standard Grant","Meghan Houghton","12/31/2022","$499,796.00","Jeffrey Nickerson, Ingrid Erickson","crowston@syr.edu","OFFICE OF SPONSORED PROGRAMS","SYRACUSE","NY","132441200","3154432807","CSE","8078","060Z, 063Z","$0.00","The landscape of jobs and work is changing rapidly, driven by the development of new technologies. Intelligent, automated machines and services are a growing part of jobs and the workplace. New technologies are enabling new forms of learning, skills assessments, and job training. The potential benefits of these technologies include increased productivity and job satisfaction, and more job opportunities. But technology connected to work can also come with risks. This research coordination network (RCN) addresses the future of work at the human-technology frontier by focusing on the use of intelligent machines in work settings. The RCN supported by this award will promote convergence across computer science, engineering, and social and behavioral science disciplines to define and address key challenges and research imperatives in the future of work at the human-technology frontier with intelligent machines. This convergence RCN will employ deep integration of knowledge, theories, methods, and data from multiple fields to form new and expanded frameworks for addressing scientific and societal challenges and opportunities. The results will include the identification and sharing of new research directions and tools to reinforce positive outcomes and mitigate negative consequences of intelligent machines in work settings. Ultimately this has the power to strengthen the U.S. economy, and improve worker performance and job satisfaction.<br/><br/>This RCN will focus on advancing the knowledge needed to develop actionable design principles that attend to both sides of the human-technology frontier in work settings that use intelligent machines. Such machines include not only autonomous robots and vehicles, but also algorithms and machine learning processes that support all types of autonomous behavior. At present, the technology side of this frontier is advancing more rapidly than the human side: people, organizations, legal frameworks, and social values, to name a few. What is necessary to bring these two side into alignment is a systems design approach that draws on both social and technological requirements as well as their interdependencies. This RCN aims to adopt this goal, thereby developing the knowledge needed to ensure that the benefits of intelligent machines are gained while the negative consequences reduced.<br/><br/>This RCN will bring together investigators from many disciplines including computer science (artificial intelligence, machine learning), robotics, human computer interaction, cognitive science, economics, sociology, law, organizational science, ergonomics, industrial and organizational psychology, engineering, and information systems, to communicate, coordinate, and integrate their research and educational activities across disciplinary and organizational boundaries. Toward this goal, this award will support three primary RCN activities over its five-year term. First, the RCN will organize annual Convergence Conferences that will focus on the contribution of convergent research on topics regarding the socio-technological landscape of work in the age of increased automation. Second, it will support a series of workshops at different disciplinary conferences to expand the reach of the network and to consolidate, test, verify, and evolve research ideas as they develop. Third, the RCN will maintain a set of shared online resources to support the community and its research efforts."
"1717062","SaTC: CORE: Small: Scalable and Meaningful Threat Intelligence Generation","CNS","Secure &Trustworthy Cyberspace","08/15/2017","08/07/2017","Damon McCoy","NY","New York University","Standard Grant","Dan Cosley","07/31/2020","$492,064.00","","dm181@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","8060","025Z, 7434, 7923, 9102","$0.00","Threat intelligence is used by organizations to protect systems and end-users by detecting and blocking communications with known attackers' systems. Quality threat intelligence can also provide methods of detecting attackers' tools, which are often less ephemeral than their attack infrastructure.Unfortunately, producing quality threat intelligence is often a highly manual and inefficient process.This has resulted inlimitedamounts of useful threat intelligence which is availableonly tothose companies that can afford it. This research develops new data-analytics methods to identifyan attacker's infrastructure and attack tools. Our methods leverage the ability toefficiently collectlarge amountsof raw attacker data, process it, and build artificial intelligence techniques to discover attack patterns. This project improves the efficiency of generating high quality threat intelligence data, and makes it more affordable to a large range of companies.<br/><br/>Achieving this goal of improving the efficiency of generating useful threat intelligence requires progress on several key challenges. The project (i) investigates supervised machine learning based methods for efficiently collected large-scale amounts of data from attackers, (ii)improvesmethods for storing this data and other freely available raw threat intelligence data such that it can be easily joined, (iii) identifies robust features that can be extracted from this raw datawhichcan be used for training supervised machine learning detection techniques,and(iv) enables high performance and efficient generation of large-scale useful threat intelligence data.Consequently, this research has the potential to transform the way in which threat intelligence data is produced and improve the security of organizations by making threat intelligence more accessible. This work also creates many educational opportunities for undergraduate and graduate students to gain experience using data-analytics techniques to efficiently detect emerging threats and improve the security of organizations."
"1738441","SBIR Phase II:  Pushing the Boundaries of Intelligent Assistants for Financial Services","IIP","SMALL BUSINESS PHASE II","09/15/2017","09/18/2017","Michael Laurenzano","MI","Clinc, Inc","Standard Grant","Peter Atherton","08/31/2019","$750,000.00","","mike@clinc.com","1940 Hedgenettle Ct.","Ann Arbor","MI","481039689","8582053027","ENG","5373","5373, 8033","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project is in providing state-of-the-art tools allowing anyone to build and deploy domain specific commercial intelligent virtual assistant (IVA) solutions. These tools allow others to understand how IVAs should be architected and integrate IVA technology into their offerings. IVAs have shown promise in numerous commercial domains including financial services, healthcare, education, law enforcement, and retail, to name a few, reducing the barrier to knowledge access within domains by providing a medium for people to converse naturally with sophisticated computer and information systems.<br/><br/>This Small Business Innovation Research (SBIR) Phase II project will address the significant technological challenges involved when scaling the domains and capabilities of an Intelligent Virtual Assistant (IVA). This project will innovate in designing scalable artificial intelligence models capable of learning and identifying hundreds or thousands of learned concepts, and designing the accompanying system architecture to support the growing compute demand of sophisticated algorithms. Specifically, the project aims at achieving: (1) Scalable Intelligence: the ability to handle hundreds or thousands of competencies and extractable semantic concepts, allowing users to interact with the system with unbounded, unconstrained language; (2) Customizable Intelligence: the ability to allow customers to (semi-) automatically train and (re)train and customize the intelligence on demand (adding new competencies, identifying new slot-value pairs, modify responses); (3) Conversational Complexity: support multi-turn conversations, where the context from prior utterances is used to refine and understand what the end-user is trying to accomplish; and (4) Scalable System Infrastructure: enhance open source IVA software infrastructure to seamlessly scale up and down the computational resources allocated for each intelligence engine based on load."
"1838230","BIGDATA: IA: Collaborative Research: Intelligent Solutions for Navigating Big Data from the Arctic and Antarctic","IIS","POLAR CYBERINFRASTRUCTURE, EarthCube, Big Data Science &Engineering","09/01/2018","08/30/2018","Maryam Rahnemoonfar","TX","Texas A&M University Corpus Christi","Standard Grant","Sylvia J. Spengler","08/31/2022","$612,823.00","","maryam.rahnemoonfar@tamucc.edu","6300 Ocean Drive, Unit 5844","Corpus Christi","TX","784125844","3618253882","CSE","5407, 8074, 8083","062Z, 8083, 9102","$0.00","The objective of this research is to investigate artificial intelligence (AI) solutions for data collected by the Center for Remote Sensing of Ice Sheets (CReSIS) in order to provide an intelligent data understanding to automatically mine and analyze the heterogeneous dataset collected by CReSIS. Significant resources have been and will be spent in collecting and storing large and heterogeneous datasets from expensive Arctic and Antarctic fieldwork (e.g. through NSF Big Idea: Navigating the New Arctic). While traditional analyses provide some insight, the complexity, scale, and multidisciplinary nature of the data necessitate advanced intelligent solutions. This project will allow domain scientists to automatically answer questions about the properties of the data, including ice thickness, ice surface, ice bottom, internal layers, ice thickness prediction, and bedrock visualization. The planned approach will advance the broader big data research community by improving the efficiency of deep learning methods and in the investigation of methods to merge data-driven AI approaches with application-specific domain knowledge. Special attention will be given to women and minority involvement in the research and the project will develop new course materials for several classes in AI at a Hispanic and minority serving institute.<br/><br/>In polar radar sounder imagery, the delineation of the ice top and ice bottom and layering within the ice is essential for monitoring and modeling the growth of ice sheets and sea ice. The optimal approach to this problem should merge the radar sounder data with physical ice models and related datasets such as ice coverage and concentration maps, spatiotemporal meteorological maps, and ice velocity. Rather than directly engineering specific relations into the image analysis that require many parameters to be defined and tuned, data-dependent approaches let the machine learn these relationships. To devise intelligent solutions for navigating the big data from the Arctic and Antarctic and to scale up the current and traditional techniques to big data, this project plans several approaches for detecting ice surface, bottom, internal layers, 3D modeling of bedrock and spatial-temporal monitoring of the ice surface: 1) Devise new methodologies based on hybrid networks combining machine learning with traditional domain specific knowledge and transforming the entire deep learning network to the time-frequency domain. 2) Equip the machine with information that is not visible to the human eye or that is hard for a human operator to consider simultaneously, to be able to detect internal layers and 3D basal topography on a large scale. Using the results of the feature tracking of the ice surface in radar altimetry, the research effort will also develop new data-dependent techniques for predicting the ice thickness for following years based on deep recurrent neural networks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1715475","RI: Small: Integrating Flexible Normalization Models of Visual Cortex into Deep Neural Networks","IIS","ROBUST INTELLIGENCE","09/01/2017","08/17/2017","Odelia Schwartz","FL","University of Miami","Standard Grant","Kenneth C. Whang","08/31/2020","$349,996.00","","odelia@cs.miami.edu","1320 S. Dixie Highway Suite 650","CORAL GABLES","FL","331462926","3052843924","CSE","7495","7495, 7923, 8089","$0.00","Recent advances in artificial intelligence models of deep neural networks have led to tremendous progress in artificial systems that recognize objects in scenes, and in a host of other applications such as speech recognition, and robotics. Although deep neural networks often incorporate computations inspired by the brain, these have typically been applied in a fairly simple and restrictive manner, rather than based on more principled models of neural processing in the brain. Using vision as a paradigmatic example, this project proposes that artificial systems can benefit from integrating approaches that have been developed in biological models of neural processing of scenes. The biological models make use of contextual flexibility, whereby neurons are influenced in a rich way by the image structure that spatially surrounds a given object or feature. This flexibility is expected to improve task performance in deep neural networks, and to impact development of artificial systems that are more compatible with human cognition. The resulting framework, with its deep architecture spanning multiple layers of processing, will, in turn, make predictions about neural processing in the brain, which will impact the neuroscience and cognitive science communities. <br/><br/>This project focuses specifically on normalization, a nonlinear computation that is ubiquitous in the brain, and that has been shown to benefit task performance in deep neural networks. The project will develop more principled strategies for determining normalization in deep convolutional neural networks. The main focus will be on learning a form of flexible normalization based on scene statistics models of visual cortex. In this framework, normalization is recruited only to the degree that a visual input is inferred to contain statistical dependencies across space. Performance will be tested for classification and segmentation on large-scale image databases, and will also target tasks more suited to mid-level vision such as figure/ground judgment. This will result in better understanding of normalization nonlinearities in deep convolutional networks, and the implications of flexible normalization for task performance and generalization compared to other forms of normalization. Biologically, normalization is poorly understood beyond primary visual cortex. The models developed will help shed light on the equivalence of this inference for middle cortical areas, and make predictions about what image structure leads to recruitment of normalization. This project will also include launching of an interdisciplinary Deep Learning Discussion Group."
"1724392","S&AS: FND: Long-Term Planning and Robust Plan Execution for Multi-Robot Systems","IIS","S&AS - Smart & Autonomous Syst","09/01/2017","07/27/2017","Sven Koenig","CA","University of Southern California","Standard Grant","James Donlon","08/31/2020","$599,999.00","Nora Ayanian","skoenig@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","039Y","046Z, 9102","$0.00","How can multi-robot teams maneuver in tight and cluttered environments when ""no plan survives contact"" with reality?  Traditional approaches plan for idealized situations and must patch up maneuvers when sensors or actuators are imprecise, making them neither robust nor safe.  This project, a collaboration of PIs from artificial intelligence and robotics, will investigate fundamental research to capture and use timing and uncertainty constraints in  large robot navigation and coordination problems.  The target applications are just-in-time manufacturing and automated warehousing, but the results will extend beyond to many applications of smart and autonomous systems that need reliable and safe planning.  <br/><br/>The project will study Multi-Agent Path Finding (MAPF), which is an NP-hard planning problem that belongs to a class of important planning problems, namely multi-agent navigation problems with temporal and spatial constraints.  The research will relax simplifying assumptions typically made by MAPF solvers, namely that plan execution is perfect and stops once all robots have reached their goal locations.  Many AI planning methods that have been developed are not used on robots, since planning/scheduling uses idealized models of the environment and plan execution is never perfect, and there is often insufficient time for re-planning if execution deviates from the plan. This project will develop well-founded planning and plan-execution methods, based on probabilistic and temporal reasoning, that fuse ideas from robotics and artificial intelligence.  In particular, the PIs will combine advances in planning algorithms from the AI community, namely Simple Temporal Networks (STN), and adapt them to the robotics domain by adding timely execution constraints, as well as sensor, actuator, and model uncertainties.   They will make project results (such as papers, videos and code) available on their web pages, present tutorials on their research results to the artificial intelligence and robotics research communities, develop teaching material for multi-robot planning, and integrate undergraduate students into their research activities."
"1838702","SCH: INT: Connected Smart Hospitals Enabled by Visible Light Communication","IIS","Smart and Connected Health","09/15/2018","09/07/2018","Albert Wang","CA","University of California-Riverside","Standard Grant","Sylvia J. Spengler","08/31/2022","$1,200,000.00","Yehuda Kalay, Gang Chen, Ramdas Pai","aw@ee.ucr.edu","Research & Economic Development","RIVERSIDE","CA","925210217","9518275535","CSE","8018","8018, 8062","$0.00","Transformation in health and medicine calls for innovation and integration of information science and engineering approaches to revolutionize healthcare delivery systems, including high-performance wireless communication and sensing technologies. Radio-frequency (RF) wireless technologies can interfere with sensitive medical equipment, hence are not universally accepted in hospitals. This research will develop and apply a visible light communication platform technology, overlaying the existing lighting infrastructure using emerging greener solid-state light-emission diode bulbs, for live tracking and efficient networking to enable smart, connected and efficient hospitals. The scope of work and contributions include developing a novel radio-frequency-free harmless light-emission diode based visible light communication platform technology to enable two-way real-time light-based tracking and networking for smart and connected hospitals, a dynamic event-based behavioral model to simulate building-user interactions in hospital settings, and an artificial intelligence enhanced algorithm to facilitate people-data-system-connected intelligent healthcare ecosystems. Success of the proposed research will transform the field of medicine and health, and achieve affordable and efficient healthcare delivery. The research outcomes will have tremendous societal and economic impacts to the nation and humanity.<br/><br/>The goal of this four-year project is to develop and apply a transformative tracking, networking and operation technologies, using visible light communication (VLC) technology, to enable smart, connected and efficient hospitals. The technical approach will be to overlay the innovative light emission diode (LED) based VLC platform technology on the existing LED lighting infrastructure in a hospital to provide a wireless network for real-time visible light tracking and communications without using radio-frequency (RF) signals, which can interfere with sensitive medical equipment. The technical contributions include novel RF-free LED-based VLC platform technologies and system-on-a-chip solutions to enable two-way real-time visible light tracking and networking for smart and connected hospitals, new dynamic event-based behavioral models to simulate building-user interactions in hospital settings, and innovative artificial intelligence enhanced algorithms to facilitate people-data-system-connected intelligent healthcare delivery ecosystems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1649972","CAREER: Adversarial Artificial Intelligence for Social Good","IIS","ROBUST INTELLIGENCE","03/01/2017","02/14/2018","Yevgeniy Vorobeychik","TN","Vanderbilt University","Continuing grant","Reid Simmons","02/28/2022","$198,977.00","","Yevgeniy.Vorobeychik@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","CSE","7495","1045, 7495","$0.00","The success of AI technologies has resulted in their widespread deployment, with algorithms for reasoning under uncertainty, such as machine learning, having a particularly high impact.  A challenge that is often ignored, however, is the adversarial nature of many domains, in which social, economic, and political interests may try to manipulate intelligent systems into making costly mistakes.  While AI has a long history in playing adversarial games, such as chess and poker, the approaches have not been appropriate for many real-world situations.  The goal of the proposed research is to develop a general framework for adversarial AI that is far broader in scope and applicability, building on insights from game theory, AI planning, and cybersecurity.<br/><br/>A key modeling insight of the proposed research is that attacks across a broad array of settings can be modeled as planning problems, so that robust algorithms can be fundamentally viewed as interdicting attack plans.  Our research will develop new foundational techniques for scalable plan interdiction under uncertainty, building off of the framework of Stackelberg games. Proposed techniques will leverage a combination of abstraction, factored representation of state, and value function approximation.  In addition, novel scalable algorithms will be developed for multi-stage interdiction problems, modeled as sequential stochastic games, considering both perfect and imperfect information. Moreover, the research will make novel modeling and algorithmic contributions in multi-defender and multi-attacker interdiction games.  Finally, in the more applied arena, the research will make significant intellectual contributions in applying advances in adversarial AI to model problems exhibiting important adversarial aspects, such as privacy-preserving data sharing, access control and audit policies, and vaccine design.<br/>"
"1809458","From AlphaGo to Power System Artificial Intelligence","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/15/2018","08/15/2018","Fangxing Li","TN","University of Tennessee Knoxville","Standard Grant","Anthony Kuh","07/31/2021","$330,000.00","","fli6@utk.edu","1 CIRCLE PARK","KNOXVILLE","TN","379960003","8659743466","ENG","7607","155E, 1653","$0.00","The game of Go is an ancient board game which is considered by-far the most complex board game for computer software or artificial intelligence (AI) to solve. AlphaGo, developed by the Google DeepMind team, is the first AI application to defeat a human professional world champion. The three components in AlphaGo (Policy Network, Value Network, and Monte-Carlo Tree Search) have similarities to some classic complex power system problems. In the proposed project, several potential AI applications in electric power systems are categorized into two groups: game-based problems and search-based problems. Detailed analysis of AlphaGo-like algorithms will be investigated for game-based and search-based power system AI applications. This is particularly important under the ongoing paradigm change in power systems evidenced by increasing variable renewable generations and demand-side participations, which lead to a larger amount of data, more uncertain scenarios, and more players. Thus, the success of the proposed project can solve the emerging challenges and potentially change the operation and planning of the power grid. <br/><br/>The intellectual merit of the proposed work includes: (1) similarity comparison of the game of Go and power system problems; (2) detailed algorithm investigations for AlphaGo-like algorithms for game-based and search-based power system problems considering multistage, multiplayer, and multi-scenario studies to address emerging challenges such as high-penetration renewables and demand-side participations; and (3) an open-source software package to implement the proposed work.<br/><br/>The broader impacts lie in the opening of a new door in AI for the area of energy science and engineering. For instance, it may provide new technologies and insights for integrated multi-energy systems involving many players from different energy sectors like gas, thermal, and electricity. From the educational perspective, the results of this project will be utilized to develop new teaching materials, to promote interdisciplinary collaboration in STEM areas, to recruit underrepresented minority and female students, to continue excellence in teaching, advising, and mentoring undergraduate and graduate students, and to develop a Web-based information center with social media to disseminate research results and the open-source software package for power system AI.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1618783","RI: Small: Effective Preference Reasoning over Combinatorial Domains: Principles, Problems, Algorithms, and Implementations","IIS","ROBUST INTELLIGENCE","07/01/2016","12/22/2017","Miroslaw Truszczynski","KY","University of Kentucky Research Foundation","Standard Grant","Weng-keen Wong","06/30/2019","$457,594.00","","mirek@cs.uky.edu","109 Kinkead Hall","Lexington","KY","405260001","8592579420","CSE","7495","7495, 7923, 9150, 9251","$0.00","Preferences are fundamental attributes of human reasoning and decision making. They appear whenever a choice between alternatives is to be made. Understanding and automating preference reasoning is a major problem of artificial intelligence, especially important for the design of autonomous intelligent decision support systems. If there are few alternatives, preferences between them can be represented explicitly and preference reasoning is typically easy. However, in practice the number of alternatives facing the decision maker can be daunting in many cases.  In such cases, modeling and representing preferences of the decision maker, and automating preference reasoning based on the model are challenging. To respond to the challenge, the project will study principles and properties of preference aggregation and optimization over large domains of alternatives, and algorithms to support preference reasoning tasks; will develop methods for preference learning and approximation in support of building preference models; and will implement software for effective preference modeling and reasoning. Areas such as knowledge representation, computational social choice, and constraint solving embodied by answer-set programming and satisfiability testing will inform these studies. The project will result in a theoretical and algorithmic framework for preference reasoning over combinatorial domains, in software tools for effective preference reasoning, and in methods to integrate them into artificial intelligence decision support systems that are becoming pervasive in industrial, scientific and governmental applications. <br/><br/>The project will assume that the space of alternatives is modeled by a combinatorial domain, where alternatives are represented in terms of values of attributes relevant to decision making. While combinatorial domains are exponentially large in the number of attributes, the sets of values of individual attributes are typically small. This opens a possibility of expressing preferences over elements in a combinatorial domain in terms of preferences on attribute values and relations between the attributes. This is the setting for the project, with preference trees, CP-nets and answer set optimization programs as formal representations of preferences over combinatorial domains. The project will focus on preference aggregation and preference optimization. Finding optimal and near-optimal alternatives, finding collections of optimal or near-optimal alternatives that are in some sense diverse (or similar), and aggregating preferences that are only partially known are some examples of specific problems we will consider. As building manually preference models over large domains is infeasible, the project will study methods to learn preference models (for instance, preference trees), and develop methods for model approximation (different models have varying computational properties, and close approximations of ``hard'' models with ``easy'' ones may prove effective for reasoning with the former).  Finally, the project will develop a software suite for several key preference reasoning tasks. The implementation will exploit advances in answer-set programming and satisfiability. The resulting software will be systematically evaluated on benchmarks coming from or motivated by practical applications."
"1703161","RI: Medium: Collaborative Research: Incorporating Biological-Motivated Circuit Motifs into Large-Scale Deep Neural Network Models of the Brain","IIS","ROBUST INTELLIGENCE","10/01/2017","08/16/2017","Daniel Yamins","CA","Stanford University","Standard Grant","Kenneth C. Whang","09/30/2020","$524,779.00","","yamins@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","7495, 7924, 8089","$0.00","This project studies the effects of incorporating, into deep neural networks for visual processing, several heretofore unincorporated features of biological visual cortical circuits. Deep neural networks are artificial circuits loosely inspired by the brain's cerebral cortex. Their abilities to solve complex problems, such as recognizing objects in visual scenes, have revolutionized artificial intelligence and machine learning in recent years. The hierarchy of layers in a deep network trained for visual object recognition also provides the best existing models of the hierarchy of areas in the visual cortex implicated in object recognition (the ""ventral stream""). This project seeks to understand whether and how incorporating additional features of brain circuits may (1) improve machine learning performance, particularly on tasks that are more challenging than those typically studied; and (2) yield improved models of visual cortex. Improving the performance of deep networks would yield great benefits across wide swaths of society and industry that are impacted by advances in artificial intelligence. Improved models of visual cortex will advance understanding of cortical function, which may lead to significant further benefits for understanding normal mental functioning and perception and their potential enhancement, as well as mental illness and perceptual and cognitive deficits. <br/><br/>Deep networks currently achieve their success using almost purely feedforward processing. Yet the visual cortical ventral stream that helped inspire deep networks also uses massive recurrent processing within each area as well as feedback connections from higher areas to lower areas and ""bypass"" connections from lower areas to areas multiple steps higher in the hierarchy. Deep networks also use ""neurons"" that can either excite or inhibit different neurons that they project to, whereas biological neurons are exclusively excitatory or inhibitory. This project will incorporate feedback and bypass connections into deep networks, as well as local recurrent processing in networks of separate excitatory and inhibitory neurons. Recent work by the investigators has shown how local recurrent processing explains a number of nonlinear visual cortical operations often summarized as ""normalization."" Simple forms of normalization currently used in deep networks maintain activities in an appropriate dynamic range, but the biological forms of normalization involve interactions between different stimulus features and locations in determining neural responses, which may have important computational roles e.g. in parsing visual scenes. The performance of deep networks incorporating these features will be assayed on a variety of visual tasks and as models of ventral stream neural data and human psychophysical data, and compared to performance of existing deep net models."
"1741706","Support for Doctoral Students from U.S. Universities to Attend AIED 2017 and/or  EDM 2017","IIS","Core R&D Programs, Cyberlearn & Future Learn Tech","06/01/2017","05/19/2017","Erin Walker","AZ","Arizona State University","Standard Grant","Amy Baylor","11/30/2018","$20,000.00","","Erin.A.Walker@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7980, 8020","7556, 8045, 8083","$0.00","The United States has historically been the global leader in the field of artificial intelligence in education (AIED), or ways to use computerized artificial intelligence to enhance teaching and learning in contexts ranging from children learning math in school, to soldiers learning highly technical jobs in the US military. The preeminent conference in this field is the AIED conference; at this conference the latest research is presented and practitioners learn the state of the art techniques that allow creation of these important educational technologies. A related conference that is equally significant is the Educational Data Mining (EDM) conference, which focuses on research on big data and analytics for education.<br/><br/>This proposal would provide partial travel support for 20 Ph.D. students, selected through a competitive process, to attend either or both of the AIED or EDM conference, present their work, and receive additional mentoring outside of their dissertation committees as part of a doctoral consortium. The intellectual merit of the work rests on the studies the graduate students submit to be considered for participation in the early career track of the conference; this work is then enhanced by guidance from world-class mentors who meet with the students in a structured format to improve their research. The broader impact includes the career impact on the twenty selected students, especially since promising graduate students whose advisors may not have funding to send them to the conference can still be included, and their work can be showcased and improved. Possible long-term broader impacts include building the field of artificial intelligence in education and data analytics researchers and thus eventually, improving the quality of education."
"1820520","ICLS 2018 Rethinking Learning in the Digital Age in ICLS Doctoral Consortium and Early Career Workshops","IIS","Cyberlearn & Future Learn Tech","04/01/2018","03/30/2018","Carolyn Rose","PA","Carnegie-Mellon University","Standard Grant","Amy Baylor","03/31/2019","$30,000.00","","cprose@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","8020","7556, 8045","$0.00","This award will support travel and registration for a Doctoral Consortium and Early Career Workshop at the annual meeting of the International Society of the Learning Sciences, which in 2018 will be held in conjunction with the Artificial Intelligence in Education conference and the Association of Computing Machinery conference on Learning at Scale. The three conferences will come together as a Festival of Learning. These joint interdisciplinary conferences will offer a rare professional opportunity for doctoral students and early career professionals to converge and present cutting-edge research from the fields of artificial intelligence, learning science, computer science, cognitive and learning sciences, psychology, and educational technology. Results will contribute to the new generation of researchers in the forward-looking technical area of this interdisciplinary area, to include the learning sciences, data analytics, and artificial intelligence in education. <br/><br/>This project will provide a travel stipend for 5 advanced graduate students to attend the Doctoral Consortium and 5 early career faculty members to attend the Early Career Workshop at the Festival of Learning. The project will also fund a shared young researchers event where 250 young researchers from the three conferences will have a poster session and panel discussion. The project will improve the dissertations of the graduate students and the research agendas of the early career, post-PhD scholars and advance the conference theme ""Rethinking Learning in the Digital Age"". This project will build on the expertise of the learning sciences community and the outcomes of previous workshops held with the International Conference of the Learning Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1704938","RI: Medium: Collaborative Research: Incorporating Biologically-Motivated Circuit Motifs into Large-Scale Deep Neural Network Models of the Brain","IIS","ROBUST INTELLIGENCE","10/01/2017","08/16/2017","Kenneth Miller","NY","Columbia University","Standard Grant","Kenneth C. Whang","09/30/2020","$525,000.00","","kdm2103@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7495","7495, 7924, 8089","$0.00","This project studies the effects of incorporating, into deep neural networks for visual processing, several heretofore unincorporated features of biological visual cortical circuits. Deep neural networks are artificial circuits loosely inspired by the brain's cerebral cortex. Their abilities to solve complex problems, such as recognizing objects in visual scenes, have revolutionized artificial intelligence and machine learning in recent years. The hierarchy of layers in a deep network trained for visual object recognition also provides the best existing models of the hierarchy of areas in the visual cortex implicated in object recognition (the ""ventral stream""). This project seeks to understand whether and how incorporating additional features of brain circuits may (1) improve machine learning performance, particularly on tasks that are more challenging than those typically studied; and (2) yield improved models of visual cortex. Improving the performance of deep networks would yield great benefits across wide swaths of society and industry that are impacted by advances in artificial intelligence. Improved models of visual cortex will advance understanding of cortical function, which may lead to significant further benefits for understanding normal mental functioning and perception and their potential enhancement, as well as mental illness and perceptual and cognitive deficits. <br/><br/>Deep networks currently achieve their success using almost purely feedforward processing. Yet the visual cortical ventral stream that helped inspire deep networks also uses massive recurrent processing within each area as well as feedback connections from higher areas to lower areas and ""bypass"" connections from lower areas to areas multiple steps higher in the hierarchy. Deep networks also use ""neurons"" that can either excite or inhibit different neurons that they project to, whereas biological neurons are exclusively excitatory or inhibitory. This project will incorporate feedback and bypass connections into deep networks, as well as local recurrent processing in networks of separate excitatory and inhibitory neurons. Recent work by the investigators has shown how local recurrent processing explains a number of nonlinear visual cortical operations often summarized as ""normalization."" Simple forms of normalization currently used in deep networks maintain activities in an appropriate dynamic range, but the biological forms of normalization involve interactions between different stimulus features and locations in determining neural responses, which may have important computational roles e.g. in parsing visual scenes. The performance of deep networks incorporating these features will be assayed on a variety of visual tasks and as models of ventral stream neural data and human psychophysical data, and compared to performance of existing deep net models."
"1840044","FW-HTF: First Person View and Augmented Reality for Airborne Embodied Intelligent Cognitive Assistants","IIS","FW-HTF: Advancing Cognitive an","09/01/2018","08/31/2018","Craig Woolsey","VA","Virginia Polytechnic Institute and State University","Standard Grant","David Miller","08/31/2021","$1,500,000.00","Joseph Gabbard, Pratap Tokekar, Matthew Hebdon","cwoolsey@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","082Y","063Z","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim. <br/><br/>The future of work will involve human operators and semi-autonomous robotic systems. Human workers control the robots, extending their sensing and physical capabilities. This technology-empowered workforce will do remote, dangerous, and increasingly specialized work. An example use of this work might be the inspection of hard-to-access bridge supports. This project will explore the use of intelligent airborne drones to help ground-based operators in the inspection of highway bridges. Through the careful integration of augmented reality (AR) with first-person-view (FPV) operator interfaces this research will enhance worker performance across a wide range of otherwise very difficult tasks. <br/><br/>The research program will address key challenges in the use of embodied intelligent cognitive assistants (e-ICAs) for infrastructure inspection. New principles of shared situation awareness will be developed for human/robot collaboration through AR/FPV user interfaces and these principles will inform interface design guidelines and evaluation measures. The research program will also emphasize collaborative perception and planning, such as peripheral/central computer vision to enhance shared situation awareness, gaze-informed adaptive viewpoint planning for improved image quality, and a global planning method for partially known and uncertain maps that adapts the plan in real-time as the worker discovers new information. Tunable control system performance will allow the worker and the e-ICA to collaborate in managing disturbance energy to optimize mission data quality and flight endurance while ensuring safety of flight. The parallel development of a public repository containing annotated deterioration imagery will support artificial intelligence based defect analytics to provide the human worker with real-time inspection cues. A parallel and coordinated economic and workforce analysis will assess the impact of airborne e-ICAs, controlled using FPV with augmented reality, on the future of work in infrastructure inspection and beyond.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1826962","WORKSHOP: Support for Travel to Participate in the ACM Intelligent User Interfaces (IUI) 2018 Conference and Student Consortium","IIS","Cyber-Human Systems (CHS)","03/15/2018","03/12/2018","Wai-Tat Fu","IL","University of Illinois at Urbana-Champaign","Standard Grant","Ephraim P. Glinert","02/28/2019","$30,000.00","","wfu@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","7367","7367, 7556","$0.00","This is funding to provide financial support for up to 15 graduate students (all from U. S. universities and working towards either their Master's degree or a Doctorate) to attend the 2018 International Conference on Intelligent User Interfaces (IUI 2018), to be held March 7-11 in Tokyo, Japan, and to participate in a full-day Student Consortium (workshop) that will be held on March 9.  Sponsored by ACM, the annual IUI conferences represent the growing interest in next-generation intelligent interactive user interfaces.  Attracting 200-300 attendees, they are the premier forum where researchers from academia and industry worldwide who work at the intersection of Human-Computer Interaction (HCI) and Artificial Intelligence (AI) come together to exchange insights and to present outstanding research and applications whose goal is to make the computerized world a more amenable place.  Unlike traditional AI the focus is not so much on making the computer smart all by itself, but rather on making the interaction between computers and people smarter; and unlike traditional HCI, there is a focus on solutions that involve large amounts of knowledge and emerging technologies such as natural language understanding, brain-computer interfaces, and gesture recognition. To this end, IUI encourages contributions not only from computer science but also from related fields such as psychology, behavioral science, cognitive science, computer graphics, design, the arts, etc.  IUI 2018 will be the 23rd conference in the series; more information about the conference is available online at http://iui.acm.org/2018.  This funding will enable attendance at the IUI conference by students who might otherwise be unable to do so for financial reasons.  It will enhance the educational experience of funded participants, by bringing them into contact with leading researchers in the field and by exposing them to the lively discussion during the course of the conference that often leads to opportunities for career advancement.  The quality of the conference itself will be enhanced as well, thanks to a broadening of the base of institutions represented and increased diversity of participants.  The rich exchange of ideas at IUI has previously proven to be a valuable source of ideas for future research, as well as leading to collaborative efforts; this funding will extend the opportunities for collaboration and provide intellectual stimulus to programs that have previously sent few or no representatives to this conference.  The organizing committee has undertaken to proactively recruit student participants from schools that have not traditionally been well represented in the IUI community.  Women and students who are members of underrepresented groups will be particularly encouraged to participate.  To further assure diversity, no more than two students will be accepted from any given institution.<br/><br/>The IUI 2018 Student Consortium will build on the success of previous such events.  The heart of the Consortium will be a full-day workshop on March 9.  Student trainees will be afforded exposure to their new research community by giving a 20-30 presentation on their work and receiving feedback from peers and a panel of senior researchers.  A group lunch and dinner will encourage social interaction among the student cohort and informal personal interaction with the mentors.  The students' work will also be featured during the main conference in a poster session, where they will gain additional experience explaining their work to others in the field.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637547","RI:   Doctoral Student Consortium at the Twenty Fourth International Conference on Case-Based Reasoning","IIS","ROBUST INTELLIGENCE","07/15/2016","07/17/2018","Ashok Goel","GA","Georgia Tech Research Corporation","Standard Grant","James Donlon","12/31/2018","$10,000.00","","ashok.goel@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7495","7495, 7556","$0.00","This project will support of the Doctoral Student Consortium at the Twenty Fourth International Conference on Case-Based Reasoning (ICCBR'16) to be held at Georgia Institute of Technology in Atlanta, USA, from October 31st through November 2nd 2016. ICCBR is an international conference series covering all aspects of research on case-based reasoning, such as memory, problem solving, decision making, learning, recommender systems, analogy, creativity, and applications in industry, business and government. Research on case-based reasoning often is interdisciplinary, with connections to artificial intelligence and intelligent agents, cognitive science and cognitive computing, human-centered computing and interactive systems, and human learning as well as machine learning.<br/><br/>With the resurgence of cognitive systems cognitive computing as evidenced by IBM's Watson system and Apple?s Siri program among many others, the ICCBR community is growing once again. The ICCBR conferences attempt to foster research carried out in the original spirit of AI, which aimed to design and implement computer programs that exhibited the breadth, generality, and flexibility often observed in human intelligence on one hand, and use the design of AI systems for insights into human intelligence on the other. We expect ICCBR'16 to significantly increase our understanding of case-based cognitive systems, and add momentum to the development of new theories, techniques and tools for case-based cognitive computing. The conference sessions and workshops will help develop human research capital by enabling interactions between senior and junior researchers and catalyzing new collaborations. The doctoral consortium will increase the exposure and visibility of young graduate student researchers in these areas, and train them by providing early input and feedback in the field in an interactive and constructive environment."
"1640830","Support for Young Researchers to attend the  2016 Intelligent Tutoring Systems Conference","IIS","Cyberlearn & Future Learn Tech","06/01/2016","07/06/2016","Beverly Woolf","MA","University of Massachusetts Amherst","Standard Grant","Tatiana D. Korelsky","05/31/2019","$20,000.00","","bev@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","8020","7556, 8045","$0.00","The Cyberlearning and Future Learning Technologies Program funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning CAP projects build capacity for research and development in the field of Cyberlearning by improving technical infrastructure, human capital, and in other ways. The Intelligent Tutoring Systems (ITS) 2016 conference offers a rare professional opportunity for interdisciplinary students to converge and present cutting-edge research from the fields of artificial intelligence (AI), learning science, computer science, cognitive and learning sciences, psychology, and educational technology. <br/><br/>This project supports travel for selected advanced graduate students to attend the doctoral consortium at the ITS 2016 conference in Croatia.  The conference has a special Young Research Track within the main conference for advanced graduate students. In this track a special session supports students to share their research with papers, posters, tutorials, workshops, and informal interactions with accomplished researchers. Students present their research ideas and receive feedback from researchers in the ITS community. An important goal of the doctoral consortium is to build the new generation of researchers in the forward-looking technical area of intelligent tutoring systems."
"1814472","CHS: Small: Multimodal Conversational Assistant that Learns from Demonstrations","IIS","Cyber-Human Systems (CHS)","08/15/2018","08/08/2018","Brad Myers","PA","Carnegie-Mellon University","Standard Grant","Ephraim P. Glinert","07/31/2021","$499,019.00","Tom Mitchell","bam@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","075Z, 7367, 7923","$0.00","Intelligent assistants such as Apple's Siri, Amazon's Alexa and Microsoft's Cortana are rapidly gaining popularity by providing a conversational natural language interface for users to access various online services and digital content.  They allow computing tasks to be performed in contexts where users cannot touch their phones (such as while driving), and on wearable and Internet of Things (IoT) devices (such as Google Home).  However, such conversational interfaces are limited in their ability to handle the ""long-tail"" of tasks and suffer from lack of customizability.  This research will explore a new multi-modal, interactive, programming-by-demonstration (PBD) approach that enables end users to add new capabilities to an intelligent assistant by programming automation scripts for tasks in any existing third-party Android mobile app using a combination of demonstrations and verbal instructions.  The system will leverage state-of-the-art machine learning and natural language processing techniques to comprehend the user's verbal instructions that supply information missing in the demonstration, such as implicit conditions, user intent and personal preferences.  The user's demonstration on the graphical user interface will be used for grounding the conversation and reinforcing the natural language understanding model.  The system will point the way to allowing the general public to more effectively use their smartphones, IoT devices and intelligent assistants, increasing the adoption, efficiency and correctness of uses of these technologies.  The integration of intelligent assistants with PBD will have broad impact by exposing people to programming concepts in an easy-to-learn way, and thereby increasing computational thinking.  <br/><br/>This project will result in several innovations beyond the current state of the art through advances in programming by demonstration (PBD) and intelligent assistants, and especially in their integration.  The work will explore leveraging verbal instructions as an additional modality to address long-standing challenges in PBD research including generalizing the data descriptions and adding control structures.  How to coordinate the two modalities to help the intelligent assistant learn new tasks effectively and efficiently from users will be investigated, and how users utilize the two modalities in multi-modal PBD systems for programming tasks in different situations will also be studied.  New ways to leverage the displayed graphical user interfaces (GUI) of apps to enhance the speech recognition and language understanding by using the strings and other context of the GUI on the smartphone will be developed.  The ability of the conversational assistant to participate in this generalization process will be enhanced, with a focus on having the system ask appropriate and helpful questions so the task automation will fit the user's needs and intentions.  New approaches to representing scripts created by PBD systems that users can read, understand and edit will be explored, as will increasing trust and usefulness of the scripts and supporting error handling, debugging and maintenance.  The new technology will also be able to extract data from and enter data into apps, and to learn, through demonstration and verbal instruction, how to transform the data into appropriate formats.  Finally, how to support sharing of scripts created by PBD systems while ensuring the appropriate levels of privacy and security will also be investigated.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1701565","Exploiting Metal-Insulator-Transition in Strongly Correlated Oxides as Neuron Device for Neuro-Inspired Computing","ECCS","ELECT, PHOTONICS, & MAG DEVICE","08/01/2017","05/01/2017","Shimeng Yu","AZ","Arizona State University","Standard Grant","Dimitris Pavlidis","07/31/2020","$360,000.00","","shimeng.yu@ece.gatech.edu","ORSPA","TEMPE","AZ","852816011","4809655479","ENG","1517","100E","$0.00","A radical shift in computing paradigm towards the neuro-inspired computing is attractive for performing data-intensive applications such as image/speech recognitions. The neuro-inspired architecture leverages the distributed computation in the neuron nodes and the localized storage in the synaptic elements. The neuron node today is generally implemented by tens of silicon transistors. Compared to the crossbar array of synaptic elements, the silicon neuron is power-hungry and area-inefficient, thereby reducing the parallelism of computing system. In such context, how to design a single device that can efficiently emulate the neuronal behavior (e.g. integrate-and-fire) is critical to the neuromorphic hardware design. This project aims to exploit the metal-insulator-transition phenomenon in strongly correlated oxides as a compact neuron node that can self-oscillate, namely oxide neuron, to overcome the aforementioned limitations of silicon neuron. The proposed research will have a profound impact on the society that is embracing the artificial intelligence. For instance, a compact design of neuromorphic hardware may enable intelligent information processing on power-efficient mobile platforms, e.g. autonomous vehicle, personalized healthcare, wearable devices, and smart sensors. The objective of the research and education integration is to train undergraduate/graduate students and next-generation workforce with interdisciplinary skills. The cross-layer nature of this project ranging from materials engineering, semiconductor device, circuit-device interaction and artificial neural network provides an ideal platform for this educational goal. The project also plans to engage minority and unrepresentative students in research. Technology transfer will be performed through video or on-site seminars and student internships with industrial collaborators.<br/><br/><br/>The goal of this research is to advance the artificial neuron device design by exploiting the volatile and threshold switching behavior in strongly correlated oxides, with the purpose of significantly reducing the area and energy of the neuron node, and making it compatible for the integration with crossbar array of resistive synaptic elements. The scope of the project is to explore various material systems of the strongly correlated oxides, in particular, NbO2 and SmNiO3 to demonstrate the self-oscillation behavior in the artificial neuron node. When such oxide device is connected with a series synaptic element whose resistance is within the on/off dynamic range of the oxide device, the node voltage between the oxide device and the synaptic element will start self-oscillation, and the oscillation frequency represents the synaptic conductance. This project aims to explore such self-oscillation to emulate the integrate-and-fire neuronal behavior. To achieve the aforementioned research goal, device fabrication, physical and electrical characterization, device modeling, and circuit-device co-design will be performed to demonstrate the feasibility of the concept and further optimize the device performance. The intellectual significance of this project is two folded. From the fundamental science perspective, the physical switching mechanism of metal-insulator-transition in strongly correlated oxides will be investigated. From the applied engineering perspective, the oxide neuron device will be integrated with the resistive crossbar array for demonstration of a neural network for solving a practical problem, i.e. the image pattern classification."
"1831151","SBIR Phase II:  In-Memory Artificial Neural Network","IIP","SMALL BUSINESS PHASE II","09/01/2018","09/04/2018","Wolfgang Hokenmaier","VT","Green Mountain Semiconductor, Inc.","Standard Grant","Richard Schwerdtfeger","08/31/2020","$750,000.00","","whokenmaier@greenmountainsemi.com","182 Main St., Suite 304","Burlington","VT","054018349","8023438175","ENG","5373","097E, 5373, 8035","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project is provided by a novel data processing architecture, utilizing high-parallel in-memory computing for certain recurring and data intensive functions. Traditional computer architecture funnels all data through the central processing unit (CPU). Multiple CPU cores and very high clock frequencies are used to address the issue of ever increasing demands on data processing capability. However, the transportation capacity of data between memory and CPU cores has become a limiting factor creating a 'memory bottleneck'. This limitation is most noticeable in the recent and rapid development of artificial intelligence applications which deploy so called neuromorphic computing techniques, which in turn require a very high parallelism in computation and proportional demands on memory bandwidth. This project performs key repetitive operations within the memory itself, leveraging the inherent parallelism of the memory architecture, thereby avoiding a large percentage of the data transport otherwise required. The resulting elimination of the memory bottleneck provides a path forward for high complexity neuromorphic computing applications such as autonomous navigation used for self-driving cars. Reduced demands on data transport and CPU also significantly reduce power consumption, enabling a wide variety of mobile artificial intelligence applications.<br/><br/>The proposed project investigates the system level integration challenges of a memory-centric neuromorphic computing approach, and aims to demonstrate a seamless integration with existing software platforms currently using traditional neuromorphic computing processors. It is important for a novel hardware platform to be compatible with existing software in order to lower barriers to market entry. This Phase II project also develops the actual semiconductor product which has been investigated in Phase I as a feasibility demonstrator. The Phase II product is based on a non-volatile high density memory architecture, and as such is expected to provide the full capability in terms of both power and operations per second. Once the hardware is available in the second half of the project, these key parameters will be thoroughly characterized and benchmarked against the current state of the art technology. A projection will be made outlining the future scaling potential using ultra high density volatile and non-volatile memory geared towards high complexity neuromorphic computing beyond what is currently possible using existing approaches.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1744159","I-Corps: Approximate Dynamic Programming and Artificial Neural Network Control for Microgrids","IIP","I-Corps","07/01/2017","07/12/2017","Shuhui Li","AL","University of Alabama Tuscaloosa","Standard Grant","Pamular Mccauley","12/31/2018","$50,000.00","","sli@eng.ua.edu","801 University Blvd.","Tuscaloosa","AL","354870005","2053485152","ENG","8023","9150","$0.00","The broader impact/commercial potential of this I-Corps project is to act as a catalyst in the growth of distributed generation and microgrid industries. This artificial intelligence based control system will potentially provide an electrical network that is reliable by reducing outages and restoration costs with incredibly fast bidirectional power flow, secured with real time diagnostics, self-healing and adaptive capabilities, and more economical by reducing equipment failures and minimizing power losses. The product potentially three broad markets, including utilities, distributed generation and consumer. The solution will enhance energy generation from renewables, improve microgrid efficiency, reliability, stability and power quality, and add intelligent control to conventional power systems. Inverter capabilities are presently a significant challenge for integrating distributed generation sources. The proposed innovation would potentially provide an appropriate solution to address this challenge.<br/><br/>This I-Corps project develops a neural network control technology for microgrid control and management. Microgrids are one path for integrating renewable and distributed generation sources into the grid and can generally support a future smart electricity grid.  A key challenge in microgrid adoption is adequate control of power inverters. Problems include high oscillations when connecting or disconnecting an energy source, fluctuating voltage and frequency, malfunctions and reliability, competing control between inverters, and high harmonic distortions. The proposed innovation uses adaptive dynamic programming and artificial neural networks to implement microgrid control. It integrates into one controller the advantages of conventional control methods, including optimal control, proportional integral control, predictive control, and sliding mode control. The proposed innovation has the potential to overcome the limitations of the conventional control technologies and better meet customer demands and requirements."
"1822650","CRCNS Research Proposal:  Collaborative Research: New Dimensions of Visual Cortical Organization","IIS","CRCNS, ROBUST INTELLIGENCE","10/01/2018","09/07/2018","Steven Zucker","CT","Yale University","Standard Grant","Kenneth C. Whang","09/30/2022","$625,115.00","","steven.zucker@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","CSE","7327, 7495","075Z, 7327, 8089, 8091","$0.00","The visual system of the mouse is now widely studied as a model for developmental neurobiology, as well as for the understanding of human disease, because it can be studied with the most powerful modern genetic and optical tools.  This project aims to discover how neurons in the visual cortex of the mouse allow it to see well by measuring how the cortex represents ecologically-relevant properties of the visual world.  Quantitative studies of neurons in the mouse's primary visual cortex to date reveal only very poor vision, but their behavior indicates that mice can see much better than that -- they avoid predators and catch crickets in the wild. To understand mouse vision, the investigators will study responses to novel, mathematically tractable stimuli resembling the flow of images across the retina as the mouse moves through a field of grass.  Studies based on these new stimuli indicate that most V1 neurons respond reliably to fine details of the visual scene.  A mathematical understanding of how the brain takes in the visual world should have real implications for how we see, and should have great benefits for artificial vision by computers and robots.  Bringing these ideas into the classroom will provide the foundation for new technologies, and will expose students to both real and artificial vision systems.<br/><br/>Analyses of the brain's visual function are limited by the stimuli used to probe them. Conventional quantitative approaches to understanding biological vision have been based on models with linear kernels in which only the output might be subject to a nonlinearity, all derived from responses of neurons in the brain to gratings of a range of spatial frequencies.  This analysis fails to capture relevant features of natural images, which can not be constrained to linearity. The goal of this project is to probe the mouse visual system beyond the linear range but below the barrier posed by the complexity of arbitrary natural images. The investigators have identified an intermediate stimulus class--visual flow patterns--that formally approximate important features of natural visual scenes, resembling what an animal would see when running through grass. Flow patterns have a rich geometry that is mathematically tractable.  This project will develop such stimuli and test them on awake-behaving mice, while recording the resultant neural activity in the visual cortex.  Studying the mouse opens up the possibility of applying the entire range of powerful modern neuroscience tools-- genetic, optical, and electrophysiological. Visual responses will be analyzed using a novel variety of machine learning algorithms, which will allow the investigators to model the possible neural circuits and then test predictions from those model circuits.  Such an understanding of the brain will inform both primate vision and the next generation of artificially-intelligent algorithms which, as a result, should benefit from being more ""brain-like.""<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1840458","Planning Grant: Engineering Research Center for Safe and Secure Artificial Intelligence Solutions (SAIS)","EEC","ENGINEERING RESEARCH CENTERS","09/01/2018","08/31/2018","Hongyi Wu","VA","Old Dominion University Research Foundation","Standard Grant","Junhong Chen","08/31/2019","$100,000.00","Chunsheng Xin, Brian Payne, Cong Wang","h1wu@odu.edu","4111 Monarch Way","Norfolk","VA","235082561","7576834293","ENG","1480","112E, 132E","$0.00","The Planning Grants for Engineering Research Centers competition was run as a pilot solicitation within the ERC program.  Planning grants are not required as part of the full ERC competition, but intended to build capacity among teams to plan for convergent, center-scale engineering research.<br/><br/>The planning grant enables the principal investigators (PIs) to work with a full spectrum of stakeholders to prepare the groundwork for establishing an Engineering Research Center (ERC) for Safe and Secure Artificial Intelligence Solutions (SAIS). The proposed center focuses on development of fundamental, theoretically-grounded, and systematic approaches to enable safe and secure AI and establishment of an interdisciplinary community that engages all stakeholders. Scholars from multiple disciplines and practitioners from multiple fields will work together to fully understand the problems and explore the design space. The success of this endeavor can potentially lead to enabling technologies for secure machine learning systems, thereby accelerating their development and widening their adoption in different application domains. Regional educators and government/industrial employers will be engaged to train cybersecurity workforce. Overall the proposed ERC SAIS contributes significantly to the protection of future cyber and physical world and safeguarding the human society. <br/><br/>The PIs will identify and engage the SAIS stakeholder community, including partners and participants from academics, government and military agencies, research centers, and various industries. The interdisciplinary team will plan a long-term vision and direction for SAIS and identify key research and development thrusts, based on the inputs from all stakeholders. The team will develop marketing plan, future member recruiting plan, and cooperative membership agreement (including membership eligibility, commitment, and intellectual property ownership). The team will decide the center's administration structure and management policies and guidelines. The team also will identify a set of research, education, workforce development, and outreach projects to be carried out during the first two years should the center be established. Finally, the team will create plans to work with university admission and K-12 educators to inspire and improve the participation of underrepresented groups in the proposed ERC SIAS and introduce cybersecurity to school counselors, teachers, students, and parents.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1824304","Collaborative Research: Deep Inference - Artificial Intelligence for Structural Estimation","SES","ECONOMICS","09/15/2018","08/10/2018","Elena Manresa","NY","New York University","Standard Grant","Seung-Hyun Hong","08/31/2020","$84,917.00","","em1849@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","SBE","1320","1320, 9179","$0.00","In order to evaluate the effect of economic policies such as extended health care coverage or changes in the minimum wage, economists use structural models which powerfully describe the mechanism at work, but estimating structural models is typically challenging.  A main tool for estimating such structural models is inference via simulation.  For different parametrizations of the model, synthetic data is generated via the model, and the parameters generating data that most closely resembles observed data are used as estimates. Recent modern artificial intelligence methods such as deep learning for image recognition are based on this same principle. These methods have been achieving impressive results over the past years. Therefore, this research takes advantage of such powerful tools in modern pattern recognition for structural estimation in economics. <br/><br/>This research considers a set-up where individual outcomes are a known function of exogenous variables and an error whose distribution is known up to a finite dimensional vector of parameters. The goal is to estimate the finite dimensional parameter. The investigators adopt the generative adversarial network approach (GANs) to find the parameter value such that given a discriminator, a device that can accurately distinguish data generated using the model from real data, is unable to do so when the data is generated according to such parameter value. The method developed in this research differs from other simulation-based minimum distance estimators in that the distance is adaptive. That is, the discriminator learns the features of the data that are best at distinguishing real from synthetic data as opposed to hard-coding what features of the data to match. This adaptability property has proven powerful in pattern recognition tasks. In structural estimation, adaptability can translate into alleviating the curse of dimensionality, and obtaining parameters that are able to more closely match entire distributions of data, as opposed to a set of pre-specified moments. This estimation framework should be useful in applications were distributional effects and heterogeneity are first order to evaluate the effect of a particular policy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1824365","Collaborative Research: Deep Inference - Artificial Intelligence for Structural Estimation","SES","ECONOMICS","09/15/2018","08/10/2018","Guillaume Pouliot","IL","University of Chicago","Standard Grant","Seung-Hyun Hong","08/31/2020","$82,384.00","","guillaumepouliot@uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","SBE","1320","1320, 9179","$0.00","In order to evaluate the effect of economic policies such as extended health care coverage or changes in the minimum wage, economists use structural models which powerfully describe the mechanism at work, but estimating structural models is typically challenging.  A main tool for estimating such structural models is inference via simulation.  For different parametrizations of the model, synthetic data is generated via the model, and the parameters generating data that most closely resembles observed data are used as estimates. Recent modern artificial intelligence methods such as deep learning for image recognition are based on this same principle. These methods have been achieving impressive results over the past years. Therefore, this research takes advantage of such powerful tools in modern pattern recognition for structural estimation in economics. <br/><br/>This research considers a set-up where individual outcomes are a known function of exogenous variables and an error whose distribution is known up to a finite dimensional vector of parameters. The goal is to estimate the finite dimensional parameter. The investigators adopt the generative adversarial network approach (GANs) to find the parameter value such that given a discriminator, a device that can accurately distinguish data generated using the model from real data, is unable to do so when the data is generated according to such parameter value. The method developed in this research differs from other simulation-based minimum distance estimators in that the distance is adaptive. That is, the discriminator learns the features of the data that are best at distinguishing real from synthetic data as opposed to hard-coding what features of the data to match. This adaptability property has proven powerful in pattern recognition tasks. In structural estimation, adaptability can translate into alleviating the curse of dimensionality, and obtaining parameters that are able to more closely match entire distributions of data, as opposed to a set of pre-specified moments. This estimation framework should be useful in applications were distributional effects and heterogeneity are first order to evaluate the effect of a particular policy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1616216","Collaborative Research: Productivity Prediction of Microbial Cell Factories using Machine Learning and Knowledge Engineering","MCB","Systems and Synthetic Biology","08/01/2016","07/30/2016","Forrest Sheng Bao","OH","University of Akron","Standard Grant","Devaki Bhaya","09/30/2018","$232,523.00","","fsb@iastate.edu","302 Buchtel Common","Akron","OH","443250001","3309722760","BIO","8011","144E, 1757, 7465","$0.00","Over the past decade, systems and synthetic biology approaches provided novel mechanism to enhance the production of diverse chemicals and biofuels from renewable resources in laboratory settings. However, it is still rare for synthetically modified strains to meet the production requirement for commercialization. Strain development falls into the tedious and costly design-build-test-learn cycle because existing modeling approaches failed to capture the complicated metabolic responses in such engineered cells. This proposal will explore an alternate, data-driven approach that has the potential to predict the productivity of synthetic organisms by leveraging the vast array of microbial cell factory publications. Using Artificial Intelligence approaches such as Machine Learning and Knowledge Representation, one can abstract ""previous lessons'' hidden in published data to facilitate a priori estimations of the metabolic output by engineered hosts given a set of specific genetic instructions and fermentation growth conditions. The resulting platform can assist current constraint-based models to design the most effective strategies for producing value-added chemicals. On the educational front, this proposal will offer educational and research training opportunities in synthetic biology, computer programming, and artificial intelligence for graduate students to provide them with a non-conventional career pathway. <br/><br/>Synthetic biology relies on extensive genetic modification and pathway engineering, which often result in unexpected physiological changes or metabolic shifts that reduce the productivity and stability of the hosts. The investigators conceived of a creative, multidisciplinary approach that relies on artificial intelligence-inspired methods for predicting the performance of two distinct unicellular cell factories (Escherichia coli and Saccharomyces cerevisiae). These platforms can be used to quantify the factors that govern microbial productivity (yield, titer, and growth rate), including the type and availability of metabolic precursors; the elements that constitute a biosynthetic pathway; fermentation conditions; and the specific genetic modification to optimize the system. By extracting and classifying information derived from referenced publications within the last 20 years, one can construct a ''knowledge base'' containing sufficient samples of bio-production assemblies. This information will then inform the building of cellular factories using supervised machine learning and non-monotonic logic programming to estimate the productivity of hosts. The data-driven platform will also be integrated into genome scale models to project physiological changes of specific mutant strains. This novel approach will reduce the need for costly design-build-test bench work. Key outcomes from this project include: (1) a database to standardize synthetic biology studies, (2) machine learning models to recognize lessons and patterns hidden in published data, and (3) integration of machine learning with flux balance models, leading to the design of strains with high chances of success in industry settings."
"1821828","Collaborative Research: Productivity Prediction of Microbial Cell Factories using Machine Learning and Knowledge Engineering","MCB","Systems and Synthetic Biology","10/05/2017","08/06/2018","Forrest Sheng Bao","IA","Iowa State University","Standard Grant","Devaki Bhaya","07/31/2019","$230,672.00","","fsb@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","BIO","8011","144E, 1757, 7465","$0.00","Over the past decade, systems and synthetic biology approaches provided novel mechanism to enhance the production of diverse chemicals and biofuels from renewable resources in laboratory settings. However, it is still rare for synthetically modified strains to meet the production requirement for commercialization. Strain development falls into the tedious and costly design-build-test-learn cycle because existing modeling approaches failed to capture the complicated metabolic responses in such engineered cells. This proposal will explore an alternate, data-driven approach that has the potential to predict the productivity of synthetic organisms by leveraging the vast array of microbial cell factory publications. Using Artificial Intelligence approaches such as Machine Learning and Knowledge Representation, one can abstract ""previous lessons'' hidden in published data to facilitate a priori estimations of the metabolic output by engineered hosts given a set of specific genetic instructions and fermentation growth conditions. The resulting platform can assist current constraint-based models to design the most effective strategies for producing value-added chemicals. On the educational front, this proposal will offer educational and research training opportunities in synthetic biology, computer programming, and artificial intelligence for graduate students to provide them with a non-conventional career pathway. <br/><br/>Synthetic biology relies on extensive genetic modification and pathway engineering, which often result in unexpected physiological changes or metabolic shifts that reduce the productivity and stability of the hosts. The investigators conceived of a creative, multidisciplinary approach that relies on artificial intelligence-inspired methods for predicting the performance of two distinct unicellular cell factories (Escherichia coli and Saccharomyces cerevisiae). These platforms can be used to quantify the factors that govern microbial productivity (yield, titer, and growth rate), including the type and availability of metabolic precursors; the elements that constitute a biosynthetic pathway; fermentation conditions; and the specific genetic modification to optimize the system. By extracting and classifying information derived from referenced publications within the last 20 years, one can construct a ''knowledge base'' containing sufficient samples of bio-production assemblies. This information will then inform the building of cellular factories using supervised machine learning and non-monotonic logic programming to estimate the productivity of hosts. The data-driven platform will also be integrated into genome scale models to project physiological changes of specific mutant strains. This novel approach will reduce the need for costly design-build-test bench work. Key outcomes from this project include: (1) a database to standardize synthetic biology studies, (2) machine learning models to recognize lessons and patterns hidden in published data, and (3) integration of machine learning with flux balance models, leading to the design of strains with high chances of success in industry settings.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1836362","CBMS Conference: Topological Methods in Machine Learning and Artificial Intelligence","DMS","INFRASTRUCTURE PROGRAM","09/01/2018","08/03/2018","Ben Cox","SC","College of Charleston","Standard Grant","Swatee Naik","08/31/2019","$35,960.00","Robert Mignone, Annalisa Calini","coxbl@cofc.edu","66 GEORGE ST","CHARLESTON","SC","294240001","8439534973","MPS","1260","7556, 9150","$0.00","This National Science Foundation award supports the NSF-CBMS regional conference on Topological Methods in Machine Learning and Artificial Intelligence, hosted by the College of Charleston in Charleston, South Carolina, during the week of May 13-17, 2019. The conference will feature Professor Gunnar Carlsson of Stanford University and Ayasdi Inc. as the Principal Lecturer. Professor Carlsson will deliver a series of ten lectures introducing participants to the fast-emerging field of Topological Data Analysis, which employs many of the techniques commonly used in topology, the study of shape, to analyze massive and complex data sets across multiple application domains. The conference will benefit a broad group of participants as data science is rapidly establishing itself as an interdisciplinary discipline with many high-impact applications. Main targets of the lecture series and the ensuing monograph will be applications to the medical sciences, including, e.g., better targeting and prediction of diseases and improved patient care, though the lectures will benefit a far larger constituency. The great majority of the NSF-supported participants will be recruited from amongst early career researchers, graduate students, minorities, and women. <br/> <br/>Topological Data Analysis refers to the use of topology as a tool for understanding and interacting with large and complex data sets. It should be viewed as another step in the development of Machine Learning. Many of the techniques used extensively in topology - including the combinatorial construction of spaces as simplicial complexes, homology and cohomology, local to global methods for computation and application, and the organizing power of the language of category theory and functoriality - all play important roles in the development of this subject. Professor Carlsson?s lecture series and the resulting monograph will introduce students and researchers to this rapidly emerging field. Topics will include topological modeling of data; machine learning; applications of homology to shape analytic tasks, statistics of image patches, and viral evolution; adapting local-to-global methods from topology to point cloud situations; persistence landscapes and persistence images with applications to drug discovery; clustering; and algorithms as data sources. The conference website is at http://math.cofc.edu/CBMS-TDA2019/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1829704","CyberTraining: CIC: CyberTraining for Students and Technologies from Generation Z","OAC","CyberTraining - Training-based","09/01/2018","07/02/2018","Geoffrey Fox","IN","Indiana University","Standard Grant","Sushil Prasad","08/31/2021","$492,283.00","Douglas Swany, Gregor von Laszewski","gcf@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","CSE","044Y","026Z, 062Z, 7361, 9102, 9179","$0.00","Information technology is playing a dramatically increasing role in society, industry, and research. This includes design and use of large databases, simulations and artificial intelligence applications hosted on clouds and supercomputers with convergent technologies. Correspondingly, there is an increasing need for research workforce job skills in these and related areas. This project takes freshly created Indiana University Engineering course material on this cyberinfrastructure and adapts it for training with an emphasis on the needs of under-represented communities. The techniques of the successful open source software movement are used to create sustainable communities around the course curriculum and software. The project is creating new technologies to enable this for today's generation of students. Skills in core cloud computing, big data, supercomputing and artificial intelligence are exemplified by applications in the life science and nanotechnology areas. This project enables the future research workforce to contribute effectively using advanced cyberinfrastructure, promoting the progress of science and advancing the national health, prosperity, and welfare, which serves the national interest, as stated by NSF's mission. <br/><br/>The future economic progress and research leadership of the U.S. is dependent on having a research workforce that is capable of making use of advanced cyberinfrastructure (CI) resources as articulated by the National Strategic Computing Initiative (NSCI). This requires a curriculum that changes and integrates modern concepts and practices for the new generation of students aiming at a ""data-enabled computational science and engineering"" expertise. This project takes what Indiana University has learned from a brand new four-year undergraduate engineering curriculum designed ab initio and taught so far to its first two undergraduate classes, and invests it into developing active training modules. The innovative curriculum integrates big data, simulations, clouds and high performance computing systems presented in a uniform framework. The course material is customized for communities of cyberinfrastructure researchers nucleated, built, and sustained via the dynamic use of GitHub and enhanced by innovative tools to build a novel learning management system optimized for cyberinfrastructure-intensive classes. The project modules include Cloud Computing, Big Data Applications and Analytics, Networking, High-Performance Computing, Artificial Intelligence/Machine Learning, and Information Visualization. There are residential sessions, with a call for participants, and purely online courses and these have both ""teach the student"" and ""teach the teacher"" modes; the latter enables easy spread of the classes. Hands-on learning with research projects built around the class material is fully supported. The project offers CyberTraining with all of the popular approaches used by the Apache Software Foundation, including Meetups and Hackathons. Modules for domain scientists and engineers, e.g., the cyberinfrastructure users that exploit advanced CI methods for research in nanoengineering and bioengineering are included. Both students and teachers contribute to the course improving the text, the software, including a unique set of examples and the project aims to show that one can build both learning and sustainability communities by using the proven techniques of the open source software community. The project uses proactive measures to enhance the involvement of under-represented communities in its activities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1616619","Collaborative Research: Productivity Prediction of Microbial Cell Factories using Machine Learning and Knowledge Engineering","MCB","Systems and Synthetic Biology","08/01/2016","07/30/2016","Yinjie Tang","MO","Washington University","Standard Grant","Devaki Bhaya","07/31/2019","$245,474.00","","yinjie.tang@seas.wustl.edu","CAMPUS BOX 1054","Saint Louis","MO","631304862","3147474134","BIO","8011","144E, 1757, 7465","$0.00","Over the past decade, systems and synthetic biology approaches provided novel mechanism to enhance the production of diverse chemicals and biofuels from renewable resources in laboratory settings. However, it is still rare for synthetically modified strains to meet the production requirement for commercialization.  Strain development falls into the tedious and costly design-build-test-learn cycle because existing modeling approaches failed to capture the complicated metabolic responses in such engineered cells. This proposal will explore an alternate, data-driven approach that has the potential to predict the productivity of synthetic organisms by leveraging the vast array of microbial cell factory publications. Using Artificial Intelligence approaches such as Machine Learning and Knowledge Representation, one can abstract ""previous lessons'' hidden in published data to facilitate a priori estimations of the metabolic output by engineered hosts given a set of specific genetic instructions and fermentation growth conditions. The resulting platform can assist current constraint-based models to design the most effective strategies for producing value-added chemicals. On the educational front, this proposal will offer educational and research training opportunities in synthetic biology, computer programming, and artificial intelligence for graduate students to provide them with a non-conventional career pathway. <br/><br/>Synthetic biology relies on extensive genetic modification and pathway engineering, which often result in unexpected physiological changes or metabolic shifts that reduce the productivity and stability of the hosts. The investigators conceived of a creative, multidisciplinary approach that relies on artificial intelligence-inspired methods for predicting the performance of two distinct unicellular cell factories (Escherichia coli and Saccharomyces cerevisiae). These platforms can be used to quantify the factors that govern microbial productivity (yield, titer, and growth rate), including the type and availability of metabolic precursors;  the elements that constitute a biosynthetic pathway; fermentation conditions; and the specific genetic modification to optimize the system. By extracting and classifying information derived from referenced publications within the last 20 years, one can construct a ''knowledge base'' containing sufficient samples of bio-production assemblies. This information will then inform the building of cellular factories using supervised machine learning and non-monotonic logic programming to estimate the productivity of hosts. The data-driven platform will also be integrated into genome scale models to project physiological changes of specific mutant strains. This novel approach will reduce the need for costly design-build-test bench work. Key outcomes from this project include: (1) a database to standardize synthetic biology studies, (2) machine learning models to recognize lessons and patterns hidden in published data, and (3) integration of machine learning with flux balance models, leading to the design of strains with high chances of success in industry settings."
"1744118","EAGER: Integration of Heat Pipes in Gas Turbines using Artificial Intelligence and Additive Manufacturing","CBET","THERMAL TRANSPORT PROCESSES","05/15/2018","06/05/2018","Amir Faghri","CT","University of Connecticut","Standard Grant","Jose Lage","04/30/2020","$149,013.00","","faghri@engr.uconn.edu","438 Whitney Road Ext.","Storrs","CT","062691133","8604863622","ENG","1406","7916","$0.00","Gas turbines power almost all modern aircraft and generate about 21% of the electricity used in the United States from natural gas. However, major losses of efficiency and reliability in turbines are caused by the tremendous amount of excess heat that turbines create. Current air-cooling technology has limited success in getting rid of this excess heat. This project uses an advanced cooling technology called heat pipes, which can dissipate significantly greater amounts of heat than air cooling. Using this technology will significantly improve fuel consumption, efficiency and reliability of gas turbines resulting in significant cost savings.<br/> <br/>The project involves constructing the vane or blade interior as a heat pipe and extending it into an adjacent heat sink, thus transferring incident heat through the heat pipe to the heat sink.  This design provides an extremely high heat transfer rate and a uniform temperature along the vane due to the internal changes of the phase of the heat pipe working fluid.  Furthermore, this technology eliminates hot spots at the vane leading and trailing edges and increases the vane life by preventing thermal fatigue cracking.  There is also the possibility of requiring no bleed air from the compressor, eliminating engine performance losses resulting from the diversion of compressor discharge air.  Combined air cooling with radially rotating heat pipes is also considered for a better cooling method. The proposed heat pipe is an innovative cooling system that includes non-conventional geometries, evaporation, condensation, vapor flow, and interaction of the liquid/vapor. These complex transport processes of heat transfer and two-phase flow of a liquid metal working fluid under high centrifugal forces and accelerations are all coupled. A detailed design analysis of integrated gas turbine heat pipe vanes and blades is made using artificial intelligence and additive manufacturing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1827427","Collaborative Research: CompCog: Achieving Analogical Reasoning via Human and Machine Learning","BCS","PERCEPTION, ACTION & COGNITION, IIS SPECIAL PROJECTS","08/15/2018","08/15/2018","Alan Yuille","MD","Johns Hopkins University","Standard Grant","Lawrence Gottlob","07/31/2021","$269,869.00","","alan.l.yuille@gmail.com","1101 E 33rd St","Baltimore","MD","212182686","4439971898","SBE","7252, 7484","075Z, 7252","$0.00","Despite recent advances in artificial intelligence, humans remain unmatched in their ability to think creatively. Intelligent machines can use massive data to learn to identify patterns that are similar to learned examples, but people can use very small amounts of data to discover deep similarities between situations that are superficially very different (e.g., engineers have devised a cooling system for buildings using principles adapted from termite mounds). This type of creative thinking depends on analogy: the ability to find and exploit resemblances based on relations among entities, rather than solely on superficial appearances. The present investigation aims to show how relations can be learned from examples (in the form of either texts or pictures) and then used to reason by analogy. The work integrates recent advances in machine learning with more human-like learning mechanisms. Improved analogy models will increase the power of computer-based information retrieval, allowing both text and pictures to serve as retrieval cues to search large databases for items that are analogous in relational structure. The large analogy datasets generated for the project will be made publically available. More flexible search engines will help to automate creative tasks such as engineering design. Identifying the computational basis for relation learning and analogical reasoning will guide development of artificial intelligence systems by providing more efficient learning mechanisms. The research team is integrating research and education activities by using this project as a training opportunity in interdisciplinary research, encompassing psychology, statistics, computer science and mathematics. <br/><br/>The research will integrate advanced computational approaches with behavioral experiments on human relation learning and analogical reasoning, using both texts and pictures as inputs. The work is guided by cognitive theory on learning and reasoning, and exploits recent advances in the field of machine vision. The project includes the creation and validation of multiple databases of analogy problems. Experiments will be performed to establish human performance levels in a variety of tasks. Computational models will be developed by synergizing big-data learning through deep networks with small-data learning through Bayesian modeling. Models will be evaluated by comparison with human benchmarks. By addressing issues that arise in reasoning from natural inputs such as texts and pictures, the models to be developed will generalize to situations that people encounter in their daily life.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1827374","Collaborative Research: CompCog: Achieving Analogical Reasoning via Human and Machine Learning","BCS","PERCEPTION, ACTION & COGNITION, IIS SPECIAL PROJECTS","08/15/2018","08/15/2018","Keith Holyoak","CA","University of California-Los Angeles","Standard Grant","Lawrence Gottlob","07/31/2021","$477,000.00","Hongjing Lu","holyoak@lifesci.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","SBE","7252, 7484","075Z, 7252","$0.00","Despite recent advances in artificial intelligence, humans remain unmatched in their ability to think creatively. Intelligent machines can use massive data to learn to identify patterns that are similar to learned examples, but people can use very small amounts of data to discover deep similarities between situations that are superficially very different (e.g., engineers have devised a cooling system for buildings using principles adapted from termite mounds). This type of creative thinking depends on analogy: the ability to find and exploit resemblances based on relations among entities, rather than solely on superficial appearances. The present investigation aims to show how relations can be learned from examples (in the form of either texts or pictures) and then used to reason by analogy. The work integrates recent advances in machine learning with more human-like learning mechanisms. Improved analogy models will increase the power of computer-based information retrieval, allowing both text and pictures to serve as retrieval cues to search large databases for items that are analogous in relational structure. The large analogy datasets generated for the project will be made publically available. More flexible search engines will help to automate creative tasks such as engineering design. Identifying the computational basis for relation learning and analogical reasoning will guide development of artificial intelligence systems by providing more efficient learning mechanisms. The research team is integrating research and education activities by using this project as a training opportunity in interdisciplinary research, encompassing psychology, statistics, computer science and mathematics. <br/><br/>The research will integrate advanced computational approaches with behavioral experiments on human relation learning and analogical reasoning, using both texts and pictures as inputs. The work is guided by cognitive theory on learning and reasoning, and exploits recent advances in the field of machine vision. The project includes the creation and validation of multiple databases of analogy problems. Experiments will be performed to establish human performance levels in a variety of tasks. Computational models will be developed by synergizing big-data learning through deep networks with small-data learning through Bayesian modeling. Models will be evaluated by comparison with human benchmarks. By addressing issues that arise in reasoning from natural inputs such as texts and pictures, the models to be developed will generalize to situations that people encounter in their daily life.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1840051","FW-HTF: The future of classroom work: Automated Teaching Assistants","DRL","FW-HTF: Advancing Cognitive an","09/01/2018","08/24/2018","Kurt VanLehn","AZ","Arizona State University","Standard Grant","Amy Baylor","08/31/2021","$1,478,882.00","","Kurt.Vanlehn@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","EHR","082Y","063Z, 1340, 8045","$0.00","The Future of Work at the Human-Technology Frontier (FW-HTF) is one of 10 new Big Ideas for Future Investment announced by NSF. The FW-HTF cross-directorate program aims to respond to the challenges and opportunities of the changing landscape of jobs and work by supporting convergent research. This award fulfills part of that aim.  Expert teachers effectively orchestrate the complex flow of ideas and products in the classroom through individual, small group, and whole class activities. In supporting the future work of teachers, this project will facilitate the classroom orchestration process through the development of an intelligent teaching assistant, implemented as a tablet-based dashboard. This will allow the teacher to delegate cognitively-demanding orchestration tasks related to classroom activities to the intelligent assistant, enabling him/her to focus on other tasks to support student learning.  Building on an existing shared-document system for middle school mathematics teachers, the proposed system will facilitate teachers in monitoring student work, assessing it, and making conclusions (e.g., indicating student progress, errors, and misconceptions) while allowing them to circulate among students who are working individually or in small groups.  Ultimately, the system will behave like an automated teaching assistant and allow teachers to be more effective and increase their job satisfaction by allowing them to concentrate on assisting learners who most need help.  <br/><br/>Building on the team's Formative Assessment with Computational Technologies (FACT) system, the development of an intelligent teaching assistant will enhance teachers' awareness of what is going on in the classroom and facilitate the cognitively-intensive tasks of orchestrating classroom activities. In the first six-month phase, the project will employ a knowledge engineering process to uncover the tacit knowledge teachers use for decision-making in managing the flow of classroom activities.  In the second phase, over two and one-half years, a series of ten comprehensive trials will be conducted to iteratively develop the cognitive policies of the system through data collection and optimizing the flow of work and ideas, carefully considering teacher input.  This knowledge will be encoded in a rule-based Artificial Intelligence where the intelligent teaching assistant can perform some of the decision-making.  Authorized by the teacher, it will send messages directly to students in specific situations - some will be feedback, some will be hints, some will be requests to visit other students and some will just be to redirect attention to get back on task.  The automated teaching assistant will also prioritize tasks for the teacher; e.g., which students to visit in the classroom.  As part of this process, new sensors will be added to FACT that will monitor the teacher's speech and location. The potential broader impact includes facilitating teachers in conducting more pedagogically complex and effective lessons and increasing teacher job satisfaction while improving student learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1753761","I-Corps: Automated Spatiotemporal Intelligence Operations for Asset Integrity Management","IIP","I-Corps","11/01/2017","11/01/2017","Christopher Lippitt","NM","University of New Mexico","Standard Grant","Pamular Mccauley","12/31/2018","$50,000.00","","clippitt@unm.edu","1700 Lomas Blvd. NE, Suite 2200","Albuquerque","NM","871310001","5052774186","ENG","8023","9150","$0.00","The broader impact/commercial potential of this I-Corps project includes the enabling of wide scale exploitation of the growing volume of airborne image data from unmanned aerial systems (UAS) to monitor the environment in near real-time. Persistent and tactical surveillance of infrastructure assets (e.g., critical infrastructure, roads, pipelines), military bases, agricultural fields, boarders, or other extensive assets requiring routine monitoring for tactical decision making is becoming cost feasible with the introduction of UAS, but the volume of data collected cannot be exploited using traditional, largely manual, methods. Automated processing and interpretation of large volumes of airborne imagery in near real-time will enable improved decision making and, subsequent, cost reductions and improved performance for a range of industries and agencies. The operations of infrastructure management, disaster response, security, intelligence, and agriculture are amongst the expected beneficiaries.<br/><br/>This I-Corps project explores the commercialization potential of a platform from near real-time analysis and exploitation of airborne image data. Research exploring the development of an airborne system for monitoring critical infrastructure during the response phase on natural disasters resulted in the development of an analytical model for repeat station imaging and refinement of a conceptual model for the design of time-sensitive remote sensing systems that collectively permit the design and implementation of automated change detection and monitoring systems from airborne imaging. This spatial analytics platform automates 3D scene reconstruction, and uses artificial intelligence and machine learning techniques to convert digital photos into a cataloged and indexed spatial intelligence database of changes over time.  3D/4D object classifiers are developed to extract complex features that 2D imagery is unable to represent. This method trains neural networks on volumetric data and multi-temporal spatial data to facilitate the extraction and identification of features and how they have changed. Object identification and characterization will provide the capability to semantically describe changes 3D and 4D space."
"1635253","Improved Human-Computer Interaction for Design of Complex Systems","CMMI","ENGINEERING DESIGN AND INNOVAT","09/01/2016","06/19/2018","Daniel Selva Valero","NY","Cornell University","Standard Grant","Georgia-Ann Klutke","08/31/2019","$299,999.00","So-Yeon Yoon, Guy Hoffman, Daniel Selva Valero","ds925@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","ENG","1464","067E, 068E, 073E","$0.00","Future design of complex systems, for example, the design of aircraft, buildings, and transportation systems, will be done collaboratively by mixed teams of humans and artificial intelligence (AI) systems. The success of this collaboration depends on the degree to which the humans and the AI systems can effectively communicate with each other their goals, intentions and plans of actions. This award seeks to improve how humans and AI systems communicate when designing such systems. In particular, the investigators will give intelligent design agents the ability to provide explanations of their actions and suggestions to humans through both verbal and non-verbal communication channels. It also investigates how the AI system can use robotic body language to improve the collaborative design process. This has potential to have an impact on many aspects of our society which engage in system design, including architecture, medicine, urban planning, industrial design, and business management. Additionally, the research project provides opportunities for education and outreach during its execution.<br/><br/>The research objective of this award is to enable mixed-initiative human-computer design of complex systems by giving intelligent design agents self-explaining abilities, modeling human-computer joint design as a collaborative activity, and leveraging the use of non-verbal channels and embodied interaction to improve human-machine communication in design. Starting from a model of design tools as intelligent agents, and based on the knowledge generated by the Human-Robot Collaboration literature, we will lay out the foundations of a new paradigm for engineering design based on mixed-initiative human-agent collaboration. The four pillars of this new paradigm are: (a) the coordination and meshing of shared plans and intentions between humans and design agents, and their resolution into individual agent plans and actions; (b) the dynamic allocation of roles and gradation of autonomy; (c) the reasoning about, generation, and maintenance of shared attention and common ground; and (d) the integration of verbal and nonverbal channels in communication about agent beliefs, intentions, and goals. Controlled experiments with human subjects will be used to test the effectiveness of the new framework and algorithms. If successful, this research can radically improve the quality of the designs and reduce the resources spent during the design process of complex engineering systems of national importance and high value to society such as systems-of-systems for weather forecasting, climate monitoring, disaster relief, or intelligence, surveillance, and reconnaissance. This research will also have broader impacts into areas outside of engineering that engage in system design activities, including architecture, medicine, urban planning, industrial design, and business management."
"1041707","Spatial Intelligence and Learning Center (SILC)","SMA","GEOGRAPHY AND SPATIAL SCIENCES, SCIENCE OF LEARN CTRS- CENTERS, REAL, Science Across Virtual Instits","10/01/2011","09/15/2017","Nora Newcombe","PA","Temple University","Cooperative Agreement","Soo-Siang Lim","09/30/2018","$18,306,816.00","Susan Goldin-Meadow, Susan Levine, Dedre Gentner, Larry Hedges","newcombe@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","SBE","1352, 7278, 7625, 8077","5912, 5936, 5946, 5948, 7278, 8058, 9177","$0.00","The Spatial Intelligence and Learning Center (SILC) was established in the fall of 2006 as one of three second-cohort Science of Learning Centers. SILC's purpose is to develop the new science of spatial learning and to use this knowledge to transform STEM educational practice. Spatial learning is the acquisition of spatial knowledge and skills, and the use of spatial knowledge and skills to facilitate learning in both spatial and non-spatial domains. It provides the foundation for a wide range of reasoning skills in STEM-based activities, from solving mathematical problems to engineering new products to understanding graphical depictions of complex systems. Previous research shows that spatial skills are a strong predictor of entry into STEM disciplines in college and into STEM careers, that substantial improvement of spatial learning is possible, and that this improvement matters to STEM success. SILC has brought together researchers from multiple lines of work on spatial cognition and education and from a variety of traditional disciplines (e. g., cognitive science, psychology, artificial intelligence, linguistics, education, STEM disciplines), integrating them to achieve new insights. SILC researchers are developing a set of powerful tools for spatial learning, honing them into effective, deployable educational techniques and practices for STEM learning, including advanced technology (e.g., intelligent educational software), effective curriculum units (e.g., in elementary school mathematics), engaging activities (e.g., in children's museums), and spatial assessment instruments (e.g., testing children's spatial skills, testing adults' STEM-relevant spatial skills). Several of the insights, tools and products from SILC's initial funding period already hold transformational potential for spatial learning. Research and translational activities in the second and last funding period, from 2011-2016, will continue the investment in the science of spatial learning, in order to allow the fulfillment of this promise."
"1618193","RI: Small: Linguistic Semantics and Discourse from Leaky Distant Supervision","IIS","ROBUST INTELLIGENCE","08/01/2016","08/11/2017","Hal Daume","MD","University of Maryland College Park","Continuing grant","Tatiana D. Korelsky","07/31/2019","$406,792.00","","hal@umiacs.umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","CSE","7495","7495, 7923","$0.00","This project studies novel algorithms for building artificial intelligence (AI) systems that can learn to improve their performance with a human in the loop. Many recent AI successes are driven by large, expensive and difficult-to-collect datasets. This yields systems that are deep, but narrow. The goal of this project is to build technology that will allow AI systems to learn from their interactions with people. The project focuses on key applications related to natural language understanding: building technology to understand the meanings of individual sentences, and integrate those meanings into the meaning of a discourse or dialog.  One specific application pursued herein relates to extracting biomedical knowledge from text, which will pave the way to helping biomedical researchers develop novel hypotheses.  The work will fund students from underrepresented groups in STEM, and encourage cross-disciplinary education at the graduate and undergraduate levels. Finally, the work will be communicated to the public not just with scientific papers, but internationally through social media and locally through visits to middle schools and high schools.<br/><br/>Natural language processing (and other fields of artificial intelligence) have had enormous success by training supervised  learning systems on large labeled datasets (""corpora"").  Unfortunately, curating such corpora is infeasible except for very specific problems. This happens either because it is too expensive, or it is too difficult to get human labelers to agree on an annotation standard.  Instead of relying solely on human labeled data, this project develops algorithms that can learn from human interaction.  These systems can continually improve their performance based on downstream performance supervision, often with a human in the loop. This work leverages recent developments on the structured contextual bandits learning framework which provides a theoretically grounded and computationally efficient way in which to develop novel approaches to distant supervision. This resulting learning techniques will push advances in natural language understanding: semantic parsing and discourse interpretation. Furthermore, the underlying imitation learning technology is broadly applicable, including novel applications to recurrent neural network models.  To aid adoption by the research community, code and data from this project will be released open source."
"1718846","RI: Small: Linguistic Structure in Neural Sequence Models","IIS","ROBUST INTELLIGENCE","08/01/2017","07/27/2017","Jason Eisner","MD","Johns Hopkins University","Standard Grant","Tatiana D. Korelsky","07/31/2020","$395,002.00","","jason@cs.jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","7495","7495, 7923","$0.00","Over the past 25 years, the field of artificial intelligence has made great strides in the ability to automatically analyze and generate sequential data.  Much of this progress has come by building probabilistic models.  For example, mathematical descriptions of how words are typically used in context are based on a scientific understanding of the relationships among letters, sounds, words, and phrases, thanks to the field of linguistics.  Probabilistic models based on this understanding have allowed us to develop computational, data-driven methods for reasoning about the likely structure and meaning of sentences.  In the same way, probabilistic models of sequences of events have led to computational methods for predicting the unfolding of future events and reconstructing the ordering of past ones.  This project starts with sophisticated probabilistic models of linguistic structure and event sequences, and aims to make them more powerful, by using ""deep learning"" (neural networks) to increase their sensitivity to contextual effects.  Deep learning has already recently had a revolutionary impact on artificial intelligence.  This research will focus on using deep learning to enhance probabilistic models in settings where the model must discover structure that is not provided in its training data, such as the compositional units of language or the causal relations among events.<br/><br/>The planned model design will not focus on hand-engineered features, but rather on broad representational choices.  The overall architectures are motivated by certain basic notions that linguists and other modelers have found indispensable in their analyses of empirical data as follows: (1) stick-breaking processes that respect duality of patterning, the linguistic notion that a word's internal form is not necessarily related to its external usage but is governed by separate rules or by chance; (2) finite-state transducers that can capture local editing that transforms an input sequence into an output sequence; (3) context-free grammars that can model hierarchical structure to help explain word sequences; and (4) temporal point processes that can capture process intensity, where different events are competing to occur next, and combinations of earlier events combine to elevate or suppress the rates of later events.  The project will infuse these probabilistic techniques with recurrent neural networks, in particular, long short-term memory (LSTM) networks.  In some cases, exact inference in the resulting models will not be tractable, necessitating the design of Monte Carlo or variational approximations."
"1630047","Symposium on Combinatorial Search, SoCS-2016","IIS","ROBUST INTELLIGENCE","07/01/2016","06/17/2016","Richard Korf","CA","University of California-Los Angeles","Standard Grant","James Donlon","06/30/2019","$7,000.00","","korf@cs.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","CSE","7495","7495, 7556","$0.00","This grant is to provide partial support for U.S.-based graduate and undergraduate students to attend the Ninth Symposium on Combinatorial Search (SoCS-2016), a scientific conference to be held at Tarrytown, NY from July 6-8, 2016. Combinatorial search is an area of artificial intelligence that deals with systematic trial-and-error exploration of a very large number of alternative solutions to a problem.   NSF funding is crucial to support students who would otherwise not be able to attend the symposium.  Attending such meetings and presenting their research is an important part of the professional development of students, addressing a critical shortage of highly-skilled computer scientists in the U.S.<br/><br/>SOCS brings together researchers in heuristic search and combinatorial optimization from all areas of artificial intelligence, planning, robotics, constraint programming, operations research, and bioinformatics.  The intellectual merit of this activity stems from bringing together in one place at one time researchers from otherwise diverse areas of computer science that both advance the state of the art in heuristic search and/or combinatorial optimization, and also use these tools in their research.  The broader impacts come from cross-fertilization of different fields that advance and/or use these tools, by promoting research in this area by providing a small intimate meeting on these topics, a forum for presenting such work, and archival proceedings for publishing work in this area.  These latter goals are instrumental to training new researchers in this area."
"1822861","Human/AI Co-Orchestration of Dynamically-Differentiated Collaborative Classrooms","IIS","STEM + Computing (STEM+C) Part, Cyberlearn & Future Learn Tech","09/01/2018","08/23/2018","Vincent Aleven","PA","Carnegie-Mellon University","Standard Grant","Kurt Thoroughman","08/31/2021","$749,995.00","Nikol Rummel","vincent.aleven@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","005Y, 8020","063Z, 8045","$0.00","This project will create and demonstrate new technology that supports dynamically-differentiated instruction for the classroom of the future. This new vision centers on carefully-designed partnerships between teachers, students, and artificial intelligence (AI). AI-powered learning software will support students during problem-solving practice, providing either individual guidance (using standard intelligent tutoring technology) or guidance so students can effectively collaborate and tutor each other. These learning activities are constantly adjusted to fit each student's needs, including switching between individual or collaborative learning. The teacher ""orchestrates"" (instigates, oversees, and regulates) this dynamic process. New tools will enhance the teacher's awareness of students' classroom progress. The goal is to have highly effective and efficient learning processes for all students, and effective ""orchestration support"" for teachers. We will implement and test this vision in the context of AI-enhanced mathematics learning in middle school. The proposed work will greatly enhance current understanding of how to design effective AI-based ""co-orchestration"" tools that draw on complementary strengths of teachers, students/peers, and AI agents to make the vision of the dynamically-differentiated classroom feasible. It will provide insight into the new classroom dynamics that arise. The work may ultimately contribute to more individualized K-12 education. The work will create a testbed that could be used to explore and rigorously test a wide range of interesting hypotheses regarding co-orchestration and dynamic differentiation of individual and collaborative learning. <br/><br/>Effective orchestration of dynamically-differentiated instruction poses significant challenges in terms of design and technical implementation. Although existing AI-based learning technologies support forms of dynamic differentiation of instruction, they tend not to support dynamic combinations of individual and collaborative learning; in fact, most only support one of these two learning modes. In addition, existing teacher support tools tend to focus only on enhancing teacher awareness, not on supporting teachers' in-the-moment decision-making and action, and not on supporting dynamic interleaving of individual and collaborative learning. In the proposed work, we tackle this challenge by integrating and extending four strands of work: intelligent tutoring systems technology; a learning environment to support combinations of individual and collaborative learning; adaptive technology support for mutual peer tutoring; and a mixed reality tool (""smart glasses"") to support teacher/AI co-orchestration. Building on this foundation, we create and demonstrate technology support for dynamically-differentiated instruction by three strands of work. First, we create AI-based tutoring software capable of supporting both individual learners and students doing mutual peer tutoring. Second, we develop a tool to support the intelligent, real-time co-orchestration, between students, teachers, and AI agents, of dynamically differentiated combinations of collaborative learning and individual learning. We do so through design-based research, prototyping, and classroom piloting. Third, we evaluate the newly-created technology for dynamically-differentiated collaborative classroom in schools, to gain an initial understanding of its benefits and challenges, and the changes in classroom practices and learning outcomes that it brings about.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1458272","IRES: Avatar-based Adaptive Context System","OISE","IRES Track I: IRES Sites (IS)","06/15/2015","06/03/2015","Avelino Gonzalez","FL","University of Central Florida","Standard Grant","Charles H. Estabrook","05/31/2019","$231,974.00","","gonzalez@ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","O/D","7727","5936, 5980, 7727","$0.00","Part 1<br/>This interdisciplinary partnership between the University of Central Florida and the Fraunhofer Institute for Digital Media Technology (FIDMT) in Ilmenau, Germany is focused on adaptive conversational avatars, the rapidly emerging field crossing computer engineering, computer science, education, communications, and social science.  Immediate applications of this research field include artificial intellegence and national security (including cyber-security), interactive robotics, improvement of quality of life for disbaled, and health and caretaking for children and elderly.<br/>This project will place students from the University of Central Florida under the mentorship of the PI (Dr. A. J. Gonzalez) and of Dr. Klaus Jantke, the counterpart at FIDMT in Ilmenau, Germany. Dr. Jantke is the director of the Children's Media Department of FIDMT located in Erfurt, Germany and has a long and illustrious history in research in computing media. The international aspect of innovative and advanced research is essential in modern research hence the PIs will work with three cohorts of students, one during each year of the project's existence. Each cohort will include one graduate student and either two undergraduates (the first year) or four (in each of the subsequent years).  The research period for each cohort will be 16 weeks - eight weeks in the US and eight weeks in Germany for each year of the grant period.<br/>This research project is motivated by an ancient art of storytelling. In our pursuit of an artificially intelligent computer agent, the IRES project seeks to build a capability to autonomously synthesize possible scenarios for the system development and to modify them dynamically upon listener request. More specifically, the topic of the research in this project is the creation of an avatar-based system that can synthesize and adapt a scenario according to the user's request in real time and without any pre-scripted pathways. Good storytellers were treasured in medieval times, given the lack of other media through which to relate a story to a mostly illiterate population. Therefore, the project seeks to embody the storyteller in a lifelike avatar that resembles an actual person. This avatar will tell the story to the listener in spoken natural language, and interact with her/him when the latter requests changes to the story. <br/><br/>Part 2<br/>Storytelling media have evolved over time, from oral stories to modern E-books. Since the development of the computer, storytelling systems have become a science of their own, and have evolved from simple systems that can only generate a single short story to systems that respond to the listener's actions by modifying the story dynamically in real time. Digital storytelling has therefore become a growing field within artificial intelligence. The project seeks to take this evolution of storytelling media one step further by doing research to create a virtual storyteller who tells a dynamic story. The story is modifiable through a request by the listener (typically a child, a student, or an elderly person), yet will seek to remain realistic as well as interesting. Every story has a story space. That is, only so many things can happen in a story. We use contextual reasoning to represent the story space. In the real world, courses of action are influenced by the current context, making some conversational avatars very attractive while others unattractive when addressing the current situation within the story space. In a similar manner, the situation faced by the protagonist in the dynamic scenario will limit the choices of actions that he/she would otherwise have, thereby taking the story in various directions, none of which need be specifically pre-scripted.  The PIs base the proposed research on the use of formal methods to manipulate the story space within the main theme of the story. By formal methods the PIs mean that one represents the story knowledge formally in terms of strings, interaction sequences such as storyboards and graphs, formulas (for conditions), and the like. Formal methods, therefore, will give the ability to reason with formal methods (string comparison, unification, anti-unification and the like) in the story space. Formal methods have been used in the literature to manipulate contextual information."
"1742656","Image-Data-Driven Deep Learning in Geosystems","CMMI","Geotechnical Engineering and M","09/01/2017","07/30/2017","Zhen Liu","MI","Michigan Technological University","Standard Grant","Richard J. Fragaszy","08/31/2019","$227,367.00","Shiyan Hu","zhenl@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","ENG","1636","036E, 037E, 038E, 1057, CVIS","$0.00","Breakthroughs in deep learning in 2006 triggered numerous cutting-edge innovations in text processing, speech recognition, driverless cars, disease diagnosis, and so on.  This project will utilize the core concepts underlying the recent computer vision innovations to address a rarely-discussed, yet urgent issue in engineering: how to analyze the explosively increasing image data including images and videos, which are difficult to analyze with traditional methods. These concepts will be employed to explore the possibility of accurately assessing the safety of retaining walls with image data.  This effort aims at setting up a paradigm for connecting engineering disciplines to artificial intelligence and enhancing the safety of geosystems as an essential infrastructure component by enabling their analysis with image-data-driven deep learning.  The project will help revitalize traditional artificial intelligence sub-areas in geotechnical and other engineering areas, just as deep learning rekindled the interest in artificial neural networks and machine learning, and turned them into leading players in STEM research and innovations.  The project may also change engineers' opinions regarding how to create knowledge with a revolutionary way attributed to deep learning, i.e., learning directly from data instead of indirectly from models established based on the data.  Innovative education and outreach effort will be made by means of developing a mobile app to disseminate the idea and products of the project.  The project will contribute to education by outreaching to K-12 students, underrepresented groups, and geotechnical engineering researchers and practitioners with the project products including the app at various events at the PIs' institution and professional conferences. <br/><br/>The goal of this study is to understand the image-data-driven deep learning in geosystems with an exploratory investigation into the stability analysis of retaining walls.  To achieve the goal, the recent breakthroughs in computer vision, which were later used as one of the core techniques in the development of Google's AlphaGo, will be studied for its capacity in assessing the stability of a typical geosystem, i.e., retaining walls.  The core concept enabling machines to surpass humans in visual classification capacity, i.e., convolutional neural nets (CNN), will be used to process the big data in geotechnical engineering, which primarily consist of still and live images (videos), that cannot be readily analyzed using traditional geotechnical engineering methods.  Conventional neural nets will be used to analyze images for retaining walls to tell whether a wall is safe or failed.  For quantitative analysis, 2D and 3D images for retaining walls will be generated using stochastic methods and analyzed using traditional limit analysis and numerical methods for labeling.  These labeled image data will be used as input to train convolutional neural nets for supervised learning. The trained nets will be tested against another independent set of data generated in the same way as the training data. Three research tasks will be conducted in this project: 1) understanding the data science for image-data-driven geotechnical engineering research, 2) investigating the connections between those image patterns in deep learning and the physical mechanisms, and 3) revealing the robustness and extrapolation capacity of the deep learning approach in the stability analysis of retaining walls."
"1810402","Spatially resolve three-dimensional tactile sensing using functionally graded piezoresistive pillar arrays","ECCS","ELECT, PHOTONICS, & MAG DEVICE","08/01/2018","07/31/2018","Burak Aksak","TX","Texas Tech University","Standard Grant","Usha Varshney","07/31/2021","$287,659.00","Richard Gale","burak.aksak@ttu.edu","349 Administration Bldg","Lubbock","TX","794091035","8067423884","ENG","1517","8028","$0.00","Despite much advancement in materials, computation power, actuators, sensors, and design, robots drastically lag in their ability to match humans in dexterous manipulation. Studies that show success in robotic manipulation suffer from complex sensing schemes and extensive post processing steps because they utilize tactile sensors that are not capable of human-like high spatial resolution or contact force magnitude and direction detection. Artificial skin-like flexible tactile sensors that can resemble the tactile sensing capabilities of their biological analogue are bound to revolutionize robotics, providing unprecedented control and dexterity, and support the recent advancements in artificial intelligence and humanoid robotics. This work addresses the pressing need for skin-like distributed tactile sensors and proposes a novel tactile sensor of flexible construction, which can resolve dynamic contact forces with fingertip-like high spatial resolution. The proposed work is transformative in its ability to equip robotic manipulators with tactile feedback comparable to that of humans, paving the way to human-like dexterity in robotics. This innovative technology has the potential to be a significant step toward the realization of corobots living and working with humans. This project complements the educational activities in biomimetic engineering and entrepreneurial awareness, giving undergraduate and graduate students the opportunity to be involved in cutting-edge research and gain skills in innovative thinking and entrepreneurship. Educational outreach activities to introduce and promote engineering to K-12 students and underrepresented groups will be an integral part of this project.   <br/><br/>The goal of this work is to enable spatially resolve three-dimensional contact force imaging and provide skin-like touch sensing capabilities (namely, local three-dimensional dynamic force sensing) to robotic platforms and facilitate human-like dexterous manipulation in robotic manipulators. The PI will achieve this goal by fabricating a novel array-type tactile sensor comprising a fibrillar polymeric contact layer which amplifies contact forces at the integrated piezoresistive base sensing layer and a flexible substrate with integrated electrodes. Preliminary experiments have demonstrated composite piezoresistors with pressure sensitivity close to that of a human fingertip. The objectives of the proposed work are to  (i) design a composite microfibrillar sensor array, based on piezoresistive sensing, which would be flexible, cheap, and durable; (ii) develop repeatable and scalable fabrication techniques; (iii) study the underlying physics for composite fiber sensing using micro-and-mesoscale characterization techniques; and (iv) study and demonstrate friction characterization, slip detection, and slip prevention using custom characterization tools.  The long-term scientific goal is to understand and quantify the relationship between three dimensional spatio-temporal contact force images and manipulation to advance robotics as well as its medical and biological applications. If successful, this project, in addition to providing unprecedented control and dexterity in robots, will support the recent advancements in other important areas of robotics, for example in artificial intelligence and humanoid robotics.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1827314","MRI: Acquisition of a GPU Accelerated Vermont Advanced Computing Core","OAC","MAJOR RESEARCH INSTRUMENTATION","09/01/2018","08/23/2018","Adrian Delmaestro","VT","University of Vermont & State Agricultural College","Standard Grant","Stefan Robila","08/31/2020","$893,120.00","Hugh Garavan, Yolanda Chen, Juan Vanegas, Joshua Bongard","Adrian.Delmaestro@uvm.edu","85 South Prospect Street","Burlington","VT","054050160","8026563660","CSE","1189","026Z, 062Z, 075Z, 1189, 8089, 8091, 9150","$0.00","This project will enable interdisciplinary science through the acquisition of a high-performance computer cluster, named DeepGreen.  Based on cutting-edge massively parallel graphics processing unit (GPU) technologies, DeepGreen will be utilized by the over 300 users from six Colleges at the University of Vermont, and throughout the Northeast. The unique hybrid architecture was designed to optimize artificial intelligence (AI) applications and will allow for rapid progress on problems of great societal importance. They include: quantum computing, drug discovery and design, safe robotics, control of adaptive crop pests, and new computer vision tools for use in the health care and transportation industries.  As an example, DeepGreen will allow the training of neural networks on the world's largest brain imaging datasets of illicit drug users, yielding novel health and policy strategies to combat the opioid epidemic.  A focus of the scientific and technical team is to broaden the number of personnel able to exploit GPU hardware for problem solving, producing the highly trained and diverse technical workforce required for the current and future AI economy. <br/><br/>DeepGreen was designed by a team of experts from the physical, medical, biological, computational, and agricultural sciences, partnered with an experienced group of information technology professionals.  It will be capable of over 8 petaflops of mixed precision calculations based on the latest NVIDIA Tesla V100 architecture with a hybrid design allowing high bandwidth message passing across heterogeneous compute nodes.  Its extreme parallelism will facilitate research in three interconnected areas: quantum many-body systems, molecular simulation and modeling, and deep learning, artificial intelligence and evolutionary algorithms.  DeepGreen will forge transformative research pipelines. It will enable the study of thousands of quantum entangled atoms, and millions of interacting components in biological systems providing insights into structure-function mechanisms.  Machine learning and deep neural networks will exploit DeepGreen's Tensor Cores to solve diverse problems. These problems include: the development of coarse grained potentials for use in molecular dynamics simulations, real time dynamic processing of crowd sourced decision making for robotics, genomic sequencing of invasive pests, and feature recognition in medical imaging to distinguish cancerous tumors from benign nodules.  Software designed for use on DeepGreen will be released to the public as open source, with other scientists and researchers being able to immediately use and extend it. This project will also support the next generation of data scientists. Training workshops focused on GPU computing and machine learning frameworks, new university courses, and partnerships with existing local NSF-funded graduate training initiatives, will drive broad utilization of DeepGreen.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1802789","D3SC: CDS&E: Collaborative Research: Development and application of accurate, transferable and extensible deep neural network potentials for molecules and reactions","CHE","Theory, Models, Comput. Method","07/15/2018","07/10/2018","Olexandr Isayev","NC","University of North Carolina at Chapel Hill","Standard Grant","Susan Atlas","06/30/2021","$350,836.00","","olexandr@email.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","MPS","6881","026Z, 062Z, 8084, 9216, 9263","$0.00","Adrian Roitberg of the University of Florida and Olexandr Isayev of the University of North Carolina at Chapel Hill are supported by an award from the Chemical Theory, Models and Computational Methods program in the Division of Chemistry. Empirical potentials---also known as force fields---play an essential role in simulating atomic-scale interactions between molecules.  They are used in the computational design of materials and pharmaceuticals.  However, current potentials have been designed to be fast or accurate, but rarely both.  This presents a critical bottleneck for the next phase of predictive chemical computer models.  In this project, Professors Roitberg and Isayev are leveraging state-of-the-art artificial intelligence (AI) to ""learn"" potentials from ultra-large datasets of molecular energies and chemical reactions. The project is creating a new force field, ANI, that is accurate and fast, while also applicable to a broad range of systems in chemistry.  This research has the potential to benefit materials design, renewable energy research, and drug design.  The project is first step toward the use of artificial intelligence techniques to create new materials and molecules beyond what the human imagination can do alone. The research team is engaged in outreach through workshops on molecular simulations, ""Talk science to me"" science for the general public, and the involvement of high school students from the North Carolina School of Science and Math (NCSSM) in the research.<br/> <br/>The objective of this project is to develop a chemically-accurate, extensible, and universal neural network potential, ANI, for use in ""in silico"" organic chemistry experimentation. The range of possible applications for ANI is very broad, from conformational searches to chemical reactions and ligand binding. Through intelligent sampling of new regions of chemical space, the researchers are expanding use cases for ANI to include arbitrary systems containing H, C, N O, F, S, P, Cl and Br atoms. The new design strategy is based on the ANAKIN-ME method, used in implementing the earlier ANI-1 potential. To train ANI-1, a database of wB97x/6-31G* DFT energies for 22 million structural conformations from 60,000 distinct organic molecules was computed through exhaustive, stochastic sampling of conformational and chemical space. Through rigorous benchmarks for organic molecules, biomolecules, and peptides, ANI-1 predicted total and relative energies with RMS errors under 1 kcal/mol, when compared to DFT reference values.  The enhancements being made to ANAKIN-ME are aimed at improving computational efficiency, expanding the range of systems that can be simulated, and achieving < 1 kcal/mol RMS error in comparison to high quality CCSD(T)/CBS quantum chemical energies. These enhancements include reducing the required dataset size for a given set of atom types, to enable inclusion of additional elements and chemistries; expanding training datasets to include data on atomic charges and forces, in addition to energies, and data for charged molecules; and implementing ""query-by-committee"" active learning approaches to facilitate learning of addition, substitution, and elimination chemical reactions by ANI.  The ANI potential is being disseminated through user-friendly open access mechanisms. The implementation of the ANI potential takes advantage of graphics processing unit (GPU) acceleration to run on GPU-enabled workstations and parallel supercomputers.  The ANI software library has a simple Python API and is being integrated with popular molecular modeling and simulation packages such as AMBER, OpenMM and Avogadro.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1406049","II-EN: Software Tools for Monte-Carlo Optimization","CNS","COMPUTING RES INFRASTRUCTURE, ROBUST INTELLIGENCE","10/01/2014","06/20/2016","Alan Fern","OR","Oregon State University","Standard Grant","Reid Simmons","09/30/2019","$456,286.00","Thomas Dietterich, Prasad Tadepalli, Sinisa Todorovic, Alex Groce","afern@eecs.oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7359, 7495","7359, 7495, 9251","$0.00","The Computing Research Infrastructure project supports the development of an open-source software library for Monte Carlo methods in artificial intelligence on a cloud-based platform.  Monte Carlo methods are randomized numerical algorithms used in AI, machine learning, data mining, and the physical sciences.  As data size and model complexity continue to grow, advanced large-scale Monte-Carlo techniques (including parallel implementation) has become ubiquitous.  However software tools to easily implement advanced techniques for large-scale Monte Carlo are not established or broadly available.<br/><br/>The software library developed in this project will help bridge this gap, and lower the barrier to adoption of advanced Monte Carlo techniques by a broad research community.  The library will include a variety of existing state-of-the-art algorithms, as well as novel software components. The algorithms and tools have many important applications, including: <br/>(a) optimization of ecological management problems, including endangered species conservation, forest fire management, and invasive species management (b) automated software testing, (c) optimization for experimental design in science and engineering, (d) tracking of multiple objects from noisy visual evidence, and (e) activity and object recognition in computer vision. These problems have significant societal and economic importance and the research has the potential to significantly extend current capabilities.<br/><br/>The algorithms and tools will be implemented using a common interface supporting a cloud-based platform, which will allow other researchers to extend and apply the library to important applications. The software library will be integrated into the<br/>undergraduate and graduate curriculum at Oregon State University.  In addition, an online course centered around the theory and application of the library components will be developed, facilitating use by a wide audience.<br/><br/>The developed library will include components based on the investigators' research that realize a number of technical<br/>innovations for Monte-Carlo Optimization (MCO), including: a) Exploiting multi-fidelity simulators in MCO for offline and online planning, (b) Developing MCO techniques for item discovery problems, (c) Developing MCO techniques for online policy improvement in sequential decision making, (d) Learning to reduce branching factors for more efficient online MCO, and (e) Integrating symbolic reasoning and MCO for scalable sequential decision making. These new capabilities will advance the state-of-the-art in artificial intelligence and enable new applications to be addressed that are beyond the scope of prior MCO methods."
"1802831","D3SC: CDS&E: Collaborative Research: Development and application of accurate, transferable and extensible deep neural network potentials for molecules and reactions","CHE","Theory, Models, Comput. Method","07/15/2018","07/10/2018","Adrian Roitberg","FL","University of Florida","Standard Grant","Susan Atlas","06/30/2021","$435,561.00","","roitberg@ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","MPS","6881","026Z, 062Z, 8084, 9216, 9263","$0.00","Adrian Roitberg of the University of Florida and Olexandr Isayev of the University of North Carolina at Chapel Hill are supported by an award from the Chemical Theory, Models and Computational Methods program in the Division of Chemistry. Empirical potentials---also known as force fields---play an essential role in simulating atomic-scale interactions between molecules.  They are used in the computational design of materials and pharmaceuticals.  However, current potentials have been designed to be fast or accurate, but rarely both.  This presents a critical bottleneck for the next phase of predictive chemical computer models.  In this project, Professors Roitberg and Isayev are leveraging state-of-the-art artificial intelligence (AI) to ""learn"" potentials from ultra-large datasets of molecular energies and chemical reactions. The project is creating a new force field, ANI, that is accurate and fast, while also applicable to a broad range of systems in chemistry.  This research has the potential to benefit materials design, renewable energy research, and drug design.  The project is first step toward the use of artificial intelligence techniques to create new materials and molecules beyond what the human imagination can do alone. The research team is engaged in outreach through workshops on molecular simulations, ""Talk science to me"" science for the general public, and the involvement of high school students from the North Carolina School of Science and Math (NCSSM) in the research.<br/> <br/>The objective of this project is to develop a chemically-accurate, extensible, and universal neural network potential, ANI, for use in ""in silico"" organic chemistry experimentation. The range of possible applications for ANI is very broad, from conformational searches to chemical reactions and ligand binding. Through intelligent sampling of new regions of chemical space, the researchers are expanding use cases for ANI to include arbitrary systems containing H, C, N O, F, S, P, Cl and Br atoms. The new design strategy is based on the ANAKIN-ME method, used in implementing the earlier ANI-1 potential. To train ANI-1, a database of wB97x/6-31G* DFT energies for 22 million structural conformations from 60,000 distinct organic molecules was computed through exhaustive, stochastic sampling of conformational and chemical space. Through rigorous benchmarks for organic molecules, biomolecules, and peptides, ANI-1 predicted total and relative energies with RMS errors under 1 kcal/mol, when compared to DFT reference values.  The enhancements being made to ANAKIN-ME are aimed at improving computational efficiency, expanding the range of systems that can be simulated, and achieving < 1 kcal/mol RMS error in comparison to high quality CCSD(T)/CBS quantum chemical energies. These enhancements include reducing the required dataset size for a given set of atom types, to enable inclusion of additional elements and chemistries; expanding training datasets to include data on atomic charges and forces, in addition to energies, and data for charged molecules; and implementing ""query-by-committee"" active learning approaches to facilitate learning of addition, substitution, and elimination chemical reactions by ANI.  The ANI potential is being disseminated through user-friendly open access mechanisms. The implementation of the ANI potential takes advantage of graphics processing unit (GPU) acceleration to run on GPU-enabled workstations and parallel supercomputers.  The ANI software library has a simple Python API and is being integrated with popular molecular modeling and simulation packages such as AMBER, OpenMM and Avogadro.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1738065","EAGER: SC2: Intelligent spectrum collaboration via a dynamically reconfigurable radio architecture","CNS","Networking Technology and Syst","04/01/2017","03/24/2017","Tan Wong","FL","University of Florida","Standard Grant","Monisha Ghosh","03/31/2019","$99,363.00","John Shea","twong@ece.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","7363","7916","$0.00","Current engineering practices and regulatory approaches on the use of the radio frequency (RF) spectrum are too antiquated to meet the ever<br/>surging demand on the RF spectrum. A promising new solution to tackle this spectrum scarcity problem is to equip radio networks with artificial intelligence so that they can learn and predict the RF environment, as well as be social by interacting with other radio networks, leading to more collaborative use of the RF spectrum. This project will develop a software-defined radio system that can intelligently sense and adapt to others' use of the radio spectrum and collaborate with other radio networks in sharing the common RF spectrum. The developed system will be characterized by its flexibility to quickly and agile adaptability to changes in how others are using the RF spectrum. It will be also be characterized by how it uses machine-learning techniques to both extract the most relevant information about how the RF spectrum is being used and to adapt the communication strategies based on this information.<br/><br/>A dynamically reconfigurable system architecture will be developed in this project to make most efficient use of all the available computational resources in order to support all radio and ML functionalities. This highly flexible software-defined structure takes advantage of the learned knowledge about the RF environment by adapting the physical and medium access control layers use of spectrum and coordinating this utilization through carefully designed network protocols. A machine learning system is developed to identify the key information about the evolution of the communication scenario, and autonomously learn the state of the model.  Reinforcement learning will be used to generate appropriate adaptive communication strategies based on the system state."
"1833225","Belmont Forum Collaborative Research Food-Water-Energy Nexus: Intelligent Urban Metabolic Systems for Green Cities of Tomorrow: an FWE Nexus-based Approach","ICER","INTERNATIONAL COORDINATION ACT","07/01/2018","07/03/2018","Luis Rodriguez","IL","University of Illinois at Urbana-Champaign","Continuing grant","Maria L. Uhle","06/30/2021","$247,793.00","Yanfeng Ouyang, Shaowen Wang","lfr@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","GEO","1679","1679, 7313, EGCH","$0.00","Many cities across the globe are facing difficult challenges managing their food, water and energy systems. The challenges stem from the fact that the issues of food, water and energy are often tightly connected with each other, not only locally but also globally. This is known as the Food-Water-Energy (FWE) nexus.  An effective solution to a local water problem may cause new local problems with food or energy, or cause new water problems at the global level. On a local scale, it is difficult to anticipate whether solutions to one issue in the nexus are sustainable across food, water and energy systems, both at the local and the global scale.  Innovative solutions that encompass the nexus are particularly important to enable cities to better manage their food, water and energy systems and understand the benefits and tradeoffs for different solutions.  <br/><br/>This award supports U.S. researchers participating in a project competitively selected by a 29-country initiative through the joint Belmont Forum- Joint Programming Initiative (JPI) Urban Europe.  The Sustainable Urbanization Global Initiative (SUGI)/Food-Water-Energy Nexus is a multilateral initiative designed to support research projects that bring together the fragmented research and expertise across the globe to find innovative solutions to the Food-Water-Energy Nexus challenge.  The call seeks to develop more resilient, applied urban solutions to benefit a much wider range of stakeholders. The rapid urbanization of the world's population underscores the importance of this focus. International partners were invited to develop solutions for this challenge.  The funds requested will be used to support U.S. participants to cooperate in consortia that consist of partners from at least three of the participating countries and that bring together natural scientists, social scientists and research users (e.g., civil society, NGOs, and industry).  Participants from other countries are funded through their national funding organizations. <br/><br/>This project aims to identify the key factors of urban metabolism and their complex interactions from FWE Nexus perspective and to improve the cost-benefit for FWE consumption by optimizing food-water-energy reallocations. This project will identify critical FWE factors and define critical pathways of food-water-energy delivery to urban centers using advanced tools such as Artificial Intelligence, data mining, system dynamics modelling, agro-logistics and scenario analysis.  The project seeks to understand the intertwined nature of food-water-energy in terms of their lifecycles, including production, processing, delivery, consumption, and disposal. The primary outcome will be the development of the intelligent urban metabolic systems for cities with challenges for green urban centers of tomorrow.  The comprehensive solutions will provide stakeholders and decision makers with information that can be used to develop strategies to help sustain the inevitable trends of urbanization by effectively managing the food-water-energy nexus.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1554626","CAREER: Smart Protection for DC Power Systems: Distributed and Proactive Approach","ECCS","ENERGY,POWER,ADAPTIVE SYS","03/01/2016","01/19/2016","Jae-Do Park","CO","University of Colorado at Denver","Standard Grant","Anil Pahwa","02/28/2021","$500,000.00","","jaedo.park@ucdenver.edu","MS F428, AMC Bldg 500","Aurora","CO","800452570","3037240090","ENG","7607","1045, 155E","$0.00","The goal of this CAREER project is to provide intelligent solutions for the protection of DC power systems, which is one of the major barriers that prevent the wide usage of DC power systems. DC power systems have received renewed attention due to a number of advantages they offer such as easy renewable energy resource integration, high-efficiency long distance transmission, and simpler interface with power electronics converters. Applications including microgrids with distributed generators, bulk power transmission, and low-voltage distribution systems have been investigated. Compared to the control aspects of DC systems that have made sizable progress, system protection has always been a challenge. The research in this project will address protection issues for DC power systems, which will contribute to strengthen this important aspect of DC power systems and can have impact in various applications. The outcomes of this research will be disseminated through presentations and publications and can be readily utilized in conjunction with other aspects of distributed and/or sustainable energy applications using DC power to generate synergistic effects on overall system reliability improvement. Furthermore, this CAREER project will academically and financially support graduate students and nurture them to prepare them as part of the next generation of multidisciplinary researchers and engineers. The project will also provide ample research opportunities to undergraduate students.<br/><br/>While the advantages of DC power systems are great, the protection aspects of these systems have posed many challenges such as effectively breaking a DC arc, autonomously locating a fault within a microgrid, DC protective equipment, and certainly the lack of standards, guidelines and experience. Although protection technology for AC systems has a long history and maturity, it is difficult to directly apply these to DC systems because of the non-alternating nature and fast dynamics of DC power. Hence, the protection of DC power systems needs to take a fundamentally different approach than that of existing AC technologies. Furthermore, complex modern power systems need more intelligence for their operation. In this CAREER project, a distributed and proactive approach will be taken as the project aims to provide a protection framework with swift fault current interruption, accurate fault location, and distributed decision-making based on various system parameters. The protection framework development will contain integrated components for fast responses and compound decisions based on multi-dimensional intelligence. The successful execution of this CAREER project will contribute to the implementation of modern power systems that take advantage of DC power. The activities will result in multidisciplinary research as well as educational impacts, and will provide interesting and useful applications of advanced artificial intelligence, control and communication technologies to the power and energy system area."
"1237080","SHB: Type II (INT): Collaborative Research: Creating Learning Systems with Mobile Technology to Improve Coordination in Perioperative Services","IIS","INFO INTEGRATION & INFORMATICS, Smart and Connected Health","10/01/2012","07/28/2014","Nathan Huynh","SC","University South Carolina Research Foundation","Standard Grant","Sylvia J. Spengler","09/30/2018","$585,916.00","Jose Vidal","huynhn@cec.sc.edu","1600 Hampton Street","COLUMBIA","SC","292080001","8037777093","CSE","7364, 8018","7364, 8018, 8062, 9150, 9251","$0.00","This project proposes to create a framework using a combination of mobile technology, learning systems, data analytics, education, and training to enhance cooperation and coordination of staff within and across perioperative services departments (POS).  Perioperative services comprise surgery preparation, operating rooms, post-anesthesia care, sterile processing and a variety of other services, such as radiology and endoscopy.  The specific objectives of this project are to: (1) enhance communication and coordination among POS staff to improve the quality of care by gathering and using important workflow milestones and introducing artificial intelligence techniques through the use of a smart-app, (2) analyze workflow data gathered with smart-apps using data analytics to provide intuitive displays of real-time information for frontline staff and a daily performance dashboard for managers, and (3) induce behavioral and cultural change in healthcare systems through training and education. While existing  information technology capabilities such as natural language processing, artificial intelligence, and speech recognition technology are promising developments in computing, their uses in health care are limited and thus need to be thoroughly investigated before they can be used in health care effectively. To accomplish these objectives, the research team will work closely with the partnering healthcare organizations, Greenville Hospital System (GHS), Palmetto Health (Palmetto), and the Medical University of South Carolina (MUSC), in developing the tools and models which will be pilot-tested at these organizations by their staff.  <br/><br/>The developed tools and models will be widely disseminated among health care providers in South Carolina. In addition, the smart-apps and agent-based simulation model will provide the team with a teaching and training tool that can be used in the classroom at Clemson University and the University of South Carolina (USC) to teach students across a variety of fields, such as business, engineering, science and healthcare students about information and workflow management techniques."
"1832091","WORKSHOP: Doctoral Consortium at AAAI Conference on Human Computation & Crowdsourcing (HCOMP 2018)","IIS","Cyber-Human Systems (CHS)","04/01/2018","03/21/2018","Carsten Eickhoff","RI","Brown University","Standard Grant","Ephraim P. Glinert","03/31/2019","$24,009.00","","carsten_eickhoff@brown.edu","BOX 1929","Providence","RI","029129002","4018632777","CSE","7367","7367, 7556","$0.00","This grant supports participation of 8 promising doctoral students from U.S.-based educational institutions in a Doctoral Consortium (workshop), along with about 6 distinguished research faculty, to be held in conjunction with the 6th AAAI Conference on Human Computation & Crowdsourcing (HCOMP 2018), which will take place July 5-8 2018, in Zurich, Switzerland, and which is sponsored by the Association for the Advancement of Artificial Intelligence.  HCOMP is the premier venue for disseminating the latest research findings on crowdsourcing and human computation.  While artificial intelligence (AI) and human-computer interaction (HCI) represent traditional mainstays of this cross-disciplinary conference, HCOMP believes strongly in inviting, fostering, and promoting broad, interdisciplinary research.  More information about the conference is available online at http://www.humancomputation.com/2018/.  The Doctoral Consortium will be a research-focused full-day meeting immediately following the conference technical program on July 8.  It will enhance the scientific workforce in this emerging research area by nurturing a group of promising young investigators interested in human computation and crowdsourcing, allowing them: to attend the conference; to learn of potential career paths within academia and industry; to access an international network of researchers who can support their professional development; and to see firsthand the interdisciplinary nature, diversity and interrelationships of research in human computation.  The faculty mentors also will serve as the review committee for student applications. The organizers will promote diversity by selecting no more than one or two students from any one school, and by prioritizing the selection of women and underrepresented minorities.  <br/><br/>The full-day Doctoral Consortium will include activities to guide the research of these promising young researchers. The Consortium will allow participants to interact with established researchers and with other students, through presentations, question-answer sessions, panel discussions, and invited presentations. Each participant will give a short presentation on their research and will receive feedback from at least one faculty mentor and from fellow students. The feedback will be geared toward helping the student participants understand and articulate how their research is positioned relative to other work on human computation and crowdsourcing.  Activities led by the faculty will include a panel discussion to give students more information about the process and lessons of research and life in academia and industry. To further integrate the Doctoral Consortium participants into the conference itself, students will have a chance to present their work in an interactive poster session, and their papers will be posted online on the workshop webpage. These activities will benefit the participants by offering each fresh perspectives and comments on their work from researchers outside their own institution, both from faculty and other students; providing a supportive setting for mutual feedback on participants' current research and guidance on future research directions; and enabling participants to form a cohort of new researchers.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1748377","CAREER: New Learning-based Algorithms for the Analysis of Very-Large-Scale Neuroimaging Data","IIS","ROBUST INTELLIGENCE, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/08/2018","Mert Sabuncu","NY","Cornell University","Standard Grant","Kenneth C. Whang","09/30/2023","$581,438.00","","ms3375@cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7495, 8624","075Z, 1045, 7495, 8089, 8091","$0.00","Artificial intelligence, fueled by recent advances in machine learning, is poised to transform healthcare and biomedical research. Machine learning algorithms allow researchers to analyze complex patterns in large datasets, in the service of advancing our understanding of biological mechanisms and developing clinical tools. This project considers very large scale brain imaging studies, including, for example, tens of thousands of individuals contributing head MRI scans and other biomedical data such as whole-genome sequences or clinical records. Such data allow researchers to map the effects of genetic, environmental, and other factors on the structure and function of the brain, which in turn advances our knowledge of disorders like Alzheimer's. Today, the primary obstacle in exploiting very large scale brain imaging datasets is computational, because existing software tools don't scale well and lack in quality assurance capabilities. This project will produce a machine-learning based computational pipeline that will fill this gap. In the largest study of its kind, we will showcase the developed software tools to chart the heritability of shapes of brain structures.  In addition, the project will implement a diverse set of educational outreach initiatives, such as a customized research experience for under-represented minority high-school students.   <br/><br/>Neuroimaging is entering a new era of unprecedented scale and complexity. Soon, we will have datasets including more than 100,000 individuals. The fundamental challenge in analyzing and exploiting these data is computational. Today, widely-used neuroimage analysis tools are computationally demanding, produce results that are sensitive to confounds, and are limited in quality control capabilities, making them infeasible at scale. This project will extend recent advances in machine learning to develop an innovative computational pipeline that addresses the drawbacks of existing methods. First, a computationally efficient and flexible brain MRI segmentation framework will be developed that integrates rich neuroanatomical prior models. The segmentation tool will be made robust to confounding effects such as subject motion via the use of an adversarial learning strategy. Learning-based methods will be further investigated to obviate the time-consuming manual quality control of segmentations. Finally, an innovative metric learning approach will be used to study genetic influences on brain morphology in the UK Biobank. The project will also implement an integrated educational plan that is focused on interdisciplinary, hands-on and lifelong learning. The researchers will devote significant effort to developing core educational material that will be adapted and utilized for audiences of various backgrounds and stages.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1704932","RI: Medium: Collaborative Research: Causal Inference: Identification, Learning, and Decision-Making","IIS","ROBUST INTELLIGENCE","08/01/2017","07/27/2017","Judea Pearl","CA","University of California-Los Angeles","Standard Grant","Weng-keen Wong","07/31/2020","$265,000.00","","judea@cs.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","CSE","7495","7495, 7924","$0.00","Understanding the causal mechanisms underlying an observed phenomenon is one of the primary goals of science. The realization that statistical associations in themselves are insufficient for elucidating those mechanisms has led researchers to enrich traditional statistical analysis with techniques based on ""causal inference"". Most of the recent advances in the field, however, operate under overly optimistic assumptions, which are often not met in practical, large-scale situations. This project seeks to develop a sound and general causal inference theory to cover those situations. The goal is to design a framework for decision-making of intelligent systems, including (1) learning a causal representation of the data-generating environment (learning), (2) performing efficient inference leveraging the learned model (planning/inference), and (3) using the new inferred representation, based on (1) and (2), to decide how to act next (decision-making). The new finding will benefit investigators in every area of the empirical sciences, including artificial intelligence, machine learning, statistics, economics, and the health and social sciences. The research is expected to fundamentally change the practice of data science in areas where the standard causal assumptions are violated (i.e., missing data, selection bias, and confounding bias). The work on decision-making is expected to pave the way toward the design of an ""automated scientist"", i.e., a program that combines both observational and experimental data, conducts its own experiments, and decides on the best choices of actions and policies. The project also helps to disseminate the principles of causal inference throughout the sciences by (1) engaging in the establishment of new ""data science"" curriculum where causal inference plays a central role, and (2) developing new educational materials for students and the general public explaining the practice of causal inference (e.g., book). Furthermore, the project supports the causal inference community by fostering a number of educational initiatives such as forums, workshops, and the creation of new incentives for the development of educational material (e.g., a ""Causality Education Award"").<br/><br/>Making claims about the existence of causal connections (structural learning), the magnitude of causal effects (identification), and designing optimal interventions (decision-making) are some of the most important tasks found throughout data-driven fields. This project studies identification, learning, and decision-making settings where (1) data are missing not at random, (2) non-parametric estimation is not feasible, and (3) aggregated behavior does not translate into guidance for individual-level decision-making. Specifically, the project considers the problem when measurements are systematically distorted (missing data), which has received an enormous amount of attention in the statistical literature, but has not essentially been investigated in the context of causal inference when data are missing not at random. The project further aims to leverage the special properties of linear models, the most common first approximation to non-parametric causal inference, to elucidate causal relationships in data, and to facilitate sensitivity analysis in such models.  Finally, the project considers the fundamental problem on how causal and counterfactual knowledge can speed-up experimentation and support principled decision-making. The goal is to develop a complete algorithmic theory to determine when a particular causal effect can be learned from data and how to incorporate causal knowledge learned (possibly by experimentation) so that it can be amortized over new environmental conditions."
"1704352","RI: Medium: Collaborative Research: Causal Inference: Identification, Learning, and Decision-Making","IIS","ROBUST INTELLIGENCE","08/01/2017","07/27/2017","Jin Tian","IA","Iowa State University","Standard Grant","Weng-keen Wong","07/31/2020","$260,169.00","","jtian@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","CSE","7495","7495, 7924","$0.00","Understanding the causal mechanisms underlying an observed phenomenon is one of the primary goals of science. The realization that statistical associations in themselves are insufficient for elucidating those mechanisms has led researchers to enrich traditional statistical analysis with techniques based on ""causal inference"". Most of the recent advances in the field, however, operate under overly optimistic assumptions, which are often not met in practical, large-scale situations. This project seeks to develop a sound and general causal inference theory to cover those situations. The goal is to design a framework for decision-making of intelligent systems, including (1) learning a causal representation of the data-generating environment (learning), (2) performing efficient inference leveraging the learned model (planning/inference), and (3) using the new inferred representation, based on (1) and (2), to decide how to act next (decision-making). The new finding will benefit investigators in every area of the empirical sciences, including artificial intelligence, machine learning, statistics, economics, and the health and social sciences. The research is expected to fundamentally change the practice of data science in areas where the standard causal assumptions are violated (i.e., missing data, selection bias, and confounding bias). The work on decision-making is expected to pave the way toward the design of an ""automated scientist"", i.e., a program that combines both observational and experimental data, conducts its own experiments, and decides on the best choices of actions and policies. The project will also help to disseminate the principles of causal inference throughout the sciences by (1) engaging in the establishment of new ""data science"" curriculum where causal inference plays a central role, and (2) developing new educational materials for students and the general public explaining the practice of causal inference (e.g., book). Furthermore, the project supports the causal inference community by fostering a number of educational initiatives such as forums, workshops, and the creation of new incentives for the development of educational material (e.g., a ""Causality Education Award"").<br/><br/>Making claims about the existence of causal connections (structural learning), the magnitude of causal effects (identification), and designing optimal interventions (decision-making) are some of the most important tasks found throughout data-driven fields. This project will study identification, learning, and decision-making settings where (1) data are missing not at random, (2) non-parametric estimation is not feasible, and (3) aggregated behavior does not translate into guidance for individual-level decision-making. Specifically, the project will consider the problem when measurements are systematically distorted (missing data), which has received an enormous amount of attention in the statistical literature, but has not essentially been investigated in the context of causal inference when data are missing not at random. The project will further aim to leverage the special properties of linear models, the most common first approximation to non-parametric causal inference, to elucidate causal relationships in data, and to facilitate sensitivity analysis in such models.  Finally, the project will consider the fundamental problem on how causal and counterfactual knowledge can speed-up experimentation and support principled decision-making. The goal is to develop a complete algorithmic theory to determine when a particular causal effect can be learned from data and how to incorporate causal knowledge learned (possibly by experimentation) so that it can be amortized over new environmental conditions."
"1514490","CHS: Medium: Transforming Scientific Presentations with Co-Presenter Agents","IIS","Cyber-Human Systems (CHS)","07/01/2015","09/01/2017","Timothy Bickmore","MA","Northeastern University","Continuing grant","Ephraim P. Glinert","06/30/2019","$1,164,306.00","Harriet Fell","bickmore@ccs.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","7367","7367, 7924","$0.00","Although journal and conference articles are recognized as the most formal and enduring forms of scientific communication, oral presentations are central to science because they are the means by which researchers, practitioners, the media, and the public hear about the latest findings thereby becoming engaged and inspired, and where scientific reputations are made.  Yet despite decades of technological advances in computing and communication media, the fundamentals of oral scientific presentations have not advanced since software such as Microsoft's PowerPoint was introduced in the 1980's.  The PI's goal in this project is to revolutionize media-assisted oral presentations in general, and STEM presentations in particular, through the use of an intelligent, autonomous, life-sized, animated co-presenter agent that collaborates with a human presenter in preparing and delivering his or her talk in front of a live audience.   The PI's pilot studies have demonstrated that audiences are receptive to this concept, and that the technology is especially effective for individuals who are non-native speakers of English (which may be up to 21% of the population of the United States).  Project outcomes will be initially deployed and evaluated in higher education, both as a teaching tool for delivering STEM lectures and as a training tool for students in the sciences to learn how to give more effective oral presentations (which may inspire future generations to engage in careers in the sciences).<br/><br/>This research will be based on a theory of human-agent collaboration, in which the human presenter is monitored using real-time speech and gesture recognition, audience feedback is also monitored, and the agent, presentation media, and human presenter (cued via an intelligent wearable teleprompter) are all dynamically choreographed to maximize audience engagement, communication, and persuasion.  The project will make fundamental, theoretical contributions to models of real-time human-agent collaboration and communication.  It will explore how humans and agents can work together to communicate effectively with a heterogeneous audience using speech, gesture, and a variety of presentation media, amplifying the abilities of scientist-orators who would otherwise be ""flying solo.""  The work will advance both artificial intelligence and computational linguistics, by extending dialogue systems to encompass mixed-initiative, multi-party conversations among co-presenters and their audience.  It will impact the state of the art in virtual agents, by advancing the dynamic generation of hand gestures, prosody, and proxemics for effective public speaking and turn-taking.  And it will also contribute to the field of human-computer interaction, by developing new methods for human presenters to interact with autonomous co-presenter agents and their presentation media, including approaches to cueing human presenters effectively using wearable user interfaces."
"1749917","CAREER: Learning Multi-Level Narrative Structure","IIS","ROBUST INTELLIGENCE","06/01/2018","01/17/2018","Mark Finlayson","FL","Florida International University","Continuing grant","James Donlon","05/31/2023","$122,499.00","","markaf@fiu.edu","11200 SW 8TH ST","Miami","FL","331990001","3053482494","CSE","7495","1045, 7495","$0.00","Why do certain stories, but not others, resonate so powerfully with certain populations? Stories (a.k.a. narratives) are powerful: where rational argument fails, a single story can drive home a point, change a mind, and even change a life. What specific structures underlie the power of narrative, and what new artificial intelligence (AI) techniques are needed to learn these structures automatically so we can leverage them in applications? This project seeks to develop these new AI techniques to automatically uncover and confirm the fundamental structures underlying narrative, developing and testing with data drawn from the domains of education and culture. This work will be of broad relevance to developing more intelligent machines, understanding the mind and brain, and improving education. It will produce fundamental insights into a universal form of communication (narrative), providing a potentially transformative new set of tools to researcher and educators.<br/><br/>The project will develop new machine learning and natural language processing approaches to learning key aspects of narrative structure. The basic structure of a narrative involves the plot, a time-ordered sequence of important events, and the plot can be divided into three levels of structure: (1) plot pieces, (2) archetypal characters, and (3) narrative arcs. The PI and his students will first learn to extract these three types of narrative structure, the third of which (narrative arcs) is as-yet untried, using novel combinations of existing grammar learning approaches and Bayesian approaches, specifically the PI's Analogical Story Merging (ASM) algorithm, the Infinite Relational Model (IRM), and iterative learning. Second, the researchers will test hypotheses that reflect why specific stories are persuasive to specific cultures, and apply these insights to improving minority engagement in STEM and computing in middle-school classrooms in Miami Dade County Public Schools. Third, the researchers will seek to uncover systematic regularities in professional education cases (such as business cases, or medical case reports) that will lead to the ability to make computational predictions as to which cases should be most effective in the classroom.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1618477","RI: Small: Unraveling and Building Top-Down Generators in Deep Convolutional Neural Networks","IIS","ROBUST INTELLIGENCE","07/01/2016","06/28/2016","Zhuowen Tu","CA","University of California-San Diego","Standard Grant","Kenneth C. Whang","06/30/2019","$449,999.00","","zhuowen.tu@gmail.com","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","CSE","7495","7495, 7923, 8089","$0.00","Deep learning has recently significantly advanced research fields that are closely related to artificial intelligence. The fundamental problem of knowledge representation however remains open and the role of top-down process in deep learning is yet not very clear. For example, to train a deep learning algorithm to detect simply the translation of a dog in an image, a data-driven way of training deep learning would require generating thousands of samples by moving the dog around in the image. However, a top-down model, if available, can directly detect translation using two variables along the axes. The main goal of this project is to explore a path to discover, learn, and build embedded deep learning models, accounting for a rich family of top-down spatial transformation and geometric composition in convolutional neural networks. The resulting models provide a transparent way of understanding the embedded top-down transformation process through neural network layers. The learned neurally-inspired top-down knowledge representation will benefit studies across multiple disciplines, including visual perception, brain sciences, cognitive modeling, and decision making. <br/><br/>The current practice in deep learning, for example convolutional neural networks (CNN), is largely dominated by data-driven bottom-up approaches. While the performances of various applications using convolutional neural networks (CNN) are impressive, there nevertheless exists a big gap between what bottom CNN can offer and what comprehensive intelligence requires. These strongly bottom-up CNN characteristics leave a big room for one to provide deep learning with the ability to also incorporate top-down information for effective knowledge representation, network learning, cognitive modeling, and visual inference. This project is about building a roadmap towards developing top-down generators. This is done by unraveling the role of explicit top-down knowledge representation and propagation, by studying the feature flows produced inside the convolutional neural networks, by building robust analysis-by-synthesis methods that combine top-down and bottom-up processes, and by creating explicit generative models to assist a wide range of applications. The benefit of studying the top-down generators to a broad family of applications is greatly intriguing, including but not limited to: creating network internal data augmentation, building object detection, developing scene understanding systems; modeling compositional and contextual object configurations; and performing zero-shot learning."
"1526301","RI: Small: Knowledge Representation and Reasoning under Uncertainty with Probabilistic Answer Set Programming","IIS","ROBUST INTELLIGENCE","08/01/2015","08/04/2015","Joohyung Lee","AZ","Arizona State University","Standard Grant","James Donlon","07/31/2019","$342,795.00","","joolee@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7495","7495, 7923","$0.00","Combining logic and probability is an important subject in Artificial Intelligence, and is recently being extensively studied in the area of statistical relational learning, where the main goal of representation is to express probabilistic models in a compact way that reflects the relational structure of the domain and ideally supports efficient learning and inference. However, in comparison with main knowledge representation languages, such languages do not allow natural, elaboration tolerant representation of commonsense knowledge. Currently, there is a big gap between the state of the art languages that are used in knowledge representation and the state of the art languages in which machine learning is done.  The success of this project will identify fundamental issues in bridging the gap between the two areas, will produce a uniform framework for both expressive representation and learning, and will contribute to the integration of knowledge representation and machine learning. The outcome of the research will be useful for many applications that require integration of knowledge representation and other areas, such as vision, robotics, and event recognition, where commonsense reasoning has to be applied on uncertain knowledge and data. The software systems developed under this project will be freely available as open source software. The research will involve both graduate and undergraduate students, contributing to a strengthened relationship between education and research. <br/><br/>The goal of the project is to design and implement a knowledge representation language that allows elaboration tolerant representation of expressive commonsense knowledge involving logic and probability, which can be efficiently computed by the techniques developed in related areas.  The proposed research aims at shifting the current logic-based foundation of answer set programming to a novel foundation that combines logic and probability, and achieving its computation by intelligently adapting and combining the methods from probabilistic reasoning and machine learning. It will build upon the existing works on answer set programming, statistical relational learning, and probabilisitic logic programming.  The project will (i) enhance the mathematical foundation of answer set programming to the novel foundation that combines logic and probability. (ii) relate it to other existing approaches in statistical relational learning, Pearl's causal models, and P-Log; (iii) design inference and learning algorithms; (iv) design a high level action language that allows elaboration tolerant representation of probabilistic transition systems; (v) apply probabilistic answer set programming to event recognition; (vi) implement and evaluate involved software systems."
"1813223","RI: Small: Concept Formation in Partially Observable Domains","IIS","ROBUST INTELLIGENCE","09/01/2018","08/30/2018","Marie desJardins","MD","University of Maryland Baltimore County","Standard Grant","James Donlon","08/31/2021","$399,993.00","","mariedj@cs.umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7495","7495, 7923","$0.00","This research focuses on providing artificial intelligence (AI) systems with ways to represent knowledge about a problem domain, by creating descriptions of its observations over time.  This work is important because the AI systems can transfer their knowledge from one problem domain to another, enabling them to learn complex behaviors in different environments over time.  In addition, the learned representation provides a basis for creating explanations of the agent's behavior, a capability that is becoming increasingly important as AI agents are being applied to more aspects of our daily lives.  The resulting learning transfer methods we will create are applicable to a wide variety of problems of interest to the broader AI community, including explainable systems, intelligent wearable computing, and robotic assistants in real world environments.<br/><br/>The agents enabled by this work will automatically extract concepts (high-level descriptors) from perceptions, construct a hierarchy of experiences, and record learned behaviors over this structure, by extending existing reinforcement learning methods with these novel representations. Concepts serve as simple, portable, efficient packets of hierarchical knowledge that can be learned in parallel.  Our novel contribution, concept-based memory, extends previous work on concept formation to identify useful properties of the domain that are not directly observable in all contexts, expanding the agent's world model and improving performance in partially observable domains.  Concept-based memory provides a process for creating multi-layered abstract representations of a domain and the tasks in the domain, enabling learning transfer across multiple tasks, and providing a basis for creating explanations of learned behaviors. Our method for concept formation in reinforcement learning domains, called concept-aware feature extraction (CAFE), produces concept-lattice representations that permit knowledge learned from one task to be applied to a new problem by identifying the appropriate level of generalization for common knowledge between the tasks.  We will enable scalability by integrating CAFE with abstract Markov decision processes (AMDPs) and by developing heuristic pruning methods that reduce the branching factor of the concept lattices<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1704908","RI: Medium: Collaborative Research: Causal Inference: Identification, Learning, and Decision-Making","IIS","ROBUST INTELLIGENCE","08/01/2017","07/27/2017","Elias Bareinboim","IN","Purdue University","Standard Grant","Weng-keen Wong","07/31/2020","$536,513.00","","eb@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7495","7495, 7924","$0.00","Understanding the causal mechanisms underlying an observed phenomenon is one of the primary goals of science. The realization that statistical associations in themselves are insufficient for elucidating those mechanisms has led researchers to enrich traditional statistical analysis with techniques based on ""causal inference"". Most of the recent advances in the field, however, operate under overly optimistic assumptions, which are often not met in practical, large-scale situations. This project seeks to develop a sound and general causal inference theory to cover those situations. The goal is to design a framework for decision-making of intelligent systems, including (1) learning a causal representation of the data-generating environment (learning), (2) performing efficient inference leveraging the learned model (planning/inference), and (3) using the new inferred representation, based on (1) and (2), to decide how to act next (decision-making). The new finding will benefit investigators in every area of the empirical sciences, including artificial intelligence, machine learning, statistics, economics, and the health and social sciences. The research is expected to fundamentally change the practice of data science in areas where the standard causal assumptions are violated (i.e., missing data, selection bias, and confounding bias). The work on decision-making is expected to pave the way toward the design of an ""automated scientist"", i.e., a program that combines both observational and experimental data, conducts its own experiments, and decides on the best choices of actions and policies. The project also helps to disseminate the principles of causal inference throughout the sciences by (1) engaging in the establishment of new ""data science"" curriculum where causal inference plays a central role, and (2) developing new educational materials for students and the general public explaining the practice of causal inference (e.g., book). Furthermore, the project supports the causal inference community by fostering a number of educational initiatives such as forums, workshops, and the creation of new incentives for the development of educational material (e.g., a ""Causality Education Award"").<br/><br/>Making claims about the existence of causal connections (structural learning), the magnitude of causal effects (identification), and designing optimal interventions (decision-making) are some of the most important tasks found throughout data-driven fields. This project studies identification, learning, and decision-making settings where (1) data are missing not at random, (2) non-parametric estimation is not feasible, and (3) aggregated behavior does not translate into guidance for individual-level decision-making. Specifically, the project considers the problem when measurements are systematically distorted (missing data), which has received an enormous amount of attention in the statistical literature, but has not essentially been investigated in the context of causal inference when data are missing not at random. The project further aims to leverage the special properties of linear models, the most common first approximation to non-parametric causal inference, to elucidate causal relationships in data, and to facilitate sensitivity analysis in such models.  Finally, the project considers the fundamental problem on how causal and counterfactual knowledge can speed-up experimentation and support principled decision-making. The goal is to develop a complete algorithmic theory to determine when a particular causal effect can be learned from data and how to incorporate causal knowledge learned (possibly by experimentation) so that it can be amortized over new environmental conditions."
"1350339","CAREER: Combining Crowdsourcing and Computational Creativity to Enable Narrative Generation for Education, Training, and Healthcare","IIS","Cyber-Human Systems (CHS)","02/15/2014","12/29/2017","Mark Riedl","GA","Georgia Tech Research Corporation","Continuing grant","William Bainbridge","01/31/2019","$549,998.00","","riedl@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7367","1045, 7367","$0.00","The proposed project explores the problem of automated narrative generation, the creation of narratives by computer systems. The project introduces a transformative new approach to narrative generation that blends human and computational creativity with crowdsourcing. The system addresses fundamental limitations of computer reliance on pre-coded domain knowledge in order to generate a virtually unlimited variety of narratives and make it possible for non-experts and non-programmers to create interactive narratives.  The research has four major components: (1) Develop artificial intelligence algorithms that emulate human ability to create narratives. (2) Design and implement novel models of human-computer creative collaboration. (3) Study fundamental questions pertaining to human narrative learning and cognition. (4) Explore the role of narrative generation in real-world domains: virtual agents that create rapport with humans and intelligent creativity augmentation tools for creating and sharing interactive experiences. The work will be piloted in two healthcare systems: a virtual agent that creates rapport and fosters longitudinal engagement with patients through autobiographical narratives; and intelligent tools that allow caregivers to create social skill scenarios for young adults with autism to practice. <br/><br/>Narratives are important because they are a fundamental means by which humans organize, understand, and explain the world. If computer systems could create effective narratives, they would be better able to interact with people. The research will result in novel algorithms, software, and a body of experimental knowledge that will enable the building of interactive narrative systems that are practical, scalable, usable by non-programmers, and can address societally important problems in education, training, and healthcare interventions. The proposed approach to creativity support will significantly lower the technical, artistic, and skill barriers to creating interactive narrative systems, opening avenues for educators, trainers, caregivers, and hobbyists to create and share interactive experiences.<br/><br/>The project includes an educational plan to develop a sustainable, annual summer hack-a-thon camp wherein high school students work alongside K-12 teachers to create interactive narratives that motivate and guide classroom inquiry based learning. The hack-a-thon aims to provide minority and low socioeconomic high school students with hands-on computing science experience and to produce a library of interactive inquiry-based learning software systems for K-12 teachers."
"1831755","SCC: Smart and Connected Churches for Promoting Health in Disadvantaged Populations","CNS","S&CC: Smart & Connected Commun","10/01/2018","09/09/2018","Timothy Bickmore","MA","Northeastern University","Standard Grant","Wendy Nilsen","09/30/2022","$2,092,670.00","Michael Paasche-Orlow","bickmore@ccs.neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","033Y","042Z","$0.00","This project brings together researchers from several disciplines with community partners to develop a range of novel sensing, monitoring, and messaging technologies to create a Virtual Safety Net (VSN) system for community members in an underserved urban community. In this effort, researchers will collaborate with members of the Black Ministerial Alliance and Health Ministry leaders of member churches, along with volunteers who provide health promotion outreach, the church leadership and a community liaison affiliated with a hospital to improve the overall health of this predominately African American community. The VSN is a research infrastructure for development of crowdsourced health interventions, in which community members author or culturally tailor intervention rules and messages. The VSN will empower the community to collectively solve health-relevant problems it identifies as important and provide preventive and health interventions that leverage support and messaging delivered individually via smartphone apps or during group meetings. The VSN will also be used to help the community identify and address social determinants of health, including food insecurity, homelessness, and health literacy. This research will have immediate impact for the 20,000 members of the 30 churches in the Black Ministerial Alliance of Boston. The technologies implemented can be rapidly disseminated to other church communities, businesses and social organizations in the US.<br/>    <br/>This SCC project aims to develop a research infrastructure that will be used to co-design and evaluate technologies in collaboration with community partners. The project will leverage the deep social support networks already existing in the Boston area. Key technologies developed in this effort include crowdsourced health interventions, in which community members author or culturally tailor intervention rules and messages. This will include developing methods to identify the range of modifications that laypersons can meaningfully make to expert-authored intervention dialogue and designing user interfaces to enable these modifications. It also includes advances in artificial intelligence-based indexing of community-authored narrative text for just-in-time messaging to motivate change in longitudinal, multi-behavior interventions. Advances in the automated generation of persuasive arguments for behavior change will also be developed. Dialogue-based interfaces to generate explainable artificial intelligence-learned models will be made to enable community members to understand and potentially modify how these models work.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"0939454","BEACON:  An NSF Center for the Study of Evolution in Action","DBI","SCI & TECH  CTRS (INTEG PTRS), CYBERINFRASTRUCTURE, STCs - 2010 Class, BEACON","08/01/2010","01/19/2018","Erik Goodman","MI","Michigan State University","Cooperative Agreement","George W. Gilchrist","07/31/2021","$43,035,209.00","Richard Lenski, Kay Holekamp, Charles Ofria, Robert Pennock","goodman@egr.msu.edu","Office of Sponsored Programs","East Lansing","MI","488242600","5173555040","BIO","1297, 7231, 8005, 8017","019Z, 7317, 7433, 7634, 9171, 9251","$0.00","The Bio/computational Evolution in Action CONsortium (BEACON) is a Science and Technology Center (STC) that enables research on evolutionary dynamics in natural and artificial systems and training of multi-disciplinary scientists in bio/computation, with a unique focus on the intersection of evolutionary biology, computer science, and engineering. The Center will enhance the development of applications of computational methods in biology, the use of artificial intelligence in computer science, and the enhancement of genetic algorithms in engineering design. Evolution by natural selection defines an algorithmic approach to finding solutions for complex problems; computer scientists and engineers have harnessed similar algorithms to a diversity of challenges that require optimization over multiple competing dimensions. Likewise, biologists have begun to employ digital modeling of the evolutionary process to examine evolution of complex biological structures and patterns in areas such as paleontology and the gene networks, which defy experimental manipulation in vivo. The Center will promote these interdisciplinary efforts by coordinating activities through three thrust groups: (1) Evolution of Genomes, Networks, and Evolvability, (2) Evolution of Behavior and Intelligence, and (3) Evolution of Communities and Collective Dynamics. <br/><br/>This center has the potential to transform both biology and computational sciences by developing digital experiments to test and apply fundamental principles of evolutionary biology. The possible impacts will be far reaching: from cyber-security to everyday computing applications, from the evolution of disease resistance to the self-organization of social behavior. The BEACON center will train the next generation of interdisciplinary scientists and educate the public about evolution and its role in solving real-world problems through significant educational outreach for K12 students and science museums."
"1722432","SBIR Phase I:  Compact, Low-cost, Automated 3D Ultrasound System for Regular and Accessible Breast Imaging","IIP","SMALL BUSINESS PHASE I","07/01/2017","08/27/2018","Maryam Ziaei-Moayyed","CA","iSono Health, Inc.","Standard Grant","Henry Ahn","03/31/2019","$225,000.00","","maryam@isonohealth.com","177 Townsend St.","San Francisco","CA","941075910","5105411320","ENG","5371","5371, 8038","$0.00","This SBIR Phase I project introduces a new paradigm for early monitoring and detection of breast cancer: the Quantified Self Exam. In the United States over 300,000 women are diagnosed and 40,000 women die from breast cancer every year. Breast cancer has a 99% survival rate if detected early, but limitations in cost, sensitivity, accessibility, and convenience of existing screening technologies result in one third of breasts cancers getting missed at early stages. Since treatment for early stage cancer is an order of magnitude less costly than treatment for stage 3 and 4 cancers, there is a clear economic and societal benefit for the development of better breast cancer monitoring and screening tools. To address this challenge, the technology proposed in this project leverages the proven benefits of ultrasound imaging and the newfound power of cloud-based artificial intelligence to provide a regular and accessible self-monitoring tool that can quantify and track suspicious changes in breast tissue. The device portability, low cost, 2 minute scan time, and automated analysis of breast image data will greatly increase the accessibility of breast cancer monitoring for women, which in turn stands to decrease the cost burden of this disease for the US healthcare system. <br/><br/>This SBIR Phase I project proposes to develop a new tool for early detection and monitoring of breast cancer: the Quantified Self Exam (QSE) that combines a low-cost, compact 3D ultrasound device and positioning accessory with artificial intelligence to empower women and their physicians with appropriate and actionable data.  The QSE technology proposed in this project operates independent of user skill and captures 3D volumetric images of the whole breast in 2 minutes.  The system architecture allows for simplified and low-cost ultrasound hardware that connects wirelessly to a smart phone/tablet and transfers captured data to secure cloud for advanced image processing and storage. The ultrasound scanner attaches to a positioning accessory for repeatable imaging that enables longitudinal 3D monitoring of abnormal growth using machine learning-based image analysis. The proposed Phase I R&D efforts focus on four objectives: (i) optimize electrical hardware and low-level imaging software for spatial resolution and image quality; (ii) build a QSE scanner that maximizes field of view and volumetric integrity; (iii) build a positioning accessory for positioning of the QSE scanner; (iv) demonstrate the longitudinal repeatability of QSE imaging by validating the alignment of 3D ultrasound volumes on a breast phantom."
"1829071","NRT-HDR: Modeling and Understanding Human Behavior: Harnessing Data from Genes to Social Networks","DGE","NSF Research Traineeship (NRT), PROGRAM EVALUATION","09/01/2018","08/22/2018","Wei Wang","CA","University of California-Los Angeles","Standard Grant","Laura Regassa","08/31/2023","$3,000,000.00","Weizhe Hong, Sean Young, Andrea Bertozzi, Junghoo 'John' Cho","weiwang@cs.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","EHR","1997, 7261","062Z, 7361, 9179, SMET","$0.00","A confluence of technologies is transforming the biological, environmental, and social sciences into data-intensive sciences. Indeed, with the data now produced every day, there exists an unprecedented opportunity to revolutionize the journey of scientific discovery.  By harnessing these data, one can advance the understanding of human conditions, behaviors, and their underlying mechanisms and social outcomes, enabling a spectrum of new and transformative research and practice.  Fundamental new approaches across computing, mathematics, engineering, and sciences are critically needed, and future scientists must be accordingly trained in these emergent cutting-edge methods. This National Science Foundation Research Traineeship (NRT) award to the University of California, Los Angeles will address this demand by training graduate students at the intersections of data science, mathematics, cryptography, artificial intelligence, genomics, behavior science, and social science. The traineeship program anticipates training one hundred twenty (120) PhD students, including fifty (50) funded trainees, from the social, biological, mathematical and computational sciences and engineering, through a unique and comprehensive training opportunity. <br/><br/>This cross-disciplinary traineeship program has four research areas: genomics and genetics; brain imaging and image analysis; mobile sensing and individual behaviors; and social networks. These areas are interconnected through three core themes: mathematical modeling and network analysis, scalable machine learning and big data analytics, and biomedical applications and social outcomes. At the nexus of these research areas and core themes, this traineeship program provides novel interdisciplinary graduate education to advance both graduate student training and scientific research.  Key features of the traineeship include novel curricula; cross-disciplinary laboratory rotations between engineering, life science, and social science; new foundational classes at the intersections of data science, mathematics, artificial intelligence, behavior science, and social science; summer internships at research institutes, big data firms, and hospitals and translational clinical settings; career, ethics, and technical communication skills development; and outreach to minority, women, and high school students with a distinct focus on groups traditionally underrepresented in STEM PhD programs. <br/><br/>The NSF Research Traineeship (NRT) Program is designed to encourage the development and implementation of bold, new potentially transformative models for STEM graduate education training. The program is dedicated to effective training of STEM graduate students in high priority interdisciplinary research areas through comprehensive traineeship models that are innovative, evidence-based, and aligned with changing workforce and research needs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1836950","D3SC: EAGER: Deep learning to design selective kinase inhibitors","CHE","Chemistry of Life Processes","09/01/2018","08/15/2018","John Karanicolas","PA","Institute For Cancer Research","Standard Grant","Susan Atlas","08/31/2020","$298,559.00","","john.karanicolas@fccc.edu","333 COTTMAN AVENUE","Philadelphia","PA","191112434","2157282659","MPS","6883","026Z, 062Z, 068Z, 7916, 8084, 9216, 9263","$0.00","John Karanicolas of the Institute for Cancer Research is supported by an award from the Chemical Theory, Models and Computational Methods program and by the Data-Driven Discovery Science in Chemistry initiative in the Division of Chemistry, to develop an artificial intelligence-based strategy for designing small molecule compounds that bind to and probe the functions of human kinases.  Kinases are a family of proteins responsible for controlling virtually all signaling processes in multicellular organisms.  Such processes are fundamental to life itself, and play a critical role in cell division, cell growth and motility, and cellular transport.  Consequently, kinases also represent potential targets for novel cancer drugs.  There are several hundred kinase proteins, organized into complex signaling pathways. Each pathway acts like a set of cascading dominos: once an initial chemical trigger occurs at a key location on the kinase molecule, it sets in motion a series of downstream reactions translating into specialized molecular functions.  Since individual kinases can participate in multiple cellular processes, these signaling pathways are often highly intertwined.  To determine the function of a particular kinase, scientists utilize small molecules as chemical probes that bind to the kinase, suppress its activity, and enable the analysis of downstream impact on cellular function. However, a significant challenge is that most existing chemical probes are not as selective as originally thought: many probes act on multiple kinases at once.  Experimental ""wet lab"" testing of all possible combinations of hundreds of kinases against tens of thousands of potential chemical probes is not practical due to cost.  Professor Karanicolas and his students are utilizing state-of-the-art advances in artificial intelligence and machine learning, publicly-available data on select kinase-probe interactions, and specialized techniques developed in his laboratory for modeling the 3D structure of protein-small molecule binding, to develop a computational model that accurately predicts kinase binding affinities and chemical probe selectivity.  The project's discoveries have the potential for significant impact in facilitating fundamental studies of cell biology, as well as the identification of selective kinase inhibitors for pharmaceutical design.  The new methods are being implemented in software distributed through public repositories and the widely-used Rosetta software suite. The research is providing cross-disciplinary training opportunities fusing chemical biology and data science to students at the high school, undergraduate, and graduate levels. <br/><br/>Modern cell biology leans heavily on kinase inhibitors as chemical probes for analyzing the consequences of deactivating a particular kinase, but the majority of commonly-used chemical probes are not sufficiently target-selective for robust interpretation of observed phenotypes.  By assembling large panels of kinases (corresponding to much of the human kinome), it is possible to experimentally determine selectivity for a given probe: however, these experiments are expensive and impractical to perform at scale.  This project is applying deep learning techniques to predict the binding affinities of individual inhibitor/kinase pairs, using 3D structural descriptors derived from a novel method for modeling inhibitor/kinase complexes, recently developed in the Karanicolas group.  Following careful training and benchmarking, the predictive model is being used in two ways: 1) to evaluate the selectivity of chemical probes that are widely used by cell biologists, and determine which compounds constitute useful tools and which compounds should be deprecated; and 2) to screen a large chemical library of small molecules to identify new candidate probes that are expected to have strong binding affinity and selectivity for a given kinase. The model's predictions in both applications are being tested experimentally through biochemical assays. While it has long been hypothesized that inclusion of 3D structural features would improve existing machine learning approaches for predicting protein/ligand binding affinities, the availability of a rapid and accurate method for building 3D structural models will allow this hypothesis to be tested for the first time. If successful, insights from this project will provide a starting point for developing models to predict binding affinities of other protein-ligand complexes as well, for expanded applications in cell biology and drug discovery.  The results of the project are being disseminated as publicly-available source code through SourceForge, and as modules within the widely-used Rosetta software suite.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1810005","Synaptic dynamics in ferroelectric devices and their application to deep neural networks","ECCS","ELECT, PHOTONICS, & MAG DEVICE","08/15/2018","08/10/2018","Asif Khan","GA","Georgia Tech Research Corporation","Standard Grant","Paul Lane","07/31/2021","$450,000.00","Saibal Mukhopadhyay","asif.khan@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","1517","100E","$0.00","Nontechnical:<br/>One of the grand visions of the modern computing era has been to mimic the cognitive capabilities of the human-brain, and even to rival them. This vision is becoming possible due to recent advances in machine learning and artificial intelligence. Current computing technologies are still far from creating a digital entity that is as capable and as energy efficient as a biological brain. Digital learning systems are notoriously power hungry and can require a room-full of digital computer clusters. Compare that to the human brain which performs all its feats at a meager power budget of twenty watts and a weight of less than two kilograms. One reason for this inefficiency is that transistors, the basic building blocks of digital computers, do not function in the same way as synapses, the basis of biological computing. The proposed research aims at overcoming this barrier by making a relatively basic change to the structure of the transistor. An emerging material with ferroelectric properties, doped hafnium oxide, will be introduced into transistors. The new device is called a ferroelectric field effect transistor and can emulate the properties of biological synapses. In this project, the unique properties of the synaptic ferroelectric transistor will be used to design and optimize artificial intelligence cores such as deep neural networks that vastly exceed the performance and efficiency of the current state-of-the-art. The project will train participating students in an interdisciplinary setting that involves material science, circuit design, computer architecture, and neuro-science. The STEM outreach and education programs will help participating undergraduates, high school students and high school teachers to broaden their experience in computer science and novel semiconductor devices.<br/><br/>Technical:<br/>The project will explore the rich domain dynamics in ferroelectric hafnia-zirconia alloy gated silicon transistors to build synaptic units for vector matrix multiplication crossbars. The architecture and system level work will entail the design and optimization of full-blown deep neural networks based on these ferroelectric crossbar kernels. Physics based compact models of ferroelectric transistors that account for the important details of domain dynamics will be developed which will tie the material-device level work and the architecture-system level work. A key feature of the project is its vertically integrated approach that involves different levels in the computing hierarchy from materials to systems. Innovations at all these different levels will ensure that the interesting properties of the emerging ferroelectric device technology can be fully leveraged to create an energy efficient and high-performance hardware platform for advanced machine learning and data intensive cognitive applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1725729","MRI: Development of an Instrument for Deep Learning Research","OAC","MAJOR RESEARCH INSTRUMENTATION, CYBERINFRASTRUCTURE","10/01/2017","09/14/2017","William Gropp","IL","University of Illinois at Urbana-Champaign","Standard Grant","Stefan Robila","09/30/2020","$2,721,983.00","Roy Campbell, Volodymyr Kindratenko, Jian Peng","wgropp@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","1189, 7231","1189","$0.00","This project will develop and deploy a novel instrument for accelerating deep learning research at the University of Illinois (UI). The instrument will integrate the latest computing, storage, and interconnect technologies in a purpose-built shared-use system. This Instrument will deliver unprecedented performance levels for extreme data intensive emerging fields of research with far-reaching impacts in many areas, such as computer vision, natural language processing, artificial intelligence, healthcare and education. The instrument development will be driven by the UI deep learning (DL) community needs and will be carried out in collaboration with IBM and Nvidia. The instrument will serve as a focal point for the rapidly growing DL research community at UI, enable expansion of several research programs at UI, and contribute to STEM education and training.<br/><br/>Specifically, the proposed instrument is a far-reaching cyberinfrastructure development for the research community and industry engaged with deep learning. The work will result in an advanced high-performing scalable instrument with capabilities far beyond those currently deployed in academia or industry to tackle large-scale deep learning projects. This instrument will serve as a focal point for a community-driven effort to advance the field of DL, integrating the work of computer scientists, systems engineers, and software developers. This project is transformative both in the systems architecture and domain science fields it will imbue, with new knowledge to be developed via new interactions and synergies that will emerge as part of this effort.<br/><br/>The proposed development of this well-integrated instrument will improve the quality and expand the scope of research and training, provide inter- and intra-organizational use amongst many disciplines, and engage private sector partners. The work will have deep and long-lasting effects on future computer architectures for compute- and data-intensive applications by making the blueprints of the novel system architecture of the instrument publically available. Access to the high-performance software developed through this project will aid numerous science domains that utilize DL frameworks. The unprecedented computational capabilities of many applications will make it possible to tackle complex science, engineering and societal problems in many important fields ranging from education, to healthcare, to artificial intelligence (AI). This project will strive to include participants from under-represented minority and female students, to make new discoveries, train, and educate a new generation of users fluent with DL tools and methodologies, contributing to the development of a highly educated, and diverse workforce with specialized skillsets. Finally, the work will enable new industry-academic collaborations benefiting both the scientific community and industry nationwide."
"1829357","Doctoral Dissertation Research: Recovering the Polyvalent Genealogies of Machine Learning, 1948 - 2017","SMA","SciSIP-DDRIG","08/01/2018","07/16/2018","Matthew Jones","NY","Columbia University","Standard Grant","Mark K. Fiegener","07/31/2019","$26,163.00","Aaron Plasek","mj340@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","SBE","7009","7626, 9179","$0.00","Machine learning techniques currently make ""high-stakes"" judgments in areas as diverse as criminal justice, credit risk, social welfare, hiring, and congressional redistricting. Such techniques make these decisions using patterns learned from historical social data. Emphasis on prediction rather than the circumstances of dataset creation have led to machine learning systems that preferentially target vulnerable populations for disparately adverse social judgments while making it more difficult for those subject to these decisions to protest unfair treatment. This study explores the limitations of such machine learning systems by tracing how technical and non-technical people, including funding agencies, have historically understood what machine learning systems could and should achieve. Particular care is given to the forms of ""learning"" valued by researchers during different moments in the 20th century, and to the emergence of theoretical concepts that were constrained and even defined by the capabilities of the available material devices. This work makes visible the efforts of women and men previously omitted in histories of artificial intelligence and machine learning, and develops a quantitative method to document how the innovations of a discipline are contingent upon interdisciplinary and transdisciplinary research networks. Finally, this project traces how the allocation of resources to particular research communities spurred scientific innovation in adjacent and seemingly unrelated academic research fields in the physical and social sciences. In this sense, the discipline of machine learning provides a useful case study for modeling the propagation of ideas across different subfields.<br/><br/>Both qualitative and quantitative historical research is employed. First, nine university and government archives are perused to reconstruct the institutional organizations, interpersonal research networks, and material computing devices available to machine learning and artificial intelligence researchers. Second, an investigation is conducted using a novel combination of topic modeling and word embeddings on a corpus of millions of full-text Association of Computing Machinery articles from 1950 to 2017 to trace how discursive influence propagates across disparate sub-disciplines. Four research products are generated: (1) a technical machine learning publication detailing the novel method used to analyze the article corpus, (2) a history of science article tracing the early history of machine learning, (3) a general audience ""think piece"" discussing the policy and ethical implications of contemporary machine learning research, (4) and the public release of the project code and the subsequent statistics generated from the article corpus. Digital copies of salient archive records discovered during this research study will be made freely available via Columbia University's Digital Repository, insofar as this is possible given the copyright and access restrictions of holding institutions. Archive materials collected and computational study of the article corpus will be used in the co-PI's doctoral dissertation exploring how machine learning has been used to classify individuals, imagine communities, and legislate forms of social and political evidence.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1818969","A Two-Way Research Street: Geometric Algorithms in Optimization and Computer-Based  Discrete Geometry","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/07/2018","Jesus De Loera","CA","University of California-Davis","Standard Grant","Matthias Gobbert","06/30/2021","$306,817.00","","deloera@math.ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","MPS","1271","9263","$0.00","At the foundation of the progress in artificial intelligence and data science that is changing society (e.g., driverless cars) is the mathematical theory of optimization. For example, convex and non-linear optimization is the engine at the core of the very successful deep neural-networks. The first part of the project develops the mathematics necessary to solve optimization theory challenges (e.g., larger amounts of data, uncertain data) and to create faster, more accurate optimization algorithms. Computers are changing the nature of mathematical research and discovery too. For instance, computers can derive formulas and proofs automaticaly, computers can search for examples, and now they can more easily extract patterns thanks to machine learning. The second part of the project investigates the use of algorithms from artificial intelligence and algorithms to attack problems in mathematics, especially in geometry.<br/><br/>This project in computational mathematics has two interacting components: The first component is to apply methods from convex geometry, algebraic geometry, geometry of numbers, and combinatorics to develop new algorithms for mixed-integer optimization problems arising in data science, especially the clustering of data with special conditions. The project also studies augmentation (primal) algorithms for integer and mixed-integer variables, these are algorithms that generalize the pivoting used for the simplex method. The second component of the project investigates geometric and combinatorial problems amenable to be investigated with computers. The computation of a number of fundamental combinatorial quantities in convex geometry, including the exact value of integer Caratheodory numbers for cones, quantitative Helly numbers, and integral Radon-Tverberg numbers, will be emphasized. The project presents a computer-based approach to prove or disprove several theorems in<br/>discrete geometry.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1823068","Workshop on Inter-Disciplinary Research Challenges in Computer Systems","CNS","Computer Systems Research (CSR","03/01/2018","03/07/2018","Xipeng Shen","NC","North Carolina State University","Standard Grant","Samee Khan","02/28/2019","$49,731.00","James Tuck","xshen5@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","7354","7556","$0.00","This award funds a visioning workshop with the goal of bringing together leading researchers and practitioners in computing systems (architecture, operating systems, languages/compilers) to reflect on the research progress in the overlapped areas of the three fields and to discuss the grand challenges for the fields so that they can rise to meet the demands of modern computing in synergy.<br/><br/>The workshop will have focused discussions in the context of four important application domains: Internet of Things (IoT)/infrastructure, augmenting Human Abilities/Artificial Intelligence, security and privacy, and complexity management/environment. It will discuss how inter-disciplinary research in computing systems could help meet the grand challenges in these domains, such as the lack of principles and techniques that reliably and efficiently support large and heterogeneous ensembles of IoT devices and humans, the safety and efficiency barriers facing the deployment of Artificial Intelligence, and the vulnerabilities in both hardware and software that threaten to undermine security and privacy.<br/><br/>The principal investigators, along with workshop participants, will produce a detailed workshop report that will outline the grand challenges and promising directions for the further development of inter-disciplinary research in computing systems. The report will be made be publicly available through the internet as well as professional journals and magazines.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1738291","SBIR Phase II:  Independent Science Learning through Serious Games with Expert Avatars and Complementary Stories","IIP","SMALL BUSINESS PHASE II","09/15/2017","05/10/2018","Peter Solomon","CT","THEBEAMER LLC","Standard Grant","Rajesh Mehta","08/31/2019","$759,990.00","Kenneth Thompson","prsolomon@comcast.net","87 Church St","East Hartford","CT","061083720","8602125071","ENG","5373","079E, 5373, 8031, 8032, 8039, 8240","$0.00","This SBIR Phase II project will provide an engaging independent-learning platform which weaves science into an exciting story for ages eight to thirteen. The platform combines a time-travel adventure game, a complementary book, and in-game avatars for important scientists (like Albert Einstein) that can answer students' questions.  It is aimed at the need for educating more science and engineering professionals by tapping into children's strong interest in games to augment current science curricula that students often find boring and uninteresting. The story is about STARDUST (atoms) and its formation and history in the universe.  It engages students by taking them back in time to identify trillions of atoms they personally inherited from Einstein and the last T-Rex.  Besides school use, the game's independent learning and engagement allows distribution directly to children for recreational use, adding another avenue for science learning, and a sustainable business model for the Company through school and commercial sales.  The technology can also support independent learning in underperforming schools. The development of the scientist avatar artificial intelligence technology will have wide application for many other educational and training requirements.  <br/><br/>The innovation is a unique platform for independent learning about the sweeping science saga of atoms during the history of the Universe and Earth, and the connection of each student to that history through the trillions of atoms they inherited from prior beings like Albert Einstein and the last T-Rex.  The platform combines video games, a complementary fictional story book (based on the science) that acts as game introduction and player guide, and in-game avatars (like Albert Einstein and Henrietta Leavitt) that can provide verbal answers to students' spoken questions.  The artificial intelligence backing the scientist avatars includes learning manager software that guides student learning and provides assessments of progress in achieving pre-established learning goals. Four players cooperate in time travel adventures, exploring the human body, the Earth, and the Universe to find out what STARDUST is (atoms), how and when it was created (in the Big Bang and supernovae), how it got into Einstein, and from him to others (e.g., the carbon cycle). Excellent test results for the Phase I prototype game suggests a successful start at creating good player engagement. The project will continue to combine learning and engagement in 10 additional episodes with new scientist avatars including female and minority scientists."
"1651538","CAREER: Evaluating the Process-Structure-Property Relationships of Carbon Nanotube Forests with In-Situ Synthesis Observation and Dynamic Simulations","CMMI","CAREER: FACULTY EARLY CAR DEV, Materials Eng. & Processing","07/15/2017","03/10/2017","Matthew Maschmann","MO","University of Missouri-Columbia","Standard Grant","Thomas F. Kuech","06/30/2022","$500,000.00","","MaschmannM@missouri.edu","115 Business Loop 70 W","COLUMBIA","MO","652110001","5738827560","ENG","1045, 8092","1045, 8021, 8025, 9150","$0.00","This Faculty Early Career Development (CAREER) Program research project investigates how carbon nanotubes interact with one another during collective growth by using direct observation and complimentary numerical simulation. Nanoscale materials such as carbon nanotubes offer superior mechanical, electrical, and thermal properties relative to many other conventional engineering materials. When vast arrays of carbon nanotubes are synthesized together they form interconnected and self-organized populations known as carbon nanotube forests. The interactions between growing nanotubes lead to the structures bending and kinking which detract from their mechanical properties.  Numerical simulations employing artificial intelligence and machine learning will facilitate the rapid exploration of high-dimensional processing space associated with nanotube formation and will guide the experimental aspects of this project. The results of this work and the understanding of the synthesis process will help control the mechanisms of carbon nanotube interactions during their synthesis, leading to enhanced and engineered carbon nanotube forest properties. Middle school students will be engaged with the research through a one-week summer camp in which hands-on nanoscale materials engineering will be merged with artistic expression through collaboration with the University of Missouri Museum of Art and Archeology. The results of these investigations will enable the use of the art and observation at the nanoscale to engage and inspire grade school children in STEM-based learning in cooperation with the university art museum.<br/><br/>The forces and mechanisms that drive carbon nanotube forest self-assembly are currently poorly understood, in part because in-situ diagnostic techniques with sufficient resolution to interrogate the evolving mechanical interactions are lagging. This project will implement direct visualization of carbon nanotube forest growth and assembly using in-situ synthesis methods within scanning and transmission electron microscopes. A variety of synthesis conditions will be investigated to link the role of important processing factors to the observed behaviors. Transmission electron microscope techniques will facilitate not only time-resolved visual inspection of individual nanotubes and their host catalyst nanoparticles but also compositional analyses at or near atomic resolution. Scanning electron microscope techniques will examine coordinated assembly of carbon nanotubes within the larger population at length scale ranging from tens of nanometers of tens of microns. Experimental observations will be input into a time-resolved finite element simulation to interrogate the forces generated during nanotube forest assembly. After synthesis, the mechanical properties of carbon nanotube forests will be measured using in-situ scanning electron microscope compression and simulated with the finite element model for validation. The validated model will serve as a vehicle for rapid assessment of process-structure-property relationships using an artificial intelligence algorithm to autonomously search for appropriate synthesis conditions that satisfy user-defined forest property sets. A carbon nanotube forest synthesis simulation tool will be made publically available at nanohub.org to facilitate broader impact of the simulations developed in this project."
"1833317","Open Compass: Leveraging the Compass AI Engineering Testbed to Accelerate Open Research","OAC","ETF","05/01/2018","04/25/2018","Paola Buitrago","PA","Carnegie-Mellon University","Standard Grant","Robert Chadduck","04/30/2020","$300,000.00","Nicholas Nystrom","paola@psc.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7476","7916","$0.00","Artificial intelligence (AI) has immense potential to contribute to advances spanning progress in science, the national health, prosperity and welfare, education, benefit society, or secure the nation's defense. Research initiatives, conferences, investments, and products based on AI abound and are expanding rapidly, while the methods, performance, and understanding of AI are in their infancy. Researchers face vexing issues such as how to improve performance, transferability, reliability, comprehensibility, and how better to train AI models with only limited data. Future progress depends on advances in hardware accelerators, software frameworks, system architectures, and creating cross-cutting expertise between scientific and AI domains. One way to accelerate progress on these topics is to create an engineering testbed, which provides a controlled environment that allows investigators to explore solutions to these - and other - challenges.  Open Compass is an exploratory research project to conduct academic pilot projects on an advanced engineering testbed for artificial intelligence, culminating in the development and publication of best practices. <br/><br/>Open Compass will: 1) engage pilot projects and research groups, documenting approaches, experiences, and lessons learned; 2) conduct training events, in-person and using the Pittsburgh Supercomputing Center's wide area classroom; 3) organize and conduct a workshop focusing on advanced AI technologies; 4) integrate experiences gained through open research collaboration with those of industry experiences to identify a comprehensive set of best practices; and 5) publish results and best practices in peer-reviewed journals, conferences, and technical reports. The broad community will benefit from publication of research results, experiences, and a knowledge base of best practices. The research community will gain access to new technologies on which to develop algorithms and applications, along with insight across new fields of those technologies' applicability and important trends for AI. Open Compass will promote workforce development through student involvement in pilot projects and training and provide feedback to industry for to enable more efficient future AI technologies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1837212","CPS: Medium: LEAR-CPS: Low-Energy computing for Autonomous mobile Robotic CPS via Co-Design of Algorithms and Integrated Circuits","CNS","CYBER-PHYSICAL SYSTEMS (CPS)","10/01/2018","09/10/2018","Sertac Karaman","MA","Massachusetts Institute of Technology","Standard Grant","Jonathan Sprinkle","09/30/2021","$1,000,000.00","Vivienne Sze","sertac@MIT.EDU","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7918","7924","$0.00","The goal of this research is to enable a new era of low-energy mobile robotic Cyber-Physical Systems (CPS). The approach is the simultaneous design of the computing hardware with the computer algorithms, with input from the physics of the system. Applications include, but are not limited to, insect-size robotic bees for artificial pollination, robotic water striders for environmental monitoring, miniature underwater autonomous vehicles for inspection, orally-administered medical robotic vehicles that can intelligently navigate the digestive system, robotic gliders that can operate in the air or underwater for months at a time, and many more. The results will enable low-power computing for artificial intelligence and autonomy to complement the existing low-energy, miniature actuation and sensing systems that have already been developed. This will enable  low-energy, miniature mobile robotic CPSs that can still provide provable guarantees on completeness, optimality, robustness and safety. <br/><br/>This project will focus on the development of novel algorithms and novel computing hardware for miniature, energy-efficient mobile robotic CPS. The proposed research will enable low-energy computation for full autonomy by way of minimizing energy consumption during design time and run time, by simultaneously designing the algorithms and the computing hardware. Decision making algorithms will minimize computing energy during run time, for instance, by considering motions that may not require heavy computation for perception and planning. The project will demonstrate the new methods by constructing the smallest fully-autonomous aerial robotic vehicle ever built. We believe the proposed foundational research and the proposed demonstration will kickstart a new cyber-physical systems subfield at the intersection of the mobile robotics literature and the computing hardware (circuits) literature.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839169","I-Corps: Neuromorphic device derived from resistive switching system","IIP","I-Corps","07/01/2018","06/18/2018","Min Hwan Lee","CA","University of California - Merced","Standard Grant","Cindy WalkerPeach","12/31/2018","$50,000.00","","mlee49@ucmerced.edu","5200 North Lake Road","Merced","CA","953435001","2097566405","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project is in facilitating innovations in a wide range of industries working on advanced computing-based applications as the result of a reliable neuromorphic chip (where neural networks are etched into silicon). This technology may accelerate the advance of machine learning and ultimately realize a breakthrough in computing architecture by overcoming the Von Neumann bottleneck -- where the intrinsic latency originated from the separation of processor and memory. Empowered by neuromorphic features of this project's technology, machine learning may be carried out with unprecedented speed and efficiency in design and energy consumption. Hence, intensive machine learning based technologies such as face recognition, autonomous driving and other areas of artificial intelligence will be advanced by a significant margin. A successful execution of the project will also facilitate widespread commercialization of emerging applications utilizing artificial intelligence and/or neuromorphic computing. <br/><br/>This I-Corps project leverages the recent innovative research related to highly controllable neuromorphic devices. The technology is based on the oxide-based resistive random access memory (ReRAM), a non-volatile memory based upon electrical stimuli-induced resistance changes, mostly by the formation and rupture of so-called nanoscale conducting filaments in each cell. The intrinsic resemblance of ReRAM cells to neuromorphic systems triggered a recent boom in related research. However, there are still considerable technical issues including wide cell-to-cell variations in operation voltage, cell current and operation speed. Unclear understanding of physical switching mechanisms precludes a rationale design of reliable cells for a commercial device. The proposed novel scheme, in which the uncontrollability is significantly minimized, is expected to achieve a breakthrough in realizing commercializable neuromorphic devices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813392","NeTS: Small: Collaborative Research: Towards Adaptive and Efficient Wireless Computing Networks","CNS","Networking Technology and Syst","10/01/2018","08/21/2018","Lei Ying","AZ","Arizona State University","Standard Grant","Monisha Ghosh","09/30/2021","$250,000.00","","lying6@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7363","7923, 9150","$0.00","Today's mobile devices are not merely smart, they are becoming intelligent as artificial intelligence applications such as Facebook Caffe2 and Google Tensor-Flow Lite are being pushed into mobile devices and as mobiles devices are being integrated into the cloud-fog-mobile architecture. This calls for efficient and adaptive computing/communication co-design of wireless networks to optimize application-level latency (including both communication latency and computing times) and to achieve energy efficiency (considering energy consumed by both communications and computing).  This project develops fundamental theories and novel architectures of low-latency, energy-efficient, and computing-centric wireless networks to support emerging mobile intelligence applications. Theories and algorithms developed by the PIs are constantly integrated into the undergraduate and graduate courses taught at the two universities. This project also provides hand-on experiences to undergraduate and high school students with state-of-the-art wireless technologies. <br/><br/>Computing/communication co-design, while new for wireless networks, is a central topic in data center networks. However, the proposed solutions, while inspiring, are not directly applicable to wireless computing networks because of the unique features of wireless networks such as wireless interference, channel fading and limited energy. This project focuses on provably optimal mechanisms that dynamically and adaptively schedule computing tasks and data transmissions to meet application-level performance requirements, and consists of three interdependent thrusts: (i) Optimal computing/communication co-design. This thrust develops mathematical models and theoretical limits of wireless computing networks, (ii) Robust computing/communication co-design. This thrust focuses on robust computing and communication co-design that achieves desired performance with imperfect state information and under unavoidable short-term system overload and (iii) Learning-aided adaptive computing/communication co-design. This thrust further improves the performance of wireless computing networks by leveraging both historical data and predictable user behaviors.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1717530","CIF: Small: Foundations of Belief Sharing in Human-Machine Systems","CCF","COMM & INFORMATION FOUNDATIONS","07/01/2017","06/28/2017","Lav Varshney","IL","University of Illinois at Urbana-Champaign","Standard Grant","Phillip Regalia","06/30/2020","$405,455.00","","Varshney@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","7797","7923, 7936","$0.00","This work aims to develop mathematical laws and foundational principles for belief sharing in systems with human and machine intelligence working together to make robust decisions. Prior work in statistical signal processing and in psychology has only considered technological limitations or human limitations independently, but jointly considering informational limitations of both humans and machines is critical in engineering future sociotechnical systems, especially when people are overwhelmed by too much information. A theory for fundamental limits and optimal designs for such systems is lacking.<br/><br/>Rather than systems with agents sharing either raw data or local decisions, we develop intermediate designs based on sharing beliefs. Belief sharing increases modularity among networked units compared to central analysis of raw data, yet also strengthens coordination compared to decentralized local decisions. We build on our prior bounded rationality models of people and stochastic models of artificial intelligence to determine optimal mixed human-machine architectures. First, we find fundamental information-theoretic limits of belief-sharing under Bayes risk and discrete choice models, new kinds of CEO problems. As a key substep, this involves determining fundamental Ziv-Zakai bounds on Bayesian estimation under non-quadratic criteria. We then use quantization and decision theory to develop optimal architectures that have cognitively- and algorithmically-limited agents, including optimal categorization of beliefs and judgment pooling rules taking human behavior into account. Finally, we consider the language needed to communicate beliefs in complicated network structures to achieve collective intelligence, studying Nash equilibria balancing focal and shared concerns."
"1565979","CRII: CPS: Towards an Intelligent Low-Altitude UAS Traffic Management System","CNS","CRII CISE Research Initiation","05/15/2016","07/26/2016","Peng Wei","IA","Iowa State University","Standard Grant","David Corman","04/30/2019","$174,998.00","","pwei@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","CSE","026Y","8228, 9150","$0.00","The objective of this project is to provide theoretical foundations for cyber-physical systems to support the increasing autonomy in the presence of other manned/unmanned air traffic. Currently the United States air transportation is facing significant challenges due to the rapid evolution of increasingly autonomous systems such as unmanned aircraft systems (UAS) and their expanding presence. However, there has been little scientific investigation on the cyber-physical systems that supports unmanned aircraft operations operating in the presence of other air vehicles. This research project explores novel strategies of coordinating and managing the UAS traffic to ensure low-altitude airspace safety and efficiency in near future. This will also help to catalyze additional cyber-physical systems research in related areas including aviation infrastructures, navigation and surveillance devices, and unmanned aerial vehicle technologies. The investigator will work with Iowa State University Extension and Outreach Office to promote UAS applications in precision agriculture, aviation safety and responsible uses of UAS.<br/><br/>The theoretical aspect of the research will leverage interdisciplinary methodologies in the fields of optimization, artificial intelligence, and control. The project designs algorithms, implements software and demonstrates proof-of-concept using low-altitude UAS traffic management as a challenge application area. This project establishes an unmanned air system traffic simulation platform, which can be used to validate new methods and tools, and enable collaborations with government, industrial and academic partners. The research outcomes are expected to provide a framework to investigate the feasibility, safety, efficiency and potential benefits of the increasing autonomy in civil aviation."
"1747798","Phase I IUCRC University of Oregon: Center for Big Learning","CNS","INDUSTRY/UNIV COOP RES CENTERS","02/01/2018","01/30/2018","Dejing Dou","OR","University of Oregon Eugene","Continuing grant","Dmitri Perkins","01/31/2023","$299,999.00","Joseph Sventek, Daniel Lowd, Allen Malony, Boyana Norris","dou@cs.uoregon.edu","5219 UNIVERSITY OF OREGON","Eugene","OR","974035219","5413465131","CSE","5761","5761","$0.00","Recent advances in machine learning are ushering in a new era in intelligent computing.  The NSF Industry/University Collaborative Research Center for Big Learning (CBL) at the University of Oregon (UO) aims to design novel algorithms and develop efficient systems for deep learning applications in the era of big data.  CBL will catalyze diverse expertise of faculty members, students, industry partners, and federal agencies to create state-of-the-art deep learning methodologies, technologies, and applications across broad domains of business, healthcare, and Internet-of-Things.  CBL will provide training for new scientists and graduate students, as well as a rich environment for cross-disciplinary engagement.<br/><br/>The mission of CBL is to perform pioneering research and development in powerful deep learning algorithms, efficient intelligent systems, and novel applications through unified and coordinated efforts in the CBL consortium. The CBL research team at the UO includes experts in data science, artificial intelligence, machine learning, high-performance computing, health informatics, and bioinformatics. They will explore research projects related to medical record analysis, health behavior prediction, natural language processing, performance optimization, financial forecasting, and computer vision by deploying various deep learning models. <br/><br/>CBL is expected to have broad transformative impacts in computational technologies, education, and society. Through research and applications to address a broad spectrum of real-world challenges, CBL will make significant contributions and impacts to the deep learning community. The discoveries from CBL will amplify opportunities for new products and services of industry in general, while delivering key techniques to CBL industry partners in particular. As the nexus of deep learning research and applications, CBL offers an ideal platform to nurture next-generation talents through world-class mentors from both academia and industry, disseminate the cutting-edge technologies, and facilitate industry/university collaborative research.<br/><br/>The center's repository is hosted at http://nsfcbl.org.  The data, code, and documents will be organized and maintained on the CBL server for the duration of the center plus five years.  The internal code repository will be hosted at GitLab.  After the software packages are well documented and tested, they will be released and hosted at popular public servers, such as GitHub and Bitbucket."
"1815563","NeTS: Small:  Collaborative Research: Towards Adaptive and Efficient Wireless Computing Networks","CNS","Networking Technology and Syst","10/01/2018","08/21/2018","Bin Li","RI","University of Rhode Island","Standard Grant","Monisha Ghosh","09/30/2021","$250,000.00","","binli@uri.edu","RESEARCH OFFICE","KINGSTON","RI","028811967","4018742635","CSE","7363","7923, 9150","$0.00","Today's mobile devices are not merely smart, they are becoming intelligent as artificial intelligence applications such as Facebook Caffe2 and Google Tensor-Flow Lite are being pushed into mobile devices and as mobiles devices are being integrated into the cloud-fog-mobile architecture. This calls for efficient and adaptive computing/communication co-design of wireless networks to optimize application-level latency (including both communication latency and computing times) and to achieve energy efficiency (considering energy consumed by both communications and computing).  This project develops fundamental theories and novel architectures of low-latency, energy-efficient, and computing-centric wireless networks to support emerging mobile intelligence applications. Theories and algorithms developed by the PIs are constantly integrated into the undergraduate and graduate courses taught at the two universities. This project also provides hand-on experiences to undergraduate and high school students with state-of-the-art wireless technologies. <br/><br/>Computing/communication co-design, while new for wireless networks, is a central topic in data center networks. However, the proposed solutions, while inspiring, are not directly applicable to wireless computing networks because of the unique features of wireless networks such as wireless interference, channel fading and limited energy. This project focuses on provably optimal mechanisms that dynamically and adaptively schedule computing tasks and data transmissions to meet application-level performance requirements, and consists of three interdependent thrusts: (i) Optimal computing/communication co-design. This thrust develops mathematical models and theoretical limits of wireless computing networks, (ii) Robust computing/communication co-design. This thrust focuses on robust computing and communication co-design that achieves desired performance with imperfect state information and under unavoidable short-term system overload and (iii) Learning-aided adaptive computing/communication co-design. This thrust further improves the performance of wireless computing networks by leveraging both historical data and predictable user behaviors.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1821666","SaTC: EDU: Microlessons to Build Readiness in the Cybersecurity Workforce","DGE","Secure &Trustworthy Cyberspace","09/01/2018","08/17/2018","Louise Yarnall","CA","SRI International","Standard Grant","Victor P. Piotrowski","08/31/2020","$300,000.00","Grit Denker","louise.yarnall@sri.com","333 RAVENSWOOD AVE","Menlo Park","CA","940253493","6508592651","EHR","8060","025Z, 7254, 7434, 9102, 9178, 9179, SMET","$0.00","Cyber threats to U.S. businesses and governments challenge both national security and industry competitiveness. Better solutions are needed for training the cybersecurity professionals who protect these networks, particularly the mid-career professionals who lack the time and resources to take courses. This research will develop and test the feasibility of using a smartphone application to deliver concise learning content, microlessons, in a user-tailored, coherent, and flexible way to support workplace learning about new cyber threats and ethical hacking procedures. This work advances learning scientists' understanding about the curriculum design processes required to convert long-form, technical lesson content into brief lessons and quizzes designed for self-directed adult learners. It also contributes to computer scientists' methods of using artificial intelligence to track learners' progress and make recommendations on the next steps in the learning process. <br/><br/>The research will have three main phases. First, researchers will select and transform existing online cybersecurity learning materials used in community college certification programs into a collection of 1- to 4-minute microlessons. The researchers will organize the content, ensure it is consistent with industry standards, and provide in-app badges. Researchers will also create set of intelligent lesson recommendations that guide learners through the reasoning that hackers use to stage attacks and that defenders use to detect, diagnose, monitor, and mitigate attacks. Lesson recommendations will adjust according to each learner's needs, existing knowledge, and past experience. Second, the research will deliver a test set of microlesson sequences on a smartphone platform called PERLS (Pervasive Learning System). This initial set of lessons will include between 200 and 350 different microlessons, quizzes, self-reflections on learning, and guided hands-on experiences with cybersecurity tools, as well as intelligent, personalized content recommendations. Third, the research will culminate with a pilot test of the prototype with up to 15 working professionals seeking to update their cybersecurity skills. This pilot will track tool usage frequency and learning progress as measured through quizzes and learners' self-reflections. The results will be shared through cybersecurity education and professional associations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1849112","I-Corps:  Real-Time Monitoring with Predictive Intelligence for Efficient Warehouse and Outdoor Inventory Management","IIP","I-Corps","09/15/2018","08/16/2018","David Grau","AZ","Arizona State University","Standard Grant","Cindy WalkerPeach","02/28/2019","$50,000.00","","david.grau@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project supports improving the efficiency of inventory and warehouse management operations with a cost-affordable technology innovation capable of monitoring goods in real-time without the need for static communications infrastructure. The project promises to enhance such operations through the extraction of information from the collected data and the provision of time-critical insights at a fraction of the costs of current commercial tools. The monitoring innovation will potentially become the first solution in the market capable of continuously monitoring goods in outdoor environments. In addition, the monitoring innovation will potentially become the first cost-affordable monitoring solution for low-value goods. The innovation promises a primary impact in the sectors of defense and construction. In reality, though, it offers the potential to positively impact the cost and efficiency of complex inventory and warehouse management operations across US industry sectors. This I-Corps team will cross-pollinate discovery and innovation across the broad spectrum of implementation scenarios by addressing the existing latent inefficiencies in such operations.<br/><br/>This I-Corps project explores the market potential of the real-time monitoring, predictive, and inexpensive innovation in support of inventory and warehouse management operations. A realistic real-time monitoring solution without the need for static communications infrastructure is a technically complex endeavor beyond the capabilities of commercial tracking and monitoring tools. The proposed innovation optimizes operations and information flows, and the response to upstream (push) and downstream (pull) processes and overall system performance. As large datasets are fused the artificial intelligence aspect of the innovation automatically identifies inefficiencies and bottlenecks, and reassesses forecasts and system decisions that account for latest events, data uncertainties, and multiple local optima. This I-Corps team plans to investigate the market potential of the innovation, validate customer needs and how the innovation can alleviate such needs, and discern sustainable business models.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1539011","VEC: Medium: Large-Scale Visual Recognition: From Cloud Data Centers to Wearable Devices","IIS","INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE","10/01/2015","09/18/2017","Jia Deng","MI","University of Michigan Ann Arbor","Continuing grant","Maria Zemankova","09/30/2018","$960,000.00","Kevin Pipe, Thomas Wenisch, Lingjia Tang, Jason Mars","jiadeng@cs.princeton.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","CSE","1640, 1714","002Z, 1640, 7924","$0.00","Advances in computer hardware and software promise to revolutionize the ways in which society interacts with visual information. However, visual recognition systems are limited by the lack of a practical means to classify the millions of concepts that arise in visual scenes and thus efficiently recognize when a small number of these concepts appear in a given scene. Furthermore, while real-time processing of visual data could significantly expand our perception of our surroundings, state-of-the-art vision systems cannot currently be implemented on wearable devices such as smartphones due to the limited heat dissipation (e.g., no fans or liquid cooling) and power such devices can provide. This research will overcome these challenges by developing artificial intelligence (AI) systems that efficiently manage the resources most crucial for high-performance wearable-based visual recognition, including the wearable device's real-time power consumption and computation. These systems will be empowered to initiate bursts of intense computation that are thermally managed by materials within the wearable device which are engineered to melt during heavy heating and solidify between bursts. Moreover, the AI systems will govern the communication between the device and external (cloud-based) computation resources as well as large-scale visual concept databases housed in data centers, thus providing extreme performance in a wearable form factor. Central concepts of this work will be integrated in undergraduate and graduate coursework, and a demonstration system will be made available to the research community and used in educational modules for high school students.<br/><br/>This effort seeks to advance the core capabilities of large-scale visual recognition by co-designing visual models and computing infrastructure. The goal is to enable encyclopedic, real-time visual recognition through seamless integration of visual computing on wearable devices and in the cloud. The PIs envision a wearable visual recognition system that continuously captures live video input while providing intelligent, real-time assistance through automatic or on-demand visual recognition by means of a combination of computation at the device and offloading to the cloud. Such a system is not currently feasible due to a number of fundamental challenges. First, the severe energy and thermal constraints of wearable devices render them incapable of performing the intensive computation necessary for visual recognition. Second,  it remains an open question how to support encyclopedic recognition in terms of both visual models and data center infrastructure. In particular, it remains unclear how current visual models, although highly successful at recognizing 1,000 object categories, can scale to millions or more distinct visual concepts. Moreover, such an encyclopedic visual model must be supported through data center infrastructure, but little progress has been made on how to build such infrastructure. This project addresses these fundamental challenges through an interdisciplinary approach integrating computer vision, hardware architecture, VLSI design, and heat transfer. The PIs will investigate three research thrusts. In Thrust 1, the PIs will develop a new type of deep neural networks that allow resource-efficient execution of modules. This new framework provide a unified way to design, learn, and run scalable visual models that can maximize the utility of recognition subject to resource constraints, such as latency, energy, or thermal dissipation of a wearable device. In Thrust 2, the PIs will design and fabricate a visual processing chip capable of computational sprinting (bursts of extreme computation well above steady-state thermal dissipation capabilities), leveraging the new framework developed in Thrust 1. In Thrust 3, the PIs will design datacenter infrastructure that supports large-scale hierarchical indexing of visual concepts for encyclopedic recognition, with a focus on latency, throughput, and energy efficiency. Finally, the PIs will build a demonstration system to evaluate the proposed algorithms, software, and hardware components and to assess the overall performance of an end-to-end system. The project web site (http://mivec.eecs.umich.edu/) will provide access to the results of this research including technical reports, datasets, and source code."
"1844740","EAGER: Exploring Cognitively Plausible Computational Models for Processing Human Language","IIS","ROBUST INTELLIGENCE","09/01/2018","08/17/2018","Anna Rumshisky","MA","University of Massachusetts Lowell","Standard Grant","Donald T. Langendoen","08/31/2020","$109,926.00","","arumshisky@gmail.com","600 Suffolk Street","Lowell","MA","018543643","9789344170","CSE","7495","7495, 7916","$0.00","Despite the recent successes of artificial intelligence techniques designed to process human language, most contemporary solutions are designed to handle very specific language processing tasks.  As a result, human-level language understanding is still out of reach for most current computational approaches, especially when retaining new information and reasoning over the accumulated knowledge is involved.  This exploratory project advances the goal of developing more cognitively realistic computational models that can mimic some of the known properties of human language processing, and as a result, be more robust and better suited as general systems for language understanding, with human-like learning which involves obtaining and updating knowledge over time.<br/><br/>While most contemporary deep learning approaches in natural language processing focus on task-specific end-to-end models, this project prioritizes generalist architectures that would be consistent with the current data on semantic priming, grouping and chunking effects in the formation and use of conceptual systems, and the effects of long- and short-term memory on the storage and retrieval of knowledge. In this project, novel neural network architectures are planned that model a subset of these properties.  The processes that enable learning and memory via strengthening of synaptic connections in the brain will be emulated by a set of representational units (r-units) with bidirectional connections, modeling the interaction between small regions of neocortex during information processing. Memory Store Activation State Model represents the connections between r-units in terms of convolutional filters applied to the memory store. The priming effects will be modeled by a pre-activation pattern produced via a sequence of deconvolutional operation.  Rate-Based Connectivity Network model combines reinforcement learning on per-node basis with a form of Hebbian learning applied to a time-varying system where each r-unit calculates rate of change of its output, allowing node activations to linger through time; it is trained with a discrete global reward signal. The goal of this project is to establish the feasibility of the proposed architectures by developing the initial proof-of-concept prototypes, demonstrating that they are able to converge on simple learning tasks, and applying them to the task of language modeling to ensure that a practically useful representation can be learned.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815535","CIF: RI: Small: Information-theoretic measures of dependencies and novel sample-based estimators","IIS","ROBUST INTELLIGENCE","08/15/2018","08/11/2018","Sewoong Oh","IL","University of Illinois at Urbana-Champaign","Continuing grant","Weng-keen Wong","07/31/2021","$146,605.00","","swoh@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","7495","7495, 7923","$0.00","Measures of dependencies play central roles in discovering associations between variables that leads to scientific discoveries. In practice, analysts need to compute these measures from data, which can be challenging. The standard estimators can fail when, for example, the data has a mixture of continuous and discrete variables, or when the data lies on a complex space with abundant boundaries. The aim of this project is to address practical issues in estimating measures of dependencies, and provide novel estimators to overcome these challenges. The success of the proposed work will result in novel estimators for discovering new aspects of data. The immediate impact is in two specific contexts: discovering correlations in biological datasets and analyzing the inner-workings of deep neural networks; the lasting impact will be in diverse fields including genomic, biology, machine learning, and artificial intelligence. This project also integrates research with education through the creation of a graduate course on statistical learning. In addition, the project will offer undergraduates the opportunity to be involved in research.<br/><br/>This proposal addresses two fundamental questions: designing novel estimators for information theoretic measures and designing novel estimators for modern measures of correlation that is defined as a solution of optimization problems. In the former, two major challenges are addressed: variables of mixed type (continuous and discrete) and boundary biases. Borrowing techniques from local log-likelihood density estimators, nearest neighbor methods, and order statistics, this leads to a new estimator that can adapt to the local geometry of the distributions in a principled way, that improves significantly over existing estimators. In modern data analysis, several measures of correlations are naturally defined as solutions of optimization problems, making them challenging to estimate. This proposal aims to provide a principled approach and propose a new estimator borrowing insights from importance sampling and nearest neighbor methods. The proposed framework is applied to estimate hypercontractivity ratio, an information theoretic quantity that captures hidden correlations in the data and is naturally defined as a solution of an infinite dimensional optimization. The proposed measure of hypercontractivity  is shown to discover potential correlations that other standard measures are not able to, in canonical synthetic examples and real datasets.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1736056","EXP: Collaborative Research: Empowering Learners to Conduct Experiments","IIS","IUSE","09/01/2017","08/23/2017","Steven Sutherland","TX","University of Houston - Clear Lake","Standard Grant","William Bainbridge","08/31/2019","$70,000.00","","Sutherland@UHCL.edu","2700 Bay Area Boulevard","Houston","TX","770581002","2812833016","CSE","1998","8045, 8209, 8841, 9178","$0.00","This project seeks to transform current practices in the teaching of scientific research methods by shifting the fundamental dynamics and focusing in a scientific domain that is relatable to a broad audience: designing and conducting social and behavioral science experiments. Scientific inquiry is key to making societal progress and improving our understanding of the world. Social and behavioral science programs are largely designed to prepare future researchers, but have a minimum expectation that students become critical consumers of research. Understanding the scientific method and the experimental methods used by researchers is necessary for establishing an ability to effectively assess the research that students will encounter in both the media and scientific outlets. Student understanding of scientific inquiry is significantly enhanced when anchored in inquiry experiences; however, opportunities for scientific research experiences are limited, even in research methods courses, due to the challenges of teaching experimental design and problems regarding access to and recruitment of participants. Without these experiences, students in higher education struggle to fully understand scientific inquiry. To address common barriers to learning how to conduct research, this project is designing a flexible, computer-based platform to be collaborative, narrative-based, engaging, and inspired by constructionist theories to facilitate learning with the use of artificial intelligence (AI) support.<br/> <br/>The platform developed in this project will serve as a model of a new genre of constructionist research environments, that enable learners to leverage technologies to create, modify, and replicate experiments, recruit participants, and analyze their results to learn about the world. The design-based research approach will operate in two cycles; in each cycle, a revised module and set of tools will be deployed. This results in two major research contributions: (1) Using mixed-methods, the theoretical and educational contribution is to study the process by which students in higher education learn to conduct experimental research, and about the roles of AI assistance, collaboration, narrative, and activities motivated by curiosity, exploration, and reflection. (2) The technological contribution is an innovative, AI-assisted set of scenario creation tools that empower learners to create experiments and that allow us to understand how an intelligent, collaborative, engaging, narrative-based platform can support students in higher education in designing and conducting social and behavioral science experiments.  With this system, it will be easier to create, run, replicate, and build upon studies and to reach out to a broader audience than the pool of university students used in typical in-person laboratory experiments. As a result, the platform will make it possible to transform social science research practices and even has the potential to foster new scientific discoveries."
"1319966","RI: Small: Any-Angle Search","IIS","ROBUST INTELLIGENCE","08/01/2013","07/20/2018","Sven Koenig","CA","University of Southern California","Standard Grant","James Donlon","07/31/2019","$452,979.00","","skoenig@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7495","7495, 7923, 9251","$0.00","In this project, the PI studies any-angle search methods. Any-angle search methods are variants of the heuristic search method A* that interleave the search with path optimizations by propagating information only along grid edges (to achieve small runtimes) but without constraining the paths to grid edges (to find short ""any-angle"" paths, namely paths whose headings can change by any angle). The objective of this project is to broaden any-angle search from a few isolated search methods to a well-understood framework and to extend its applicability. To this end, the PI is developing new any-angle search methods and analyzing their properties, which is complicated by the fact that even base properties often do not transfer from A* to them. The team will also evaluate all new and existing any-angle search methods against each other and against alternative search methods, for example, to understand how they trade off among runtime, path length and memory consumption.<br/><br/>Any-angle search is a recent search paradigm that promises to result in a new class of powerful path-planning methods for mobile robots, including underwater and aerial vehicles. The project includes dissemination activities to raise awareness of any-angle search in artificial intelligence and robotics (such as via tutorials, open-source code and web applets) and offers research opportunities to both graduate and undergraduate students."
"1409987","RI: Medium: Collaborative Research: Experience-Based Planning: A Framework for Lifelong Planning","IIS","ROBUST INTELLIGENCE","08/01/2014","06/10/2016","Sven Koenig","CA","University of Southern California","Standard Grant","James Donlon","07/31/2019","$348,000.00","","skoenig@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7495","7495, 7924, 9251","$0.00","Robots need to improve their behavior over time, yet produce consistent behavior in order to allow humans to predict their actions, which is necessary to develop trust in their behavior or even cooperate with them. Furthermore, many tasks repeat, such as opening drawers. This project develops technology that addresses these issues by viewing planning as a lifelong process and exploiting the structure of human environments for efficiency, for example that drawers typically open in similar ways.<br/><br/>This research collaboration is developing a framework for lifelong planning based on experience graphs that aims to improve performance of planning over time by exploiting past experiences when solving similar planning tasks. The concept is novel because experiences are used to guide the heuristic search as opposed to be used for mere replay or adaptation. The idea that makes this possible is a novel heuristic search-based framework that can take advantage of prior experiences and still provide rigorous guarantees on completeness and path quality. The team studies how experiences can be utilized effectively during planning, how planning should gather experiences, how it should prune redundant experiences and how it can obtain experiences from demonstrations. Applications include everyday household tasks and low-volume manufacturing tasks. The software developed in this collaborative research is being integrated into the SBPL library, one of the core libraries in ROS. The project also incorporates educational activities as well as activities that help to bridge the research communities in robotics and artificial intelligence, two separate communities despite their common interest in autonomous systems."
"1822752","Collaborative Research: CSEdPad: Investigating and Scaffolding Students' Mental Models during Computer Programming Tasks to Improve Learning, Engagement, and Retention","IIS","Cyberlearn & Future Learn Tech","09/01/2018","07/31/2018","Peter Brusilovsky","PA","University of Pittsburgh","Standard Grant","Kurt Thoroughman","08/31/2021","$250,519.00","","peterb@mail.sis.pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","CSE","8020","063Z, 8045","$0.00","Computing skills, such as computer programming, are an integral part of many disciplines, including the fields of science, technology, engineering, and math (STEM). Although such skills are in high-demand, and the number of aspiring Computer Science (CS) students is encouraging, a large gap between the supply of CS graduates and the demand persists because, for instance, college CS programs suffer from high attrition rates in introductory CS courses. One reason for the high attrition rates in introductory CS courses is the inherent complexity of CS concepts and tasks. To help students better cope with the high level of complexity, this project investigates a novel education technology, called CSEdPad (CS Education Pad), meant to ease students' introduction to programming during their early encounters with CS concepts and tasks. Moreover, the project forges new frontiers in CS education through a research program that advances our understanding of students' source code comprehension, learning, and motivational processes. The CSEdPad project has the potential to transform how students perceive computer science, increase their programming skills and self-efficacy, and lead to increased retention rates. The result will be a win-win-win situation for aspiring students, CS programs and their organizations, and the overall economy.<br/><br/>The CSEdPad system design brings to bear proven educational technologies and techniques to improve students' mental model construction, learning, engagement, and retention in CS education. In particular, the system targets source code comprehension, a critical skill for both learners and professionals. It monitors and scaffolds source code comprehension processes while students engage in a variety of code comprehension tasks. Key approaches being explored include Animated Pedagogical Agents, self-explanation, and the Open Social Learner Model. Outcome variables include comprehension measures, learning gains, engagement level, retention, and self-efficacy. Due to its interdisciplinary nature, the project will impact several fields including Computer Science education, cognitive psychology, intelligent tutoring systems, and artificial intelligence. Students participating in the experiments will be selected from a diverse student body with respect to gender, ethnicity, and socioeconomic status. An increase in recruitment and retention of students from these populations will have far-reaching implications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1514253","RI: Medium: Sentential Decision Diagrams","IIS","ROBUST INTELLIGENCE, Unallocated Program Costs","07/01/2015","05/15/2018","Adnan Darwiche","CA","University of California-Los Angeles","Continuing grant","James Donlon","06/30/2019","$705,865.00","","darwiche@cs.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","CSE","7495, 9199","7495, 7924, 9251","$0.00","Logical and probabilistic reasoning are now routinely used in various fields of computer science and engineering, including artificial intelligence in particular. These modes of reasoning currently underlie systems that perform automated diagnosis, planning, software and hardware verification, web information extraction, bioinformatics, vision and robotics. This project aims at advancing the state of the art in logical and probabilistic reasoning, to allow scientists and engineers to learn and reason with much larger models than is currently possible. The project is based on a particular computational paradigm, known as knowledge compilation, which transforms knowledge into forms that facilitate their efficient processing by reasoning and learning algorithms. The results expected from this project will provide domain-independent, highly scalable, tools and techniques for addressing computational problems that arise in healthcare, industrial automation, and information management. The project will also provide a context for training graduate students in the computational paradigm of knowledge compilation, and will target the integration of this paradigm into computer science curricula.<br/><br/>More specifically, the project aims to develop a new framework for knowledge compilation based on the recently discovered Sentential Decision Diagram (SDD). The SDD is a target compilation language, which generalizes the Ordered Binary Decision Diagram (OBDD) that has been quite influential in many areas of computer science and engineering. This project has two parts. The first part is concerned with developing the SDD compilation language further, both theoretically and practically. On the theoretical side, there is a number of pending of questions relating to lower and upper bounds on SDDs, in addition to questions that must be answered to fully understand their relation to OBDDs. On the practical side, the SDD package needs to be extended to enhance its scalability and to provide new functionality that is needed for fully exploiting SDDs in a wider spectrum of applications. The second part of the project is concerned with a more recent discovery: The probabilistic SDD (PSDD). This compilation language aims at inducing probability distributions over propositional theories, in a very principled and efficient manner. Our objective here is to develop PSDDs into a mature tool, with a corresponding public package, for learning tractable probabilistic models under massive logical constraints, and for compiling probabilistic graphical models into PSDDs for the purpose of more scalable probabilistic reasoning.<br/>"
"1718945","RI: SMALL: Efficient Implementations of Goal-Directed Solvers for Answer Set Programming","IIS","ROBUST INTELLIGENCE","09/01/2017","08/04/2017","Gopal Gupta","TX","University of Texas at Dallas","Standard Grant","James Donlon","08/31/2020","$420,000.00","","gupta@utdallas.edu","800 W. Campbell Rd., AD15","Richardson","TX","750803021","9728832313","CSE","7495","7495, 7923","$0.00","The goal of this project is to develop efficient implementation techniques for realizing automated reasoning systems that emulate human-style common sense reasoning. Automating common sense reasoning is important for developing advanced applications of artificial intelligence (AI), particularly, in areas where the thought process of an expert needs to be automated, e.g., reasoning performed by a medical doctor during diagnosis and prescribing a treatment. Human reasoning is difficult to emulate on a computer, as humans simplify reasoning by using default conclusions (e.g., if Tweety is a bird, it must fly) coupled with raising exceptions (if Tweety turns out to be a penguin later, retract the conclusion about Tweety's flying abilities). Because of this peculiar nature of human reasoning, approaches based on standard logic do not work very well: one has to resort to a non-monotonic logic, i.e., a logic in which conclusions reached now may be withdrawn later as new information becomes available. Research conducted in this project will result in efficient, query-driven implementations of these non-monotonic logics. Successful completion of this project will result in advanced applications such as an automated system that can advise a physician on how to treat a particular disease, or a self-driving car's decision-making system that can emulate a human's driving expertise.<br/><br/>The project will rely on the paradigm of answer set programming (ASP) to represent common sense knowledge. An answer set program consists of rules containing (possibly negated) predicates. Current ASP systems rely on first grounding the answer set program to obtain an equivalent propositional program, and then using a Boolean satisfiability (SAT) solver to find models of this propositional program that contain the answer that is sought by the user. The grounding requirement restricts the range of programs that can be executed. This project builds upon earlier research on directly executing predicate answer set programs, i.e., without grounding them first. It aims to realize faster implementations of such systems by designing a virtual machine to which an answer set programs will be compiled to and executed."
"1423260","CHS: Small: Advanced Design Principles for Computer Simulated Agents","IIS","Cyber-Human Systems (CHS)","09/01/2014","05/19/2017","Christine Lisetti","FL","Florida International University","Continuing grant","William Bainbridge","08/31/2019","$545,618.00","Mark Williams","lisetti@cis.fiu.edu","11200 SW 8TH ST","Miami","FL","331990001","3053482494","CSE","7367","7367, 7923, 9251","$0.00","This project will investigate human interaction with simulated agents in situations where humans expect empathic communication, such as healthcare.  In domains such as this, the person interacts with computer-based interventions (CBI) as an education process evolves.  Almost all psychosocial interventions currently available on the web are delivered merely via text.  Research indicates that many users will lose interest and drop out, although completion is critical to achieving desired goals.  Human-computer interaction literature suggests that interacting with simulated agents can increase the user's engagement, but that the user will expect social competence when interacting with them.  This project will answer a set of research questions for the design of simulated characters with some empathic intelligence, to create a new modality for the delivery of CBIs.  The specific health-related application area will facilitate development and evaluation of new techniques and design principles, that will have much wider applicability, potentially whenever people interact with computer-based systems through simulated agents. <br/><br/>This research will advance the ability of computer scientists to create competent simulated agents that can adapt their verbal and non-verbal behavior to the user's affective states, and over time tailor their interaction to the specific user to produce the maximum positive impact in terms of users' engagement and achievement of their goals.  The model of empathy and social competence developed will enable simulated characters to adapt in real time to a user's short-lived emotions over a single interactive session.  Longer-term affective states will be modeled over long-term interaction via follow-up sessions with the same individual.  Thus, development of rapport between a human and an artificial intelligence is a dynamic process over time, and the research is expected to discover new principles that might not be seen in exclusively short-term interactions. The project will provide: (1) a scheme to design tailored interaction by constructing a dynamic user-model with user's demographic information and fluctuating personal characteristics; (2) a model of empathic verbal communication built by combining motivational interviewing techniques with an ontology-based dialog system; (3) a computational model for the integration of verbal and non-verbal communication cues by adapting the character's facial expressions, vocal modulation, and kinesics to its verbal utterances in the context of the session.  In addition, the research will engage scientific questions about diversity in communication style across human groups, facilitated by the fact that the project is housed at the region's principal minority-serving research university.  The fact that the research will involve students in the development of systems that integrate multiple technologies will give them an excellent educational experience, gaining competence that will be valuable for a range of future careers."
"1813537","RI:Small:Robust Performance Models","IIS","ROBUST INTELLIGENCE, EPSCoR Co-Funding","09/01/2018","06/29/2018","Lars Kotthoff","WY","University of Wyoming","Standard Grant","James Donlon","08/31/2021","$412,000.00","","larsko@uwyo.edu","1000 E. University Avenue","Laramie","WY","820712000","3077665320","CSE","7495, 9150","7495, 7923, 9150","$0.00","Algorithms are ubiquitous in modern society and integral to the economy. Whether finding optimal assignments of packages and operators to planes, trucks, and ships, or translating between different languages, the problems solved become larger and more challenging every day. Crucially enabling such developments are advances in artificial intelligence. There are often different approaches for solving the same type of problem, and they are often synergistic -- where one fails, another performs well.  AI techniques in this project allow the best approach for a given problem to be chosen automatically.  This research will allow for such choices to be made more robustly even in difficult circumstances, resulting in improved performance and reduced effort to deploy AI in practical systems. Ultimately, the project will make it easier for humans to develop high-performance AI systems.<br/><br/>Algorithm selection is the process of automatically matching synergistic algorithmic choices to the specific properties of a problem in order to achieve optimal performance.  Current methods for making such choices over available algorithms are often limited in applicability by the hardware on which the algorithms were benchmarked, the resource limits imposed on runs, and subject to bias caused by performance fluctuations in randomized algorithms.  In many cases, these issues are caused by reliance on brittle performance measures, limiting practical application in academia and industry.  This project aims to address these limitations in three ways. First, it will define a notion of robustness to guide algorithm selection, and identify properties of algorithms, experimental setups, and computational environments that affect robustness. Second, it will develop specific performance measures informed by this definition of robustness, and which are portable across different hardware platforms. Third, it will mitigate the impact of brittle performance measures through new approaches to building performance models based on machine learning.  The project will result in the dissemination of shared data and benchmarks to the broader AI community, for example through the Algorithm Selection Library (ASlib).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822181","2nd Summer School on Cognitive Robotics: Proposed Summer School","IIS","ROBUST INTELLIGENCE","07/01/2018","06/27/2018","Brian Williams","MA","Massachusetts Institute of Technology","Standard Grant","Reid Simmons","06/30/2019","$25,000.00","","williams@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7495","7495, 7556","$0.00","This grant supports a week-long summer school on Cognitive Robotics to be held in Boston, Ma in July 2018. The summer school will be a combination of invited talks and tutorials, which are designed to introduce researchers to issues in planning and execution from perspectives of both Robotics and Cognitive Artificial Intelligence, and daily labs, which are designed to give students hands-on experience with robotic hardware and state-of-the-art software tools for developing robotic behaviors. The summer school will help expose graduate students to cutting-edge ideas at the intersection of Robotics and Cognitive Systems and will help to form a new community of researchers in this interdisciplinary area.  The hands-on experience with, and open-source release of, the Enterprise Executive Architecture will facilitate the formation of this collaborative community.  The summer school concludes with a grand challenge using robot hardware that combines what the students have learned during the week.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1526723","RI: Small: Bayesian Modeling of Situated Communicative Goals","IIS","PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","09/01/2015","06/10/2016","Matthew Stone","NJ","Rutgers University New Brunswick","Continuing grant","Tatiana D. Korelsky","08/31/2019","$499,945.00","Pernille Hemmer","matthew.stone@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","CSE","7252, 7495","7252, 7495, 7923","$0.00","This multidisciplinary project undertakes a program of research in natural language generation (NLG), the subfield of artificial intelligence that aims to construct intuitive, accessible utterances to communicate the data, knowledge and reasoning of computational systems.  NLG capabilities have an important role in facilitating new, more natural interaction with computers, both in current applications such as mobile information access and in emerging ones such as personal assistants and human-robot interaction.  NLG systems remain inflexible and difficult to build, however.  This research aims to addresses this problem by developing techniques to train NLG systems to match human language use.  The project is a close collaboration that links psychological experiments, designed to uncover the strategies human speakers use, to computational experiments, which apply these strategies in NLG systems using machine learning.<br/><br/>The theoretical framework at the center of this project is Bayesian cognitive modeling, a probabilistic approach that explains human information processing in terms of decision making under uncertainty.  Applied to language use, Bayesian cognitive modeling involves estimating the communicative goals speakers adopt, the knowledge and meanings available to speakers, and the choices speakers make to express needed information in suitable linguistic terms.  Such knowledge and strategies can then be used to drive NLG systems.  The specific research of the project investigates three key domains for applying NLG to construct messages to describe real-world situations: making lexical choices, constructing complex linguistic structures compositionally, and fulfilling multiple overlapping communicative goals.  The project explores each domain through interrelated activities carried out by an interdisciplinary team of computer scientists and psychologists: to formalize speaker choices using a range of Bayesian cognitive models; to fit the models to visually-grounded language corpora using machine learning; to evaluate the empirical scope of goal-directed reasoning by comparing the learned models both to attested human choices and to baseline learned models; and to assess how well the models match human comprehension of linguistic meaning.  The intellectual merits of the project lie in bridging the gap between traditional goal-directed rational models of human behavior and state-of-the-art computational methods that instantiate templates or reproduce likely patterns.  In addition to the societal impacts of the technology, the broader impacts of the project include the construction of data resources, models and modeling tools that will be distributed to facilitate further research, and contributions to ongoing initiatives for education in cognitive science at Rutgers."
"1755593","CRII: CHS: Predicting When, Why, and How Multiple People Will Disagree when Answering a Visual Question","IIS","Cyber-Human Systems (CHS)","05/01/2018","03/16/2018","Danna Gurari","TX","University of Texas at Austin","Standard Grant","Ephraim P. Glinert","04/30/2020","$174,947.00","","danna.gurari@ischool.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","7367","7367, 8228","$0.00","The goal of a visual question answering (VQA) system is to empower people to find the answer to any question about any image.  For example, a VQA system could enable blind people to address daily visual challenges such as learning whether a pair of socks match or learning what type of food is in a can.  VQA services could also facilitate the creation of smarter environments, say to monitor how many defective products are on a factory assembly line at any given time.  A limitation of existing VQA systems is that they do not account for the fact that a visual question may elicit different answers from different people.  VQA systems could save time and reduce user frustration if they empowered users to anticipate and resolve any answer disagreements that may arise.  Blind and sighted people could more rapidly and accurately learn about the diversity of human perspectives on the visual world.  VQA services also could teach people how to ask visual questions that elicit the desired answer diversity.<br/><br/>This project will create artificial intelligence (AI) models that can account for the possible diversity of answers inherent in crowd intelligence.  Specifically, AI models will be designed to predict when, why, and how human answer disagreement occurs, which in turn will enable new designs for human-computer partnerships.  This is challenging because it necessitates designing frameworks that simultaneously model and synthesize different and potentially conflicting perceptions of images and language for the many possible causes of disagreement.  To ensure that the AI models generalize across a broad range of applications, an existing corpus of over one million visual questions asked by blind and sighted people will be used to create annotated datasets that indicate when, why, and how much answer disagreement arises.  Methods will then be developed for automatically predicting directly from a visual question how much answer diversity will arise from a crowd, and why disagreement arises when it does.  Finally, a system will be designed for guiding visually-impaired users to more quickly formulate visual questions so they can receive a single, unambiguous crowd response (e.g., guide the person to better frame the visual content of interest with a mobile phone camera).  User studies with blind users will be conducted to empirically test the efficacy of the new system, with a focus on uncovering human-based issues in real-world, real-time situations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1736185","EXP: Collaborative Research: Empowering Learners to Conduct Experiments","IIS","IUSE, Cyberlearn & Future Learn Tech","09/01/2017","03/30/2018","Casper Harteveld","MA","Northeastern University","Standard Grant","William Bainbridge","08/31/2019","$367,662.00","Gillian Smith","c.harteveld@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","1998, 8020","8045, 8209, 8841, 9178","$0.00","This project seeks to transform current practices in the teaching of scientific research methods by shifting the fundamental dynamics and focusing in a scientific domain that is relatable to a broad audience: designing and conducting social and behavioral science experiments. Scientific inquiry is key to making societal progress and improving our understanding of the world. Social and behavioral science programs are largely designed to prepare future researchers, but have a minimum expectation that students become critical consumers of research. Understanding the scientific method and the experimental methods used by researchers is necessary for establishing an ability to effectively assess the research that students will encounter in both the media and scientific outlets. Student understanding of scientific inquiry is significantly enhanced when anchored in inquiry experiences; however, opportunities for scientific research experiences are limited, even in research methods courses, due to the challenges of teaching experimental design and problems regarding access to and recruitment of participants. Without these experiences, students in higher education struggle to fully understand scientific inquiry. To address common barriers to learning how to conduct research, this project is designing a flexible, computer-based platform to be collaborative, narrative-based, engaging, and inspired by constructionist theories to facilitate learning with the use of artificial intelligence (AI) support.<br/> <br/>The platform developed in this project will serve as a model of a new genre of constructionist research environments, that enable learners to leverage technologies to create, modify, and replicate experiments, recruit participants, and analyze their results to learn about the world. The design-based research approach will operate in two cycles; in each cycle, a revised module and set of tools will be deployed. This results in two major research contributions: (1) Using mixed-methods, the theoretical and educational contribution is to study the process by which students in higher education learn to conduct experimental research, and about the roles of AI assistance, collaboration, narrative, and activities motivated by curiosity, exploration, and reflection. (2) The technological contribution is an innovative, AI-assisted set of scenario creation tools that empower learners to create experiments and that allow us to understand how an intelligent, collaborative, engaging, narrative-based platform can support students in higher education in designing and conducting social and behavioral science experiments.  With this system, it will be easier to create, run, replicate, and build upon studies and to reach out to a broader audience than the pool of university students used in typical in-person laboratory experiments. As a result, the platform will make it possible to transform social science research practices and even has the potential to foster new scientific discoveries."
"1714855","ACL 2017 Student Research Workshop","IIS","ROBUST INTELLIGENCE","02/01/2017","01/18/2017","Marine Carpuat","MD","University of Maryland College Park","Standard Grant","Tatiana D. Korelsky","01/31/2019","$15,000.00","","marine@cs.umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","CSE","7495","7495, 7556","$0.00","The Association for Computational Linguistics (ACL) is the primary international organization for computational linguistics and natural language processing.  It also is one of the primary application areas for researchers in machine learning and artificial intelligence.  The proceedings of its annual meeting provide the foundation of the field; it is the most cited and most respected publication in computational linguistics.  Thus, it is also the most important gathering of researchers in computational linguistics and natural language processing. This project is to subsidize travel, conference and housing expenses of students selected to participate in the ACL Student Research Workshop, which will take place during the main ACL conference from July 31 - August 2, 2017 in Vancouver, Canada.  The Student Research Workshop helps create a new generation of researchers with a more thorough understanding of their field, with connections and collaborations across institutions, and with innovative and exciting research programs.  This contributes to America's pool of researchers with the needed scientific and engineering knowledge and skills. The workshop encourages a spirit of collaborative research and builds a supportive environment for a new generation of computational linguists.<br/><br/>The Student Research Workshop solicits two categories of submissions: research papers and research proposals. The research proposal can have only one author who must be a student. The research papers can have multiple authors, with the first author being a student (at either the graduate or undergraduate level).  The workshop is a venue for students to receive constructive critical feedback on their work from experts outside of their institution, and to connect with other students and senior researchers in their field.  The students gain exposure by presenting their work earlier than they would otherwise (i.e., in a form not yet ready for the main conference). This is particularly valuable for students from smaller institutions and undergraduate students. In addition, the workshop is organized and run by students. The student organizers gain valuable opportunities for professional growth and interaction with the researchers on the organizing committee of the main conference."
"1619344","RI: Small: Harnessing the Power of Constraint Propagation by Controlling Consistency Levels and Synthesizing Constraints","IIS","ROBUST INTELLIGENCE","07/01/2016","04/13/2018","Berthe Choueiry","NE","University of Nebraska-Lincoln","Standard Grant","James Donlon","06/30/2019","$486,000.00","","choueiry@cse.unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","CSE","7495","7495, 7923, 9150, 9251","$0.00","Decision and optimization problems raise many challenges in daily life as well as in business, engineering, and science.  Solving them ""well"" and ""quickly"" directly benefits our life-styles and economy, and allows us to effectively manage our resources.   Many scientific disciplines have focused on formalizing and solving such difficult combinatorial problems.   Constraint Processing (CP), a subfield of Artificial Intelligence, has focused on the transparent modeling of the restrictions (i.e., constraints) that govern those problems and create their complexity.  By examining how constraints interact among themselves and how interactions propagate along the constraints, CP has developed generic mechanisms to solve a problem by ruling out forbidden decisions and combinations of decisions, gradually eliciting the acceptable solutions and the optimal choices.  To this end, CP has formalized in terms of consistency properties how constraints interact among themselves and with the possible options.   Thus, the identification of such properties and the design of algorithms for enforcing them are at the heart of CP, and constitute perhaps what best distinguishes this area from other scientific disciplines concerned with the same computational problems.  The goal of this project is to understand the tradeoffs between the effectiveness and the cost of a variety of consistency algorithms, and to control how to interleave them dynamically during problem solving to solve difficult problems and reduce computational cost.<br/><br/>In particular, the research will garner the most computational benefits from consistency-based techniques by dynamically (a) selecting the right level of consistency to enforce at any point during search, and (b) synthesizing new constraints over opportunistically chosen variables.  The proposed activities extend on recent practical algorithms for higher-levels consistency, and contribute to the progress of the research in fundamental aspects of CP.  The developed methods will benefit other types of graphical models such as games as well as the next generation of commercial and public-domain constraint solvers. The insight gained from this research will improve the scope and content of the introductory and advanced courses on CP both at the undergraduate and graduate levels.   The various research tasks will allow the mentoring and training of young engineers and scientists to understand the roots of complexity in problem solving and to learn how to overcome it in practice."
"1827830","2018 Association for Computational Linguistics (ACL) Student Workshop","IIS","ROBUST INTELLIGENCE","04/01/2018","03/16/2018","Marie-Catherine de Marneffe","OH","Ohio State University","Standard Grant","Tatiana D. Korelsky","11/30/2018","$18,000.00","","demarneffe.1@osu.edu","Office of Sponsored Programs","Columbus","OH","432101016","6146888735","CSE","7495","7495, 7556","$0.00","The Association for Computational Linguistics (ACL) is the primary international organization for computational linguistics and natural language processing. It also is one of the primary application areas for researchers in machine learning and artificial intelligence. The proceedings of its annual meeting provide the foundation of the field; it is the most cited and most respected publication in computational linguistics. Thus, it is also the most important gathering of researchers in computational linguistics and natural language processing. This project is to subsidize travel, conference and housing expenses of students selected to participate in the ACL Student Research Workshop, which will take place during the main ACL conference from July 15-25, 2018 in Melbourne, Australia. The Student Research Workshop helps create a new generation of researchers with a more thorough understanding of their field, with connections and collaborations across institutions, and with innovative and exciting research programs. This contributes to America's pool of researchers with the needed scientific and engineering knowledge and skills. The workshop encourages a spirit of collaborative research and builds a supportive environment for a new generation of computational linguists. <br/><br/>The Student Research Workshop solicits two categories of submissions: research papers and research proposals. The research proposal can have only one author who must be a student. The research papers can have multiple authors, with the first author being a student (at either the graduate or undergraduate level). The workshop is a venue for students to receive constructive critical feedback on their work from experts outside of their institution, and to connect with other students and senior researchers in their field. The students gain exposure by presenting their work earlier than they would otherwise (i.e., in a form not yet ready for the main conference). This is particularly valuable for students from smaller institutions and undergraduate students. In addition, the workshop is organized and run by students. The student organizers gain valuable opportunities for professional growth and interaction with the researchers on the organizing committee of the main conference.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1750082","CAREER: Visual Recognition with Knowledge","IIS","ROBUST INTELLIGENCE","08/15/2018","01/17/2018","Yezhou Yang","AZ","Arizona State University","Continuing grant","James Donlon","07/31/2023","$101,523.00","","yz.yang@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","CSE","7495","1045, 7495","$0.00","This project will address the problem of Visual Recognition with Knowledge (VR-K): a challenging Artificial Intelligence task to enable a seeing machine to identify unknown visible concepts from previous encounters (annotated data samples) and knowledge (other contextual information). For example, consider such a system that has never encountered a zebra, but which has previous visual encounters with ""horses"" and ""black and white striped"" patterns. Incorporating the linguistic input that, ""A zebra is a horse-like animal with a black and white striped appearance"", the machine's task is to formulate a new recognizer for the visual concept ""zebra"" and to recognize this new concept later. A system that integrates visual and linguistic information in this way can provide the basis for robust personal mobile applications or service robots, such as visual assistants to the vision-impaired, and voice-enable agents for elder care.<br/> <br/>Conventional supervised learning techniques have been perfected to perform increasingly well on narrow performance tasks. To enable satisfactory performance in service robots and mobile multimedia applications, this research will integrate background and commonsense knowledge models to enable higher level reasoning together with such high-performance recognizers. This project will develop the VR-K framework focused on enabling more generalizable computer vision algorithms through integration with natural language understanding and grounding in knowledge-based reasoning. The research program will include 1) developing efficient probabilistic reasoning engines to construct recognition models of unseen concepts (object and attribute) without new annotation through probabilistic semantic parsing; 2) setting up new large-scale visual challenges and testbeds as the basis for rigorous performance evaluation of visual recognition with knowledge models and ablation analysis; and 3) prototyping the proposed framework on service robots and mobile devices for evaluation of the proposed framework's performance in complex real-world applications over a variety of user studies. The project will include education and outreach activities advancing AI in undergraduate research, diversity enhancement, Entrepreneurial Mindset (EM) education, and K-12 classrooms, and will include workshops to introduce AI and deep learning to professionals in non-CS professions such as medical research and pathology.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1803423","The 2018 NAACL Student Research Workshop","IIS","ROBUST INTELLIGENCE","04/01/2018","03/07/2018","Samuel Bowman","NY","New York University","Standard Grant","Tatiana D. Korelsky","03/31/2019","$15,000.00","","sb6065@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7495","7495, 7556","$0.00","The Association for Computational Linguistics (ACL) is the primary international organization for computational linguistics and natural language processing, which in turn is one of the primary application areas for research in machine learning and artificial intelligence. The annual meeting of the North American chapter of the ACL (NAACL) is one of the most prestigious and selective international conferences in these fields. The proceedings of this meeting is among the most cited publications in computational linguistics, and the meeting itself is the most important meeting for North American researchers in the field on years when it is held. This project will subsidize travel, conference and housing expenses of students selected to participate in the NAACL Student Research Workshop, which will take place during the main NAACL conference June 1?6, 2018 in New Orleans, LA. The Student Research Workshop helps create a new generation of researchers with a more thorough understanding of their field, with connections and collaborations across institutions, and with innovative and exciting research programs. This contributes to America's pool of researchers with the needed scientific and engineering knowledge and skills. The workshop encourages a spirit of collaborative research and builds a supportive environment for a new generation of computational linguists. <br/><br/>The Student Research Workshop solicits two categories of submissions: research papers and research proposals. The research proposal can have only one author who must be a student. The research papers can have multiple authors, with the first author being a student (at either the graduate or undergraduate level). The workshop is a venue for students to receive constructive critical feedback on their work from experts outside of their institution, and to connect with other students and senior researchers in their field. The students gain exposure by presenting their work earlier than they would otherwise (i.e., in a form not yet ready for the main conference). This is particularly valuable for students from smaller institutions and undergraduate students. In addition, the workshop is organized and run by students. The student organizers gain valuable opportunities for professional growth and interaction with the researchers on the organizing committee of the main conference.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1651565","CAREER: Modeling and Inference for Large Scale Spatio-Temporal Data","IIS","ROBUST INTELLIGENCE","03/15/2017","02/13/2018","Stefano Ermon","CA","Stanford University","Continuing grant","Kenneth C. Whang","02/28/2022","$207,034.00","","ermon@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7495","1045, 7495","$0.00","Key sustainability challenges, such as poverty mitigation, climate change, and food security, involve global phenomena that are unique in scale and complexity. Our global sensing capabilities - from remote sensing to crowdsourcing - are becoming increasingly economical and accurate. These recent technological developments are creating new spatio-temporal data streams that contain a wealth of information relevant to sustainable development goals. Actionable insights, however, cannot be easily extracted because the sheer size and unstructured nature of the data preclude traditional analysis techniques. This five-year career-development plan is an integrated research, education, and outreach program focused on developing new AI techniques to extract actionable insights from large-scale spatio-temporal data. These techniques have the potential to yield accurate, inexpensive, and highly scalable models to inform research and policy.<br/><br/>The research goal of this project is to develop new modeling and algorithmic frameworks to help address global sustainability challenges involving spatio-temporal data. This research will develop new predictive models of complex spatio-temporal phenomena integrating in unique ways ideas from graphical models and representation learning, improving their overall performance. New approaches to learn from unlabeled data exploiting various forms of prior domain knowledge, including spatio-temporal dependencies and relationships between different data modalities, will be developed. To learn models and make predictions at scale, this project will also develop new scalable probabilistic inference methods based on the use of random projections to reduce the dimensionality of probabilistic models while preserving their key properties. The techniques developed will be made available to both academia and industry through open-source software, and will enable computationally feasible approaches for analyzing large spatio-temporal datasets and for modeling global scale phenomena. Predictions and data products produced by this project will enable new analyses and advance sustainability disciplines. Results will be disseminated widely through scientific articles, research seminars, and conference presentations to maximize the benefits to the scientific community. Educational and outreach efforts will include the involvement of undergraduate students undertaking independent research projects, a website describing research bridging computation and, and a summer outreach program aimed at introducing under-represented high-school students to computer science and artificial intelligence."
"1350671","CAREER: Problem Solving in Dynamic, Distributed Environments","IIS","ROBUST INTELLIGENCE, EPSCoR Co-Funding","01/15/2014","01/23/2014","Roger Mailler","OK","University of Tulsa","Standard Grant","James Donlon","12/31/2018","$450,793.00","","roger-mailler@utulsa.edu","800 S. Tucker Drive","Tulsa","OK","741049700","9186312192","CSE","7495, 9150","1045, 7495, 9150","$0.00","Computers are increasingly used to monitor and manage many aspects of our daily lives.  These systems are often required to work together to solve complex problems that are rapidly changing.  Current approaches to addressing these situations develop tailored distributed protocols that are verified through empirical testing.  This project increases the practical applicability of distributed problem solving techniques by developing a theoretical model of these problems based on thermodynamic theory.  Using this model, a protocol's performance can, for the first time ever, be predicted under previously untested conditions.<br/><br/>This theoretical model is validated through extensive empirical evaluation and this project develops a new protocol that alters its problem solving strategy to maximize the trade-off between deliberate and reactive decision making based on environmental dynamics.  This protocol is applied to address a pressing practical problem: allocating telescopes for tracking objects in Low Earth Orbit (LEO). With nearly all of our manned space missions and satellites in LEO, effectively monitoring space debris has broad implications to society at large and scientific progress along numerous directions.<br/><br/>This transformative research combines cross-disciplinary ideas from artificial intelligence, distributed systems, and statistical physics.   The educational initiatives in this project directly address the recruitment and retention of students, especially focusing on women and minorities, into Computer Science by generating excitement through the Heartland Gaming Expo and by utilizing a new peer outreach program, called Engineering Ambassadors."
"1718384","RI: Small: A New Approach to Integrating Graphical Models in Decision-Theoretic Planning","IIS","ROBUST INTELLIGENCE","08/15/2017","07/25/2017","Eric Hansen","MS","Mississippi State University","Standard Grant","James Donlon","07/31/2020","$427,000.00","","hansen@cse.msstate.edu","PO Box 6156","MISSISSIPPI STATE","MS","397629662","6623257404","CSE","7495","7495, 7923, 9150","$0.00","This project addresses one of the central problems of research in Artificial Intelligence: the problem of planning, or sequential decision making, under uncertainty and imperfect information. Planning algorithms are widely-used for control and decision-making problems in engineering and business, with many practical applications in robotics, process control, logistics, user-adaptive systems, resource management, and related problems where automation of decision making is useful. This project considers two widely-used decision-theoretic frameworks for planning under uncertainty and imperfect information, which are partially observable Markov decision processes and influence diagrams, and integrates these two frameworks in a novel way that leverages their complementary advantages. <br/><br/>The project integrates these two frameworks by showing how to generalize algorithms for solving influence diagrams, especially classic variable elimination algorithms, so that they use algorithmic techniques for solving partially observable Markov decision processes (POMDPs) to improve scalability, as well as to represent plans and strategies more compactly. The generalized variable elimination algorithms developed in this project can behave like traditional algorithms for solving influence diagrams, or like traditional algorithms for solving POMDPs, depending on the order in which variables are eliminated. From this perspective, algorithms for influence diagrams and POMDPs that once appeared dissimilar can be viewed as special cases of the same, more general algorithm. More importantly, this perspective allows these complementary algorithmic techniques to be combined in new ways, leading to planning algorithms with improved performance, wider applicability, and easier-to-interpret results.  The project focuses on several related research problems that will extend this approach and make it more useful in practice, including the development of new heuristics for variable elimination ordering, the development of approaches to improving planner performance by leveraging problem structure, including context-specific independence, and the development of an integrated approach to bounded-error approximation that will allow tradeoffs between plan quality and computation time. Although the project focuses on finite-horizon planning problems, the integrated approach may also be used in solving infinite-horizon planning problems with non-Markovian structure. In addition to the intellectual impact of this research, the project will contribute to education, student mentoring, and outreach."
"1652052","CAREER: Active and Action-Centric Visual Understanding","IIS","ROBUST INTELLIGENCE","07/01/2017","08/22/2018","Ali Farhadi","WA","University of Washington","Continuing grant","Jie Yang","06/30/2023","$124,002.00","","afarhad2@gmail.com","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","7495","1045, 7495","$0.00","This project develops technologies for visual semantic planning; the problem of producing ordered sequences of actions that change the current world state from what is depicted in a given image or video to the state defined by a query task. The project bridges the gap between current levels of image understanding and what is needed to actively understand the visual world to the extent that an agent can plan and perform tasks. The project develops the technology for a crucial next step in recognition: active and action-centric image understanding by semantic understanding of actions, their preconditions and effects, and visual planning.  Doing so empowers several applications in healthcare, prospective memory failure care, visually impaired care, elderly care, robotics, entertainment, and education.<br/><br/>This research addresses the visual planning problem that entails knowing what actions are, how they change the world state, and which sequences of actions change the current state to a desired one. Successful active understanding of images requires addressing several fundamental and challenging problems at the intersection of computer vision and artificial intelligence. The research is focused on the development of a framework for active visual understanding, new scalable algorithms for joint detection of actions and their arguments, new datasets and representations for actions' preconditions and effects, new algorithms for predicting the consequences of actions with intuitive laws of physics, and visual semantic planning. The developed framework is designed for active and action-centric image understanding by large-scale, semantic action recognition, modeling actions' preconditions and effects, predicting consequences of actions, and visual planning. These resources not only enable new research directions in computer vision, robotics, and AI, but also bring together some of the independent efforts across these disciplines."
"1840878","RAPID: Collaborative Research: Machine Learning for Dehazing Unmanned Aerial System Imagery from Volcanic Eruptions","IIS","ROBUST INTELLIGENCE","08/01/2018","08/04/2018","David Merrick","FL","Florida State University","Standard Grant","David Miller","07/31/2019","$6,331.00","","dmerrick@fsu.edu","874 Traditions Way, 3rd Floor","TALLAHASSEE","FL","323064166","8506445260","CSE","7495","7495, 7914","$0.00","The ongoing eruption of the Kilauea volcano in Hawaii is the first reported time that small unmanned aerial systems (UAS) have been used for the emergency response to a volcanic eruption. The Center for Robot-Assisted Search and Rescue (CRASAR) flew 44 small UAS flights for the Hilo Fire Department and Hawaii County Civil Defense. The eruption imagery was partially occluded by plumes of steam carrying toxic gases, something that had not been encountered before. The plumes interfere with responders comprehending the tactical situation because it obscures the ground below and often prevents software from generating useful surface maps. While volcanic eruptions are fairly rare, the same plume problem is likely to occur in other hazardous material events. Machine learning techniques for dehazing were only partially successful because plumes present a very different set of challenges than removing urban haze or smog. This project conducts rapid research to remove or reduce plumes, from stills and video, in near real-time in order to support responses to the ongoing disaster. It will make the datasets available so that they can be used for training and evaluating new machine learning algorithms. The project will host a follow up workshop at the 2019 AAAI Conference on Artificial Intelligence in Hawaii.<br/><br/>This project creates a UAS open-source imagery dataset from the ongoing Leilani, Hawaii, volcanic eruption event. It uses the dataset to expand and refine dehazing algorithms that will help Hawaii public safety agencies and volcanologists see through the plumes of steam and gas that is interfering with mapping the extent and volume of the lava. Plumes of steam mingled with sulfur dioxide interfered with interpreting the boundaries of the lava field and introduced errors into stitching images together or caused details to be averaged out. Smog is a homogeneous, thin visual phenomenon while plumes are heterogeneous and thick, limiting the utility of current techniques and requiring focused research. The dataset offers an opportunity for a corpus of real imagery that can serve as machine learning training data and enable comparison of before and after results. The intellectual merit of the project is twofold. It provides a unique opportunity to explore a new area of machine learning for heterogeneous, thick plumes in images. The comprehensive dataset will enable foundational work in computer vision, machine learning, and emergency informatics.  The research will immediately improve emergency management of the Leilani eruption event and emergency management in general.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1840873","RAPID: Collaborative Research: Machine Learning for Dehazing Unmanned Aerial System Imagery from Volcanic Eruptions","IIS","ROBUST INTELLIGENCE","08/01/2018","08/04/2018","Robin Murphy","TX","Texas A&M Engineering Experiment Station","Standard Grant","David Miller","07/31/2019","$80,742.00","Zhangyang Wang","murphy@cse.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","CSE","7495","7495, 7914","$0.00","The ongoing eruption of the Kilauea volcano in Hawaii is the first reported time that small unmanned aerial systems (UAS) have been used for the emergency response to a volcanic eruption. The Center for Robot-Assisted Search and Rescue (CRASAR) flew 44 small UAS flights for the Hilo Fire Department and Hawaii County Civil Defense. The eruption imagery was partially occluded by plumes of steam carrying toxic gases, something that had not been encountered before. The plumes interfere with responders comprehending the tactical situation because it obscures the ground below and often prevents software from generating useful surface maps. While volcanic eruptions are fairly rare, the same plume problem is likely to occur in other hazardous material events. Machine learning techniques for dehazing were only partially successful because plumes present a very different set of challenges than removing urban haze or smog. This project conducts rapid research to remove or reduce plumes, from stills and video, in near real-time in order to support responses to the ongoing disaster. It will make the datasets available so that they can be used for training and evaluating new machine learning algorithms. The project will host a follow up workshop at the 2019 AAAI Conference on Artificial Intelligence in Hawaii.<br/><br/>This project creates a UAS open-source imagery dataset from the ongoing Leilani, Hawaii, volcanic eruption event. It uses the dataset to expand and refine dehazing algorithms that will help Hawaii public safety agencies and volcanologists see through the plumes of steam and gas that is interfering with mapping the extent and volume of the lava. Plumes of steam mingled with sulfur dioxide interfered with interpreting the boundaries of the lava field and introduced errors into stitching images together or caused details to be averaged out. Smog is a homogeneous, thin visual phenomenon while plumes are heterogeneous and thick, limiting the utility of current techniques and requiring focused research. The dataset offers an opportunity for a corpus of real imagery that can serve as machine learning training data and enable comparison of before and after results. The intellectual merit of the project is twofold. It provides a unique opportunity to explore a new area of machine learning for heterogeneous, thick plumes in images. The comprehensive dataset will enable foundational work in computer vision, machine learning, and emergency informatics.  The research will immediately improve emergency management of the Leilani eruption event and emergency management in general.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1814955","III: Small: Collaborative Research: Building Subjective Knowledge Bases by Modeling Viewpoints","IIS","INFO INTEGRATION & INFORMATICS","09/01/2018","08/03/2018","Brendan O'Connor","MA","University of Massachusetts Amherst","Standard Grant","Maria Zemankova","08/31/2021","$249,978.00","","brenocon@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","7364","7364, 7923","$0.00","This project will develop and empirically evaluate methods for creating subjective knowledge bases: databases of opinions and viewpoints as they are asserted by individuals in books, web forums, and social media. While most knowledge base research seeks to extract real-world truth from text, many factual assertions are either about inherently subjective propositions (such as ""apples are delicious"") or are non-subjective assertions that happen to contradict other belief holders or even consensus reality (such as ""the Earth is flat""). This project pioneers new methods to automatically extract expressions of opinions and viewpoints from a textual corpus and use those assertions to build a subjective knowledge base that can accommodate contradictory and conflicting statements from different authors. Such a subjective knowledge base will help researchers answer a range of questions: What contradictory claims are being made in historical books, or contemporary social media? What propositions does a particular ideological community hold, and are they compatible with, or contradictory to, those held by other communities? This project lays the foundation for understanding a broad range of phenomena that can be seen as conflicts between coherent viewpoints.  The resulting computational models will lay the groundwork for intelligent systems that are robust with respect to the way in which propositions are used in the real world; as applications in artificial intelligence are being deployed more and more in social contexts, this research will inform these methods with more nuanced information about the diversity of human viewpoints.  This work will also include a substantial educational component, incorporating human context into algorithm design in undergraduate STEM education and broadening the use of natural language processing and machine learning across a range of disciplines.<br/><br/>While previous work has focused on the primary task of identifying degrees of certainty (belief, viewpoints) in text, the primary contribution of this project will be modeling the structure of individual extracted viewpoints through the variables of the viewpoint holders and the viewpoint communities to which they belong. Models for building subjective knowledge bases accept subjective claims as fully semantic relational propositions, like recent research in open information extraction. However, instead of relying on the typical assumption of cross-document consensus, these models will embrace the simultaneous presence of contradictory claims across different author groups or even within the writings of the same individual. Major project components include: developing and refining broad-domain part-of-speech and syntactic parsing to be effective across both social media and historical books; using these tools to support author-centric latent-variable models of structured knowledge, which infers latent positions for both propositions and their viewpoint-holders; and improving the model with linguistic analysis of factuality and viewpoint (belief) commitment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813470","III: Small: Collaborative Research: Building Subjective Knowledge Bases by Modeling Viewpoints","IIS","INFO INTEGRATION & INFORMATICS","09/01/2018","08/03/2018","David Bamman","CA","University of California-Berkeley","Standard Grant","Maria Zemankova","08/31/2021","$250,000.00","","dbamman@berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","CSE","7364","7364, 7923","$0.00","This project will develop and empirically evaluate methods for creating subjective knowledge bases: databases of opinions and viewpoints as they are asserted by individuals in books, web forums, and social media. While most knowledge base research seeks to extract real-world truth from text, many factual assertions are either about inherently subjective propositions (such as ""apples are delicious"") or are non-subjective assertions that happen to contradict other belief holders or even consensus reality (such as ""the Earth is flat""). This project pioneers new methods to automatically extract expressions of opinions and viewpoints from a textual corpus and use those assertions to build a subjective knowledge base that can accommodate contradictory and conflicting statements from different authors. Such a subjective knowledge base will help researchers answer a range of questions: What contradictory claims are being made in historical books, or contemporary social media? What propositions does a particular ideological community hold, and are they compatible with, or contradictory to, those held by other communities? This project lays the foundation for understanding a broad range of phenomena that can be seen as conflicts between coherent viewpoints.  The resulting computational models will lay the groundwork for intelligent systems that are robust with respect to the way in which propositions are used in the real world; as applications in artificial intelligence are being deployed more and more in social contexts, this research will inform these methods with more nuanced information about the diversity of human viewpoints.  This work will also include a substantial educational component, incorporating human context into algorithm design in undergraduate STEM education and broadening the use of natural language processing and machine learning across a range of disciplines.<br/><br/>While previous work has focused on the primary task of identifying degrees of certainty (belief, viewpoints) in text, the primary contribution of this project will be modeling the structure of individual extracted viewpoints through the variables of the viewpoint holders and the viewpoint communities to which they belong. Models for building subjective knowledge bases accept subjective claims as fully semantic relational propositions, like recent research in open information extraction. However, instead of relying on the typical assumption of cross-document consensus, these models will embrace the simultaneous presence of contradictory claims across different author groups or even within the writings of the same individual. Major project components include: developing and refining broad-domain part-of-speech and syntactic parsing to be effective across both social media and historical books; using these tools to support author-centric latent-variable models of structured knowledge, which infers latent positions for both propositions and their viewpoint-holders; and improving the model with linguistic analysis of factuality and viewpoint (belief) commitment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822816","Collaborative Research: CSEdPad: Investigating and Scaffolding Students' Mental Models during Computer Programming Tasks to Improve Learning, Engagement, and Retention","IIS","S-STEM:SCHLR SCI TECH ENG&MATH, Core R&D Programs, Cyberlearn & Future Learn Tech","09/01/2018","07/31/2018","Vasile Rus","TN","University of Memphis","Standard Grant","Kurt Thoroughman","08/31/2021","$499,136.00","Scott Fleming","vrus@memphis.edu","Administration 315","Memphis","TN","381523370","9016783251","CSE","005y, 1536, 7980, 8020","063Z, 8045","$0.00","Computing skills, such as computer programming, are an integral part of many disciplines, including the fields of science, technology, engineering, and math (STEM). Although such skills are in high-demand, and the number of aspiring Computer Science (CS) students is encouraging, a large gap between the supply of CS graduates and the demand persists because, for instance, college CS programs suffer from high attrition rates in introductory CS courses. One reason for the high attrition rates in introductory CS courses is the inherent complexity of CS concepts and tasks. To help students better cope with the high level of complexity, this project investigates a novel education technology, called CSEdPad (CS Education Pad), meant to ease students' introduction to programming during their early encounters with CS concepts and tasks. Moreover, the project forges new frontiers in CS education through a research program that advances our understanding of students' source code comprehension, learning, and motivational processes. The CSEdPad project has the potential to transform how students perceive computer science, increase their programming skills and self-efficacy, and lead to increased retention rates. The result will be a win-win-win situation for aspiring students, CS programs and their organizations, and the overall economy.<br/><br/>The CSEdPad system design brings to bear proven educational technologies and techniques to improve students' mental model construction, learning, engagement, and retention in CS education. In particular, the system targets source code comprehension, a critical skill for both learners and professionals. It monitors and scaffolds source code comprehension processes while students engage in a variety of code comprehension tasks. Key approaches being explored include Animated Pedagogical Agents, self-explanation, and the Open Social Learner Model. Outcome variables include comprehension measures, learning gains, engagement level, retention, and self-efficacy. Due to its interdisciplinary nature, the project will impact several fields including Computer Science education, cognitive psychology, intelligent tutoring systems, and artificial intelligence. Students participating in the experiments will be selected from a diverse student body with respect to gender, ethnicity, and socioeconomic status. An increase in recruitment and retention of students from these populations will have far-reaching implications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1527434","RI: Small: New Directions in Computational Social Choice and Mechanism Design","IIS","ROBUST INTELLIGENCE","09/01/2015","08/03/2015","Vincent Conitzer","NC","Duke University","Standard Grant","James Donlon","08/31/2019","$499,972.00","","conitzer@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7495","7495, 7923","$0.00","We often need to make collective decisions: who will represent us as president, where will we all go out for dinner tonight, who will receive the award, and so on. Similar problems are faced in multiagent systems in artificial intelligence. What are the best procedures for reaching such decisions? The agents could vote over the outcome, but what should the exact procedure be? This is studied in the theories of social choice and mechanism design, with the latter focusing particularly on agents that act strategically in their own self-interest. However, an ever-increasing amount of activity is moving online, and collective decision making is no exception. For example, we rate or vote on content, products, and people online. Key aspects of these novel applications are not present in the traditional models of social choice and mechanism design. For example, in an Internet-based mechanism, who gets to and who will participate? How can we know that a single agent is not participating multiple times? How can we allow agents to meaningfully participate when the number of voting events is potentially overwhelming? The proposed research aims to extend the traditional models to incorporate these aspects and to develop new algorithmic and other techniques to ensure outcomes are meaningful and increase economic efficiency and human welfare.<br/><br/>In many domains, multiple self-interested agents need to make a collective decision. The theory of social choice concerns how such collective decisions should be made. Closely related, the theory of mechanism design concerns how to design mechanisms for such problems that result in good outcomes even when agents behave strategically. In recent years, major progress has been made on understanding the computational aspects of both social choice and mechanism design. In the proposed research, the PI and his team set out to adapt these techniques to novel domains such as those enabled by the Internet or the availability of new data. For example, one key issue is the identity of the participating agents. In an Internet-based mechanism, who gets to and who will participate? How can we know that a single agent is not participating multiple times? The PI and his team aim to address such issues with techniques based on social network structure, as well as on the effort that agents expend participating. Another key issue is the possibility of agents strategically providing inaccurate data. Again, explicit modeling of the agents' effort costs in doing so will play a key role."
"1815598","RI:Small:Tractable Decision-Theoretic Planning Driven by Data","IIS","ROBUST INTELLIGENCE","07/01/2018","06/25/2018","Prashant Doshi","GA","University of Georgia Research Foundation Inc","Standard Grant","James Donlon","06/30/2021","$466,514.00","","pdoshi@cs.uga.edu","310 East Campus Rd","ATHENS","GA","306021589","7065425939","CSE","7495","7495, 7923","$0.00","Automated planning is about finding a sequence of actions that is expected to successfully complete the task at hand. Decision-theoretic planning approaches automated planning as a sequence of decisions, each of which optimizes the planner's combined immediate and longer-term preferences. This approach to automated planning allows for realistic actions whose outcomes are often uncertain and reasons with the planner's possibly inexact preferences in addition to precise goals. However, decision-theoretic planning relies on an accurate specification of the planning problem, which is often impractical and is computationally very costly. This research is addressing these challenges by investigating a new and meaningful planning problem representation that is learned directly from data, which alleviates the need for tedious specifications. The representation is designed to yield more efficient computation of solutions. Consequently, this research has the potential to transition automated planning to large pragmatic applications, such as in flow routing in high-density computer networks, which will be demonstrated in this project. The project will train graduate students for entering the workforce in an important area of artificial intelligence, and it will facilitate an international research collaboration between researchers in US and Canada. The PI will use the outcomes of this research to inform his classroom instruction, which will provide students with exposure to how automated planning can be useful to the society.      <br/><br/>The technical approach is merging two threads of previous progress toward developing a new graphical model called the dynamic sum-product-max network. In these previous threads, the PI generalized sum-product networks, which allow efficient probabilistic inference, in two directions. First, along the temporal dimension thereby allowing inference over a sequence of variables, and second, enabling efficient non-sequential decision making by including decision and utility variables. This research is reconciling the fundamental hardness of decision-theoretic planning with the efficiency of dynamic sum-product-max networks by studying which class of planning problems can be compactly represented by the new model. As these models can be directly learned from data, the research is also establishing the appropriate schema for the data and creating an evaluation testbed of datasets. A final thrust is developing a portfolio of methods for automatically learning both the structure and parameters of dynamic sum-product-max networks from appropriate data, with a focus on learning valid models. The research plan is expected to yield a new graphical representation and associated methods that allow efficient data-driven planning whose utility will be demonstrated by real-world applications in collaboration with industry.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1741472","BIGDATA: F: Audio-Visual Scene Understanding","IIS","Big Data Science &Engineering","09/01/2017","08/24/2017","Chenliang Xu","NY","University of Rochester","Standard Grant","Maria Zemankova","08/31/2021","$650,000.00","Zhiyao Duan","chenliang.xu@rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","CSE","8083","7433, 8083","$0.00","Understanding scenes around us, i.e., recognizing objects, human actions and events, and inferring their spatial, temporal, correlative and causal relations, is a fundamental capability in human intelligence. Similarly, designing computer algorithms that can understand scenes is a fundamental problem in artificial intelligence. Humans consciously or unconsciously use all five senses (vision, audition, taste, smell, and touch) to understand a scene, as different senses provide complimentary information. For example, watching a movie with the sound muted makes it very difficult to understand the movie; walking on a street with eyes closed without other guidance can be dangerous. Existing machine scene understanding algorithms, however, are designed to rely on just a single modality. Take the two most commonly used senses, vision and audition, as an example, there are scene understanding algorithms designed to deal with each single modality. However, no systematic investigations have been conducted to integrate these two modalities towards more comprehensive audio-visual scene understanding. Designing algorithms that jointly model audio and visual modalities towards a complete audio-visual scene understanding is important, not only because this is how humans understand scenes, but also because it will enable novel applications in many fields. These fields include multimedia (video indexing and scene editing), healthcare (assistive devices for visually and aurally impaired people), surveillance security (comprehensive monitoring of the suspicious activities), and virtual and augmented reality (generation and alternation of visuals and/or sound tracks). In addition, the investigators will involve graduate and undergraduate students in the research activities, integrate research results into the teaching curriculum, and conduct outreach activities to local schools and communities with an aim to broader participation in computer science. <br/><br/>This project aims to achieve human-like audio-visual scene understanding that overcomes the limitations of single-modality approaches through big data analysis of Internet videos. The core idea is to learn to parse a scene into elements and infer their relations, i.e., forming an audio-visual scene graph. Specifically, an element of the audio-visual scene can be a joint audio-visual component of an event when the event shows correlated audio and visual features. It can also be an audio component or a visual component if the event only appears in one modality. The relations between the elements include spatial and temporal relations at a lower level, as well as correlative and causal relations at a higher level. Through this scene graph, information across the two modalities can be extracted, exchanged and interpreted. The investigators propose three main research thrusts: (1) Learning joint audio-visual representations of scene elements; (2) Learning a scene graph to organize scene elements; and (3) Cross-modality scene completion. Each of the three research thrusts explores a dimension in the space of audio-visual scene understanding, yet they are also inter-connected. For example, the audio-visual scene elements are nodes in the scene graph, and the scene graph, in turn, guides the learning of relations among scene elements with structured information; the cross-modality scene completion generates missing data in the scene graph and is necessary for good audio-visual understanding of the scene. Expected outcomes of this proposal include: a software package for learning joint audio-visual representations of various scene elements; a web-deployed system for audio-visual scene understanding utilizing the learned scene elements and scene graphs, illustrated with text generation; a software package for cross-modality scene completion based on scene understanding; and a large-scale video dataset with annotations for audio-visual association, text generation and scene completion. Datasets, software and demos will be hosted on the project website."
"1743637","Symposium on Combinatorial Search - 2017","IIS","ROBUST INTELLIGENCE","05/15/2017","06/05/2017","Nathan Sturtevant","CO","University of Denver","Standard Grant","James Donlon","04/30/2019","$10,000.00","","sturtevant@cs.du.edu","2199 S. University Blvd.","Denver","CO","802104711","3038712000","CSE","7495","7495, 7556","$0.00","This grant supports student travel for select students and post-doctoral researchers to participate in the Symposium on Combinatorial Search (SoCS-2017) June 16-17 in Pittsburgh, PA.  SoCS is an annual event that brings together researchers in heuristic search and combinatorial optimization drawing from diverse areas of artificial intelligence, planning, robotics, constraint programming, operations research, bioinformatics, and computer games. This consortium is oriented on research and career development for students who have identified their PhD topics and are just embarking on that independent research.  <br/><br/>Sponsoring student travel to SoCS fosters a community of researchers from otherwise diverse areas of computer science to both advance the state of the art in heuristic search and/or combinatorial optimization, and also use these tools in their research.  Students participating in this symposium are also more likely to take full advantage of the top-tier conference in the International Conference on Automated Planning and Scheduling (ICAPS) 2017 taking place immediately prior to this symposium, and co-located with it.  The entire event provides an opportunity for students to engage in discussion with scientists from around the world and to explore new research directions and topics."
"1716333","RI: Small: Algorithmic Mechanism Design for Multi-Type Resource Allocation","IIS","ROBUST INTELLIGENCE","08/15/2017","07/27/2017","Lirong Xia","NY","Rensselaer Polytechnic Institute","Standard Grant","James Donlon","07/31/2020","$373,536.00","","xial@cs.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","7495","7495, 7923","$0.00","Allocating indivisible items to multiple agents without monetary transfer is a pressing problem in our society. In many situations, items are categorized into multiple types and each agent must get at least one item per type. Such problems are called multi-type resource allocation (MTRA). For example, MTRA arises in allocating courses to students, allocating computational resources to users in cloud computing, allocating medical resources to patients, as well as in multi-type exchange market and centralized welfare programs that involve multiple sub-programs. Unfortunately, most previous research overlook information regarding resource type, and are thus hindered by three barriers: preference bottleneck, computational bottleneck, and threats of agents' strategic behavior. The project aims at establishing theoretical and algorithmic foundations of mechanism design for MTRA with the help of Artificial Intelligence. The newly designed mechanisms will improve the economic efficiency and computational efficiency of resource allocation in multiagent systems, socio-economics systems, and operations research.<br/><br/>In doing so, the researcher will design and evaluate novel graphical languages to address the preference bottleneck; design novel frameworks for discovering new mechanisms, including sequential allocation mechanisms and extensions of the top-trading-cycles mechanism, to address the computational bottleneck; use game theory to analyze and measure agents' strategic behavior; and use high computational complexity to prevent agents' strategic behavior. Outcomes of the research will be integrated into an open-source Online Preference Reporting and Aggregation (OPRA) system, which serves as a platform to bridge theory, practice, and education."
"1736065","EXP: Collaborative Research: Empowering Learners to Conduct Experiments","IIS","IUSE","09/01/2017","08/23/2017","Camillia Matuk","NY","New York University","Standard Grant","William Bainbridge","08/31/2019","$112,000.00","","cmatuk@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","1998","8045, 8209, 8841, 9178","$0.00","This project seeks to transform current practices in the teaching of scientific research methods by shifting the fundamental dynamics and focusing in a scientific domain that is relatable to a broad audience: designing and conducting social and behavioral science experiments. Scientific inquiry is key to making societal progress and improving our understanding of the world. Social and behavioral science programs are largely designed to prepare future researchers, but have a minimum expectation that students become critical consumers of research. Understanding the scientific method and the experimental methods used by researchers is necessary for establishing an ability to effectively assess the research that students will encounter in both the media and scientific outlets. Student understanding of scientific inquiry is significantly enhanced when anchored in inquiry experiences; however, opportunities for scientific research experiences are limited, even in research methods courses, due to the challenges of teaching experimental design and problems regarding access to and recruitment of participants. Without these experiences, students in higher education struggle to fully understand scientific inquiry. To address common barriers to learning how to conduct research, this project is designing a flexible, computer-based platform to be collaborative, narrative-based, engaging, and inspired by constructionist theories to facilitate learning with the use of artificial intelligence (AI) support.<br/> <br/>The platform developed in this project will serve as a model of a new genre of constructionist research environments, that enable learners to leverage technologies to create, modify, and replicate experiments, recruit participants, and analyze their results to learn about the world. The design-based research approach will operate in two cycles; in each cycle, a revised module and set of tools will be deployed. This results in two major research contributions: (1) Using mixed-methods, the theoretical and educational contribution is to study the process by which students in higher education learn to conduct experimental research, and about the roles of AI assistance, collaboration, narrative, and activities motivated by curiosity, exploration, and reflection. (2) The technological contribution is an innovative, AI-assisted set of scenario creation tools that empower learners to create experiments and that allow us to understand how an intelligent, collaborative, engaging, narrative-based platform can support students in higher education in designing and conducting social and behavioral science experiments.  With this system, it will be easier to create, run, replicate, and build upon studies and to reach out to a broader audience than the pool of university students used in typical in-person laboratory experiments. As a result, the platform will make it possible to transform social science research practices and even has the potential to foster new scientific discoveries."
"1763642","RI: Medium: Recognizing, Mitigating and Governing Bias in AI","IIS","ROBUST INTELLIGENCE","09/01/2018","05/31/2018","Arvind Narayanan","NJ","Princeton University","Standard Grant","James Donlon","08/31/2022","$800,000.00","Olga Russakovsky","arvindn@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","CSE","7495","7367, 7495, 7924","$0.00","Artificial Intelligence (AI) technologies mediate our interactions with the world and our daily decision making, ranging from shopping to hiring to surveillance. The development of rich AI algorithms able to process and learn from unparalleled amounts of data holds promise for making impartial, well-informed decisions. However, such systems also absorb human biases, such as gender stereotyping of activities and occupations. Left unchecked, they will perpetuate these biases on an unparalleled scale. A steady stream of press confirms that this is a widespread problem in real-world applications. This research brings together an interdisciplinary team to develop the science of AI bias. The findings will impact AI researchers and developers (through novel methodologies), computational social scientists (through a deeper study of human biases at web scale), educators and policy makers (through the comprehensive analysis of bias), and downstream users of AI technology. <br/><br/>Compared to applications such as criminal risk scoring where fairness has traditionally been studied, modern AI systems are characterized by massive datasets, complex deep models and an unprecedented breadth of applications. This results in a wider spectrum of biases with complex propagation pathways, requiring an in-depth scientific investigation. The project develops the tools and techniques for recognizing, mitigating and governing bias in AI by combining expertise in deep learning, crowdsourcing and dataset curation, AI ethics, analyzing inference risk, web measurement, and science and technology studies. The component on recognizing bias includes an application of the Implicit Association Test combined with zero-shot learning to understand the societal bias of web corpora. Mitigating bias includes bridging active learning with research on adversarial examples for AI models. Governing bias includes a qualitative and quantitative study of downstream bias effects. The research is designed to be tightly connected, as for example when the recognition of curation bias in datasets leads to techniques in mitigating bias through enforcing group fairness in deep learning to governing bias in deployed system through developing bias observatories. The study will include advancements in machine learning (decomposing deep architectures, adapting reinforcement learning, exploring domain adaptation), human-computer interaction (developing novel active learning techniques, studying model interpretability), and digital ethnography (studying the effect of AI bias on culture, establishing an AI bias taxonomy). It will serve as a bridge between these fields, establishing tighter connections between them.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813709","RI: Small: Learning Dynamics and Evolution towards Cognitive Understanding of Videos","IIS","ROBUST INTELLIGENCE","09/01/2018","08/11/2018","Chenliang Xu","NY","University of Rochester","Standard Grant","Jie Yang","08/31/2021","$449,990.00","Jiebo Luo","chenliang.xu@rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","CSE","7495","075Z, 7495, 7923","$0.00","A fundamental capability of human intelligence is being able to learn to act by watching instructional videos. Such capability is reflected in abstraction and summarization of the instructional procedures as well as in answering questions such as ""why"" and ""how"" something happened in the video. This project aims to build computational models that are able to perform well in above tasks, which require, beyond the conventional recognition of objects, actions and attributes in the scene, the higher-order inference of any relations therein. Here, the higher-order inference refers to inference that cannot be answered immediately by direct observations and thus requires stronger semantics. The developed technology will enable many applications in other fields, e.g., multimedia (video indexing and retrieval), robotics (reasoning capability of why and how questions), and healthcare (assistive devices for visually impaired people). In addition, the project will contribute to education and diversity by involving underrepresented groups in research activities, integrating research results into teaching curriculum, and conducting outreach activities to local K-12 communities. <br/><br/>The research will develop a framework to perform higher-order inference in understanding web instructional videos, such that models devised in this framework are capable of not only discovering and captioning procedures that constitute the instructional event but also answering questions such as why and how something happened. The framework is built on a video story graph that models the dynamics (the composition of actions at different scales) and evolution (the change in object states and attributes), and it supports higher-order inference upon deep learning units and incorporation of external knowledge graph in a unified framework. Methodologies to extract such video story graphs and use them to discover, caption procedures and perform question-answering will be explored. Expected outcomes of this project include: a software package for constructing and performing inference on video story graphs and incorporating external knowledge; a web-deployed system to process user-uploaded instructional videos; and a large video dataset with procedure and question-answering annotations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815701","III: Small: Automatic Learning-based Services for Distributed Data Management Systems","IIS","INFO INTEGRATION & INFORMATICS","08/15/2018","08/03/2018","Olga Papaemmanouil","MA","Brandeis University","Standard Grant","James French","07/31/2021","$499,913.00","","olga.papaemmanouil@gmail.com","415 SOUTH ST MAILSTOP 116","WALTHAM","MA","024532728","7817362121","CSE","7364","075Z, 7364, 7923","$0.00","The distributed nature of most database management systems (DBMSs) brings about new challenges to the daily tasks of database administrators. Apart from database tuning, today's administrators are often responsible for: (a) adapting data partitioning and replication schemes; (b) managing dynamic workloads to meet query prioritization and performance goals; as well as (c) provisioning computing resources on demand. Unfortunately, the complexity of these tasks often exceeds engineers' abilities to scientifically model them. To address this challenge, this project will couple existing learning-driven theory with distributed data management systems to have significant impact on the design of DBMSs. By leveraging advanced learning algorithms from machine learning and game theory, the project will allow DBMSs to move away from ""hard-coded algorithmic intelligence,"" rigid data structures, and algorithms that are based on informal intuition. Instead, DBMSs will be able to incorporate ""learning-based intelligence"" that provides reasoning on numerous decisions based on pattern recognition capabilities and mathematically proven insights. Leveraging information to learn and adapt could unleash tremendous potential as databases evolve to systems capable of automatically tuning themselves. The results of this project will also reduce the human effort of database administrators as they will be offered predictive models, decision tools and insight to the interplay between data distribution, workload management, and query performance. <br/><br/>The project will provide solutions to some of the key technical challenges that arise when tuning the performance of dynamic workloads on distributed data management systems. This research will lead to the design of new algorithms and learning-based frameworks for supporting data distribution, replication, query dispatching, query scheduling, and performance prediction without human intervention. These techniques will be automatically customized to application-level performance goals and user-defined query priorities and will allow distributed DBMSs to naturally handle dynamic workloads, changing data access patterns, and varying resource availability. By coupling unsupervised/supervised learning, deep learning and game theory to data management tasks the project will transform data management systems to ""database science"" tools through which system administrators will be able to explore and derive insight on the factors that affect the performance of a database and its deployed applications. As a result, the project will deliver complex predictive and correlation models between query, data, resource-related features and system performance.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816012","CHS: Small: Deep Integration of Crowds and AI for Robust, Scalable, and Privacy-Preserving Conversational Assistance","IIS","Cyber-Human Systems (CHS)","08/15/2018","08/02/2018","Jeffrey Bigham","PA","Carnegie-Mellon University","Standard Grant","William Bainbridge","07/31/2021","$500,000.00","","jbigham@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7367","075Z, 7367, 7923","$0.00","This research will use the recently deployed crowd-powered conversational assistant, Chorus, as a scaffold to develop technical components that allow it to automate itself over time. Chorus introduces a hybrid intelligence model in which humans and machines collaboratively power a single intelligent system. This is unlike both fully-automated approaches which are limited in terms of the domains they cover, and individual human-based conversational support which does not scale.  Conversation is interactive communication. When people converse with one another, they build and refine a shared context that makes finding and making sense of information efficient and more effective. Computers capable of engaging users in natural conversations about arbitrary topics would revolutionize how, when, and where people have access to information. Despite many successes, computers are still far from being able to converse naturally across general domains. Systems resulting from this research will be robust enough and scalable enough to be used in real world domains. These types of hybrid systems may lead to new, generally applicable models that are useful in real-time human computation and natural language understanding. This work will inform a better understanding of how automated agents can learn from crowd-powered systems in order to gradually assume more responsibility over time.<br/><br/>Creating a robust, general-purpose dialog system from the bottom up is difficult because it requires solving multiple hard problems at once. This project employs a complementary top-down approach that will (1) use the growing Chorus data set to train automatic responders, (2) facilitate integration of existing task-specific dialog systems, (3) develop learning systems to sample among integrated dialog systems and choose the best to respond, (4) develop learning systems to choose the best responses from among automated and human suggestions, (5) develop learning systems able to recommend relevant elements from the user's history based on context, (6) develop crowd-powered systems for allowing users to safely control their devices, and (7) develop crowd-powered systems that allow users to safely access private repositories such as their email. Integral to this work is the interplay between computers and people.  Central goals are to better understand how computers and people can complement the work of one another; learn how people can teach computers to be better in the difficult domain of robust dialog, and develop novel approaches for applying human computation when the crowd is handling confidential information or has control of a physical device such as a user's mobile phone. Lessons learned from exploring the top-down approach of introducing a crowd-powered conversational agent that is gradually replaced by automation may apply generally to other hard problems. This approach may allow research topics to be explored before successful computational approaches have been developed for foundational problems, such as learning how to properly curate persistent memory before having the ability to create reliable conversational assistants.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813490","RI: Small: Adaptive Metareasoning for Bounded Rational Agents","IIS","ROBUST INTELLIGENCE","08/01/2018","07/23/2018","Shlomo Zilberstein","MA","University of Massachusetts Amherst","Standard Grant","James Donlon","07/31/2021","$404,722.00","","shlomo@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","7495","075Z, 7495, 7923","$0.00","Metareasoning is the process by which an intelligent agent monitors and controls its own thought processes so as to produce effective action in a timely manner.  Just as people must decide when to stop thinking and take action, AI systems also need to be able to interrupt their decision-making process and commit to an action or plan.  While people often use heuristic methods to determine the interruption time, this project offers metareasoning techniques that optimize the value of computation and stop planning when the urgency to take action outweighs the anticipated benefit of continued computation.  The project transforms the ability of researchers and practitioners to create responsive planning systems by offering easy-to-use, off-the-shelf adaptive metareasoning techniques to control them.  Additional areas of broader impact include mentoring of student researchers with special attention to underrepresented groups, a range of outreach activities to local schools, targeted activities to increase diversity in computer science, and industrial collaborations.<br/><br/>The approach uses planning algorithms that can be interrupted at any time, offering a tradeoff between runtime and quality of results.  To take advantage of this tradeoff, novel metareasoning techniques are developed that overcome the drawbacks of existing methods.  The key idea is to replace the reliance on extensive offline experiments by creating new ways to predict performance and adapt the prediction quickly to the specific problem instance at hand.  The project answers fundamental questions about the feasibility, efficiency, and scalability of optimizing meta-level control with minimal computational overhead.  The main contributions are: (1) online performance prediction methods for efficient meta-level control of anytime algorithms that outperform state-of-the-art methods; (2) a novel approach to create and adapt meta-level control policies online using reinforcement learning techniques; (3) extensions of the above methods to control a portfolio of anytime algorithms, allowing transitions from one algorithm to another using shared intermediate solution representations; and (4) extensions of the above methods to control the internal operation of adjustable anytime algorithms.  The team evaluates the new metareasoning techniques on complex computational tasks using a range of anytime algorithms based on different programming paradigms and demonstrates ease of use and significant performance gains relative to existing metareasoning techniques.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1749833","CAREER:Towards Perceptual Agents That See and Reason Like Humans","IIS","ROBUST INTELLIGENCE","06/01/2018","06/01/2018","Subhransu Maji","MA","University of Massachusetts Amherst","Standard Grant","Jie Yang","05/31/2023","$545,586.00","","smaji@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","7495","075Z, 1045, 7495","$0.00","Recent advancements in computer vision systems have enabled their widespread deployment in areas like social media, healthcare, robotics, and ecology, among many others. While such applications hold exceptional promise for improving our well-being and advancing scientific discovery, the ubiquity of these intelligent systems presents new technical, social, and cultural challenges for their wide-scale adoption. This project leads an integrated effort of research, teaching, and outreach to address some of these challenges. The project develops architectures that are substantially more accurate and capable of extracting detailed information from perceptual data across different modalities. An emphasis of this work is to develop computer vision systems that can reason about data in ways that are interpretable by humans. This project also promotes diversity, engages high school, undergraduate, and graduate students in research activities, and fosters collaborations with industry and researchers in areas such as ecology and biology through workshops.<br/><br/>This research explores new directions that improve the capabilities of visual perception and reasoning systems for analyzing image data, spatio-temporal data, and depth data. The research develops a novel class of graph-based and factorized architectures for 3D shape and spatio-temporal analysis that provide better tradeoffs between computational cost, memory overhead, and accuracy than existing models. The research develops weakly supervised techniques for learning shape and motion representations from large amounts of unlabeled data. The research also develops a novel class of techniques for transforming visual data to semantic representations such as attributes, natural language, and symbolic programs. These techniques will improve the interpretability of machine learning models and enable collaborative learning and inference between humans and AI agents.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1824119","I-Corps:  Machine Learning Approach for Microbial Process Control and Management","IIP","I-Corps","04/01/2018","03/07/2018","Hong Liu","OR","Oregon State University","Standard Grant","Cindy WalkerPeach","03/31/2019","$50,000.00","","liuh@engr.orst.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project will directly affect the treatment and management of the over 80 km3 of wastewater and solid wastes produced each year in the US. Waste treatment processes are directly tied to environmental and human health in both developed and developing countries but are subject to high costs due to significant energy and maintenance requirements. Municipal wastewater treatment alone accounts for about 3% of electrical energy consumed in the U.S and other developed countries. The successful implementation of the proposed technology, which integrates artificial intelligence (AI) into existing waste treatment infrastructure, has the potential to greatly improve the management of microbial communities associated with treatment processes thereby improving overall effectiveness and sustainability. This solution represents a new way for customers to cut energy and operational costs and improve effectiveness of their treatment processes without large investments in infrastructure. Potential markets for this technology include public, municipal facilities in addition to treatment facilities in the industrial/agricultural sector.  Development of the proposed technology will likely spur additional applications of AI systems in other fields centered around microbial community based engineered systems like bioproduct production, biosensing, and bioremediation.<br/><br/>This I-Corps project is based on our recent development of a machine learning based approach used to accurately predict microbial community structure, process stability, and reactor performance for wastewater treatment. This novel approach, which incorporates genomic data along with environmental and operational parameters into data-mining datasets has demonstrated significant increases in accurately predicting process stability and performance of small-scale wastewater systems compared to models developed without consideration of microbial community dynamics. The predictive models developed through the construction of artificial neural networks have potential to inform engineering decisions for optimized performance and stability of environmental biotechnologies in full-scale systems. Development and implementation of this approach will not only progress the understanding and control of microbial communities that inhabit environmental biotechnologies but may be expanded to other microbiomes such as those associated with human health and biogeochemical cycles.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1457304","Collaborative Research: Navigation and the Neural Integration of Multimodal Sensory Information in the Brain of an Arthropod","IOS","ANIMAL BEHAVIOR","08/01/2015","07/24/2015","Verner Bingman","OH","Bowling Green State University","Standard Grant","Michelle M. Elekonich","07/31/2019","$270,000.00","Daniel Wiegmann","vbingma@bgnet.bgsu.edu","302 Hayes Hall","Bowling Green","OH","434030230","4193722481","BIO","7659","7659, 9178, 9179, 9251, SMET","$0.00","The ability of many animals to navigate through their environment far exceeds what humans are able to do without the help of technology. Exceptional navigation is not limited to animals with large brains, like birds and mammals. It can also be found in animals with simpler nervous systems. The tropical amblypygid, a scorpion-like animal, is able to find its way home at night through dense, tropical forest understory.  The study of how different types of sensory information (visual, chemical, tactile) are processed by amblypygids as they solve navigation problems can reveal fundamental design properties of simple nervous systems that are somehow capable of controlling complex, learned behavior. These design properties can inspire engineering solutions applicable to robotic and artificial intelligence systems. The study of charismatic tropical amblypygids also serves as an alluring gateway for teachers to introduce K-12 students to the importance of neuroscience for understanding how organisms acquire and process information from their environment and how this information influences learning and memory. To support engagement with K-12 students, their teachers and the general public, researchers supported by this grant will develop internet-based educational materials in both English and Spanish. <br/><br/>By conducting behavioral experiments that assess amblypygid (Phrynus pseudoparvulus) movements after displacement from a home refuge, researchers will assess the relative importance of visual, chemical and mechanical information in supporting navigation. These experiments will either involve manipulation of animal sense organs or the sensory cues in their environment. The neurobiological work will focus on a brain area known as ""mushroom bodies"", which are thought to support spatial memory. In parallel with the behavioral work, researchers will explore the nervous system routes by which information from different sensory stimuli is sent to the mushroom bodies. Particular attention will be given to how the mushroom bodies ""engineer"" or ""integrate"" the different sensory inputs.  The integration of sensory inputs is hypothesized to be necessary to support complex navigation and will likely have applied potential for design of sophisticated artificial systems. Finally, the importance of the mushroom bodies in navigation, and their capacity to combine different sources of sensory information, will be tested under the same conditions of the behavioral experiments noted above, except using animals whose mushroom bodies are impaired."
"1843025","EAGER: Type II: Deep Learning and Combinatorial Algorithms for Inorganic Crystal Structure Prediction","DMR","DMR SHORT TERM SUPPORT, CONDENSED MATTER & MAT THEORY","01/01/2019","08/22/2018","Sanguthevar Rajasekaran","CT","University of Connecticut","Standard Grant","Daryl W. Hess","12/31/2020","$299,999.00","","rajasek@engr.uconn.edu","438 Whitney Road Ext.","Storrs","CT","062691133","8604863622","MPS","1712, 1765","054Z, 062Z, 7916, 7926, 9216","$0.00","NONTECHNICAL SUMMARY<br/>This EAGER award supports research and education involving a new collaboration kindled at the MATDAT18 Datathon event focused on developing artificial intelligence methods to discover new materials or identify specific materials with desired properties for an application.  Methods involving computation, materials data, and the tools of data science offer the potential to find or design a material with desired properties much faster and at lower cost than traditional methods used by materials scientists and engineers. <br/><br/>In this project, the research team will develop novel machine learning techniques to mine knowledge from various publicly available databases on materials and their properties. The knowledge thus gained can be utilized for material selection and design.  The team will focus first on using the methods of data science and materials data from a large community repository obtained from using computers and theory to calculate the energy needed to form a material from its constitutive elements.  <br/><br/>All the techniques developed in this project will be coded as software for different computers. Software will be released as open source codes to the materials science and data science communities via a number of mechanisms including the GitHub. This project will also provide educational opportunities to graduate and undergraduate students and a first-hand research experience in data analysis for materials science. Results of this project will be incorporated in appropriate undergraduate and graduate courses. Strong efforts will be made to include minorities and women. Results of this project will be disseminated widely via publications in journals and international conferences.<br/><br/>TECHNICAL SUMMARY<br/>This EAGER award supports research and education involving a new collaboration kindled at the MATDAT18 Datathon event focused on developing deep learning predictors for formation energies and other materials properties. Large databases of computed material properties, such as The Materials Project and AFLOWLIB developed under Materials Genome Initiative, host properties of tens of thousands of materials. They are primarily employed to screen materials for various target applications such as photocatalysis and battery materials. Such databases can also be utilized to develop deep learning-based predictors of materials properties. These predictions are expected to be more accurate than predictions made using traditional machine learning (ML) techniques. <br/><br/>Even cutting edge conventional ML methods such as Gradient Boosting or Random Forest of Trees have limited capacity, or the ability to learn, when compared to multi-layer deep artificial neural networks employed in deep learning to mine vast data. In this project the research team aims to develop a deep learning predictor for formation energy of crystals. The investigators also propose to develop other relevant combinatorial algorithms for solving this problem. Formation energy, which is the energy difference between the crystal and the constituent elements in their atomic form, is one of the most reliable properties available from these databases. The focus of this project is on fast and highly accurate prediction of formation energies and stability of materials by utilizing the superior capacity of deep learning systems and other algorithms to learn from big data.<br/><br/>The project will deliver a publicly accessible cyber infrastructure implementing a deep learning system capable of predicting formation energies for inorganic materials with an accuracy that is vastly superior to that of the predictors built with traditional ML models, and new forms of chemical representations of materials that can be reused to predict other properties of materials. One of the challenges in the employment of deep learning techniques is in the large training times taken by these algorithms. The research team plans to address this challenge with a variety of algorithmic innovations including novel parallel training algorithms. The investigators plan to employ a number of parallel architectures including CPU clusters and GPUs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1824198","Research Coordination Network: Cognitive Functions in the Learning of Symbolic Signals & Systems","BCS","Science of Learning, M3X - Mind, Machine, and Motor","09/01/2018","08/15/2018","Cornelia Fermuller","MD","University of Maryland College Park","Standard Grant","Kurt Thoroughman","08/31/2021","$500,000.00","Shihab Shamma, Ralph Etienne-Cummings","fer@cfar.umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","SBE","004Y, 058Y","059Z, 070E","$0.00","The objective of this Research Coordination Network (RCN) is to advance understanding of how biological systems learn complex symbolic signals, and create artificial systems with similar capabilities. By defining a common framework to describe these signals, and their variability across space and time, the RCN will develop methods and tools applicable to a wide range of domains, including language, music, action, perception, and navigation. The RCN will build upon research in Neuromorphic Engineering and its development of bio-inspired, low-power computing platforms, sensors, and signal processing. Using these tools, the RCN will focus on high-level cognitive functions, to create complex, bio-inspired systems that learn through engagement in tasks. The network will bring together neuroscience, cognitive science, applied mathematics, computer science, and engineering, with emphasis on machine learning and artificial intelligence. Network members will participate in a yearly three-week, hands-on workshop, that will develop and test new tools and ideas, stimulate new collaborations, and educate students on unique interdisciplinary skills. <br/><br/>The RCN will facilitate interactions and collaborative projects among participating researchers employing a wide range of paradigms that specifically deal with three thrusts: the role of neural plasticity for learning symbolic systems; the adaptive mechanisms underlying the learning of sensory-motor tasks; and transitioning to real-world applications such as automatic speech and dynamic scene understanding, neuromorphic hardware implementations, cognitive computational algorithms, and databases acquisition. Specific examples of such diverse projects include brain process models that assess learning and expertise; algorithms, based on physiological or abstract events, that process input from neuromorphic hardware; and development of software and neuromorphic hardware for signal interpretation and action execution.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1456221","Collaborative Research: Navigation and the Neural Integration of Multimodal Sensory Information in the Brain of an Arthropod","IOS","ANIMAL BEHAVIOR","08/01/2015","07/24/2015","Wulfila Gronenberg","AZ","University of Arizona","Standard Grant","Michelle M. Elekonich","07/31/2019","$365,000.00","","wulfi@neurobio.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","BIO","7659","7659, 9179","$0.00","The ability of animals to navigate through their environment often far exceeds human capabilities (without the help of technology). Exceptional navigation is not limited to animals with large brains, like birds and mammals. It can also be found in animals with simpler nervous systems. The tropical amblypygid, a scorpion-like animal, is able to find its way home at night over distances exceeding 10 meters through dense, tropical forest understory.  The study of how different types of sensory information (visual, chemical, tactile) are processed by amblypygids as they solve navigation problems can reveal fundamental design properties of simple nervous systems that are somehow capable of controlling complex, learned behavior. These design properties can inspire engineering solutions applicable to robotic and artificial intelligence systems. The study of charismatic tropical amblypygids also serves as an alluring gateway for teachers to introduce K-12 students to the importance of neuroscience for understanding how organisms acquire and process information from their environment and how this information influences learning, memory and associated behavior. To support engagement with K-12 students, their teachers and the general public, researchers will, among other activities, develop internet-based educational materials in both English and Spanish and develop various scientific inquiry activities for science events. <br/><br/>By conducting behavioral experiments that assess amblypygid (Phrynus pseudoparvulus) movements after they are displaced from a home refuge, researchers will assess the relative importance of visual, chemical and mechanical information in supporting navigation. These experiments will either involve manipulation of animal sense organs or the sensory cues in their environment. The neurobiological work will focus on a brain area known as the ""mushroom bodies"", which are thought to support spatial memory. In parallel with the behavioral work, researchers will explore the nervous system routes by which information from different sensory stimuli is sent to the mushroom bodies. Particular attention will be given to how the mushroom bodies ""engineer"" or ""integrate"" the different sensory inputs.  The integration of sensory inputs is hypothesized to be necessary to support complex navigation and will likely be crucial for the design of any sophisticated artificial system. Finally, the importance of the mushroom bodies in navigation, and their capacity to combine different sources of sensory information, will be tested under the same conditions of the behavioral experiments noted above, except using animals whose mushroom bodies are impaired."
"1750920","CAREER: Advances in Graph Learning and Inference","CCF","COMM & INFORMATION FOUNDATIONS","02/01/2018","01/29/2018","Chinmay Hegde","IA","Iowa State University","Continuing grant","Phillip Regalia","01/31/2023","$160,413.00","","chinmay@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","CSE","7797","1045, 7935","$0.00","Graph-based data processing algorithms impact a variety of application domains ranging from transportation networks, artificial intelligence systems, cellphone networks, social networks, and the Web. Nevertheless, the emergent big-data era poses key conceptual challenges: several existing graph-based methods used in practice exhibit unreasonably high running time; several other methods operate in the absence of correctness guarantees. These challenges severely imperil the safety and reliability of higher-level decision-making systems of which they are a part. This research introduces an innovative new computational framework for graph learning and inference that addresses these challenges. Specific applications studied in this project include: better approaches for monitoring roadway congestion and identify traffic incidents in a timely manner; root-cause analysis of complex events in social networks; and design of better personalized learning systems, lowering educational costs and increasing quality nationwide. Activities include integrated programs to increase participation of women and under-represented minorities in the computational sciences. <br/><br/>From a technical standpoint, the investigator pursues three research themes: (i) designing scalable non-convex algorithms for learning the edges (and weights) of an unknown graph given a sequence of independent static and/or time-varying local measurements; (ii) designing new approximation algorithms for utilizing the structure of a given graph to enable scalable post-hoc decision making in complex systems; (iii) developing provable algorithms for training special families of artificial neural networks, and filling gaps between rigorous theory and practice of neural network learning. Progress in each of the above themes will be extensively evaluated using real-world data from engineering applications including social network data, highway monitoring data, and fluid-flow simulation data. Collaborations with domain experts in each of these application areas will ensure that the new theory, tools, and software emerging from this project will lead to meaningful societal benefits."
"1841800","CAREER: Teaching Machines to Design Self-Assembling Materials","DMR","CONDENSED MATTER & MAT THEORY","06/01/2018","07/17/2018","Andrew Ferguson","IL","University of Chicago","Continuing grant","Daryl W. Hess","05/31/2019","$90,001.00","","andrewferguson@uchicago.edu","6054 South Drexel Avenue","Chicago","IL","606372612","7737028669","MPS","1765","1045, 8400, 9216","$0.00","TECHNICAL SUMMARY<br/><br/>This CAREER award supports theoretical and computational research and education in the understanding and design of self-assembling biomaterials. Self-assembly of structured aggregates by the spontaneous organization of their constituent building blocks is prevalent in the natural world, and is an attractive route to fabricate artificial materials with desirable properties that cannot be easily produced by other means. The design of building blocks programmed to self-assemble custom materials is a grand challenge in materials science.<br/><br/>In this work, the PI will integrate statistical mechanics theory with nonlinear machine learning algorithms to establish a new theoretical and computational approach to understand and program the self-assembly of nanostructured biomaterials. Using these tools, the PI will extract from molecular simulations the pathways and mechanisms by which building blocks self-assemble into structured aggregates. This methodology overcomes a key scientific challenge by integrating thermodynamics and kinetics in a unified framework that identifies both what stable aggregates form (thermodynamics) and how they assemble (kinetics and mechanisms). <br/><br/>The collective order parameters unveiled by this approach are good descriptors of the slow dynamical motions driving assembly, and present a natural parameterization for kinetically meaningful free energy landscapes that link building block properties to collective assembly behavior. By ""sculpting"" the landscape topography through rational manipulation of building block structure and chemistry the PI's group will program the assembly of desired structures that are thermodynamically stable and kinetically accessible (design).<br/><br/>The PI will apply a new approach to three technologically important self-assembling biomaterials: 1) ""patchy colloid"" polyhedral clusters for small molecule encapsulation, 2) ultra-short peptide mineralization templates for silica nanotubes for controlled drug release, heavy metal ion adsorption, and catalysis, and 3) antimicrobial peptide amphiphile nanostructures for antibiotic resistant bacteria. This work will establish new basic understanding and control of materials assembly, and accelerate development of new structural and functional biomaterials. <br/><br/>The integrated education and outreach plan incorporates the scientific outcomes into education and outreach, and supports graduate training, undergraduate research, and mentoring of underrepresented minority groups. The PI will create a new materials science course to equip the next generation workforce with computational tools, support undergraduate students in performing portions of the work, and promote the recruitment, retention, and success of students of color through mentorship of minority students and high school outreach.<br/><br/>NONTECHNICAL SUMMARY<br/><br/>This CAREER award supports a theoretical and computational research program to design microscopic building blocks with the ability to spontaneously self-organize into materials with desirable properties. This way of making materials is known as ""bottom-up self-assembly"", as opposed to more familiar ""top-down"" manufacturing. Imagine if it will be possible one day to design molecules with just the right shape and properties so that shaking them in a flask spontaneously self-assembled a solar cell! In this work, the PI will combine ideas from the fields of thermodynamics and machine learning (sometimes known as artificial intelligence) to establish a new tool to allow computers to learn both what structures can be formed by a particular building block, and how they assemble. The PI will then flip this problem to use our tool to help reverse-engineer building blocks to assemble custom materials. <br/><br/>The PI's group will apply these tools to the design of three useful biological materials: 1) micron-sized particles possessing directional sticky patches that assemble polyhedral clusters to hold and deliver small molecules, 2) short peptides that assemble networks to template the synthesis of silica nanotubes for drug delivery, cleanup of heavy metal pollutants, and catalysis of chemical reactions, and 3) longer peptides that assemble into nanometer sized rods that can kill antibiotic resistant bacteria such as the MRSA ""superbug"".<br/><br/>This award also supports an integrated research and education program in which the scientific results from this work will enrich and enhance undergraduate and graduate classes, and high school outreach activities. Undergraduate students will directly participate in the scientific research by working with the PI during the summer months. The PI will also design and teach a new class providing hands-on experience in the computational materials modeling, analysis, and design, and maintain his commitment to promote the recruitment and success of students of color through mentorship of undergraduate and graduate minority students."
"1709641","BRAIN: Brain-Inspired Memristive Nanofiber Neural Networks","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/01/2017","06/26/2017","Juan Nino","FL","University of Florida","Standard Grant","Anthony Kuh","07/31/2020","$323,660.00","","jnino@mse.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","ENG","7607","155E","$0.00","The human brain is currently the most powerful information processor known to man. Recent advances in neural networks and network science indicate that in order to match the power and efficiency of the brain, there is a need for a brand-new type of neuromorphic hardware that is able to connect physically independent neurons with dedicated, modifiable synapses. The PI and coworkers have developed a brain-inspired concept where, preliminary theoretical and experimental results show that a mat of memristive nanofibers is anticipated to yield neural networks with enhanced connectivity, functionality, and overall performance. This project aims at assessing the potential of this concept and it is guided by the overarching fundamental question can these brain-inspired memristive nanofiber neural network (MN3) architectures be effectively used for advanced neuromorphic computing.<br/><br/>The intellectual merit of the project stems from its goal to investigate the potential of MN3 architectures as the basis for novel neural network architectures that emulate the brain's computational abilities. This BRAIN project has three main objectives: 1) Manufacture MN3 architectures based on connective matrices of conductive-core, memristive-shell nanofibers and electrically characterize the networks in order to compare their characteristics to theoretical simulations; 2) Develop a simulation framework for modeling the proposed MN3 architectures in order to investigate and predict the signal behavior and computational properties of the networks; and 3) Investigate methods for implementing and training the networks as artificial neural networks, and evaluate the resulting networks on a set of benchmark machine learning tasks to determine performance characteristics. <br/><br/>The broader impacts of the project can be summarized in four main areas: a) investigation of a new brain-inspired design paradigm for fabricating neural networks that, if successful, can potentially transform the broad fields of neuromorphic hardware and machine learning; b) advancement of the discovery and understanding of neural network architectures while training undergraduate and graduate students in STEM fields; c) dissemination of the gained scientific and technological understanding of memristive networks through professional conferences, peer-review publications, and online hubs; and d) dissemination of tutorials and workshops on Artificial Intelligence targeting the general population in collaboration with the Cade Museum."
"1746232","SBIR Phase I:  A Hybrid Brain-Computer Interface for Virtual and Augmented Reality","IIP","SMALL BUSINESS PHASE I","01/01/2018","12/20/2017","Jay Jantz","MA","Neurable Inc.","Standard Grant","Nancy Kamei","12/31/2018","$224,915.00","","jayj@neurable.com","25 1st Street","Cambridge","MA","021411802","9173124551","ENG","5371","108E, 5371, 8018, 8042, 8089, 8091","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project addresses the need for non-invasive brain-computer interfaces (BCIs) and hands-free control of technologies, including artificial and virtual reality (AR/VR) and smart devices. The proposed multi-purposed BCI is expected to have immediate applications for several industries, including manufacturing and medicine. Currently, existing systems are either too expensive or limited for real-time control. The proposed BCI is specifically designed for 3 dimensional environments, and is intended to leverage multiple ('hybrid') signals from the human body to allow increased performance using affordable hardware. It is also designed for and expected to allow AR/VR control, which can enable productivity applications, as well as model BCI use in real-world scenarios. The long term goal is to enable users to scroll menus, select objects, and even type using their brain activity. The platform uses the existing form-factor of AR/VR headsets to incorporate brain-sensing electrodes, and will be compatible with popular devices, independently or in parallel with their existing controllers. The electrodes are designed to be safe, non-invasive, and dry (requiring conductive gel or saline). The high-risk, high-reward research to be conducted under this project will significantly advance the applications of BCI systems in general, with an emphasis on AR/VR technologies.<br/><br/>The proposed project concerns a novel hybrid BCI by combining oculomotor and electroencephalography (EEG) signals via a custom machine learning platform. BCIs detect and interpret neural signals enabling control over a variety of technologies. However, current BCIs remain extremely limited in their applicability. They either require expensive equipment, invasive surgery, or have too low performance when using affordable noninvasive hardware. This BCI aims to provide real-time control in 3-dimensional scenarios, (e.g., AR/VR/real-world smart devices), while using affordable hardware. This SBIR Phase I project seeks to combine three distinct innovations: high-performance EEG signal analysis, high-speed eye movement classification, and custom multi-signal ensemble classification techniques. Specifically, the project seeks to use a custom machine learning and artificial intelligence approach informed by physiology to combine oculomotor and EEG signals to specifically enable3D AR/VR control. The ultimate goal is to develop a high performance BCI system that affords flexible user control across hardware, software, and mobile applications."
"1727336","Doctoral Dissertation Research: The interaction of expectations and evidence in pragmatic inference and generalizations","BCS","DDRI Linguistics","08/01/2017","07/20/2017","Chigusa Kurumada","NY","University of Rochester","Standard Grant","William J. Badecker","01/31/2019","$11,813.00","Amanda Pogue","ckuruma2@ur.rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","SBE","8374","1311, 9179","$0.00","Spoken language not only communicates information about a speaker's thoughts or desires; it also conveys information about the speaker's identity. By simply listening to speakers' voices, accents, and word choice, we can learn a great deal about them, in addition to what is being talked about. Previous studies of language processing, however,have almost exclusively focused on the linguistic signal abstracted from individual speakers, investigating what listeners think is true about the world based on what an individual speaker has said. The project aims toexplore the mechanism by which listeners extract information about the speakerthrough processing the linguistic signal. It then addresses the question of whether, and if so how, the increased knowledge about the speaker facilitates language comprehension.This research, consequently allows researchers to build a foundation for exploring howyoung children may learn speaker differences, which can contribute to new pedagogicaltools for helping children to better interact with, and learn from, diverse populations.Secondly, the work will likely have industry applications for artificial intelligence technology,allowing it to better adapt its functionality to an individual user's talking style.<br/><br/>This dissertation project employs two approaches to investigating what information listeners extract from spoken utterances. First,a large-scale online surveytechnique will be used to solicit responses from participants from a wider variety of linguisticand cultural backgrounds than those included in previous studies. Participants are exposed to utterances produced bytwo speakers and subsequently answer questions that probe their sensitivity to across-speaker differences. In the second set of experiments, a combination ofan artificial language learningparadigmand an eye-tracking methodology will be used to study real-time language comprehension behaviors.Listeners' eye-gaze will be used to gain fine-grained information aboutthe real-time development oftheir linguistic expectations. By combining these experimental approaches,the researchers elucidatehow the human language comprehension system derives fine-grainedexpectations for future linguisticinput and how the mechanism develops as a function of increased knowledge about linguistic communication."
"1456817","Collaborative Research: Navigation and the Neural Integration of Multimodal Sensory Information in the Brain of an Arthropod","IOS","AISL, ANIMAL BEHAVIOR","08/01/2015","04/01/2016","Eileen Hebets","NE","University of Nebraska-Lincoln","Standard Grant","Michelle M. Elekonich","07/31/2019","$285,215.00","","ehebets2@unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","BIO","7259, 7659","7259, 7659, 9178, 9179, 9251, SMET","$0.00","The ability of animals to navigate through their environment often far exceeds human capabilities (without the help of technology). Exceptional navigation is not limited to animals with large brains, like birds and mammals. It can also be found in animals with simpler nervous systems. The tropical amblypygid, a scorpion-like animal, is able to find its way home at night over distances exceeding 10 meters through dense, tropical forest understory.  The study of how different types of sensory information (visual, chemical, tactile) are processed by amblypygids as they solve navigation problems can reveal fundamental design properties of simple nervous systems that are somehow capable of controlling complex, learned behavior. These design properties can inspire engineering solutions applicable to robotic and artificial intelligence systems. The study of charismatic tropical amblypygids also serves as an alluring gateway for teachers to introduce K-12 students to the importance of neuroscience for understanding how organisms acquire and process information from their environment and how this information influences learning, memory and associated behavior. To support engagement with K-12 students, their teachers and the general public, researchers will, among other activities, develop internet-based educational materials in both English and Spanish and develop various scientific inquiry activities for science events. <br/><br/>By conducting behavioral experiments that assess amblypygid (Phrynus pseudoparvulus) movements after they are displaced from a home refuge, researchers will assess the relative importance of visual, chemical and mechanical information in supporting navigation. These experiments will either involve manipulation of animal sense organs or the sensory cues in their environment. The neurobiological work will focus on a brain area known as the ""mushroom bodies"", which are thought to support spatial memory. In parallel with the behavioral work, researchers will explore the nervous system routes by which information from different sensory stimuli is sent to the mushroom bodies. Particular attention will be given to how the mushroom bodies ""engineer"" or ""integrate"" the different sensory inputs.  The integration of sensory inputs is hypothesized to be necessary to support complex navigation and will likely be crucial for the design of any sophisticated artificial system. Finally, the importance of the mushroom bodies in navigation, and their capacity to combine different sources of sensory information, will be tested under the same conditions of the behavioral experiments noted above, except using animals whose mushroom bodies are impaired."
"1738375","SBIR Phase II:  Mobile Manipulation Hospital Service Robots","IIP","SMALL BUSINESS PHASE II","09/15/2017","09/06/2018","Andrea Thomaz","TX","Diligent Droids, LLC","Standard Grant","Nancy Kamei","02/29/2020","$699,985.00","","athomaz@diligentdroids.com","2418 Spring Ln PO Box 5017","Austin","TX","787034480","6177847154","ENG","5373","169E, 5373, 8018, 8042","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project on hospital service robots is improving the quality of care in hospital systems that are under increased pressure to provide high-quality patient-centric care while functioning as profitable businesses. Hospitals face a shortage of qualified nurses and high rates of nurse turnover. Nurses play a critical role in communicating care plans, educating patients, and guarding against medical errors. The amount of time they spend in direct care activities is a key determinant of patient satisfaction, better patient outcomes, fewer errors, and shorter lengths of stay. In the face of nursing shortages across the U.S., it is increasingly important to have nurses performing at the 'top of their license'. Reducing the amount of time they spend on non-nursing tasks is crucial to this goal. Automation could address these challenges and labor shortage by allowing clinical staff to focus on providing skilled care. The proposed project aims to develop technology that is general-purpose enough to transfer to other markets, such as long term care facilities and, eventually, individual consumers. Robots that perform assistive tasks in homes could increase the feasibility of independent living for many older adults.<br/><br/><br/>The proposed project will establish the technical and commercial feasibility of developing hospital service robots that act as assistants on acute care units, enabling nurses to spend more time at the bedside with patients. This project will make technical advances along three dimensions: the ability of the proposed robot to autonomously navigate within nursing units and across the hospital (navigation capabilities); to easily adapt its manipulation skills to specific tasks and to physical characteristics of a particular hospital/unit (adaptive learning of manipulation skills); and to work alongside humans in a socially acceptable manner, including appropriate navigation in crowded hallways, speech, and eye gaze behaviors that communicate the robot's intentions (socially intelligent interoperability). The team intends to collaborate closely with a single partner hospital to iteratively improve the reliability and robustness of the artificial intelligence software suite developed with NSF funding and to deploy production-quality versions of the three core competencies. The final 6 months will involve a long-term deployment, with the robot autonomously working on an acute care unit of the partner hospital. The impact of the robot on unit staff and workflows will be documented, with the ultimate goal of developing a service robot that hospital staff view as a competent member of the care team."
"1744386","Convergence HTF: A Workshop Shaping Research on Human-Technology Partnerships to Enhance STEM Workforce Engagement","BCS","SOCIAL PSYCHOLOGY, INSPIRE","09/01/2017","08/23/2017","Keivan Stassun","TN","Vanderbilt University","Standard Grant","Steven Breckler","08/31/2019","$98,346.00","Maithilee Kunda, Zachary Warren, Frank Tong, Nilanjan Sarkar","keivan.stassun@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","SBE","1332, 8078","060Z, 063Z, 7556","$0.00","The landscape of jobs and work is changing rapidly, driven by the development of new technologies. Intelligent, automated machines and services are a growing part of jobs and the workplace. New technologies are enabling new forms of learning, skills assessments, and job training. The potential benefits of these technologies include increased productivity and satisfaction, and more job opportunities. The workshop supported by this award aims to harness these innovations to enhance the science, technology, engineering, and mathematics (STEM) job opportunities and workforce engagement of individuals with autism spectrum disorder (ASD), and related developmental disabilities. The workshop will promote the convergence of psychology, data science, computer science, engineering, learning science, special education, organizational behavior, and business to define key challenges and research imperatives at the nexus of humans, technology, and work. This convergence workshop will employ deep integration of knowledge, theories, methods, and data from multiple fields to form new and expanded frameworks for addressing scientific and societal challenges and opportunities. The results of the workshop will include the identification and sharing of new research directions and tools to enhance STEM workforce engagement of individuals with ASD and related developmental disabilities. This convergence workshop addresses the future of work at the human-technology frontier.<br/><br/>The workshop will explore tools and approaches to enhance retention, engagement, and productivity in STEM jobs, and specifically to harness unique capabilities and accommodate for individual needs of individuals with ASD. The workshop will develop a convergence research agenda around four topics, including 1) human-technology partnerships to support success in K-12 STEM education, 2) tools for characterizing individual capabilities and affinities and mapping these to STEM workforce needs, 3) artificial-intelligence and visual-cognition tools for human interaction with data, and 4) technologies to accommodate for unique needs and capabilites in the workplace. These topics will integrate previously disparate disciplines and research approaches, with speakers encompassing a wide range of subject matter expertise; from engineers and technologists who are developing human-technology interfaces and devices, to psychologists who are harnessing human-technology partnerships to better understand unique human capabilities for STEM, to computer scientists who are studying and developing novel data-visualization approaches patterned on autistic visual thinking, to organizational scientists developing innovative employment models for the creation of STEM sector employment spaces and technologies that leverage and support autistic individuals in the workforce. The conclusions and recommendations from the workshop will be disseminated via a white paper, and will be used to design a research agenda to help leverage human-technology advances to maximize workforce opportunities and productivity."
"1745410","EAGER: Deep Learning-Based Self-Organizing Network for B5G Communications with Massive IoT Devices","ECCS","COMMS, CIRCUITS & SENS SYS","09/01/2017","07/20/2017","Meryem Simsek","CA","International Computer Science Institute","Standard Grant","Akbar Sayeed","08/31/2019","$149,217.00","","simsek@ICSI.Berkeley.EDU","1947 CENTER ST STE 600","Berkeley","CA","947044115","5106662900","ENG","7564","153E, 7916","$0.00","Future wireless networks are expected to provide a platform for highly reliable and ultra-low latency information exchange that will revolutionize the way machines communicate and how people interact. A vast number of devices, particularly sensors and actors, is anticipated to be able to connect to a single wireless access point, empowering the deployment of massive Internet of Things devices that generate an enormous amount of information, namely Big Data. The management of both, the wireless connections of the devices and the Big Data they generate, requires substantial changes to legacy wireless networks. The goal of this project is to conduct exploratory research on such changes, which, if successful, will deliver a key corner stone to the future deployment of massive Internet of Things. This deployment will constitute an essential component in various aspects of life, such as improvements in consumer products, e.g. home automation and better consumer oriented entertainment; in health, through smart body sensors and remote, low-cost diagnosis; in more cost-efficient manufacturing; in environmental monitoring, e. g., for enhancing environmental conditions like reduced air pollution; or in the realization of smart cities.<br/><br/>Following the recent great success of artificial intelligence, machine learning, and specifically deep learning in many different applications, the goal of this project is to explore and to perform research on novel deep-learning-assisted autonomous decision-making approaches for the self-management of future wireless communications networks. The problem to be solved is to establish an efficient and effective wireless network self-management architecture that is flexible enough to facilitate the deployment and operation of diverse massive Internet of Things devices. This architecture is expected to be able to exploit hidden information in Big Data generated by the Internet of Things devices through deep learning techniques. The research into this architecture comprises the exploration of novel machine learning algorithms for the intelligent, predictive, and autonomous allocation of radio and network resources at different layers of the wireless network. Ultimately, a novel multi-layer self-organizing network architecture will be introduced that fully exploits the flexibility and capability of future wireless networks for servicing massive Internet of Things. The developed approaches will lay the foundations of substantially enhancing legacy self-organizing wireless networks and will impact the design of future wireless networks, its efficiency, and the realization of various emerging use cases generating Big Data likewise. The results will also provide novel insights into the role of Big Data for the communications industry, potentially fostering the development of new business models and strengthening the industry's national and international competitiveness."
"1845928","NCS-FO: Collaborative Research: Developing Underwater EEG Electrodes for Octopus Research","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2018","08/08/2018","Walter Besio","RI","University of Rhode Island","Standard Grant","Uri Hasson","08/31/2020","$100,000.00","","besio@uri.edu","RESEARCH OFFICE","KINGSTON","RI","028811967","4018742635","SBE","8624","7916, 8089, 8091, 8551, 9150","$0.00","The octopus is a social animal, with high intelligence and problem-solving skills, that is very distant from humans in terms of its evolution.  This project aims to fabricate neuroelectric sensors and experimental protocols that would enable studying visual and higher level cognitive processes in the octopus while they are engaged in natural behaviors in an underwater environment. This will necessitate development of new engineering solutions for crafting electroencephalography (EEG) sensors that can record signal underwater, new solutions for removing noise artifacts from these highly complicated recordings, as well as careful design of experiments that could study such behaviors in a virtual-reality environment. While the brain of the octopus is very different from that of the human, it does support well-defined cognitive functions. Therefore, understanding whether and how octopuses' brains implement processes such as learning, attention, habituation, and surprise can produce new and important understandings of how neurobiological systems can support function.  This research might reveal that the neural substrates of cognitive function in the octopus are organized according to principles that differ drastically from those found in in humans.<br/><br/>This EAGER project has several aims. It will develop the first underwater EEG, first testing well-validated paradigms on humans performing task underwater and benchmarking against known waveforms. The electrodes will be constructed so that they do not corrode in salt water. It will also develop high-quality virtual reality stimulation that could impact octopuses' behavior in an underwater environment. It will utilize EEG frequency-tagging techniques to determine processing of environmental stimulus by the octopus. This will allow studying whether octopuses present characteristic responses that are analogous to surprise, adaptation, working memory and attention effects (in primates and other vertebrates). The study will also allow answering how and in what manner do octopuses sleep. All data, artifacts and modeling software will be made publicly available and constitute an important resource for the community. The results of this study could impact our general understanding of how brains support complex cognitive functions, with direct relevance to artificial intelligence efforts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1845123","NCS-FO: Collaborative Research: Developing Underwater EEG Electrodes for Octopus Research","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2018","08/08/2018","Gideon Caplovitz","NV","Board of Regents, NSHE, obo University of Nevada, Reno","Standard Grant","Uri Hasson","08/31/2020","$39,884.00","","gcaplovitz@unr.edu","1664 North Virginia Street","Reno","NV","895570001","7757844040","SBE","8624","7916, 8089, 8091, 8551, 9150","$0.00","The octopus is a social animal, with high intelligence and problem-solving skills, that is very distant from humans in terms of its evolution.  This project aims to fabricate neuroelectric sensors and experimental protocols that would enable studying visual and higher level cognitive processes in the octopus while they are engaged in natural behaviors in an underwater environment. This will necessitate development of new engineering solutions for crafting electroencephalography (EEG) sensors that can record signal underwater, new solutions for removing noise artifacts from these highly complicated recordings, as well as careful design of experiments that could study such behaviors in a virtual-reality environment. While the brain of the octopus is very different from that of the human, it does support well-defined cognitive functions. Therefore, understanding whether and how octopuses' brains implement processes such as learning, attention, habituation, and surprise can produce new and important understandings of how neurobiological systems can support function.  This research might reveal that the neural substrates of cognitive function in the octopus are organized according to principles that differ drastically from those found in in humans.<br/><br/>This EAGER project has several aims. It will develop the first underwater EEG, first testing well-validated paradigms on humans performing task underwater and benchmarking against known waveforms. The electrodes will be constructed so that they do not corrode in salt water. It will also develop high-quality virtual reality stimulation that could impact octopuses' behavior in an underwater environment. It will utilize EEG frequency-tagging techniques to determine processing of environmental stimulus by the octopus. This will allow studying whether octopuses present characteristic responses that are analogous to surprise, adaptation, working memory and attention effects (in primates and other vertebrates). The study will also allow answering how and in what manner do octopuses sleep. All data, artifacts and modeling software will be made publicly available and constitute an important resource for the community. The results of this study could impact our general understanding of how brains support complex cognitive functions, with direct relevance to artificial intelligence efforts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1844589","NCS-FO: Collaborative Research: Developing Underwater EEG Electrodes for Octopus Research","BCS","IntgStrat Undst Neurl&Cogn Sys","09/01/2018","08/08/2018","Peter Tse","NH","Dartmouth College","Standard Grant","Uri Hasson","08/31/2020","$159,999.00","","Peter.Tse@dartmouth.edu","OFFICE OF SPONSORED PROJECTS","HANOVER","NH","037551404","6036463007","SBE","8624","7916, 8089, 8091, 8551, 9150","$0.00","The octopus is a social animal, with high intelligence and problem-solving skills, that is very distant from humans in terms of its evolution.  This project aims to fabricate neuroelectric sensors and experimental protocols that would enable studying visual and higher level cognitive processes in the octopus while they are engaged in natural behaviors in an underwater environment. This will necessitate development of new engineering solutions for crafting electroencephalography (EEG) sensors that can record signal underwater, new solutions for removing noise artifacts from these highly complicated recordings, as well as careful design of experiments that could study such behaviors in a virtual-reality environment. While the brain of the octopus is very different from that of the human, it does support well-defined cognitive functions. Therefore, understanding whether and how octopuses' brains implement processes such as learning, attention, habituation, and surprise can produce new and important understandings of how neurobiological systems can support function.  This research might reveal that the neural substrates of cognitive function in the octopus are organized according to principles that differ drastically from those found in in humans.<br/><br/>This EAGER project has several aims. It will develop the first underwater EEG, first testing well-validated paradigms on humans performing task underwater and benchmarking against known waveforms. The electrodes will be constructed so that they do not corrode in salt water. It will also develop high-quality virtual reality stimulation that could impact octopuses' behavior in an underwater environment. It will utilize EEG frequency-tagging techniques to determine processing of environmental stimulus by the octopus. This will allow studying whether octopuses present characteristic responses that are analogous to surprise, adaptation, working memory and attention effects (in primates and other vertebrates). The study will also allow answering how and in what manner do octopuses sleep. All data, artifacts and modeling software will be made publicly available and constitute an important resource for the community. The results of this study could impact our general understanding of how brains support complex cognitive functions, with direct relevance to artificial intelligence efforts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1841097","Community-Building Workshop on Programmable System Security in a Software-Defined World","CNS","Computer Systems Research (CSR, Networking Technology and Syst","08/01/2018","08/06/2018","Kun Sun","VA","George Mason University","Standard Grant","Samee Khan","07/31/2019","$48,500.00","","ksun3@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7354, 7363","073Z, 7556","$0.00","We increasingly live in a software-defined world where systems that were once implemented as rigid control systems or fixed-function hardware systems are now highly programmable through software interfaces that decouple underlying hardware details and offer remote control and centralized management. Early examples of software-defined systems (SD-X) include multi-tenant clouds, software-defined networking (SDN), network functions virtualization (NFV), software-defined infrastructure (SDI), and software-defined radios (SDR). While SD-X technologies have rapidly proliferated within industry and received considerable systems research attention, the paradigm has not been fully exploited in approaching a wide array of important security challenges. The objective of this workshop is to identify those research challenges and opportunities to exploit SD-X approaches in making system security more programmable, agile, orchestrated, and intelligent. This workshop creates a much-needed opportunity for a cross-cutting group of researchers to fill out the vision of what programmable security based on SD-X could be, including research challenges, long-term visions, and key issues. In the process, this workshop will promote a more focused community and vision where traditionally disparate communities previously worked in isolation and without a more ambitious system security vision within the context of complex software-defined infrastructures. The workshop report will be made available to the public via the workshop website.<br/><br/>Broad directions to be considered by the workshop attendees include, but are not limited to: (1) new abstractions for data/control planes aimed specifically at security, (2) new architectures that integrate diverse SD-X domains (networking, processing, storage, etc.) for a more powerful and comprehensive security framework, (3) new programming and language paradigms for programmable security, (4) a better understanding of attack surfaces and adversarial methods within modern software-defined infrastructures, (5) new formal and experimental methodologies for reasoning about software-defined security, (6) the integration of emerging Artificial Intelligence/Machine Learning and data-driven capabilities into programmable system security, (7) new applications paradigms that exploit programmable paradigms in innovative ways, and (8) the application of programmable security approaches to emerging platforms and infrastructure domains. Overall, workshop participants will help to build community and define the vision of a new generation of security technologies in the rapidly expanding world of software-defined infrastructures and devices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1744356","Workshop: Understanding Emerging Technologies and the Future of Work","BCS","SOCIAL PSYCHOLOGY, IUSE, SCIENCE, TECH & SOCIETY","09/01/2017","08/31/2017","Laurel Smith-Doerr","MA","University of Massachusetts Amherst","Standard Grant","Steven Breckler","08/31/2019","$99,970.00","Enobong Branch, Shlomo Zilberstein, Shannon Roberts, Henry Renski","lsmithdoerr@soc.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","SBE","1332, 1998, 7603","063Z","$0.00","Intelligent, interactive, and highly networked machines are a growing part of work and the workplace.  Automation is moving from the factory floor to knowledge and service occupations.  The potential benefits of technology include increased productivity and more job opportunities.  But technology connected to work can also carry substantial social costs.  The workshop supported by this award will promote the convergence of education, social and behavioral sciences, computational sciences, and engineering with stakeholders. This diverse group will define key research challenges that focus on the intersection of humans, technology, and work.  Convergence is the deep integration of knowledge, theories, methods, and data from multiple fields to form new and expanded frameworks for addressing scientific and societal challenges and opportunities. Two workshops will address the future of work at the human-technology frontier. The workshops will focus on the challenges of shaping emergent technologies that are equitable. They will also consider how the technologies will engage a wider range of people in the workforce of the future.  The results of the workshops will include reports, communication materials, and the organization of interdisciplinary panels at professional scientific meetings.<br/><br/>The specific focus of this workshop effort is on understanding the social and technical dimensions of new technologies. The goal is to develop a research agenda that will help us understand the challenges of shaping emergent technologies in ways that result in good jobs for a wide range of U.S. workers. This includes a workshop that will bring together expert scientists to consider (1) how the changing organization of work and technology affects income inequality; (2) how decisions are made in developing artificial intelligence and processes for human-technology partnerships; (3) how to develop methods for assessing emerging technologies in terms of likely work satisfaction and inequality in employment outcomes; and (4) how workforce development and economic systems can help make high-paying stable jobs widely available. The second workshop will include stakeholders and will focus on how to use these ideas at the local level."
"1560478","Research Experience for Undergraduates in UAV Technologies","EEC","","08/01/2016","07/21/2016","Subodh Bhandari","CA","Cal Poly Pomona Foundation, Inc.","Standard Grant","Mary Poats","07/31/2019","$380,001.00","Fang Tang","sbhandari@cpp.edu","3801 West Temple, Bldg 55","Pomona","CA","917682557","9098692948","ENG","P226","7736, 9250","$0.00","This Research Experiences for Undergraduates (REU) Site program at California State Polytechnic University, Pomona (CPP), offers state-of-the-art, multi-disciplinary research experiences in unmanned aerial vehicles (UAV) technologies, engineering, and computer science to diverse and talented cohorts of undergraduates, particularly women and Hispanic students, from 2 and 4 year institutions with limited or no research opportunities. UAV's have the potential of replacing manned aircraft for dull, dirty, and dangerous missions. In addition, UAV's are less expensive than manned aircraft and pose no risk to human operators. Military applications include intelligence, surveillance, and reconnaissance (ISR), battlefield damage assessment, and force protection.  Civilian applications include remote sensing, scientific research, search and rescue missions, border patrol, surveillance of disaster-affected areas, aerial photography, aerial mapping for geotechnical survey, vegetation growth analysis, crop dusting, and precision agriculture.  The UAV industry is the fastest growing sector of the aerospace industry.  However, there is a lack of professionals entering the workforce for UAV related jobs.  This REU program is designed to increase students' interest in UAV technologies by means of first-hand experience on UAV research with direct mentorship by faculty advisors from various departments within the CPP Colleges of Engineering and Science.  <br/><br/>This REU Site offers undergraduates, in collaboration with CPP faculty and graduate students, opportunities to conduct research during a 10-week summer program, on state-of-the-art technologies and advanced research projects in UAV flight dynamic and control, computer vision, artificial intelligence, embedded systems, and robotics. In addition to their research, students will participate in weekly research seminars, research meetings, and professional development seminars. The seminars will include topics such as literature review, writing a scientific paper, improving written and oral communication skills, technical presentations, graduate education, career paths, resume building, and ethics in science and engineering. The 10-week program will also include outreach activity. The students will give presentations on UAV technologies, engineering, and computer science to K-12 students at local schools. This will enhance students' communication skills, allow them to see the broader implications of their research, and see how they can positively impact society through research. The discoveries made during these collaborations will be communicated to the broader scientific community via publications and presentations. <br/><br/>This site is supported by the Department of Defense in partnership with the NSF REU program."
"1822207","Planning IUCRC University of Arizona: Center for Networked Embedded, Smart and Trusted Things (NESTT)","CNS","INDUSTRY/UNIV COOP RES CENTERS","08/01/2018","07/29/2018","Frederic Zenhausern","AZ","University of Arizona","Standard Grant","Dmitri Perkins","07/31/2019","$15,000.00","","fzenhaus@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","CSE","5761","5761","$0.00","Most public health systems around the world are investing into initiatives promoting and supporting the convergence of medicine and technology for improving the healthcare delivery systems. These efforts rely on integrating sensing, logistics, computing, actuation and communication functionalities in everyday practices. The University of Arizona will work with Arizona State University, University of Southern California, University of Connecticut, and Southern Illinois University to form a new IUCRC for Networked Embedded, Smart and Trusted Things (NESTT). The vision of NESTT is to contribute to the development of an equitable, safe and secure connected world. NESTT will achieve this vision by focusing on creating holistic IoT solutions, integrating technology disciplines with expertise in medicine, law, business, and humanities.<br/><br/>In order to make these transformative approaches and technologies a reality, machine learning and artificial intelligence are some of the emerging tools for processing the massive amounts of IoT data and information that will shift the medical decision making processes from simple binary modes to complex ""nuanced"" and ""near real-time"" models. UofA NESTT site will co-organized workshops to design industry specifications and prototype health logistics appliances, wearable sensor systems, ambient intelligence and A.I. data algorithms that can be integrated effectively into the regulatory framework and processes of the healthcare delivery system by enabling the IoT advanced technology solutions planned at the other NESTT nodes.<br/><br/>There is trend in digitalization of medicine and healthcare, especially with the emergence of the Internet of Things which will disrupt the healthcare industry in this decade. UA NESTT site will investigate this digital transformation through the entire value chain, from discovery to bedside. Health platforms designed to address unmet needs and improve medical access to underserved large populations will provide useful solutions to the global healthcare challenges. UA NESTT academic, clinical and business partners will contribute their expertise to provide contextualization and standardization of information to offer real-world insights in digital transformation of the healthcare sector.<br/><br/>The agenda and documentation of activities for the NESTT IUCRC planning meetings will be made available on UofA's website for the Center for Applied Nanobioscience and Medicine (https://phoenixmed.arizona.edu/anbm ). It will be maintained until the establishment of NESTT, and then merged with the NESTT site.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1824854","Synthesis and design workshop: Designing Scalable Advanced Learning Ecosystems","DRL","STEM + Computing (STEM+C) Part","09/01/2018","07/25/2018","Robert Kadel","GA","Georgia Tech Research Corporation","Standard Grant","Tatiana D. Korelsky","08/31/2019","$93,953.00","Yakut Gazi, Stephen Harmon, Ashok Goel","rob.kadel@gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","EHR","005Y","7556","$0.00","The U.S. is currently at a crossroads in higher education where access to quality post-secondary education is a prerequisite for entry into the middle class but the ability to afford such an education is becoming increasingly limited. Georgia Tech proposes the Scalable Advanced Learning Ecosystem to address this mismatch. Building on successful online education programs that have offered Master?s degrees in computer science and analytics, Georgia Tech hosts a workshop for higher education administrators and researchers to establish components of Scalable Advanced Learning Ecosystems that can be applied across colleges and universities. The goal of Scalable Advanced Learning Ecosystems is to create educational experiences that can be scaled to growing populations of students while providing the personalized attention that has typically been the domain of unscalable individual, face-to-face teaching and advising.<br/><br/>Technical description<br/><br/>Georgia Tech hypothesizes that with growing demand for higher education, but with a limited supply of professors, advisors, and budgets to meet such demand, Scalable Advanced Learning Ecosystems can be used to provide personalization and customization for large populations of students. Human activity and expertise are used to guide the creation of this ecosystem's innovations, but day-to-day operations are machine-driven. The innovations include: Personalized Learning Systems that use artificial intelligence and machine learning to establish customized educational plans for each student; Intelligent Tutoring Systems that modify the presentation and sequence of materials in response to student performance; Data Mining and Learning Analytics that extract useful and actionable information to understand student uses of learning resources and outcomes; Scalable Online Environments that deliver high-quality, high-engagement learning experiences; and Immersive Learning Environments that simulate a physical presence in real or imagined worlds, overlay content on those worlds, and merge real and virtual worlds to produce new learning opportunities. The workshop is  held on November 29 and 30, 2018 at the Global Learning Center on the Georgia Tech campus in Midtown Atlanta, and participating institutions are selected by proposals submitted that describe each institution?s interest in Scalable Advanced Learning Ecosystems and the institution?s commitment to action to improve educational access.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1657600","CRII: RI: Reasoning Geometric Commonsense for 3D Image/Video Parsing","IIS","CRII CISE Research Initiation","05/01/2017","05/03/2017","Xiaobai Liu","CA","San Diego State University Foundation","Standard Grant","Jie Yang","04/30/2019","$115,062.00","","xiaobai.liu@mail.sdsu.edu","5250 Campanile Drive","San Diego","CA","921822190","6195945731","CSE","026Y","7495, 8228","$0.00","Commonsense reasoning studies the consensus reality, knowledge, causality, and rationales available to the overwhelming majority of people, and can be used to enhance all aspects of Artificial Intelligence (AI). This project develops representations of geometric commonsense as well as computing principles of commonsense reasoning for computer vision applications. The project systemically studies commonsense knowledge over geometric dimensions of scene entities, e.g., the length of a sedan is shorter than that of a bus; or that window edges on the same faade are parallel to each other and are orthogonal to the edges on the ground. These first-order and second-order knowledges, once extracted, are fairly stable across different types of scenes, and are informative enough for enhancing the understanding of images or videos in both 2D and 3D. The project integrates research with education by supporting graduate students, and outreaches to computer vision and AI research communities by organizing workshops in the relevant conferences.<br/><br/>This research studies geometric commonsense reasoning for 3D scene parsing in images or videos, and contributes a unified probabilistic approach that is capable of reconstructing a wide variety of scene categories (e.g., suburb, urban, campus) from a single input image or a monocular video sequence.  The project approaches the problem from two aspects. First, a new attributed grammar model is developed to represent both images and the associated geometric commonsense knowledge using a hierarchical graphical structure. With this grammar model, the segmentation of semantic regions, the reconstruction of scene entities, and the reasoning of geometric commonsense can be all solved through creating a valid parse graph from images or videos. Second, a new computing framework is introduced so that the inference of image parsing can be conducted in the joint space of discrete semantic labels and continuous geometric labels, and the learning of grammar models can be conducted over training images with weak supervision. The developed techniques enable a state-of-the-art computer vision system that can robustly estimate semantic and geometric scene structures from images or videos."
"1724101","S&AS: FND: Reliable Semi-Autonomy with Diminishing Reliance on Humans","IIS","S&AS - Smart & Autonomous Syst, ROBUST INTELLIGENCE","09/01/2017","05/29/2018","Shlomo Zilberstein","MA","University of Massachusetts Amherst","Standard Grant","Irene Sattler","08/31/2020","$707,512.00","Joydeep Biswas","shlomo@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","039Y, 7495","046Z, 9251","$0.00","Building reliable autonomous systems that can construct and execute plans to achieve some assigned goals, without human intervention, has been the hallmark of artificial intelligence and robotics since their inception.  Reliable autonomy is becoming increasingly important as it enables innovative new applications in areas such as transportation, health, and sustainable living.  Despite substantial progress, there are still considerable barriers to the long-term, large scale deployment of fully autonomous systems such as self-driving cars or mobile service robots.  These barriers range from technological and economic constraints to ethical and legal issues.  This project offers a comprehensive approach to circumvent these barriers by building semi-autonomous systems that rely on rich forms of human assistance, ranging from advice to constant supervision of the system with the possibility of taking over control.  The project develops techniques to assure the safety of such systems when human assistance is delayed and to reduce their reliance on human assistance over time.  Additionally, the project contributes to training of undergraduate and graduate students in this interdisciplinary area, mentoring of students with special attention to underrepresented groups, outreach activities to local schools, and strengthening of industrial collaborations.<br/><br/>The project answers fundamental questions about the feasibility, efficiency, and scalability of planning and learning algorithms to support semi-autonomous systems.  The main thrusts of the project are (1) develop techniques that can delegate autonomy to a system with some restrictions, and provide strong guarantees that these restrictions will be respected and that the system will maintain a safe state even when human assistance is delayed; (2) develop planning and learning algorithms that are cognizant of the availability of rich forms of human assistance and can effectively factor such assistive actions into the overall plan; (3) handle the high computational complexity of optimizing the interaction with humans under uncertainty and partial observability by creating a hierarchical multi-objective decision model; and (4) leverage human assistance to enable robust and accurate mapping and navigation in new areas, while reducing the reliance on human supervision over time.  The project evaluates these capabilities in complex realistic settings involving a campus-scale robot deployment, a driving simulator, and autonomous vehicles in collaboration with Nissan."
"1620070","Collaborative Research:  Algorithms for Large-scale Stochastic and Nonlinear Optimization","DMS","COMPUTATIONAL MATHEMATICS","08/01/2016","06/17/2016","Richard Byrd","CO","University of Colorado at Boulder","Standard Grant","Leland M. Jameson","07/31/2019","$136,371.00","","richard@cs.colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","MPS","1271","9263","$0.00","The promise of artificial intelligence has been a topic of both public and private interest for decades. Starting in the 1990s the field has been benefited from the rapidly evolving and expanding field of machine learning. The intelligent systems that have been borne out of machine learning, such as search engines, recommendation platforms, and speech and image recognition software, have become an indispensable part of modern society.  Rooted in statistics and relying heavily on the efficiency of numerical algorithms, machine learning techniques capitalize on increasingly powerful computing platforms and the availability of very large datasets.  One of the pillars of machine learning is mathematical optimization, which, in this context, involves the computation of parameters for a system designed to make decisions based on yet unseen data. The goal of this project is to develop new optimization algorithms that will enable the continuing rise of the field of machine learning.<br/>  <br/>The research consists of two projects, which are thematically related and address the solution of optimization problems that are nonlinear, high dimensional, stochastic, involve very large data sets and in some cases are non-convex. Two families of algorithms will be developed to garner the benefits of both stochastic gradient methods and batch methods, while avoiding their shortcomings. One of these algorithms uses a gradient aggregation approach that re-uses gradient values computed at previous iterations. The challenge is to design an algorithm that is efficient in minimizing testing error, not just training error. The second approach employs adaptive sampling techniques to reduce the noise in stochastic gradient approximations as the optimization progresses. An important aspect of this research is the design of an efficient strategy for incorporating second-order information that captures curvature of the optimized loss function, even in the case when Hessian estimates are based on inaccurate gradients. In all cases, the goal is research is to design and implement algorithms in software, and test them on realistic machine learning applications."
"1651142","Conference:   Perceptrons and Syntactic Structures at 60: Computational Modeling of Language","BCS","LINGUISTICS, ROBUST INTELLIGENCE","08/01/2017","07/19/2017","Joseph Pater","MA","University of Massachusetts Amherst","Standard Grant","William J. Badecker","01/31/2019","$24,184.00","Brendan O'Connor","pater@linguist.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","SBE","1311, 7495","1311, 7495, 7556","$0.00","This workshop will bring together leading researchers in cognitive science and artificial intelligence who specialize in the integration of linguistic theory with statistical approaches, especially neural networks. Neural networks have been important in many of the recent advances in language technologies (in what's called ""deep learning""), and the greater integration of linguistic structure into these models promises to lead to further breakthroughs. <br/><br/>The main focus of this meeting will be on how integration of models of linguistic structure with probabilistic learning theories may lead to a deeper understanding of the way that humans process and represent language. This sort of integration has been difficult to achieve in the past in part because of the separation of researchers in each tradition into different disciplines interacting in different conferences. In-depth analysis of the structure of human languages is conducted in mostly in Linguistics, while neural network modeling and other statistical learning research is conducted mostly in Psychology and Computer Science. The workshop will be held as part of the inaugural meeting of the Society for Computation in Linguistics, taking place concurrently with the meeting of the Linguistic Society of America. It will thus bring researchers from other disciplines into contact with linguists, and will stimulate productive intellectual exchange."
"1661755","CAREER: A New Neat Framework for Statistical Machine Learning","IIS","ROBUST INTELLIGENCE","09/01/2016","01/24/2017","Pradeep Ravikumar","PA","Carnegie-Mellon University","Continuing grant","Weng-keen Wong","08/31/2019","$229,400.00","","pradeepr@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7495","1045","$0.00","The pendulum in Artificial Intelligence (AI) research has periodically swung from so called ""neat"" or mathematically rigorous approaches, and ""scruffy"" or more adhoc approaches. In recent years, real-world data across varied fields of science and engineering are increasingly complex, and involve a large number of variables, which has resulted in a surge of scruffier methods. This proposal develops a general ""neat"" framework for such modern settings by leveraging state of the art developments in two of the most popular subfields of machine learning methods: graphical models and high-dimensional statistical methods. These developments have in common that a complex model parameter is expressed as a superposition of simple components, which is then leveraged for tractable inference and learning.<br/><br/>Our unified framework results not only in a unified picture of these developments but also provides newer methods to work with such high-dimensional data. The research thus impacts problems across science and engineering wherever statistical machine learning approaches are being used (such as genomics, natural language processing and image analysis, to name a few). The work on a unified framework for statistical machine learning problems is highly coupled with a push for imparting training to students on what we call ""comptastical"" thinking. This combines both computational and statistical thinking required for addressing the problems of limited computation and limited data inherent in modern statistical AI application domains. The proposal also develops an infrastructure for component-based courses with relationally organized lecture module components."
"1400784","A Grammar-Based Approach to Visual-Haptic Object Perception","BCS","PERCEPTION, ACTION & COGNITION, Cyber-Human Systems (CHS), ROBUST INTELLIGENCE","09/01/2014","08/14/2014","Robert Jacobs","NY","University of Rochester","Standard Grant","Betty H. Tuller","08/31/2019","$399,049.00","","robbie@bcs.rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","SBE","7252, 7367, 7495","7252, 7367, 7495, 9251","$0.00","People can perceive the shape of objects accurately and reliably but how this occurs is not yet understood. This ability may stem, at least in part, from our use of both visual information and haptic information (information obtained when an object is touched or grasped). Moreover, if we learn to recognize an object based on visual information, we can often recognize the same object when our eyes are closed but we are allowed to grasp it. Similarly, if we learn to recognize an object based on haptic information, we can often recognize the object when we see it but cannot touch it. In other words, we exhibit cross-modal transfer of object shape information. How does information from the eyes and hands link up in the brain to yield a coherent representation of object shape? Insights obtained from this research can contribute both to our understanding of how humans perceive object shape using vision and/or touch and to development of improved robotic and other artificial intelligence systems operating in multi-modal settings in industrial, medical, military, and other applications.<br/><br/>The present project develops a theory of visual-haptic object shape perception in which people's notions of object similarity are not based on sensory features but rather on latent or hidden variables that represent object parts and their spatial relations in an abstract, modality-independent format. Object representations are formalized using a probabilistic ""shape grammar"" with Bayesian inference used to infer grammar-based object representations when an object is viewed, when it is grasped, or both. The model is tested using data obtained from behavioral studies of visual, haptic, and visual-haptic object shape perception by humans. The investigators will explore the types of representational change that underlie the transition from perceptual novice to expert (e.g, radiologists) and will assess whether perceptual expertise is well characterized as category learning, grammar learning, both, or neither. The research program will also develop a large public database of code for re-creating both visual and haptic features of complex objects. This will allow other researchers to fabricate the objects using a 3D printer, enhancing complementarity and comparison across research sites. Finally, training undergraduate and graduate students in the emerging field of computational cognitive science will contribute to a new generation of multidisciplinary scientists working across traditional boundaries between cognitive science and computer science."
"1611742","Teaching Critical Thinking Skills in Science with sInvestigator","DUE","IUSE","10/01/2016","10/06/2016","Gheorghe Tecuci","VA","George Mason University","Standard Grant","R. Corby Hovis","09/30/2019","$300,000.00","James Trefil, Dorin Marcu, Mihai Boicu, Nancy Holincheck","tecuci@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","EHR","1998","8209, 8244, 9178","$0.00","A team of experts from computer science, artificial intelligence, science teaching and pedagogy, systems architecture, software engineering, knowledge engineering and human computer interaction at George Mason University (GMU) is developing a cognitive assistance tool, ""sInvestigator,"" to help students acquire critical thinking skills in addressing scientific problems. The sInvestigator cognitive assistant is a significant technological innovation, based upon a computational theory of reasoning in science. It incorporates a substantial amount of general knowledge about scientific reasoning with evidence guiding and helping the student with the scientific inquiry process. The tool is novel and operates on multiple computer platforms. It is designed for students to use at home and in the lab and supports their acquisition of the core competency of evidence-based reasoning. The resulting theory is extendable to all STEM disciplines both undergraduate and K-12. Broadening participation is achieved through workshops having the capacity of 50-70 participants. Recruiting targets community colleges and minority serving institutions to attract women and underrepresented groups to the workshops organized in collaboration with the GMU Center for Teaching and Faculty Excellence. Evidence based reasoning is at the core of problem solving and decision making not only in STEM disciplines but also law, intelligence analysis, forensics, medicine, history, archeology and other domains. The developed educational materials together with sInvestigator exercises are widely distributed. Information on how teachers and researchers can freely obtain the sInvestigator are posted on GMU's Learning Agents Center website.<br/><br/>The three-year project is first piloted in two Honors courses enrolling 30-40 students. Working in teams, students are guided to approach a scientific problem as ceaseless discovery of evidence, hypothesis and arguments. New knowledge is added by answering research questions that explore improvements in student perception of science process skills and gains in student content knowledge, as measured by course assessments. Students experience numerous opportunities to exercise imagination and creativity and acquire critical scientific practices, particularly: (1) Asking questions; (2) Constructing explanations; (3) Engaging in argument from evidence; and (4) Obtaining, evaluating and communicating explanations (NRC, 2012 p.3). The use of sInvestigator is explored in a sequence of courses to learn what works and what does not work and incrementally evolve the theory and the approach while developing and testing case studies. The mixed-methods evaluation is mostly formative with a focus on understanding students' collaborative experiences with sInvestigator through surveys and interviews. Modification of assessment tools is made based upon evaluation which allows for analysis of student intrinsic motivation, career motivation, self-determination, self-efficacy and grade motivation. In the final year a quasi-experimental research design will be used to evaluate the impact of sInvestigator in a general science course with 250-300 students in two course sections. The design allows for a comparison group on student achievement scores using course assessments, a Science Motivation Questionnaire and a Science Process skills inventory."
"1655300","Discovering Hierarchical Representations for Action Understanding","BCS","GVF - Global Venture Fund, PERCEPTION, ACTION & COGNITION","08/01/2017","04/05/2017","Hongjing Lu","CA","University of California-Los Angeles","Standard Grant","Betty H. Tuller","07/31/2020","$555,792.00","","hongjing@ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","SBE","054Y, 7252","5946, 5980, 7252","$0.00","A major issue in the psychological sciences is understanding how people can infer the intentions of others. Humans are remarkably adept at predicting the actions of other people and making inferences about their intention and goals. The present investigation examines how humans make such inferences from the physical movements of others. The work is guided by a computational theory of biological motion understanding that quantifies what aspects of actions allow observers to make inferences about the meaning of actions and what might come next. The larger goal is to explain how perception and reasoning operate synergistically to infer hidden goals and intentions. These findings will guide development of the next generation of intelligent machine-vision systems, useful in forensic sciences as well as many other real-world applications. Such systems will need to perform challenging tasks that currently are difficult and time-consuming for humans (for example, automated interpretation of human actions recorded in low-resolution surveillance video). The project will also help to identify individual differences in action understanding, potentially revealing the nature of the impairments in action understanding observed in people with autism disorder. In addition, the project will provide a unique training opportunity for students who are interested in interdisciplinary research at the interface between cognitive science and artificial intelligence and will provide an in-depth international research experience for a graduate student and postdoctoral fellow.<br/><br/>The research will integrate advanced psychophysical methods with sophisticated computational approaches. A key aim is to develop a unified theory based on a hierarchical non-parametric Bayesian framework, specifying the fundamental computational mechanisms involved in perception of human actions and reasoning about them. More generally, the project will use human body movements as an underutilized approach to understanding general problems in learning: how to construct, use and transform hierarchical representations to support human perception and cognition. Three aims are particularly noteworthy. First, the project will integrate computational modeling approaches with behavioral experiments to investigate the critical connection between perceptual and cognitive systems. Second, the project uses action stimuli derived from motion capture data in the real world as the visual input (CCTV images collected in the UK and secured at the University of Glasgow). By avoiding the limitations of studies that use restricted examples and constrained environments, the investigators maximize the likelihood that the findings will generalize to real-world situations. Third, the project will develop significant extensions of Bayesian approaches in order to study complex visual processes by combining generative models with probabilistic constraints.  This award is co-funded by the Perception, Action, and Cognition Program and the Office of International Science and Engineering."
"1750101","CAREER: Machine Learning Assisted Crowdsourcing for Phishing Defense","CNS","Secure &Trustworthy Cyberspace","06/01/2018","04/11/2018","Gang Wang","VA","Virginia Polytechnic Institute and State University","Continuing grant","Dan Cosley","05/31/2023","$92,425.00","","gangwang@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","8060","025Z, 1045, 7434","$0.00","This project aims to address the growing threat of phishing attacks, messages that try to trick people into revealing sensitive information, by combining human and machine intelligence. Existing detection methods based on machine learning and blacklists are both brittle to new attacks and somewhat lenient, in order to avoid blocking legitimate messages; as a result, widely used email systems are vulnerable to carefully crafted phishing emails. To address this, the project team will develop systems that automatically block obvious scams while forwarding less certain cases to groups of crowd workers trained to detect phishing mails. To support these workers' decision-making, the team will develop novel explanations of the system's decision making that will highlight the aspects of both the message and its algorithm that triggered the need for human judgment. The system will also aggregate these crowd decisions to generate real-time phishing alerts that can be shared to both individual users and to email systems. The project will lead to advances in interpretable machine learning, an important topic given the increasing role that artificial intelligence and machine learning systems play in society, and also increase our ability to characterize the evolution of phishing attacks and the vulnerability of internet platforms and users to those attacks over time. The project team will also use the work as an important component of new courses on usable security and outreach programs to high school teachers and students to both educate them about and increase their participation in cybersecurity research.<br/><br/>The work is organized around three main objectives: empirical characterization of phishing risks, developing accurate and interpretable machine learning models for phishing detection, and developing reliable crowdsourcing systems for phishing alerts. The team will assess phishing risks through developing analytics tools on the effective adoption and configuration of anti-spoofing protocols in email systems, using adversarial machine learning methods to conduct black box testing on existing phishing detectors, and creating reactive honeypots that entice and respond to phishing attacks in order to collect data on not just the initial phishing emails but on attackers' behaviors throughout the course of a successful phishing attack. The data collected on phishing emails will be used to develop the machine learning models, using Convolutional Neural Network and Long Short-Term Memory based deep learning techniques to generate both suspicious features and confidence estimates of individual decisions. The suspicious features will be used to generate interpretable security cues such as text annotations or icons by first creating simpler and more interpretable machine learning models such as decision trees that mimic the local detection boundary near the target emails in the feature space. Rules in the decision tree will be mapped back to interface elements and email content to provide the warnings, and these will be compared to generic email security warnings in a series of user studies that also model people's ability to detect phishing using a variety of cues, features, and media. Those individual models, along with the confidence estimates from the phishing detection model, will then be used to drive a crowdsourcing-based system where the models of individual users' quality will be aggregated to make reliable judgments around emails the models judge as too suspicious to pass but not suspicious enough to automatically filter.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1725447","SPX: Collaborative Research: Ula! - An Integrated Deep Neural Network (DNN) Acceleration Framework with Enhanced Unsupervised Learning Capability","CCF","SPX: Scalable Parallelism in t","09/01/2017","07/22/2017","Yuan Xie","CA","University of California-Santa Barbara","Standard Grant","Anindya Banerjee","08/31/2021","$280,000.00","","yuanxie@ece.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","CSE","042Y","026Z","$0.00","In light of very recent revolutions of unsupervised learning algorithms (e.g., generative adversarial networks and dual-learning) and the emergence of their applications, three PIs/co-PI from Duke and UCSB form a team to design Ula! - an integrated DNN acceleration framework with enhanced unsupervised learning capability. The project revolutionizes the DNN research by introducing an integrated unsupervised learning computation framework with three vertically-integrated components from the aspects of software (algorithm), hardware (computing), and application (realization). The project echoes the call from the BRAIN Initiative (2013) and the Nanotechnology-Inspired Grand Challenge for Future Computing (2015) from the White House. The research outcomes will benefit both Computational Intelligence (CI) and Computer Architecture (CA) industries at large by introducing a synergy between computing paradigm and artificial intelligence (AI). The corresponding education components enhance existing curricula and pedagogy by introducing interdisciplinary modules on the software/hardware co-design for AI with creative teaching practices, and give special attentions to women and underrepresented minority groups.<br/><br/>The project performs three tasks: (1) At the software level, a generalized hierarchical decision-making (GHDM) system is designed to efficiently execute the state-of-the-art unsupervised learning and reinforcement learning processes with substantially reduced computation cost; (2) At the hardware level, a novel DNN computing paradigm is designed with enhanced unsupervised learning supports, based on the novelties in near data computing, GPU architecture, and FGPA + heterogeneous platforms; (3) At the application level, the usage of Ula! is exploited in scenarios that can greatly benefit from unsupervised learning and reinforcement learning. The developed techniques are also demonstrated and evaluated on three representative computing platforms: GPU, FPGA, and emerging nanoscale computing systems, respectively."
"1629559","XPS: FULL: Broad-Purpose, Aggressively Asynchronous and Theoretically Sound Parallel Large-scale Machine Learning","CCF","Exploiting Parallel&Scalabilty","09/01/2016","02/06/2018","Eric Xing","PA","Carnegie-Mellon University","Standard Grant","Aidong Zhang","08/31/2020","$625,379.00","Garth Gibson","epxing@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","8283","","$0.00","Many artificial intelligence (AI) applications such as image understanding and natural language processing rely on Machine Learning (ML) methods to automatically extract valuable knowledge from Big Data (Big Learning). Efficient ML requires not only expertise in advanced mathematical models and algorithms, but also experiences with large computer clusters where issues such as machine failures, memory/network bottlenecks, inter-machine latencies must be properly handled through complex system programming. Such demand on ""dual skill"" often prevents democratizing large-scale AI to wide user communities, and necessitates a new framework that bridges ML and the distributed computing environment of a cluster with a single-machine-like simple interface, allowing ML practitioners to be agnostic about the backend details, and able to quickly prototype or deploy ML programs on clusters. Solutions to such a need remain rare. In this project the PIs develop a new general purpose framework for ML on distributed systems, offering highly efficient and theoretically justified protocols (e.g. communication, scheduling, and partitioning functions) to orchestrate a heterogeneous computer cluster to become programmable and act like a single big computer, and execute distributed ML programs correctly and at a speed orders of magnitude faster than current systems such as Hadoop and Spark. With this new framework, data scientists will be able to conduct ML analytics with complex models on massive data without the need for dedicated engineering and infrastructure teams, allowing Big Learning more readily accessible to society.<br/> <br/>Specifically, over a four year span, the proposed research focuses on three technical aims: (1) Building a System Framework for Big Learning, by developing a new architecture that supports both data- and model-parallel execution of large ML programs, using intelligent scheduler, parameter server, and consistency controller that are configurable to provide flexible options for model/data parallelization, synchronization schemes, load balance, fault tolerance, and multi-instance tenancy; (2) Building a Multi-Level-Abstraction Programming Interface, which supports easy parallel programming of both basic and advanced ML algorithms for large-scale applications; and (3)Conducting theoretical analysis of distributed ML algorithms on the proposed system, based on unique insights such as block consistency and error-tolerance under bounded synchronism. The goal is to develop a system framework to achieve general, automatic, and effective parallelization of ML programs."
"1607486","US-German Research Proposal: Neurocomputation in the Visual Periphery: Experiments and Models","IIS","CRCNS, ROBUST INTELLIGENCE","12/01/2016","09/19/2017","Ruth Rosenholtz","MA","Massachusetts Institute of Technology","Continuing grant","Kenneth C. Whang","11/30/2019","$681,746.00","","rruth@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7327, 7495","7327, 8089, 8091","$0.00","Peripheral vision comprises over 99.99% of the visual field. Its strengths and limitations strongly constrain visual perception -- what humans can see at a glance, and the processes by which they move their eyes to piece together information about the world. Peripheral vision differs from foveal vision in complex and interesting ways, most importantly due to ""crowding,"" in which identifying a peripheral stimulus can be substantially impaired by the presence of other, nearby stimuli. This project will examine the nature of the encoding in visual cortex, through development and testing of a set of models of peripheral vision. These models will be targeted at answering key questions about the neurobiological mechanisms. The collaborating investigators, in the US and Germany, will develop models and create a benchmark dataset of behavioral results to be explained. The models and dataset will be made freely available, to aid other researchers and to inform the development of applications such as heads up displays and user interfaces. This work will provide insight into what features are encoded in visual cortex, as well as what tradeoffs may have led the visual system to develop that encoding. Understanding those tradeoffs may inform computer vision which, like human vision, faces constraints on processing capacity. <br/><br/>The development of new model variants will be based on insights from neurophysiology, natural image statistics, sparse coding, and the recent success of convolutional neural networks in artificial intelligence. The investigators will gather benchmark behavioral phenomena far richer than existing crowding datasets, through a combination of studying natural image tasks and model-driven experiments. They will then compare predictions of the new models, as well as of Dr. Rosenholtz's existing high-performing model of peripheral vision, on the benchmark dataset. Doing so will identify the best-performing model(s), and answer key questions about the nature of pooling computations and of non-linear operators, and about the complexity, nature, and purpose of the features encoded by peripheral vision.<br/><br/>A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF)."
"1551866","CompCog: The edge of the lexicon: Productive knowledge and direct experience in the acquisition and processing of multiword expressions","BCS","LINGUISTICS, PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","08/15/2016","08/22/2016","Roger Levy","MA","Massachusetts Institute of Technology","Standard Grant","William J. Badecker","01/31/2020","$329,233.00","","rplevy@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","SBE","1311, 7252, 7495","1311, 7252, 7495, 9179","$0.00","Language is the most discrete, measurable cultural record of the human mind, and is uniquely expressive among the communicative systems found in nature. Every day we comprehend hundreds of sentences that we hear or read but have never encountered before, and we produce hundreds more. Yet our success at these many acts of communication belies the difficulty of the task: language is rife with ambiguity, our attention is limited, our environments may be noisy, and we often have incomplete information about the shared knowledge and beliefs of the people we engage with. This ability, unique to our species, poses profound challenges for our scientific understanding of the capabilities of the human mind.  Deepening our understanding of these capabilities requires a combination of ideas and methods from linguistics, psychology, and computer science. Advances in this area help lay the groundwork for improvements in natural language technologies such as document summarization, paraphrasing, question answering, and machine translation, and in better identification, diagnosis, and treatment of language disorders.<br/><br/>Within this broader research enterprise, this project focuses on the ""edge of the lexicon"", elucidating the conditions under which a linguistic expression begins to get stored in the mind of the native speaker who uses it, and the consequences of the expression being stored as a holistic unit. Native speakers know both productive rules that license and allow interpretation of phrases and sentences that they have never before encountered and a rich inventory of lexical items that can be combined through these productive rules. Many of these lexical items are individual words, but there is evidence that specific, frequent multi-word expressions, such as ""meat and potatoes"" or ""large majority"" may also get stored in the lexicon. This project combines artificial intelligence-based computational models, large linguistic datasets, and controlled psychological experimentation to explore the edge of the lexicon, probing how direct experience with specific multi-word expressions leads to their being stored in one's mental lexicon, how such storage is reconciled with productive knowledge in language comprehension and production, and how these expressions emerge and change over time."
"1725456","SPX: Collaborative Research: Ula! - An Integrated Deep Neural Network (DNN) Acceleration Framework with Enhanced Unsupervised Learning Capability","CCF","SPX: Scalable Parallelism in t","09/01/2017","07/22/2017","Yiran Chen","NC","Duke University","Standard Grant","Yuanyuan Yang","08/31/2021","$520,000.00","Hai Li","yiran.chen@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","042Y","026Z","$0.00","In light of very recent revolutions of unsupervised learning algorithms (e.g., generative adversarial networks and dual-learning) and the emergence of their applications, three PIs/co-PI from Duke and UCSB form a team to design Ula! - an integrated DNN acceleration framework with enhanced unsupervised learning capability. The project revolutionizes the DNN research by introducing an integrated unsupervised learning computation framework with three vertically-integrated components from the aspects of software (algorithm), hardware (computing), and application (realization). The project echoes the call from the BRAIN Initiative (2013) and the Nanotechnology-Inspired Grand Challenge for Future Computing (2015) from the White House. The research outcomes will benefit both Computational Intelligence (CI) and Computer Architecture (CA) industries at large by introducing a synergy between computing paradigm and artificial intelligence (AI). The corresponding education components enhance existing curricula and pedagogy by introducing interdisciplinary modules on the software/hardware co-design for AI with creative teaching practices, and give special attentions to women and underrepresented minority groups.<br/><br/>The project performs three tasks: (1) At the software level, a generalized hierarchical decision-making (GHDM) system is designed to efficiently execute the state-of-the-art unsupervised learning and reinforcement learning processes with substantially reduced computation cost; (2) At the hardware level, a novel DNN computing paradigm is designed with enhanced unsupervised learning supports, based on the novelties in near data computing, GPU architecture, and FGPA + heterogeneous platforms; (3) At the application level, the usage of Ula! is exploited in scenarios that can greatly benefit from unsupervised learning and reinforcement learning. The developed techniques are also demonstrated and evaluated on three representative computing platforms: GPU, FPGA, and emerging nanoscale computing systems, respectively."
"1841099","Community-Building Workshop on Programmable System Security in a Software-Defined World","CNS","Computer Systems Research (CSR","08/01/2018","08/06/2018","Guofei Gu","TX","Texas A&M Engineering Experiment Station","Standard Grant","Samee Khan","07/31/2019","$1,485.00","","guofei@cse.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","CSE","7354","073Z, 7556","$0.00","This workshop brings together networking, systems, and security researchers to discuss and establish a vision for programmable security in modern software-defined infrastructures (e.g., cloud, Internet-of-Things, or edge computing environments). The output of the workshop will be a public report documenting the discussions and a set of recommendations on research directions and frontiers. The workshop and the report will stimulate research collaboration and the creation of a common research vision between disparate communities.<br/><br/>We increasingly live in a software-defined world where systems that were once implemented as rigid control systems or fixed-function hardware systems are now highly programmable through software interfaces that decouple underlying hardware details and offer remote control and centralized management. Early examples of software-defined systems (SD-X) include multi-tenant clouds, software-defined networking (SDN), network functions virtualization (NFV), software-defined infrastructure (SDI), and software-defined radios (SDR). While SD-X technologies have rapidly proliferated within industry and received considerable systems research attention, the paradigm has not been fully exploited in approaching a wide array of important security challenges. The objective of this workshop is to identify those research challenges and opportunities to exploit SD-X approaches in making system security more programmable, agile, orchestrated, and intelligent.  This workshop creates a much-needed opportunity for a cross-cutting group of researchers to fill out the vision of what programmable security based on SD-X could be, including research challenges, long-term visions, and key issues. In the process, this workshop will promote a more focused community and vision where traditionally disparate communities previously worked in isolation and without a more ambitious system security vision within the context of complex software-defined infrastructures.  The workshop report will be made available to the public via the workshop website.<br/> <br/>Broad directions to be considered by the workshop attendees include, but are not limited to: (1) new abstractions for data/control planes aimed specifically at security, (2) new architectures that integrate diverse SD-X domains (networking, processing, storage, etc.) for a more powerful and comprehensive security framework, (3) new programming and language paradigms for programmable security, (4) a better understanding of attack surfaces and adversarial methods within modern software-defined infrastructures, (5) new formal and experimental methodologies for reasoning about software-defined security, (6) the integration of emerging Artificial Intelligence/Machine Learning and data-driven capabilities into programmable system security, (7) new applications paradigms that exploit programmable paradigms in innovative ways, and (8) the application of programmable security approaches to emerging platforms and infrastructure domains. Overall, workshop participants will help to build community and define the vision of a new generation of security technologies in the rapidly expanding world of software-defined infrastructures and devices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1823366","CRI: CI-NEW: Trainable Reconfigurable Development Platform for Large-Scale Neuromorpic Cognitive Computing","CNS","COMPUTING RES INFRASTRUCTURE","08/01/2018","07/03/2018","Gert Cauwenberghs","CA","University of California-San Diego","Standard Grant","Sankar Basu","07/31/2021","$1,500,000.00","Emre Neftci, Amitava Majumdar","gert@ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","CSE","7359","7359","$0.00","Neuromorphic cognitive computing aims at learning to solve complex cognitive tasks by emulating the principles and physical organization of highly efficient and resilient adaptive information processing in the biological brain.  Despite over 30 years of development and a recent surge of broad interest across all Science, Technology, Engineering and Mathematics (STEM) disciplines, access to neuromorphic cognitive computing remains mostly limited to a small community of highly trained researchers in the field due to high entry barriers and costs associated with the specialized nature and complex operation of currently available systems.  This project will construct and support a general-purpose neuromorphic cognitive computing platform that will be the largest and most versatile realized to date as well as the first to be broadly available and open to the research community at large, for research into new forms of brain-inspired computing that are more effective and more efficient in approaching the cognitive capabilities of the human mind.  Targeting wide adoption by a diverse cross-section of users in the broader STEM research community, the platform will feature a natural user interface that shields novice users from the challenges arising in operating and configuring highly specialized neuromorphic hardware, by providing a set of user-friendly software tools maintained by and shared with the user community.  Building on extensive existing network and storage infrastructure for user access and data sharing at the San Diego Supercomputer Center, the platform will be hosted and maintained through the Neuroscience Gateway (NSG) Portal, which currently serves over 600 active users in the scientific community.<br/><br/>The large-scale neuromorphic platform will serve as a new and unparalleled resource to the Computer and Information Science and Engineering (CISE) research community, addressing a great need for an experimental testbed for research in alternative forms of computing beyond the traditional von Neumann paradigm and the impending physical limits to Moore's Law expansion in the scaling of computing technology.  The reconfigurable platform will feature a hierarchically interconnected network of in-memory computing processing nodes that emulates, in real-time, highly flexible neural dynamics (integrate-and-fire, graded, stochastic binary, etc) of up to 128 million neurons with high flexible connectivity and plasticity (spike-timing dependent plasticity, gradient-based deep learning, etc) of up to 32 billion synapses.  The system will be capable of biophysical detail in computational neuroscience modeling, as well as high performance and efficiency in on-line adaptive pattern recognition, serving and bringing together both computational neuroscience and computational intelligence communities that have traditionally pursued disparate computational approaches.  The user interface of the platform will support software tools and resources for deep learning and run-time optimization in artificial intelligence applications, and for interference of structure and functional connectivity from recorded neural activity in computational neuroscience research, among others.  To facilitate greatest scientific and societal impact, the infrastructure will be made available free of charge, on a time-managed shared basis, to any researcher in return for agreeing to share source code and data necessary to replicate results reported in the literature.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1620022","Collaborative Research:   Algorithms for Large-Scale Stochastic and Nonlinear Optimization","DMS","OE Operations Engineering, COMPUTATIONAL MATHEMATICS","08/01/2016","06/17/2016","Jorge Nocedal","IL","Northwestern University","Standard Grant","Leland M. Jameson","07/31/2019","$270,000.00","","nocedal@eecs.northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","MPS","006Y, 1271","071E, 072E, 073E, 077E, 078E, 9102, 9263","$0.00","The promise of artificial intelligence has been a topic of both public and private interest for decades. Starting in the 1990s the field has been benefited from the rapidly evolving and expanding field of machine learning. The intelligent systems that have been borne out of machine learning, such as search engines, recommendation platforms, and speech and image recognition software, have become an indispensable part of modern society.  Rooted in statistics and relying heavily on the efficiency of numerical algorithms, machine learning techniques capitalize on increasingly powerful computing platforms and the availability of very large datasets.  One of the pillars of machine learning is mathematical optimization, which, in this context, involves the computation of parameters for a system designed to make decisions based on yet unseen data. The goal of this project is to develop new optimization algorithms that will enable the continuing rise of the field of machine learning.<br/>  <br/>The research consists of two projects, which are thematically related and address the solution of optimization problems that are nonlinear, high dimensional, stochastic, involve very large data sets and in some cases are non-convex. Two families of algorithms will be developed to garner the benefits of both stochastic gradient methods and batch methods, while avoiding their shortcomings. One of these algorithms uses a gradient aggregation approach that re-uses gradient values computed at previous iterations. The challenge is to design an algorithm that is efficient in minimizing testing error, not just training error. The second approach employs adaptive sampling techniques to reduce the noise in stochastic gradient approximations as the optimization progresses. An important aspect of this research is the design of an efficient strategy for incorporating second-order information that captures curvature of the optimized loss function, even in the case when Hessian estimates are based on inaccurate gradients. In all cases, the goal is research is to design and implement algorithms in software, and test them on realistic machine learning applications."
"1820415","SBIR Phase I:  Virtual Music helper, next-generation educational social platform for conservatory music practice and performance empowered by AI and AR","IIP","SMALL BUSINESS PHASE I","07/01/2018","06/19/2018","Melody Fallah-Khair","CA","eBibelot Inc","Standard Grant","Rajesh Mehta","12/31/2018","$225,000.00","","melody@ebibelot.com","11955 Walbrook Dr.","saratoga","CA","950703450","6507049457","ENG","5371","5371, 8031, 8032","$0.00","This SBIR Phase I project focuses on development of a prototype for a Virtual Music Helper (VMH) for children. Research confirms that music and music learning enhances intelligence, learning and IQ specially in kids. Even children with attention deficit/ hyperactivity disorder benefit from listening to music beforehand in mathematics tests. Children who learn or practice music have shown better results in STEM subjects. However, studies also suggest children opt out of music class based on false belief that they lack musical ability and many kids often find the music practice non-engaging, and boring eventually losing interest and quitting. Parents find it challenging to entice the kids to sit down and practice or they cannot help their kids because either they don?t have time or are not music savvy themselves to help them. The virtual music helper can read the kids? music homework, guide them through the exercise and provide immediate correction. This helper is not to replace teachers, but help the parents at home and encourage kids to practice more. In broader terms this project may spur significant research in finding effective methods for tutoring kids in subjects other than music such as math or language, or for kids with special needs.<br/><br/><br/>This SBIR Phase I project proposes a Virtual Music Helper (VMH) that is empowered by Artificial Intelligence and Augmented Reality for kids. VMH is a 3D mobile-virtual-human (avatar) that can be personalized for each kid and conduct live dialog with kids both from visual and behavioral perspectives. VHM offers smart content for teachers about each student's progress and weak points. The technical challenges this project will address is the detection and correction of mistakes kids make including polyphonic pitch detection from acoustic instrument, conversion of note sheets to machine readable music format with high accuracy and speed, empowering the avatar with decision making algorithms to provide proper correction and feedback verbally and visually. This platform is also intended to support multiple popular instruments and multiple languages.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1524565","Comp Cog:  Collaborative Research on the Development of Visual Object Recognition","BCS","DS - Developmental Sciences, PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","08/01/2015","09/02/2016","James Rehg","GA","Georgia Tech Research Corporation","Continuing grant","Chalandra Bryant","07/31/2019","$313,582.00","Fuxin Li, Maithilee Kunda","rehg@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","SBE","1698, 7252, 7495","1698, 7252, 7298, 7495, 9179","$0.00","Human visual object recognition is fast and robust.  People can recognize a large number of visual objects in complex scenes, from varied views, and in less than optimal circumstances.  This ability underlies many advanced human skills, including tool use, reading, and navigation.  Artificial intelligence devices do not yet approach the level of skill of everyday human object recognition. This project will address one gap in current knowledge, an understanding of the visual experiences that allow skilled object recognition to develop, by capturing and analyzing the visual experiences of 1- to 2-year-old toddlers.  This is a key period for understanding human visual object recognition because it is the time when toddlers learn a large number of object categories, when they learn the names for those objects, and when they instrumentally act on and use objects as tools.  Two-year-old children, unlike computer vision systems, rapidly learn to recognize many visual objects.  This project seeks to understand how the training experiences (everyday object viewing) of toddlers may be optimal for building robust visual object recognition. The project aims to (1) understand the visual and statistical regularities in 1- to 2-year-old children's experiences of common objects (e.g., cups, chairs, trucks, dogs) and (2) determine whether a training regimen like that experienced by human toddlers supports visual object recognition by state-of-the art machine vision. <br/><br/>Considerable progress in understanding adult vision has been made by studying the visual statistics of ""natural scenes."" However, there is concern about possible artifacts in these scenes because they typically photographs taken by adults and thus potentially biased by the already developed mature visual system that holds the camera and frames the pictures. Also, photographed scenes differ systematically from the scenes sampled by people as they move about and act in the world.  Accordingly, there is increased interest in egocentric views collected from body-worn cameras, the method used in the present work.  Toddlers will wear lightweight head cameras as they go about their daily activities, allowing the investigators to capture the objects the toddlers see and the perspectives and contexts in which they see them.  The research will analyze the frequency, views, visual properties, and range of seen objects for the first 100 object names normatively learned by young children, providing a first description of the early learning environment for human visual object recognition.  These toddler-perspective scenes  will be used as inputs to machine learning models to better understand how the visual information in the scenes supports and constrains the development of visual object recognition. Machine-learning experiments will determine which properties and statistical regularities are most critical for learning to recognize common object categories in multiple scene contexts.  Data collected will be shared through Databrary, an open data library for developmental science."
"1838124","BIGDATA: F: Collaborative Research: Mining for Patterns in Graphs and High-Dimensional Data: Achieving the Limits","IIS","Big Data Science &Engineering","10/01/2018","09/10/2018","Jiaming Xu","IN","Purdue University","Standard Grant","frank olken","09/30/2021","$345,168.00","","jx77@duke.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","8083","062Z, 8083","$0.00","While modern datasets are very large, the amount of information per variable is often relatively small. This includes datasets from genomics, social networks, and many applications in machine learning and artificial intelligence. For instance, in genomics we often track hundreds of thousands of genes, but only have a few hundred independent samples for each one. Similarly, online social networks are massive, but the structure of friendships only gives us a relatively small amount of data per individual. This kind of data is called ""high-dimensional"", and poses new challenges for mathematics, statistics, and computer science, especially when (as with all real data) they are noisy or incomplete. This project will identify exactly when and how it is mathematically possible to find patterns in these massive but noisy datasets, giving scientists across many fields a useful guide to how much data they need to draw reliable conclusions, and to develop new algorithms that will solve modern data science problems efficiently and optimally.<br/><br/>Through the study of community detection, noisy graph isomorphism, and matrix/tensor factorization, this project will develop a general framework to 1) locate the information-theoretic limit below which the observation is too noisy to detect the underlying pattern, or even to tell if a pattern exists; 2) devise efficient algorithms that succeed all the way down to the lowest possible signal-to-noise ratio; 3) prove that important classes of algorithms need super-polynomial time in certain hard regimes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1526431","III: Small: Collaborative Research: Adaptive Integration of Textual and Geospatial Information for Mining Massive Map Collections","IIS","INFO INTEGRATION & INFORMATICS","09/01/2015","08/18/2015","Erik Learned-Miller","MA","University of Massachusetts Amherst","Standard Grant","Maria Zemankova","08/31/2019","$297,859.00","","elm@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","7364","7364, 7923","$0.00","Libraries and archives are digitizing historical maps for widespread online access. Without technology for searching them, large map collections relevant to a given problem or question may remain obscure even in online archives. If all of the text in a map can be read automatically by computer, a wealth of information becomes quickly available -- location names, geographic features, and often statistics. This project will increase capacity for search and analysis of historical maps by automatically recognizing place names and other text in these digitized artifacts while simultaneously aligning them with modern geography. The improvements this project will make to current text recognition methods will facilitate more powerful uses of humanity's trove of old maps -- for example, by allowing scientists and policymakers to establish changes in land usage, waterways, or borders over time. By creating free, open-source tools for studying historical maps, this project will increase public engagement with science and technology and empower any Internet user to explore the intersection of technology and history. This research will train a diverse group of graduate and undergraduate students in constructing, learning, and making predictions with adaptive models featuring heterogeneous yet highly interdependent entities.<br/><br/>Although many institutions are digitizing hundreds of thousands of historical maps, most digitized map images are poorly annotated, limiting their usefulness. Manual annotation and metadata association is highly laborious. This project's primary objectives are (1) to fully automate text and shape-based georeferencing (aligning map images to the known global geography) while (2) indexing words and place names (for search) by enhancing text detection and recognition methods in these complex artifacts. These innovations will address the shortcomings of manual georeferencing and current automated text recognition algorithms. The researchers will employ an iterative interpretation process for solving problems including text/graphics separation, text recognition, and georeferencing. For example, the fact that all members of a given class of text entities on a map (e.g., county names) are typically rendered in the same text style can be used to inform predictions about difficult members of the category with information derived from more easily-recognized members. The researchers will use a dataset of annotated maps containing over 12,000 words in 9,000 place names as benchmark data for testing the algorithms developed in the project. Software, data, and benchmarks will be broadly distributed on the project website (http://www.cs.grinnell.edu/~weinman/research/maps.shtml). Findings will be shared with the research community through journals and conferences in the computer vision, artificial intelligence, and GIS communities."
"1838251","BIGDATA: F: Collaborative Research: Mining for Patterns in Graphs and High-Dimensional Data: Achieving the Limits","IIS","Big Data Science &Engineering","10/01/2018","09/10/2018","Cristopher Moore","NM","Santa Fe Institute","Standard Grant","frank olken","09/30/2021","$737,645.00","","moore@santafe.edu","1399 HYDE PARK ROAD","SANTA FE","NM","875018943","5059462727","CSE","8083","062Z, 8083","$0.00","While modern datasets are very large, the amount of information per variable is often relatively small. This includes datasets from genomics, social networks, and many applications in machine learning and artificial intelligence. For instance, in genomics we often track hundreds of thousands of genes, but only have a few hundred independent samples for each one. Similarly, online social networks are massive, but the structure of friendships only gives us a relatively small amount of data per individual. This kind of data is called ""high-dimensional"", and poses new challenges for mathematics, statistics, and computer science, especially when (as with all real data) they are noisy or incomplete. This project will identify exactly when and how it is mathematically possible to find patterns in these massive but noisy datasets, giving scientists across many fields a useful guide to how much data they need to draw reliable conclusions, and to develop new algorithms that will solve modern data science problems efficiently and optimally.<br/><br/>Through the study of community detection, noisy graph isomorphism, and matrix/tensor factorization, this project will develop a general framework to 1) locate the information-theoretic limit below which the observation is too noisy to detect the underlying pattern, or even to tell if a pattern exists; 2) devise efficient algorithms that succeed all the way down to the lowest possible signal-to-noise ratio; 3) prove that important classes of algorithms need super-polynomial time in certain hard regimes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822929","CRCNS Research Proposal: Collaborative Research: Evaluating Machine Learning Architectures Using a Massive Benchmark Dataset of Brain Responses to Natural Scenes","IIS","CRCNS, IntgStrat Undst Neurl&Cogn Sys","10/01/2018","09/10/2018","Thomas Naselaris","SC","Medical University of South Carolina","Standard Grant","Kenneth C. Whang","09/30/2021","$422,619.00","Kendrick Kay","tnaselar@musc.edu","171 ASHLEY AVE","CHARLESTON","SC","294258908","8437923838","CSE","7327, 8624","7327, 8089, 8091, 9150","$0.00","Machine learning technologies have the potential to radically transform the study of the human brain, but require far more data than is typically collected during conventional neuroscience experiments. The goal of this project is to drive the application of ML techniques to neuroscience research by generating a massive dataset of brain responses from the human visual system. The resulting dataset will be freely available to scientists, educators, and students. Through a yearly modeling competition, neuroscientists will gain experience in the application of advanced computational methods and ML researchers will gain a deeper understanding of the challenges and complexities of the human brain. Results of the modeling competition will be presented at an annual conference attended by both machine learning and neuroscience researchers and students, providing an opportunity for the two groups to interact and discuss approaches. This project will foster open collaboration between neuroscientists and artificial intelligence researchers and a culture of sharing data, ideas, and progress. <br/><br/>The long-term goal of this work is to generate data that will lead to the development of experimentally validated and computationally powerful models of the human visual system. The project leaders will use high-field (7 Tesla) functional magnetic resonance imaging (fMRI) to measure brain responses to a broad sampling of natural images in human observers. The specific objectives are as follows: (1) Acquire, pre-process, and distribute a massive, high-resolution fMRI dataset that exploits state-of-the-art imaging techniques. The dataset will include multiple samples of brain responses to roughly eighty thousand photographs drawn from an image collection that is widely used by the ML community. (2) Establish and host an annual competition for modeling this rich dataset at the conference on Cognitive Computational Neuroscience. (3) Bridge the gap between ML architectures and the human brain by testing new ML-inspired architectures as models of the visual system. The project leaders will focus specifically on recent developments in ML that suggest new hypotheses about the dorsal visual stream.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1526350","III: Small: Collaborative Research: RUI: Adaptive Integration of Textual and Geospatial Information for Mining Massive Map Collections","IIS","INFO INTEGRATION & INFORMATICS, EPSCoR Co-Funding","09/01/2015","08/18/2015","Jerod Weinman","IA","Grinnell College","Standard Grant","Maria Zemankova","08/31/2019","$202,140.00","","jerod@acm.org","1121 Park Street","Grinnell","IA","501121690","6412694983","CSE","7364, 9150","7364, 7923, 9150, 9229","$0.00","Libraries and archives are digitizing historical maps for widespread online access. Without technology for searching them, large map collections relevant to a given problem or question may remain obscure even in online archives. If all of the text in a map can be read automatically by computer, a wealth of information becomes quickly available -- location names, geographic features, and often statistics. This project will increase capacity for search and analysis of historical maps by automatically recognizing place names and other text in these digitized artifacts while simultaneously aligning them with modern geography. The improvements this project will make to current text recognition methods will facilitate more powerful uses of humanity's trove of old maps -- for example, by allowing scientists and policymakers to establish changes in land usage, waterways, or borders over time. By creating free, open-source tools for studying historical maps, this project will increase public engagement with science and technology and empower any Internet user to explore the intersection of technology and history. This research will train a diverse group of graduate and undergraduate students in constructing, learning, and making predictions with adaptive models featuring heterogeneous yet highly interdependent entities.<br/><br/>Although many institutions are digitizing hundreds of thousands of historical maps, most digitized map images are poorly annotated, limiting their usefulness. Manual annotation and metadata association is highly laborious. This project's primary objectives are (1) to fully automate text and shape-based georeferencing (aligning map images to the known global geography) while (2) indexing words and place names (for search) by enhancing text detection and recognition methods in these complex artifacts. These innovations will address the shortcomings of manual georeferencing and current automated text recognition algorithms. The researchers will employ an iterative interpretation process for solving problems including text/graphics separation, text recognition, and georeferencing. For example, the fact that all members of a given class of text entities on a map (e.g., county names) are typically rendered in the same text style can be used to inform predictions about difficult members of the category with information derived from more easily-recognized members. The researchers will use a dataset of annotated maps containing over 12,000 words in 9,000 place names as benchmark data for testing the algorithms developed in the project. Software, data, and benchmarks will be broadly distributed on the project website (http://www.cs.grinnell.edu/~weinman/research/maps.shtml). Findings will be shared with the research community through journals and conferences in the computer vision, artificial intelligence, and GIS communities."
"1822683","CRCNS Research Proposal: Collaborative Research: Evaluating Machine Learning Architectures Using a Massive Benchmark Dataset of Brain Responses to Natural Scenes","IIS","CRCNS","10/01/2018","09/10/2018","Kendrick Kay","MN","University of Minnesota-Twin Cities","Standard Grant","Kenneth C. Whang","09/30/2021","$652,405.00","","kay@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7327","7327, 8089, 8091","$0.00","Machine learning technologies have the potential to radically transform the study of the human brain, but require far more data than is typically collected during conventional neuroscience experiments. The goal of this project is to drive the application of ML techniques to neuroscience research by generating a massive dataset of brain responses from the human visual system. The resulting dataset will be freely available to scientists, educators, and students. Through a yearly modeling competition, neuroscientists will gain experience in the application of advanced computational methods and ML researchers will gain a deeper understanding of the challenges and complexities of the human brain. Results of the modeling competition will be presented at an annual conference attended by both machine learning and neuroscience researchers and students, providing an opportunity for the two groups to interact and discuss approaches. This project will foster open collaboration between neuroscientists and artificial intelligence researchers and a culture of sharing data, ideas, and progress. <br/><br/>The long-term goal of this work is to generate data that will lead to the development of experimentally validated and computationally powerful models of the human visual system. The project leaders will use high-field (7 Tesla) functional magnetic resonance imaging (fMRI) to measure brain responses to a broad sampling of natural images in human observers. The specific objectives are as follows: (1) Acquire, pre-process, and distribute a massive, high-resolution fMRI dataset that exploits state-of-the-art imaging techniques. The dataset will include multiple samples of brain responses to roughly eighty thousand photographs drawn from an image collection that is widely used by the ML community. (2) Establish and host an annual competition for modeling this rich dataset at the conference on Cognitive Computational Neuroscience. (3) Bridge the gap between ML architectures and the human brain by testing new ML-inspired architectures as models of the visual system. The project leaders will focus specifically on recent developments in ML that suggest new hypotheses about the dorsal visual stream.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1633857","BIGDATA: F: Open-World Foundations for Big Uncertain Data","IIS","Big Data Science &Engineering","09/01/2016","09/06/2016","Guy Van den Broeck","CA","University of California-Los Angeles","Standard Grant","Sylvia J. Spengler","08/31/2019","$432,202.00","","guyvdb@cs.ucla.edu","10889 Wilshire Boulevard","LOS ANGELES","CA","900951406","3107940102","CSE","8083","7433, 8083","$0.00","Driven by the need to learn from vast amounts of text data, efforts throughout natural language processing, information extraction, databases, and AI are coming together to build large-scale knowledge bases. These systems continuously crawl the web to extract relational data from text, and have already populated their databases with millions of entities and billions of tuples. Large-scale probabilistic knowledge bases are revolutionizing the way we access data. They are now routinely used by scientists to build knowledge bases of publications, by law enforcement to extract information from the dark web, and by regular search engine users who find their results augmented with structured information. Such knowledge bases are inherently probabilistic: to go from raw text to structured data, a sequence of statistical machine learning techniques associate probabilities with database tuples. This project revisits the semantics underlying such systems, and provide a more adequate foundational framework. In particular, the closed-world assumption of probabilistic databases, that facts not in the database have probability zero, clearly conflicts with their everyday use, and obstructs the progress in this area.<br/><br/>More specifically, this project develops a new semantic foundation based on the open-world assumption, that facts not in the database are possible, but have unknown probability. It designs the basic algorithms for query answering in this setting, both exact and approximate. Moreover, in a deep theoretical component, this project studies fundamental questions of data and domain complexity that are unique to open-world reasoning about big uncertain data. Finally it develops proof-of-concept applications in machine learning and data mining, and additional knowledge-representation layers that strengthen open-world reasoning. The developed semantics provide meaningful answers when some tuple probabilities are not precisely known. The developed algorithms allow for efficient query answering, even when reasoning about the open world, in time linear in the database size for tractable queries. This project provides a scientific leap at the fundamental, semantic level. It also provides a context for training undergraduate and graduate students in subjects spanning databases, artificial intelligence, theory, and machine learning, and will target the integration of probabilistic knowledge bases into computer science curricula."
"1741431","BIGDATA: IA: Distributed Semi-Supervised Training of Deep Models and Its Applications in Video Understanding","IIS","Big Data Science &Engineering","09/01/2017","07/07/2018","Boqing Gong","FL","University of Central Florida","Standard Grant","Aidong Zhang","08/31/2020","$662,431.00","Liqiang Wang, Mubarak Shah","bgong@icsi.berkeley.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","CSE","8083","7433, 8083","$0.00","This project investigates semi-supervised training of deep neural network models using large-scale labeled and unlabeled data in a distributed fashion. Deep neural networks have recently been widely deployed in artificial intelligence and related scientific fields, largely attributing to well-labeled big datasets and improved computing capabilities. However, the unlabeled data, which is often bigger, is inherently ruled out by the prevailing supervised training of the deep models. It is indeed highly challenging to model the unlabeled parts of many recent and emerging datasets, which are often unstructured and distributed over different nodes of a network (e.g., the videos captured by a camera network). This project aims to explore how to effectively use the unlabeled and distributed data to complement the discriminative cues of the labeled data, to jointly learn accurate and robust deep models. The research seamlessly unifies machine learning, computer vision, and parallel computing, and fosters unique interdisciplinary research and education programs for the graduate and undergraduate students.<br/><br/>Despite the progress on semi-supervised learning and deep learning, the confluence of these two is mostly studied on a small scale in single-machine environment. However, many new datasets easily grow beyond the computation or even storage capacity of a single machine. Hence, it becomes a pressing need to investigate the semi-supervised learning of deep models on parallel computing platforms. To better account for this scenario, this project develops improved network architectures to facilitate the parallel training, and the training procedure developed adaptively switches between synchronized and asynchronized modes for optimal efficiency. The main idea is to incorporate a parametric distribution to the neural network and use covariate matching to coordinate the network behaviors across different machines. The researchers also explore a novel application, extreme-scale spatial-temporal action annotation of video sequences, to benchmark the algorithms and frameworks in this project."
"1623124","EXP: Collaborative Research: Extracting Salient Scenarios from Interaction Logs (ESSIL)","IIS","Cyberlearn & Future Learn Tech","09/01/2016","08/26/2016","Barbara Grosz","MA","Harvard University","Standard Grant","Amy Baylor","08/31/2019","$170,000.00","","grosz@eecs.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","8020","8045, 8841","$0.00","The Extracting Salient Scenarios from Interaction Logs (ESSIL) project proposes to develop a new type of educational technology to support students' learning about complex systems from their participation in a multi-person immersive simulation.  Many important challenges we face today as a society -- including responding to climate change, managing global economies, city planning, disease outbreaks -- are ""complex systems"" problems, meaning that important phenomena in each (for instance trends in weather, stock bubbles, traffic jams, disease transmission) result not from a single cause, but because many small causes combine together. Participating in a simulation has the potential to help students understand the principles of complex systems, but because different principles surface depending on how each simulation unfolds, it can be difficult for teachers to adjust their lesson plans on the fly to highlight the principles that emerge in a given simulation run. To address this challenge, ESSIL will develop methods to create ""automatic salient recaps,"" as a way to help learners and their teachers make better sense of simulations. These recaps, which will be automatically generated, provide a story of ""what happened"" in the simulation in a way that both helps students remember their experience and reveals important scientific principles. Teachers and other facilitators will use these recaps, along with an accompanying discussion guide, to support productive learning conversations about the scientific principles incorporated in a simulation. The recaps will be developed for a large-scale immersive simulation installed at the New York Hall of Science (NYSCI), potentially improving the educational experience of thousands of daily visitors.  The capabilities developed to produce them have widespread applicability, because logs of student interactions are routinely produced by many educational systems.  The project is supported by the Cyberlearning and Future Learning Technologies Program, which funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by designing and building new kinds of learning technologies and studying their possibilities for fostering learning and challenges to using them effectively. <br/> <br/>The immersive simulation context for the project is Connected Worlds, an embodied, multi-person ecology simulation at NYSCI, with pedagogical goals around sustainability and systems thinking. Using logs from groups of students interacting with Connected Worlds, ESSIL will construct selective recaps of their experience that both are personally salient to them (by including memorable details of their experience) and have explanatory coherence (to enable their discussion of important interconnections in the simulation's underlying model). Artificial Intelligence-based methods will be developed to 1) identify salient changes in the state of the simulation during  student interaction and 2) construct qualitative models of causal chains that could have led to these changes. These qualitative models will be used to generate salient recaps and discussion guides based on them, which will be provided to teachers whose classes are visiting NYSCI. The effectiveness of the innovation will be investigated by comparing visiting students' conversations with and without ESSIL-generated discussion supports and by interrogating their resulting models of the Connected Worlds system through concept maps."
"1623091","EXP: Collaborative Research: Extracting Salient Scenarios from Interaction Logs (ESSIL)","IIS","Cyberlearn & Future Learn Tech","09/01/2016","08/26/2016","Andee Rubin","MA","TERC Inc","Standard Grant","Amy Baylor","08/31/2019","$324,979.00","","andee_rubin@terc.edu","2067 Massachusetts Avenue","Cambridge","MA","021401339","6178739600","CSE","8020","8045, 8841","$0.00","The Extracting Salient Scenarios from Interaction Logs (ESSIL) project proposes to develop a new type of educational technology to support students' learning about complex systems from their participation in a multi-person immersive simulation.  Many important challenges we face today as a society -- including responding to climate change, managing global economies, city planning, disease outbreaks -- are ""complex systems"" problems, meaning that important phenomena in each (for instance trends in weather, stock bubbles, traffic jams, disease transmission) result not from a single cause, but because many small causes combine together. Participating in a simulation has the potential to help students understand the principles of complex systems, but because different principles surface depending on how each simulation unfolds, it can be difficult for teachers to adjust their lesson plans on the fly to highlight the principles that emerge in a given simulation run. To address this challenge, ESSIL will develop methods to create ""automatic salient recaps,"" as a way to help learners and their teachers make better sense of simulations. These recaps, which will be automatically generated, provide a story of ""what happened"" in the simulation in a way that both helps students remember their experience and reveals important scientific principles. Teachers and other facilitators will use these recaps, along with an accompanying discussion guide, to support productive learning conversations about the scientific principles incorporated in a simulation. The recaps will be developed for a large-scale immersive simulation installed at the New York Hall of Science (NYSCI), potentially improving the educational experience of thousands of daily visitors.  The capabilities developed to produce them have widespread applicability, because logs of student interactions are routinely produced by many educational systems.  The project is supported by the Cyberlearning and Future Learning Technologies Program, which funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by designing and building new kinds of learning technologies and studying their possibilities for fostering learning and challenges to using them effectively. <br/> <br/>The immersive simulation context for the project is Connected Worlds, an embodied, multi-person ecology simulation at NYSCI, with pedagogical goals around sustainability and systems thinking. Using logs from groups of students interacting with Connected Worlds, ESSIL will construct selective recaps of their experience that both are personally salient to them (by including memorable details of their experience) and have explanatory coherence (to enable their discussion of important interconnections in the simulation's underlying model). Artificial Intelligence-based methods will be developed to 1) identify salient changes in the state of the simulation during  student interaction and 2) construct qualitative models of causal chains that could have led to these changes. These qualitative models will be used to generate salient recaps and discussion guides based on them, which will be provided to teachers whose classes are visiting NYSCI. The effectiveness of the innovation will be investigated by comparing visiting students' conversations with and without ESSIL-generated discussion supports and by interrogating their resulting models of the Connected Worlds system through concept maps."
"1808692","Model Reduction of High Dimensional Hidden Markov Models and Markov Decision Processes","ECCS","ENERGY,POWER,ADAPTIVE SYS","09/01/2018","08/21/2018","Munther Dahleh","MA","Massachusetts Institute of Technology","Standard Grant","Anthony Kuh","08/31/2021","$360,000.00","Yury Polyanskiy","dahleh@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","ENG","7607","1653","$0.00","Intellectual Merit: We currently live in an era where data is a major currency promising a transformative change to our society. Consequently, there has been a surge in the use of machine learning (ML) algorithms on high dimensional data producing unstructured stochastic models. Such models tend to be of very high dimensions limiting their utility in various applications involving optimization or decision systems. This proposal focuses on developing a foundational theory for model reduction applied to classes of stochastic models, in particular, Hidden Markov Models (HMMs); these are stochastic models that are described by underlying finite dimensional state space. <br/><br/>Broader Impact: Ultimately, a model reduction theory will impact many fundamental aspects related to complex stochastic models including simulation, prediction, coding, robust learning, decision design and reinforcement learning. This research will develop new insights to address similar questions for other stochastic models including jump linear systems, and graphical models with latent variables and will have a direct impact on problems related to artificial intelligence and reinforcement learning. The latter is emerging as a popular approach for many decision-systems applications involving social behavior-- where simple mechanistic models do not exist. Examples of such problems are critical infrastructures and smart services where high dimensional unstructured data is available in real time. Models emerging in such approaches tend to have very high dimensions. <br/><br/>A foundational theory for model reduction will affect the way we learn and utilize complex stochastic models. As a result, this development will enter our courses at MIT in a fashion similar to how model reduction theory impacted courses in linear system theory. The development should affect classes in stochastic models, machine learning, and statistical learning theory, reinforcement learning, and AI.  We also intend to incorporate the connection between model reduction and statistical learning in our new MIT micromasters in statistics and data science.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1623094","EXP: Collaborative Research: Extracting Salient Scenarios from Interaction Logs (ESSIL)","IIS","Cyberlearn & Future Learn Tech","09/01/2016","08/26/2016","Leilah Lyons","NY","New York Hall of Science","Standard Grant","Amy Baylor","08/31/2019","$55,000.00","","llyons@nyscience.org","47-01 111TH STREET","Corona","NY","113682950","7186990005","CSE","8020","8045, 8841","$0.00","The Extracting Salient Scenarios from Interaction Logs (ESSIL) project proposes to develop a new type of educational technology to support students' learning about complex systems from their participation in a multi-person immersive simulation.  Many important challenges we face today as a society -- including responding to climate change, managing global economies, city planning, disease outbreaks -- are ""complex systems"" problems, meaning that important phenomena in each (for instance trends in weather, stock bubbles, traffic jams, disease transmission) result not from a single cause, but because many small causes combine together. Participating in a simulation has the potential to help students understand the principles of complex systems, but because different principles surface depending on how each simulation unfolds, it can be difficult for teachers to adjust their lesson plans on the fly to highlight the principles that emerge in a given simulation run. To address this challenge, ESSIL will develop methods to create ""automatic salient recaps,"" as a way to help learners and their teachers make better sense of simulations. These recaps, which will be automatically generated, provide a story of ""what happened"" in the simulation in a way that both helps students remember their experience and reveals important scientific principles. Teachers and other facilitators will use these recaps, along with an accompanying discussion guide, to support productive learning conversations about the scientific principles incorporated in a simulation. The recaps will be developed for a large-scale immersive simulation installed at the New York Hall of Science (NYSCI), potentially improving the educational experience of thousands of daily visitors.  The capabilities developed to produce them have widespread applicability, because logs of student interactions are routinely produced by many educational systems.  The project is supported by the Cyberlearning and Future Learning Technologies Program, which funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by designing and building new kinds of learning technologies and studying their possibilities for fostering learning and challenges to using them effectively. <br/> <br/>The immersive simulation context for the project is Connected Worlds, an embodied, multi-person ecology simulation at NYSCI, with pedagogical goals around sustainability and systems thinking. Using logs from groups of students interacting with Connected Worlds, ESSIL will construct selective recaps of their experience that both are personally salient to them (by including memorable details of their experience) and have explanatory coherence (to enable their discussion of important interconnections in the simulation's underlying model). Artificial Intelligence-based methods will be developed to 1) identify salient changes in the state of the simulation during  student interaction and 2) construct qualitative models of causal chains that could have led to these changes. These qualitative models will be used to generate salient recaps and discussion guides based on them, which will be provided to teachers whose classes are visiting NYSCI. The effectiveness of the innovation will be investigated by comparing visiting students' conversations with and without ESSIL-generated discussion supports and by interrogating their resulting models of the Connected Worlds system through concept maps."
"1830366","NRI: INT: Customizing Semi-Autonomous Nursing Robots Using Human Expertise","IIS","National Robotics Initiative","09/01/2018","08/18/2018","Kris Hauser","NC","Duke University","Standard Grant","Wendy Nilsen","08/31/2021","$962,572.00","Ryan Shaw","kris.hauser@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","8013","063Z, 8086","$0.00","Remote-controlled robots have the potential to allow humans to perform useful tasks without putting themselves in danger, or without travelling long distances. This project explores how humans can control nursing robots that can communicate with patients, collect vital signs, and perform routine cleaning tasks in quarantine environments. The use of these robots has the potential to protect nurses from infection during disease outbreaks, and to protect patients with weakened immune system. A significant challenge in this effort is to make the user interface to the robot easy enough for nurses to use without significant training. Because engineers are not experts in nursing, the research will let nurses customize the user interface by teaching the robot about objects, places, and tasks that are typically used in nursing. After training, artificial intelligence algorithms will then automatically estimate which actions the nurse wants to perform, and these will be presented in a simple user interface that allows the nurse to select those actions quickly. <br/><br/>This project will continue an interdisciplinary collaboration between Duke's School of Engineering and School of Nursing. Research will be conducted in three thrust areas: 1) smart human operator interfaces for supervised autonomy that learn mappings between multimodal sensor input streams to provide simple, interpretable task options and status feedback; 2) hierarchical task learning algorithms for helping human experts train novel composite tasks; and 3) real world evaluation of human-robot system speed, reliability, operator workload, and operator learning curve using registered nurses and nursing students performing simulated clinical tasks in training environments.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1808898","Collaborative Research: Reinforcement learning based adaptive optimal control of powered knee prosthesis for human users in real life","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/15/2018","08/14/2018","He Huang","NC","North Carolina State University","Standard Grant","Anthony Kuh","07/31/2021","$149,075.00","","hhuang11@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","ENG","7607","1653","$0.00","The proposed research aims at designing robust, real time learning controllers for powered lower limb prosthesis worn by above-knee amputees. It centers on adaptive optimal tuning of prosthetic knee joint impedance parameters with an ultimate goal of achieving human-prosthesis symbiosis. Current state-of-the-art approaches rely on a predetermined collection of knee joint impedance parameters, resulted from tedious manual tuning in a clinic. In addition to a lack of adaptability to different users, current impedance controls do not adapt to different use environments. One of the key design challenge is due to the constant interaction between the human user and the robotic leg. As such, advanced robotics including those employing latest artificial intelligence technologies, control system theory and design, and existing biomechanics based controls cannot meet the needs of real time learning control of a powered prosthetic leg in a human-prosthesis system. Given the nature of the problem, reinforcement learning based adaptive optimal control, also referred to as adaptive dynamic programming (ADP), holds great promise to delivering the next generation of prosthesis control solutions. <br/><br/>Intellectual Merit: The design challenge requires innovative approaches of real time reinforcement learning control. The learning controller has to be designed without knowing an explicit dynamic system model describing the human-prosthesis system, while assuring human user safety and system stability, and being scalable and adaptable to different users and use conditions. Putting it all together, the success of this project will be an important milestone for machine learning, control engineering, and rehabilitation engineering. <br/><br/>Broader Impacts: This research has a direct impact on improving the lives of above-knee amputees. Also of great societal impact is the potential of reducing health care cost. New knowledge gained from human-robot interaction will not only aid amputees but also stroke patients who use exoskeleton as assistive devices. The proposed research will also benefit several research communities such as wearable robots, machine learning, and rehabilitation to develop new technologies addressing real applications. To excite and educate future leaders and researchers in science and engineering, the project will provide an opportunity for integration of our research work into graduate education and postdoc training.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1734938","NCS-FO: Neuroimaging to Advance Computer Vision, NLP, and AI","IIS","GVF - Global Venture Fund, Core R&D Programs, IntgStrat Undst Neurl&Cogn Sys","08/15/2017","08/07/2017","Jeffrey Siskind","IN","Purdue University","Standard Grant","Kenneth C. Whang","07/31/2020","$1,000,000.00","Ronnie Wilbur, Evguenia Malaia","qobi@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","054Y, 7980, 8624","5946, 5980, 6869, 8089, 8091, 8551, 8817","$0.00","It is often said that a picture is worth a thousand words. Frequently, to search for what is needed, whether images or objects in those images, words are needed instead. Getting accurate labels for efficient searches is a longstanding goal of computer vision, but progress has been slow. This project employs new methods to significantly change how picture-word labeling is accomplished by taking advantage of the best picture recognizer available, the human brain. Through functional magnetic resonance imaging and electroencephalography, brain activity of humans looking at pictures/videos is recorded and then used to improve performance on artificial intelligence (AI) tasks involving computer vision and natural language processing. Current systems use machine learning to train computers to recognize objects (nouns) and activities (verbs) in images/video, which are then used to describe events. Reasoning tasks (e.g., solving math problems) can then be done. These systems are trained on specially prepared datasets with samples of nouns for objects, verbs for activities, sentences describing events, and exam questions and answers. A novel paradigm using humans to perform the same tasks while their brains are scanned allows determination of neural patterns associated with those tasks. The brain activity patterns, in turn, are used to train better computer systems.<br/><br/>The central hypothesis is that understanding human processing of grounded language involving predication and its use during reasoning will materially improve engineered computer vision, natural language processing, and AI systems that perform image/video captioning, visual question answering, and problem solving.  Scientific and engineering goals include developing models of human language grounding and reasoning consistent with neuroimaging, to improve engineered systems integrating language and vision that support automated reasoning.  The main scientific question is to understand mechanisms by which predicates and arguments are identified, linked, and used for reasoning by the human brain.  The hypothesis, that predicate-argument linking in visual and linguistic representations are accomplished similarly, and that this then supports reasoning and problem solving, will be tested using multiple neuroimaging modalities, and machine learning algorithms to decode ""who did what to whom"" from brain scans of subjects processing linguistic and visual stimuli.  The iterative approach will involve understanding information integration at the neural level, to improve machine learning performance on AI tasks by training computers to perform increasingly complex tasks with neuroimaging data from stimuli derived from large-scale natural tasks.  Using identical datasets for human and machine performance will support translation of scientific advances to engineering practice involving integration of computer vision and natural language processing.<br/><br/>This award is cofunded by the Office of International Science and Engineering."
"1808752","Collaborative Research: Reinforcement learning based adaptive optimal control of powered knee prosthesis for human users in real life","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/15/2018","08/14/2018","Jennie Si","AZ","Arizona State University","Standard Grant","Anthony Kuh","07/31/2021","$250,925.00","","si@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","ENG","7607","1653","$0.00","The proposed research aims at designing robust, real time learning controllers for powered lower limb prosthesis worn by above-knee amputees. It centers on adaptive optimal tuning of prosthetic knee joint impedance parameters with an ultimate goal of achieving human-prosthesis symbiosis. Current state-of-the-art approaches rely on a predetermined collection of knee joint impedance parameters, resulted from tedious manual tuning in a clinic. In addition to a lack of adaptability to different users, current impedance controls do not adapt to different use environments. One of the key design challenge is due to the constant interaction between the human user and the robotic leg. As such, advanced robotics including those employing latest artificial intelligence technologies, control system theory and design, and existing biomechanics based controls cannot meet the needs of real time learning control of a powered prosthetic leg in a human-prosthesis system. Given the nature of the problem, reinforcement learning based adaptive optimal control, also referred to as adaptive dynamic programming (ADP), holds great promise to delivering the next generation of prosthesis control solutions. <br/><br/>Intellectual Merit: The design challenge requires innovative approaches of real time reinforcement learning control. The learning controller has to be designed without knowing an explicit dynamic system model describing the human-prosthesis system, while assuring human user safety and system stability, and being scalable and adaptable to different users and use conditions. Putting it all together, the success of this project will be an important milestone for machine learning, control engineering, and rehabilitation engineering. <br/><br/>Broader Impacts: This research has a direct impact on improving the lives of above-knee amputees. Also of great societal impact is the potential of reducing health care cost. New knowledge gained from human-robot interaction will not only aid amputees but also stroke patients who use exoskeleton as assistive devices. The proposed research will also benefit several research communities such as wearable robots, machine learning, and rehabilitation to develop new technologies addressing real applications. To excite and educate future leaders and researchers in science and engineering, the project will provide an opportunity for integration of our research work into graduate education and postdoc training.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816363","CHS: Small: Optimizing Human-Machine Performance via Neurofeedback and Adaptive Autonomy","IIS","Cyber-Human Systems (CHS)","09/01/2018","08/14/2018","Paul Sajda","NY","Columbia University","Standard Grant","Tonya Smith-Jackson","08/31/2021","$498,785.00","","ps629@columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","7367","7367, 7923, 8089, 8091","$0.00","Our society is being fundamentally transformed by increased interaction between humans and autonomous artificial intelligence (AI) systems. However, the addition of autonomy to our lives will not be successful unless we understand how smart machines and humans should best interact and communicate. Human-machine communication today is almost entirely linguistic, using spoken language for systems such as Siri or Alexa, or typed text for chatbots.  However, humans communicate extremely efficiently with each other byu sing much more than just words; for example by being sensitive to facial expression, gestures, gait, and intonation. In fact, great teams, whether sports teams or military combat teams, are excellent at predicting teammates behavior and state of mind. In this project, the investigators consider both basic science and technology questions with respect to how to communicate that cognitive and physiological state of a human that is co-operating with an autonomous AI. The project has very broad implications since it addresses fundamental questions related to the interactions between humans and smart machines.<br/><br/>The project investigates the  hypothesis that adaptive autonomy together with coordinated neurofeedback can be employed in the same system to optimize human-machine performance. Investigators will develop a framework and investigate the hypothesis within the context of boundary avoidance tasks, or BAT, which  is a class of tasks in which  task critical boundaries surround the optimal operating point of the control system. These tasks are particularly interesting when considering human control because they typically result in a positive feedback loop that systematically increases the arousal state of the human subject, resulting in increasingly poor task performance and ultimate task failure, consistent with the Yerkes-Dodson law. Our framework uses a brain-computer interface (BCI) to both engage autonomy as well as being a source for neurofeedback that can shift human subjects to their performance 'sweet-spot'. This project will advance the science and technology development of how human-machine systems can be optimally integrated, specifically when both 1) the machine has access to ongoing changes in human cognitive and physiological state during performance of the task and 2) the human is made aware of their own state via appropriate neurofeedback.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1841368","EAGER: Perceptions of Fairness and Justice in AI Software for Talent Acquisition","IIS","Cyber-Human Systems (CHS)","01/01/2019","08/03/2018","Lynette Yarger","PA","Pennsylvania State Univ University Park","Standard Grant","Tonya Smith-Jackson","12/31/2020","$225,054.00","","lyarger@ist.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","7367","7367, 7916, 9102","$0.00","Perceived fairness and justice in job recruiting and hiring are influenced by several factors. Some factors are the consistency of the decision-making process across people and time, timely and informative feedback, propriety of the interview questions, and the extent to which pre-employment tests appear to relate to the job requirements. These factors come together to influence decisions about recruiting and hiring and are being made increasingly with the help of artificial intelligence (AI). In this project, a sociotechnical frame is applied to explore perceptions of fairness and justice of AI-supported talent acquisition algorithms. the investigator will elicit and analyze perceptions of human resources personnel, African American job seekers, and AI software designers. The outcomes will be used to inform the design of bias recognition and mitigation procedures and technologies for both humans and the algorithms being used.<br/><br/>The intellectual merit of this exploratory study is the development of qualitative instruments and metrics that can be used to measure perceptions of algorithmic fairness and justice. The research approach extends a theory of procedural rules for perceived fairness of selection systems by using a three-pronged approach comprising job seekers who are under-represented in the IT industry, human resource professionals who manage the talent acquisition process, and IT professionals who design AI software with fairness as the core value in product design and development. Perceptions using scenarios are examined as well as the actual experiences of jobseekers who are affected by these decisions. This research contributes to an assessment of algorithmic fairness at a time when there is currently little insight into how historically marginalized populations might perceive or be adversely affected by AI systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1527668","III: Small: Sampling Techniques in Computational Logic","IIS","INFO INTEGRATION & INFORMATICS, ","09/01/2015","06/28/2018","Moshe Vardi","TX","William Marsh Rice University","Standard Grant","Aidong Zhang","08/31/2019","$488,286.00","","vardi@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","CSE","7364, R217","7364, 7923, 8237","$0.00","Constrained sampling and counting are two fundamental problems in data analysis. In constrained sampling the task is to sample randomly from among possible solutions to a Boolean formula. A related problem is that of constrained counting, determining the number of possible solutions to a Boolean formula.  These problems have applications in machine learning, probabilistic reasoning, and planning, among other areas  In particular, te project looks at the electronic-design-automation industry to determine what practical solutions to the problems require. Both problems can be viewed as aspects of one of the most fundamental problems in artificial intelligence, which is to understand the structure of the solution space of a given set of constraints.<br/><br/>This project focuses on the development of new algorithmic techniques for constrained sampling and counting, based on a universal hashing - a classical algorithmic technique in theoretical computer science. Many of the ideas underlying the proposed approach go back to the 1980s, but they have never been reduced to practice. This project builds on recent progress in Boolean reasoning to develop methods to reduce these algorithmic ideas to practice. Methods for approximations with formal guarantees provide opportunities to scale what is fundamentally a computationally intractable problem. Pruning techniques can also reduce ""waste"" in hashed solutions, but introduce challenges in ensuring samples are independently distributed. This work has potential for breakthrough results in constrained sampling and counting, providing a new algorithmic toolbox in machine learning, probabilistic reasoning, and the like."
"1819331","SBIR Phase I:  Platform to Elucidate the Causal Mutations Behind Human Inherited Diseases","IIP","SMALL BUSINESS PHASE I","07/01/2018","07/12/2018","eMalick Njie","NY","GENETIC INTELLIGENCE","Standard Grant","Ruth M. Shuman","06/30/2019","$225,000.00","","bertrand@geneticintelligence.com","153E W 110th St","New York","NY","100290000","9178931659","ENG","5371","5371, 8038","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) project is the development of an artificial intelligence-based software platform to elucidate inherited diseases by identifying the causative genetic factors in the whole genome at large, not just the tiny portion of the genome called the exome. This technology will help solve the longstanding problems of multigenic inherited diseases and help unlock the full potential of gene therapy modalities such as CRISPR, which require knowledge of the causal mutation for targeting. With a defined genetic target, truly curative therapeutics and early, accurate diagnostics will be made possible. Through this platform, pharmaceutical companies will benefit from a shortened drug development cycle and a lower risk of clinical trial failure while diagnostics companies will be able to develop fast and accurate molecular diagnostics targeting the mutations identified by the platform. <br/><br/>This SBIR Phase I project proposes to build a build a proof-of-concept software platform that employs a combination of supervised and unsupervised machine learning algorithms to process, sort, and analyze human whole genome sequencing data from an Amyotrophic Lateral Sclerosis (ALS) cohort from a set genetic background. ALS is an incurable, debilitating disease whose genetic causes remain largely unknown. Identifying these mutations will enable the development of efficacious treatments for the conditions. Three main objectives will be accomplished for the platform. One, the ability to process full-size, high coverage human whole genome data automatically through the pipeline in a scalable manner. Two, the ability to identify the genetic background of a test subject with a top-5 error rate of <1%, an important verification step to minimize incorrect cohort stratification from false ancestry self-reports. Three, the ability to rapidly identify at least one genetic feature known to be associated with ALS (e.g., SOD1, C9ORF72), which will help provide early validation for the platform.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1841354","CHS: EAGER: Handling Online Risks and Creating Safe Spaces: Content Moderation in Live Streaming Micro Communities","IIS","Cyber-Human Systems (CHS)","08/01/2018","07/26/2018","Donghee Yvette Wohn","NJ","New Jersey Institute of Technology","Standard Grant","William Bainbridge","07/31/2020","$214,735.00","","wohn@njit.edu","University Heights","Newark","NJ","071021982","9735965275","CSE","7367","7367, 7916","$0.00","This research will investigate how individuals and small groups handle content moderation real time in the context of live streaming, from both technical and social perspectives, distinguishing between professional content creators who create content for a living, and hobbyists.  Live streaming services such as Twitch are the latest form of social media that marries user-generated content with the traditional concept of live television broadcasting: as someone broadcasts, viewers can post comments in a chat interface that is displayed alongside the broadcast, creating an interactive synchronous media experience. This real-time interaction, however, makes the platform ripe for deviant behavior, as potential harassers can visually see the immediate impact of their harsh words on the person who is broadcasting. Most current forms of social media rely on crowdsourced methods of moderation, where users report bad content that is ultimately reviewed by a human moderator. This does not work well in the context of real-time moderation, posing greater social and technological challenges. This project will study approaches to improving understanding of the sociotechnical aspects of content moderation from the perspective of micro communities on live streaming platforms. By understanding how streamers currently moderate audiences through manual and automated labor, the research will identify opportunities for technology to assist and enhance the moderation process and provide guidelines for sustainable and scalable moderation. Exploration of different governance structures of moderation may also yield insights into alternative models of moderation for the future of social media and understanding of how different moderation practices may influence the evolution of positive and negative norms in micro communities. <br/><br/>Because live streaming is such a new phenomenon, presenting novel technical and social challenges, exploratory research is required before any serious attempt to solve its problems through technology design.  This research agenda will advance knowledge about how moderation influences the development of social norms in micro communities from a qualitative perspective, laying the groundwork for future large-scale empirical studies, experiments, and development of useful artificial intelligence tools. The research will be able to identify the breadth of methods that are employed in the practice of moderation that will yield a comprehensive framework of understanding the conceptual functions of moderation by building a taxonomy of moderation, and develop a common language for both academics and practitioners that enables mapping between problems and potential design solutions. Moreover, through ethnographic work, the research will provide descriptive knowledge of this new form of social media that results in novel research questions unique to this particular technology.  This research will inform design of moderation tools and practices that could impact millions of people who publish content online and yet even more people who view that content. By focusing on the individual producer, rather than the corporation running the system, as the center of their own system, the findings may be able to empower a new era of Internet activity in which individuals and small groups have more agency over what happens online.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1657379","CRII: CHS: Mining Intentions on Social Media to Enhance Situational Awareness of Crisis Response Organizations","IIS","CRII CISE Research Initiation","09/01/2017","03/01/2017","Hemant Purohit","VA","George Mason University","Standard Grant","Dan Cosley","08/31/2019","$174,965.00","","hpurohit@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","026Y","7367, 8228","$0.00","In large-scale emergencies, people post a lot of information about their status, needs, and abilities to help on social media. In principle, these posts might help emergency management teams get a better picture of the situation and find useful resources, but the number and questionable accuracy of these posts make them less useful than they could be. This project is about developing tools that identify people's intentions related to the emergency, sorting tweets into categories such as requests for help or information, offers of help, announcements of their safety or location, and so on. This problem of intent inference is a key scientific problem in natural language processing and artificial intelligence, with practical uses in a number of areas beyond emergency management, including web search and providing location-aware services. The researchers will attack the intent inference problem by narrowing it to the emergency response domain. First, they will work closely with emergency response teams to identify meaningful categories of intent that align with emergency response needs, in order to guide the collection and labeling of social media posts. Then, they will develop strategies drawn from existing image and natural language processing techniques and informed by the emergency response context to do the categorization work. Finally, they will build and evaluate a tool that uses the categorization algorithms to highlight the social media posts that are most likely to be useful to emergency responders. The work will be used to help develop courses around data science at the lead researcher's school, and the tools will be made publicly available through an open source code and advertised to communities of interest. <br/><br/>To build the set of crisis-specific intent categories, the research team will first analyze existing operational manuals for emergency response including the Incident-Command-System models to extract key processes and initial categories, then refine that set working with experts from the Fairfax Fire and Rescue Department, an advisory committee of social media working group for emergency services at Department of Homeland Security that has members across the country, and members of the project's advisory board.  Intent extraction will be modeled as a multilabel classification problem on two dimensions: type of intent, and topical category; this formulation maps well to characteristics of posts (which might contain multiple intents and topics) and scopes the complexity of general intent inference. Datasets will be gathered from prior crisis events and labeled by crowd workers interested in humanitarian work according to the categories identified from the first phase. Features of posts will be constructed from posts? metadata using natural language processing techniques on textual content, image processing techniques on multimedia content and author profiling techniques. Features will include extracting syntactic-semantic patterns that represent declarative and psycholinguistic knowledge as well as ideas from discourse analysis, while features of authors will be drawn from their provided profile information as well as aggregate inferences from their posts. The team will use a multi-task learning framework as the underlying algorithm to leverage relationships between the different categories to be classified.  Finally, the developed interface will support faceted browsing by intent, topic, location, and response management process, and be evaluated through training exercises with the research team's practitioner partners."
"1821894","Collaborative Research: Multimodal Affective Pedagogical Agents for Different Types of Learners","IIS","Cyberlearn & Future Learn Tech","08/01/2018","07/23/2018","Nicoletta Adamo-Villani","IN","Purdue University","Standard Grant","Amy Baylor","07/31/2021","$498,823.00","Bedrich Benes","nadamovi@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","8020","063Z, 8045","$0.00","While most research on embodied pedagogical agents (adaptive virtual agents that guide and mentor learners) explores cognitive features, this project investigates the role of agent affect/emotion. This project examines how the agent's affective state (e.g., seeming interested or concerned) impacts different types of students (e.g., differing by knowledge level, gender, underrepresented group status, interest in STEM fields, and personality profile) when learning from online statistics lessons. The project integrates several areas of research: a) computer graphics research on life-like and believable representation of emotion in embodied agents, b) advanced methods and techniques from artificial intelligence and computer vision for real-time recognition of emotions, c) cognitive psychology research on learning from affective agents, and d) education research on the efficacy of affective agents for improving student learning of STEM concepts. Through experimental research the project will advance the state of the art in agent design and implementation by integrating findings on effective emotion regulation with algorithms that support life-like expression of emotions in embodied agents. <br/><br/>To investigate the multimodal design features of affective pedagogical agents, the project has two main objectives: (1) research and develop novel algorithms for emotion recognition and for life-like emotion representation in embodied animated agents, and (2) develop an empirically grounded research base to guide the design of affective pedagogical agents for different types of learners. In one series of experiments the project will determine evidence-based design principles to guide the development of agents that demonstrate emotion/affect, including which kinds of affective states are most effective for which kinds of learners. In a second series of experiments, the project will implement a web-camera system to detect the emotional state of the learner (e.g., confused, interested, content, or bored), adapting the emotional state displayed by the agent in response. Of interest is whether students learn the statistics lesson better when the pedagogical agent is sensitive to the learner's emotional state than when it is not. In addition to its scientific merit, the project will develop and make available a toolkit of affective animated pedagogical agents that adapt to learner characteristics to be used by learners of all ages, for education and training in a variety of subject matters and settings.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1821833","Collaborative Research: Multimodal Affective Pedagogical Agents for Different Types of Learners","IIS","Cyberlearn & Future Learn Tech","08/01/2018","07/23/2018","Richard Mayer","CA","University of California-Santa Barbara","Standard Grant","Amy Baylor","07/31/2021","$250,000.00","","mayer@psych.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","CSE","8020","063Z, 8045","$0.00","While most research on embodied pedagogical agents (adaptive virtual agents that guide and mentor learners) explores cognitive features, this project investigates the role of agent affect/emotion. This project examines how the agent's affective state (e.g., seeming interested or concerned) impacts different types of students (e.g., differing by knowledge level, gender, underrepresented group status, interest in STEM fields, and personality profile) when learning from online statistics lessons. The project integrates several areas of research: a) computer graphics research on life-like and believable representation of emotion in embodied agents, b) advanced methods and techniques from artificial intelligence and computer vision for real-time recognition of emotions, c) cognitive psychology research on learning from affective agents, and d) education research on the efficacy of affective agents for improving student learning of STEM concepts. Through experimental research the project will advance the state of the art in agent design and implementation by integrating findings on effective emotion regulation with algorithms that support life-like expression of emotions in embodied agents. <br/><br/>To investigate the multimodal design features of affective pedagogical agents, the project has two main objectives: (1) research and develop novel algorithms for emotion recognition and for life-like emotion representation in embodied animated agents, and (2) develop an empirically grounded research base to guide the design of affective pedagogical agents for different types of learners. In one series of experiments the project will determine evidence-based design principles to guide the development of agents that demonstrate emotion/affect, including which kinds of affective states are most effective for which kinds of learners. In a second series of experiments, the project will implement a web-camera system to detect the emotional state of the learner (e.g., confused, interested, content, or bored), adapting the emotional state displayed by the agent in response. Of interest is whether students learn the statistics lesson better when the pedagogical agent is sensitive to the learner's emotional state than when it is not. In addition to its scientific merit, the project will develop and make available a toolkit of affective animated pedagogical agents that adapt to learner characteristics to be used by learners of all ages, for education and training in a variety of subject matters and settings.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1636859","BD Spokes: Spoke: South: Collaborative: Using Big Data for Environmental Sustainability: Big Data + AI Technology = Accessible, Usable, Useful Data!","IIS","BD Spokes -Big Data Regional I, INFORMATION TECHNOLOGY RESEARC","10/01/2016","08/21/2017","Jennifer Hammock","VA","Smithsonian Institution","Standard Grant","Beth Plale","09/30/2019","$294,320.00","","hammockj@si.edu","Office of Sponsored Projects","Arlington","VA","222023709","2026337110","CSE","024Y, 1640","028Z, 043Z, 7433, 8083","$0.00","Protecting the environment is among the biggest challenges facing our society. As the effects of environmental degradation, global warming and climate change continue to grow, there is an increasingly urgent and critical need for research and education in biological diversity, ecological modeling and environmental sustainability. On one hand, professional and citizen scientists need ready access to large-scale biological, ecological and environmental data for modeling, simulation and analysis. On the other, college teachers and students in biology and ecology need to access large-scale data in a form meaningful to them. The various audiences will engage with big data in different ways and so a variety of knowledge-building tools are needed. This project brings together two dozen scientists from a dozen institutions in academia, government and industry to address the problem of translating big data into meaningful knowledge in support of research and education in environmental sustainability.  <br/><br/>Encyclopedia of Life  (EOL) is the world's largest database of biological species and other biodiversity information. EOL also works closely with scores of other biodiversity datasets such as BISON, GBIF, and OBIS. This project seeks to make EOL and related biodiversity data sources accessible, usable, and useful, by integrating extant artificial intelligence tools for information extraction, modeling and simulation, and question answering. The focus of this project will be on the data engineering required for this integration and construction of a resulting EOL+ system. The project team will provide access to EOL+ such that users can build their own tools and services on top of EOL+. The team will work with the NSF South Big Data Hub to organize yearly workshops for building and supporting a community of users of EOL+. Professional and citizen scientists, and teachers and students alike, will be able to access EOL+ through NSF's South Big Data Hub webportal, and use it for modeling and analysis, explanation and prediction, as well as education and workforce development in biological diversity, ecological modeling and environmental sustainability."
"1717705","CHS:Small: A Kinder, Gentler Technology: Enhancing Human-Machine Symbiosis Using Adaptive, Personalized Affect-Aware Systems","IIS","Cyber-Human Systems (CHS)","08/15/2017","08/04/2017","Domen Novak","WY","University of Wyoming","Standard Grant","Dan Cosley","07/31/2020","$447,889.00","Sean McCrea","dnovak1@uwyo.edu","1000 E. University Avenue","Laramie","WY","820712000","3077665320","CSE","7367","7367, 7923, 9150","$0.00","A longstanding goal in artificial intelligence is to develop smart systems that interact well with humans.  Advances in sensing and machine learning are increasingly allowing computers to infer mental states, raising questions about how agents might use those inferences to adapt to human partners.  This project will systematically address how to design and evaluate ""affect-aware"" systems that adapt their behavior based on estimates of their users' emotional experiences.  The team will first look at the effectiveness of current strategies that vary the difficulty of educational tasks and games based on inferred affect.  They will then develop new strategies that take into account both individual personality and dynamic characteristics of the physical environment.  Finally, they will evaluate these strategies, paying particular attention to what happens when systems act on incorrect inferences about affect.  These studies will help pave the way toward self-driving cars, conversational assistants, and virtual reality characters that consider affect when interacting with people, ideally leading to better experiences and outcomes.  The team will also develop new interdisciplinary courses in human factors and human-computer interaction, connecting with industrial partners to help train students in both the practice and research of these kinds of adaptive systems.  Further, they will do public outreach about these systems and use them to provide summer research experiences for K-12 and community college students, focusing on those from groups traditionally underrepresented in computing.<br/><br/>The project will be structured as a series of lab studies, using spatial cognition games and robot-assisted motor rehabilitation tasks as testbeds that allow the team to directly manipulate task difficulty and measure enjoyment/engagement and performance/learning outcomes.  The team will first collect training data with people using the testbeds at randomly selected difficulty levels and reporting the perceived level of difficulty as too easy (bored), too hard (frustrated), or about right, while capturing heart rate signals, skin conductance and temperature, electroencephalogram (EEG) data, and environmental factors including light, time of day, and room temperature.  These will be used to train affect recognizers using a variety of machine learning methods: linear discriminant analysis (including a Kalman adaptive version), support vector machines, neural and Bayesian networks, and random forests.  Using a common adaptation strategy that adjusts difficulty up or down one step, the team will measure the enjoyment and performance outcomes that affect-aware recognizers achieve both with and without considering environmental factors, comparing those to a baseline strategy that adapts difficulty based only on task performance.  During these experiments, the team will also collect data about users' personality characteristics and use those to develop individualized recognition models and adaptation strategies for different personality types. These individualized models and strategies will be evaluated by comparing them to the baseline data from the first experiment.  Finally, they will compare the outcomes of these systems with those from a ""best-case"" system controlled by humans and a ""worst-case"" error-prone system that chooses adaptation strategies randomly, looking at those induced error rates along with the natural error rates captured during the other experiments to determine the effect of recognition and adaptation error on satisfaction and task outcomes."
"1734944","Collaborative Research: NCS-FO: Connecting Spikes to Cognitive Algorithms","IIS","IntgStrat Undst Neurl&Cogn Sys","01/01/2018","08/07/2017","Alexander Huk","TX","University of Texas at Austin","Standard Grant","Kenneth C. Whang","12/31/2021","$234,752.00","","huk@mail.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","8624","8089, 8091, 8551","$0.00","Experimental neuroscientists can record the signals communicated among the neurons that are collectively involved in producing meaningful behaviors, but making sense of these patterns of activity in terms of specific mental functions is challenging. This research project aims to discover the unseen mental processes that underlie such meaningful behavior from those recordings. The technology developed in this endeavor will uncover new ways of understanding mental processes hidden deep in the noisy signals collected from multiple neurons and will be used to derive new theoretical models (cognitive algorithms) to explain how populations of neurons work together. Such models will contribute to the development of diagnostic tools and neural prosthetics for cognitive dysfunctions in perception, working memory, and decision making, and can also inspire advances in machine learning and artificial intelligence.<br/> <br/>The technical goal of this project is to develop a data-driven framework amenable to visualization and interpretation of neural activity underlying cognition. The core of the project is the identification and recovery of an interpretable low-dimensional nonlinear continuous dynamical system that underlies observed neural time series, and its validation through experimental perturbations. This will answer two key scientific questions: (1) How are task and cognitive variables represented in low-dimensional neural trajectories; and (2) What are the laws that govern the time evolution of the neural states. Answering these questions will help us understand how subjects implement and switch between different cognitive strategies, and more importantly, will provide a means for testing previously proposed theoretical models of the neural computations underlying cognition. This project will develop a number of statistical methods that can (i) extract private and shared noise from single-trial electrophysiological observations, (ii) combine recordings from multiple sessions to infer a common cognitive neural dynamics model, and (iii) design control stimulation to perturb the current neural state. Specifically, these tools will be applied to recordings from cortical areas involved in visuomotor decision-making to discover (1) how the co-variability in a population of sensory neurons encodes decision variables, (2) how the cognitive strategy changes when sensory evidence statistics change, and (3) the underlying dynamics that sustain spatial working memory. The success of this project could transform how the field analyzes population activity with low-dimensional structure in the context of cognitive tasks and beyond."
"1757520","SCH: INT: Collaborative Research: FITTLE+: Theory and Models for Smartphone Ecological Momentary Intervention","IIS","Smart and Connected Health","08/18/2017","09/20/2017","Peter Pirolli","FL","Florida Institute for Human and Machine Cognition, Inc.","Standard Grant","Sylvia J. Spengler","09/30/2018","$192,193.00","","ppirolli@ihmc.us","40 S. Alcaniz St.","Pensacola","FL","325026008","8502024473","CSE","8018","8018, 8062, 9251","$0.00","Many health conditions are caused by unhealthy lifestyles and can be improved by behavior change. Traditional behavior-change methods (e.g., weight-loss clinics; personal trainers) have bottlenecks in providing expert personalized day-to-day support to large populations for long periods. There is a pressing need to extend the reach and intensity of existing successful health behavior change approaches in areas such as diet and fitness. Smartphone platforms provide an excellent opportunity for projecting maximally effective interventions for behavior change into everyday life at great economies of scale. Smartphones also provide an excellent opportunity for collecting rich, fine-grained data necessary for understanding and predicting behavior-change dynamics in people going about their everyday lives. The challenge posed by these opportunities for detailed measurement and intervention is that current theory is not equally fine-grained and predictive. <br/><br/>This interdisciplinary project investigates theory and methods to support fine-grained behavior-change modeling and intervention integrated via smartphone into the daily lives of individuals and groups.  Fittle+ develops a new and transformative form of smartphone-delivered Ecological Momentary Intervention (EMI) for improving diet and physical activity. This approach will provide social support and autonomously planned and personalized coaching that builds on methods from mobile sensing, cognitive tutoring, and evidence-based social design. The foundation for this new approach will require new predictive computational theories of health behavior change. Current coarse-grained conceptual theories of individual health behavior change will be refined into fine-grained predictive computational models. These computational models will be capable of tracking moment-by-moment human context, activity, and social patterns based on mobile sensing and interaction data. Using these monitoring capabilities, Fittle+'s computational models will support assessment of, and predictions about, individual users and groups based on underlying motivational, cognitive, and social mechanisms. These predictive models will also be used to plan and optimize coaching actions including detailed diagnostics, individualized goals, and contextually and personally adapted interventions. <br/><br/>The collaborative team of researchers works with weight-loss interventionists at one of nation's largest health organization's facility in Hawaii. The team includes expertise in mobile sensing, artificial intelligence, computational cognition, social psychology, human computer interaction, computer tutoring, and measurement theory."
"1453721","CAREER: Statistical Information Retrieval Modeling for Complex Search","IIS","INFO INTEGRATION & INFORMATICS","02/01/2015","02/15/2018","Grace Hui Yang","DC","Georgetown University","Continuing grant","James French","01/31/2020","$552,012.00","","huiyang@cs.georgetown.edu","37th & O St N W","Washington","DC","200571789","2026250100","CSE","7364","1045, 7364","$0.00","With the increasing popularity of Web applications and users' deep involvement in the Web, search engines face great challenges with a new degree of complexity. For instance, location-based services collect more complex contextual information such as geo-locations, season, time and temperature. Users' search activities have become more complex and usually task-based generating a variety of feedback and engagement signals such as clicks, mouse movements, eye tracking results, and query reformulations. Moreover, search is not only an individual user's personalized activity, but also activities shared by many users with similar information needs. Search engines are presented with the richest types of information and the largest amount of data ever and the complexity of the available information is tremendous. This demands that search engines be upgraded from retrieval systems that basically look for documents for single queries to decision engines that can pick the best choices for information seeking tasks. Through disseminating research results in papers and tools, the project will make three types of broad impact. First, the techniques developed in this project will benefit a broad population of everyday users and empower them to deal with complex, task-oriented web search. Second, the algorithms and software developed will provide fellow researchers and practitioners a handful of useful tools for solving IR problems incorporating dynamics. Third, the project will reach out to middle school girls and elementary school students. It will be easy for any search engine user to start using the proposed new search engine. However, to be an expert on IR, students need to be good at mathematics, natural language processing, user interface, artificial intelligence, and programming. This will be an excellent project to attract young people and minorities to these STEM disciplines.<br/><br/>This project aims to create the next generation search engines, to be more specific, decision engines. The focus will be on designing, experimenting, and deploying statistical models for modeling the dynamics presented in the search process. The technical challenges are: (1) given the complexity of the available data, integrating a search engine appropriately into the right places in the larger context for the ultimate information seeking tasks; (2) providing theoretical and practical support to formal modeling of user engagement and other dynamics in retrieval models for better retrieval effectiveness; (3) modeling a user's exploration in the information space and optimizing a search engine's actions and algorithms; and (4) modeling interactions between a user and a search engine as well as interactions among multiple users, creating the dynamic environment for them all to interact and to game with each other and achieve a win-win optimization. The success of this project will start a new research field in IR: dynamic IR modeling. The results of this research will be highly influential with great impact on the next generation search engines. The work will build a foundation for future advances in the fields of reinforcement learning in IR and game theory in IR."
"1659774","REU Site: Carnegie Mellon University Robotics Institute REU Site","IIS","RSCH EXPER FOR UNDERGRAD SITES","06/01/2017","03/27/2017","John Dolan","PA","Carnegie-Mellon University","Standard Grant","Wendy Nilsen","05/31/2020","$359,938.00","","jmd@cs.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1139","9250","$0.00","This Research Experiences for Undergraduates (REU) Site will advance knowledge by training students in the key technological area of robotics and preparing them for graduate study and technical leadership.  The sciences that make up the discipline of robotics provide a unique opportunity to immerse students in research with real-world applications. Rapid research advances place robotics at the forefront of the nation's interests. Furthermore, robotics plays a vital role in science, technology, engineering, and mathematics education due to its multi-disciplinary nature. Robotics-related technologies are becoming ubiquitous, for example sensors and wearable devices, and they are dominating national headlines and discussions on such innovations as driverless cars, big data and data mining, or medical robotics.  An emphasis on increasing the participation of under-represented groups in this site has the potential to extend both the range of research projects within the robotics field and the range of societal concerns and problems addressed by these researchers as they enter upon and conduct their careers. <br/><br/>This site will provide high-quality guided research experiences for undergraduate students with leading faculty in computer vision, field and space robotics, artificial intelligence, manipulation, and machine learning. Additional mentors, including researchers and graduate students, will provide unique perspectives and insights into science and engineering education careers. Mentors will meet weekly with scholars to facilitate their research experience and positive learning outcomes. The strategic goal of this site is to provide research experiences and mentorship to U.S. citizens and permanent residents from under-represented groups and those from higher education institutions with fewer research opportunities. Student recruitment and selection will be conducted accordingly and will draw on broad past experience in attracting under-served populations.  The leadership team and participating faculty share this commitment and bring expertise in mentoring students from diverse backgrounds to communicate their research results to coming generations of students, middle school and high school teachers, and the general public."
"1832383","WORKSHOP: Doctoral Consortium at the 2018 ACM/IEEE Human Robot Interaction (HRI) Conference","IIS","Cyber-Human Systems (CHS)","04/15/2018","04/12/2018","William Smart","OR","Oregon State University","Standard Grant","Ephraim P. Glinert","03/31/2019","$20,000.00","","smartw@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7367","7367, 7556","$0.00","This award support a Pioneers Workshop (doctoral consortium) of approximately 24 students (20 graduate participants, one undergraduate participant, and three student organizers), along with distinguished research faculty.  The event takes place as part of the first day of activities at the 13th International Conference on Human Robot Interaction (HRI 2018), held March 5-8 in Chicago, and which was jointly sponsored by ACM and IEEE.  HRI is the premier conference for showcasing the very best interdisciplinary and multidisciplinary research on human-robot interaction, with roots in diverse fields including robotics, artificial intelligence, social psychology, cognitive science, human-computer interaction, human factors, engineering, and many more.  It is a single-track, highly selective annual international conference that invites broad participation.  The theme of HRI 2018 was ""Robots for Social Good.""  The conference sought contributions from a broad set of perspectives, including technical, design, methodological, behavioral, and theoretical, that advance fundamental and applied knowledge and methods in human-robot interaction, with the goal of enabling human-robot interaction through new technical advances, novel robot designs, new guidelines for design, and advanced methods for understanding and evaluating interaction.  More information about the conference is available online at http://humanrobotinteraction.org/2018.  The Pioneers Workshop was designed to afford a unique opportunity for the best of the next generation of researchers in human-robot interaction to be exposed to and discuss current and relevant topics as they are being studied in several different research communities.  This is important for the field, because it has been recognized that transformative advances in research in this fledgling area can only come through the melding of cross-disciplinary knowledge and multinational perspectives.  Participants were encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years.  Participants also gained leadership and service experience, as the workshop was largely student organized and student led.  The PI expressed his strong commitment to recruiting women and members from under-represented groups.  To further ensure diversity the event organizers considered each applicant's potential to offer a fresh perspective and point of view with respect to HRI, and worked to recruit students who are just beginning their graduate degree programs in addition to students who are further along in their degrees.  <br/><br/>The Pioneers Workshops are designed to complement the conference, by providing a forum for students and recent graduates in the field of HRI to share their current research with their peers and a panel of senior researchers in a setting that is less formal and more interactive than the main conference.  During the workshop, participants talk about the important upcoming research themes in the field.  The formation of collaborative relationships across disciplines and geographic boundaries is encouraged.  To these ends, the workshop format encompasses a variety of activities including keynotes, a distinguished panel session, and breakout sessions.  To start the day, all workshop attendees briefly introduce themselves and their interests.  Following the opening keynote, approximately half of the participants present 3-minute overviews of their work, leading into an interactive poster session.  This enables all participants to share their research and receive feedback from students and senior researchers in an informal setting.  The workshop organizers facilitate the post-presentation discussion and encourage participants to ask questions of their peers during the interactive break and poster session.  After lunch, the remaining workshop participants give their 3-minute overviews, followed by presentation of their posters during a second interactive poster session.  Senior researchers (in addition to those on the panel) are invited to attend the student presentations and poster sessions in order to provide feedback to participants, and workshop participants are invited to present their posters during the main poster session of the HRI conference as well.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1755628","CRII: CHS: Automatically Praising Learning Process to Promote the Growth Mindset in Computer Science","IIS","Cyber-Human Systems (CHS)","03/15/2018","03/09/2018","Eleanor O'Rourke","IL","Northwestern University","Standard Grant","Dan Cosley","02/29/2020","$174,738.00","","eorourke@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7367","7367, 8228","$0.00","There is a pressing need to train large numbers of computer scientists to meet the demands of our nation's economy, but many students struggle in introductory programming courses. Recent studies show that these courses often promote the fixed mindset, or the belief that programming aptitude is an inborn trait. Psychology research shows that students with the fixed mindset view mistakes as indications of low ability and perform poorly in the face of challenge. In contrast, students with the growth mindset believe that programming aptitude is malleable and excel when challenged. This project aims to design, build, and evaluate programming tools that help students develop the growth mindset by automatically detecting and praising good learning behaviors as students write code. This research will contribute scientific knowledge about the growth mindset in the domain of computer science and provide insights about the process of learning to program. The project team will deploy the tools to hundreds of students at their own university and release them for free online for any student or teacher to use. If successful, this intervention has the potential to improve the experiences, skills, and diversity of students who successfully complete programming courses and go on to participate in employment and research in STEM fields.<br/><br/>This project aims to develop a new growth mindset intervention that leverages the programming environment by using artificial intelligence techniques to automatically detect and praise good learning processes in real time. Programming environments provide a unique opportunity to track and understand student learning behaviors, and offer a scalable environment for praising good practices automatically. By exposing and praising the learning process, this intervention will teach students to attribute their successes and failures to malleable learning processes, rather than an innate aptitude for computer science. This research will be conducted in two phases. First, the project team will develop heuristics that detect good learning processes using behavioral log data, leveraging the computer science education literature and studying the behavior of fixed and growth mindset students to identify good processes. Second, the team will iteratively design and build a programming environment extension that uses the validated heuristics to automatically detect and praise good learning process, and evaluate this intervention through a controlled ten-week study with university students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1636848","BD Spokes: SPOKE: SOUTH: Collaborative:  Using Big Data for Environmental Sustainability:  Big Data + AI Technology = Accessible, Usable, Useful Knowledge!","IIS","BD Spokes -Big Data Regional I, INFORMATION TECHNOLOGY RESEARC","10/01/2016","09/07/2017","Ashok Goel","GA","Georgia Tech Research Corporation","Standard Grant","Beth Plale","09/30/2019","$870,445.00","","ashok.goel@cc.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","024Y, 1640","028Z, 043Z, 7433, 8083, 9251","$0.00","Protecting the environment is among the biggest challenges facing our society. As the effects of environmental degradation, global warming and climate change continue to grow, there is an increasingly urgent and critical need for research and education in biological diversity, ecological modeling and environmental sustainability. On one hand, professional and citizen scientists need ready access to large-scale biological, ecological and environmental data for modeling, simulation and analysis. On the other, college teachers and students in biology and ecology need to access large-scale data in a form meaningful to them. The various audiences will engage with big data in different ways and so a variety of knowledge-building tools are needed. This project brings together two dozen scientists from a dozen institutions in academia, government and industry to address the problem of translating big data into meaningful knowledge in support of research and education in environmental sustainability.  <br/><br/>Encyclopedia of Life  (EOL) is the world's largest database of biological species and other biodiversity information. EOL also works closely with scores of other biodiversity datasets such as BISON, GBIF, and OBIS. This project seeks to make EOL and related biodiversity data sources accessible, usable, and useful, by integrating extant artificial intelligence tools for information extraction, modeling and simulation, and question answering. The focus of this project will be on the data engineering required for this integration and construction of a resulting EOL+ system. The project team will provide access to EOL+ such that users can build their own tools and services on top of EOL+. The team will work with the NSF South Big Data Hub to organize yearly workshops for building and supporting a community of users of EOL+. Professional and citizen scientists, and teachers and students alike, will be able to access EOL+ through NSF's South Big Data Hub webportal, and use it for modeling and analysis, explanation and prediction, as well as education and workforce development in biological diversity, ecological modeling and environmental sustainability."
"1734910","NCS-FO: Connecting Spikes to Cognitive Algorithms","IIS","IntgStrat Undst Neurl&Cogn Sys","01/01/2018","08/07/2017","Il Memming Park","NY","SUNY at Stony Brook","Standard Grant","Kenneth C. Whang","12/31/2021","$715,232.00","","memming.park@stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","CSE","8624","8089, 8091, 8551","$0.00","Experimental neuroscientists can record the signals communicated among the neurons that are collectively involved in producing meaningful behaviors, but making sense of these patterns of activity in terms of specific mental functions is challenging. This research project aims to discover the unseen mental processes that underlie such meaningful behavior from those recordings. The technology developed in this endeavor will uncover new ways of understanding mental processes hidden deep in the noisy signals collected from multiple neurons and will be used to derive new theoretical models (cognitive algorithms) to explain how populations of neurons work together. Such models will contribute to the development of diagnostic tools and neural prosthetics for cognitive dysfunctions in perception, working memory, and decision making, and can also inspire advances in machine learning and artificial intelligence.<br/> <br/>The technical goal of this project is to develop a data-driven framework amenable to visualization and interpretation of neural activity underlying cognition. The core of the project is the identification and recovery of an interpretable low-dimensional nonlinear continuous dynamical system that underlies observed neural time series, and its validation through experimental perturbations. This will answer two key scientific questions: (1) How are task and cognitive variables represented in low-dimensional neural trajectories; and (2) What are the laws that govern the time evolution of the neural states. Answering these questions will help us understand how subjects implement and switch between different cognitive strategies, and more importantly, will provide a means for testing previously proposed theoretical models of the neural computations underlying cognition. This project will develop a number of statistical methods that can (i) extract private and shared noise from single-trial electrophysiological observations, (ii) combine recordings from multiple sessions to infer a common cognitive neural dynamics model, and (iii) design control stimulation to perturb the current neural state. Specifically, these tools will be applied to recordings from cortical areas involved in visuomotor decision-making to discover (1) how the co-variability in a population of sensory neurons encodes decision variables, (2) how the cognitive strategy changes when sensory evidence statistics change, and (3) the underlying dynamics that sustain spatial working memory. The success of this project could transform how the field analyzes population activity with low-dimensional structure in the context of cognitive tasks and beyond."
"1763618","RI: Medium: Extreme Clustering","IIS","ROBUST INTELLIGENCE","09/01/2018","08/23/2018","Andrew McCallum","MA","University of Massachusetts Amherst","Standard Grant","Weng-keen Wong","08/31/2022","$1,103,937.00","Akshay Krishnamurthy","mccallum@cs.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","CSE","7495","075Z, 7495, 7924","$0.00","Clustering is a fundamental tool for data science, hypothesis discovery, pattern discovery, and information integration.  Given a collection of objects, clustering is the task of automatically grouping the objects so that objects within a group (called a cluster) are more similar to each other than to objects in other clusters.  Clustering is widely used in medicine, engineering, science and commerce. Most modern clustering methods scale well to a large number of objects, but not to a large number of clusters.  Furthermore currently widely used clustering methods excessively assign objects to clusters, suffer in accuracy, and do not represent uncertainty in the clustering.  All of these weaknesses limit analysis capabilities in many scientific, engineering, and other high-impact applications. This project is developing new machine learning and algorithms for large-scale clustering that scales to both massive number of objects and massive number of clusters.  This project will build on the recent preliminary success with a family of algorithms that build hierarchical clustering, which supports efficient re-assignment of data to new clusters, and which naturally represents uncertainty.  The new research aims to further increase accuracy and scalability. The project team will demonstrate its new research in multiple domains relevant to national priorities, including clustering chemical compounds for material science discovery, clustering single cell genome data, and entity resolution on scientific metadata (such as paper authors, patent authors, papers, institutions, etc)--- creating tools that advance scientific discovery, collaboration and scientific peer review.  All of the software developed as part of this project will be released as open source software in order to facilitate experimentation and adoption of our methods in research and practice. The project team will develop a tutorial at the intersection of machine learning and algorithms, and will additionally teach a course on efficient clustering methods to researchers beyond computer scientists.<br/><br/>This project will develop new research on machine learning and algorithms for hierarchical clustering that scales to both massive number of input objects, N, and massive number of clusters, K---a problem setting termed ""extreme clustering,"" named after its similarly- motivated supervised cousin, ""extreme classification."" The project builds on the successes of recent preliminary work on PERCH, a family of algorithms for large-scale, incremental-data, non-greedy, hierarchical clustering that has achieved remarkable new state-of-the-art results. The method efficiently routes new data points to the leaves of an incrementally-built tree. Motivated by the desire for both accuracy and speed, the approach performs tree rotations both for the sake of enhancing subtree purity and encouraging balanced trees. Experiments demonstrate that PERCH constructs more accurate trees than other tree-building clustering algorithms and scales well with both N and K, achieving a higher quality clustering than the strongest at clustering competitor in nearly half the time. The project will perform new research (a) improving flexibility through alternative clustering cost functions and data representations, (b) further improving scalability and accuracy through new tree routing functions, (c) developing new tree-cut methods for determining the best clusterings and distributions over clusterings, and (d) inventing new methods for joint clustering of multiple inter-related data instance types. Evaluation and application of the research will be conducted on multiple broad-impact, large-data domains, including biomedicine, material science, image analysis, and scientific information integration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1845216","EAGER: Visual Representation Learning Using Mixed Labeled and Unlabeled Data","IIS","ROBUST INTELLIGENCE","09/01/2018","08/13/2018","Hamed Pirsiavash","MD","University of Maryland Baltimore County","Standard Grant","Jie Yang","08/31/2020","$167,041.00","","hpirsiav@umbc.edu","1000 Hilltop Circle","Baltimore","MD","212500002","4104553140","CSE","7495","075Z, 7495, 7916","$0.00","Recent advances in deep learning has led to great results in visual recognition and object detection. These deep learning models have various applications from self-driving cars to early disease diagnosis and household robots. However, most such models are supervised, meaning that they need large scale manually annotated datasets to tune the parameters, and obtaining the annotation may be expensive in many applications. This project explores a family of self-supervised learning algorithms where the learning is based on unlabeled data only. The new models can learn visual features that can be used for various visual recognition tasks including object detection and action recognition. This project provides research opportunities for under-represented groups and integrates research outcomes into the course curriculum.<br/><br/>This project studies a family of self-supervised learning algorithms that can learn rich features from unlabeled images and videos. Self-supervised learning algorithms harvest the knowledge from unlabeled data by modeling some regularity in the space of natural images or videos. This project studies novel self-supervised learning algorithms based on constraining the learning by relating transformations of images to transformations of their representations. Moreover, this project studies a novel multi-task learning framework for aggregating the knowledge learned from multiple supervised and self-supervised learning algorithms. This algorithm uses quantization methods to ignore the task specific details of the representation in transferring the knowledge. This algorithm results in a rich set of representations that generalize well across various visual recognition tasks.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816380","CHS: Small: Teachable Object Recognizers for the Blind","IIS","Cyber-Human Systems (CHS)","08/15/2018","08/13/2018","Hernisa Kacorri","MD","University of Maryland College Park","Standard Grant","Ephraim P. Glinert","07/31/2021","$497,653.00","","hernisa@umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","CSE","7367","075Z, 7367, 7923","$0.00","Identifying objects, from packages of food to items of clothing, is an everyday task that we perform predominantly using our sense of sight.  Blind persons, for whom sighted help is not available, attempt such tasks using a combination of senses, strategies, and ad hoc organizing systems.  In recent years, members of the blind community have been early adopters of mobile apps that use image recognition for identifying objects.   However, such solutions currently have limited use for many objects of interest, because image recognizers cannot provide enough granularity to distinguish among all possible objects of interest across all users.  They also tend to be trained on images taken by sighted people with different background clutter, scale, viewpoints, occlusion, and image quality than in photos taken by blind users.  The goal of this research is to empower blind users to customize the recognition task to their objects of interest, photo-taking strategies, and environment, through a new approach called teachability which holds the promise of allowing end users that are non-experts to provide the training examples for the machine learning models in these applications.  Specifically, a teachable object recognizer (TOR) app will be designed, deployed and publicly released that blind users can train by providing labels along with a few examples of their objects through a smartphone's camera.  If successful, project outcomes will have broad impact by changing the nature of smart assistive technologies by empowering people with disabilities to define the functionality of such technologies, especially for small recognition tasks.<br/><br/>This project addresses the data scarcity issue in accessibility through teachability, where end users teach models pretrained on more available yet less relevant data, with fewer but more pertinent data specific to their needs.  The work will examine the concept of teachability in the context of object recognition for the blind, and will investigate whether accessibility research can leverage advances in computer vision with limited data from blind users.  Questions to be explored will include: How to best explain such intelligent systems to users for higher quality training data? What is the best way to measure their efficacy? What design parameters, sensing modalities, interactions, and algorithms are most influential on their success? The project will include a variety of research methods: surveys, participatory design sessions, prototype usability testing, lab-based user studies, and longitudinal real-world evaluation with blind users.  Using a working prototype mobile application on teachable object recognition, it will investigate accessible interactions on learning-to-train and examine the underlying mechanisms by which robustness and scalability of such teachable assistive technologies can be improved.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1814745","RI:Small: Learning shape features with deep neural networks","IIS","ROBUST INTELLIGENCE","09/01/2018","08/11/2018","Longin Jan Latecki","PA","Temple University","Standard Grant","Jie Yang","08/31/2021","$449,999.00","Haibin Ling","latecki@temple.edu","1801 N. Broad Street","Philadelphia","PA","191226003","2157077547","CSE","7495","075Z, 7495, 7923","$0.00","This project investigates how to effectively learn shape features with deep neural networks from images. It has been commonly believed that features learned by deep neural networks from images include texture, color, and shape of objects. Although visualizations of learned features demonstrate that contours of objects are extracted in the process of deep learning, our preliminary results provide clear arguments that 2D shape features are not well captured by current deep neural networks. This project develops a framework for effective learning of shape features with deep neural networks. The research brings new insights to a core problem in computer vision: shape understanding, which relates to many subfields in computer vision ranging from low-level tasks, such as segmentation and image statistics, to high-level ones, such as visual retrieval and object detection in images. The project includes plan to deploy the research results directly to applications such as biodiversity study (species recognition). The project also involves high school students and undergraduates in research.<br/><br/>This project conducts both theoretical and experimental research to gain better understanding why shape features are not well captured by current deep neural networks. Then it develops new learning strategies specifically targeted for shape features by following two main alternatives: (1) constraining the filter learning for Convolutional Neural Networks so that they are more contour focused, and (2) designing special structures of Deep Neural Networks for learning shape representation. The project designs circular sequential networks for silhouette-based shape classification, which encode naturally contour context information while implicitly performing contour matching. It also extends these networks to sketches, which are composed of both closed and open contours. Attention models are investigated on shapes to analyze roles of parts in shape representations so as to improve further shape matching and recognition algorithms.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816148","RI: Small: Uncovering Dynamics from Internet Imagery","IIS","ROBUST INTELLIGENCE","08/15/2018","08/10/2018","Jan-Michael Frahm","NC","University of North Carolina at Chapel Hill","Standard Grant","Jie Yang","07/31/2021","$450,000.00","","jmf@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","7495","075Z, 7495, 7923","$0.00","Virtual- and augmented reality (VR/AR) technologies have the promise to enable new and exciting ways of perceiving the world from the comfort of our homes and desks. Among the current applications of 3D VR visualizations, obtaining realistic depictions of actual real-world environments is highly desired in educational experiences. This project will develop scalable algorithms for computing ""living 3D models"" that can represent elements such as people and cars moving around the scene, water flowing in fountains, or chairs outside cafes being placed in different places on different days. To overcome the need for dedicated capture, the project targets publicly available Internet photo collections, which have the requisite data diversity to drive large-scale, cost-effective VR/AR content generation. The research not only supports the field of VR/AR but also provides improved analysis methods for a broad range of other applications, including forensic analysis, cultural heritage conversation, city planning, virtual training, and education, with particularly potential impact in enhancing social study experiences for economically disadvantaged students. <br/><br/>This project will aggregate object instances in the individual 2D images of the photo collection to infer the motion dynamics of the entire class of objects in the scene, e.g., all cars or all people. The method will thus infer and model the motion dynamics without ever seeing the motion of these objects, since there is typically only one observation per object instance available due to the uncontrolled, crowd-sourced capture. The key information for the inference will be the observation of the varying densities of the dynamic scene elements in the scene. The novel scene representation stores the accumulated dynamics in object class scene occupancy maps, as well as object class motion flows for the scene, e.g., the information where pedestrians move to in the scene and how they move within the scene. The developed methodology will open new and exciting avenues for research on jointly recovering semantic labels and 3D geometry in the wild, a task that is one of the currently most challenging problems in 3D computer vision.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813651","CHS: Small: Watch One, Do One, Teach One: An Integrated Robot Architecture for Skill Transfer","IIS","Cyber-Human Systems (CHS)","08/15/2018","08/08/2018","Brian Scassellati","CT","Yale University","Standard Grant","Ephraim P. Glinert","07/31/2021","$500,000.00","","brian.scassellati@yale.edu","Office of Sponsored Projects","New Haven","CT","065208327","2037854689","CSE","7367","075Z, 7367, 7923","$0.00","In the last several years, robotics research has transitioned from being concerned exclusively with building fully autonomous and capable robots to include building partially-capable robots that collaborate with human partners, allowing the robot to do what robots do best and the human to do what humans do best.  This transition has been fueled by a renaissance of safe, interactive systems designed to enhance the efforts of small- and medium-scale manufacturing, and has been accompanied by a change in the way we think robots should be trained.   Learning mechanisms in which the robot operates in isolation, learning from passive observation of people performing tasks, are being replaced by mechanisms where the robot learns through collaboration with a human partner as they accomplish tasks together.  This project will seek to develop a robot architecture that allows for new skills to be taught to a robot by an expert human instructor, for the robot to then become a skilled collaborator that operates side-by-side with a human partner, and finally for the robot to teach that learned skill to a novice human student.  To achieve this goal, popular but opaque learning mechanisms will need to be abandoned in favor of novel representations that allow for rapid learning while remaining transparent to explanation during collaboration and teaching, in conjunction with a serious consideration of the mental state (the knowledge, goals, and intentions) of the human partner.  A fundamental outcome of this work will be a unified representation linking the existing literature in learning from demonstration to collaborative scenarios and scenarios involving the robot as an instructor. Thus, project outcomes will have broad impact in application domains such as collaborative manufacturing, while also enhancing our substantial investment in education and training (especially research offerings for graduate and undergraduate investigators), and will furthermore enrich the efforts to broaden participation in computing.<br/><br/>This effort will build upon research in three subfields and extend the state-of-the-art to address deficiencies in each:<br/><br/>1 - Robot as Student.  Building on work from Learning from Demonstration, the team will construct robots that learn task models from humans.   However, to be useful to the other thrust areas, these models must not be opaque as many current learning techniques are.   Instead, a transparent model will allow the robot to provide and ask feedback about its performance, explain what it has learned, and to proactively ask questions that speed up learning.<br/><br/>2 - Robot as Collaborator.  The relatively new field of Human-Robot Collaboration struggles with synchronizing task execution between human and robot partners.   By linking to models of learned task behavior and models of user intention and understanding, the team will construct systems that become proficient in negotiating task allocation, accommodating user preferences, and restoring/updating internal representations in case of errors or change of plans.<br/><br/>3 - Robot as Teacher.  Fields including Intelligent Tutoring Systems build models of user knowledge, typically modeled using Bayesian knowledge tracing.  These models, however, simply show knowledge as known, unknown, or forgotten, and only for factual knowledge.   By linking with concrete representations of task and intent, the team will create robots that can detect, extend, or repair the mental model of a student for real-world tasks.<br/><br/>A set of milestones across three years will culminate in a demonstration of a robot that can learn a new task, collaborate on that task, and then teach that task to others.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813935","III: Small: Transfer Learning using Transformation among Models and Samples","IIS","INFO INTEGRATION & INFORMATICS","08/15/2018","08/03/2018","C.S. George Lee","IN","Purdue University","Standard Grant","Aidong Zhang","07/31/2021","$499,938.00","","csglee@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7364","075Z, 7364, 7923","$0.00","As huge volumes of unlabeled data are generated and made available in many domains, annotating data in these domains becomes burdensome and creates a major bottleneck in maintaining machine-learning databases.  This project will investigate a family of transfer-learning methods as an automatic annotation tool, without human involvement, in annotating data for various machine-learning settings.  The novelty of the project's transfer-learning approach is based on the common concept of matching-based optimization technique to solve the different forms of transfer learning.  The optimization will be carried out using transformations at different levels for different forms.  The planned transfer-learning framework will exploit lots of unlabeled data or a few labelled data in the target domain and prior knowledge in the form of labelled source data, source models or other auxiliary information in the source domain.  Using this common matching-based optimization framework, this will bring out a natural transition from low-level, sample-based matching to high-level, model-based matching for the different forms of transfer learning.  The family of transfer learning methods will have promising ramifications in diverse areas such as intelligent robots and self-driving cars so that they operate efficiently in new and changing environments without the need of large amount of annotated data in the new environments.<br/><br/>This project will investigate two major forms of transfer learning -- domain adaptation and few-shot learning.  The research will focus on studying the effect of the proposed matching-based optimization technique to solve the different forms of transfer learning.  The project will focus on three major tasks, depending on what information is available in each task: (Task 1) Unsupervised domain adaptation, where the source-domain data is labelled while the target-domain data is unlabeled.  In this case, the project team will investigate the optimization based on matching each source-domain sample with each target-domain sample to learn a generalizable target model; (Task 2) Hypothesis transfer learning, where the source and the target domain tasks are different, and only source models and sparsely labelled target domain data will be used to learn a generalizable target model.  The model will be learned using matching between source models and target-domain samples; (Task 3) Few-shot learning, where the goal is to learn a generalizable target model from a few labelled samples in the target domain by utilizing auxiliary source knowledge.  The project team will study whether transformation between source-model parameters can be substituted as useful auxiliary source-domain knowledge.  Hence, the planned research will minimize the requirement of obtaining lots of labelled samples used in machine learning, and it will realize robust learning systems that are generalizable across tasks and domains.  Furthermore, since the matching is carried out among each individual sample/model of information locally and explicitly, the results are expected to be better than previous methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815275","RI: SMALL: Robust Reinforcement Learning Using Bayesian Models","IIS","ROBUST INTELLIGENCE","08/15/2018","07/31/2018","Marek Petrik","NH","University of New Hampshire","Standard Grant","Weng-keen Wong","07/31/2021","$437,753.00","","mpetrik@cs.unh.edu","51 COLLEGE RD SERVICE BLDG 107","Durham","NH","038243585","6038622172","CSE","7495","075Z, 7495, 7923","$0.00","Basing decisions on data is preferable to relying on heuristics or rules of thumb. Using data effectively, however, can be challenging. In domains like agriculture or medicine, datasets are usually small, biased, and noisy. For instance, the full effects of reduced pesticide applications depend on the weather and the impacts on yield may not be known until the harvest. Reducing pesticide applications reduces costs and provides ecological and consumer benefits, but using too little of it can easily cause a crop failure and significant financial losses. These dual problems of limited data availability and a high cost of failure are also common in manufacturing, maintenance, and even robotics. Because most existing reinforcement learning methods assume large datasets, stakeholders often dismiss data-driven methods and rely on heuristics to make decisions that are apparently safe but quite sub-optimal. This research develops new robust methods for data-driven decision making that can recommend good actions that are also safe even when data is limited. The new reinforcement learning methods use prior domain knowledge to estimate the confidence in possible outcomes to prevent catastrophic failure when predictions are incorrect. The practical viability of these methods is tested on the problem of using historical data to recommending improved pesticide schedules for fruit orchards and is disseminated to practitioners.<br/><br/>This research targets reinforcement learning problems with 1) limited or expensive data and 2) a high cost of failure. When bad decisions cause large losses, injury, or death, then having confidence in a policy's quality is more important than its optimality gap. Computing high-confidence policies in reinforcement learning is difficult. Even small errors can quickly accumulate through positive feedback loops and covariate shift. Therefore, more robust methods are needed to convince practitioners to benefit from data instead of relying on heuristics. The project combines robust optimization with model-based reinforcement learning to compute good policies that are resistant to data errors. Robust optimization has achieved successes in many areas but can be difficult to use with reinforcement learning. It requires a model of plausible uncertainty levels, so-called ambiguity sets, to properly balance solution?s quality and confidence. Constructing good ambiguity sets manually in sequential decision problems is very difficult even for robust optimization experts. This research investigates a new data-driven Bayesian approach to robust reinforcement learning. It combines hierarchical Bayesian models with robust optimization to leverage powerful hierarchical modeling techniques while avoiding the computational complexity often associated with Bayesian reinforcement learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815455","RI: Small: Collaborative Research: Computational Methods for Argument Mining: Extraction, Aggregation, and Generation","IIS","ROBUST INTELLIGENCE","08/01/2018","07/24/2018","Claire Cardie","NY","Cornell University","Standard Grant","Tatiana D. Korelsky","07/31/2021","$290,823.00","","cardie@cs.cornell.edu","373 Pine Tree Road","Ithaca","NY","148502820","6072555014","CSE","7495","075Z, 7495, 7923","$0.00","Understanding, evaluating and generating arguments are all crucial elements in the decision-making and reasoning process. Not surprisingly then, a multitude of arguments are encountered and constructed on a daily basis as decisions are made at work and at home, in our social life and in our civic life. In spite of their ubiquity in our lives, most people are not particularly skilled in the interpretation or generation of arguments. At best, making sense of the often massive amount of argumentative online text on a topic of interest remains a daunting task. And while numerous tools exist for representing, modeling and visualizing arguments and argumentative discussions, they are limited by the substantial human effort required to input, organize and annotate arguments for use by the tools. Thus there exists a pressing need for, and this project aims to develop, automated techniques from the field of Natural Language Processing to support all facets of argumentation. This project will have a wide array of broader impacts, including providing other<br/>researchers with annotated datasets and tools for the analysis and generation of arguments, enhancing education through graduate and <br/>undergraduate mentoring, and promoting STEM education diversity through programs for middle and high school girls.  <br/><br/><br/>This project aims to break new ground in the burgeoning area of argument mining. It develops a collection of computational models that comprise the basis of an argumentation toolkit---methods that can be combined and reused to support a range of argumentation applications. The project focuses on inter-related threads of research covering three critical areas of exploration for computational argumentation: (1) argument extraction---making sense of argumentative text. Drawing upon recent developments in structured learning, techniques are developed to identify the components and the structure of an argument within a single document or single turn in an online dialog. (2) Argument aggregation---clustering the components of argumentative text (e.g. sentences, turns) drawn from multiple documents according to the facets of the topic under discussion that they address. Representation learning methods are proposed to better capture topical content and argumentative styles. (3) Argument generation---constructing coherent arguments via rewriting. A neural argument generation framework with key phrase extraction as an intermediate representation is created to improve interpretation of sentences from different sources. A discourse-aware neural generation model is also investigated as an extension to improve the coherence of the generated text.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1814522","RI: Small: Applying discrete reasoning steps in solving natural language processing tasks","IIS","ROBUST INTELLIGENCE","08/01/2018","07/25/2018","Gregory Durrett","TX","University of Texas at Austin","Standard Grant","Tatiana D. Korelsky","07/31/2021","$447,614.00","","gdurrett@cs.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","7495","075Z, 7495, 7923","$0.00","Modern natural language processing systems are effective at shallow analysis of unstructured text data, performing tasks such as discovering events, identifying the actors of those events, and grouping events with the same actors. Neural networks help make these systems robust to effects like paraphrasing, but still capture mostly superficial text patterns. To answer deeper questions about things like causal relationships between the events in a text, a system might need to combine several pieces of information, abstract away irrelevant details, and incorporate prior world knowledge to arrive at an answer. This project aims to develop systems that can address these challenges: these systems explicitly model reasoning over text and draw on the power of neural networks to do this reasoning in a nuanced way. Such reasoning is explicitly taught to the systems via ""handholding"" supervision, which encourages the systems to mimic how humans solve a problem and helps them generalize better to new problem instances. This alignment with what humans do also serves to expose the systems' decision-making processes; it provides a form of explanation of their behavior so that one may evaluate them against desired criteria such as equitability.<br/><br/>This proposal's technical innovation is focused on two fronts: designing latent variable models and exploiting new types of handholding supervision during model training. These techniques are explored in the context of three challenging problems requiring complex reasoning: (1) solving mathematical word problems; (2) resolving coreference using world knowledge; (3) answering questions from documents. For each problem, new models are proposed centering around discrete derivations of answers, which draw on state-of-the-art tools like attention-based recurrent neural networks to capture the larger context of the reasoning process. The discreteness of the models' decisions provides an anchor to incorporate auxiliary supervision, which is hard to do in fully end-to-end neural models. The nature of the handholding supervision depends on the task and is a combination of incidental supervision, heuristically identified derivations, and targeted human annotation. Each of the addressed problems tests different aspects of the approach, such as handling complex derivations and incorporating world knowledge, and these problems yield concrete evaluation frameworks to understand the efficacy of the proposed techniques.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813341","RI: Small: Collaborative Research: Computational Methods for Argument Mining: Extraction, Aggregation, and Generation","IIS","ROBUST INTELLIGENCE","08/01/2018","07/24/2018","Lu Wang","MA","Northeastern University","Standard Grant","Tatiana D. Korelsky","07/31/2021","$209,177.00","","kellywanglu@gmail.com","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","7495","075Z, 7495, 7923","$0.00","Understanding, evaluating and generating arguments are all crucial elements in the decision-making and reasoning process. Not surprisingly then, a multitude of arguments are encountered and constructed on a daily basis as decisions are made at work and at home, in our social life and in our civic life. In spite of their ubiquity in our lives, most people are not particularly skilled in the interpretation or generation of arguments. At best, making sense of the often massive amount of argumentative online text on a topic of interest remains a daunting task. And while numerous tools exist for representing, modeling and visualizing arguments and argumentative discussions, they are limited by the substantial human effort required to input, organize and annotate arguments for use by the tools. Thus there exists a pressing need for, and this project aims to develop, automated techniques from the field of Natural Language Processing to support all facets of argumentation. This project will have a wide array of broader impacts, including providing other<br/>researchers with annotated datasets and tools for the analysis and generation of arguments, enhancing education through graduate and <br/>undergraduate mentoring, and promoting STEM education diversity through programs for middle and high school girls.  <br/><br/><br/>This project aims to break new ground in the burgeoning area of argument mining. It develops a collection of computational models that comprise the basis of an argumentation toolkit---methods that can be combined and reused to support a range of argumentation applications. The project focuses on inter-related threads of research covering three critical areas of exploration for computational argumentation: (1) argument extraction---making sense of argumentative text. Drawing upon recent developments in structured learning, techniques are developed to identify the components and the structure of an argument within a single document or single turn in an online dialog. (2) Argument aggregation---clustering the components of argumentative text (e.g. sentences, turns) drawn from multiple documents according to the facets of the topic under discussion that they address. Representation learning methods are proposed to better capture topical content and argumentative styles. (3) Argument generation---constructing coherent arguments via rewriting. A neural argument generation framework with key phrase extraction as an intermediate representation is created to improve interpretation of sentences from different sources. A discourse-aware neural generation model is also investigated as an extension to improve the coherence of the generated text.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815886","RI: Small: Coordination in tightly coupled domains: Stepping stone rewards to induce the correct joint actions","IIS","ROBUST INTELLIGENCE","09/01/2018","07/02/2018","Kagan Tumer","OR","Oregon State University","Standard Grant","James Donlon","08/31/2021","$400,000.00","","kagan.tumer@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","CSE","7495","075Z, 7495, 7923","$0.00","This project introduces a new multiagent learning approach that leads to coordinated behavior in tightly coupled domains, that is, in domains where all agents must do the right thing at the right time for the team to achieve its goals. For example, getting a team of agents to lift and move an object heavier than the payload capacity of any single agent requires a sufficient number of agents to perform the correct action at the correct time. Unfortunately, most current learning methods fail in such situations because they rely on reinforcing the correct agent behavior only after the agents stumble upon the right actions. But what if the agents never jointly find the right actions? This project addresses this issue by introducing ""stepping-stone rewards"" that incentivize agents to perform the right actions even if their teammates have not yet found the correct complementary actions. The impact of this project will be to create larger and more capable multiagent teams that can be deployed in industry (such as factory robots that are not limited to a single task), in the field (such as autonomous search and rescue systems), in education (such as interactive learning via online gameplay) and in the home (such as networks of smart appliances).<br/><br/>The main technical contribution of this project is to shift the learning problem faced by an agent from ""did I take the correct action?"" to ""would my action have been correct had other agents taken the complementary action?"" In tightly coupled multiagent domains, the first question results in very little positive feedback, creating a difficult to impossible learning problem. The new stepping stone rewards leverage hypothetical partners (partners that are surmised by an agent to explore the joint-action space) to overcome this difficulty by assessing the potential benefits of a particular action. Intuitively, stepping-stone rewards create a gradient for the agents to follow to enable fast and efficient learning in tightly coupled domains.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1727303","CI-EN: Enhancement of a Large-scale Multiagent Simulation Tool","CNS","COMPUTING RES INFRASTRUCTURE","09/01/2017","07/11/2017","Sean Luke","VA","George Mason University","Standard Grant","James Donlon","08/31/2020","$896,303.00","Robert Simon, Andrew Crooks","sean@cs.gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","CSE","7359","7359","$0.00","An agent-based simulation is a software simulation of many independent actors (people, robots, animals, companies, etc.) interacting in complex ways.  For example, one might build a simulation of a swarm of ants, a school of fish, a large group of robots collectively building a house, a city of people under siege by a large medieval army, or the spread of urban legends over a social network. These kinds of simulations are used for everything from building software for swarms of delivery robots, to understanding the spread of disease in third-world slums, to predicting the impact of climate change on human migration patterns.  Similarly, these simulations help researchers and policy makers in engineering and robotics, in artificial intelligence, and in the biological and social sciences.  Such simulations can get very large, with large numbers of actors.  This project involves building a software tool to assist in the development of large-scale agent-based simulations spread over potentially many separate computers, and to make it easy for them to place their agents in simulated locations on the Earth.  At the same time the tool will be easy to use for high school and undergraduate students.<br/><br/>The project will develop a distributed agent-based modeling tool for constructing large simulations of swarms and groups of agents.  The project enhances an existing, successful open-source Java multiagent simulation library called MASON.  MASON is designed to run on a single machine; but the enhanced version will also allow distribution over many machines.  The enhanced tool will also include facilities for embedding agents in geographical information systems (GIS), model optimization and automation, interfaces for alternative programming languages targeting the Java Virtual Machine, statistics facilities, internal testing and verification, and integration with software tools.  The enhancement will not only provide a distributed simulation facility for researchers in the social sciences, biology, and engineering, but will also improve on MASON's graphical interface and language facilities to make it easier to use as a teaching tool."
"1729720","The Development of Relational Processing in Infancy","BCS","Science of Learning, DS - Developmental Sciences","08/15/2017","08/22/2017","Susan Hespos","IL","Northwestern University","Standard Grant","Soo-Siang Lim","07/31/2020","$596,080.00","Kenneth Forbus, Dedre Gentner","hespos@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","SBE","004Y, 1698","059Z, 1698","$0.00","Analogical ability is the ability to make relational comparisons between objects, events, or ideas, and to see common relational patterns across them.  It is a cornerstone of higher reasoning ability, and is essential for learning mathematics and science.  This project  investigates the nature of this ability and how it develops in infants, tracing its development over the first year of life.  Delineating the conditions that promote relational learning in young infants, will lead to insights into how best to promote relational learning in children and in adults who show lags in abstract learning. One result of the proposed studies will be a set of methods and tools that can be used by teachers and caregivers to support relational learning. For example, this research can serve as a springboard for developing targeted interventions for young children diagnosed with language delay, as well as those diagnosed with autistic spectrum disorders.  Another result will be a better understanding of how to build artificial intelligence systems that learn more like people, with far less data than today's systems require.<br/><br/>The starting point for this proposal is a recent demonstration that 7- and 9-month-old infants can form abstract same and different relations, and apply them to new objects.  The preliminary studies suggest that even 3-month-old infants are capable of relational learning; however, they are highly vulnerable to distraction by the interestingness of the objects in the pairs.  The new research will use four series of experiments to trace infants' ability to learn abstract relations.  The first will examine the processes that promote relational learning in 3-month-olds.  The second will investigate the conditions that support spontaneous comparison and learning in 7- and 9-month-olds.  The third series will test how language influences relational learning- specifically, whether naming relations can improve learning, and whether naming objects can impede relational learning.  The fourth series of experiments will investigate the generalizability of these effects by testing a variety of abstract relations.  Computational modeling of the learning patterns found in our studies will provide complementary insights on these processes. Taken together, these studies will reveal information critical to understanding analogical processes and the origin and evolution of higher-order cognition."
"1416907","IBSS: New Methods for Investigating the Formation of Individual and Shared Concepts and Their Dynamic Dispersion Across Related Societies","SMA","Interdiscp Behav&SocSci IBSS","09/01/2014","08/29/2014","Kimberly Jameson","CA","University of California-Irvine","Standard Grant","Brian D. Humes","02/28/2019","$980,923.00","Louis Narens, Natalia Komarova, Dominik Wodarz","kjameson@uci.edu","141 Innovation Drive, Ste 250","Irvine","CA","926173213","9498247295","SBE","8213","8213, 8605","$0.00","This interdisciplinary research project will develop and test new mathematical models that explore the ways through which conceptual meaning is represented in languages as those languages change in complexity over time.  The project investigators also will examine the ways such meaning is shared among groups of individuals in societies.  The project's models will describe the dynamic development of concepts as a geometric system and will provide methods for understanding the linguistic representation of concepts and the ways semantic meaning from one community can be influenced by that of neighboring communities.  Although this project will focus on the ways that color terms have evolved within languages and societies, the insights and information from this project will apply beyond the domain of color representation to any set of concepts in which objects have a similarity structure that can be assessed and described mathematically.  Examples of the kinds of situations where the approach and methods to be developed during this project will have utility are the following:  (1) the development of unambiguous and formally scalable artificial intelligence and robotic analogs of human classification and categorization systems; (2) the development of a global communication methodology that could be used to enhance  rapid global information messaging capabilities; and (3) the construction of standardized systems for information representation in critical systems, such as medical diagnostic systems and transportation systems. <br/><br/>The formation and communication of concepts permeate a diverse range of human activities.  They play roles in education systems; in the organization and design of transportation systems; in the physical and virtual design of retail markets and consumer goods; in classifications of quality and risk in medical diagnoses; in business performance; and in social values.  Psychologists, linguists, anthropologists, computer scientists, and other scholars have studied concepts by focusing on specific examples of concept formation while trying to understand how such conceptual systems are formed.  One specific concept that has received attention is how color terms ""evolve"" and how their conceptual meaning is understood and shared by members of a society.  Conceptualization of color is an important special case because color stimuli can be precisely measured and easily duplicated, and the human perceptual space of a million colors can be described with mathematical precision.  This project will focus on the development and testing of mathematical models that capture the ways color term concepts are categorized and shared.  The models to be designed and tested will use geometric formalisms for characterizing meaning in general and will specifically demonstrate their use by investigating color terms and concepts.  Testing will use data from a wide variety of societies, including the Mesoamerican Color Survey (MCS), a database of systematically collected categorization behaviors of 900 individuals who have communicated with one or more of 116 endangered or developing languages that are at various stages of color lexicon development.  The MCS is largely in hand-written form, and one product of this project will be its full digitalization using modern computer science crowd-sourcing methods.  Full digitalization of the MCS database will make it available for use by the global scientific community for the first time.  This project is supported through the NSF Interdisciplinary Behavioral and Social Sciences Research (IBSS) competition."
"1835690","Elements: Software: Autonomous, Robust, and Optimal In-Silico Experimental Design Platform for Accelerating Innovations in Materials Discovery","OAC","DMR SHORT TERM SUPPORT, Software Institutes","10/01/2018","09/08/2018","Byung-Jun Yoon","TX","Texas A&M Engineering Experiment Station","Standard Grant","Bogdan Mihaila","09/30/2021","$600,000.00","Raymundo Arroyave, Xiaoning Qian, Xiaofeng Qian","bjyoon@ece.tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","CSE","1712, 8004","026Z, 054Z, 077Z, 7923, 7926, 8004, 9216","$0.00","Accelerating the development of novel materials that have desirable properties is a critical challenge as it can facilitate advances in diverse fields across science, engineering, and medicine with significant contributions to economic growth. For example, the US Materials Genome Initiative calls for cutting the time for bringing new materials from discovery to deployment by half at a fraction of the cost, by integrating experiments, computer simulations, and data analytics. However, the current prevailing practice in materials discovery relies on trial-and-error experimental campaigns and/or high-throughput screening approaches, which cannot efficiently explore the huge design space to develop materials with the targeted properties. Furthermore, measurements of material composition, structure, and properties often contain considerable errors due to technical limitations in materials synthesis and characterization, making this exploration even more challenging. This project aims to develop a software platform for robust autonomous materials discovery that can shift the current trial-and-error practice to an informatics-driven one that can potentially expedite the discovery of novel materials at substantially reduced cost and time. Throughout the project, the PI and Co-PIs will mentor students and equip them with the skills necessary to tackle interdisciplinary problems that involve materials science, computing, optimization, and artificial intelligence. Research findings in the project will be incorporated into the courses taught by the PI and Co-PIs, thereby enriching the learning experience of students.<br/><br/>The objective of this project is to develop an effective in-silico experimental design platform to accelerate the discovery of novel materials. The platform will be built on optimal Bayesian learning and experimental design methodologies that can translate scientific principles in materials, physics, and chemistry into predictive models, in a way that takes model and data uncertainty into account. The optimal Bayesian experimental design framework will enable the collection of smart data that can help exploring the material design space efficiently, without relying on slow and costly trial-and-error and/or high-throughput screening approaches. The developed methodologies will be integrated into MSGalaxy, a modular scientific workflow management system, resulting in an accessible, reproducible, and transparent computational platform for accelerated materials discovery that allows easy and flexible customization as well as synergistic contributions from researchers across different disciplines.<br/><br/>This project is supported by the Office of Advanced Cyberinfrastructure in the Directorate for Computer & Information Science & Engineering and the Division of Materials Research in the Directorate of Mathematical and Physical Sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1713439","Applying Game Design Principles for Supporting Computational Literacy Experiences in Museum Exhibits","DRL","AISL","09/01/2017","08/16/2017","Matthew Berland","WI","University of Wisconsin-Madison","Standard Grant","Catherine Eberbach","08/31/2020","$951,474.00","Leilah Lyons, Matthew A. Cannady","mberland@wisc.edu","21 North Park Street","MADISON","WI","537151218","6082623822","EHR","7259","8244","$0.00","Becoming computationally literate is increasingly crucial to everyday life and to expanding workforce capacity. Research suggests that computational literacy--knowing what, when, how, and why to use the ideas of computer science, in combination with the capacity to view problems and potential solutions through the lens of computational structures and procedures--can be supported through digital game play. This project aims to develop a social and creative exhibit game that foregrounds aspects of computer science, specifically artificial intelligence (AI) and computer programming, in ways that enable youth to explore, construct, and share computational complex systems content with one another and other museum visitors. To play the game, pairs of youth visitors will use code cards to program the behavior of AI animals in a virtual forest. As they do so, youth will engage with computational literacy practices, such as basic computer programming, describing their computational ideas, and doing computational problem solving with their friends. Their activity will be projected on a large screen as a strategy for enabling youth to test, rehearse, and communicate their computational ideas and to also interest other visitors into computational problem solving.<br/><br/>Using multi-perspective and iterative design-based research, university learning scientists, museum practitioners, and game developers will pursue research questions around how science museums can better engage youth who are traditionally underrepresented in computer science in complex computational practices. Data sources will include interactive-log data, observations of visitor interactions with the game, visitor interviews, and visitor surveys. A multimodal and mixed methods approach that searches for convergences between qualitative analysis, quantitative analysis, and learning analytics will be used to generate research findings. Changes in computational literacy will be assessed by evaluating what problems visitors choose to solve with programming, how they frame those problems, and their selections from among possible solutions, what they program, how they program, and how they describe programming ideas. The results of this project will include: 1) a social, interactive gameplay experience that supports the development of computational literacy; 2) design principles for game-based exhibits that facilitate development of computational literacy; and 3) new knowledge of variations in design and gameplay across diverse gameplay users, including those from underrepresented groups in computer science. It is anticipated that 1,000 museum youth visitors will directly participate in the study.  <br/><br/>This project is funded by the Advancing Informal STEM Learning (AISL) program, which seeks to advance new approaches to, and evidence-based understanding of, the design and development of STEM learning in informal environments. This includes providing multiple pathways for broadening access to and engagement in STEM learning experiences, advancing innovative research on and assessment of STEM learning in informal environments, and developing understandings of deeper learning by participants."
"1733884","AitF: Collaborative Research: Efficient High-Dimensional Integration using Error-Correcting Codes","CCF","Algorithms in the Field","09/01/2017","08/11/2017","Dimitris Achlioptas","CA","University of California-Santa Cruz","Standard Grant","Tracy J. Kimbrel","08/31/2021","$438,177.00","","optas@cs.ucsc.edu","1156 High Street","Santa Cruz","CA","950641077","8314595278","CSE","7239","","$0.00","Efficiently estimating integrals of high-dimensional functions is a fundamental and largely unsolved computational problem, manifesting in scientific areas from biology and physics to economics. In particular, in Artificial Intelligence and Machine Learning, a wide array of methods are computationally limited precisely because they require the computation of high-dimensional integrals. While computing such integrals exactly is highly intractable, approximations suffice for many applications. Currently, approximation is attempted using two main classes of algorithms: Markov Chain Monte Carlo (MCMC) sampling methods and variational inference techniques. The former are asymptotically accurate, but their computational budget is inflexible and often prohibitive. The latter have manageable computational budget, but typically come with no accuracy guarantees. This project will investigate a new family of computationally efficient approximation methods which reduce the task of integration to the much better studied task of optimization, thus leveraging decades of research and engineering in combinatorial optimization methods and technology. A key goal of the project is to develop an open-source software library of efficient tools for high-dimensional integration.<br/><br/>The reduction of integration to optimization builds on the probabilistic reduction of decision problems to uniqueness promise problems developed in the mid-80s. Specifically, the idea is to use systems of random parity equations in order to specify random subsets of the function's domain, and relate integration to the task of optimization over these subsets. In general, the capacity for efficient optimization fundamentally stems from the capacity to summarily dispense large parts of the domain as uninteresting. The key question to be addressed by the project is whether it is possible to define random subsets over which optimization is both tractable and informative for integration. To that end, the project will employ random systems of linear equations corresponding to Low Density Parity Check (LDPC) matrices for error-correcting codes. The energy landscape, i.e., the number of violated equations, of such systems is far smoother than that of the generic (dense) random systems of linear equations that underlie the original mid-80s technique, thus being far more amenable to optimization. The project will also build upon the deep understanding gained in the last two decades for LDPC codes in the field of communications, with the goal of integrating a priori knowledge about the energy landscape in the optimization strategy. This will provide a fundamentally new use for error-correcting codes, creating a bridge between the areas of optimization and information theory."
"1828265","MRI: Acquisition of a Composable Platform as a Service Instrument for Deep Learning & Visualization (COMPaaS DLV)","CNS","IIS SPECIAL PROJECTS","10/01/2018","09/07/2018","Maxine Brown","IL","University of Illinois at Chicago","Standard Grant","Rita V. Rodriguez","09/30/2021","$997,363.00","Robert Kenyon, Andrew Johnson, Georgeta-Elisab Marai","maxine@uic.edu","809 S. Marshfield Avenue","CHICAGO","IL","606124305","3129962862","CSE","7484","1189","$0.00","This project is about acquiring a much-in-demand Graphics Processing Unit (GPU)-based instrument, to develop a Service Instrument for Deep Learning and Visualization called ""COMPaaS DLV: COMposable Platform"".  The project aims to complement available campus computing resources via the campus's research network. It will be able to access local and remote computing and storage facilities funded, including XSEDE, Blue Waters, Deep Learning Instrument and Chameleon. This critical instrumentation will provide a platform to pursue fundamental science and engineering research training in deep learning (data mining and data analytics, computer vision, natural language processing, artificial intelligence), visualization (simulation, rendering, visual analytics, video steaming, image processing), and a combination of deep learning and visualization (e.g., when data is so large that it cannot be easily visualized, then deep learning is used to extract features of interest to be visualized). The instrumentation also enables investigation and contribution to societal issues in disciplines such as anthropology, biology, cybersecurity, data-literacy, fraud detection, healthcare, manufacturing, urban sustainability, and cyber-physical systems (e.g., autonomous cars). <br/><br/>Its design utilizes state-of-the-art computer architecture, known as composable architecture, in which the computer's components (traditional processor, GPU, storage, and networking) form a fluid pool of resources, such that different applications with different workflows can be run simultaneously, with each configuring the resources it requires almost instantaneously, at any time. Given composable infrastructure scalability and agility, it is more beneficial than traditional clouds and clusters that are rigid, overprovisioned, and expensive.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1747397","Doctoral Dissertation Research: Information, Public Opinion, and Behavior","SES","Political Science DDRIG","07/15/2018","07/26/2018","Mary Gallagher","MI","University of Michigan Ann Arbor","Standard Grant","Brian D. Humes","06/30/2019","$15,733.00","Blake Miller","metg@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","SBE","009Y","1371, 9179","$0.00","This project explores how political information manipulation in authoritarian regimes can affect the behaviors, attitudes, and opinion of individuals. This project is important to our understanding of how authoritarian regimes gain popular support and maintain control over populations using social media and big data. Planned survey experiments will measure the effect of political information manipulation tactics (censorship, astroturfing, and digital repression).   As much of social interaction has moved into a digital space, governments have greater access to personal and social data. At the same time, the fields of artificial intelligence and machine learning have experienced unprecedented growth along with a similarly rapid growth in the power of microprocessors. These advances have given governments better tools to digest, process, and make informed decisions based on these massive stores of personal data. This project is a first step toward understanding how these common data-driven information manipulation tactics work and impact individuals in authoritarian governments, essential knowledge for scholars of modern politics and public opinion in a highly networked and digital age.<br/><br/>In this project, the effects of experiencing political information manipulation on individual behaviors and opinion in authoritarian regimes are explored using both survey experiments and large-N correlational analyses. It is hypothesized that government information manipulation that is covert---when the identity of the government as information manipulator obscured---will increase the magnitude of individual-level effects in a direction favorable to the government. More specifically, when compared to more overt government information manipulation, covert information manipulation will be more persuasive, will more dramatically increase positive perceptions of the state, will more dramatically decrease one's sense of political efficacy, and will decrease one's willingness to express opinions more than overt manipulation. To test these hypotheses, a pseudo experiment will be run using a large database of syndicated articles identified using automated near-duplicate detection. Syndicated state media articles, appearing on different news websites with identical text but different comments, will be compared across a treatment group (articles with comments from astroturfers and ordinary users) and a control group (articles with comments from only ordinary users). Variables targeting each of the hypotheses above will be drawn from the text using statistical and natural language processing methods. Additionally, three survey experiments will be conducted to test, respectively, the effect of censorship, astroturfing, and digital repression in overt and covert forms. This work is critical to understand how modern authoritarian regimes leverage social media to guide public opinion, mobilize regime support, and demobilize opponents.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1727894","SNM: Manufacturing Autonomy for Directed Evolution of Materials (MADE-Materials) for Robust, Scalable Nanomanufacturing","CMMI","SNM - Scalable NanoManufacturi, NANOMANUFACTURING","09/01/2017","05/21/2018","David Hoelzle","OH","Ohio State University","Standard Grant","Khershed Cooper","08/31/2021","$1,502,521.00","Max Shtein, Kira Barton","hoelzle.1@osu.edu","Office of Sponsored Programs","Columbus","OH","432101016","6146888735","ENG","025Y, 1788","081E, 083E, 084E, 116E, 9178, 9231, 9251","$0.00","The development and manufacturing of cutting edge materials typically involves time-consuming materials and process design phases, followed by extensive testing of samples to adjust process conditions as the manufacturing scales up from the lab, to pilot plan, to industrial process scale. These distinct steps drive up the cost barrier to introduction of new and improved materials into the industrial pipeline and increase the cost of domestically manufactured advanced nanomaterials. Fortunately, recent developments in numerical modeling, additive manufacturing, and rapid testing of materials suggest that a new approach to material development and nanomanufacturing, where the previously distinct and time-consuming phases could be carried out nearly instantaneously to arrive at optimal material structure as well as process conditions for its manufacture. The focus of this award is to revamp the traditional, open-loop synthesis of nanostructured materials by: 1) using a versatile 3-D printing approach to manufacture these nanomaterials and nanostructures, 2) incorporate material property characterization directly into the printing process, and 3) use an artificial intelligence (AI) algorithm to adjust on the fly process conditions to achieve desired material properties. These concepts and components will be integrated into technical coursework, hands-on research opportunities, and outreach workshops to a broad range of students and the public. The co-PIs plan to leverage existing outreach and educational activities through their group's collaboration with a local museum, as well as curricular and extracurricular activities.<br/> <br/>The approach and framework is an investigation of process modeling, materials synthesis and characterization, and system design to autonomously discover new material configurations and reduce manufacturing defects and uncertainty. This AI framework will ""understand"" process-structure-property relationships, manufacturing constraints, and, importantly, statistical variations in material properties and manufacturing quality. The intellectual merit of this study is the discovery of general nanomanufacturing tools and feedstocks, with supervisory genetic algorithms, that autonomously correct for defects and compensate for innate manufacturing inaccuracies by a search for alternative designs; this is in contrast to standard tools that minimize uncertainty (e.g. environmental controls) or rely on post-fabrication characterization with human intervention. The framework will be tested using nanoscale additive manufacturing (AM) as the fundamental manufacturing tool and nanostructured metamaterials as the application. The paradigm and nanoscale metamaterials made via this approach have far-reaching impacts on scalable nanomanufacturing for integrated systems. The paradigm of systems that autonomously evolve parameters to meet construct specifications is extensible to macroscale additive manufacturing and pharmaceuticals where the process parameter space and chemistries available is vast, and design is not intuitive. Additive nanomanufacturing has the potential to transform metamaterial design by enabling design in 3-dimensions (3D) with multiple materials, creating complex composite metastructures."
"1747486","Real-world language: Future directions in the science of communication and the communication of science","BCS","PERCEPTION, ACTION & COGNITION","09/15/2017","07/17/2017","James Magnuson","CT","University of Connecticut","Standard Grant","Betty H. Tuller","02/28/2019","$20,943.00","","james.magnuson@uconn.edu","438 Whitney Road Ext.","Storrs","CT","062691133","8604863622","SBE","7252","7252, 7556","$0.00","This award will support the organization of a two-day workshop on future challenges in language science, with integrated discussion of science communication (making language science research accessible to specialist peers, scientists in other fields, and the general public). The workshop will take place in Madison, WI, immediately following the 2018 Cognitive Science Society annual meeting. Language science is an interdisciplinary area drawing on theories and methods from linguistics, cognitive psychology, developmental psychology, and artificial intelligence, among other fields. The primary goal is basic scientific understanding of the human capacity for language and potential longer-term impact on technology, education, and health.<br/><br/>Invited speakers will 1) provide critical reviews of different theoretical perspectives, methodological approaches, and tools (such as eye tracking, electroencephalography, or functional magnetic resonance imaging); 2) focus on near- and long-term challenges facing language science; or 3) focus on science communication and education. In an effort to spark discussion and collaboration,  research interest groups will be formed that will hold videoconference meetings in Fall, 2018. Plans include strategies for promoting student participation and inclusion of women and members of under-represented groups."
"1831250","SBIR Phase II:  Virtual Learning Assistants for Open Response Assessments","IIP","SMALL BUSINESS PHASE II","09/01/2018","09/04/2018","Dharmendra Kanejiya","MA","Cognii, Inc.","Standard Grant","Rajesh Mehta","08/31/2020","$750,000.00","","dharm@cognii.com","745 Atlantic Ave 331","Boston","MA","021112735","6178991744","ENG","5373","5373, 8031","$0.00","This SBIR Phase II project focuses on creating scalable Virtual Learning Assistant technology for automatic educational assessments using open response questions. Educational researchers and experts believe that the best pedagogies responsible for improving students' learning outcomes involve (i) open response questions assessments and (ii) one-to-one instructional tutoring. Students learn better when they are given an opportunity to construct answers in their own words instead of selecting from multiple choices and when they receive immediate guidance and coaching. However, these two pedagogies are very time consuming and expensive to implement, making them very difficult to scale. The proposed project will apply the most advanced technologies such as Artificial Intelligence and Natural Language Processing to solve both these problems. Students will benefit from the interactive formative assessment that engages them in a natural language conversation. This innovation is applicable across the grade levels in K-12, higher education, and adult learning and across the subject areas including the sciences. It will facilitate implementation of more rigorous academic standards and make online education more effective. This innovation will improve students' learning outcomes, save teachers' time and reduce the cost of delivering high quality engaging education at a large scale.<br/><br/>This project will create a new type of virtual assistant technology that is exclusively focused on education. The proposed Virtual Learning Assistant (VLA) will advance the conversational AI technology to create pedagogically rich learning and assessment environments for any topic in a content area. The VLA is uniquely distinct from general purpose virtual assistants in its ability to evaluate an open response answer instead of merely serving information. This project will investigate and create various algorithms for processing natural language input arising in an educational setting across different subjects or topics. The resulting mobile and web based product will allow teachers to create new high-quality assessment items with minimal input and assign them to their students. When a student answers a question, the VLA will analyze it instantly for linguistic syntax and semantics using statistical and deterministic knowledge representations. The VLA will generate not only a numerical score reflecting the accuracy of the answer, but also a qualitative feedback that will guide the student towards conceptual mastery of the topic. As part of this Phase II research, a pilot study will be conducted each year involving teachers and students to study the efficacy of the VLA and its scalability.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1755829","CRII: CIF: Fundamental Limits of Conditional Stochastic Optimization","CCF","COMM & INFORMATION FOUNDATIONS","06/01/2018","12/18/2017","Niao He","IL","University of Illinois at Urbana-Champaign","Standard Grant","Phillip Regalia","05/31/2020","$175,000.00","","niaohe@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","CSE","7797","7935, 8228","$0.00","Decision-making in the presence of randomness has been a fundamental and longstanding challenge in many fields of science and engineering.  In the wake of recent breakthroughs in artificial intelligence, there has been a prominent transition of interests and demands from classical (single-stage) stochastic optimization to multi-stage stochastic programming. In contrast to classical stochastic optimization, multi-stage stochastic problems are known to suffer from the curse of dimensionality, for which efficient universal oracle-based algorithms are not readily available. The goal of this research is to build bridges from classical stochastic optimization to multi-stage stochastic problems by developing an understanding of the fundamental limits of an intermediate class of optimization problems - conditional stochastic optimization - in the hopes of closing the algorithmic and theoretical gaps. Because of its specificity (i.e., it involves nonlinear functions of conditional expectations and lacks unbiased stochastic oracles), this class of optimization problems falls beyond the theoretical and practical grasp of the vast majority of state-of-the-art optimization algorithms. <br/><br/>The investigator will undertake a systematic study of this subject by (i) establishing new techniques for the design of algorithms adapted to different observation schemes and exploitable structures and (ii) developing sample complexities and non-asymptotic convergence analysis for the proposed algorithms. This research will significantly extend the current scope of stochastic optimization in both theory and applicability.  It will also lay the foundation for achieving the long-term goal of bridging to multi-stage decision-making problems and enriching the computational toolbox and theoretical developments for optimization under uncertainty.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1661529","Collaborative Research: ABI Innovation: Enabling machine-actionable semantics for comparative analyses of trait evolution","DBI","ADVANCES IN BIO INFORMATICS","09/01/2017","01/26/2018","Wasila Dahdul","SD","University of South Dakota Main Campus","Standard Grant","Peter H. McCartney","08/31/2020","$336,493.00","Paula Mabee, Wasila Dahdul","Wasila.Dahdul@usd.edu","414 E CLARK ST","Vermillion","SD","570692307","6056775370","BIO","1165","9150","$0.00","The millions of species that inhabit the planet all have distinct biological traits that enable them to successfully compete in or adapt to their ecological niches. Determining accurately how these traits evolved is thus fundamental to understanding earth's biodiversity, and to predicting how it might change in the future in response to changes in ecosystems. Although sophisticated analytical methods and tools exist for analyzing traits comparatively, applying their full power to the myriad of trait observations recorded in the form of natural language descriptions has been hindered by the difficulty of allowing these tools to understand even the most basic facts implied by an unstructured free-text statement made by a human observer. The technological arsenal needed to overcome this challenge is now in principle available, thanks to a number of recent breakthroughs in the areas of knowledge representation and machine reasoning, but these technologies are challenging enough to deploy, orchestrate, and use that the barriers to effectively exploit them remains far too high for most tools. This project will create infrastructure that will dramatically reduce this barrier, with the goal of providing comparative trait analysis tools easy access to algorithms powered by machines reasoning with and making inferences from the meaning of trait descriptions. Similar to how Google, IBM Watson, and others have enabled developers of smartphone apps to incorporate, with only a few lines of code, complex machine-learning and artificial intelligence capabilities such as sentiment analysis, this project will demonstrate how easy access to knowledge computing opens up new opportunities for analysis, tools, and research. It will do this by addressing three long-standing limitations in comparative studies of trait evolution: recombining trait data, modeling trait evolution, and generating testable hypotheses for the drivers of trait adaptation.<br/><br/>The treasure trove of morphological data published in the literature holds one of the keys to understanding the biodiversity of phenotypes, but exploiting the data in full through modern computational data science analytics remains severely hampered by the steep barriers to connecting the data with the accumulated body of morphological knowledge in a form that machines can readily act on. This project aims to address this barrier by creating a centralized computational infrastructure that affords comparative analysis tools the ability to compute with morphological knowledge through scalable online application programming interfaces (APIs), enabling developers of comparative analysis tools, and therefore their users, to tap into machine reasoning-powered capabilities and data with machine-actionable semantics. By shifting all the heavy-lifting to this infrastructure, tools can programmatically obtain answers to knowledge-based questions that would otherwise require careful study by a human export, such as objectively and reproducibly assessing the relatedness, independence, and distinctness of characters and character states, with only a few lines of code. To accomplish this, the project will adapt key products and know-how developed by the Phenoscape project, including an integrative knowledgebase of ontology-linked phenotype data, metrics for quantifying the semantic similarity of phenotype descriptions, and algorithms for synthesizing morphological data from published trait descriptions. To drive development of the computational infrastructure and to demonstrate its enabling value, the project's objectives focus on addressing three concrete long-standing needs for which the difficulty of computing with domain knowledge is the major impediment: (1) computationally synthesizing, calibrating, and assessing morphological trait matrices from across studies; (2) objectively and reproducibly incorporating morphological domain knowledge provided by ontologies into evolutionary models of trait evolution; and (3) generating testable hypotheses for adaptive diversification by incorporating semantic phenotypes into ancestral state reconstruction and identifying domain ontology concepts linked to evolutionary changes in a branch or clade more frequently than expected by chance. In addition, to better prepare evolutionary biologist users and developers of comparative analysis tools for adopting these new capabilities, a domain-tailored short-course on requisite knowledge representation and computational inference technologies will be developed and taught. More information on this project can be found at http://cate.phenoscape.org/."
"1832993","RII Track-4: EASE - Functional Electrical Stimulation and Mechanical Actuation of Soft Exoskeletons","OIA","EPSCoR Research Infrastructure","09/01/2018","08/20/2018","Vishesh Vikas","AL","University of Alabama Tuscaloosa","Standard Grant","Chinonye Whitley","08/31/2020","$250,956.00","","vvikas@eng.ua.edu","801 University Blvd.","Tuscaloosa","AL","354870005","2053485152","O/D","7217","9150","$0.00","Non-Technical Description<br/>Soft material robotics is envisioned to be the future of robotics that combines the concepts of the Internet of Things (IoTs), wearable sensors, material science and artificial intelligence to fabricate robots that can assist and collaborate with humans. This field is of special interest to roboticists and engineers as it has multiple fundamental challenges and there are tremendous benefits for applications to fields such as agriculture, disaster robotics to assistive rehabilitation. This project will enable researchers from the University of Alabama to enhance their capabilities to develop next-generation soft material exoskeletons (exosuits) stimulated by mechano-neuromuscular actuators through a collaboration with researchers at the University of Pittsburgh. Mechanically and electrically actuated soft exosuits are envisioned to have an impact on the fields of assistive robotics, rehabilitation robotics, and elder care. The research will result in the development of design and control principles for mechano-neuromuscular actuated soft wearable exosuits, thus greatly enhancing life and reducing rehabilitation cost for individuals who suffer from paralysis, stroke, and spinal cord injuries. The applied nature of this research will play an instrumental role in attracting students to STEM fields that include computer science, electrical engineering, mechanical engineering and biomedical engineering.<br/><br/>Technical Description<br/>The proposed project will integrate learning with research to develop design methodologies and control principles for composite fiber-reinforced soft exosuits.  These exosuits will integrate electro-mechanical actuation (motor-tendons) with the functional electrical stimulation (FES) of muscles to provide ease of movement by assistance and rehabilitation. This research will advance the University of Alabama's (UA) rehabilitation research through the development of design methodologies for motor-tendon driven soft exosuits by adapting principles from fields of compliant mechanisms and composite materials for soft structures. The resulting multi-layer soft material composite exosuits, with reinforced fibers, will address stress concentration and distribution problems specific to electromechanical actuators. This will include addressing anchor-point stress concentration and efficient transfer of actuator forces between components. Nonlinear controllers will be developed to integrate electromechanical and neuromuscular actuation in soft exosuits to effect ease of movement. The proposed research will contribute towards the understanding of design principles for soft wearable materials, which are tough to model, and how their behavior and/or interaction varies with the environment of contact. Furthermore, the research will contribute towards the development of next-generation actuation technologies for mechano-neuromuscular actuators. The research will result in hybrid control principles for mechano-neuromuscular actuators that provide wearable soft exosuits with less stiffness. Given the medical resources and interdisciplinary faculty at UA, this proposal will help in building capacity for a wearable robotics and rehabilitation research program in the state of Alabama.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1707316","NeuroNex Technology Hub: Multimodal Integrated Neural Technologies (MINT) - Connecting Physiology to Functional Mapping","DBI","Engineering of Biomed Systems, CROSS-EF ACTIVITIES","09/01/2017","08/15/2018","Euisik Yoon","MI","University of Michigan Ann Arbor","Cooperative Agreement","Reed Beaman","08/31/2019","$3,100,000.00","Gyorgy Buzsaki, James Weiland, Cynthia Chestek, Viviana Gradinaru","esyoon@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","BIO","5345, 7275","8091","$0.00","In order to understand how neural signals propagate to conduct specific functions in behaving animals and how individual neurons are physically connected in the context of behavior, advanced tools should be available at the hands of neuroscientists. The Multimodal Integrated Neural Technologies (MINT) hub aims to develop and provide tools that are able to read from and modulate neurons at multiple sites independently at high spatial and temporal resolutions. The hub will disseminate tools and methods to correlate the recorded cell activity with the structural connection. In this way, the connectivity of active cells can be visualized, labeled, and traced for detailed functional mapping. The mission of the MINT hub is to provide a collection of tools, synergistically developed, integrated, and available to the neuroscience community, to address one theme: connecting neurophysiology and structural analysis with a greater scale and resolution. The synergistic integration of these neurotechnology tools at the MINT Hub would accelerate the rate of discovery in neuroscience. This in turn can be expected to pave the way to improved treatments for neurological disorders and to breakthroughs in artificial intelligence, especially neuromorphic computing. The MINT hub will provide annual training workshops for new users to be familiar with new technologies and able to use them effectively. To achieve sustainability, the hardware tools will be actively marketed to the community and those with sustainable volume will be transitioned to commercialization partners. Importantly, this program will cross-train neuroscience and technology personnel during the course of this program, resulting in preparation of a new generation of multi-disciplinary engineers and scientists.<br/><br/>This hub uniquely combines high-density electrodes, chemical sensing, optical stimulation, and cell labeling. Fiberless high-density optoelectrodes can allow optical stimulation of individual or few neurons with high specificity and selectivity using monolithically integrated micro-LEDs or optical waveguides on multi-shank silicon probes. Carbon microthreads will be used to create advanced arrays that will dramatically increase the ability to record from interconnected neurons and label those cells with high accuracy. Advanced metal alloys will also be used to greatly enhance the signal-to-noise ratio of miniaturized electrodes. The MINT hub will innovate viral vector delivery and tissue clearing in the nervous system and combine these with multispectral labeling for intact cell phenotyping. Furthermore, an open-source software will be developed to improve the accuracy and efficiency of anatomical reconstruction for creating connectivity maps. The MINT hub will validate the developed tools and methods in three in-vivo experiments to exemplify what can be accomplished when the proposed modalities and methods are synergistically integrated. This NeuroTechnology Hub award is co-funded by the Division of Emerging Frontiers within the Directorate for Biological Sciences, and the Division of Chemical, Bioengineering, Environmental & Transport Systems within the Directorate for Engineering as part of the BRAIN Initiative and NSF's Understanding the Brain activities."
"1545858","PIRE: International Program for the Advancement of Neurotechnology (IPAN)","OISE","CROSS-EF ACTIVITIES, PIRE","11/01/2015","08/10/2018","Euisik Yoon","MI","University of Michigan Ann Arbor","Continuing grant","Cassandra M. Dudka","10/31/2020","$5,000,000.00","Kensall Wise, Gyorgy Buzsaki, Edward Stuenkel, Gregory Quirk","esyoon@umich.edu","3003 South State St. Room 1062","Ann Arbor","MI","481091274","7347636438","O/D","7275, 7742","5921, 5927, 5936, 5942, 5946, 7298, 7742","$0.00","This project entitled ""International Program for the Advancement of Neurotechnology (IPAN)"" is about understanding the complexity and mysteries of the brain. It is cited by many as the biggest scientific challenge of this century. In this International Program for the Advancement of Neurotechnology (IPAN), the researchers are creating a holistic system for studying brain activity by closely integrating hardware from leading neurotechnologists with novel software from leading neuroscientists.  Enabling this large-scale collaboration should accelerate the rate of discovery in neuroscience. This in turn will pave the way to improved treatments for neurological disorders and to breakthroughs in artificial intelligence in the next decade. The PIRE team will also provide advanced educational opportunities for undergraduates with the express purpose of recruiting future U.S. STEM (science, technology, engineering and mathematics) researchers. Graduate students and postdocs will also be enrolled in a unique cross-training program between neuroscience and neurotechnology laboratories. The resulting experience will prepare a new generation of globally-connected multi-disciplinary engineers and scientists while driving critical advances in neurotechnology.<br/><br/>IPAN is an explicit partnership of leading neuroscientists and technologists to develop and deliver a hardware and software system that fundamentally simplifies the ability of a neuroscientist to (i) identify recorded neuron types, (ii) reconstruct local neural circuits, and (iii) deliver biomimetic or synthetic inputs in a cell-specific targeted manner. This project teams the University of Michigan, New York University, Howard Hughes Medical Institute, and the University of Puerto Rico with the University of Freiburg,  the  University  of  Hamburg-Eppendorf,  the  Korea  Institute  of  Science  and  Technology, Singapore?s Institute for Microelectronics, and University College London.   Complementary strengths, world-class infrastructures, and strong student exchange programs are an important part of this IPAN team, with major thrusts in Technology, Neuroscience, and Education. The enabling technology to meet these three system goals (i-iii) will be next-generation neural probes equipped with novel optoelectronics, high-density recording interfaces, and low-noise multiplexed digital outputs. The neuroscience thrust will help define the technology from the onset and are developing novel software tools to accelerate the analysis of large neurophysiological data sets. The team includes leading system neuroscientists with unique  capabilities  specializing  in  memory,  sensory,  fear,  and  development, and  will  work  with technologists to validate both the technology and the software tools in distinctive neuroscience applications."
"1830965","SBIR Phase II:  Fast Creation of Photorealistic 3D Models using Consumer Hardware","IIP","SMALL BUSINESS PHASE II","09/01/2018","09/04/2018","Jeevan Kalanithi","CA","Openspace","Standard Grant","Peter Atherton","08/31/2020","$750,000.00","","zoinks@gmail.com","3802 23rd St","San Francisco","CA","941143321","4159947035","ENG","5373","5373, 8033","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project will be substantial: a successful project would transform the construction industry, making it far more efficient by reducing legal conflicts, schedule slips and poor decision making. The proposed work will enable the fast and easy creation of 100% complete visual documentation of a physical space; this documentation can be generated many times throughout the course of construction. In so doing, the proposed project will allow professionals in the construction industry to track progress and communicate with their teams far more efficiently than ever before. A second outcome of the project will be the creation of vast, detailed, never before seen datasets of construction projects and real estate, allowing technical innovations in artificial intelligence and computer vision to impact one of the largest industries in the nation and the world. For example, systems could be trained to automatically spot safety concerns, augmenting the efforts of safety managers and keeping workers safer than ever before.<br/><br/>This Small Business Innovation Research (SBIR) Phase II project will develop a fast, easy to use and cheap method to create photorealistic immersive models using off the shelf consumer hardware. Technical hurdles include validating the quality and efficacy of models generated with consumer hardware and automatic creation of routes through the 3D space without human annotation. Technical milestones involve using various sensor streams as well as other prior data to build these routes. With these hurdles cleared, advanced work may include automated analytics between and among 3D models of the same site captured over time. Because of the system's ease of use, it will enable the collection of large, totally novel datasets. The goal of the research is to produce a prototype that a layperson can use to create an immersive model of a physical site in order to document it with no annotation effort. The plan to reach these goals includes iterative software development against the hurdles listed above, as well as continuous user feedback to guide and refine development.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1661516","Collaborative Research: ABI Innovation: Enabling machine-actionable semantics for comparative analyses of trait evolution","DBI","ADVANCES IN BIO INFORMATICS","09/01/2017","08/30/2017","Josef Uyeda","VA","Virginia Polytechnic Institute and State University","Standard Grant","Peter H. McCartney","08/31/2020","$172,356.00","","josef.uyeda@gmail.com","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","BIO","1165","9150","$0.00","The millions of species that inhabit the planet all have distinct biological traits that enable them to successfully compete in or adapt to their ecological niches. Determining accurately how these traits evolved is thus fundamental to understanding earth's biodiversity, and to predicting how it might change in the future in response to changes in ecosystems. Although sophisticated analytical methods and tools exist for analyzing traits comparatively, applying their full power to the myriad of trait observations recorded in the form of natural language descriptions has been hindered by the difficulty of allowing these tools to understand even the most basic facts implied by an unstructured free-text statement made by a human observer. The technological arsenal needed to overcome this challenge is now in principle available, thanks to a number of recent breakthroughs in the areas of knowledge representation and machine reasoning, but these technologies are challenging enough to deploy, orchestrate, and use that the barriers to effectively exploit them remains far too high for most tools. This project will create infrastructure that will dramatically reduce this barrier, with the goal of providing comparative trait analysis tools easy access to algorithms powered by machines reasoning with and making inferences from the meaning of trait descriptions. Similar to how Google, IBM Watson, and others have enabled developers of smartphone apps to incorporate, with only a few lines of code, complex machine-learning and artificial intelligence capabilities such as sentiment analysis, this project will demonstrate how easy access to knowledge computing opens up new opportunities for analysis, tools, and research. It will do this by addressing three long-standing limitations in comparative studies of trait evolution: recombining trait data, modeling trait evolution, and generating testable hypotheses for the drivers of trait adaptation.<br/><br/>The treasure trove of morphological data published in the literature holds one of the keys to understanding the biodiversity of phenotypes, but exploiting the data in full through modern computational data science analytics remains severely hampered by the steep barriers to connecting the data with the accumulated body of morphological knowledge in a form that machines can readily act on. This project aims to address this barrier by creating a centralized computational infrastructure that affords comparative analysis tools the ability to compute with morphological knowledge through scalable online application programming interfaces (APIs), enabling developers of comparative analysis tools, and therefore their users, to tap into machine reasoning-powered capabilities and data with machine-actionable semantics. By shifting all the heavy-lifting to this infrastructure, tools can programmatically obtain answers to knowledge-based questions that would otherwise require careful study by a human export, such as objectively and reproducibly assessing the relatedness, independence, and distinctness of characters and character states, with only a few lines of code. To accomplish this, the project will adapt key products and know-how developed by the Phenoscape project, including an integrative knowledgebase of ontology-linked phenotype data, metrics for quantifying the semantic similarity of phenotype descriptions, and algorithms for synthesizing morphological data from published trait descriptions. To drive development of the computational infrastructure and to demonstrate its enabling value, the project's objectives focus on addressing three concrete long-standing needs for which the difficulty of computing with domain knowledge is the major impediment: (1) computationally synthesizing, calibrating, and assessing morphological trait matrices from across studies; (2) objectively and reproducibly incorporating morphological domain knowledge provided by ontologies into evolutionary models of trait evolution; and (3) generating testable hypotheses for adaptive diversification by incorporating semantic phenotypes into ancestral state reconstruction and identifying domain ontology concepts linked to evolutionary changes in a branch or clade more frequently than expected by chance. In addition, to better prepare evolutionary biologist users and developers of comparative analysis tools for adopting these new capabilities, a domain-tailored short-course on requisite knowledge representation and computational inference technologies will be developed and taught. More information on this project can be found at http://cate.phenoscape.org/."
"1819546","Automated Feedback in Undergraduate Computing Theory Courses","DUE","IUSE","10/01/2018","08/30/2018","Ivona Bezakova","NY","Rochester Institute of Tech","Standard Grant","Stephanie August","09/30/2021","$299,417.00","Edith Hemaspaandra","ib@cs.rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757987","EHR","1998","8209, 8244, 9178","$0.00","Computing theory poses and answers questions such as ""Which problems are efficiently computable and which are not?"" Answering such questions is important for any computer scientist and for any kind of software development.  For example, it is better to determine if a problem is computable before spending a lot of time trying to write a program to solve it. Unfortunately, many students struggle with computing theory, because it is more abstract and mathematical than other computer science topics. As in any other knowledge area, students need to practice to get better at computing theory. A problem is that feedback on their work is not immediate and, while students wait for feedback, they stop interacting with the material. They may have to wait for days, since grading an assignment often takes a lot of instructor time and the instructors may have many assignments to grade. This project will increase the speed and, potentially, the quality of feedback to computing theory students by developing an automated feedback tool.  The feedback will tell students whether a solution is correct or not, a convincing reason why an incorrect solution is incorrect, and provide information about the quality of a solution. Students will be able to use this immediate feedback to improve their solutions, get more practice, and increase their understanding of the material. In addition to building the feedback tool, this project aims to conduct research on the feedback tool's effectiveness.  This project has the potential to contribute to the education of a strong computing workforce and to support development of students' independent learning skills.  <br/><br/>Although understanding computing theory concepts is very important, it is challenging. Typically, as a first step, students in computing theory classes learn about various models of computation. To understand more complex computational issues, students need to fully comprehend the possibilities and limitations of these models. JFLAP (Java Formal Languages and Automata Package) is a widespread tool that provides a way for students to interact with these concepts. However, like other interactive tools in this area, it does not provide detailed feedback on student solutions. This project will build a feedback and grading tool on top of JFLAP, to increase the likelihood that the feedback tool will have broad applicability. To accomplish this goal, the project will develop and evaluate the tool in the context of three research areas: (1) Computer Science Education:  Do students who use the tool understand theoretical computer science concepts better than students who do not use the tool? (2) Theoretical Computer Science:  How can software generate a convincing reason for why a student solution is incorrect? and (3) Artificial Intelligence: How can feedback be given about the quality of a student's solution?  The project's research and software development activities will involve ten undergraduate students, who will be recruited with emphasis on including women and deaf/hard-of-hearing students.  Thus, the project will directly contribute to these students' scientific and professional development.  Project outcomes will be disseminated at scientific conferences and workshops, as well as at the University's innovation fair, which is attended by 35,000 visitors, including middle and high school students. Developing the feedback tool and completing research on its effectiveness has the potential to improve instruction and learning of computing theory.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1526189","AF: Small: Exact algorithms for the quantum satisfiability problem","CCF","ALGORITHMIC FOUNDATIONS","09/01/2015","06/08/2015","Sevag Gharibian","VA","Virginia Commonwealth University","Standard Grant","Dmitry Maslov","12/31/2018","$196,593.00","","sgharibian@vcu.edu","P.O. Box 980568","RICHMOND","VA","232980568","8048286772","CSE","7796","7923, 7928","$0.00","Among the most fundamental problems in theoretical computer science is the k-SATISFIABILITY problem (k-SAT), which roughly asks: Given a set of Boolean constraints of a special form, each acting on k out of n bits, does there exist an assignment to all n bits which simultaneously satisfies every constraint? This problem has far-reaching applications in areas ranging from artificial intelligence to electronic design automation to theorem proving, thus underscoring its significance. <br/><br/>More recently, a quantum generalization of k-SAT has arisen, known as k-QSAT, which finds applications in areas such as quantum error-correcting codes. Moreover, k-QSAT is physically well-motivated, as it can be thought of as modeling how quantum systems in nature are governed by local quantum constraints. Unlike k-SAT, however, much less is known about k-QSAT. The aim of this project is precisely to close this fundamental knowledge gap. In particular, this project broadly asks: In what cases can non-trivial algorithms be developed for solving k-QSAT? <br/><br/>The resolution of this question will yield deep insights into which properties of quantum systems can be computed efficiently by a classical computer. Moreover, the results obtained will be disseminated through a variety of avenues, including conferences, new course materials, and high school workshops aimed at exposing young computer scientists to the frontiers of research."
"1814406","SaTC: CORE: Small: Super-Human Cryptanalysis for Scalable Side-Channel Analysis","CNS","Secure &Trustworthy Cyberspace","09/01/2018","08/30/2018","Berk Sunar","MA","Worcester Polytechnic Institute","Standard Grant","Sandip Kundu","08/31/2021","$500,000.00","Thomas Eisenbarth","sunar@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","8060","025Z, 7434, 7923","$0.00","The project takes the rapidly evolving advances in deep learning and applies them in the context of side-channel analysis (SCA). Finding SCA leakages on real devices can be a tedious process, resulting devices ranging from wearables to embedded Internet of Things (IoT) devices entering the marketplace without proper protection. This project explores ways to automate side-channel security analysis using deep learning techniques. To protect devices against SCA, the project also explores a novel approach to countermeasure design by applying the concept of adversarial learning.<br/><br/>SCA is essentially one complex statistical signal processing problem, which deep learning is ideally suited to solve. The project systematically quantifies the impact of deep learning on SCA by applying deep learning methods to all necessary steps in SCA, namely alignment, noise reduction, feature extraction and model building. Meaningful parameter sets for a representative list of reference targets are explored. The project also adapts adversarial learning techniques to counteract optimized side-channel information recovery, thereby inventing an entirely new class of side-channel countermeasures, where machine learning adaptively shapes leakage signals to prevent correct classification. <br/><br/>The SCA analysis and protection tools explored in this project will be invaluable for the health of our national computing and communications infrastructure. They will be released as an easy-to-use open-source toolbox. Furthermore, the project provides new insights and training for the next generation of experts at the intersection of two critical technologies, i.e. artificial intelligence and security. <br/><br/>More information on the project, including important data and developed code, is available at: http://v.wpi.edu/research/superhuman, until circa 2026.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1709351","CDS&E: D3SC: The Dark Reaction Project:  A machine-learning approach to exploring structural diversity in solid state synthesis","DMR","CONDENSED MATTER & MAT THEORY, Theory, Models, Comput. Method, DATANET","09/01/2017","07/26/2017","Joshua Schrier","PA","Haverford College","Standard Grant","Daryl W. Hess","08/31/2020","$645,288.00","Alexander Norquist, Sorelle Friedler","jschrier@haverford.edu","370 Lancaster Avenue","Haverford","PA","190411336","6108961000","MPS","1765, 6881, 7726","054Z, 7433, 8084, 9177","$0.00","NONTECHNICAL SUMMARY<br/>This award receives funds from the Division of Materials Research, the Chemistry Division and the Office of Advanced Cyberinfrastructure. This award supports research and education that uses data-centric methods to enable the prediction of metal oxide compounds with desired properties. Organically-templated metal oxides have a tremendous degree of structural diversity and compositional flexibility. This allows chemists to tune the structures, properties, and symmetries of these compounds to optimize their performance in specific applications that include catalysis, molecular sieving, gas adsorption, and nonlinear optics.  However, new compounds are typically created by a trial-and-error procedure, and creating novel compounds with specific structures is a grand challenge in solid state chemistry.  This project will develop artificial intelligence techniques for computers called machine learning techniques that can be used to predict the conditions for chemical reactions that will increase structural diversity and lead to specific structural features.  This project will also develop machine learning techniques that generate human-readable explanations about the formation mechanism, which will be tested in the laboratory.<br/> <br/>The primary impact of this project will be to decrease the amount of time and to lower the cost of discovering new materials with specific structural features, which in turn help bring new materials for applications to market more quickly.  This project is an example of a collaboration among synthetic chemists, computational chemists, and computer scientists and as a model it may be directly transferred to a wide range of disciplines and avenues of investigation. Undergraduate student research opportunities and curricular developments will be involved throughout the project, thus contributing to the scientific workforce.<br/> <br/>TECHNICAL SUMMARY <br/>This award receives funds from the Division of Materials Research, the Chemistry Division and the Office of Advanced Cyberinfrastructure. This award supports research and education that uses data-centric methods to enable the prediction of metal oxide compounds with desired properties. Hydrothermal synthesis is widely used to create new metal oxide materials with a wide range of functional properties and applications.  This project will advance the field by developing software infrastructure for associating the results of X-ray diffraction experiments with individual reactions, extracting structural outcome descriptors from this data, and then determining the extent to which these structural outcomes can be predicted from reaction description data.  This will be achieved by developing structural outcome descriptors for geometric properties, non-covalent interaction properties, and electron-density properties, then building machine learning models that correlate these outcomes to reaction conditions, and finally testing the quality of these predictions experimentally.  Active learning and auditable and interpretable models will be incorporated into the workflows to help synthetic chemists select better (more insightful/novel) reactions in an interactive fashion."
"1812245","A Search for Neutrino-less Double Beta Decay with nEXO","PHY","NUCLEAR PRECISION MEASUREMENTS","09/01/2018","08/29/2018","Andrea Pocar","MA","University of Massachusetts Amherst","Continuing grant","Allena Opper","08/31/2021","$250,000.00","","pocar@physics.umass.edu","Research Administration Building","Hadley","MA","010359450","4135450698","MPS","1234","","$0.00","One fundamental question in science today is why the Universe and everything in it is made almost exclusively of matter and essentially no anti-matter when the equations describing Nature lead us to expect a nearly equal amount of matter and anti-matter.  This award supports investigations at the University of Massachusetts, Amherst into one possible origin of this imbalance through the study of whether the lightest fundamental particle in Nature, the neutrino, is made of both matter and anti-matter.   If this is the case, a very rare nuclear process known as neutrino-less double beta decay is possible. This decay, in which a nucleus transforms into another by emitting two electrons and nothing else, would unambiguously determine that neutrinos and anti-neutrinos are the same particle, i.e. that they are Majorana particles.  The work at UMass Amherst focuses on key R&D aspects for the design of the detector for the nEXO experiment, with research carried out in the lab with postdocs and students (graduate and undergraduate), in an academic, research-intensive environment.  The PI and his group are also involved in operating and analyzing the data of the EXO-200 experiment, a smaller scale nEXO predecessor running in New Mexico and holding one of the best sensitivities for neutrino-less double beta decay to date.  The activities supported by this award train human resources of diverse backgrounds and develop technologies that align with strategic sectors for the US, such as data science and artificial intelligence, nuclear medicine and non-proliferation, and national security programs at national laboratories. The UMass Amherst particle astrophysics group has a record of excellence and diversity for undergraduate involvement in research, and the Amherst Center for Fundamental Interactions (ACFI) actively contributes to promoting the physics related to this proposal to the broader physics community.<br/><br/><br/>The core of the nEXO detector is a Time Projection Chamber (TPC), a technology that can identify and suppress with high efficiency most background signals mimicking neutrinoless-double beta decays. The detector will measure the position and energy of each ionizing event occurring inside its volume, as well as finer information about the spatial distribution and sharing of event energy between two detection channels, ionization and scintillation light. Combined with a detector design that minimizes the residual radioactivity in its constituents, this information provides a powerful environment for a neutrino-less double beta decay signal to emerge once all other interactions are properly identified. The UMass Amherst group works on the development of key elements of nEXO. The PI coordinates the design of the nEXO TPC. With his group, he studies novel silicon-based detectors (specifically Silicon PhotoMultipliers, SiPMs) sensitive to the xenon scintillation light (178 nm) that combine good light collection efficiency, minimal radioactive contamination, uniformity of response, and are practically available to cover several square meters of surface in nEXO.   An integral part of the program is a continued participation in the EXO-200 experiment, and the analysis of its data. Of particular interest are refined searches for neutrino-less double beta decay of xenon-136 and xenon-134.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1817212","AF: Small: A New Approach to Analysis and Design of Algorithms for Stochastic Control and Optimization","CCF","ALGORITHMIC FOUNDATIONS","10/01/2018","08/23/2018","Rahul Jain","CA","University of Southern California","Standard Grant","Balasubramanian Kalyanasundaram","09/30/2021","$399,999.00","","rahul.jain@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7796","7923, 7926, 7933","$0.00","Randomized algorithms for stochastic optimization and control underpin many developing technologies such as Artificial Intelligence (AI), Autonomous Robotics, and Big Data Analytics. Their development is hampered by a lack of suitable mathematical tools. In many cases, current mathematical techniques such as those based on Stochastic Lyapunov theory are rather difficult to use, thus necessitating invention of customized techniques for algorithm design for each problem and its analysis. This project will develop a new class of mathematical techniques, called probabilistic contraction analysis, that are easier to use, and more broadly applicable. The project's aim is not just analysis of existing algorithms, but development of analysis tools with an eye on design. The project outcomes can accelerate development of new algorithms for stochastic control and optimization problems that arise in many important application fields such as AI, Autonomy, Big Data Analytics, etc. The project will train under-represented and/or female PhD students and postdocs, as well as high school students and teachers.<br/><br/>Given a randomized algorithm for stochastic optimization and control, this project views each iteration as applying a random operator, and develops new ""probabilistic contraction"" analysis techniques, created by the investigator, that use stochastic dominance arguments to show convergence to probabilistic fixed points. Specifically, the investigator will develop empirically-inspired algorithms for optimal control of continuous state and action space Markov decision processes, and unconstrained and constrained stochastic optimization problems. The techniques to be developed may be useful for a broader class of stochastic iterative algorithms, and lead to development of a probabilistic fixed point theory of random operators on Banach spaces.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1822092","Planning IUCRC at University of Nebraska-Lincoln:  Center for Engineering and Manufacturing Technologies Advancing Food Safety and Security (CAFSS)","IIP","INDUSTRY/UNIV COOP RES CENTERS","09/01/2018","08/28/2018","Theodore Lioutas","NE","University of Nebraska-Lincoln","Standard Grant","Andre Marshall","08/31/2019","$15,000.00","Jeyamkondan Subbiah","Theo.lioutas@unl.edu","151 Prem S. Paul Research Center","Lincoln","NE","685031435","4024723171","ENG","5761","5761","$0.00","The US food and beverage industry employs 1.46 million individuals and is responsible for more than 10% of all manufacturing shipments. Even though sanitation is one of the food industry's biggest production expenses, inadequate sanitation remains one of the greatest threats to America's food safety and security due to the lack of modern technology and consistent application of sanitation policies.<br/><br/>CAFSS will strive to integrate and streamline the entire food supply chain in the US from 'Farm to Fork' and supply safe (pathogen and allergen free), secure (uninterrupted and fully traceable sources), wholesome and plentiful supply of food to the US and Global consumers.<br/><br/>CAFSS objectives will focus on addressing two grand challenges of national importance:<br/><br/>1) Ensuring a stable and sustainable supply of affordable, safe, nutritious food not only for the US but also for the rest of the world.<br/>2) Equipping and empowering US food manufacturers and their supporting industries, to establish highly competitive manufacturing plants in the US and the world.<br/><br/>The US food industry adds commercial value to agricultural products and provides employment opportunities in both rural and urban areas and CAFSS will enhance the overall sustainability and profitability through automation and new private-public partnerships.<br/><br/>The proposed CAFSS will bridge technological gaps, which fall under the general theme of food safety, security and traceability of all raw materials throughout the entire supply chain from 'Farm to Fork'.  Bridging these gaps will require multidisciplinary collaborations among public and private enterprises and groundbreaking research and development within the following fundamental science and engineering platforms:<br/><br/>1) Automation, control and robotics; IoT systems and data integration; <br/>2) New sensors; big data analytics and artificial intelligence; <br/>3) New functionalized surfaces, new materials / coatings  <br/>4) Novel food sterilization technologies. <br/><br/>Automation, control, and robotics minimize human contact with food and greatly enhance food safety. Newer sensors with data analytics enable the food companies to improve food safety, quality, and traceability. Novel functionalized surfaces enhance food sanitation efficiency thereby reducing production downtime, and energy and water requirements.  Novel food sterilization and pasteurization technologies improve food safety with minimal deterioration in food quality and they meet consumers' demand for minimally processed foods.<br/><br/>Research projects will be carried out at CAFSS hub facilities in Nebraska and Georgia and the resulting breakthroughs will allow the US food manufacturing industry to join other industries in terms of efficiency, automation, lower cost, predictability, safety and security of goods supplied.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1634627","Actor-Critic-Like Stochastic Adaptive Search Algorithms for Simulation Optimization","CMMI","OE Operations Engineering","09/01/2016","08/02/2016","Jiaqiao Hu","NY","SUNY at Stony Brook","Standard Grant","Georgia-Ann Klutke","08/31/2019","$199,923.00","","jiaqiao.hu.1@stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","ENG","006Y","071E, 072E, 073E, 077E, 078E","$0.00","Many systems arising in applications from engineering design, manufacturing, and health care require the use of simulation optimization techniques to improve their performance. However, despite significant progress in recent years, simulation optimization remains an area with many theoretical and practical challenges. This research project aims to expand the current knowledge in this field by investigating a novel approach that integrates theories and tools from reinforcement learning (a subarea of artificial intelligence) within a class of adaptive search algorithms called the model-based methods to solve simulation optimization problems. Because of the generality of these methodologies, the resulting techniques will have broad applicability in a wide array of industry and science sectors. In particular, through collaboration with power engineers, the developed algorithms will be tested and applied to voltage control problems in electric power systems, potentially benefiting both utility companies and energy consumers. The research plan will be closely integrated with the education and training of students in engineering by incorporating new developments into the graduate courses the investigator teaches and recruiting  female and underrepresented minority students to the project.<br/><br/>The goal of this research is to advance theoretical underpinnings of new model-based algorithms that can be orders of magnitude more efficient than the state-of-the-art. This will be accomplished by exploring the connections between model-based methods and policy gradient-based reinforcement-learning algorithms. Specifically, the investigator will examine how to use the insights from actor-critic algorithms in the reinforcement learning framework to effectively reduce the sampling variance of model-based methods. If successful, the approach will integrate function approximation techniques within a model-based optimization setting to provide algorithms with low-variance performance estimates in searching for improved solutions. This research may change the manner in which these algorithms are implemented and applied, leading to faster and more efficient algorithms for solving a broad class of optimization problems, especially in settings that require expensive function evaluations or simulations for performance estimation."
"1822117","Planning IUCRC at Georgia Institute of Technology:  Center for Engineering and Manufacturing Technologies Advancing Food Safety and Security (CAFSS)","IIP","INDUSTRY/UNIV COOP RES CENTERS","09/01/2018","08/28/2018","Douglas Britton","GA","Georgia Tech Applied Research Corporation","Standard Grant","Andre Marshall","08/31/2019","$15,000.00","","doug.britton@gtri.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","5761","5761","$0.00","The US food and beverage industry employs 1.46 million individuals and is responsible for more than 10% of all manufacturing shipments. Even though sanitation is one of the food industry's biggest production expenses, inadequate sanitation remains one of the greatest threats to America's food safety and security due to the lack of modern technology and consistent application of sanitation policies.<br/><br/>CAFSS will strive to integrate and streamline the entire food supply chain in the US from 'Farm to Fork' and supply safe (pathogen and allergen free), secure (uninterrupted and fully traceable sources), wholesome and plentiful supply of food to the US and Global consumers.<br/><br/>CAFSS objectives will focus on addressing two grand challenges of national importance:<br/><br/>1) Ensuring a stable and sustainable supply of affordable, safe, nutritious food not only for the US but also for the rest of the world.<br/>2) Equipping and empowering US food manufacturers and their supporting industries, to establish highly competitive manufacturing plants in the US and the world.<br/><br/>The US food industry adds commercial value to agricultural products and provides employment opportunities in both rural and urban areas and CAFSS will enhance the overall sustainability and profitability through automation and new private-public partnerships.<br/><br/>The proposed CAFSS will bridge technological gaps, which fall under the general theme of food safety, security and traceability of all raw materials throughout the entire supply chain from 'Farm to Fork'.  Bridging these gaps will require multidisciplinary collaborations among public and private enterprises and groundbreaking research and development within the following fundamental science and engineering platforms:<br/><br/>1) Automation, control and robotics; IoT systems and data integration; <br/>2) New sensors; big data analytics and artificial intelligence; <br/>3) New functionalized surfaces, new materials / coatings  <br/>4) Novel food sterilization technologies. <br/><br/>Automation, control, and robotics minimize human contact with food and greatly enhance food safety. Newer sensors with data analytics enable the food companies to improve food safety, quality, and traceability. Novel functionalized surfaces enhance food sanitation efficiency thereby reducing production downtime, and energy and water requirements.  Novel food sterilization and pasteurization technologies improve food safety with minimal deterioration in food quality and they meet consumers' demand for minimally processed foods.<br/><br/>Research projects will be carried out at CAFSS hub facilities in Nebraska and Georgia and the resulting breakthroughs will allow the US food manufacturing industry to join other industries in terms of efficiency, automation, lower cost, predictability, safety and security of goods supplied.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1721550","Collaborative Research:  Automatic Video Interpretation and Description","DMS","OFFICE OF MULTIDISCIPLINARY AC, CI REUSE, CDS&E-MSS","09/01/2017","08/20/2017","Wing Hung Wong","CA","Stanford University","Standard Grant","Christopher W. Stark","08/31/2020","$160,000.00","","whwong@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","MPS","1253, 6892, 8069","1253, 7433, 8004, 8083, 9263","$0.00","Digital information processing has become an essential part of modern life. It is nowadays often expressed in a form of multimedia, involving videos accompanied with images, captions, and audio. Given the explosive growth of such multimedia data, it is extremely critical that it is accurately summarized and organized for automatic processing in artificial intelligence. One important yet challenging problem is automatic interpretation and summarization of video content, having enormous applications in video advertisements, online video searching and browsing, movie recommendation based on personal preference, and essentially any electronic commerce platform. In this project, the research team plans to develop statistical tools to raise our capacity of processing digital information to respond to a rapid growth of video content in real-world applications. The primary objective is to create a learning system to decipher the meaning of visual expressions as perceived by the audience, with a focus on understanding semantic meaning conveyed by a video.<br/><br/>This project aims to develop methods of automatic video interpretation and description, which understands visual thoughts expressed by a video and generates semantic expressions of the content of a video. Particularly, it will utilize conditional dependence structures of entities as well as between entities and their pertinent actions, in a framework of multi-label and hierarchical classification. It will focus on three areas: 1) entity and action learning, 2) semantic learning for long videos and content-based segmentation, and 3) automatic video description generation, each of which develops techniques in novel ways. In each area, classification will be performed collaboratively based on pairwise conditional label dependencies and temporal dependencies of video frames, characterized by graphical and hidden Markov models. Special effort will be devoted to learning from multiple sources and extracting latent structures corresponding to scenes of a video. The PIs also plan to release the software developed as open source and build a user community around the language by ensuring that interested researchers are able to contribute to the codebase of the software developed. This will allow a wider growth of the  project. This aspect is of special interest to the software cluster in the Office of Advanced Cyberinfrastructure, which has provided co-funding for this award."
"1827225","CC* Network Design: Network Upgrades to Improve Engagement in Science Discovery and Education","OAC","Campus Cyberinfrastrc (CC-NIE)","08/01/2018","07/25/2018","Donna Liss","MO","Truman State University","Standard Grant","Kevin L. Thompson","07/31/2020","$400,000.00","Jon Beck, Jim McNabb","dliss@truman.edu","100 E. Normal","Kirksville","MO","635014200","6607857245","CSE","8080","9150","$0.00","Truman State University, with the support of the Missouri Research and Education Network (MOREnet) and the University of Missouri, is upgrading the campus network and infrastructure to better enable access to, and use of, scientific data through improved data transfer capabilities for large datasets.  The enhanced infrastructure supports faculty and undergraduate research in understanding star spots, quantifying light pollution in geographical areas, understanding the inhibition mechanisms of drugs to treat global health issues, natural language processing to improve approaches in artificial intelligence, and building low-cost, real-time, soil sensors.  An expanded curriculum that includes hands-on training in cybersecurity and IPv6 technologies is also enabled by utilizing these network resources.  <br/><br/>The improvements include upgrades to the network switch and distribution technologies that result in a ten-fold increase in data transfer and access rates for faculty in STEM-related disciplines, as well as increases in the data transfer bandwidth to the campus observatory, deployment of IPv6 in support of the computer science curriculum, establishment of network performance metrics to inform continued growth, and robust and secure access (through federated identity management) to off-campus research tools and intra-institutional collaboration opportunities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1532846","NCS-FO: A circuit theory of cortical function","ECCS","Engineering of Biomed Systems, IntgStrat Undst Neurl&Cogn Sys","08/01/2015","08/10/2015","Charles Gilbert","NY","Rockefeller University","Standard Grant","Kenneth C. Whang","07/31/2019","$970,091.00","Winrich Freiwald, George Reeke","gilbert@rockefeller.edu","1230 YORK AVENUE","NEW YORK","NY","100656399","2123278309","ENG","5345, 8624","004E, 8089, 8091, 8551","$0.00","This project aims to develop and test a new conceptual framework for understanding brain function, and informing biologically based artificial intelligence systems.  The underlying theory holds that the properties of any neuron and any cortical area are not fixed but undergo state changes with changing perceptual task, expectation and attention.   Because of the multiple routes by which this top-down information can be conveyed, each neuron is essentially a microcosm of the brain as a whole.   <br/><br/>In this framework, a neuron is viewed as an adaptive processor rather than merely a link in a labeled line, taking on functions that are required for performing the current task.  The theory accounts for cortical function at the circuit level.  Through an interaction between feedback and intrinsic connections neurons select inputs that are relevant to a task and suppress inputs that are irrelevant.  The experiments will combine visual psychophysics, fMRI, large scale high density electrode array recordings and optogenetic manipulation.  These techniques will be used to measure changes in effective connectivity between cortical areas and the relationship between effective connectivity and the information represented by neurons at different recording sites as animals perform different visual recognition tasks.  Computational models will be developed to account for how task-dependent gating of connections can be achieved and will reproduce the functional dynamics observed experimentally.  Though the experiments will focus on the visual modality, the findings from the work will formulate a general theory of brain function that is broadly applicable to the brain as a whole."
"1714779","AF: Small: Lower Bounds for Computational Models, and Relations to Other Topics in Computational Complexity","CCF","ALGORITHMIC FOUNDATIONS","09/01/2017","07/10/2017","Ran Raz","NJ","Princeton University","Standard Grant","Tracy J. Kimbrel","08/31/2020","$450,000.00","","ranr@princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","CSE","7796","7923, 7927","$0.00","Computational complexity theory is a mathematical field that studies the limits of computers and the resources needed to perform computational tasks. A mathematical theory of computation is crucial in our information age, where computers are involved in essentially every part of our life. Computational complexity is also essential in designing efficient communication protocols, secure cryptographic protocols and in understanding human and machine learning. Studying the limits of computational models is among the most exciting, most challenging, and most important topics in theoretical computer science and is essential for understanding the power of computation and for the development of a theory of computation.<br/><br/>The project will study lower bounds for the resources required by different computational models, as well as related topics in computational complexity. The project will focus on three main research directions:<br/><br/>Time-Space lower bounds for learning: In a sequence of recent works, the PI and his coauthors proved that some of the most extensively studied learning problems require either a super-linear memory size or a super-polynomial number of samples. The project will further study memory/samples lower bounds for learning and their relations to other topics in complexity theory. Lower bounds for learning under memory constraints demonstrate the importance of memory in learning and cognitive processes. They may be relevant to understanding human learning and may have impact on machine learning, artificial intelligence and optimization. They also have applications in cryptography.<br/><br/>Lower bounds for arithmetic circuits: The project will study lower bounds for arithmetic circuits and formulas, as well as for subclasses of arithmetic circuits and formulas. Lower bounds for arithmetic circuits may have a broader impact within theoretical computer science, because of the centrality of polynomials in theoretical computer science.<br/><br/>Lower bounds for communication complexity: In a sequence of recent works, the PI and his coauthors proved the first gaps between information complexity and communication complexity. These results show that compression of interactive communication protocols to their information content is not possible, and hence show that interactive analogs to Shannon's source coding theorem and Huffman coding are not possible. Separation results of communication complexity and information complexity may be relevant to electrical engineering and in particular to the design of efficient communication protocols. The project will further study these topics, and more generally, lower bounds for communication complexity and their relations to other topics in computational complexity."
"1760991","Seventh International Conference on Computational Harmonic Analysis","DMS","COMPUTATIONAL MATHEMATICS","01/01/2018","12/04/2017","Alexander Powell","TN","Vanderbilt University","Standard Grant","Matthias Gobbert","12/31/2018","$15,000.00","Emanuel Papadakis","alexander.m.powell@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","MPS","1271","7556, 9263","$0.00","The Seventh International Conference on Computational Harmonic Analysis (ICCHA7) will take place at Vanderbilt University in Nashville, TN during May 14-18, 2018, in conjunction with the 33rd Annual Shanks Conference and Lecture. The conference website https://my.vanderbilt.edu/iccha7 contains a list of the conference plenary speakers and other conference information.  Computational harmonic analysis is a fundamental tool for analyzing and representing information, and is especially motivated by modern applications where data has complex structure and massively high dimension.  Applications of computational harmonic analysis include many areas of national technological interest such as data science, neural networks and artificial intelligence, medical imaging, radar signal processing, coding theory, and quantum computing.  The conference will discuss the most recent theoretical breakthroughs, practical advances, and emerging directions in computational harmonic analysis.  The plenary speakers include a diverse assortment of experts, and female and early career scientists are well-represented.  An important broader impact of the conference is to support the participation of students, early career scientists, and underrepresented minorities; the conference will make a particular effort to invite and provide travel support to members of these groups.  Travel support will be strongly prioritized to those without other sources of travel funding, so as to make the conference accessible those who would not otherwise be able to attend.  This will contribute to expanding and diversifying the nation's talent pool and workforce in the mathematical sciences by contributing to the training of underrepresented groups in STEM fields.<br/><br/>Specific technical topics addressed at the conference will include, but are not limited to: compressed sensing, phase retrieval, convolutional neural networks, wavelets and multiscale transforms, frame theory, graph-based signal processing, time-frequency analysis, analog-to-digital conversion, signal and image processing, quantum computation, and mathematical learning theory.  A main intellectual merit of the conference is to provide a venue to disseminate recent advances in computational harmonic analysis.  The conference will consist of plenary talks, as well as shorter talks and minisymposia in parallel sessions.  There will be numerous opportunities for mathematical interaction and collaboration among the participants.  The conference will provide an interdisciplinary link between mathematicians, engineers, and scientists from other fields who are working on computational harmonic analysis."
"1839909","CICI: SSC: SciTrust: Enhancing Security for Modern Software Programming Cyberinfrastructure","OAC","Cyber Secur - Cyberinfrastruc","10/01/2018","08/24/2018","Yanfang Ye","WV","West Virginia University Research Corporation","Standard Grant","Kevin L. Thompson","09/30/2021","$649,156.00","Brian Woerner, Xin Li","yanfang.ye@mail.wvu.edu","P.O. Box 6845","Morgantown","WV","265066845","3042933998","CSE","8027","9150","$0.00","Software plays a vital role supporting scientific communities. Modern software programming cyberinfrastructure (CI), consisting of online discussion platforms (such as Stack Overflow) and social coding repositories (such as Github), offers an open-source and collaborative environment for distributed scientific communities to expedite the process of software development. Within the ecosystem, researchers and developers can reuse code snippets and libraries, or adapt existing ready-to-use software to solve their own problems. Despite the apparent benefits of this new social coding paradigm, its potential security-related risks have been largely overlooked; insecure or malicious codes could be easily embedded and distributed, which could severely damage the scientific credibility of CI. Therefore, there is an urgent need for developing scalable techniques and tools to automatically detect these open-source insecure or malicious codes. To address this issue, this proposed project seeks to explore innovative links between Artificial Intelligence (AI) and cybersecurity to enhance the security of modern software programming CI. <br/><br/>The key components of the proposed research are three-fold: (1) a novel AI-based solution (iTrustSO) utilizing social coding properties is developed to automatically identify suspicious insecure code snippets on Stack Overflow; (2)  a cross-platform model is constructed to represent the complex interplay between GitHub and Stack Overflow; deep learning techniques are then utilized to build a predictive model (iTrustGH) for automatic detection of malicious codes on GitHub; and (3) a user-friendly tool (SciTrust) is developed to enhance code security for software development. The broader impacts of this work include benefits to scientific communities and the whole society by promoting the efficiency of cyber-enabled software development without sacrificing the security. The establishment of a Cybersecurity Lab through this project enhances the education and workforce training in cybersecurity. The project integrates research with education through curriculum development and student mentoring activities for the newly-established cybersecurity degree program. It is also expected to increase the participation of underrepresented groups including minority and women.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1821819","Phase I IUCRC The Georgia Institute of Technology: Center for Fiber-Wireless Integration and Networking for Heterogeneous Mobile Data Communications (FiWIN)","CNS","INDUSTRY/UNIV COOP RES CENTERS","09/01/2018","08/23/2018","Gee-Kung Chang","GA","Georgia Tech Research Corporation","Continuing grant","Dmitri Perkins","08/31/2020","$150,000.00","Hua Wang, John Barry, Umakishore Ramachandran, Xiaoli Ma","gkchang@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","5761","5761","$0.00","The Fiber-Wireless Integration and Networking (FiWIN) Center for Heterogeneous Mobile Data Communications is an NSF Industry/University Cooperative Research Program (I/UCRC) led by the Georgia Institute of Technology (GT) since 2015. Based on recognized research leadership and accumulated expertise in integrated fiber-wireless access technologies, FiWIN is favorably positioned to make substantial contributions to access network architectures, functional designs of network elements, and optimized system interfaces and operations for the globally competitive next generation mobile communication networks. FiWIN has successfully completed the first three years of operation. The center expands its scope with the addition of Auburn University (AU) as a Member Site in 2018.<br/><br/>GT has been and continues to be a leading global player in the development of fiber wireless integration and networking technologies for delivering high data rate, large capacity and low latency multi-band 5G services. The combined expertise of AU and GT will expand FiWIN's scope to develop radio frequency (RF) integrated circuits for beamforming in coordinated multi-point transmission, in mission-critical sensors for industrial and health Internet of Things (IoT) applications and in heterogeneous cell coverage with mobile edge computing. Mutual synergy will foster advances in data compression algorithms, bandwidth efficient waveform and modulation, and machine learning to autonomously mitigate nonlinear behaviors of 5G network elements.<br/><br/>An affordable and reliable advanced communication network will drive academic innovation and business agility for providing a vital gateway for economic and societal growth. The continuing rise of social media and artificial intelligence will revolutionize on how we interact with the internet, the machines and with one another. It will enable new kinds of data analytics to be harnessed for tangible business, education and everyday life benefits. Outcomes of our research will be innovative technologies to benefit US competitive industrial offerings for 5G systems and cloud/fog computing by teaching and fostering students to be ready for a versatile and skilled workforce. <br/><br/>All FiWIN Center research products are published in archival journals or conference proceedings in compliance according to the Center's Membership agreement and Bylaws. A reference library containing archival research products (Annual reports, Industrial Advisory Board (IAB) presentations, student project proposals and outcome presentations, and a list of publications) will be maintained and updated and be accessible to FiWIN Center Members, FiWIN research team members, and general public with security protection for a period of 5 years after the Center has graduated. An interactive web-based server http://fiwin.org will be used for sharing scientific data products with IAB members and the public.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839567","ATE 2.0: Preparing Technicians for the Future of Work","DUE","ADVANCED TECH EDUCATION PROG","09/01/2018","08/23/2018","Ann-Claire Anderson","TX","CORD","Standard Grant","V. Celeste  Carter","08/31/2022","$3,471,157.00","Richard Gilbert, Michael Lesiecki, Hope Cotner","anderson@cord.org","4901 Bosque Boulevard","Waco","TX","767105841","2547418334","EHR","7412","1032, 9178, SMET","$0.00","The workplace of today is undergoing a major transformation driven by machine learning, artificial intelligence, the internet-of-things, robotics, and systems-integrated process control. NSF's focus on the Future of Work at the Human Technology Frontier recognizes that technology advances are changing industries at an unprecedented pace.  These technological advances promise benefits to the nation by creating new enterprises, occupations, and opportunities for innovation and global leadership while drastically altering the workplace as we know it.  As technology evolves, so will tasks and occupations, creating a demand for an expanding array of knowledge, skills, and services. The demand for positions involving tasks that can be automated will decline and, in some cases, disappear, while entirely new occupations will emerge. This transformation is already affecting America's technicians. This project proposes strategies and collaborative regional activities with industry that will enable the NSF-ATE community to prepare technicians for the changing workplace by transforming technician education at the secondary and post-secondary educational levels.<br/><br/>This project will convene academic partners, industry leaders, and economic development professionals.  These individuals will serve as collaborative thought partners in framing, testing, refining, and supporting strategies that transform technician education to assure regional competitiveness in the evolving workplace. Technological education today generally focuses on industry segments and single sectors. Yet, soon technicians will need skill sets that cross industries and support both core and advanced STEM skills. This project will identify key cross-disciplinary and new disciplinary knowledge and skills needed by technicians in industries that are responding to the changing workplace. Regional networks of academic partners will actively collaborate with industry to strengthen ATE efforts to improve technician education across the US. It is expected that bringing the relevant stakeholders together will facilitate the needed paradigm shift in technician education, and coalesce support around industry expectations for technician education.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1829008","NRT: Technology-Human Integrated Knowledge Education and Research (THINKER)","DGE","NSF Research Traineeship (NRT), PROGRAM EVALUATION","09/01/2018","08/22/2018","Laine Mears","SC","Clemson University","Standard Grant","Laura Regassa","08/31/2023","$2,993,421.00","Amy Apon, Deborah Switzer, Laura Stanley, Joshua Summers","mears@clemson.edu","230 Kappa Street","CLEMSON","SC","296345701","8646562424","EHR","1997, 7261","062Z, 9150, 9179, SMET","$0.00","The pervasiveness of new digital technologies in manufacturing is changing the way that data are generated, interpreted and shared over networks of machines, robotics and software systems. This ""industrial internet of things"" holds great promise for improving the quality and productivity of manufacturing in the United States. However, the ability of human workers to effectively interface with such digital systems is limited, potentially leading to disruptions in cognition that may negatively affect output and job satisfaction. This National Science Foundation Research Traineeship (NRT) award prepares master's and doctoral degree students at Clemson University to advance discoveries at the nexus of humans, technology, work, and health, through the convergence of human factors, robotics, cognitive sciences, artificial intelligence, systems engineering, education, manufacturing and social behavioral sciences. This will be achieved through the design and integration of human digital technologies that enhance humans' physical and cognitive interaction and abilities in manufacturing environments. The project anticipates training fifty (50) M.S. and Ph.D. students, including twenty-two (22) funded trainees, from electrical engineering, industrial engineering, computer science, manufacturing, systems integration, psychology, and sociology. These students will interface with a parallel program of undergraduate and technical college students in a controlled manufacturing environment to test deployment and integration across multiple academic levels.<br/><br/>This project responds to the critical need to help shape and better prepare the STEM graduate student of tomorrow through an innovated curriculum that focuses on the new digital and smart manufacturing, automation, and associated data systems.  The training and research takes a human-centered design approach in the emerging digital manufacturing enterprise (i.e., Industrial Internet of Things), by quantifying physical and human cognition and developing augmented technologies (e.g. augmented reality aids for worker empowerment) to improve worker behaviors and attitudes in the manufacturing enterprise.  This project will focus on an automotive industry exemplar (i.e., vehicle assembly operation), employing a factory setting which includes parts manufacture, structural and subassembly operations, robotics, kitting, logistics, and a full-scale vehicle assembly line, together with parallel programs in undergraduate and technical college curricula. The multi-level educational approach is expected to drive improved team communication, generate knowledge on worker behaviors and attitudes, and prepare students for leading implementation of the technologies under study in manufacturing and other industries.  <br/><br/>The NSF Research Traineeship (NRT) Program is designed to encourage the development and implementation of bold, new potentially transformative models for STEM graduate education training. The program is dedicated to effective training of STEM graduate students in high priority interdisciplinary research areas through comprehensive traineeship models that are innovative, evidence-based, and aligned with changing workforce and research needs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1528179","CSR: Small: Automatic Storage and Network Contention Management for Large-scale High-performance Computing Systems","CNS","Computer Systems Research (CSR","09/01/2015","08/12/2015","Darrell Long","CA","University of California-Santa Cruz","Standard Grant","M. Mimi McClure","08/31/2019","$450,000.00","","darrell@cs.ucsc.edu","1156 High Street","Santa Cruz","CA","950641077","8314595278","CSE","7354","7354, 7923","$0.00","High performance computing is essential to science, industry, and the environment, from resource exploration to the design of the next generation of consumer electronics. These high performance computer systems are among the most complex and expensive computer systems and require that their resources be used in the most efficient manner. Many of the applications that utilize high performance computing are data-intensive, and storage system performance is a crucial aspect of system performance. However, storage systems are notoriously sensitive to contention caused by competition among storage clients for limited bandwidth and disk access. This is a significant problem for shared storage systems. <br/><br/>This project provides an automatic storage contention alleviation and reduction system (ASCAR) for large-scale high-performance storage to increase bandwidth utilization and fairness of resource allocation. ASCAR uses machine learning methods combined with several heuristics to discover the fittest control strategy. It is a highly scalable and fully automatic storage contention and congestion management system, which can improve the efficiency of both legacy and new systems, with no need to change either server hardware/software or existing applications. ASCAR regulates I/O traffic from the client side using a rule based algorithm. It employs a shared-nothing design and requires no runtime coordination between clients or with a central coordinator whatsoever, because runtime coordination is slow and unscalable. The effectiveness of ASCAR relies on the quality of traffic control. The research team has designed a prototype algorithm, the SHAred-nothing Rule Producer (SHARP), which produces rules in an unsupervised manner by systematically exploring the solution space of possible designs. Starting from one initial rule, SHARP uses heuristics similar to random-restart hill climbing to find the optimal parameters without the need for an exhaustive search. ASCAR monitors the workloads running on the system and uses several heuristics to pick up the fittest rules. <br/><br/>It is clear that computer systems are getting ever more sophisticated, and human-lead empirical-based approach towards system optimization is not the most efficient way to realize the full potential of these modern, complex, high performance computing systems. This research brings machine learning, artificial intelligence, and big data methods to systems research and could lead to a very low cost I/O performance increase for a wide range of systems."
"1721216","Collaborative Research:  Automatic Video Interpretation and Description","DMS","OFFICE OF MULTIDISCIPLINARY AC, CI REUSE, CDS&E-MSS","09/01/2017","08/20/2017","Xiaotong Shen","MN","University of Minnesota-Twin Cities","Standard Grant","Christopher W. Stark","08/31/2020","$160,000.00","","xshen@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","MPS","1253, 6892, 8069","1253, 7433, 8004, 8083, 9263","$0.00","Digital information processing has become an essential part of modern life. It is nowadays often expressed in a form of multimedia, involving videos accompanied with images, captions, and audio. Given the explosive growth of such multimedia data, it is extremely critical that it is accurately summarized and organized for automatic processing in artificial intelligence. One important yet challenging problem is automatic interpretation and summarization of video content, having enormous applications in video advertisements, online video searching and browsing, movie recommendation based on personal preference, and essentially any electronic commerce platform. In this project, the research team plans to develop statistical tools to raise our capacity of processing digital information to respond to a rapid growth of video content in real-world applications. The primary objective is to create a learning system to decipher the meaning of visual expressions as perceived by the audience, with a focus on understanding semantic meaning conveyed by a video.<br/><br/>This project aims to develop methods of automatic video interpretation and description, which understands visual thoughts expressed by a video and generates semantic expressions of the content of a video. Particularly, it will utilize conditional dependence structures of entities as well as between entities and their pertinent actions, in a framework of multi-label and hierarchical classification. It will focus on three areas: 1) entity and action learning, 2) semantic learning for long videos and content-based segmentation, and 3) automatic video description generation, each of which develops techniques in novel ways. In each area, classification will be performed collaboratively based on pairwise conditional label dependencies and temporal dependencies of video frames, characterized by graphical and hidden Markov models. Special effort will be devoted to learning from multiple sources and extracting latent structures corresponding to scenes of a video. The PIs also plan to release the software developed as open source and build a user community around the language by ensuring that interested researchers are able to contribute to the codebase of the software developed. This will allow a wider growth of the  project. This aspect is of special interest to the software cluster in the Office of Advanced Cyberinfrastructure, which has provided co-funding for this award."
"1721445","Collaborative Research: Automatic Video Interpretation and Description","DMS","OFFICE OF MULTIDISCIPLINARY AC, CI REUSE, CDS&E-MSS","09/01/2017","08/20/2017","Yunzhang Zhu","OH","Ohio State University","Standard Grant","Christopher W. Stark","08/31/2020","$79,999.00","","Zhu.219@osu.edu","Office of Sponsored Programs","Columbus","OH","432101016","6146888735","MPS","1253, 6892, 8069","1253, 7433, 8004, 8083, 9263","$0.00","Digital information processing has become an essential part of modern life. It is nowadays often expressed in a form of multimedia, involving videos accompanied with images, captions, and audio. Given the explosive growth of such multimedia data, it is extremely critical that it is accurately summarized and organized for automatic processing in artificial intelligence. One important yet challenging problem is automatic interpretation and summarization of video content, having enormous applications in video advertisements, online video searching and browsing, movie recommendation based on personal preference, and essentially any electronic commerce platform. In this project, the research team plans to develop statistical tools to raise our capacity of processing digital information to respond to a rapid growth of video content in real-world applications. The primary objective is to create a learning system to decipher the meaning of visual expressions as perceived by the audience, with a focus on understanding semantic meaning conveyed by a video.<br/><br/>This project aims to develop methods of automatic video interpretation and description, which understands visual thoughts expressed by a video and generates semantic expressions of the content of a video. Particularly, it will utilize conditional dependence structures of entities as well as between entities and their pertinent actions, in a framework of multi-label and hierarchical classification. It will focus on three areas: 1) entity and action learning, 2) semantic learning for long videos and content-based segmentation, and 3) automatic video description generation, each of which develops techniques in novel ways. In each area, classification will be performed collaboratively based on pairwise conditional label dependencies and temporal dependencies of video frames, characterized by graphical and hidden Markov models. Special effort will be devoted to learning from multiple sources and extracting latent structures corresponding to scenes of a video. The PIs also plan to release the software developed as open source and build a user community around the language by ensuring that interested researchers are able to contribute to the codebase of the software developed. This will allow a wider growth of the  project. This aspect is of special interest to the software cluster in the Office of Advanced Cyberinfrastructure, which has provided co-funding for this award."
"1820827","CDS&E: Structure-Aware Representation Learning Using Deep Networks","DMS","CDS&E-MSS","07/01/2018","06/14/2018","Xiuyuan Cheng","NC","Duke University","Continuing grant","Christopher W. Stark","06/30/2021","$66,394.00","Qiang Qiu","xiuyuan.cheng@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","MPS","8069","8083, 9263","$0.00","In recent years, deep neural networks have been widely applied to analyze Big Data produced in various fields of science, industry and society. In the area of signal processing, deep Convolutional Neural Network (CNN) is one of the most successful computational models, with numerous applications including visual object recognition, object detection and localization. Despite the wide success of deep networks, the data representation computed by these models does not necessarily reflect the geometric information in the input data in an understandable way; a gap remains between the remarkable performance of deep models and the interpretability of such performance. In particular, deep networks trained from enormous amounts of data typically have no specific structures in the model parameters, which also leads to significant redundancy in the model. This project will investigate the mathematical foundation for imposing appropriate structures in deep networks, aiming at more analyzable and efficient network models with theoretically guaranteed performance. The results will have direct applications in various machine learning tasks, improving the accuracy, computational efficiency and interpretability of existing models. The theoretical analysis to be developed will deepen the mathematical understanding of deep networks, which is important for the next generation of computational tools for machine learning. Students engaged in the project will be trained in an interdisciplinary environment of mathematics and electrical engineering, developing skills in both analysis and software implementation, which benefits their future careers in academia or industry. The project will also train future mathematicians and electrical engineers through course development, especially courses on machine learning and image sciences with public online repositories. The project explores the new possibility of representation learning using deep networks, a tool with immense potential to address key challenges in today's Big Data analysis and artificial intelligence. <br/><br/>The goal of the project is to develop novel mathematical analysis of the deep Convolutional Neural Network (CNN) model, as well as innovative designs of CNNs with appropriate structures based on the analysis. Specifically, the PIs will study: (1) the geometric structures in the channels of the convolutional layers, with which the CNN representations can collaboratively and explicitly encode geometric information in the data with improved interpretability and robustness; (2) the spatial structures of the convolutional filters, by which the filter regularity can be analytically imposed so that the CNN representations can be provably stable to input variations; and (3) efficient software implementation, which transfers the theoretical results into applications such as object detection and image segmentation in computer vision. The PIs will use tools from harmonic analysis and approximation theory to address the following open problems in the field: the removal of redundancy in trained CNN filters in a principled way while avoiding under-fitting, the more efficient learning of invariant representations with respect to geometrical transforms in the data, and the theoretical guarantees of the deep representations learned by an adaptive network that is trained from data. The new mathematical understanding will guide the design of deep networks to achieve better performance, in accuracy and computational speed, and better interpretability of the learned data representation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1747043","SBIR Phase I:  Mia Learning Independent Reading Choice Support System","IIP","SMALL BUSINESS PHASE I","01/01/2018","08/20/2018","Darren Cambridge","DC","Mia Learning LLC","Standard Grant","Rajesh Mehta","10/31/2018","$225,000.00","","darren@mialearning.com","1140 Third St NE","Washington","DC","200023406","2022705224","ENG","5371","5371, 8031","$0.00","This Small Business Innovation Research Phase I project will build children's motivation to read and help them access books best suited to their individual interests, purposes, and abilities. Even though robust research demonstrates both intrinsic motivation to read and print book ownership strongly shape reading achievement, few existing educational software products address them. The project will develop a voice chatbot app elementary students will use in class to receive personalized book recommendations and coaching on choosing well. An associated book subscription service will allow kids to own books they choose, including in very low income schools through partnerships with non-profits. Together, these offerings will tap a combined U.S. children's book and literacy educational software market for grades 2-5 that tops $1.4 billion dollars annually. Unlike most other ""personalized"" or ""adaptive"" learning systems, the app will use machine learning and artificial intelligence to increase the agency of students and teachers. It will focus on helping students improve their ability to make their own choices rather than making those choices for them.  <br/><br/>The intellectual merit of this project lies in its innovative combination of a recommender system and a pedagogical agent to simultaneously assist students in completing an authentic task (choosing books to read independently) quickly and well while also teaching them to complete the task increasingly effectively and independently over multiple performances. The voice conversational interface will provide this combined task support and coaching through an emotionally engaging narrative experience accessible to struggling readers. The research will yield a field-tested prototype of the system, constructing a domain model, authoring conversational content, developing machine learning technology, and iteratively improving the system through usability and pilot testing in elementary school classrooms. Technical challenges include tuning automated voice recognition in naturalistic classroom environments, overcoming the cold start problem to generate high quality initial recommendations, and supporting acquisition of both cognitive and metacognitive skills within an ill-structured domain where measurement of successful performance has complex dependencies with student identity and social context."
"1813091","Theory and Applications of Localized Kernel Bases to Meshfree Methods","DMS","APPLIED MATHEMATICS","09/01/2018","08/19/2018","Joseph Ward","TX","Texas A&M University Main Campus","Standard Grant","Michael H. Steuerwalt","08/31/2021","$230,812.00","Francis Narcowich","jward@math.tamu.edu","400 Harvey Mitchell Pkwy South","College Station","TX","778454375","9798626777","MPS","1266","","$0.00","The need for analyzing and modeling data taken from scattered, irregularly placed sites arises frequently in diverse fields: atmospheric science, artificial intelligence, computer-aided design graphics, data mining, medical imaging, learning networks, and many other areas.  For example, weather prediction or climate modeling is based on geophysical data collected at scattered sites, by sensors on satellites, ground stations, or stations at sea.  Carrying out such tasks presents difficulties for traditional methods, which are based on collecting data at uniformly placed sites or which require constructing ""meshes"" (think wire fence) that must be carefully tailored to deal with the data sites involved.  Newer methods, the so-called kernel methods, are meshfree and can handle scattered data.  The investigators further develop the theory of kernel methods, on the basis of which algorithms can be developed that are easier to use, faster, less expensive to implement, and capable of handling data from a hundred thousand or more sites.<br/><br/>Scattered data problems present a challenge for any method, including the traditional kernel-type algorithms based on translates of one (conditionally) positive definite function.  Scattered data occur naturally in meshfree methods, machine learning, neural nets, and other situations.  Dealing with such data, ideally, requires local, stable bases, preconditioners, and other similar tools.  In recent work on the sphere and rotations in space where no boundary is present, the investigators have developed novel bases related to certain classes of kernels.  For problems where boundaries are inherent, their bases need further development.  One key part of this project involves a novel idea of extrapolating data slightly beyond the boundary of a compact domain to enhance the approximation power of the method.  Another key area of investigation involves local approximation orders for data that is far more general than the typical quasi-uniform assumptions.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1761178","Supporting Student Planning with Open Learner Models in Middle Grades Science","DUE","Core R&D Programs","08/15/2018","08/19/2018","James Lester","NC","North Carolina State University","Standard Grant","Andrea Nixon","07/31/2021","$1,499,183.00","Roger Azevedo","lester@csc.ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","EHR","7980","8244, 8817","$0.00","This project is supported by the Education and Human Resources Core Research (ECR) program, which supports fundamental research in STEM learning and learning environments.  Self-regulated learning requires learners to set learning goals, plan how to achieve them, monitor the success of their plans, and make needed changes.  Critical gaps exist in our understanding of how and to what extent middle school students can engage in self-regulated learning during science inquiry activities.  Analogous gaps exist in our understanding of how to help students become self-regulated learners.  Computer-based learning tools might help fill these gaps, but these tools are usually ""closed,"" meaning that how the software interprets students' knowledge and progress is hidden from the student.  In contrast, ""open"" learning tools provide students with understandable, visual representations of their knowledge and progress.  Such ""open learner models"" may be useful for helping students develop self-regulated learning skills.  For example, by providing easy-to-understand representations of student progress, open learner models may support the self-regulated learning processes of goal setting and planning. This project focuses on the design, development, and investigation of open learner models for student goal setting and planning in middle school science. The project will explore how students engage in goal-directed learning behaviors using data from eye tracking, log files, and think-aloud exercises.   It is anticipated that the project results can advance the goal of high quality STEM learning experiences for all students.<br/> <br/>A major project goal is improving students' problem-solving abilities and learning outcomes through a theoretically grounded, data-driven open learner model. The project is designed to integrate an open learner model into the Future Worlds science learning environment for middle school ecosystems education. A culminating between-subjects experiment will be conducted to compare a baseline version of Future Worlds that does not have an open learner model (control condition) with a version of Future Worlds that has an embedded open learner model (experimental condition). The project will use state-of-the-art artificial intelligence computational frameworks to recognize students' goals and plans from observations of their problem-solving activities in an online learning environment.  It is hypothesized that the open learner model will yield better student learning outcomes, with improved science problem-solving skills, increased science content knowledge, increased metacognitive awareness, and enhanced science self-efficacy.  The project is designed to make significant contributions to both theory and practice of self-regulated learning. The project's aim is to make contributions to foundational knowledge and theory by advancing our understanding of how to improve science learning with open learner models: (1) With a focus on student goal setting and planning in technology-rich learning environments, the project aims to formulate an empirically-based theoretical framework for open learner model-enhanced learning that addresses both cognitive and metacognitive components of middle grades science education. (2) By conceptualizing goal setting and planning to account for self-regulated learning in the context of science problem solving, the project is designed to create a rich framework that connects goal setting and planning to students' problem solving and metacognitive processes. (3) By expanding to fine-grained process data, the project is intended to make methodological contributions that will enable the field to go beyond self-report measures, which have long dominated research on self-regulated learning. (4) The project plans to produce learning analytic techniques that yield predictive models of goal setting and planning in science problem solving, as well as open learner models to effectively support student goal setting and problem solving.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1835473","Elements: Data:  Integrating Human and Machine for Post-Disaster Visual Data Analytics:  A Modern Media-Oriented Approach","OAC","DATANET","01/01/2019","08/18/2018","Shirley Dyke","IN","Purdue University","Standard Grant","Amy Walton","12/31/2021","$597,955.00","Thomas Hacker, Bedrich Benes","sdyke@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","7726","062Z, 077Z, 7923","$0.00","This project creates a science-oriented visual data service that facilitates the query of datasets based on visual content. The approach allows a user to search for data based on visual similarity, even in cases where a term for the failure or observation does not yet have a scientific name.  The visual analysis data and application services will be deployed on a cloud-based platform.  The results will produce a framework enabling access to and analysis of a large amount of imagery from diverse sources.  <br/><br/>The research team creates VISER (Visual Structural Expertise Replicator), which will serve as a comprehensive cloud-based data analytics service and will facilitate the use of and integrate data and applications most needed by the user.  The framework will implement two novel concepts: data-as-a-service and applications-as-a-service, which will bring data and applications to the user without the need to configure software systems or packages.  The approach also employs artificial intelligence to interpret the contents of the images.  VISER will use convolutional neural networks (CNNs) to train custom classifiers for new categories.  Three applications will be developed and deployed within VISER:  App1 will extract relevant visual context, App2 will facilitate similarity-based visual searching (through the use of a Siamese CNN), and App3 will help perform automatic extraction of pre-event/pre-disaster images based on Google Street View.  The application of these tools would advance both the science of automated pattern recognition and of more effective construction techniques.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1726377","MRI: Development of Monitors for Alaskan and Canadian Auroral Weather in Space (MACAWS)","AGS","MAJOR RESEARCH INSTRUMENTATION","09/15/2017","09/01/2017","Anthea Coster","MA","Northeast Radio Observatory Corp","Standard Grant","S. Irfan Azeem","08/31/2020","$698,287.00","","acoster@haystack.mit.edu","77 Massachusetts Ave","Cambridge","MA","021394307","6172531975","GEO","1189","1189, 1521, 4444","$0.00","This Major Research Instrumentation development award is for the creation of a network of ground-based receivers that can use satellite navigation signals to provide crucial information about the Earth's ionosphere.  This network will include 35 sites in Alaska and Canada, bringing additional measurements to a data-sparse region.  The development activities also include making the system dynamic, adaptable, and autonomous.  Improving the amount and quality of data will help to answer many questions about the basic ionospheric processes, which could lead to improvements in the robustness of satellite navigation systems.  Many of the receivers will also be placed at schools, providing an educational benefit to the students.<br/><br/>The goal of this development award is to provide a ground-based sensor web network that provides both real-time and historical Global Navigation Satellite Systems (GNSS) ionospheric data products for use in geospace science and space weather monitoring in currently unsampled or under-sampled auroral/polar regions in North America.  A sensor web is a dynamic, adaptable, and autonomous network of sensors that can use artificial intelligence to react in real time to information from its instruments.  Thirty-five GNSS receivers will be deployed in Alaska and Canada to retrieve Total Electron Content (TEC) and scintillation statistics.  The project will result in the creation of a unified North American TEC map, development and deployment of triggering algorithms for highly dynamic periods, and the distribution of real-time TEC data to users.  Four specific scientific topics would be addressed: 1) What mechanism is responsible for the formation of polar cap patches?  And how do polar cap patches exit the night-side polar cap?  What is the relationship of the tongue of ionization to polar cap patches? 2) What contribution does the lower atmosphere make to variability in the high-latitude ionosphere? 3) What causes the irregularities that form at the front of the tongue of ionization in the nightside polar ionosphere?  What causes the irregularities that form with the SED plume as observed by SuperDarn? 4) What are the specific auroral and sub-auroral mechanisms that produce GPS scintillations?"
"1848913","I-Corps: Autonomous Unmanned Vehicle Ecosystem Technology","IIP","I-Corps","09/15/2018","08/16/2018","Michael Lawrence","NY","CUNY Queensborough Community College","Standard Grant","Cindy WalkerPeach","02/28/2019","$50,000.00","","mlawrence@qcc.cuny.edu","222-05 56th Avenue","Oakland Gardens","NY","113641497","7186316222","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project is the use of autonomous robotic systems to save lives across multiple disaster levels by multiplying human efforts in areas such as disaster response, extending to reduced response times and improved rescue efforts during disaster relief. Using autonomous systems, such as drones, that run software which allows for the use of biosensors and on-board machine learning, natural disaster responders can find survivors faster and reduce casualties. The technology understands mission objectives (intent-driven), coordinates with others (collaborative autonomy) and is voice enabled (natural language conversational interface), allowing it to work well with both humans and machines. These and other features lend this technology to broad commercial applications, offering the best strategy to mitigate multiple disaster levels - at the district or provincial level by assessing strengths and vulnerabilities to various hazards; at the community level like search and rescue during a flood or fire; and at the household level like ambulatory drone service care for the aging.<br/><br/>This I-Corps project will be focused on translating scientific research to commercialization through lessons on the business model canvas and extensive customer discovery. Our research has involved hands-on technical experimentation using deep/machine learning software for prototype development and literature reviews on a variety of software capabilities. Using a camera with machine learning, we were able to identify a human with most of the body obscured. Hardware acts as transport for the optical and acoustical biosensor package which can take action autonomously by utilizing artificial intelligence (AI) technologies extending to: realtime onboard object detection capable of identifying a person in rubble, even when the person is partially obscured (Machine/Deep Learning/edge), offline cloud-enriched datasets for cloud-sourced analysis, voice recognition/conversational natural language processing/speech synthesis. Blockchain enabled autonomous swarm management technology on multiple robotic devices will enable multiple machine collaboration. All sensor data is time-stamped and stored in the cloud where the AI technologies are used to enrich the data. Enriched data is made available offline via the internet to thousands of volunteers for human review. Results from our research show that the technological capability exists, the software and hardware components combined meet a need established through our initial customer discovery.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1750731","CAREER: The Future of Work in Health Analytics and Automation: Investigating the Communication that Builds Human-Technology Partnerships","SES","CROSS-DIRECTORATE  ACTIV PROGR, Science of Organizations","09/01/2018","08/15/2018","Joshua Barbour","TX","University of Texas at Austin","Continuing grant","Georgia Chao","08/31/2023","$204,471.00","","barbourjosh@utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","SBE","1397, 8031","063Z, 1045","$0.00","Advances in technologies such as the internet of things, robotics, and artificial intelligence are transforming work through data-intensive automation, which may eliminate jobs without creating new ones or deskill and diminish existing work. This project will investigate how work is automated to encourage forms that benefit work and workers. The project will expand knowledge about the everyday conversations that shape the implementation of automation, and how leaders make choices about how to have those conversations in the first place. The project will focus on health and healthcare work, with is a context likely to be affected by datafication and automation and likely to provide STEM-related careers for individuals who have the right skills. In healthcare, automation may help providers prevent medical errors, lower the costs of caregiving, and augment or create new forms of work, but the success of such systems depends on how they are designed and implemented. By focusing on the actual communication involved in automation, the project will generate theoretical insights and practical recommendations for leaders in health and analytics organizations, regarding (a) what makes the communication involved in data-intensive automation effective or not, and (b) how to structure and facilitate that communication. The research will be used to create short films and a learning module for students making key career decisions. The films and module will be designed to reach groups underrepresented in STEM and to provide information about STEM careers affected by automation and STEM-related, communication competencies. The project will help students at community colleges and universities understand and prepare for the opportunities and challenges of automation.<br/><br/>Recent research has demonstrated that automation is determined not merely by the features of new technology or pressures to make work more efficient, but by a complex, communicatively-negotiated mix of workers' and managers' ideas about factors such as market forces, professional standards, regulation, industry knowledge, and human and technology workflows. Automation involves intertwined changes in the technologies and organization of work. These changes unfold in and through everyday communication about how work is and ought to be accomplished. Using a combination of interview and observational methods, the project will investigate two theoretically and practically important contexts: (1) Healthcare organizations that develop and implement technologies such as automated metrics dashboards and clinical decisions support systems, and (2) Quantified Self communities where practitioners of personal analytics are creating new human-technology partnerships, new forms of work and play, through automation. Insights from this project will advance research on automation, data-intensive work, communication design, and organizational and technological change.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839014","Challenges and Opportunities in Scientific Data Discovery and Reuse in the Data Revolution: Harnessing the Power of AI","OAC","NSF Public Access Initiative","10/01/2018","08/17/2018","Nicholas Nystrom","PA","Carnegie-Mellon University","Standard Grant","Beth Plale","09/30/2019","$50,000.00","Paola Buitrago, Huajin Wang, Keith Webster","nystrom@psc.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7414","7556","$0.00","The volume and heterogeneity of scientific data goes beyond a researcher?s ability to find relevant data, make different formats interoperable, and deal with difficult ontological and language issues. Progress requires bringing together experts in data curation with experts in Artificial Intelligence (AI) to begin a dialog and collaboration on AI tools to span the gap between data and its reuse.  The PIs will organize the conference ""Challenges and Opportunities in Scientific Data Discovery and Reuse in the Data Revolution: Harnessing the Power of AI""; the objective is to bring together diverse stakeholders including research librarians and data managers, the AI community, and users and consumers of scientific data to dialog around critical places in the data lifecycle where AI could be groundbreaking.  <br/><br/>This project is supported by the National Science Foundation?s Public Access Initiative which is managed by the NSF Office of Advanced Cyberinfrastructure on behalf of the Foundation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1842567","NSF Nanoscale Science and Engineering (NSE) 2018 Grantees Conference, at  Westin Alexandria Hotel, Alexandria, VA, on December 6-7, 2018","ECCS","ELECT, PHOTONICS, & MAG DEVICE, ENG NNI SPECIAL STUDIES","08/15/2018","08/16/2018","Robert Westervelt","MA","Harvard University","Standard Grant","Lawrence S. Goldberg","07/31/2019","$100,000.00","","westervelt@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","ENG","1517, 7681","7237, 7556","$0.00","The NSF Nanoscale Science and Engineering (NSE) 2018 Grantees Conference is a two-day annual event that brings together nanoscale educators, researchers, and experimentalists from academia, government, and industry to highlight information on the research and education activities funded by NSF NSE grants. The primary goals are to promote dissemination of innovative research progress, to facilitate research partnerships, and to identify future research directions. Panel discussions will be moderated by NSF-funded researchers as well as NSF Program Directors. The conference helps advance the goals of the NSF and the U.S. National Nanotechnology Initiative. Conference materials are made available to the global audience following the event at the website www.nseresearch.org, along with archival information from previous events. <br/><br/>The NSE grantees conference will foster interaction among academic, government, and industry researchers in nanotechnology fields. Keynote presentations and interactive panel discussions on the grand challenges in and convergence of nanotechnology generate opportunities for creative interdisciplinary collaboration. Identification and exploration of future trends in nanotechnology and cyberinfrastructure enable researchers and industry to prepare to fully capitalize on next-generation capabilities. The first day of the conference will focus on Progress in Foundational Nanotechnology and Infrastructure. Topics will include nanoscale modeling and simulation, the use of big data in nanotechnology research, nanotechnological devices and systems, two-dimensional nano-materials, and quantum phenomena in nanoscale systems. The second day of the conference will focus on Progress in Grand Challenges and Convergence. Topics will include the convergence of nanotechnology with a variety of other fields including biotechnology, cognitive science, cyber and artificial intelligence fields, and brain-like cognitive engineering systems. The second day will also include discussions of education challenges and societal impacts of nanotechnology.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1827633","PFI-TT: Scalable Silicon Photonic Switches for Data Centers","IIP","PARTNRSHIPS FOR INNOVATION-PFI","08/15/2018","08/15/2018","Ming Wu","CA","University of California-Berkeley","Standard Grant","Jesus Soriano Molla","01/31/2020","$200,000.00","","wu@eecs.berkeley.edu","Sponsored Projects Office","BERKELEY","CA","947045940","5106428109","ENG","1662","1662, 8034","$0.00","The broader impact/commercial potential of this PFI project is to introduce scalable silicon photonic switches with fast response time and low power consumption to enhance the capacity and efficiency of the interconnect networks in data centers. The global internet traffic has continued to grow exponentially, fueled by the increase of mobile devices and cloud-based applications for artificial intelligence, video streaming, social networking as well as enterprise compute/collaborate needs. A majority of the data traffic remains within the datacenter. The number of hyperscale datacenters will double in five years. Each of these hyperscale datacenters houses hundreds of thousands of servers and consumes 100 MW of power. Such growth is not sustainable without fundamental changes in how datacenter is designed. Scalable photonic switches with fast response time and low power consumption can improve the efficiency and performance of datacenters. Optical switching is agnostic to data rate, unlike the electrical packet switches in current networks. It enables programmable datacenter networks, allowing the network to adjust its topology to match the traffic patterns of applications.<br/><br/>The proposed project will accelerate the development and commercialization of scalable silicon photonic switches and make them widely available to datacenters and telecommunication industry. Current optical switches in the market are bulky, slow, and expensive. In this PFI-TT, we propose to replace the bulk optical switches with fully integrated (single chip) silicon photonic switches. Silicon photonics use complementary-metal-oxide-semiconductor (CMOS) foundries to mass produce photonic integrated circuits at low cost, leveraging economies of scale of the multi-trillion-dollar microelectronics industry. We use micro-electro-mechanical-system (MEMS) actuation to dramatically reduce the optical insertion loss and power consumption. Silicon photonic switches with microsecond response time and low optical loss will revolutionize datacenter networks. The anticipated outputs of this program include a prototype switch with proven reliability and a strategy to scale up production. The ultimate goal is to spin out a new company building switching subsystems supplying to both datacenter and the telecommunications industry.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1827546","PFI-TT: Smart Climate Control in Shared Workspaces for More Personalization and Efficiency","IIP","PARTNRSHIPS FOR INNOVATION-PFI","08/15/2018","08/14/2018","Koushik Kar","NY","Rensselaer Polytechnic Institute","Standard Grant","Jesus Soriano Molla","01/31/2020","$200,000.00","Sandipan Mishra","koushik@ecse.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","ENG","1662","1662, 8034","$0.00","The broader impact/commercial potential of this PFI project is in attaining significant energy savings in building operations, and in creating more comfortable and personalized work environments for its occupants. Energy efficiency measures in the buildings not only provides a means to reduce energy related costs, it also provides tremendous opportunity to reduce greenhouse gas emissions. Further, the technology that this project aims to develop and evaluate can also create a more personalized workspace for human occupants in a shared space, leading to better wellness and increased productivity of employees in indoor shared workplaces. The education and outreach goals of the project will be enhanced through cross-disciplinary training of a graduate student researcher, and involvement of undergraduate students in the experimental evaluation of the BEES system in a Smart Conference Room facility at RPI. The project team will actively engage with industrial partners and potential clients towards maximizing its commercialization potential. We believe that the proposed technology has considerable future potential for creating new jobs in emerging areas such as Smart Buildings, Internet-of-Things, and Artificial Intelligence.<br/><br/>The proposed project seeks to develop a data-driven learning and integrated control solution for heterogeneous HVAC elements in shared office spaces, with the aim of providing more personalized thermal environments to occupants and minimizing overall energy usage. Even with the high cost of operating the current HVAC systems, occupant dissatisfaction with thermal environments in workplaces have been highlighted by several recent studies. This project seeks to address this issue through the integrated application of i) data-driven learning of the indoor environment, and ii) integrated control of heterogeneous HVAC elements that typically exist in such shared office spaces. Firstly, it will utilize data driven modeling of complex spatiotemporal dynamics of the physical environment, and the dependency between the controls available and the environmental variables. Secondly, it will utilize the data-driven model towards integrated control of the heterogeneous HVAC elements associated with the space to attain differentiated temperatures across the space as desired by the occupants. The product of this project will be a software prototype that will operate in conjunction of sensor and IoT devices, and networked HVAC elements. This integrated HVAC control technology will be evaluated for technical performance and commercial viability in a smart conference room.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1800188","Collaboration Of Midwest Professionals for Logistics Engineering Technology Education Project","DUE","ADVANCED TECH EDUCATION PROG","10/01/2018","08/14/2018","Jeremy Banta","OH","Columbus State Community College","Standard Grant","Heather Watson","09/30/2021","$268,000.00","","jbanta1@cscc.edu","550 East Spring Street","Columbus","OH","432151722","6142872639","EHR","7412","1032, 9178, SMET","$0.00","The supply chain, or logistics, industry continues to grow in the Midwest region of the United States. Jobs in this industry are also becoming more dependent on technologies such as predictive analytics, artificial intelligence, and robotics. Nearly 15,000 transportation and warehousing businesses are located across the cities of Columbus, Ohio; Dayton, Ohio; and Chicago, Illinois. The ongoing growth helps support and strengthen the logistics industry in this regional economy. As a result, there is an increasing need for logistics engineering technicians in the region. In this project, a grouping of community colleges who are leaders in the logistics field in this Midwest region will be formed. The project will be led by Columbus State Community College, Oakton Community College, and Sinclair Community College. It will seek to build career pathways in logistics engineering technology for students, encourage more students to complete degrees in this field, develop faculty experience on the latest technologies, and improve the technical skills of graduates. The goal will be to provide highly-skilled logistics engineering technicians to support the regional and national needs of the supply chain sector. <br/><br/>The project will aim to improve technician education to support the increasingly complex technology needs of the supply chain sector while connecting graduates to employment opportunities in a variety of logistics industries. This project will work with employers, industry experts, and colleges to establish an innovation network. The network of partners will identify and create educational resources for emerging skills and technologies within the sector. The existing logistics curriculum at Columbus State Community College combines technology applications with engineering systems and integrates them with supply chain operations. This curriculum will be enhanced to integrate new topics in data-driven analytics and networking systems. The adapted curriculum will also be implemented and tested at the partnering institutions. The network infrastructure will inform and regularly evaluate efforts in curriculum and career pathway development; in providing professional development material and trainings for high school and college faculty; and on the use of prior learning assessments for adult and returning learners, particularly veterans and recent graduates in need of new skills for the ever-changing logistics job market. Results will be widely disseminated through an interactive project website, through publications, and at regional and national conferences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1800186","Collaboration Of Midwest Professionals for Logistics Engineering Technology Education Project","DUE","ADVANCED TECH EDUCATION PROG","10/01/2018","08/14/2018","Robert Sompolski","IL","Oakton Community College","Standard Grant","Heather Watson","09/30/2021","$149,998.00","","somplski@oakton.edu","1600 East Golf Road","Des Plaines","IL","600161234","8473767099","EHR","7412","1032, 9178, SMET","$0.00","The supply chain, or logistics, industry continues to grow in the Midwest region of the United States. Jobs in this industry are also becoming more dependent on technologies such as predictive analytics, artificial intelligence, and robotics. Nearly 15,000 transportation and warehousing businesses are located across the cities of Columbus, Ohio; Dayton, Ohio; and Chicago, Illinois. The ongoing growth helps support and strengthen the logistics industry in this regional economy. As a result, there is an increasing need for logistics engineering technicians in the region. In this project, a grouping of community colleges who are leaders in the logistics field in this Midwest region will be formed. The project will be led by Columbus State Community College, Oakton Community College, and Sinclair Community College. It will seek to build career pathways in logistics engineering technology for students, encourage more students to complete degrees in this field, develop faculty experience on the latest technologies, and improve the technical skills of graduates. The goal will be to provide highly-skilled logistics engineering technicians to support the regional and national needs of the supply chain sector. <br/><br/>The project will aim to improve technician education to support the increasingly complex technology needs of the supply chain sector while connecting graduates to employment opportunities in a variety of logistics industries. This project will work with employers, industry experts, and colleges to establish an innovation network. The network of partners will identify and create educational resources for emerging skills and technologies within the sector. The existing logistics curriculum at Columbus State Community College combines technology applications with engineering systems and integrates them with supply chain operations. This curriculum will be enhanced to integrate new topics in data-driven analytics and networking systems. The adapted curriculum will also be implemented and tested at the partnering institutions. The network infrastructure will inform and regularly evaluate efforts in curriculum and career pathway development; in providing professional development material and trainings for high school and college faculty; and on the use of prior learning assessments for adult and returning learners, particularly veterans and recent graduates in need of new skills for the ever-changing logistics job market. Results will be widely disseminated through an interactive project website, through publications, and at regional and national conferences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1800182","Collaboration Of Midwest Professionals for Logistics Engineering Technology Education Project","DUE","ADVANCED TECH EDUCATION PROG","10/01/2018","08/14/2018","Ned Young","OH","Sinclair Community College","Standard Grant","Heather Watson","09/30/2021","$152,000.00","","ned.young@sinclair.edu","444 West Third Street","Dayton","OH","454021460","9375124573","EHR","7412","1032, 9178, SMET","$0.00","The supply chain, or logistics, industry continues to grow in the Midwest region of the United States. Jobs in this industry are also becoming more dependent on technologies such as predictive analytics, artificial intelligence, and robotics. Nearly 15,000 transportation and warehousing businesses are located across the cities of Columbus, Ohio; Dayton, Ohio; and Chicago, Illinois. The ongoing growth helps support and strengthen the logistics industry in this regional economy. As a result, there is an increasing need for logistics engineering technicians in the region. In this project, a grouping of community colleges who are leaders in the logistics field in this Midwest region will be formed. The project will be led by Columbus State Community College, Oakton Community College, and Sinclair Community College. It will seek to build career pathways in logistics engineering technology for students, encourage more students to complete degrees in this field, develop faculty experience on the latest technologies, and improve the technical skills of graduates. The goal will be to provide highly-skilled logistics engineering technicians to support the regional and national needs of the supply chain sector. <br/><br/>The project will aim to improve technician education to support the increasingly complex technology needs of the supply chain sector while connecting graduates to employment opportunities in a variety of logistics industries. This project will work with employers, industry experts, and colleges to establish an innovation network. The network of partners will identify and create educational resources for emerging skills and technologies within the sector. The existing logistics curriculum at Columbus State Community College combines technology applications with engineering systems and integrates them with supply chain operations. This curriculum will be enhanced to integrate new topics in data-driven analytics and networking systems. The adapted curriculum will also be implemented and tested at the partnering institutions. The network infrastructure will inform and regularly evaluate efforts in curriculum and career pathway development; in providing professional development material and trainings for high school and college faculty; and on the use of prior learning assessments for adult and returning learners, particularly veterans and recent graduates in need of new skills for the ever-changing logistics job market. Results will be widely disseminated through an interactive project website, through publications, and at regional and national conferences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1810282","PIC: Hybrid Silicon Electronic-Photonic Integrated Neuromorphic Networks","ECCS","ELECT, PHOTONICS, & MAG DEVICE","09/01/2018","06/14/2018","Stefan Preble","NY","Rochester Institute of Tech","Standard Grant","Dominique M. Dagenais","08/31/2021","$422,733.00","Dhireesha Kudithipudi","sfpeen@rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757987","ENG","1517","094E, 095E","$0.00","Neuromorphic computing is a sub-field of artificial intelligence that implements physical architectures inspired by the learning processes in the brain.  There have been significant efforts to realize neural network architectures using electronic integrated circuit technology.  However, electronic-only hardware is not suitable for high bandwidth applications critical to a modern information world. In contrast, the internet is powered by photonic technologies (lasers, electro-optic modulator and photodetectors) because of light's high bandwidth, speed and low energy consumption. Consequently, this project aims to realize high performance neural networks that utilize light. These photonic neural networks will be integrated on a photonic chip in order to realize scalable and efficient architectures.  However, in order to build neural networks that transcend today's state-of-art, it is necessary to also leverage electronics due to the challenges surrounding photonic memory and amplification, both of which are key to realizing a general purpose neural network. This hybrid approach, where electronics and photonics would be integrated together,  enables the investigation of the broadest class of problems.  In addition to these research aims, this project is an interdisciplinary activity that will provide technical training for future science and engineering professionals.  There will be outreach activities that bring the research to  K-12, undergraduate, and graduate students. Students from underrepresented backgrounds will be actively engaged by providing lab visits with hands-on activities.  Lastly, the education initiatives of AIM Photonics Academy will be leveraged to disseminate the research in the project. Overall this project will impact the broader community with applications in autonomous systems, vision systems, information networks, cybersecurity, robotics and other high bandwidth applications.<br/><br/><br/>This project aims to address two fundamental questions, i) How can photonics maximize functionality in the compute domains?, ii) What neuromorphic algorithms can solve a broad class of problems using photonics?<br/>The overall goal of this project is to demonstrate hybrid silicon electronic-photonic integrated neuromorphic networks. The proposed paradigm leverages the power of optical interference to realize high performance neuromorphic computing networks. Photonic implementations of neural networks offer the inherent advantage that light can easily perform computational tasks that are traditionally challenging to do in electronic-only implementations  (e.g. a Fourier transform can be done optically by simply passing light through a lens). The underlying integrated photonic-electronic network proposed here utilizes a Multimode interference coupler as a neural core (Neuro-MMI) in order to realize interference between multiple inputs and outputs in a compact footprint. The principal investigators propose to realize reconfigurability of the weights in the neural network wrapped around the MMI core. The Neuro-MMI core will be integrated with optoelectronic nonlinear thresholding circuits (along with electronic memory) to realize different classes of neural networks (feed forward neural networks and recurrent neural networks).  Active Neuro-MMI's will be studied to realize on-chip learning and new learning rules will be investigated that are inherent for these topologies. Furthermore, the use of wavelength division multiplexing will be explored  to achieve  dense connectivity and parallelism in order to maximize the performance of the networks. One unique feature of the proposed hybrid photonic-electronic network is the reconfigurability to switch between feed forward and recurrent neural networks on a single chip.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1831524","RIDIR: A Big Data Approach to Understanding American Growth","SES","ECONOMICS, Data Infrastructure","09/01/2018","08/07/2018","Konstantinos Arkolakis","MA","National Bureau of Economic Research Inc","Standard Grant","Joseph Whitmeyer","08/31/2021","$1,004,899.00","","costas.arkolakis@yale.edu","1050 Massachusetts Avenue","Cambridge","MA","021385398","6178683900","SBE","1320, 8294","","$0.00","This project uses a big data approach to find out what lies behind the tremendous growth in the American economy in the nineteenth and twentieth centuries.  This award supports a team of researchers, Costas Arkolakis and Michael Peters at Yale University, and Sun Kyoung Lee at Columbia University, who employ artificial intelligence and machine learning technologies to link and then analyze massive amounts of historical US federal census, Department of Labor, and Bureau of Labor Statistics data. The transformation of the US economy during this time period was remarkable, from a rural economy at the beginning of the 19th century to an industrial nation by the end. More strikingly, after lagging behind the technological frontier for most of the nineteenth century, the United States entered the twenty-first century as the global technological leader and the richest nation in the world.  Results from this project will allow Americans to understand how people lived and how business operated.  It will reveal the past that led us to where we are now in terms of people, geography, prices and wages, wealth, revenue, output, capital, numbers and types of workers, urbanization, migration, and industrialization.<br/><br/>In this project, multiple data sets, involving variables such as family status, age, ethnicity, occupation, literacy, and income, are linked. This enables researchers to build a robust picture of the factors that shaped the American economic geography and to illuminate major aspects of America's economic growth during the ""Second Industrial Revolution"" (1850-1940), a period characterized by an influx of people of European origin.  One analysis constructs pairs of parent-child data and investigates, over time, how a child's chance of moving up relative to the child's parents has evolved. Another reveals how economic shocks and policies affected trends in intergenerational mobility. A third uses digitized plant-level Census of Manufactures data to explore the factors that contributed to manufacturing growth at the firm level and how this, in turn, affected America's aggregate economic growth. The data will be shared with other researchers in fields such as economics, history and sociology, enabling them to uncover the underlying forces of America's remarkable economic transition and growth.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1825535","Investigating the Effectiveness of Machine Learning Paradigms for Supporting Engineering Designers in Rapidly Evolving Digital Manufacturing","CMMI","EDSE-Engineering Design and Sy","08/15/2018","08/07/2018","Christopher McComb","PA","Pennsylvania State Univ University Park","Standard Grant","Richard Malak","07/31/2021","$424,743.00","Timothy Simpson, Nicholas Meisel","uum209@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","ENG","072Y","067E, 073E","$0.00","Manufacturing technology is advancing at an unprecedented rate as it become increasingly digital.  Taking advantage of new manufacturing technology is critical for maintaining national security and prosperity, but even dedicated experts and leading-edge companies struggle to keep pace with manufacturing's rapid advancement.  This makes it difficult for engineers to learn about the latest manufacturing technology and design products that take full advantage of new fabrication processes as they become available.  Fortunately, many new manufacturing technologies rely on digital models that produce abundant design data to which machine learning can be applied to derive design knowledge.  While design and manufacturing datasets may be useful for that reason, they are also highly variable in both number and quality of solutions.  This work investigates how the size and quality of these datasets relate to the accuracy and usefulness of machine learning insights, and how this impacts the support provided to engineering designers.  In this work, we focus on additive manufacturing (also called ""3D printing"") as a representative digital manufacturing technology that is rapidly evolving and growing, and which is projected to contribute substantially to the nation?s future manufacturing portfolio. Studies conducted with engineering students as part of this work will be used to provide skill training as well as collect data, helping prepare them for the manufacturing workforce.<br/><br/>The research will combine machine learning, additive manufacturing, and explainable artificial intelligence to evaluate the use of automated design feedback derived from existing crowdsourced additive manufacturing design challenges.  First, part designs will be mined from open, online repositories as well as through curated repositories established in this work via in-class design challenges.  Next, a machine learning pipeline will be implemented to extract design patterns from curated digital repositories.  This will make it possible to test the effect of repository size on the accuracy of design feedback and of repository size on the granularity of feedback.  Finally, a user validation study will be conducted in which students will undertake a design task specific to additive manufacturing technology.  Feedback with varying characteristics will be provided to some participants by extending the machine learning pipeline developed previously with explainable capabilities.  Specific technical deliverables will include (1) a novel dataset of voxelized part designs, (2) a deeper understanding of the impact of repository size and quality on usefulness of machine-generated feedback, and (3) empirical evidence of the impact of real-time additive manufacturing feedback on the solutions generated by engineering designers.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1525943","AF: Small: Is the Simulation of Quantum Many-Body Systems Feasible on the Cloud?","CCF","ALGORITHMIC FOUNDATIONS","08/01/2015","08/21/2017","Pawel Wocjan","FL","University of Central Florida","Standard Grant","Dmitry Maslov","07/31/2019","$385,434.00","Dan Marinescu, Eduardo Mucciolo","wocjan@cs.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","CSE","7796","7923, 7928, 9251","$0.00","Simulating quantum mechanics with its unique effects such as superposition, interference, and entanglement is a hard problem for classical computing systems including supercomputers and computer clouds with a very large number of servers. To efficiently simulate large quantum-mechanical systems using a computer cloud one has to overcome major obstacles. This research investigates optimal algorithms for contracting tensor networks which arising in the study of condensed matter physics. These algorithms minimize the required communication between the nodes of the computer cloud and exploit its hierarchical organization. The broader research objective in this effort is to optimally exploit the architecture of hierarchically organized systems for big data applications that exhibit fine-grained parallelism.<br/>This research project aims to find new efficient methods for simulating large quantum systems that are important for quantum information processing, condensed matter physics, materials science, and chemistry. Its goals are to design and implement novel parallel and distributed simulation algorithms optimized for cloud computing environments such as Amazon Web Services and the National Science Foundation?s future cloud for scientific computing. The ultimate motivation of this project is to enable researchers world-wide to significantly push the boundary in terms of the size of quantum systems that they can simulate reliably and within a reasonable time and with a reasonable budget. While the research mainly concentrates on efficient algorithms and their implementation for the study of properties of condensed matter systems, it also attempts to derive generic strategies to other classes of applications, for instance, in artificial intelligence and in machine learning."
"1832282","Building Capacity: Institute for Interdisciplinary Science:  Preparing Students for the 4th Industrial Revolution","DUE","HSI-Hispanic Serving Instituti","10/01/2018","08/07/2018","Andrea Holgado","TX","Saint Edward's University","Standard Grant","Ellen Carpenter","09/30/2023","$1,499,950.00","Charles Hauser, Laura J Baker, Paul Walter, Raychelle Burks","aholgado@stedwards.edu","3001 South Congress Ave","Austin","TX","787046489","5124442621","EHR","077Y","8209, 9178","$0.00","The Improving Undergraduate STEM Education: Hispanic-Serving Institutions Program (HSI Program) aims to enhance undergraduate STEM education and build capacity at HSIs. Projects supported by the HSI program will also generate new knowledge about how to achieve these aims. This project at St. Edward's University in Austin, Texas aims to create the Institute for Interdisciplinary Science.  The Institute will support student workforce training, cross-sector cooperation, and interdisciplinary activities that can prepare faculty and students for opportunities in the 4th Industrial Revolution.  This revolution is predicted to produce a virtually-connected world in which digital, physical, and biological domains are intertwined.  It is a world of smart homes, cloud computing, big data analytics, e-commerce, robotics, and artificial intelligence. As the 4th Industrial Revolution unfolds, collaborations between industry and higher education become critical to ensure that graduates have the knowledge and skills to be successful in the new workplace. The Institute will facilitate these collaborations by developing mutually beneficial industry-academia partnerships, providing professional development and research opportunities, and facilitating networking for exchange of new directions and ideas. The Institute's partnerships with companies will offer summer internships, which can provide economic support and encouragement to students pursuing STEM degrees, and support eventual entry into STEM careers.  In turn, students will contribute to research and development in the digital era, furthering the objectives of the companies where they work.  This project has the potential to serve as a model for other institutions, especially HSIs and other Minority-Serving Institutions (MSIs), to develop programs with similar goals, thus broadening participation and increasing diversity in the STEM workforce.<br/><br/>This project will support efforts of the School of Natural Sciences at St. Edward's University to build capacity in interdisciplinary sciences, informatics, and emerging technologies and to increase students' readiness for the 4th Industrial Revolution. The Institute aims to establish an educational and professional framework that will facilitate cross-sector partnerships and interdisciplinary collaborations. The Institute will: (i) coordinate on-campus interdisciplinary seminars and experiential learning events that will challenge faculty and students to explore complicated problems with cross-disciplinary approaches; (ii) organize cross-sector cooperative agreements with public and private entities around the Austin, Texas area and beyond; (iii) expose STEM majors to postgraduate opportunities by connecting them with employers and graduate programs through guaranteed internships; (iv) finance faculty and student professional development by offering awards to faculty and micro-credentialing scholarships to students; and (v) catalyze faculty advancement, interdisciplinary collaborations, and innovative research by offering research opportunity awards.   The project's research questions will focus on effects of the interventions on student persistence and on whether faculty professional development grants and research opportunity awards are a means to enhance student success.  Together, these activities are designed to improve student access and success in the emerging 4th Industrial Revolution.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1659628","REU: From the intertidal to the deep ocean: Monterey Bay Regional Ocean Science REU Program","OCE","EDUCATION/HUMAN RESOURCES,OCE","05/01/2017","08/03/2018","Corey Garza","CA","University Corporation at Monterey Bay","Continuing grant","Elizabeth Rom","04/30/2020","$514,985.00","","cogarza@csumb.edu","100 Campus Center","seaside","CA","939558001","8315823089","GEO","1690","9250","$0.00","A Research Experience for Undergraduates (REU) program at the California State University, Monterey Bay (CSUMB) campus will bring eleven undergraduates to CSUMB each summer for three years. This program includes a partnership with five other organizations, including the Naval Postgraduate School, Hopkins Marine Station of Stanford University, Moss Landing Marine Laboratory, Monterey Bay Aquarium Research Institute, and Elkhorn Slough National Estuarine Research Reserve, which are all within a short distance of CSUMB. Students will live at CSUMB, but they will conduct research and be mentored by CSUMB faculty and researchers at partner organizations. Research themes include Oceanography, Marine Biology and Ecology, Ocean Engineering, and Marine Geology, with a wide range of topics in each of these themes. Students receive a stipend, housing and travel expenses. Professional development activities include workshops on scientific ethics and Responsible Conduct in Research (RCR), scientific boating, Geographical Information Systems (GIS), graduate school admissions and fellowships, and scientific communication. Many students will be able to present their research results at a conference or a professional meeting following the program. This program will provide unique research and professional development opportunities to a diverse group of thirty-three students and thus supports the national goal of creating a well-trained scientific workforce.<br/><br/>Students who participate in the this program have the opportunity to work with researchers at a variety of marine science research institutions. Potential research topics include, but are not limited to: Trace Metal Analysis; Internal Wave Dynamics; Ocean Analysis and Prediction; Ocean Modeling; Nearshore Processes; Coastal Circulation; Marine Microbiology; Fish Ecology; Population Genetics; Invasion Ecology; Biomechanics; Remotely Operated Vehicles (ROVs); Autonomous Underwater Vehicles (AUVs); Artificial Intelligence; Coastal Erosion; Seafloor Mapping, and Biogeochemical Analysis."
"1658042","Collaborative Research: Combining models and observations to constrain the marine iron cycle","OCE","CHEMICAL OCEANOGRAPHY","07/01/2017","03/03/2017","Thomas Weber","NY","University of Rochester","Standard Grant","Simone Metz","06/30/2020","$221,390.00","","t.weber@rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","GEO","1670","","$0.00","Tiny marine organisms called phytoplankton play a critical role in Earth's climate, by absorbing carbon dioxide from the atmosphere. In order to grow, these phytoplankton require nutrients that are dissolved in seawater. One of the rarest and most important of these nutrients is iron. Even though it is a critical life-sustaining nutrient, oceanographers still do not know much about how iron gets into the ocean, or how it is removed from seawater. In the past few years, scientists have made many thousands of measurements of the amount of dissolved iron in seawater, in environments ranging from the deep sea, to the Arctic, to the tropical oceans. They found that the amount of iron in seawater varies dramatically from place to place. Can this data tell us about how iron gets into the ocean, and how it is ultimately removed? Yes. In this project, scientists working on making measurements of iron in seawater will come together with scientists who are working on computer models of iron inputs and removal in the ocean. The goal is to work together to create a program that allows our computer models to ""learn"" from the data, much like an Artificial Intelligence program. This program will develop a ""best estimate"" of where and how much iron is coming into the ocean, how long it stays in the ocean, and ultimately how it gets removed. This will lead to a better understanding of how climate change will impact the delivery of iron to the ocean, and how phytoplankton will respond to climate change. With better climate models, society can make more informed decisions about how to respond to climate change. The study will also benefit a future generation of scientists, by training graduate students in a unique collaboration between scientists making seawater measurements, and those using computer models to interpret those measurements. Finally, the project aims to increase the participation of minority and low-income students in STEM (Science, Technology, Engineering, and Mathematics) research, through targeted outreach programs.<br/><br/><br/><br/>Iron (Fe) is an important micronutrient for marine phytoplankton that limits primary productivity over much of the ocean; however, the major fluxes in the marine Fe cycle remain poorly quantified. Ocean models that attempt to synthesize our understanding of Fe biogeochemistry predict widely different Fe inputs to the ocean, and are often unable to capture first-order features of the Fe distribution. The proposed work aims to resolve these problems using data assimilation (inverse) methods to ""teach"" the widely used Biogeochemical Elemental Cycling (BEC) model how to better represent Fe sources, sinks, and cycling processes. This will be achieved by implementing BEC in the efficient Ocean Circulation Inverse Model and expanding it to simulate the cycling of additional tracers that constrain unique aspects of the Fe cycle, including aluminum, thorium, helium and Fe isotopes. In this framework, the inverse model can rapidly explore alternative representations of Fe-cycling processes, guided by new high-quality observations made possible in large part by the GEOTRACES program. The work will be the most concerted effort to date to synthesize these rich datasets into a realistic and mechanistic model of the marine Fe cycle. In addition, it will lead to a stronger consensus on the magnitude of fluxes in the marine Fe budget, and their relative importance in controlling Fe limitation of marine ecosystems, which are areas of active debate. It will guide future observational efforts, by identifying factors that are still poorly constrained, or regions of the ocean where new data will dramatically reduce remaining uncertainties and allow new robust predictions of Fe cycling under future climate change scenarios to be made, ultimately improving climate change predictions. A broader impact of this work on the scientific community will be the development of a fast, portable, and flexible global model of trace element cycling, designed to allow non-modelers to test hypotheses and visualize the effects of different processes on trace metal distributions. The research will also support the training of graduate students, and outreach to low-income and minority students in local school districts."
"1658392","Collaborative research: Combining models and observations to constrain the marine iron cycle","OCE","CHEMICAL OCEANOGRAPHY","07/01/2017","03/03/2017","Timothy DeVries","CA","University of California-Santa Barbara","Standard Grant","Simone Metz","06/30/2020","$274,355.00","","tdevries@geog.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","GEO","1670","","$0.00","Tiny marine organisms called phytoplankton play a critical role in Earth's climate, by absorbing carbon dioxide from the atmosphere. In order to grow, these phytoplankton require nutrients that are dissolved in seawater. One of the rarest and most important of these nutrients is iron. Even though it is a critical life-sustaining nutrient, oceanographers still do not know much about how iron gets into the ocean, or how it is removed from seawater. In the past few years, scientists have made many thousands of measurements of the amount of dissolved iron in seawater, in environments ranging from the deep sea, to the Arctic, to the tropical oceans. They found that the amount of iron in seawater varies dramatically from place to place. Can this data tell us about how iron gets into the ocean, and how it is ultimately removed? Yes. In this project, scientists working on making measurements of iron in seawater will come together with scientists who are working on computer models of iron inputs and removal in the ocean. The goal is to work together to create a program that allows our computer models to ""learn"" from the data, much like an Artificial Intelligence program. This program will develop a ""best estimate"" of where and how much iron is coming into the ocean, how long it stays in the ocean, and ultimately how it gets removed. This will lead to a better understanding of how climate change will impact the delivery of iron to the ocean, and how phytoplankton will respond to climate change. With better climate models, society can make more informed decisions about how to respond to climate change. The study will also benefit a future generation of scientists, by training graduate students in a unique collaboration between scientists making seawater measurements, and those using computer models to interpret those measurements. Finally, the project aims to increase the participation of minority and low-income students in STEM (Science, Technology, Engineering, and Mathematics) research, through targeted outreach programs.<br/><br/><br/><br/>Iron (Fe) is an important micronutrient for marine phytoplankton that limits primary productivity over much of the ocean; however, the major fluxes in the marine Fe cycle remain poorly quantified. Ocean models that attempt to synthesize our understanding of Fe biogeochemistry predict widely different Fe inputs to the ocean, and are often unable to capture first-order features of the Fe distribution. The proposed work aims to resolve these problems using data assimilation (inverse) methods to ""teach"" the widely used Biogeochemical Elemental Cycling (BEC) model how to better represent Fe sources, sinks, and cycling processes. This will be achieved by implementing BEC in the efficient Ocean Circulation Inverse Model and expanding it to simulate the cycling of additional tracers that constrain unique aspects of the Fe cycle, including aluminum, thorium, helium and Fe isotopes. In this framework, the inverse model can rapidly explore alternative representations of Fe-cycling processes, guided by new high-quality observations made possible in large part by the GEOTRACES program. The work will be the most concerted effort to date to synthesize these rich datasets into a realistic and mechanistic model of the marine Fe cycle. In addition, it will lead to a stronger consensus on the magnitude of fluxes in the marine Fe budget, and their relative importance in controlling Fe limitation of marine ecosystems, which are areas of active debate. It will guide future observational efforts, by identifying factors that are still poorly constrained, or regions of the ocean where new data will dramatically reduce remaining uncertainties and allow new robust predictions of Fe cycling under future climate change scenarios to be made, ultimately improving climate change predictions. A broader impact of this work on the scientific community will be the development of a fast, portable, and flexible global model of trace element cycling, designed to allow non-modelers to test hypotheses and visualize the effects of different processes on trace metal distributions. The research will also support the training of graduate students, and outreach to low-income and minority students in local school districts."
"1730044","CompCog:  Collaborative Research:  Learning Visuospatial Reasoning Skills from Experience","BCS","Science of Learning","08/15/2017","08/16/2017","Maithilee Kunda","TN","Vanderbilt University","Standard Grant","Soo-Siang Lim","07/31/2019","$200,000.00","Bethany Rittle-Johnson","mkunda@vanderbilt.edu","Sponsored Programs Administratio","Nashville","TN","372350002","6153222631","SBE","004Y","059Z","$0.00","This project uses methods from artificial intelligence (AI) to better understand how people learn visuospatial reasoning skills like mental rotation, which are a critical ingredient in the development of strong math and science abilities.  In particular, this project proposes a new approach to quantify the learning value contained in different visual experiences, using wearable cameras combined with a new AI system that learns visuospatial reasoning skills from video examples.  Results from this project will not only advance the state of the art in AI but also will enable researchers to measure how valuable different real-world visual experiences are in helping people to learn visuospatial reasoning skills.  For example, certain types of object play activities might be particularly valuable for helping a child to learn certain visuospatial reasoning skills.  Ultimately, this new measurement approach could be used to identify early signs of visuospatial reasoning difficulties in children and could also help in the design of new visuospatial training interventions to boost children's early math and science development.<br/><br/>The core scientific question that this project aims to answer is: How are visuospatial reasoning skills learned from first-person visual experiences?  This question will be answered through computational experiments with a new AI system---the Mental Imagery Engine (MIME)---that learns visuospatial reasoning skills, like mental rotation, from video examples.  Training data will include first-person, wearable-camera videos from two different settings that are both important for human learning:  unstructured object manipulation by infants and visuospatial training interventions designed for children.  Results from experiments with the MIME AI system will advance the state of the art in both AI and the science of human learning by helping to explain how visuospatial reasoning skills can be learned from visual experiences, and, in particular, how having different kinds of visual experiences can affect the quality of a person's learning outcomes in different ways."
"1830730","Research Initiation: Exploring Epistemologies where Engineering Meets Art","EEC","ENGINEERING EDUCATION","09/01/2018","08/01/2018","Suren Jayasuriya","AZ","Arizona State University","Standard Grant","Julie Martin","08/31/2020","$197,689.00","Nadia Kellam","sjayasur@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","ENG","1340","110E, 1340","$0.00","Recently, the combination of engineering and the arts has been championed as an effective educational model for training future engineers. The diverse ideas and skills required from combining engineering and art encourages creative student thinking and opens new, non-traditional pathways into engineering. New domains of engineering such as computer graphics, 3D printing, artificial intelligence, and human-computer interaction require engineers to work with designers, visual artists, and humanities scholars for their science and technologies to have societal impact. Engineers need not just technical skills, but social awareness and communication skills to effectively work across these domain boundaries of art and engineering. Through combining engineering and art curriculum, these needs are addressed in a meaningful way. These programs typically feature an extensive collaboration or design project for students in engineering and the arts to interact and work with one another. However, much research has pointed out the difficulty of these interactions between participants due to the diversity of viewpoint, background, and skills. This project aims to understand theories of knowledge that students utilize in a collaborative engineering and arts environment. This will help develop a better understanding of the nature of interactions at the boundary of art and engineering. Insights that emerge from this work promise to improve the educational experiences of engineers interacting in these programs and foster new, diverse and inclusive ways of working for the engineering workforce. <br/><br/>This project is a comparative study of two subsets of students at Arizona State University: (i) a group of engineering and arts students pursuing a year-long design/capstone project from the transdisciplinary School of Arts, Media and Engineering; and (ii) a contrasting group of engineering students pursuing a year-long senior design project in a traditional Electrical, Computer and Energy Engineering School. Through analysis of these student's experiences, researchers answer a series of research questions on the range and depth of epistemological beliefs held by participants in both populations, and any similarities and differences among the participants. In addition, through discourse analysis of language and terms used by participants and of observation notes of working groups, researchers reveal philosophical viewpoints and how these viewpoints affect communication, offering insight into effective collaboration between engineering and the arts.  The intellectual merits of this proposal include generation of fundamental knowledge into the epistemological viewpoints and interactions in art and engineering learning environments and conceptual frameworks of personal epistemology in education. The broader impacts of this project include pedagogical material for transdisciplinary engineering and media arts courses, public outreach and participation through the Center for Science and the Imagination, and participation in the Digital Culture Summer Institute to introduce a diverse set of middle and high school students to engineering and the arts projects.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1710302","Magneto-optoelectronic response in 2D atomic-layered materials","ECCS","ELECT, PHOTONICS, & MAG DEVICE","08/01/2017","07/03/2017","Ramesh Mani","GA","Georgia State University Research Foundation, Inc.","Standard Grant","Paul Lane","07/31/2020","$320,418.00","","rmani@gsu.edu","58 Edgewood Avenue","Atlanta","GA","303032921","4044133570","ENG","1517","094E, 100E","$0.00","Abstract:<br/>Non-technical Description:<br/>The United States has the highest Gross Domestic Product in the world because it has been the leader in technological breakthroughs. Relatively recent advances such as the personal computer, the World Wide Web, the cell phone, high definition television, the forth-coming autonomous car and artificial intelligence, all have roots in government funded research and development. The meteoric growth in these areas has been made possible by the rapid advances in semiconductor capability for both electronics and photonics. To access new areas for growth, there is now a need to develop flexible, faster, thinner, and more power efficient semiconductor materials with new capability. This aim has led to the so-called van der Waals bonded materials, which are materials that can be peeled, layer by layer, down to the thickness of a single 2-dimensional (2D) atomic layer. Such materials promise high speed, greater power efficiency, flexibility, and novel electro-optic properties not found in materials utilized thus far. Thus, this research aims to study their material properties with a view towards applications. <br/>The research is to be carried out in the Physics & Astronomy Department of Georgia State University [GSU], one of the most diverse universities in the nation. The undergraduate Science, Technology, Engineering and Mathematics (STEM) educational component of this proposal aims to translate the abilities of general university students from historically underrepresented groups and women in STEM fields, into the pursuit of a career path in a STEM field, by providing them early exposure to a supportive, confidence building, research experience through mini-science projects in the 2D materials area. Such education/training provided in a southern urban inner-city academic institution in downtown Atlanta, Georgia, will help to add underrepresented sections of society to the nation's science and technology skill base for the electronics, photonics, defense, and wireless communications industries. <br/>Technical Description:<br/>Single atomic layers of bulk van der Waals bonded crystals, and stacks built up by van der Waals epitaxy including a number of single atomic layers with differing electronic, optical, spin, and superconducting properties, offer the possibility of obtaining new physical properties not available in existing bulk materials' properties that can be utilized to address outstanding technological problems in low power and flexible electronics, sensing, and photonics. Thus, this research will experimentally examine the magneto-optoelectronic response under steady state photo-excitation of 2D atomic-layered materials including mono-layer and bilayer graphene, atomically thin hexagonal boron nitride (h-BN), mono- and bilayer-molybdenum disulfide (MoS2), and other transition metal-dichalcogenides. A research team consisting of graduate students and a postdoc, with help from undergraduates participating in mini science projects, will build up 2D atomic-layered crystals by van der Waals epitaxy; fabricate devices by electron beam lithography, plasma etch, and metallization; and examine the properties of electrically contacted and non-contacted devices in the presence of a magnetic field under microwave, mm-wave, and terahertz photo-excitation. Here, some specific problems of interest include the mm-wave magneto-response of graphene, the electric field effect on photoresponse in h-BN encapsulated graphene and MoS2, and the study of the spin properties in graphene across the neutrality point. Such studies are expected to provide insight into the electronic structure of 2D materials, their photo response, spin-g-factors, spin lifetimes, and the dependence of induced bandgaps on applied electric and magnetic fields - attributes that would identify the suitability of such systems for various desirable applications.  Potentially transformative results could include the observation of novel radiation-induced magnetoresistance oscillations in graphene, the realization and measurement of long spin lifetimes in h-BN encapsulated graphene, and the measurement of bandgaps in electric field biased bilayer h-BN encapsulated graphene or MoS2 or other transition metal dichalcogenides in the small bandgap limit."
"1711775","Bridging the Gap Between Education and Research through Pre-College Engineering Systems (PCES) Outreach Program","ECCS","ENERGY,POWER,ADAPTIVE SYS","08/01/2017","07/18/2017","James Momoh","DC","Howard University","Standard Grant","Anil Pahwa","07/31/2020","$170,000.00","","jmomoh@howard.edu","2400 Sixth Street N W","Washington","DC","200599000","2028064759","ENG","7607","1340, 155E, 9177","$0.00","The purpose of the project is to develop a residential summer research and education Science Technology Engineering and Mathematics (STEM) outreach program targeted at 11th and 12th graders from across the country. The program will advance students' preparation for careers in engineering through integration of research and education. The students in the program will undertake lectures on topics such as advanced mathematics and physics, chemistry, preparatory scholastic aptitude testing, advanced placement courses, and will be exposed to fundamentals of engineering courses and special topics in Electrical and Computer Engineering such as artificial intelligence, communications, nanotechnology, photonics, energy systems and smart grid technologies. These courses will prepare and motivate students for research work in energy management, automation functions for secured critical infrastructures, sensor based systems and safe environment. The background achieved and exposure through hands-on activities will capacity for a future diverse workforce of underrepresented groups and women to pursue careers in engineering.<br/><br/>The research work in the pre-college engineering systems program will include various fields of engineering and science used to help students to appreciate the role of creativity, analytical and hands-on work in conducting engineering projects, processes and systems. The research work will involve needs assessment, constraints, problem formulation and design of algorithms, implementation, testing and validation under different scenarios. The major areas for project ideas include communication and signal processing, photonics/electronics, nanotechnology, materials and energy and power systems, with each area having its own set of specific projects. Under communication and signal processing, specific projects include the solar bag, smart phones, new integrated display board, and others. In photonics/electronics, the specific works include mobile diagnostics for power electronics and smart displays. Nanotechnology and materials projects include design of nano toothpaste, nano skating boots, and a nano tricycle for kids. In the area of energy and power systems, smart city design using renewable energy resources and electric vehicles with self driving properties are specific project areas. Furthermore, wireless sensors, a handmade wristwatch for health monitoring, and automatic fan control will be pursued within the computer engineering projects. Students will work in teams and final products will be presented at the end of the program each year to an audience of faculty, parents and a representative of the funding agency, the National Science Foundation (NSF). Mentoring during and after the program (during the school year) will be in place to track students' continued progress toward life-long pursuit of engineering as a carrier. Lessons learned will be shared with other engineering schools so that the country will benefit from the NSF investment in education and research activities for pre-college students at Howard University."
"1704860","AF: Large: Collaborative Research: Nonconvex Methods and Models for Learning: Toward Algorithms with Provable and Interpretable Guarantees","CCF","ALGORITHMIC FOUNDATIONS","06/01/2017","05/16/2017","Sanjeev Arora","NJ","Princeton University","Continuing grant","Rahul Shah","05/31/2022","$669,782.00","Yoram Singer, Elad Hazan","arora@cs.princeton.edu","Off. of Research & Proj. Admin.","Princeton","NJ","085442020","6092583090","CSE","7796","7925, 7926","$0.00","Artificial Intelligence along with Machine Learning are perhaps the most dominant research themes of our times - with far reaching implications for society and our current life style. While the possibilities are many, there are also doubts about how far these methods will go - and what new theoretical foundations may be required to take them to the next level overcoming possible hurdles. Recently, machine learning has undergone a paradigm shift with increasing reliance on  stochastic optimization to train highly non-convex models -- including but not limited to deep nets. Theoretical understanding has lagged behind, primarily because most problems in question are provably intractable on worst-case instances. Furthermore, traditional machine learning theory is mostly concerned with classification, whereas much practical success is driven by unsupervised learning and representation learning. Most past theory of representation learning was focused on simple models such as k-means clustering and PCA, whereas  practical work uses vastly more complicated models like autoencoders, restricted Boltzmann machines and deep generative models. The proposal presents an ambitious agenda for extending theory to embrace and support these practical trends, with hope of influencing practice. Theoretical foundations will be provided for the next generation of machine learning methods and optimization algorithms. <br/><br/>The project may end up having significant impact on  practical machine learning, and even cause a cultural change in the field -- theory as well as practice -- with long-term ramifications. Given the ubiquity as well as  economic and scientific implications of machine learning today, such impact will extend into other disciplines, especially in (ongoing) collaborations with researchers in neuroscience. The project will train a new generation of machine learning researchers, through an active teaching and mentoring plan at all levels, from undergrad to postdoc. This new generation will be at ease combining cutting edge theory and applications. There is a pressing need for such people today, and the senior PIs played a role in training/mentoring several existing ones.<br/> <br/>Technical contributions will include new theoretical models of knowledge representation and semantics, and also frameworks for proving convergence of nonconvex optimization routines. Theory will be developed to explain and exploit the interplay between representation learning and supervised learning that has proved so empirically successful in deep learning, and seems to underlie new learning paradigms such as domain adaptation, transfer learning, and interactive learning. Attempts will be made to replace neural models with models with more ""interpretable""  attributes and performance curves.  All PIs have a track record of combining theory with practice. They  are also devoted to a heterodox research approach, borrowing from all the past phases of machine learning: interpretable representations from the earlier phases (which relied on logical representations, or probabilistic models), provable guarantees from the middle phase (convex optimization, kernels etc.), and an embrace of nonconvex methods from the latest deep net phase. Such eclecticism is uncommon in machine learning, and may give rise to new paradigms and new kinds of science."
"1353757","IDBR Type A: Miniaturized Two-photon Microscopy for Deep Brain Imaging: An Integrated Circuit Design Using Electrowetting Optics","DBI","INSTRUMENTAT & INSTRUMENT DEVP, BIOPHOTONICS, IMAGING &SENSING, CROSS-EF ACTIVITIES","04/01/2014","03/01/2016","Juliet Gopinath","CO","University of Colorado at Boulder","Continuing grant","Robert Fleischmann","03/31/2019","$945,874.00","Emily Gibson, Victor Bright, Diego Restrepo","juliet.gopinath@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","BIO","1108, 7236, 7275","8007","$0.00","An award is made to the University of Colorado to do deep brain imaging using a novel miniature nonlinear microscope. Optical imaging methods combined with fluorescent markers offer the unprecedented ability to study functioning of the complex neural networks in the brain down to the resolution of individual neurons. However, due to light scattering in tissue, over 75% of the brain cannot be studied. Technology that offers the path for high resolution deep brain functional imaging is urgently needed in order to further advance the fundamental understanding of how the brain works. This project will investigate a fiber-optic imaging instrument incorporating adaptable optics. The miniature fiber-optic imaging system implanted minimally-invasively will enable visualization of thousands of neurons deep in the brain. The large volume of imaging is important for understanding the complex interconnections involved in neural networks while access to new regions of the brain will open up study in important areas of the brain that are currently not accessible with other techniques.<br/><br/>The work is interdisciplinary in nature, combining aspects of biology, materials science, physics, and engineering and will provide excellent opportunities for students to broaden their scientific knowledge outside of a specific discipline. The PI's will disseminate the results of their work through teaching and education outreach that includes student groups, undergraduate research opportunity programs and summer programs for under-represented undergraduates. Beyond basic research, results from this project will be used to further the understanding of brain function, advance artificial intelligence, and treat neurological disorders."
"1826218","QRM: Using Visual Information to Quantify Microstructure-Processing-Property Relationships","CMMI","Materials Eng. & Processing, DMREF, ","09/01/2018","07/30/2018","Elizabeth Holm","PA","Carnegie-Mellon University","Standard Grant","Alexis Lewis","08/31/2022","$554,618.00","Bryan Webler","eaholm@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","ENG","8092, 8292, R210","062Z, 8021, 8025, 8400, 9102","$0.00","To advance technology for infrastructure and manufacturing, new, high-performance materials must be developed, with tunable properties (for example, strength or electrical conductivity) and predictable performance. The computational tools used to predict material performance have often relied on Materials Engineers examining pictures of a material's microscopic substructure, termed the microstructure, to determine the relationships between microstructural features and material properties. The analysis of microstructural images can be expensive and time consuming, and can produce inconsistent results. This award supports fundamental research to build the tools to enable an automated approach to microstructure image analysis, with the aim of better understanding the microstructural features that control material properties and performance. In this project, researchers will collect a large set of microstructural images and use artificial intelligence (AI) tools including computer vision and machine learning to analyze them. The AI system will autonomously identify different features of the microstructure, measure them, and link them to how the materials was made (processing) and how it performs (properties). The advantages of this system are that it is fast, objective, general, and may perceive information that is not readily visible to humans. To test and validate this approach, it will be applied to understanding scientifically challenging problems with application in advanced manufacturing, including predicting the strength of materials, and determining the limits of microstructural information. This project will additional train Materials Science and Engineering students in the principles of AI. Furthermore, the methods and results of this project will be made publicly available.<br/><br/>The quantitative representation of microstructure is the foundational tool of microstructural science and traditionally involves a human deciding a priori what to measure and how to measure it. However, recent advances in data science, including computer vision (CV) and machine learning (ML) offer new approaches to extracting information from microstructural images. In this project, the PIs will acquire, curate, and publish a diverse collection of microstructural image data sets, including composition, processing, and property metadata, and will build a suite of CV/ML tools for autonomous microstructural image representation and quantification. The CV/ML approach will be applied to finding quantitative composition-microstructure-processing-property relationships, with the goal of materials discovery. Case studies will focus on achieving scientific understanding of additive manufacturing processes; enhancing knowledge of deformation mechanisms; advancing microstructural science to include visual signals that are not perceptible by humans; and assessing the degree of scientific knowledge learned by a black-box ML method. The methods and results developed in this project will be disseminated via open access codes and data repositories, and will contribute to workforce development by educating Materials Science and Engineering students in the principles of computer vision and machine learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1721926","STTR Phase I:  Smart and Fast Atomic Force Microscope for Imaging and Characterization","IIP","STTR PHASE I","07/01/2017","07/30/2018","Larry Janness","MI","RHK Technology Inc","Standard Grant","Ben Schrag","02/28/2019","$225,000.00","Darrin Hanna","janness@rhk-tech.com","1050 E. Maple Road","Troy","MI","480832813","2485775426","ENG","1505","1505, 8034","$0.00","This Small Business Technology Transfer Phase I project represents a change in concept and technical paradigm for Atomic Force Microscopy (AFM) technology, and as such shall significantly impact research and development in both industry and academia.  As discussed in the Technical Merits below, the proposed AFM is fast, smart, and more powerful in terms of imaging and probing local mechanics.  The company has a track record of commercializing AFM controllers that are compatible with most all types of scanners, commercial and home-constructed.  Current AFM users can purchase the new scanner and/or controller to attain the enhanced performance. In addition, new AFM users are also anticipated especially in the areas of nanomaterials, devices and sensors, and multidimensional devices and materials where both high spatial and temporal resolutions are paramount.  Further, the combined high spatial resolution in conjunction with fast speed shall result in immediate advances in the fields of material development, surface coating, nanomaterial and nanodevice inspection and quality control, nanolithography, and tissue engineering.  Based on current market trends, sales are anticipated to reach $25M within the first three years.  The amount is likely higher given the forecasted growth of the global microscopy market. <br/><br/>The intellectual merit of this project includes three cutting edge improvements to current AFM: (1) faster image acquisition speed; (2) automated and rapid feature finding and tracking; (3) 1-2 orders of magnitude of improvement in speed and efficiency in nanomechanical imaging.  The ultra-high speed will be achieved by implementing a novel reconfigurable processor optimized for AFM into a unique hybrid, low-noise controller architecture, which is highly versatile and compatible with various known configurations of AFM microscopes from many different vendors.  In addition, the automatic feature finding and tracking functions will be accomplished using artificial intelligence directly in hardware and a novel scan pattern, completely different from current ?trace-retrace? scanning trajectory in current AFM.  These new and ?smart? approaches further speed up scanning and tracking speed.  Finally, the AFM will be able to produce nanomechanical images with high speed and accuracy using multifrequency spectroscopy. This concept has been proposed, and individual aspects have been demonstrated in isolation through simulations or lab prototypes over the past five years or more.  The faster and more powerful electronic controller shall enable the test and implementation of multifrequency spectroscopy technology in its full potential."
"1827009","IRES Track I: International Research Experience for Students on Non-Volatile Processor Based Self-Powered Embedded Systems","OISE","IRES Track I: IRES Sites (IS)","10/01/2018","07/27/2018","Jingtong Hu","PA","University of Pittsburgh","Standard Grant","Maija M Kukla","09/30/2021","$299,999.00","","jthu@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","O/D","7727","5978, 9200","$0.00","The objective of this project is to provide U.S. students with valuable research experience related to battery-less embedded systems in future Internet of Things (IoT) in China, which has one of the world's largest electronic industry and market. The project will select five (5) graduate students and two (2) undergraduate students nation-wide each year and support them to visit Tsinghua University (THU) over a period of eight (8) weeks. <br/><br/>The vision of IoT is to embed small computers into objects around our daily life to improve our economy and societal well-being. It is estimated that the Internet of Things (IoT) will consist of almost 50 billion objects by 2020. However, one of the biggest challenges is how to power these billions of embedded devices since batteries need frequent recharging and impose health and environmental concerns. In this project, the students will work with renowned research groups at THU to develop future IoT sensors that can reply on energy harvested from ambient environment sources, such as solar energy, radio frequency energy, kinetic energy, and thermal energy. Since ambient energy is intrinsically intermittent, the students will conduct research on nano-scale device, circuits, system, and software to realize computer systems that can work with intermittent energy supply. Such systems will dramatically improve our capability of collecting data while reducing the maintenance costs. Potential applications include smart healthcare, smart building and infrastructure monitoring, smart environmental monitoring, etc. This IRES project will not only offer U.S. students an opportunity to work in one of the best engineering research universities in China, but also fully immerse them in a foreign environment and improve their talents in working with a global team. <br/><br/>The project contains well-planned recruitment, preparation, mentoring and post-trip activities. The proposed research targets at nano-scale device, circuits, system, and software issues in battery-less embedded systems that need to be addressed urgently. The first project aims to develop fast, energy efficient, and uniform write operations for nano-scale memory device, which is critical to tolerate intermittency of harvested energy. The project addresses a fundamental inconsistency issue when the NVP is interacting with external volatile peripheral devices, which is one of the most imminent roadblocks towards wide application of NVPs. <br/>The second project addresses a fundamental inconsistency issue when the battery-less device is collecting data and communicating with external devices. The project aims to develop efficient and accurate binarized neural network for individual ultraviolet (UV) exposure pattern recognition system running on nonvolatile IoT platform, which could be generalized to many other applications. <br/> The third project aims to develop efficient and accurate artificial intelligence for individual ultraviolet (UV) exposure pattern recognition system running on battery-less IoT platform, which could be generalized to many other applications. It can be anticipated that with the close interaction with THU and the Beijing Innovation Center for Future Chips, the breakthroughs made from these projects can have a direct impact on future IoT market.<br/><br/>The project will enable U.S. students to conduct high-quality research on realizing battery-less embedded systems, in collaboration with their faculty mentors in THU. Such experiences expose U.S. students to the international research community at a critical early stage in their careers. It is expected that through participating in this program, U.S. students will gain extensive experience on the<br/>research of embedded computer systems, on the culture of China, and on performing and collaborating in an international environment in general. The experience will also be shared to the broader community through the personal social media such as Facebook, Twitter, and Youtube, Web2.0 based forum, carefully integrated activities such as research for undergraduate students, minorities and underrepresented groups, as well as outreach events for local K-12 schools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1800592","D3SC: Machine Learned Free Energies of Compounds","CHE","Theory, Models, Comput. Method, CDS&E","09/01/2018","07/27/2018","Charles Musgrave","CO","University of Colorado at Boulder","Standard Grant","Susan Atlas","08/31/2021","$517,497.00","","charles.musgrave@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","MPS","6881, 8084","026Z, 062Z, 8084, 9216, 9263","$0.00","Charles Musgrave of the University of Colorado Boulder and collaborator Aaron Holder are supported by the Division of Chemistry, and the Division of Chemical, Bioengineering, Environmental, and Transport Systems, to develop and apply machine learning approaches for the discovery of new materials. While the periodic table provides a many possible combinations of elements from which to form materials, only a fraction of these compounds will be stable or have desirable properties for particular applications. Furthermore, of the large number of possible compounds, only about one thousand have known properties at elevated temperatures. For the past fifty years, computational chemists have used equations of quantum mechanics to discover new materials.  However, screening large numbers of candidate materials for a specific technological application remains too computationally demanding to be practical.  Recently, statistical learning approaches have been developed which can extract systematic information from large quantities of data to train highly reliable ""artificial intelligence"" models for predicting properties of a new system.  In this project, Professors Musgrave and Holder are using machine learning approaches applied to predict the stabilities, structures, and chemical reactivity of materials. The predicted properties can then be used to identify candidate materials for catalyzing technologically-important reactions, such as splitting water into oxygen and hydrogen, converting carbon dioxide into useful products, or the 'green' synthesis of ammonia from nitrogen and water.  The models are available on public repositories as machine learning computer codes, and through publicly-accessible databases.  The project is training high school, undergraduate and graduate students in the development and application of state-of-the-art machine learning methods for chemistry and chemical engineering applications.  The researchers participation in the Broadening Opportunity through the Leadership and Diversity (BOLD) Center at University of Colorado.  The incorporation of new concepts in machine learning and chemistry are integrated into courses and through the departmental LearnChemE YouTube platform.<br/><br/>This project combines expertise in electronic structure, thermodynamics, computational science, and machine learning to study one of the most fundamental properties of molecules--the Gibbs free energy, G(T). The data-driven approach takes advantage of results showing that the vibrational entropy and Helmholtz free energy computed in the constant-volume quasiharmonic approximation - quantities that critically contribute to G(T) but are computationally challenging to calculate quantum-mechanically - have systematic temperature dependence and can be accurately and efficiently predicted using machine learning, coupled with knowledge of the chemical composition of the material.  The researchers are extending this observation to apply machine learning methods to model G(T) directly, using experimental data for several hundred molecules for training and descriptor extraction.  The resulting descriptors are being used to predict thermochemical data for ~20,000 unique compositions tabulated in the Inorganic Crystal Structure Database, and in turn, to compute temperature-dependent convex hull phase diagrams and solid-state reaction equilibria.  The models and G(T) data are available on large databases. The new methodology is enabling the discovery of general trends and new chemical knowledge of the effects of temperature and composition on reactivity, synthesizability, stability and metastability. In addition to providing deep insights into the thermochemistry of molecules and reactions, this research is enabling the identification of anomalies that may indicate systems where emerging properties are altering the behavior of the molecule. For example, where temperature-dependent emergent or quantum phenomena create unique materials properties. Despite the technological and economic importance of advanced materials in a broad range of technologies, much is still unknown about the detailed behavior that give rise to their stability and reactivity. Potential applications of the new techniques and thermochemical databases produced include thermochemical water splitting using redox materials, ammonia synthesis by chemical looping, oxidation chemistries, carbothermal reduction of oxides, and reduction of molecules by molecular hydrogen or other reductants.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1804024","Inter-comparison of Direct Quantification and Areal Micrometeorological Methods to Investigate the Transport and Fate of Methane from Heterogeneous Sources in Natural Gas Fields","CBET","ENVIRONMENTAL ENGINEERING","09/01/2018","07/27/2018","Derek Johnson","WV","West Virginia University Research Corporation","Standard Grant","Karl Rockne","08/31/2021","$321,788.00","Omar Abdul-Aziz","derek.johnson@mail.wvu.edu","P.O. Box 6845","Morgantown","WV","265066845","3042933998","ENG","1440","9150","$0.00","The use of natural gas is increasing worldwide. Methane, the primary component of natural gas, is a highly potent greenhouse gas (GHG) that contributes to climatic changes.  Recent research suggests that methane can be released from natural gas fields, but large uncertainties in these data do not allow accurate quantification of the amount. The proposed research will reduce this uncertainty and advance knowledge in measurement methods and modeling tools for the quantification of methane emissions in natural gas fields. The project will support graduate and undergraduate researcher from underrepresented engineering students in rural Appalachia, addressing societal needs for broadening participation in science and engineering. If successful, the results of this research will help protect the Nation's energy security by potentially influencing regulatory activities and improving the efficiency of natural gas production.<br/><br/>Due to maturation of technologies such as directional drilling and enhanced recovery, natural gas production continues to grow in the U.S. However, the magnitude and fate of leaking methane emissions from natural gas fields remain highly uncertain and unresolved. Recent studies show significant variations in methane losses, from less than 1% to 17% of the total natural gas produced. These large variations are generally attributed to uncertainty in top-down (indirect aerial fluxes or downwind measurements) and bottom-up (direct component level measurements and emissions factors) estimates, which include measurement uncertainty and a general lack of high fidelity data sets. The goal of this research is to reduce these uncertainties by collecting and analyzing temporal top-down measurements of methane fluxes and environmental variables based on eddy-covariance flux techniques and Gaussian plume measurements in concert with direct bottom-up measurements. This research will employ advanced data analytics using empirical models and artificial intelligence to improve the mechanistic understanding of methane emissions in natural gas fields across West Virginia and the greater Appalachian region. Accurate quantification with indirect measurement techniques would decrease the need for the labor-intensive leak detection schemes currently employed. The research findings will be broadly disseminated through peer-reviewed publications and conference presentations. The researchers will leverage industrial collaborations at the Marcellus Shale Energy and Environmental Laboratory (MSEEL) in Morgantown, WV, to communicate the research outcomes. The research group will also work with the West Virginia University Energy Institute to develop outreach materials and conduct seminars in the Marcellus region.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1800435","D3SC: CDS&E: Conformer Toolkit: Generating Accurate Small Molecule Conformer Ensembles","CHE","Theory, Models, Comput. Method","08/15/2018","07/27/2018","Geoffrey Hutchison","PA","University of Pittsburgh","Standard Grant","Susan Atlas","07/31/2021","$411,333.00","David Koes","geoffh@pitt.edu","University Club","Pittsburgh","PA","152132303","4126247400","MPS","6881","026Z, 062Z, 8084, 9216, 9263","$0.00","Geoffrey Hutchison and David Koes of the University of Pittsburgh are supported by the Chemical Theory, Models and Computational Methods Program in the Division of Chemistry, to develop and apply novel statistical machine learning or ""artificial intelligence"" techniques to analyze the structure and flexibility of molecules.  Most molecules are flexible, and at room temperature can exist in multiple interconverting geometries called conformers.  As molecules increase in size, complexity, and flexibility, the number of possible stable conformers increases exponentially. To accurately predict molecular properties, it is important to take into account all geometries---even those lower-probability conformers---if they have some probability of spontaneously forming at a given temperature.  Thus, a challenge is to efficiently identify these conformers despite an extremely complex, multi-dimensional geometric search spaces.  Professors Hutchison and Koes implement a unique grid-based neural network approach to predict conformers, trained on databases of high-quality calculations generated using NSF XSEDE supercomputing resources.  The machine learning techniques are validated against experimental and computational benchmarks.  They are also applied to developing improved methods for identifying drug targets, and for optimizing the design of plastic electronic materials. The databases and software developed for this project are publicly disseminated.  New tutorial resources are developed for Avogadro and 3DMol.js software tools, and new educational components on programming, visualization, and statistical machine learning areincorporated into the ""Mathematics for Chemists"" course taught by Professor Hutchison.  Both investigators give open lectures on data science and chemistry to the public and to local high school students.  They are also actively engaged in outreach to underrepresented groups through the American Chemical Society Project Seed, Pittsburgh Public Schools Science and Technology Academy, and the Drug Discovery, Systems, and Computational Biology Summer Academy for high school students.<br/><br/>The first part of this project draws upon a connection between statistical thermodynamics and Bayesian statistics. Using experimental and computational data, one can estimate distributions of dihedral angles for most molecules. From such probabilities, Bayesian optimization can be used to accurately explore and sample Boltzmann-weighted ensembles of the potential energy surface. The second aim takes advantage of recent improvements in quantum chemical methods for predicting thermochemistry for organic molecules. Using these accurate energies in tandem with experimental and other computational databases, recurrent neural-network thermochemical models are produced for molecules of different sizes and containing a wide range of elements. The resulting large data repositories and open source software tools are disseminated to the community, and used as the foundation for educational materials in a new curriculum for chemistry.  They are providing the basis for ongoing outreach and broadening participation activities to high school and undergraduate students, involving a state-of-the-art, interdisciplinary mix of data science, machine learning, and computational chemistry.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1824005","Improving and Integrating Global Diversity Estimates Using Transparent Methods","SES","POLITICAL SCIENCE","08/15/2018","07/16/2018","Avital Livny","IL","University of Illinois at Urbana-Champaign","Standard Grant","Brian D. Humes","07/31/2021","$315,583.00","Scott Althaus","alivny@illinois.edu","1901 South First Street","Champaign","IL","618207406","2173332187","SBE","1371","040Z","$0.00","Understanding the socio-political impact of ethnic, religious, and linguistic diversity is a vital concern for both social scientists and policy-makers. Using several different datasets measuring diversity around the world, researchers have found that it often has a negative impact on democracy, development and political stability. However, these findings rely on fundamentally flawed datasets: their demographic estimates come from questionable sources and do not vary within countries or over time. This makes them ill-suited to studying outcomes like war and development, which often change rapidly and cluster in space. In addition, the existing datasets cannot be directly compared, making it difficult to assess their accuracy. Rather than investing time and money in the collection of new data, this project builds on an existing resource: 9 million survey responses from 175 countries around the world. By using Artificial Intelligence (AI) methods to compare these surveys to official statistics and generate improved diversity estimates, other researchers will be able to apply this method in other areas like health and inequality where government statistics are missing or questionable. Further, this project will make our results directly comparable to existing datasets. These data and methods will be made available through a user-friendly online portal, where scientists, policy-makers, and members of the public will be able to explore the data. They will also be able to create their own datasets and use visualization tools to see how the world's demographics are changing and consider what this means for our future.<br/><br/>Existing estimates of ethnic, religious, and linguistic diversity are correlated cross-sectionally with a number of socio-political and economic outcomes including development, conflict, and social capital. Close examination of these data raises validity concerns: few are based on high-quality official statistics, the majority coming from questionable secondary sources. Further, criteria for group inclusion (i.e., ontologies) are opaque and inconsistently applied. Even where they appear accurate, data are static and aggregated at the country level, although they are often used to explain time-varying and spatially disaggregated outcomes. Ontologies in extant datasets are also incompatible, making comparison and integration difficult. This proposal improves existing measures by applying machine learning methods to compare 9 million responses across 175 countries with a new database of census results. An algorithm will identify survey design features that maximize accuracy, to define a compensatory weighting scheme across these features. The result is a set of survey-based demographic estimates with improved validity, even for countries lacking reliable census data. This method of triangulating surveys and official statistics is generalizable to research areas that use either source and can also inform improved survey design. The project will also develop tools for linking surveys, censuses, and existing datasets based on explicit and transparent decision rules to facilitate their comparison and integration. An online portal will provide access to datasets and code, supporting customized data manipulation and visualization. The methods and tools proposed here -- emphasizing accuracy, transparency, and cross-resource integration -- should serve as a model for future data collection.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1832294","Examining groundwater-flood and soil moisture-flood relationships across scales using national-scale data mining, deep learning and knowledge distillation","EAR","HYDROLOGIC SCIENCES","07/01/2018","07/26/2018","Chaopeng Shen","PA","Pennsylvania State Univ University Park","Continuing grant","Venkataraman Lakshmi","12/31/2020","$249,862.00","","cxs1024@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","GEO","1579","","$0.00","In many parts of the United States, it has been shown that groundwater levels and soil moisture, which quantifies the wetness of the soil, are connected via the mechanism of flood production. Water cannot infiltrate into the ground when groundwater is close to the surface and is thus forced to quickly run off to rivers, creating higher flooding risks. However, the relationship between groundwater and floods has been found to be highly diverse and difficult to predict. Depending on terrain, groundwater depth, and many other factors, floods lead groundwater increase in some cases while groundwater can lead floods in others. Previous research from selected experimental watersheds have not resulted in a comprehensive and transferable understanding of the controlling processes. This project will take a big-data, machine learning approach to enhance our understanding of this relationship, allowing us to heuristically exploit previously under-utilized groundwater data for flood predictions and reducing damages. Using learning patterns from national-scale groundwater and streamflow data, the machine learning algorithms will create plausible groundwater-flood relationships. Taking advantage of the big hydrologic data from available satellite missions, this project will create shared undergraduate course modules to enhance student's ability to work with big data and increase their awareness of global water issues.<br/><br/>This research advances hydrologic science by answering the following overarching question: at catchment scales, do groundwater levels in the catchment provide predictive power for flood threshold functions and baseflow? We will address this question in multiple small steps. We will identify the kinds of groundwater-rainfall-runoff (GW-P-Q) relations that can be found over the Continental United States. These relations are quantified by the correlations between water table depths and flood thresholds (and baseflow) at different lags and time scales. We will seek the factors dictate the type of GW-P-Q relations and whether these relations are stable across seasons and years. We will employ two approaches: a human-directed classification analysis, and a knowledge distillation scheme based on deep learning (DL), a rapidly advancing group of techniques supporting the recent surge in artificial intelligence. In the first approach, we will use classification and regression tree to identify factors that could explain the GW-P-Q relations. In the DL-based approach, we will train continental-scale time series DL models using all available data to forecast discharge. This approach addresses the issue with classification trees in which not enough data are available for branch nodes. Through a novel knowledge distillation procedure, we transfer the knowledge gained in the deep network to more interpretable formats, including explicit mathematical formula. Results from the study will provide a comprehensive understanding of GW-P-Q relations where regional patterns and physical controls emerge. Besides gaining new knowledge, a significant by-product is the trained DL models. They can be used as a flood forecasting tool to integrate recent soil moisture and groundwater observations, which have not been exploited until now. The educational activity will mesh with the research activity by engaging undergraduate students in handling, visualizing and interpreting big hydrologic data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1654187","CAREER: Instrumental divergence and goal-directed choice","BCS","COGNEURO","02/15/2017","08/25/2017","Mimi Liljeholm","CA","University of California-Irvine","Continuing grant","Uri Hasson","01/31/2022","$519,821.00","","m.liljeholm@uci.edu","141 Innovation Drive, Ste 250","Irvine","CA","926173213","9498247295","SBE","1699","1045, 1699","$0.00","Theories of instrumental behavior distinguish between goal-directed decisions, motivated by a deliberate consideration of the probability and current utility of their consequences, and habits, which are rigidly and automatically elicited by the stimulus environment based on reinforcement history.  In spite of the far-reaching implications of this distinction, ranging from the structuring of economic policies to the diagnosis and treatment of behavioral pathology, much is still unknown about what factors shape goal-directed decisions and what conditions prompt a transition from goal-directed to habitual action selection.  Generally, while computationally expensive, a goal-directed strategy offers greater levels of flexible instrumental control.  Since subjective utilities often change from one moment to the next, such flexibility is essential for reward maximization and thus may have intrinsic value, potentially serving to motivate and reinforce specific decisions, as well as to justify the general processing cost of goal-directed computations.  A critical requirement for flexible instrumental control, however, is that available action alternatives yield distinct outcome states.  With the support of this NSF Career award, Dr. Mimi Liljeholm is investigating the novel hypotheses that instrumental divergence? the difference between outcome probability distributions associated with alternative actions? can shape choice preferences, induce conditioned reinforcement, and arbitrate between goal-directed and habitual decision strategies.  The objective of this research is to address important gaps in current knowledge about the nature and limits of goal-directed behavior, using a combination of innovative experimental designs, computational modeling and functional magnetic resonance imaging (fMRI).  The educational component of the award provides hands-on training in neuroimaging methods, and in the computational and neural bases of learning and decision-making, at undergraduate and graduate levels.  <br/><br/>All studies use a simple gambling task in which alternative actions yield different colored tokens, each worth a particular amount of money, with various probabilities.  In studies assessing a preference for flexible instrumental control, the relevant choice is between pairs of actions with different levels of instrumental divergence.  Expected monetary pay-offs vary independently of instrumental divergence across options, dissociating the relative contribution of each factor to behavioral choice performance.  Studies investigating the capacity of high instrumental divergence to induce conditioned reinforcement measure changes in the affective valence of visual stimuli based on their association with high versus low instrumental divergence.  Finally, following extended exposure to high versus low instrumental divergence, the degree to which behavior is goal-directed or habitual is assessed using a standardly employed outcome devaluation procedure, in which the monetary amount associated with a particular token color is altered: Goal-directed, but not habitual, decisions are modulated by such changes in the utility of sensory-specific outcomes states.  Neuroimaging data is acquired by scanning participants with fMRI as they perform the task, and a reinforcement learning framework is used to model the intrinsic value of flexible instrumental control (by treating instrumental divergence as a surrogate reward) at behavioral and neural levels. Since many psychiatric disorders are characterized by an abnormal sense of agency, and addiction associated with a rapid transition from goal-directed to habitual action-selection, broader impacts of this project include the potential development of pre-clinical diagnostic assays for early detection of cognitive, affective and behavioral pathology.  The concepts advanced under this project may also help improve the performance of reinforcement learning algorithms, for example by using instrumental divergence to specify new optimization criteria, potentially benefiting medical, industrial and commercial applications of artificial intelligence."
"1730146","CompCog:  Collaborative Research:  Learning Visuospatial Reasoning Skills from Experiences","BCS","Science of Learning","08/15/2017","08/16/2017","Linda Smith","IN","Indiana University","Standard Grant","Soo-Siang Lim","07/31/2019","$99,691.00","","smith4@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","SBE","004Y","059Z","$0.00","This project uses methods from artificial intelligence (AI) to better understand how people learn visuospatial reasoning skills like mental rotation, which are a critical ingredient in the development of strong math and science abilities.  In particular, this project proposes a new approach to quantify the learning value contained in different visual experiences, using wearable cameras combined with a new AI system that learns visuospatial reasoning skills from video examples.  Results from this project will not only advance the state of the art in AI but also will enable researchers to measure how valuable different real-world visual experiences are in helping people to learn visuospatial reasoning skills.  For example, certain types of object play activities might be particularly valuable for helping a child to learn certain visuospatial reasoning skills.  Ultimately, this new measurement approach could be used to identify early signs of visuospatial reasoning difficulties in children and could also help in the design of new visuospatial training interventions to boost children?s early math and science development.<br/><br/>The core scientific question that this project aims to answer is: How are visuospatial reasoning skills learned from first-person visual experiences?  This question will be answered through computational experiments with a new AI system---the Mental Imagery Engine (MIME)---that learns visuospatial reasoning skills, like mental rotation, from video examples.  Training data will include first-person, wearable-camera videos from two different settings that are both important for human learning:  unstructured object manipulation by infants and visuospatial training interventions designed for children.  Results from experiments with the MIME AI system will advance the state of the art in both AI and the science of human learning by helping to explain how visuospatial reasoning skills can be learned from visual experiences, and, in particular, how having different kinds of visual experiences can affect the quality of a person?s learning outcomes in different ways."
"1658380","Collaborative research: Combining models and observations to constrain the marine iron cycle","OCE","CHEMICAL OCEANOGRAPHY","07/01/2017","03/03/2017","Jefferson Moore","CA","University of California-Irvine","Standard Grant","Simone Metz","06/30/2020","$470,704.00","Francois Primeau","jkmoore@uci.edu","141 Innovation Drive, Ste 250","Irvine","CA","926173213","9498247295","GEO","1670","","$0.00","Tiny marine organisms called phytoplankton play a critical role in Earth's climate, by absorbing carbon dioxide from the atmosphere. In order to grow, these phytoplankton require nutrients that are dissolved in seawater. One of the rarest and most important of these nutrients is iron. Even though it is a critical life-sustaining nutrient, oceanographers still do not know much about how iron gets into the ocean, or how it is removed from seawater. In the past few years, scientists have made many thousands of measurements of the amount of dissolved iron in seawater, in environments ranging from the deep sea, to the Arctic, to the tropical oceans. They found that the amount of iron in seawater varies dramatically from place to place. Can this data tell us about how iron gets into the ocean, and how it is ultimately removed? Yes. In this project, scientists working on making measurements of iron in seawater will come together with scientists who are working on computer models of iron inputs and removal in the ocean. The goal is to work together to create a program that allows our computer models to ""learn"" from the data, much like an Artificial Intelligence program. This program will develop a ""best estimate"" of where and how much iron is coming into the ocean, how long it stays in the ocean, and ultimately how it gets removed. This will lead to a better understanding of how climate change will impact the delivery of iron to the ocean, and how phytoplankton will respond to climate change. With better climate models, society can make more informed decisions about how to respond to climate change. The study will also benefit a future generation of scientists, by training graduate students in a unique collaboration between scientists making seawater measurements, and those using computer models to interpret those measurements. Finally, the project aims to increase the participation of minority and low-income students in STEM (Science, Technology, Engineering, and Mathematics) research, through targeted outreach programs.<br/><br/><br/><br/>Iron (Fe) is an important micronutrient for marine phytoplankton that limits primary productivity over much of the ocean; however, the major fluxes in the marine Fe cycle remain poorly quantified. Ocean models that attempt to synthesize our understanding of Fe biogeochemistry predict widely different Fe inputs to the ocean, and are often unable to capture first-order features of the Fe distribution. The proposed work aims to resolve these problems using data assimilation (inverse) methods to ""teach"" the widely used Biogeochemical Elemental Cycling (BEC) model how to better represent Fe sources, sinks, and cycling processes. This will be achieved by implementing BEC in the efficient Ocean Circulation Inverse Model and expanding it to simulate the cycling of additional tracers that constrain unique aspects of the Fe cycle, including aluminum, thorium, helium and Fe isotopes. In this framework, the inverse model can rapidly explore alternative representations of Fe-cycling processes, guided by new high-quality observations made possible in large part by the GEOTRACES program. The work will be the most concerted effort to date to synthesize these rich datasets into a realistic and mechanistic model of the marine Fe cycle. In addition, it will lead to a stronger consensus on the magnitude of fluxes in the marine Fe budget, and their relative importance in controlling Fe limitation of marine ecosystems, which are areas of active debate. It will guide future observational efforts, by identifying factors that are still poorly constrained, or regions of the ocean where new data will dramatically reduce remaining uncertainties and allow new robust predictions of Fe cycling under future climate change scenarios to be made, ultimately improving climate change predictions. A broader impact of this work on the scientific community will be the development of a fast, portable, and flexible global model of trace element cycling, designed to allow non-modelers to test hypotheses and visualize the effects of different processes on trace metal distributions. The research will also support the training of graduate students, and outreach to low-income and minority students in local school districts."
"1827523","PFI-TT: Acoustic Continuous Condition Monitoring of Manufacturing Machinery","IIP","PARTNRSHIPS FOR INNOVATION-PFI","09/01/2018","07/23/2018","Juan Bello","NY","New York University","Standard Grant","Jesus Soriano Molla","02/29/2020","$200,000.00","","jpbello@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","ENG","1662","1662, 8029","$0.00","The broader impact/commercial potential of this PFI project is in providing the manufacturing sector with advanced solutions for the early detection of machine malfunctions via continuous acoustic monitoring. Machinery malfunctions have significant negative effects on the manufacturing industry, including: unscheduled downtime leading to the under-utilization of equipment and staff; the production of off-spec products leading to waste of finished product and raw materials; as well as costly-repairs and inefficient maintenance schedules. All these effects increase the cost of manufacturing and can result in loss of revenue, directly affecting the margin of profitability, and thus the competitiveness, for these companies. By improving machine condition monitoring and enabling the widespread adoption of predictive maintenance, we believe our solutions can contribute to the growth of the US manufacturing sector, with all the significant ancillary benefits that entails. Better prediction of machine failures could also potentially affect energy efficiency, environmental impact and workplace safety in manufacturing operations. <br/><br/><br/>The proposed project will develop an integrated, Industrial Internet-of-Things (IIoT) solution to continuous condition monitoring of manufacturing machinery. Our solution is centered around a network of low-cost, high quality, remote acoustic sensing devices with embedded artificial intelligence (AI) for sound recognition, that can automatically detect and diagnose the early signs of machine failure. Our novel focus on acoustic emissions, both in the audible and ultrasonic range, means that our sensors are non-contact and thus easy to install, capable of monitoring multiple parts per sensor, and able to produce earlier warnings than those possible with existing solutions. Furthermore, our use of AI for sound recognition results in fast and scalable analytics in real-time with minimal expertise required. We provide a unified cyber-infrastructure integrating edge computing, cloud data storage and an easy-to-use dashboard to facilitate navigation, retrieval and operation. This combination has the potential to result in a disruptive and transformative product that improves machine condition monitoring while significantly lowering the cost of deployment and operation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1520031","IBSS: The Spread and Impact of Moral Messages: Machine Learning, Network Evolution, and Behavioral Prediction","SMA","Interdiscp Behav&SocSci IBSS","08/15/2015","08/15/2017","Jesse Graham","CA","University of Southern California","Standard Grant","Thomas J. Baerwald","01/31/2019","$640,267.00","Jesse Graham, Morteza Dehghani, Stephen Vaisey","jesse.graham@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","SBE","8213","8213, 8605","$0.00","In the immediate aftermath of the 2013 Boston Marathon tragedy, hundreds of thousands of prosocial acts were evident on social media, such as reposted links for blood donation sites, information regarding how to get in touch with loved ones, and even offers to provide food and shelter for those in need. Far from isolated acts, these behaviors occurred within social networks, amid shared moral messages of empathy and solidarity.  This interdisciplinary research project will examine how people respond to public crises and how moral reactions shape these responses in social networks.  The project will contribute new theoretical insights and methodological advances in moral psychology, network sociology, computer science, and other fields.  It will enhance understanding of how moral concerns spread through social networks and explore new theoretical frameworks dealing with human moral decision making and group dynamics.  These theoretical frameworks will guide the development of artificial intelligence techniques for building descriptive models of morality, and the new methods of sentiment analysis and machine learning will be used to assess theoretical models of moral concerns and social influence in networks.  By examining factors influencing the spread of moral messages and participation in prosocial activities, such as charitable giving, the project may help increase the well-being of individuals in emergency situations.  The project also will facilitate future inquiry into how the public and persistent nature of social media may provide new ways to understand and forecast social change.<br/><br/>The interdisciplinary science of morality has developed well-validated measures of moral concerns using a number of different approaches, such as Moral Foundations Theory and Schwartz's Values Circumplex.  Empirical research in this field usually has assessed moral judgments via questionnaires gathering information well after actions have occurred, however.  Sociology has done more to assess behavior as it occurs but has used even more limited measures.  Recent innovations in computer science offer new ways to gather information about the structure of moral judgments and large-scale behavior in natural settings as well as the relationships between the two.  The investigators will employ these new computer-based methods to examine texts from social media in order to examine the structure of moral concerns and values without relying on preset questionnaires.  They will investigate the network dynamics of the spread of moral messages and behaviors, and they will determine how moral content in social media can predict real-world behavior at both individual and societal scales. The investigators will couple machine learning and sentiment analysis techniques with theories about moral cognition and social dynamics.  Among questions they will pursue are how well everyday moral judgments (made without researcher prompting) correspond with dominant psychological theories of morality and whether it is possible to model and predict how moral influence can lead to subsequent prosocial or antisocial behavior.  This project is supported through the NSF Interdisciplinary Behavioral and Social Sciences Research (IBSS) competition."
"1801426","SaTC: CORE: Medium: Collaborative: Towards Trustworthy Deep Neural Network Based AI: A Systems Approach","CNS","Secure &Trustworthy Cyberspace","08/01/2018","07/20/2018","Suman Jana","NY","Columbia University","Standard Grant","Sandip Kundu","07/31/2021","$300,000.00","","suman@cs.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","CSE","8060","025Z, 7434, 7924","$0.00","Artificial intelligence (AI) is poised to revolutionize the world in fields ranging from technology to medicine, physics and the social sciences. Yet as AI is deployed in these domains, recent work has shown that systems may be vulnerable to different types of attacks that cause them to misbehave; for instance, attacks that cause an AI system to recognize a stop sign as a speed-limit sign. The project seeks to develop methodologies for testing, verifying and debugging AI systems, with a specific focus on deep neural network (DNN)-based AI systems, to ensure their safety and security. <br/><br/>The intellectual merits of the proposed research are encompassed in four new software tools that will be developed: (1) DeepXplore, a tool for automated and systematic testing of DNNs that discovers erroneous behavior that might be either inadvertently or maliciously introduced; (2) BadNets, a framework that automatically generated DNNs with known and stealthy misbehaviours in order to stress-test DeepXplore; (3) SafetyNets; a low-overhead scheme for safe and verifiable execution of DNNs in the cloud; and (4) VisualBackProp; a visual debugging tool for DNNs. The synergistic use of these tools for secure deployment of an AI system for autonomous driving will be demonstrated.<br/><br/>The project outcomes will significantly improve the security and safety of AI systems and increase their deployment in safety- and security-critical settings, resulting in broad societal impact. The results of the project will be widely disseminated via publications, talks, open access code, and competitions hosted on sites such as Kaggle and NYU's annual Cyber-Security Awareness Week (CSAW). Furthermore, students from under-represented minority groups in science, technology, engineering and mathematics (STEM) will be actively recruited and mentored to be leaders in this critical area.  <br/><br/>The code for this project will be made publicly available via github.com. Preliminary code for the tools that will be developed is already hosted on this website, including DeepXplore (https://github.com/peikexin9/deepxplore) and BadNets (https://github.com/Kooscii/BadNets/). These repositories will be linked to from a homepage that describes the entire project. The project homepage will be hosted on wp.nyu.edu/mlsecproject.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1723344","AitF: Collaborative Research: Algorithms for Probabilistic Inference in the Real World","CCF","Algorithms in the Field","01/01/2017","12/28/2016","David Sontag","MA","Massachusetts Institute of Technology","Standard Grant","Tracy J. Kimbrel","08/31/2020","$399,999.00","","dsontag@mit.edu","77 MASSACHUSETTS AVE","Cambridge","MA","021394301","6172531000","CSE","7239","","$0.00","Statistical models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data.  The process of using a model to answer specific questions, such as inferring the state of several random variables given evidence observed about others, is called probabilistic inference.  Probabilistic graphical models, a type of statistical model, are often used in diverse applications such as medical diagnosis, understanding protein and gene regulatory networks, computer vision, and language understanding.  On account of the central role played by probabilistic graphical models in a wide range of automated reasoning applications, designing efficient algorithms for probabilistic inference is a fundamental problem in artificial intelligence and machine learning.<br/> <br/>Probabilistic inference in many of these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve.  However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently.  This project focuses on bridging the gap between theory and practice for probabilistic inference problems in large-scale machine learning systems.  The PIs will identify structural properties and methods of analysis that differentiate real-world instances from worst-case instances used to show NP-hardness, and will design efficient algorithms with provable guarantees that would apply to most real-world instances.  The project will also study why heuristics like linear programming and other convex relaxations are so successful on real-world instances.  The efficient algorithms for probabilistic inference developed as part of this project have the potential to be transformative in machine learning, statistics, and more applied areas like computer vision, social networks and computational biology.  To help disseminate the research and foster new collaborations, a series of workshops will be organized bringing together the theoretical computer science and machine learning communities.  Additionally, undergraduate curricula will be developed that use machine learning to introduce students to concepts in theoretical computer science."
"1801495","SaTC: CORE: Medium: Collaborative: Towards Trustworthy Deep Neural Network Based AI: A Systems Approach","CNS","Secure &Trustworthy Cyberspace","08/01/2018","07/20/2018","Siddharth Garg","NY","New York University","Standard Grant","Sandip Kundu","07/31/2021","$899,990.00","Brendan Dolan-Gavitt, Anna Choromanska","sg175@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","8060","025Z, 7434, 7924","$0.00","Artificial intelligence (AI) is poised to revolutionize the world in fields ranging from technology to medicine, physics and the social sciences. Yet as AI is deployed in these domains, recent work has shown that systems may be vulnerable to different types of attacks that cause them to misbehave; for instance, attacks that cause an AI system to recognize a stop sign as a speed-limit sign. The project seeks to develop methodologies for testing, verifying and debugging AI systems, with a specific focus on deep neural network (DNN)-based AI systems, to ensure their safety and security. <br/><br/>The intellectual merits of the proposed research are encompassed in four new software tools that will be developed: (1) DeepXplore, a tool for automated and systematic testing of DNNs that discovers erroneous behavior that might be either inadvertently or maliciously introduced; (2) BadNets, a framework that automatically generated DNNs with known and stealthy misbehaviours in order to stress-test DeepXplore; (3) SafetyNets; a low-overhead scheme for safe and verifiable execution of DNNs in the cloud; and (4) VisualBackProp; a visual debugging tool for DNNs. The synergistic use of these tools for secure deployment of an AI system for autonomous driving will be demonstrated.<br/><br/>The project outcomes will significantly improve the security and safety of AI systems and increase their deployment in safety- and security-critical settings, resulting in broad societal impact. The results of the project will be widely disseminated via publications, talks, open access code, and competitions hosted on sites such as Kaggle and NYU's annual Cyber-Security Awareness Week (CSAW). Furthermore, students from under-represented minority groups in science, technology, engineering and mathematics (STEM) will be actively recruited and mentored to be leaders in this critical area.  <br/><br/>The code for this project will be made publicly available via github.com. Preliminary code for the tools that will be developed is already hosted on this website, including DeepXplore (https://github.com/peikexin9/deepxplore) and BadNets (https://github.com/Kooscii/BadNets/). These repositories will be linked to from a homepage that describes the entire project. The project homepage will be hosted on wp.nyu.edu/mlsecproject.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1811317","Nonparametric Statistical Image Analysis: Theory and Applications","DMS","STATISTICS","05/01/2018","05/11/2018","Rabindra Bhattacharya","AZ","University of Arizona","Continuing grant","Nandini Kannan","04/30/2021","$72,306.00","","rabi@math.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","MPS","1269","8091","$0.00","Non-Euclidean data are ubiquitous. They arise in many forms such  as digital images for (1) medical diagnostics (MRI, CT scans, DTI of the brain), (2) scene recognition from satellite images, (3) identifying defects in manufactured products, (4) artificial intelligence (robotic identification of objects), etc. Proper geometric descriptions of these require tools from modern differential geometry. Classical statistical methods are inadequate for their analysis; parametric models, which assume the form of the distribution of the underlying data modulo a finite number of unknown parameters, are often misspecified. A model-independent methodology developed by the PI and others has been shown to be very effective in analyzing such data. The present project aims at vastly broadening the scope of this methodology for applications. <br/><br/>A basic component of the methodology proposed is the notion of the Fre'chet mean of a probability Q on a metric space, which minimizes the expected squared distance from a point. The metric space is generally a differential manifold, often provided with a natural Riemannian metric. But it may also be a so called geodesic space of non-positive curvature, including many graphical spaces as well as stratified spaces made up of manifolds of different dimensions glued together. For the methodology to work one must establish (a) the uniqueness of the Fre'chet minimizer and (b) the asymptotic distribution of the sample Fre'chet mean. It is one of the goals of the present project to significantly extend the earlier theory in this regard, opening the way to many new applications. Another important objective is to extend to such spaces the nonparametric Bayes theory of density estimation, classification and regression. One special aim here is to explore an intriguing phenomenon:  in simulation studies with moderate sample sizes, the nonparametric Bayes estimator of the density of Q far outperforms not only the kernel density estimator, but also the MLE when the data are simulated from a parametric model! An understanding of this is expected to lead to a wider and more effective use of the nonparametric Bayes methodology. Finally, the PI proposes to develop a graphical method for robotic vision of objects, with much less computational complexity than that of other methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1516684","Increasing Learning and Efficacy about Emerging Technologies through Transmedia Engagement by the Public in Science-in-Society Activities","DRL","AISL","08/01/2015","07/19/2018","Edward Finn","AZ","Arizona State University","Continuing grant","Alphonse T. DeSena","07/31/2019","$2,999,999.00","Steve Gano, Ruth Wylie, Rae Ostman, David Guston","edfinn@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","EHR","7259","8244","$0.00","The range of contemporary ""emerging"" technologies with far-reaching implications for society (economic, social, ethical, etc.) is vast, encompassing such areas as bioengineering, robotics and artificial intelligence, genetics, neuro and cognitive sciences, and synthetic biology. The pace of development of these technologies is in full gear, where the need for public understanding, engagement and active participation in decision-making is great. The primary goal of this four-year project is to create, distribute and study a set of three integrated activities that involve current and enduring science-in-society themes, building on these themes as first presented in Mary Shelley's novel, Frankenstein, which will be celebrating in 2018 the 200th anniversary of its publication in 1818. The three public deliverables are: 1) an online digital museum with active co-creation and curation of its content by the public; 2) activities kits for table-top programming; and 3) a set of Making activities.  The project will also produce professional development deliverables: workshops and associated materials to increase practitioners' capacity to engage multiple and diverse publics in science-in-society issues.  The initiative is funded by the Advancing Informal STEM Learning (AISL) program, which seeks to advance new approaches to, and evidence-based understanding of, the design and development of STEM learning in informal environments. This includes providing multiple pathways for broadening access to and engagement in STEM learning experiences, advancing innovative research on and assessment of STEM learning in informal environments, and developing understandings of deeper learning by participants.<br/><br/>This project by Arizona State University and their museum and library collaborators around the country will examine the hypothesis that exposing publics to opportunities for interactive, creative, and extensive engagement within an integrated transmedia environment will foster their interest in science, technology, engineering and mathematics (STEM), develop their 21st century skills with digital tools, and increase their understanding, ability, and feelings of efficacy around issues in science-in-society.  These three distinct yet interlocking modes of interaction provide opportunities for qualitative and quantitative, mixed-methods research on the potential of transmedia environments to increase the ability of publics to work individually and collectively to become interested in and involved with science-in-society issues."
"1541029","EarthCube IA: Collaborative Proposal: LinkedEarth: Crowdsourcing Data Curation & Standards Development in Paleoclimatology","ICER","EarthCube","09/01/2015","07/28/2015","Julien Emile-Geay","CA","University of Southern California","Standard Grant","Eva E. Zanzerkia","08/31/2019","$684,779.00","Yolanda Gil","julieneg@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","8074","7433","$0.00","Natural climate variability signficantly modulates anthropogenic global warming, and only paleoclimate observations can adequately constrain it. Moreover, such observations are most powerful when many records are brought together to provide a spatial understanding of past variability. However, there is currently no universal way to share paleoclimate data between users or machines, hindering integration and synthesis. Large-scale, international, paleoclimate data syntheses have a long and successful history, but have been needlessly labor-intensive. Recognizing that (1) paleoclimate data curation requires expert knowledge; (2) top-down data management approaches are ineffectual; (3) existing infrastructure does not foster standardization; there emerges a critical need for a flexible platform enabling crowdsourced data curation and standards development.The platform will be combined with editorial and community-driven processes which will result in a system that has the potential to engage a broad user base in geoscientific data curation. The proposed framework will lower barriers to participation in the geosciences, enabling more ""dark data"" to join the public domain using community-sanctioned protocols. The pilot project will facilitate the work of hundreds of paleoclimate scientists, accelerating scientific discovery and the dissemination of its results to society.<br/><br/>Semantic wikis provide a simple, intuitive interface to semantic languages and infrastructure that build on open Web architecture. Like traditional wikis, they enable the collaborative authoring of content. Secure access and time-stamped content also enable the tracking of changes and the accountability of users, as well as moderation capabilities by community members of recognized expertise. In contrast to traditional wikis, semantic wikis allow contributors to assign meaning to their content, specifying relationships between the objects they describe. This enables artificial intelligence reasoners to parse, process and translate these data into more useful forms. The technology is well-proven, scalable, and completely transparent to the user, requiring no computer science knowledge or more sophisticated technology than a web browser. The LinkedEarth Wiki will automatically translate this information into Linked Open Data, a universal format to share data across the Web. To demonstrate this concept?s broad applicability across paleoclimate science, the project?s target community is the PAGES2k consortium, an international collaboration dedicated to the climate of the Common Era. Social technologies will be developed to power collective curation, standards development and quality control by the community itself. The project will demonstrate applicability to other paleogeosciences, serving as a potential template for other geoscientific disciplines."
"1747785","Phase II IUCRC UNC Charlotte Site: Center for Visual and Decision Informatics (CVDI)","CNS","INDUSTRY/UNIV COOP RES CENTERS","03/01/2018","02/06/2018","Mirsad Hadzikadic","NC","University of North Carolina at Charlotte","Continuing grant","Ann Von Lehmen","02/28/2022","$102,163.00","Wenwen Dou, Zbigniew Ras, Mohamed Shehab, Jean-Claude Thill","mirsad@uncc.edu","9201 University City Boulevard","CHARLOTTE","NC","282230001","7046871888","CSE","5761","5761","$0.00","The Center for Visual and Decision Informatics (CVDI) focuses on developing advanced visual and decision support tools and techniques that enable decision makers to improve the way organizations' information is interpreted and exploited. This award will create a CVDI Site at the University of North Carolina, Charlotte, which will focus on data science and big data analytics research related to risk mitigation in financial services, healthcare, and social good. Financial services and healthcare, along with energy, retail, and logistics are the key sectors of Charlotte's economy. On the other hand, social good is an important issue currently facing Charlotte community. Social good analytics can aid the community's effort to improve living conditions of its citizens, which will positively influence the overall workforce readiness for employers. This contribution will be measured in novel data collection mechanisms and long-term outcomes of implemented policies. The net effect will be more resilient industry, increased economic development, increased social capital, and increased economic mobility in all segments of the community.<br/><br/>The researcher team on this award is uniquely focused on developing long-term capability for researching, understanding, and documenting risk, as well as creating tools and applications for explaining and predicting such risks. This will be accomplished through the application of data- and analytics-driven technologies, including, but not limited to, data and analytics platform, advanced visualization techniques, artificial intelligence and deep-learning algorithms, agent-based modeling and simulation, network science analysis, and systems dynamics methods. Over the next 5 years, this Site will seek to transform UNC Charlotte into the national hub of innovation and creativity for the benefit of industry and the society.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1658436","Collaborative research: Combining models and observations to constrain the marine iron cycle","OCE","CHEMICAL OCEANOGRAPHY","07/01/2017","03/03/2017","Seth John","CA","University of Southern California","Standard Grant","Simone Metz","06/30/2020","$197,957.00","","sethjohn@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","1670","","$0.00","Tiny marine organisms called phytoplankton play a critical role in Earth's climate, by absorbing carbon dioxide from the atmosphere. In order to grow, these phytoplankton require nutrients that are dissolved in seawater. One of the rarest and most important of these nutrients is iron. Even though it is a critical life-sustaining nutrient, oceanographers still do not know much about how iron gets into the ocean, or how it is removed from seawater. In the past few years, scientists have made many thousands of measurements of the amount of dissolved iron in seawater, in environments ranging from the deep sea, to the Arctic, to the tropical oceans. They found that the amount of iron in seawater varies dramatically from place to place. Can this data tell us about how iron gets into the ocean, and how it is ultimately removed? Yes. In this project, scientists working on making measurements of iron in seawater will come together with scientists who are working on computer models of iron inputs and removal in the ocean. The goal is to work together to create a program that allows our computer models to ""learn"" from the data, much like an Artificial Intelligence program. This program will develop a ""best estimate"" of where and how much iron is coming into the ocean, how long it stays in the ocean, and ultimately how it gets removed. This will lead to a better understanding of how climate change will impact the delivery of iron to the ocean, and how phytoplankton will respond to climate change. With better climate models, society can make more informed decisions about how to respond to climate change. The study will also benefit a future generation of scientists, by training graduate students in a unique collaboration between scientists making seawater measurements, and those using computer models to interpret those measurements. Finally, the project aims to increase the participation of minority and low-income students in STEM (Science, Technology, Engineering, and Mathematics) research, through targeted outreach programs.<br/><br/><br/><br/>Iron (Fe) is an important micronutrient for marine phytoplankton that limits primary productivity over much of the ocean; however, the major fluxes in the marine Fe cycle remain poorly quantified. Ocean models that attempt to synthesize our understanding of Fe biogeochemistry predict widely different Fe inputs to the ocean, and are often unable to capture first-order features of the Fe distribution. The proposed work aims to resolve these problems using data assimilation (inverse) methods to ""teach"" the widely used Biogeochemical Elemental Cycling (BEC) model how to better represent Fe sources, sinks, and cycling processes. This will be achieved by implementing BEC in the efficient Ocean Circulation Inverse Model and expanding it to simulate the cycling of additional tracers that constrain unique aspects of the Fe cycle, including aluminum, thorium, helium and Fe isotopes. In this framework, the inverse model can rapidly explore alternative representations of Fe-cycling processes, guided by new high-quality observations made possible in large part by the GEOTRACES program. The work will be the most concerted effort to date to synthesize these rich datasets into a realistic and mechanistic model of the marine Fe cycle. In addition, it will lead to a stronger consensus on the magnitude of fluxes in the marine Fe budget, and their relative importance in controlling Fe limitation of marine ecosystems, which are areas of active debate. It will guide future observational efforts, by identifying factors that are still poorly constrained, or regions of the ocean where new data will dramatically reduce remaining uncertainties and allow new robust predictions of Fe cycling under future climate change scenarios to be made, ultimately improving climate change predictions. A broader impact of this work on the scientific community will be the development of a fast, portable, and flexible global model of trace element cycling, designed to allow non-modelers to test hypotheses and visualize the effects of different processes on trace metal distributions. The research will also support the training of graduate students, and outreach to low-income and minority students in local school districts."
"1819850","SBIR Phase I:  Developing a Single-Visit System to Screen, Diagnose, and Treat Cervical Neoplasia","IIP","SMALL BUSINESS PHASE I","07/15/2018","07/16/2018","Joseph Carson","CA","Pensievision, Inc.","Standard Grant","Henry Ahn","03/31/2019","$224,289.00","","joe@pensievision.com","5820 Oberlin Drive, #104","San Diego","CA","921213717","8582554529","ENG","5371","5371, 8038","$0.00","This SBIR Phase I project will develop an innovative 3D medical imaging technology for early-stage detection and analysis of cancers, initially focusing on detecting pre-cancer cervical lesions. This project will advance from creatively assembling existing active optics hardware to inventing a new microfiber-based active optics system to circumvent limits of space confinement and 3D resolution. The project's fundamental strategy for identifying pre-cancers of the cervix, which relies on a macroscopic 3D digital analysis combined with microscopic cell evaluation, is naturally amenable to artificial intelligence technologies. The versatility of this imaging platform enables the resolving of medical diagnostic challenges in wealthy settings and the resolving of cost-saving barriers in resource-limited settings. The imaging technology can be extended beyond medical practice to other scientific and industrial disciplines. Potentially, this project has an immediate impact on saving lives and costs via the early detection of fatal diseases. Additionally, the data and knowledge acquired developing and implementing this imaging system provide opportunities to meaningfully develop new computational strategies for educational, engineering and industrial interests. The innovative, commercially viable, platform technology offers opportunities for significant, tax-revenue-generating global profits, for future technology application spin-offs, and for producing high technology jobs for U.S. citizens.<br/><br/>The project innovation will voyage from state-of-the-art 3D software development to the creation of a new type of fiber bundle imager with an electronically controlled actively focusing lens. Combined, these tasks achieve the creation of a miniaturized 3D imaging system capable of navigating confined spaces within the body, such as inside the cervix opening. For all prototypes developed for this project, final 3D renderings are enabled by proprietary 3D rendering software, capable of quantifying tissue color, volume and shape at the macroscopic level, while also evaluating cell size and approximate shape at the microscopic level. In wealthy settings, this system would be desirable for implementing a single-phase cervical cancer screening strategy to replace the current two-phase approach, which requires Pap smear and/or human papilloma virus assay, followed by the more expensive colposcopy in the case of an abnormal result. In resource-limited regions and/or regions with difficult-to-reach populations, where it is challenging to get patients to return for a follow-up visit, the technology would offer a low-cost, pre-screening method that only requires a single visit. This 3D imaging system could be combined in the future with a therapeutic agent administered at the time of diagnosis, thus offering a single-visit, screen-diagnose-and-treat method.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815949","SHF: Small: Lazy Data Structures for Data-Intensive Applications","CCF","SOFTWARE & HARDWARE FOUNDATION","10/01/2018","07/16/2018","Yu David Liu","NY","SUNY at Binghamton","Standard Grant","Anindya Banerjee","09/30/2021","$449,827.00","","davidl@cs.binghamton.edu","4400 VESTAL PKWY E","BINGHAMTON","NY","139026000","6077776136","CSE","7798","7923, 7943","$0.00","Developing and optimizing data-intensive applications is a crucial but challenging goal in the Big Data era. This project aims to research and design a novel programming system to improve the performance and assurance of data-intensive applications. The project's novelties are (i) laying a new foundation for programming, optimizing, and reasoning about Big Data systems, and (ii) building a practical software ecosystem to improve the quality of data-intensive applications. The project's impacts are (i) shedding fundamental insight in data-intensive programs, with a broad range of applications from social network analysis to artificial intelligence; (ii) enabling new curriculum development, and bringing underrepresented students to the exciting frontier of data-intensive computing. <br/><br/>The project centers around the idea of data-centric laziness: the operations to be performed over data structures --- such as topological changes or payload queries --- may be delayed and flexibly memoized within the data structure itself in a decentralized manner. The project is carried out in several directions. First, it conducts a foundational study on laziness in the presence of data processing, including a rigorous study on the subtleties in designing a lazy propagation system, a proof of observable equivalence between lazy and eager data processing, a cost-based semantics for capturing lazy behaviors, and a unification of eagerness vs. laziness and data vs. computation. Second, it investigates how parallelism and laziness interact to improve the performance of lazy data structures, through the support of asynchronous data processing, in-data propagation parallelism, and concurrent garbage collection of propagation labels. Third, it bridges the language foundation with practical algorithm design and system building, exploring algorithm-oriented programming abstractions, partition-based out-of-core data processing, just-in-time data structure re-organization, and propagation-aware performance monitoring.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1744294","I-Corps: Data Analytics and Automated Candidate Assessment","IIP","I-Corps","07/01/2017","07/12/2017","Saman Aliari Zonouz","NJ","Rutgers University New Brunswick","Standard Grant","Cindy WalkerPeach","12/31/2018","$50,000.00","","saman.zonouz@rutgers.edu","33 Knightsbridge Road","Piscataway","NJ","088543925","8489320150","ENG","8023","","$0.00","The broader impact and commercial potential of this I-Corps project will improve the transition quality and efficiency of university students to companies. This platform will potentially provide several customer segments such as students, companies and universities with solutions that remove many barriers that currently make job hunting and hiring a time-consuming, costly, stressful, and often biased endeavor. The impact of the product goes beyond a specific academic major, and has the potential to cover all scientific subject matters for which there is a robust job market. Most importantly, the solution will remove the current potential biases against underrepresented minorities by automating the skill assessment process and minimizing the human involvement in the process.<br/><br/>This I-Corps project will develop effective, unbiased, and automated platforms and algorithms for skill assessment. The target customers will be the companies, and university graduates that would like to enter the job market with no prior experience. This research will propose novel techniques and working tools using artificial intelligence and machine learning methods to provide interaction during the interview process between the assessment engine and the interviewee. The project further develops novel formal methods and programming language analysis techniques to analyze the answers submitted by the candidate during the interview and adaptively select the next sequence of questions for each specific candidate. A realistic test-bed infrastructures on which the candidates will be asked to perform experiments is used to assess the expertise level of the candidates.  These novel techniques for automated interviews will reduce the cost and time for both companies and students."
"1734082","D3SC and EAGER: Using Deep Learning to Find Algorithms for Optimizing Chemical Reactions","CHE","Chem Struct,Dynmcs&Mechansms B","09/01/2017","06/09/2017","Richard Zare","CA","Stanford University","Standard Grant","Tingyu Li","08/31/2019","$209,734.00","","zare@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","MPS","9102","7433, 7916, 8084","$0.00","With support from the Chemical Structure, Dynamics and Mechanisms - B Program in the Division of Chemistry and in response to the Data-Driven Discovery Science in Chemistry (D3SC) Dear Colleague Letter, Professor Richard N. Zare at Stanford University is working on optimizing chemical reactions in microdroplets with deep reinforcement learning.  Unoptimized reactions are expensive because they waste time and reagents.  A common way for chemists to explore reaction optimization is to change one variable at a time while all other variables remain fixed. This method, however, might not find the best conditions, that is the global optimum.  Another way is to search across all combinations of reaction conditions by using batch chemistry. This approach gives a better chance to find the global optimal condition, but it is time-consuming and expensive. Deep reinforcement learning is believed to be a superior approach in which the computer analyzes a large data set and recognizes the pattern of features that lead to best reaction outcomes.  It is like training a dog: suppose we want the dog to pick up a ball.  If the dog does what we want, we say ""Good dog!""; if it does not, we say ""Bad dog!"". Similarly, Professor Zare uses a machine learning method to give the system a positive reward if the reaction reaches a better result than previous ones, or a negative reward if it does not.  A repeated process will eventually result in a set of best reaction conditions for certain reactions.  Professor Zare and his group apply this approach to microdroplet chemistry, where many reactions can be carried out in small droplets and be accelerated by factors of one thousand to one million compared with the same reaction happening in bulk solution. Combining the efficient deep reinforcement learning method with accelerated microdroplet reactions, Professor Zare and his group are seeking to find optimal reaction conditions in a fast way.  This combined approach can represent a significant step for enabling artificial intelligence to be used to optimize chemical reactions, which should have benefits in chemical production, drug screening, and materials discovery.  The students in the Zare group enjoy the unique opportunity to experience micro-droplet chemical synthesis, fast chemical characterization, and deep learning-based complex data analysis.<br/><br/>A reaction can be thought of as a system having multiple inputs (parameters) and providing one or more outputs. Example inputs include: temperature; solvent composition; pH; catalyst; droplet size; and time. Example outputs include: product yield; selectivity; purity; and cost. The goal of reaction optimization described here is to select the best inputs to achieve a given output, which can be formulated as a reinforcement learning system. In order to find the optimal reaction conditions, Professor Zare is searching for critical reaction condition to try at the next step based on previous reaction conditions and product yields. A recurrent neural network is used to model the policy for reaction optimization. The reinforcement learning system is trained on mock reactions (random functions) and then real reactions for better performance.  The approach, if successful, could help better understanding of fundamental features of reactivity and enable important industrial applications."
"1806079","Automated Search for Materials for Ammonia Synthesis and Water Splitting","CBET","ENERGY FOR SUSTAINABILITY","09/01/2018","07/09/2018","Charles Musgrave","CO","University of Colorado at Boulder","Standard Grant","Carole Read","08/31/2020","$136,329.00","Aaron Holder","charles.musgrave@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","ENG","7644","","$0.00","The use of renewable electricity and solar energy to convert water, carbon dioxide, and nitrogen into energy-dense fuels and high-valued chemicals can improve the storage and utilization of intermittent solar and wind energy. This technology for ""solar fuels"" has benefits in utilization of renewable energy sources into value added chemicals used to make industrial products. This project supports fundamental research of the discovery of advanced catalysts for a wide range of redox reactions. When conducting new materials discovery, for a given family of promising material compositions, only a fraction of materials will have desirable properties for the targeted reaction applications. For many of these solid-state materials, the chemical equilibria and driving forces for chemical reactions are unknown. Statistical learning approaches have been developed which can extract information from large quantities of data to train highly reliable ""artificial intelligence"" models for predicting properties of a new material system. In this project, the principal investigators are using machine learning approaches applied to experimental data for hundreds of materials to predict the stabilities, structures, and chemical reactivity of hundreds of materials. The predicted properties can then be used to identify candidate materials for catalyzing technologically-important reactions, such as splitting water into oxygen and hydrogen, converting carbon dioxide into useful products, or the 'green' synthesis of ammonia from nitrogen and water. The models are being made available on public repositories such as machine learning computer codes, and through publicly-accessible materials databases. The project is training high school, undergraduate and graduate students in the application of state-of-the-art machine learning methods for chemistry, chemical engineering, and materials science applications. The research is integrated with education and outreach through the PI's participation in the Broadening Opportunity through the Leadership and Diversity (BOLD) Center at University of Colorado, and the incorporation of new concepts in machine learning and chemistry within the PI's courses. <br/><br/>This project will apply machine learning approaches for the discovery of new oxide and oxynitride materials at scale for catalyzing splitting water into oxygen and hydrogen or the 'green' synthesis of ammonia from nitrogen and water. The chemical driving forces for the reactions involved in splitting water and ammonia synthesis depend critically on the energy to create an oxygen vacancy in the oxide or oxynitride material. In this project, The PI is using machine learning approaches trained on a set of oxygen vacancy formation energies that were calculated quantum mechanically. This project is complementary and leverages grant CHE 1800592 that focuses on the development of the machine learning methods and datasets. The predicted properties can then be used to identify candidate oxides and oxynitrides for catalyzing splitting water or ammonia synthesis. This project combines expertise in electronic structure, thermodynamics, computational materials science, and machine learning to study a central property of oxides - their oxygen vacancy formation energies, EV. The data-driven approach takes advantage of results showing that EV depends systematically on various materials properties, such as the electronic band gap and the enthalpy of formation of the material. The researchers will apply machine learning methods to model EV directly, using quantum mechanically calculated EV data for several hundred materials for training and descriptor extraction. The resulting descriptors are being used to predict EV for unique oxide and nitride compositions, and in turn, will enable the computation of millions of reaction equilibria for the oxidation and reduction reactions for water splitting and ammonia synthesis mediated by these materials. Despite the enormous technological and economic importance of advanced oxides and oxynitrides in a broad range of technologies, much is still unknown about the detailed behavior that give rise to their chemical properties. Potential applications of the new techniques and thermochemical databases produced by this project include thermochemical water splitting using redox materials, ammonia synthesis by chemical looping, oxidation of materials, the carbothermal reduction of oxides, oxygen separation membranes, and solid oxide fuel cell electrolytes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1552097","CAREER: Pursuing New Tools for Approximation Algorithms","CCF","ALGORITHMIC FOUNDATIONS","03/01/2016","05/07/2018","Shayan Gharan","WA","University of Washington","Continuing grant","Rahul Shah","02/28/2021","$227,932.00","","shayan@cs.washington.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","CSE","7796","1045, 7926","$0.00","Many of the large-scale industries are now employing sophisticated algorithms to solve variants of fundamental optimization problems. For example, Amazon uses a variant of the Traveling Salesman Problem (TSP) known as the vehicle routing problem for routing Amazon-Fresh Trucks. Uber solves a variant of TSP to route its shared-ride services. Many of the social networks including Facebook and Google+ solve variants of constraints satisfaction problems for their social targeting tasks. These optimization problems have ubiquitous applicability but they are computationally challenging in the sense that many are known to be NP-hard. This means that under standard assumptions they cannot be solved optimally by algorithms which terminate in reasonable time. The field of approximation algorithms attempts to develop efficient algorithms that find solutions close to the optimum. These approximation algorithms have found many applications in the real world. The project will advance state-of-the-art in approximation algorithms which will not only have impact on industry but also contribute to our fundamental understanding of P vs NP issue, which is at the core of computer science.<br/><br/>This project aims to develop new tools and techniques to obtain improved approximation algorithms for fundamental optimization problems, including the TSP and Constraint Satisfaction problems. The project intends to prove new algebraic properties of stable polynomials and use them to study graphs from an algebraic point of view. These tools will lead to design a new class of approximation algorithms. These new tools coming out of this project will be incorporated in the next generation of courses in approximation algorithms that focus on algebraic techniques. Although grounded in computer science theory, the project will also attract many graduate students outside of theory from applied fields like machine learning and artificial intelligence forming basis for interdisciplinary research."
"1726047","Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students","DUE","IUSE","09/01/2017","07/21/2017","Kimberly Talley","TX","Texas State University - San Marcos","Standard Grant","Heather Watson","08/31/2022","$184,034.00","","kgt5@txstate.edu","601 University Drive","San Marcos","TX","786664616","5122452314","EHR","1998","8209, 8238, 8244, 9178","$0.00","Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
"1725659","Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students","DUE","IUSE","09/01/2017","07/21/2017","Benjamin Caldwell","TX","LeTourneau University","Standard Grant","Heather Watson","08/31/2022","$137,420.00","","BenjaminCaldwell@letu.edu","P O BOX 7001","Longview","TX","756077001","9032333100","EHR","1998","8209, 8244, 9178","$0.00","Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
"1725423","Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students","DUE","IUSE","09/01/2017","07/21/2017","Julie Linsey","GA","Georgia Tech Research Corporation","Standard Grant","Heather Watson","08/31/2022","$429,108.00","","julie.linsey@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","EHR","1998","8209, 8244, 9178","$0.00","Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
"1823015","SPX: Collaborative Research: Automated Synthesis of Extreme-Scale Computing Systems Using Non-Volatile Memory","CCF","SPX: Scalable Parallelism in t","10/01/2018","07/05/2018","Nathaniel Cady","NY","SUNY Polytechnic Institute","Standard Grant","Anindya Banerjee","09/30/2022","$500,000.00","","ncady@sunypoly.edu","257 Fuller Rd.","Albany","NY","122033603","5184378689","CSE","042Y","026Z","$0.00","The project investigates the design of a scalable computing infrastructure that uses nanoscale non-volatile memory (NVM) devices for both storage and computation. The project's novelties are (i) the use of multiple parallel flows of current through naturally occurring sneak paths in NVM crossbars for computation; (ii) the replacement of slow organic expert-driven discovery of flow-based computing designs by automated synthesis techniques for accelerated discovery of novel NVM crossbar designs; and (iii) a pervasive focus on fault-tolerance throughout the design of exact, approximate and stochastic flow-based computing designs. The project's impacts are (i) the design of an end-to-end framework that maps compute-intensive kernels written in a high-level programming language onto nanoscale NVM crossbar designs and (ii) the creation of a new scalable capability to perform exact and approximate in-memory digital computations on fault-prone nanoscale NVM crossbars. The team of computer scientists and nanoscience researchers is creating flow-based computing designs for four benchmark problems: the Feynman grand prize problem, computer vision, basic linear algebra, and simulation of dynamical systems. The automatically synthesized NVM crossbar designs are being evaluated using high-performance simulations and experimental benchmarking in a modern nanotechnology laboratory. <br/><br/><br/>Computing using multiple parallel flows of current through data stored in nanoscale crossbars is often fast and more energy-efficient, but the design of such crossbars is highly unintuitive for human designers. The project explores a combination of formal methods for checking satisfiability of Boolean formulae, and artificial intelligence techniques such as best-first search, to automatically synthesize NVM crossbar designs from specifications written in a high-level programming language. The team of computer scientists and nanoscience researchers is pursuing a transformative agenda for extreme-scale computing by leveraging memory devices in NVM crossbars as structurally-constrained fault-prone distributed nano-stores of data, and exploiting the natural parallel flow of current through NVM crossbars for computing over data stored in the distributed nano-stores. The NVM crossbar designs generated from OpenCV, LAPACK, and ODEINT programs are evaluated using the Xyce circuit simulation software and subsequently fabricated for experimental benchmarking. By combining storage and computation on the same device, the project circumvents the von Neumann barrier between the processor and the memory and creates scalable solutions for extreme-scale computing on fault-prone NVM crossbars without introducing substantial changes to the programming model.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1726306","Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students","DUE","IUSE","09/01/2017","07/21/2017","Tracy Hammond","TX","Texas A&M Engineering Experiment Station","Standard Grant","Heather Watson","08/31/2022","$988,683.00","Kristi Shryock, Stephanie Valentine","hammond@tamu.edu","TEES State Headquarters Bldg.","College Station","TX","778454645","9798477635","EHR","1998","8209, 8244, 9178","$0.00","Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
"1822976","SPX: Collaborative Research: Automated Synthesis of Extreme-Scale Computing Systems Using Non-Volatile Memory","CCF","SPX: Scalable Parallelism in t","10/01/2018","07/05/2018","Sumit Jha","FL","University of Central Florida","Standard Grant","Anindya Banerjee","09/30/2022","$500,000.00","","jha@eecs.ucf.edu","4000 CNTRL FLORIDA BLVD","ORLANDO","FL","328168005","4078230387","CSE","042Y","026Z","$0.00","The project investigates the design of a scalable computing infrastructure that uses nanoscale non-volatile memory (NVM) devices for both storage and computation. The project's novelties are (i) the use of multiple parallel flows of current through naturally occurring sneak paths in NVM crossbars for computation; (ii) the replacement of slow organic expert-driven discovery of flow-based computing designs by automated synthesis techniques for accelerated discovery of novel NVM crossbar designs; and (iii) a pervasive focus on fault-tolerance throughout the design of exact, approximate and stochastic flow-based computing designs. The project's impacts are (i) the design of an end-to-end framework that maps compute-intensive kernels written in a high-level programming language onto nanoscale NVM crossbar designs and (ii) the creation of a new scalable capability to perform exact and approximate in-memory digital computations on fault-prone nanoscale NVM crossbars. The team of computer scientists and nanoscience researchers is creating flow-based computing designs for four benchmark problems: the Feynman grand prize problem, computer vision, basic linear algebra, and simulation of dynamical systems. The automatically synthesized NVM crossbar designs are being evaluated using high-performance simulations and experimental benchmarking in a modern nanotechnology laboratory. <br/><br/>Computing using multiple parallel flows of current through data stored in nanoscale crossbars is often fast and more energy-efficient, but the design of such crossbars is highly unintuitive for human designers. The project explores a combination of formal methods for checking satisfiability of Boolean formulae, and artificial intelligence techniques such as best-first search, to automatically synthesize NVM crossbar designs from specifications written in a high-level programming language. The team of computer scientists and nanoscience researchers is pursuing a transformative agenda for extreme-scale computing by leveraging memory devices in NVM crossbars as structurally-constrained fault-prone distributed nano-stores of data, and exploiting the natural parallel flow of current through NVM crossbars for computing over data stored in the distributed nano-stores. The NVM crossbar designs generated from OpenCV, LAPACK, and ODEINT programs are evaluated using the Xyce circuit simulation software and subsequently fabricated for experimental benchmarking. By combining storage and computation on the same device, the project circumvents the von Neumann barrier between the processor and the memory and creates scalable solutions for extreme-scale computing on fault-prone NVM crossbars without introducing substantial changes to the programming model.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1754610","Collaborative Research: Origin and Evolutionary Divergence of the Pancrustacean Brain","IOS","ORGANIZATION","07/01/2018","06/12/2018","Gabriella Wolff","WA","University of Washington","Continuing grant","Evan Balaban","06/30/2022","$166,654.00","","gabwolff@uw.edu","4333 Brooklyn Ave NE","Seattle","WA","981950001","2065434043","BIO","7712","1096, 9178","$0.00","It is still unknown when brains first appeared during the early history of life. The ways in which major brain parts that are structurally distinctive have changed over evolutionary time are also poorly understood. These knowledge gaps are partly due to the fact that fossil brains are rare and have been difficult to study. This project features scientists from three collaborating laboratories who will pool their resources to identify a set of invertebrate brain centers that mediate learning and memory. Structural and functional similarities and differences among these areas will be established across modern insect and crustacean species. The major question this research is answering is whether these brain centers share common genetic and computational attributes due to the brain?s fundamental organization being inherited by the descendants from a common ancestor; or, because brains that have arisen independently in different invertebrate groups are not able to perform certain functions unless brain areas that give them these same abilities have also arisen independently. These questions will be answered by precisely measuring the brain structures in fossilized invertebrate animals and comparing their basic arrangements with modern counterparts. The broader impact of this research will be to identify invertebrate proxies of the learning-and-memory brain centers found in vertebrate animals alive today, including humans. Identification of such proxies will inform us about how brains have evolved, and will contribute to a broader understanding of how memory centers are organized. The results will impact theories of, and research on, neural networks and artificial intelligence, and at the same time the scientists carrying out this research will develop novel strategies for identifying genealogical correspondence of brain structures across a very broad range of species. Brains analyzed for this research will be digitally reconstructed in 3D and uploaded to an open-source database for education and research purposes. The research will also provide advanced neuroscience structural analysis and genomics training to students from diverse backgrounds.<br/><br/>The neuronal organization and circuit properties of insect mushroom bodies are well known, as are their functional properties for learning and memory. While the existence of mushroom-body-like centers exist across arthropods, it is not known whether these phenotypically or genotypically correspond to the centers in insects. The planned research will identify mushroom body-like centers across a broad range of species, analyze their discrete neural arrangements, circuit organization, and molecular attributes. These comparisons will identify the species within and outside Arthropoda that possess functional and morphological correspondences in these structures. Transcriptomics will address whether phenotypically-corresponding centers share common genomic attributes, and whether there are unique genetic networks that define arthropod mushroom bodies or whether these networks differentiate mushroom bodies in different groups of arthropods such as in insects and crustaceans. The identification of broad phenotypic and genotypic homology of these centers across a broad phyletic spectrum would suggest an ancient origin of these learning and memory centers. Equally intriguing would be results suggesting convergent evolution of learning and memory centers across taxa.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1725785","Enhancing Visualization Skills and Conceptual Understanding Using a Drawing-Recognition Tutoring System for Engineering Students","DUE","IUSE","09/01/2017","07/21/2017","Vimal Viswanathan","CA","San Jose State University Foundation","Standard Grant","Heather Watson","08/31/2022","$75,155.00","","vimal.viswanathan@sjsu.edu","210 North Fourth Street","San Jose","CA","951125569","4089241400","EHR","1998","8209, 8238, 8244, 9178","$0.00","Visual and spatial skills are important for scientific and engineering innovation. The ability to represent real systems through accurate yet simplified diagrams is a crucial skill for engineers. A growing concern among engineering educators is that students are losing both the skill of sketching and the ability to produce the free-body diagrams (FBDs) of real systems. These diagrams form the basis for various types of engineering analyses. To address this concern, investigators will redesign and test a cutting-edge educational technology for engineering concepts of statics and mechanics. The sketch-based technology developed at Texas A&M University, called Mechanix, enabled students to hand-draw FBDs, trusses, and other objects using digital ink and provided helpful feedback. The upgraded Mechanix software will include enhanced artificial intelligence (AI) to understand the sketches and provide immediate feedback to the student for individualized tutoring. Instructors will also receive real-time detailed information from the system so they can clarify misconceptions and guide students through problem solutions during classes. This free-hand sketch-based system will focus learning on the fundamental engineering concepts and not on how to use a software tool. These engineering concepts directly relate to a wide variety of designs including bridges, buildings, and trusses that are vital to the infrastructure of the nation's cities. The project will help prepare engineers with improved abilities to develop these designs that are essential in society.<br/><br/>This project will aim to demonstrate the impact of the sketch-recognition based tutoring system on students' motivation and learning outcomes, both generally and among students of diverse backgrounds. The Mechanix system will be converted to an HTML5 format to work on all devices and expand its accessibility for institutions with various technological requirements. Additional AI algorithms will be developed to accommodate more types of statics problems, increased sketch-recognition accuracy and speed, and improved feedback mechanisms for instructors that merge performance information for the students in a class. The upgraded system will be studied in various engineering courses across five different universities, and introduced to over 2,500 students in engineering and related fields. The investigators will utilize controlled classroom experiments, digital data collection, pre/post concept testing, focus groups, and interviews to explore the external validity of Mechanix as a learning tool. Analysis of Covariance will be used to compare outcomes for students using Mechanix and students in control groups. Project outcomes and the Mechanix software will be shared through the project website, professional development workshops, and publications."
"1751765","AF: EAGER: Homomorphism Problems in Digraphs (Dichotomies)","CCF","ALGORITHMIC FOUNDATIONS","09/15/2017","09/05/2017","Arash Rafiey","IN","Indiana State University","Standard Grant","Tracy J. Kimbrel","08/31/2019","$141,056.00","Geoffrey Exoo, Jeffrey Kinne, Laszlo Egri","Arash.Rafiey@indstate.edu","200 N 7TH STREET","TERRE HAUTE","IN","478091902","8122373088","CSE","7796","7916, 7926, 7927","$0.00","Graph coloring is one of the most important problems in theoretical computer science.  Many combinatorial optimization problems can be viewed as graph coloring problems.  For a given graph G and integer k, the question is whether there exists a coloring of its vertices with k colors such that any two adjacent vertices receive different colors.  The Graph (or Directed Graph) Homomorphism Problem is a generalization of graph coloring.  In the Graph Homomorphism Problem, the goal is to find a mapping from an input graph (or digraph) to a fixed target graph (or digraph) H that preserves adjacency.<br/><br/>Homomorphism problems, and the equivalent formulation as so-called constraint satisfaction problems (CSPs), enjoy a wide variety of applications as optimization problems that must be solved in practice.  Such applications can be seen in scheduling, planning, databases, artificial intelligence, and many other areas.<br/><br/>The Digraph Homomorphism Problem and CSPs have been two very active research areas in Theoretical Computer Science over the last two decades.  Several  tools (mostly algebraic) have been developed for solving CSPs, and very recently a number of proposed solutions (including our solution) to the main conjecture in the area (known as the CSP Conjecture) have arisen.  The present project aims to verify in detail each approach to distill the most elegant proof and most efficient algorithms.  The approach is purely combinatorial, using techniques from graph theory.<br/><br/>The project will also tackle problems closely related to the newly proposed solutions to the CSP Conjecture.  For example, the PIs seek forbidden obstruction characterizations for the types of digraphs H that make homomorphism problems feasible. This would help to improve the running time of the current algorithm.<br/><br/>The project aims also to have a high educational impact, through training graduate students in theoretical computer science, producing <br/>freely available and high quality lecture notes and survey material on the field, seeking connections between the research and other important areas of research across computing, and utilizing novel teaching and dissemination methods."
"1728370","SNM: Large-area Printing and Integration of Metal Nanowires and Organic Semiconductors for Stretchable Electronics and Sensors","CMMI","SNM - Scalable NanoManufacturi","07/01/2017","06/23/2017","Yong Zhu","NC","North Carolina State University","Standard Grant","Khershed Cooper","06/30/2021","$1,296,937.00","Jingyan Dong, Brendan O'Connor","yong_zhu@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","ENG","025Y","081E, 083E, 084E","$0.00","Stretchable electronics and sensors, such as electronic skin, have wide ranging transformative applications in autonomous artificial intelligence (e.g. robots), medical diagnostics, and prosthetic devices capable of providing at least the same level of sensory perception as the biological equivalent. For example, for electronic skin to meet these expectations, a large number of distributed tactile sensors that are able to stretch and conform to curvilinear objects are required. Moreover, electronics that is conformal to human skin and deform in response to human motion requires stretchability. The functional requirements of stretchable electronics and sensors can be met through nano-enabled technologies, but their successful production requires innovation in scalable manufacturing and integration of processing methods. This Scalable NanoManufacturing (SNM) research project aims to investigate a scalable nanomanufacturing approach to fabricate large-area, high-resolution, stretchable electronics and sensor arrays by heterogeneous integration of metal nanowires and organic semiconductors. The research conducted as part of this award is integrated into interdisciplinary education for the involved students, course curriculum, and K-12 outreach. The project strongly encourages underrepresented students to participate in all aspects of the research.<br/><br/>Advancing the scalable nanomanufacturing of stretchable electronic skin requires: (1) stretchable functional materials (conductors, semiconductors), (2) a manufacturing strategy to integrate heterogeneous nanomaterials into a stretchable platform, and (3) optimal device design and integrated operation capabilities in both electronic and mechanical functionality. To meet these needs, the research investigates metal nanowires and polymer semiconductor material platforms. Stretchable conductors are achieved through forming nanowire-elastomer composites. Printing metal nanowires in large scale with high resolution is challenging. Here nanowire processing focuses on the fundamental understanding of the nanowire ink properties, ink-substrate interactions, and exploration of methods such as gravure and electrohydrodynamic printing. Approaches to achieve high-performance intrinsically stretchable polymer semiconductors are investigated with a focus on blending conjugated polymers with a secondary polymer matrix. Polymer semiconductor processing focuses on a combination of solution casting and advanced transfer printing methods. Device architecture and integrated manufacturing strategies are optimized to achieve high performance electronic-skin."
"1829622","CyberTraining: CIU: SJSU Data Science for All Seminar Series","OAC","CyberTraining - Training-based","09/01/2018","07/02/2018","Leslie Albert","CA","San Jose State University Foundation","Standard Grant","Sushil Prasad","08/31/2021","$410,060.00","Esperanza Huerta, Scott Jensen","leslie.albert@sjsu.edu","210 North Fourth Street","San Jose","CA","951125569","4089241400","CSE","044Y","026Z, 062Z, 7361, 9102, 9179","$0.00","The Nation's research enterprise faces a shortage of data scientists. Expanding the pipeline of data science students, particularly from underrepresented populations, requires educational institutions to increase awareness of data science and inspire a passion for data in students as they begin their academic careers. Currently, few community colleges or undergraduate programs provide training in cyberinfrastructure tools or data science techniques to a broad student population. This project takes a novel approach to augmenting the Nation's data science workforce by training community college and undergraduate students to provide data analytics support to data scientists through a series of ""Data Science for All"" extracurricular seminars. The seminars require no prior data science knowledge, emphasize transferable skills, and present a feasible path into data science-related research and other careers for students from a broad array of disciplines and from underrepresented groups without extending their time to graduation. By increasing the Nation's data science capabilities and the diversity of its data science research workforce, the project serves the national interest, as stated by NSF's mission: to promote progress of science and advance the prosperity and welfare of the Nation. <br/><br/>The goals of this project are to increase undergraduate student awareness of data-driven science and to grow and diversify the population of students trained to perform data wrangling - the data acquisition, transformation, cleaning, and profiling required to prepare data for analysis. According to industry experts, data wrangling is the ""heavy lifting"" of data science, constituting up to 80% of a data scientist's daily work. Shifting this time-consuming effort to trained data analysts free data scientists to focus more of their time on research. The project achieves its goals through the development and delivery of widely consumable, extracurricular seminars providing interactive training on data science concepts and industry-leading data wrangling tools to undergraduate and community college students. Initial seminar topics, selected in collaboration with the project's advisory board, include Python, Jupyter notebooks, Apache Spark, Tableau, and demystifying artificial intelligence (AI). The seminars' focus on data wrangling also introduces students to data preparation documentation - capturing the data provenance needed for reproducible science. This project's contribution to the Nation's data science workforce is broadened through the free and open distribution of its seminar materials and supplemental resources and its online instructor support community. To encourage adoption at Bay Area community colleges and universities, instructor training is provided through co-instruction and a teaching-the-teacher model. The project contributes to pedagogical research by identifying instructional approaches most effective in teaching data science to a diverse population of undergraduate students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1144591","IGERT: Soft Material Robotics","DGE","IGERT FULL PROPOSALS, NSF Research Traineeship (NRT), IGERT Chemistry, IGERT Physics, IGERT Materials Research","07/01/2012","07/20/2016","Barry Trimmer","MA","Tufts University","Continuing grant","Laura Regassa","12/31/2018","$2,709,035.00","David Kaplan","barry.trimmer@tufts.edu","136 Harrison Ave","Boston","MA","021111817","6176273696","EHR","1335, 1997, 8062, 8063, 8064","1335, 9179, SMET","$0.00","IGERT: Soft Material Robotics.<br/><br/>This Integrative Graduate Education and Research Traineeship (IGERT) award creates an interdisciplinary graduate program to  develop advances in the field of soft robotics. These machines, inspired by animals, will be capable of complex tasks that are difficult to achieve with conventional robots, suitable for close interactions with humans, and able to work in environmentally sensitive locations. The research will cross traditional disciplinary boundaries, employing novel biomaterials, exploiting cellular processes and tissue engineering methods, and using control strategies derived from evolutionary principles ? approaches that are comparatively rare in conventional robotics.<br/><br/>Broader Impacts: The development of this new technology provides an exciting opportunity to train inventive and entrepreneurial future science and engineering leaders. IGERT trainees will train in multiple disciplines, including materials science, neuromechanics, mechanical control systems, computer science, artificial intelligence and product design. Novel collaborative training approaches include the formation of mentorship teams and an innovative problem solving-based model of education. IGERT trainees will exploit bioengineering approaches to machine design, fabricate and control new robotic devices to address a wide range of current medical, social and environmental challenges. For example, soft robots could be developed for internal medical diagnosis and delivery of therapeutics, or for search and rescue operations and bioremediation. The international partners, leaders in the emerging field of soft robots, will help trainees form collaborations and affiliations across the world. These students will bridge emerging areas of biology and engineering to create revolutionary new technologies including robots for human assistance and environmentally-friendly biodegradable robots. <br/><br/>IGERT is an NSF-wide program intended to meet the challenges of educating U.S. Ph.D. scientists and engineers with the interdisciplinary background, deep knowledge in a chosen discipline, and the technical, professional, and personal skills needed for the career demands of the future. The program is intended to establish new models for graduate education and training in a fertile environment for collaborative research that transcends traditional disciplinary boundaries, and to engage students in understanding the processes by which research is translated to innovations for societal benefit.<br/><br/>"
"1829225","Individuating and comparing objects and events","BCS","LINGUISTICS","03/01/2018","03/08/2018","Alexis Wellwood","CA","University of Southern California","Standard Grant","William J. Badecker","12/31/2020","$462,064.00","","wellwood@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","SBE","1311","1311, 9178, 9179, 9251","$0.00","The primary mode by which we communicate our ideas about the world and about each other is through language. However, languages aren't merely passive vehicles for the transmission of information. Rather, our sentences carry along with them evidence of the fundamental concepts and categories that we use to understand the world and each other. At one level, this fact about language might seem obvious: a person on one side of an argument might choose to use words that a person on a different side might not, and attending to these different choices tells us something about the people speaking. Such observations about language and language users are studied in fields like sociolinguistics. Yet, our language also reveals more basic truths about us which are not as easily accessible to consciousness, and which are more tied to elements of our common experience. For example, people talk as if there are objects that can be counted (""four spoons"") and substances that cannot (e.g., ""four muds"" is odd), even if arranged in discrete piles. Investigating language at this deeper level can thus reveal basic structures of thought, informing theories of cognition and its development, as well as applications in artificial intelligence.<br/><br/>This project studies parallels in the conceptualization of the basic categories 'object' and 'event' as they are encoded in language and understood by both adults and 4 year olds. Previous research in linguistics and the philosophy of language has uncovered striking formal parallels in the encoding of these categories across nominal and verbal language. The project links this research to what is known about object representation in cognitive science, and uses this link to extend what is known about event representation. Specifically, the project (i) tests whether the observed linguistic parallels correspond to parallels in how adults and children conceptualize minimally-different static and dynamic scenes, (ii) investigates the extent to which representational biases for simple dynamic scenes predicts how adults and children understand quantificational language involving words like ""more"", and (iii) probes the hypothetical universality of the language-cognition linkages by teaching English-speaking adults and children attested, but non-English patterns of event encoding. The results of this project will demonstrate the fruitfulness of connecting formal semantics, philosophy of language, and cognitive science to illuminate the interface between linguistic and non-linguistic perception and cognition.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1827139","CC* Networking Infrastructure: The Roadrunner High-Performance Science, Engineering, and Business DMZ","OAC","Campus Cyberinfrastrc (CC-NIE)","07/01/2018","06/29/2018","Bryan Wilson","TX","University of Texas at San Antonio","Standard Grant","Kevin L. Thompson","06/30/2019","$500,000.00","Harry Millwater, Bernard Arulanandam, Brent League","BRYAN.WILSON@UTSA.EDU","One UTSA Circle","San Antonio","TX","782491644","2104584340","CSE","8080","","$0.00","World-class research in cyber security, bioinformatics, cloud computing, machine learning, artificial intelligence, real-time computing and other related areas requires efficient and often near-immediate access to large data sets in order to reduce the time from theory to discovery. In addition, discoveries are often interdisciplinary and multi-institutional. As a result, a critical enabling feature for impactful, collaborative research is a dedicated high-speed network that is omnipresent across a campus. The University of Texas at San Antonio (UTSA), a Hispanic Serving Institution, is implementing a dedicated research network (DMZ) to facilitate data-intensive computation and research collaboration endeavors. This infrastructure fills a gap that currently exists in the ""last mile"" bottleneck from a research lab to the DMZ. <br/><br/>In particular, the project calls for installation of 10 Gb/s switches across campus that, in concert with the dedicated research network, provide 5-10X faster data transfer rates. These improvements foster access by UTSA faculty and students to the campus' high-performance computing facility, high-speed data storage, and visualization laboratory as well as the Texas Advanced Computing Center (TACC) in Austin, Texas. The new network also enhances experiential learning activities such as UTSA's annual CyberPatriot competition, undergraduate research projects in cloud and high-performance computing, cloud computing ELab training for undergraduates, as well as certification programs such as the Master's level certification in cloud computing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1316223","RCN Proposal: Macroecology of Infectious Disease","DEB","ECOLOGY OF INFECTIOUS DISEASES","09/01/2013","06/05/2017","Patrick Stephens","GA","University of Georgia Research Foundation Inc","Continuing grant","Samuel M. Scheiner","08/31/2019","$499,451.00","Robert Poulin, Sonia Altizer, Katherine Smith, Alonso Aguirre","prsteph@uga.edu","310 East Campus Rd","ATHENS","GA","306021589","7065425939","BIO","7242","7242, EGCH","$0.00","Scientists from multiple disciplines, including wildlife biology, public health, veterinary parasitology and biomedical sciences, have compiled a wealth of data on the distribution and impacts of infectious diseases, with most studies focused on particular locations or single host-pathogen interactions. This wealth of data creates the opportunity to address a pressing need, namely to explore the patterns and drivers of infectious disease emergence in humans and natural ecosystems at global scales. This project will create a Research Coordination Network to bring together internationally recognized experts from ecology, conservation medicine, parasitology and computational sciences to quantify and explore the drivers of global scale patterns of pathogen biodiversity. Participants will work together to assemble data sets of unprecedented size, including information about disease occurrence in host species ranging from insects to humans. With help from experts in machine learning (artificial intelligence) and geographic information systems (GIS), they will work to build predictive models that can be used to understand the changing distributions of infectious diseases and identify future hotspots of novel disease emergence in humans and wildlife.<br/><br/>Emerging infectious diseases, especially those that jump from wildlife to livestock and humans, threaten public health around the world. Using state of the art computational methods, the RCN will be able to answer critical questions such as: How and why do certain pathogens successfully move from one host species to another? Are hotspots of pathogen biodiversity in wildlife the same areas as hotspots of disease emergence in humans and livestock? To share its findings, the RCN will develop educational products such as webcasts and workshops aimed at educational levels from high school to post graduate, and will train students from under-represented groups through a summer research program. The RCN will also develop and maintain databases of global infectious disease biodiversity and make these data freely available to the academic community and the general public."
"1817048","SHF: Small: Algorithms and Software for Scalable Kernel Methods","CCF","SOFTWARE & HARDWARE FOUNDATION","07/01/2018","06/25/2018","George Biros","TX","University of Texas at Austin","Standard Grant","Almadena Y. Chtchelkanova","06/30/2021","$476,172.00","","gbiros@gmail.com","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","7798","7923, 7942","$0.00","Scientists and engineers are increasingly interested in using machine learning methods on huge datasets that cannot be processed on a single workstation.  At the same time public and private institutions are making significant investments on high-performance computing (HPC) clusters equipped with thousands of leading edge processors and network connectivity. However, despite the availability of such HPC systems, data analysis tasks are mostly restricted to a single or a few workstations. The reason is that, with few exceptions, existing machine learning software does not scale efficiently on HPC systems. The need to process in-situ large scientific and engineering datasets is not met with current software and significant downsampling is required in order to use existing tools. A serious bottleneck in current artificial intelligence (AI) workflows is the significant cost of training for large scale problems. The slow convergence of existing methods and the large number of calibration hyper-parameters (learning rate, batch size, and other knobs that control the performance of the AI system) make training extremely expensive. Design and analysis of scalable optimization algorithms for faster training, that is the fitting of the machine learning (ML) model parameters to the data, are needed for analytics in real time  and at scale, which is the goal of this project.<br/><br/>The proposed research will introduce novel numerical methods and parallel algorithms for second-order/Newton methods that will be tailored to machine learning (ML) models and will be many orders of magnitude faster than the existing state of-the-art (first-order methods like steepest descent). The researchers plan to design, analyze, and implement robust approximations for covariance matrices, a class of matrices in AI and computational statistics, used in statistical analysis (e.g., sampling, risk assessment, and uncertainty quantification). The investigators plan to design, analyze, and implement scalable fast algorithms in the context of high-performance computing for the so called nearest-neighbor problem, a particular method in ML, data analysis, and information retrieval. The resulting software library will provide a means for end-to-end tools for discovery and innovation and provide new capabilities in the NSF XSEDE infrastructure project. Along with  research activities, an educational and dissemination program is designed to communicate the results of this work to both students and researchers, as well as a more general audience of computational and application scientists.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1721595","SBIR Phase I:  Wearable Technology to Prevent Decompression Sickness Underwater by Continuously Monitoring Bubble Presence in the Bloodstream and Tissues","IIP","SMALL BUSINESS PHASE I","07/01/2017","07/10/2017","William Garcia","PR","SIL Technologies LLC","Standard Grant","Henry Ahn","02/28/2019","$225,000.00","","william.garcia@siltechnologies.company","2539 Calle 14","Rincon","PR","006772461","5182217114","ENG","5371","5345, 5371, 8018, 8042, 9150","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to enable the development of a unique wearable scuba-diving device that will eliminate the risk of Decompression Sickness (DCS), by monitoring in real time the formation of nitrogen bubbles in the body of the user while in the dive. The risk to develop DCS while conducting underwater activities occurs during the ascension phase, when the changing pressure may yield the formation of nitrogen bubbles in tissues and body. The presence of bubbles triggers a variety of serious injuries with long term consequences and even death. Any professional and licensed recreational scuba training makes trainees aware about the risks associated to DCS. Divers are instructed to follow ascent rates and safety stops according with criteria established from statistical considerations of empirical data. Nevertheless, DCS is suffered by rule-abiding divers during 3% of the immersions, requiring costly and distressing evacuation and treatment with hyperbaric chambers. The wearable device will alert the scuba-diver before the sickness develops, reducing the risk to suffer DCS, making underwater activities simpler and safer. <br/><br/>The proposed project plans to demonstrate an innovative ultrasonic resonant concept adapted from the acoustic chamber notion. Acoustic chambers are structures which are belted by piezoelectric arrangements which are set to deform expanding and compressing when subjected to oscillating electric voltages. The frequency of oscillations can be set to match the modes of vibration of the media entering in resonance. Under such conditions the setup is extremely sensitive to minor changes in the elastic properties of the system, such as those induced by the presence of compressible bubbles. This project will execute a plan to produce a wearable design of the piezoelectric array. Artificial intelligence as well as conventional methods will be employed to analyze the electrical disturbances, and relate them to the bubbles sizes in real time. The computing, data acquisition and power requirements will be determined. Ultimately, these results will determine the feasibility to integrate all the required components in an autonomous wearable DCS risk detection device by a scuba diver."
"1818643","XPS: FULL: Collaborative Research: Parallel and Distributed Circuit Programming for Structured Prediction","CCF","Exploiting Parallel&Scalabilty","10/01/2017","06/18/2018","Vivek Sarkar","GA","Georgia Tech Research Corporation","Standard Grant","Anindya Banerjee","07/31/2019","$88,265.00","","vsarkar@rice.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","8283","","$0.00","This project develops a system for ""circuit programming,"" which allows a programmer to focus on the high-level solution to a problem rather than on the details of how the computation is organized. Circuit programming consists of writing rules that describe how data items depend on one another. The intellectual merits lie in the design of a new programming language for specifying these rules, along with the algorithms whereby the computer automatically finds efficient strategies for managing the necessary computations on available parallel hardware.  The project's broader significance and importance lie in its potential to streamline work in areas such as artificial intelligence and machine learning.  With the growing complexity of systems in these areas and their need to process big data in depth, research and teaching typically get bogged down in programming details, especially for parallel platforms; this project aims to delegate those details to automatic methods.<br/><br/>The research develops a programming system for Dyna, a circuit programming language that enables concise specification of large function graphs that may be cyclic and/or infinite. Dyna employs (1) a pattern-matching notation that augments pure Prolog with evaluation and aggregation and (2) an object-like mechanism for dynamically defining new sub-circuits as modifications of old ones.  This project is building an adaptive system that can mix forward and backward chaining to seek a fixpoint of the circuit and to update this fixpoint as the inputs change.  The system will perform compile-time and runtime analysis of the Dyna program and will map it to Habanero, a system for scheduling parallel computations on multicore processors, with extensions for task priorities, task cancellation, GPU execution, and distributed execution.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1839072","I-Corps: Embedded Cooling","IIP","I-Corps","07/01/2018","06/18/2018","Yogendra Joshi","GA","Georgia Tech Research Corporation","Standard Grant","Cindy WalkerPeach","12/31/2018","$50,000.00","","yogendra.joshi@me.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project's technology has its basis in a range of microfluidic cooling products. The potential of the technology is its positive impacts on several computing technologies where it may expand the limits of processing frequency and therefore system speed/performance. Commercial applications that can benefit from the project's technology are broad, such as those requiring the acceleration of high-performance computing in data centers, graphics computing in the fields of artificial intelligence, self-driving transportation, videogame hardware, digital currency (blockchain) technology, augmented and virtual reality, among others. The I-Corps customer discovery activities will also provide useful insights into other potential markets for this project's cooling technology, confirming if there is a need/interest by other industries, such as lasers, concentrated solar photovoltaics, and thermoelectric products, among many potential markets that use liquid-cooling systems at some level. <br/><br/>This I-Corps project is motivated by a technology that consists of an embedded microfluidic cooling layer that offers significantly enhanced heat removal capabilities when compared with current thermal hardware -- this is as a result of eliminating the thermal interfaces and heat spreaders commonly used in microelectronic devices. The heat removal is directly managed by bonding the microfluidic cooling layer to the silicon chip surface through a metallic joint. The resulting micro-cooling layer replaces the need for the heat spreader used in current technologies since the microstructures embedded in the cooling layer have the appropriate feature sizes and layout with an appropriate flow distribution through engineered manifolds for effective heat dissipation. This technology provides the capability of unlocking the clock frequency on micro-processing units by allowing the input of higher voltages to the computing cores, while also keeping the device temperature below design limits. Laboratory experimentation with these microfluidic cooling layers under a wide variety of operating conditions and refrigerants has demonstrated capabilities for removing heat fluxes of up to 500 W/cm2; a 5x increase when compared with the current maximum heat fluxes of commercial, high-end central processing units (CPUs) and graphics processing units (GPUs).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1809399","Topological Insulator Field Effect Transistors for Memory and Sensors","ECCS","ELECT, PHOTONICS, & MAG DEVICE","08/01/2018","06/18/2018","Qiliang Li","VA","George Mason University","Standard Grant","Usha Varshney","07/31/2021","$360,000.00","Dimitrios Ioannou","qli6@gmu.edu","4400 UNIVERSITY DR","FAIRFAX","VA","220304422","7039932295","ENG","1517","107E","$0.00","Relentless, Exponential progress on Complementary Metal-Oxide-Semiconductor (CMOS) technology over the last four decades has made possible the design and fabrication of the powerful silicon chips which are the engines of the microelectronics revolution which changed contemporary society: Computers, Smart Phones, Internet of things (IoT), Artificial Intelligence (AI), and the list goes on, there is no aspect of modern life that has not been touched by the silicon chip. Progress on conventional CMOS technology has however slowed down significantly, as miniaturization (according to Moore's Law) is reaching fundamental, physics imposed limits. To make progress possible ""beyond CMOS"", researchers around the world consider new approaches to use new materials (for example, topological insulators), and invent new types of transistors and new types of high-speed, high-density and low-power memory technology. Consequently, the goal of the research in this proposal is to further exploit our understanding of the properties of topological insulator nanowires and thin films to build new-concept field effect transistors with operational principles different than the conventional CMOS technology, while continuing to benefit from the existing vast experience semiconductor industry has accumulated over the years with this technology (CMOS). If successful, the outcomes of the proposed research will also include new memory devices and sensors, made possible by these topological insulator transistors. Graduate, undergraduates and high-school students will have the opportunity to interact with collaborators from Industry and Government Laboratories. <br/><br/>The goal of the proposed research is to design and fabricate Topological- Insulator Field-Effect transistors platform to explore and exploit the potential of gate-controlled topological surface state for applications in new-concept nonvolatile memory and sensor devices. The specific aims of this proposal are: (i) to design and fabricate topological insulator transistors with large on-state current and near-zero off-state current; (ii) to explore gate design and device geometry for achieving robust and efficient control of the spin-polarized electron current; (iii) to exploit the spin-polarized electron current for spin-based logic and nonvolatile memory devices with low-power operation; and (iv) to exploit the resulting devices for enhancing the topological photoelectronic effect for infrared sensors with high sensitivity and selectivity. The research involves preparation of novel topological insulator nanowires and thin films, nanoscale device integration, and characterization, with a focus on achieving in the first instance high-quality topological insulator transistors. The topological insulator nanowires and thin films will be grown at wafer scale for in-situ device integration to achieve clean device interfaces and metal contacts. The topological insulator transistors will be fabricated with engineered gate/source/drain contacts and ferromagnetic insulator/channel interface to achieve: high on/off current ratio, large on-state current and sharp switching, with surface states efficiently tuned by the gate-source electric field. This proposal presents a complete route from materials preparation, to device integration and measurement, to applications focusing on logic transistors, nonvolatile memory and sensors.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819477","SBIR Phase I:  A Controversy Detection Signal for Finance","IIP","SMALL BUSINESS PHASE I","06/15/2018","06/15/2018","Shiri Dori-Hacohen","MA","Automated Controversy Detection, LLC","Standard Grant","Peter Atherton","11/30/2018","$225,000.00","","shiri@controversies.info","10 Oak Dr. Apt A","Granby","MA","010339767","6177925067","ENG","5371","5371, 8032","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to use controversy detection to support financial institutions' ability to reduce their risks and increase profits. This is part of a growing trend towards ""alternative data"" products relying on artificial intelligence and machine learning. Besides the financial industry, there are numerous potential applications of controversy detection technology in a variety of market verticals, such as crisis management, defense applications, and advertising technology. Beyond commercial applications, there is scope for social impact by opening analysis and explanatory power of controversies to individual users. Controversies have a massive impact on civic society and the so-called ""filter bubble"" exacerbates polarization, both political and otherwise; fake news on both sides of the political spectrum has recently captured public attention and generated political concern. Positive impact on society from commercializing this technology includes helping users become better informed and more capable of critically evaluating the often-overwhelming stream of online content. Proving the feasibility of this innovation in a highly quantifiable space such as finance could answer a customer need in that space and create new jobs for the economy, while enabling social good applications that can improve civic society.<br/><br/>This Small Business Innovation Research (SBIR) Phase I project relies on sophisticated machine learning and information retrieval techniques to automatically detect controversial topics. The initial data were collected at the University of Massachusetts Amherst, using NSF-supported research, which recognized controversy by mapping the text of a webpage to algorithmically-identified controversial topics. Research has demonstrated that controversy cannot be detected using existing methods of sentiment analysis, a widely-adopted natural language processing method. This project bridges the gap between the current capabilities of this nascent technology and the clear user need in the financial domain. It will evaluate the feasibility of controversy detection by applying a real-time controversy detection signal to financial data to reduce risk and increase returns.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1817120","CSR: Small: Redshift: An Operating System for Pervasive Hardware Acceleration","CNS","Computer Systems Research (CSR","06/15/2018","06/14/2018","Anton Burtsev","CA","University of California-Irvine","Standard Grant","Matt Mutka","05/31/2021","$460,000.00","","aburtsev@uci.edu","141 Innovation Drive, Ste 250","Irvine","CA","926173213","9498247295","CSE","7354","7923","$0.00","In contrast to today's systems centered around general-purpose processors also known as central processing units (CPUs), the next generation of high-performance computers will inherently rely on diverse, heterogeneous hardware ranging from many-core processors like Intel Xeon Phi that contains up to 72 processor cores and graphical processing units (GPUs) to specialized hardware accelerators, like specialized machine-learning chips and field-programmable gate arrays (FPGAs) re-programmed on demand for a specific task. In a hardware-accelerated environment that consists of many diverse execution units, the execution of a program is no longer a conventional thread tied to a single CPU, but a graph of small computations scheduled on a set of hardware accelerators each implementing a part of the program logic. Redshift is a new operating system for developing applications that leverage performance of a heterogeneous hardware-accelerated system.<br/><br/>At the core of Redshift is a dataflow programming model that enables execution of commodity programs on a network of heterogeneous hardware execution units with only minimal modifications. Redshift implements programs as collections of asynchronous invocations that transparently move execution between hardware functions. A novel runtime maps computations to execution units, balances load among them, and scales the hardware graph of computation in response to load. <br/><br/>The problem of efficient computing environments has large impacts on society as a whole: a rapidly growing share of scientific discoveries is done in silico. As this trend continues, we as a society depend on computational capacity of modern computers. Redshift will provide a foundation for developing the next generation of computation intensive applications in the areas of artificial intelligence, e.g., speech and image recognition, personal digital assistance, big-data analytical applications, genomic and personalized medicine, drug discovery, and many more.<br/><br/>Redshift will be implemented as a practical layer compatible with de facto research and industry standard Linux operating system, and will be open source, directly benefiting the broader community. To make our approach widely available, Redshift will be hosted in a publicly-readable repository, and will be available to anyone (https://github.com/mars-research/redshift). Additionally, as parts of Redshift will be developed in the openly-available National Science Foundation-funded CloudLab and Emulab testbeds, Redshift will be available for a test drive via a CloudLab profile (https://www.cloudlab.us/p/redshift/testdrive) that automatically instantiates a collection of nodes running Redshift).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813117","CSR: Small: Collaborative Research: Safety Guard: A Formal Approach to Safety Enforcement in Embedded Control Systems","CNS","Computer Systems Research (CSR","08/01/2018","06/14/2018","Chao Wang","CA","University of Southern California","Standard Grant","Samee Khan","07/31/2021","$250,000.00","","wang626@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","7354","7923","$0.00","Ensuring the safety of embedded control systems, such as the ones used in cars, is remarkably difficult as shown by the many recalled cars in recent years, causing tens of billions of financial loss each year. This project aims to improve the safety of critical components in embedded control systems by developing safety guards, a reactive component generated automatically from safety requirements and attached to the original system, to ensure the combined system is safe even if the original system violates the safety requirements. <br/><br/>The intellectual merit of this project lies in the set of methods and tools to be developed for synthesizing safety guards of black-box systems. Specifically, this project consists of three research tasks: (a) building a benchmark suite of critical components and their safety requirements; (b) developing synthesis algorithms for constructing the finite-state machines (FSMs) of the safety guards; and (c) developing software synthesis tools for automatically generating software code that implements these FSMs. <br/><br/>This research project will benefit a wide range of application domains, including automotive and avionics, which will be investigated through collaborations with industry. It will help improve the safety of critical components, including those based on machine learning and artificial intelligence techniques. It will simplify certification since the relatively simple safety guard can be certified against safety requirements in place of the detailed model of a critical component. And last but not the least, it will simplify the development process by allowing people to focus on functionality and performance without worrying about safety violations at the same time. <br/><br/>The resulting software tools, together with evaluation benchmarks and experimental data, will be made available to the public. To facilitate dissemination and sharing, the project will maintain online documentations, tutorials, slides, and source code of the tool and benchmark repositories. Besides the research websites of participants at Virginia Tech and University of Southern California, the following website will be dedicated to disseminate the project results broadly: http://chaowang-vt.github.io/safetyguard/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1759592","I-Corps: Embedded Machine Listening for Smart Acoustic Monitoring","IIP","I-Corps","11/01/2017","11/01/2017","Juan Bello","NY","New York University","Standard Grant","Cindy WalkerPeach","04/30/2019","$50,000.00","","jpbello@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","ENG","8023","","$0.00","The broader impact/commercial potential of this I-Corps project is the use of embedded machine listening as a low-cost, turnkey solution for early detection of machinery malfunction and improve predictive maintenance. In manufacturing, sound-based condition monitoring coupled with data-driven maintenance can help significantly reduce unscheduled work stoppages, faulty products and waste of raw materials. Building management systems can be augmented by integrating real-time condition updates for critical machinery such as HVAC units, elevators, boilers and pumps, minimizing disruption for managers and users of those services. This technology is flexible, accurate and data-driven, potentially providing a low barrier to adoption for prospective customers and adaptability to various markets. Beyond predictive maintenance, applications include noise level monitoring for ensuring compliance in workplaces and airports, home and building security, early alert for traffic accidents, bio-acoustic monitoring of animal species, and outdoor noise monitoring at scale for improved enforcement in smart cities.<br/><br/>This I-Corps project further develops research at the intersection of artificial intelligence and the internet of things. The technology consists of a calibrated and highly accurate acoustic sensor with embedded sound recognition AI based on deep learning.  Sound conveys critical information about the environment that often cannot be measured by other means. In manufacturing, early stage machinery malfunction can be indicated by abnormal acoustic emissions. In smart homes and buildings, sound can be monitored for signs of alarm, distress or compliance.  Sound sensing is omnidirectional and robust to occlusion and contextual variables such as lightning conditions at different times of the day. Many existing solutions cannot identify different types of sounds or complex acoustic patterns, making them unsuited for these applications. This solution is both low cost and capable of identifying events and sources at the network edge, thus eliminating the need for sensitive audio information to be transmitted."
"1812963","CSR: Small: Collaborative Research: Safety Guard: A Formal Approach to Safety Enforcement in Embedded Control Systems","CNS","Computer Systems Research (CSR","08/01/2018","06/14/2018","Haibo Zeng","VA","Virginia Polytechnic Institute and State University","Standard Grant","Samee Khan","07/31/2021","$250,000.00","","hbzeng@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","7354","7923","$0.00","Ensuring the safety of embedded control systems, such as the ones used in cars, is remarkably difficult as shown by the many recalled cars in recent years, causing tens of billions of financial loss each year. This project aims to improve the safety of critical components in embedded control systems by developing safety guards, a reactive component generated automatically from safety requirements and attached to the original system, to ensure the combined system is safe even if the original system violates the safety requirements. <br/><br/>The intellectual merit of this project lies in the set of methods and tools to be developed for synthesizing safety guards of black-box systems. Specifically, this project consists of three research tasks: (a) building a benchmark suite of critical components and their safety requirements; (b) developing synthesis algorithms for constructing the finite-state machines (FSMs) of the safety guards; and (c) developing software synthesis tools for automatically generating software code that implements these FSMs. <br/><br/>This research project will benefit a wide range of application domains, including automotive and avionics, which will be investigated through collaborations with industry. It will help improve the safety of critical components, including those based on machine learning and artificial intelligence techniques. It will simplify certification since the relatively simple safety guard can be certified against safety requirements in place of the detailed model of a critical component. And last but not the least, it will simplify the development process by allowing people to focus on functionality and performance without worrying about safety violations at the same time. <br/><br/>The resulting software tools, together with evaluation benchmarks and experimental data, will be made available to the public. To facilitate dissemination and sharing, the project will maintain online documentations, tutorials, slides, and source code of the tool and benchmark repositories. Besides the research websites of participants at Virginia Tech and University of Southern California, the following website will be dedicated to disseminate the project results broadly: http://chaowang-vt.github.io/safetyguard/<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819157","Multigrid Methods and Machine Learning","DMS","COMPUTATIONAL MATHEMATICS","07/01/2018","06/14/2018","Jinchao Xu","PA","Pennsylvania State Univ University Park","Continuing grant","Miao-Jung Ou","06/30/2021","$113,936.00","Ludmil Zikatanov","xu@math.psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","MPS","1271","9263","$0.00","The goal of this project is to merge advanced tools from multigrid (MG) methods and machine learning (ML) towards the development of a novel class of numerical techniques targeting the data intensive applications emerging in physical, biological and social sciences.  Multigrid methods, including both geometric and algebraic multigrid (GMG and AMG) methods, are effective tools for solving linear as well as nonlinear algebraic system of equations arising from scientific and engineering computing.  On the other hand, there is a significant advancement in machine learning (ML) techniques, especially convolutional neural networks (CNN), which have successful applications in many areas such as image classification and processing.  The proposed project is to explore the resemblances and differences between these two different technologies so that more efficient multigrid methods as well more efficient deep learning models are developed.  The existing rich theory of multigrid method is expected to shed new light to the theoretical understanding of deep neural networks whereas the numerous empirical techniques used in the vast and ever-growning deep learning literature can be used to design general multigrid methods with wider range of applications.  This interdisciplinary research project is expected to have a direct impact to both the scientific computing community and the artificial intelligence industry.<br/><br/>More specifically, MG and CNN are similar for the use of multilevel hierarchy and the use of many technical components such as smoothers (MG) versus convolutions (CNN), restriction (MG) versus convolution with stride (CNN). But they also have some major differences: CNN has multiple channels of convolutions to be trained whereas MG often has one single smoother given a priori. Such relationships motivate the design of new multigrid methods with more general smoothers and restrictions that are subject training in different ways and, as a result, multigrid methods will become more adaptive and robust in its application to different practical problems.  The well-understood MG structure and theory can be adapted to understand and improve the existing deep learning model such as residual neural networks.  Furthermore, multilevel iterative techniques used in MG will also be investigated to speed up the stochastic gradient descent method that is now the standard training algorithm for most deep neural networks in machine learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1754798","Collaborative Research: Origin and Evolutionary Divergence of the Pancrustacean Brain","IOS","ORGANIZATION","07/01/2018","06/12/2018","Nicholas Strausfeld","AZ","University of Arizona","Continuing grant","Evan Balaban","06/30/2022","$161,437.00","","flybrain@neurobio.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","BIO","7712","1096, 9178, 9179","$0.00","It is still unknown when brains first appeared during the early history of life. The ways in which major brain parts that are structurally distinctive have changed over evolutionary time are also poorly understood. These knowledge gaps are partly due to the fact that fossil brains are rare and have been difficult to study. This project features scientists from three collaborating laboratories who will pool their resources to identify a set of invertebrate brain centers that mediate learning and memory. Structural and functional similarities and differences among these areas will be established across modern insect and crustacean species. The major question this research is answering is whether these brain centers share common genetic and computational attributes due to the brain?s fundamental organization being inherited by the descendants from a common ancestor; or, because brains that have arisen independently in different invertebrate groups are not able to perform certain functions unless brain areas that give them these same abilities have also arisen independently. These questions will be answered by precisely measuring the brain structures in fossilized invertebrate animals and comparing their basic arrangements with modern counterparts. The broader impact of this research will be to identify invertebrate proxies of the learning-and-memory brain centers found in vertebrate animals alive today, including humans. Identification of such proxies will inform us about how brains have evolved, and will contribute to a broader understanding of how memory centers are organized. The results will impact theories of, and research on, neural networks and artificial intelligence, and at the same time the scientists carrying out this research will develop novel strategies for identifying genealogical correspondence of brain structures across a very broad range of species. Brains analyzed for this research will be digitally reconstructed in 3D and uploaded to an open-source database for education and research purposes. The research will also provide advanced neuroscience structural analysis and genomics training to students from diverse backgrounds.<br/><br/>The neuronal organization and circuit properties of insect mushroom bodies are well known, as are their functional properties for learning and memory. While the existence of mushroom-body-like centers exist across arthropods, it is not known whether these phenotypically or genotypically correspond to the centers in insects. The planned research will identify mushroom body-like centers across a broad range of species, analyze their discrete neural arrangements, circuit organization, and molecular attributes. These comparisons will identify the species within and outside Arthropoda that possess functional and morphological correspondences in these structures. Transcriptomics will address whether phenotypically-corresponding centers share common genomic attributes, and whether there are unique genetic networks that define arthropod mushroom bodies or whether these networks differentiate mushroom bodies in different groups of arthropods such as in insects and crustaceans. The identification of broad phenotypic and genotypic homology of these centers across a broad phyletic spectrum would suggest an ancient origin of these learning and memory centers. Equally intriguing would be results suggesting convergent evolution of learning and memory centers across taxa.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816717","CSR: SMALL: Low-Latency Model Inference Using Cellular Batching","CNS","Computer Systems Research (CSR","09/01/2018","06/13/2018","Jinyang Li","NY","New York University","Standard Grant","Samee Khan","08/31/2021","$411,325.00","","jinyang@cs.nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","CSE","7354","7923","$0.00","Successful cloud deployment of machine learning services, such as language translation, image search and home assistants require a high performance serving system that can process hundreds of thousands requests per  second.  It is particularly crucial for the serving system to ensure low latency, as even tens of milliseconds increase in delays can annoy users when using a service like the home assistant.  Among the widely-used deep learning models, recurrent neural network (RNN) is an important class of models that incur high latency  when processed by existing serving systems.  This project aims to develop a new serving system that can handle a variety of Artificial Intelligence (AI) tasks using RNN-based deep learning models with significantly improved latency.<br/><br/>To achieve good throughput on modern hardware, one must perform batched computation.  This project develops a new, dynamic approach to batching, called Cellular Batching.  Cellular Batching performs batching and execution at the granularity of a ""cell"" (aka a subgraph with embedded model weights) instead of the entire dataflow graph, as is done in existing systems.  Under Cellular Batching, a new request can immediately join the execution of ongoing requests to minimize queuing delays and increase effective batching.  The project will complete research tasks that make Cellular Batching practical (by developing an efficient scheduler and supporting zero-downtime model upgrading) and generalize it to different models such as search-guided RNNs.<br/><br/>Deep learning models based on RNNs are becoming widely used to accomplish various AI tasks ranging from speech recognition and language translation, to question answering.  As such, there is a pressing demand for a high-throughput and low-latency serving system, in order to improve end-user experience and reduce the cost of deployment.  By demonstrating significant latency and throughput benefits, there is high potential for Cellular Batching to be widely adopted.  This project will also develop a new course component on high performance machine learning systems as part of the graduate-level distributed systems course.<br/><br/>This project will produce data in the form of source code, various serving benchmarks, and experimental results.  The source code and all benchmarks used in the experiments will be distributed via Github.  A local copy of the source code and the publications produced by the project will also be made available at the URL (http://batchmaker.news.cs.nyu.edu) for at least three years beyond the award period.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1819733","SBIR Phase I:  Measure What We Treasure: Developing a Structural Cognitive Analytics and Assessment (SCAA) Technology","IIP","SMALL BUSINESS PHASE I","06/15/2018","06/13/2018","Laura Cabrera","DC","Plectica LLC","Standard Grant","Rajesh Mehta","11/30/2018","$224,000.00","","lac19@cornell.edu","P O Box 42597","Washington","DC","200152604","6469418822","ENG","5371","5371, 8031, 8032","$0.00","This SBIR Phase I project will address the pedagogical and evaluative problems caused by our current inability to measure core outcomes beyond information recall. The proposed innovation makes important educational outcomes such as deep understanding, cognition (thinking skills) and awareness of thinking (metacognition) measurable. Reliable assessment of these outcomes has broad significance to education and society writ large, as many employers struggle with skills gaps between high school and college graduates and the professional, personal and societal demands on adults in the 21st Century. This research combines cognitive science, epistemology, systems science, and complex systems with new developments in artificial intelligence, including machine learning and neural networks, and aligns well with the NSF's mission to promote progress in science and advance national prosperity. This project not only has the potential to impact core tenets of educational practice - including how teachers teach, how learners learn, and how we measure and understanding knowledge - but also may have impact on science through increased ability to map and analyze patterns and common structures in knowledge and generally for Americans to increase their developmental skills and abilities. Beginning in an educational market valued at $8-15 billion, this project has the potential to catalyze significant job creation and have significant commercial impact across a range of related industries.<br/><br/>This SBIR Phase I project introduces a visual grammar for mapping ideas in a canvas-based environment, and provides a neural-network based mechanism for quantitatively comparing expressions of complex ideas along many dimensions to facilitate a new approach to thinking, learning, and assessment. Maps of ideas will be tokenized and serialized and then fed through a recurrent neural network model to produce encoded numeric vector representations that are meaningfully comparable in their encoded form. Once in this form, vectors will be compared and evaluated for content and structure similarity, and insights offered in many dimensions: depth of detail, understanding of relationships, and numerous other meaningful measures. These vectors enable scalable, consistent, constructive assessment in a way not previously possible. In the mapping environment, teachers and students will create maps either on their own, or collaboratively together in real-time. As users create maps, we use the generated vectors to analyze both content and structure, and then prompt users to think about their subject matter from new perspectives. As a means of evaluation, teachers will create mapping activities for students to complete, and then student maps will be quantitatively compared to the standards and target maps which represent the complete understanding of the topic.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1754770","Collaborative Research: Origin and Evolutionary Divergence of the Pancrustacean Brain","IOS","ORGANIZATION","07/01/2018","06/12/2018","Todd Oakley","CA","University of California-Santa Barbara","Continuing grant","Evan Balaban","06/30/2022","$250,000.00","","oakley@lifesci.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","BIO","7712","1096, 9178","$0.00","It is still unknown when brains first appeared during the early history of life. The ways in which major brain parts that are structurally distinctive have changed over evolutionary time are also poorly understood. These knowledge gaps are partly due to the fact that fossil brains are rare and have been difficult to study. This project features scientists from three collaborating laboratories who will pool their resources to identify a set of invertebrate brain centers that mediate learning and memory. Structural and functional similarities and differences among these areas will be established across modern insect and crustacean species. The major question this research is answering is whether these brain centers share common genetic and computational attributes due to the brain?s fundamental organization being inherited by the descendants from a common ancestor; or, because brains that have arisen independently in different invertebrate groups are not able to perform certain functions unless brain areas that give them these same abilities have also arisen independently. These questions will be answered by precisely measuring the brain structures in fossilized invertebrate animals and comparing their basic arrangements with modern counterparts. The broader impact of this research will be to identify invertebrate proxies of the learning-and-memory brain centers found in vertebrate animals alive today, including humans. Identification of such proxies will inform us about how brains have evolved, and will contribute to a broader understanding of how memory centers are organized. The results will impact theories of, and research on, neural networks and artificial intelligence, and at the same time the scientists carrying out this research will develop novel strategies for identifying genealogical correspondence of brain structures across a very broad range of species. Brains analyzed for this research will be digitally reconstructed in 3D and uploaded to an open-source database for education and research purposes. The research will also provide advanced neuroscience structural analysis and genomics training to students from diverse backgrounds.<br/><br/>The neuronal organization and circuit properties of insect mushroom bodies are well known, as are their functional properties for learning and memory. While the existence of mushroom-body-like centers exist across arthropods, it is not known whether these phenotypically or genotypically correspond to the centers in insects. The planned research will identify mushroom body-like centers across a broad range of species, analyze their discrete neural arrangements, circuit organization, and molecular attributes. These comparisons will identify the species within and outside Arthropoda that possess functional and morphological correspondences in these structures. Transcriptomics will address whether phenotypically-corresponding centers share common genomic attributes, and whether there are unique genetic networks that define arthropod mushroom bodies or whether these networks differentiate mushroom bodies in different groups of arthropods such as in insects and crustaceans. The identification of broad phenotypic and genotypic homology of these centers across a broad phyletic spectrum would suggest an ancient origin of these learning and memory centers. Equally intriguing would be results suggesting convergent evolution of learning and memory centers across taxa.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1747381","SBIR Phase I:  Game-Based Psychometric Assessments for College and Career Match","IIP","SMALL BUSINESS PHASE I","01/01/2018","12/26/2017","Allison Rosenberg","WA","posed2, Inc.","Standard Grant","Rajesh Mehta","10/31/2018","$224,885.00","","allisonrosenberg@live.com","1906 8th Ave. W","Seattle","WA","981192004","9196723442","ENG","5371","5371, 8031","$0.00","The broader social impact and commercial potential of this Small Business Innovation Research (SBIR) Phase I project reflects the increasing importance and proliferation of artificial intelligence and algorithmic systems in the educational arena and in other domains of human resources. This places the project strategically at the vanguard of scientific discovery, in building a technology tool that will serve society?s goals. In the post-secondary education and training domains, market inefficiencies require excess spending on both sides of the transaction, adversely affecting both supply and demand. As the nation continues to deliberate the value of higher education in the face of $1.3 billion in student loan debt, streamlining the college application process by matching students and institutions based on an applicant?s career goals can reduce costs for students, their families, and institutions alike. Outside the field of education, this project will impact workplaces where employer-employee matching algorithms will be used in recruiting, hiring, training, and team building, across the domains of health, innovation, national defense, and beyond. Ultimately, people analytics platforms have unlimited potential for national and international commercialization, thus generating tax revenue, creating jobs, and otherwise bolstering the economy. <br/> <br/>The proposed project focuses on the deployment of people analytics in the domain of college and career readiness and success. While talent evaluation through such innovative software is in its infancy, the small company's approach to college match will revolutionize how students identify their professional goals and then optimize their college experience for successful life launch. The small company's team of behavioral and data scientists, game designers, and software engineers, are creating video games that provide insights into a college applicant's career potential. Their platform captures massive amounts of micro-behavioral data -- how long players hesitate before making a move, persistence in the face of challenge or frustration, ability to parallel process -- to create a psychographic profile of the player's career-critical characteristics, including traits like competitiveness, extroversion, risk tolerance, and other enduring, personal traits difficult to discern through resumes and traditional, college application materials. Once a student's career objectives become clear, the company's proprietary recommendation engine suggests educational institutions and curricula best suited to attain the player?s career goals. In addition to expanding the game platform and collecting player data to develop and fine tune predictive algorithms, this project also will examine factors that influence a player's response to the insights and recommendations the platform provides. This work will investigate the impact of transparency, or ""scrutability"", of game-based assessments and implement visualization tools that promote the player's understanding of why specific recommendations are made."
"1657598","CRII: AF: Characterization and Complexity of Information Elicitation","CCF","CRII CISE Research Initiation, ALGORITHMIC FOUNDATIONS","06/01/2017","05/29/2018","Rafael Frongillo","CO","University of Colorado at Boulder","Standard Grant","Tracy J. Kimbrel","05/31/2019","$182,300.00","","raf@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","026Y, 7796","7796, 7932, 8228, 9251","$0.00","The way one judges the accuracy of predictions can greatly impact what predictions people or computers make.  For example, Glenn Brier argued in 1950 that the way meteorologists were evaluated would actually give them an incentive to distort the true probability of rain.  Brier's study inspired a growing body of work in statistics, economics, and now computer science, which studies evaluation metrics that incentivize accurate reports from people or machines.  These evaluation metrics are also used in machine learning, a branch of artificial intelligence, where a designer implicitly tells the computer what statistic to predict by providing only the evaluation metric itself.  This project seeks to mathematically characterize this link between statistics and evaluation metrics, and moreover, to understand the computational and statistical difficulty of evaluating different statistics.  A precise understanding of this link would provide new evaluation metrics with the potential to increase predictive power across a vast array of applications such as climate simulations and smart cities.  In particular, metrics for statistics that quantify uncertainty or risk could improve decision making in many fields, including healthcare, engineering, and finance.<br/><br/>A dominant algorithmic paradigm in machine learning, encompassing most regression techniques and classification algorithms, is that of empirical risk minimization (ERM): choosing a model from some class that best fits the data, according to some evaluation metric called a loss function.  A thread of research in theoretical machine learning called property elicitation gives a mathematical formalism to describe the link between loss functions and their corresponding statistics.  In these terms, this project seeks to characterize the statistics which have calibrated loss functions, and determine how many regression parameters or data points are required for the calibration to hold.  These questions are particularly relevant to machine learning when restricting attention to certain classes of loss functions which can be easily optimized or which have desirable statistical learning guarantees.  The class of statistics from mathematical finance known as risk measures, which are used to regulate banks, form an important focus of the project."
"1661356","Collaborative Research: ABI Innovation: Enabling machine-actionable semantics for comparative analyses of trait evolution","DBI","ADVANCES IN BIO INFORMATICS","09/01/2017","08/30/2017","Todd Vision","NC","University of North Carolina at Chapel Hill","Standard Grant","Peter H. McCartney","08/31/2020","$880,522.00","","tjv@bio.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","BIO","1165","9150","$0.00","The millions of species that inhabit the planet all have distinct biological traits that enable them to successfully compete in or adapt to their ecological niches. Determining accurately how these traits evolved is thus fundamental to understanding earth's biodiversity, and to predicting how it might change in the future in response to changes in ecosystems. Although sophisticated analytical methods and tools exist for analyzing traits comparatively, applying their full power to the myriad of trait observations recorded in the form of natural language descriptions has been hindered by the difficulty of allowing these tools to understand even the most basic facts implied by an unstructured free-text statement made by a human observer. The technological arsenal needed to overcome this challenge is now in principle available, thanks to a number of recent breakthroughs in the areas of knowledge representation and machine reasoning, but these technologies are challenging enough to deploy, orchestrate, and use that the barriers to effectively exploit them remains far too high for most tools. This project will create infrastructure that will dramatically reduce this barrier, with the goal of providing comparative trait analysis tools easy access to algorithms powered by machines reasoning with and making inferences from the meaning of trait descriptions. Similar to how Google, IBM Watson, and others have enabled developers of smartphone apps to incorporate, with only a few lines of code, complex machine-learning and artificial intelligence capabilities such as sentiment analysis, this project will demonstrate how easy access to knowledge computing opens up new opportunities for analysis, tools, and research. It will do this by addressing three long-standing limitations in comparative studies of trait evolution: recombining trait data, modeling trait evolution, and generating testable hypotheses for the drivers of trait adaptation.<br/><br/>The treasure trove of morphological data published in the literature holds one of the keys to understanding the biodiversity of phenotypes, but exploiting the data in full through modern computational data science analytics remains severely hampered by the steep barriers to connecting the data with the accumulated body of morphological knowledge in a form that machines can readily act on. This project aims to address this barrier by creating a centralized computational infrastructure that affords comparative analysis tools the ability to compute with morphological knowledge through scalable online application programming interfaces (APIs), enabling developers of comparative analysis tools, and therefore their users, to tap into machine reasoning-powered capabilities and data with machine-actionable semantics. By shifting all the heavy-lifting to this infrastructure, tools can programmatically obtain answers to knowledge-based questions that would otherwise require careful study by a human export, such as objectively and reproducibly assessing the relatedness, independence, and distinctness of characters and character states, with only a few lines of code. To accomplish this, the project will adapt key products and know-how developed by the Phenoscape project, including an integrative knowledgebase of ontology-linked phenotype data, metrics for quantifying the semantic similarity of phenotype descriptions, and algorithms for synthesizing morphological data from published trait descriptions. To drive development of the computational infrastructure and to demonstrate its enabling value, the project's objectives focus on addressing three concrete long-standing needs for which the difficulty of computing with domain knowledge is the major impediment: (1) computationally synthesizing, calibrating, and assessing morphological trait matrices from across studies; (2) objectively and reproducibly incorporating morphological domain knowledge provided by ontologies into evolutionary models of trait evolution; and (3) generating testable hypotheses for adaptive diversification by incorporating semantic phenotypes into ancestral state reconstruction and identifying domain ontology concepts linked to evolutionary changes in a branch or clade more frequently than expected by chance. In addition, to better prepare evolutionary biologist users and developers of comparative analysis tools for adopting these new capabilities, a domain-tailored short-course on requisite knowledge representation and computational inference technologies will be developed and taught. More information on this project can be found at http://cate.phenoscape.org/."
"1757885","REU Site: BME Community of Undergraduate Research Scholars for Cancer (BME CUReS Cancer)","EEC","HUMAN RESOURCES DEVELOPMENT","06/01/2018","04/09/2018","Mia Markey","TX","University of Texas at Austin","Standard Grant","Mary Poats","05/31/2021","$397,808.00","Laura Suggs","mia.markey@utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","ENG","1360","116E, 9178, 9250","$0.00","The BME Community of Undergraduate Research Scholars for Cancer (BME CUReS Cancer) REU Site at the University of Texas (UT) at Austin will provide opportunities for a diverse group of talented undergraduates traditionally underrepresented in engineering to make contributions towards the fundamental understanding of the physical principles of cancer development, prevention, and treatment during a ten-week summer research experience. An aim of this research experience is that the Scholars will be inspired to go on in their careers to function in multi-disciplinary teams of researchers from disparate fields in engineering, medicine, biological science, physical science, and healthcare fields to advance human health. The Site's partnership with the UT Medical School and Texas 4000, a non-profit organization that cultivates student leaders and engages communities in the fight against cancer, will help to increase public awareness of cancer research, in particular how physical science and engineering positively impact healthcare.<br/><br/>Cancer is a disease of complexity and engineering principles in particular are developed to study, model, and solve complex problems. The scientific theme of the BME CUReS Cancer Site is leveraging Biomedical Engineering to Open a New Frontier in Oncology. BME CUReS Cancer Scholars will be matched with a project of appropriate scope from 35 different laboratories representing a wide range of research topics pertinent to cancer research, such as biomaterials, drug delivery, optical imaging, medical imaging, and artificial intelligence in medicine. These topics were selected in response to the barriers to achieving progress in cancer research that have been identified by the National Cancer Institute. It is now broadly recognized that understanding how the range of physical laws and principles governing the behavior of all matter are operative in cancer at every scale will be critical to understanding and controlling cancer. Cancer is a disease of complexity and engineering principles in particular are developed to study, model, and solve complex problems. Biomedical Engineering is uniquely poised to make a significant intellectual contribution to addressing these key challenges in cancer<br/>research using an engineering approach.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1717896","AF: Small: Efficiently Learning Neural Network Architectures with Applications","CCF","ALGORITHMIC FOUNDATIONS","09/01/2017","06/26/2017","Adam Klivans","TX","University of Texas at Austin","Standard Grant","Tracy J. Kimbrel","08/31/2020","$449,920.00","","klivans@cs.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","7796","7923, 7926","$0.00","In the last few years there have been several breakthroughs in machine learning and artificial intelligence due to the success of tools for learning ""deep neural networks"" including the best computer program for playing Go, the best programs for automatically playing Atari games, and the best tools for several fundamental object-recognition tasks.  These are considered some of the most exciting new results in all of computer science.<br/><br/>From a theoretical perspective, however, the mathematics underlying these neural networks is not as satisfying.  We have few rigorous results that explain how and why heuristics for learning deep neural networks perform so well in practice. The primary research goal of this proposal is to develop provably efficient algorithms for learning neural networks that have rigorous performance guarantees and give applications to related problems from machine learning.  Given the ubiquity of machine learning algorithms, this research will have direct impact on data science problems from a diverse set of fields including biology (protein interaction networks) and security (differential privacy).  The PI is also developing a new data mining course at UT-Austin that will incorporate the latest research from these areas.<br/><br/>A central technical question of this work is that of the most expressive class of neural networks that can be provably learned in polynomial time.  Furthermore, the algorithm should be robust to noisy data.  A neural network can be thought of as a type of directed circuit where the internal nodes compute some activation function of a linear combination of the inputs.  The classical example of an activation function is a sigmoid, but the ReLU (rectified linear unit) has become very popular.  In a recent work, the PI showed that a neural network consisting of a sum of one layer of sigmoids is learnable in fully-polynomial time, even in the presence of noise.  This is the most expressive class known to be efficiently learnable.  Can this result be extended to more sophisticated networks?  This question has interesting tie-ins to kernel methods and kernel approximations.<br/><br/>For the ReLU activiation, the PI has shown that this problem is most likely computationally intractable in the worst case.  The intriguing question then becomes that of the minimal assumptions needed to show that these networks are computationally tractable.  In a recent work, the PI has shown that there are distributional assumptions that imply fully-polynomial-time algorithms for learning sophisticated networks of ReLUs.  Can these assumptions be weakened?  This work has to do with proving that certain algorithms do not overfit by using compression schemes.  Another type of assumption that the weights of the unknown network are chosen in some random way (as opposed to succeeding in the worst-case).  This corresponds to the notion of random initialization from machine learning.  Can we prove a type of smoothed analysis for learning neural networks, where we can give fully-polynomial-time learning algorithms for almost all networks?<br/><br/>Finally, in this proposal we will explore what other tasks can be reduced to various types of simple neural network learning.  For example, the problem of one-bit compressed sensing can be viewed as learning a threshold activation using as few samples as possible.  Still, we lack a one-bit compressed sensing algorithm that has optimal tolerance for noise.  Another canonical example is matrix or tensor completion, where it is possible to reduce these challenges to learning with respect to polynomial activations.  Finding the proper regularization to ensure low sample complexity is an exciting area of research."
"1725743","SPX: CISIT: Computing In Situ and In Memory for Hierarchical Numerical Algorithms","CCF","SPX: Scalable Parallelism in t","10/01/2017","09/11/2017","George Biros","TX","University of Texas at Austin","Standard Grant","M. Mimi McClure","09/30/2020","$800,000.00","Lizy John, Andreas Gerstlauer","gbiros@gmail.com","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","042Y","026Z, 9229","$0.00","High performance computing holds an enormous promise for revolutionizing science, technology, and everyday life through modeling and simulation, statistical inference, and artificial intelligence.  Despite the numerous successes in software and hardware technologies, energy efficiency barriers have become a major hurdle towards more powerful computers -- from mobile devices all the way to supercomputers. The originally natural separation between the memory subsystem and the central processing unit (CPU) of a computer has emerged as one the main reasons for energy inefficiency. Data movement between the memory and the CPU requires orders of magnitude more energy than the computations themselves. To address these challenges, this project will consider novel architectural design paradigms and algorithms that are aimed at blurring these traditional boundaries between separated memory and computation subsystems and, by distributing computations to be performed directly in the memory or as part of the memory data transfers, achieve order of magnitude gains inenergy efficiency and performance. This project will investigate such novel approaches in the context of a class of methods in computational mathematics, which appear at the core of many problems in computational science, large-scale data analytics, and machine learning.<br/><br/>Specifically, this project will focus on data-driven rather than compute-driven co-design of algorithms and architectures for the construction, approximation, and factorization of hierarchical matrices. The end-goal of the project is the design of a novel architecture, CISIT (for ``Computing In Situ and In Transit''), that specifically aims to address acceleration of both computation and data movement in the context of hierarchical matrices. CISIT will uniquely combine traditional general-purpose CPU and GPU cores with: (1) acceleration of core algorithmic primitives using custom hardware; (2) in-situ computing capabilities that will comprise both processing in or near main memory as well as computing within on-chip caches and memory close to the cores; (3) novel in-transit compute capabilities that will enable cutting down on and in many cases completely eliminating unnecessary roundtrip data transfers by processing of data transparently as it is transferred between main memory and local compute cores across the cache hierarchies. Upon success, CISIT will influence future architectural implementations.  Along with the research activities, an educational and dissemination program will be designed to communicate the results of this work to both students and researchers, as well as a more general audience of computational and application scientists."
"1814369","NSF-BSF:  SHF: Small: Certifiable Verification of Large Neural Networks","CCF","SOFTWARE & HARDWARE FOUNDATION","10/01/2018","05/23/2018","Clark Barrett","CA","Stanford University","Standard Grant","Nina Amla","09/30/2021","$480,924.00","","barrett@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7798","7923, 8206","$0.00","Software systems play important roles in almost every area of modern life.  In order to reduce the difficulty of developing new software, research in the field of artificial intelligence (AI) has been promoting a new model of programming: instead of having a human engineer design and code algorithms, a set of training examples are used together with machine-learning algorithms to automatically extrapolate software implementations. In classical programing, because such code is written by humans, we can persuade others that it is correct. In machine-learned systems, however, the program amounts to a highly complex mathematical formula for transforming inputs into outputs. The key difficulty, however, is that it is not possible currently to reason about correctness in such systems.<br/><br/>This project addresses this issue by developing an algorithm, called Reluplex, capable of proving properties of deep neural networks (DNNs) or providing counter-examples if the properties fail to hold.  The project has three main objectives. First, the investigators develop algorithmic techniques to greatly reduce the number of states that need to be explored by a verification tool.  Second, they develop a strategy for producing checkable verification proofs.  Checkable correctness proofs make it unnecessary to rely on correctness of the verification tool; one can instead rely only on the correctness of a small trusted proof-checker.  Finally, the investigators implement this approach in an open-source tool and evaluate it on real-world industrial DNNs. Given that AI components are becoming ubiquitous in safety-critical systems, such as autonomous vehicles, this research will increase trust in these systems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1554123","CAREER: Locally Adaptive Nonparametric Estimation for the Modern Age - New Insights, Extensions, and Inference Tools","DMS","STATISTICS, Division Co-Funding: CAREER","07/01/2016","05/23/2018","Ryan Tibshirani","PA","Carnegie-Mellon University","Continuing grant","Gabor J. Szekely","06/30/2021","$231,216.00","","ryantibs@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","MPS","1269, 8048","1045","$0.00","Nonparametric modeling---which means, roughly, flexible modeling of smooth trends without specific assumptions about their form or shape---finds diverse applications in many areas such as epidemiology, astrophysics, finance, and artificial intelligence. It is also a field ripe for modern statistical development, since nonparametric models are in a sense even more appealing in the ""big data"" era, as it is precisely in data-rich settings that the increased flexibility of these models will begin to show real rewards in terms of statistical accuracy. The proposed work will develop nonparametric methods (and affiliated software) that will be useful to data scientists who model smooth, nonlinear trends in areas like those mentioned above, as well as many others. A specific scientific emphasis will be the forecasting of influenza and dengue fever. Such forecasts will help policy makers design and implement more effective countermeasures towards these diseases. The proposal puts forward two main ideas for educational training, closely related to the research aims to be pursued. The first is a set of short videos on nonparametric smoothing, intended as supplements to an undergraduate level course called Advanced Methods for Data Analysis. They will be integrated with an interactive quiz system, and will be made freely available (on YouTube) so that others outside the class may watch too. The second idea is a statistical computation training group, for PhD students from Statistics and Computer Science.<br/><br/>""Locally adaptive"" nonparametric methods offer more fine-grained flexibility than traditional nonparametric methods, in that they can simultaneously represent different amounts of smoothness at different parts of the function domain. Currently, locally adaptive nonparametric methods are not often used in big, modern data sets, likely because of their computational inefficiency, and the general inavailability of locally adaptive methods in many modern problem settings. The proposed work seeks to change this, and to push the state of the art in modern locally adaptive nonparametric estimation. The research aims are to: deepen the theoretical understanding of existing locally adaptive methods for univariate problems; efficiently scale these methods and extend these theories to problems where data are collected in high dimensions and over graphs; and develop inferential tools for all of these locally adaptive procedures. The specific contributions will be balanced between the theoretical (statistical theories that describe the underpinnings of the methods in question) and computational (practical algorithms that describe implementation of these methods at scale) perspectives. A final more applied research aim is to use the proposed methods to improve and extend a forecasting system for major epidemics such as influenza and dengue fever."
"1832831","Summer 2018 Causal Inference Workshops","DMS","STATISTICS","05/15/2018","05/22/2018","Alexander Volfovsky","NC","Duke University","Standard Grant","Gabor J. Szekely","04/30/2019","$30,000.00","","alexander.volfovsky@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","MPS","1269","7556","$0.00","This award provides partial support for new researchers to attend two conferences on causal inference in summer 2018: The Atlantic Causal Inference Conference (ACIC) held in Pittsburgh, PA on May 22-23, 2018 and the Causal Workshop at the Conference on Uncertainty in Artificial Intelligence (UAI)  held in Monterey, CA on August 6-10, 2018. Both conferences serve as flagship gatherings of leaders in reasoning about causes of observed effects.  In recent years, causal inference has seen important advances, especially through a dramatic expansion in its theoretical and practical domains. Machine learning methods have focused on ultra-high-dimensional models and scalable stochastic algorithms, whereas more classical causal inference has been guiding policy in complex domains involving economics, social and health sciences, and business. Through such advances, a powerful cross-pollination has emerged as a new set of methodologies promising to deliver more robust data analysis than each field could individually.<br/><br/>The primary purpose of the two conferences is to advance the study of causal inference and to bridge gaps between different communities within causal inference, by promoting interaction and networking among new researchers. At both conferences, the supported participants will present their research via invited and contributed talks or via poster presentations. Since the conferences draw on causal inference communities in statistics, biostatistics, computer science, and other disciplines, these conferences present a great opportunity for new researchers to see the breadth of opportunities for research and collaboration in this area.  More information is available at the conference web sites:<br/><br/>ACIC: https://www.cmu.edu/acic2018/ <br/><br/>UAI: https://sites.google.com/view/causaluai2018<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1527497","AF: Small: Using Ordinal Information to Approximate Cardinal Objectives in Social Choice, Matching, Group Formation, and Assignment Problems","CCF","ALGORITHMIC FOUNDATIONS","06/15/2015","02/22/2016","Elliot Anshelevich","NY","Rensselaer Polytechnic Institute","Standard Grant","Tracy J. Kimbrel","05/31/2019","$350,470.00","","eanshel@cs.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","7796","7923, 7926, 7932, 9251","$0.00","Many modern algorithms must make decisions using only limited information: they not only need to make the best choices given the input, but also don't know what the ""true"" input actually is; and yet they are required to make good choices anyway. This problem arises often in settings where the goal is to maximize the total happiness (a.k.a. social welfare or total utility) of the system, such as social choice settings in which voters submit their preferences for different alternatives, matching settings (e.g., matching people with job openings or organ donors with patients), assigning people to groups or projects, economic market settings, and many others. In all of these settings, the people or agents involved may care deeply about which outcome is selected (e.g., which alternative is selected by the voting mechanism, or which patients are assigned a donated kidney), with the mechanism designer's goal being to maximize the overall welfare and satisfaction. Unfortunately, in all these applications, only limited information is usually available: it is relatively easy to obtain *ordinal* information (which choice is preferred to which other choice by each participant), but almost impossible to obtain the underlying numerical information (how *much* each choice is preferred by each participant). This project will use a novel notion of approximation to give new insight into the design and evaluation of many mechanisms for the settings mentioned above. The approximation algorithms resulting from this project will be used to suggest new protocols, which would not only optimize some notion of fairness (as is common in social choice), or maximize the size of a matching (as is common in kidney exchange), but would have provable guarantees on the quality of the outcomes. One reason why such guarantees have not been considered in the past is that without the knowledge of exact numerical utilities or exact compatibilities between matches, protocols can only rely on ordinal, or otherwise limited, information. However, as preliminary work shows, one can often design algorithms which behave well no matter what the *true* information is, as long as the underlying (unknown) numerical values have some reasonable structure, or are at least correlated in some way, which is certainly the case for most applications. Because of this, this project will provide a different perspective, and will result in algorithms which produce provably good outcomes while using only limited ordinal information.  Due to the applications touched by this project, the work done should be of interest to researchers in many fields, including Social Choice, Artificial Intelligence, Game Theory, Social Networks, and Economics. This research will be strongly complemented by the PI's education plan, which includes teaching several courses with research components, presenting this work at numerous scientific seminars, and recruiting several graduate and undergraduate students to work on this project.<br/><br/>The primary goal of this project is to design and analyze algorithms which only know ordinal information, and yet create solutions which are provably close to the ""true"" optimal solution: the one which would be chosen if the full numerical information were known. The project will specifically focus on the settings of social choice, matching, group formation, and economic markets. Very little is known about approximation algorithms in the presence of ordinal information, and designing such algorithms for the settings above will likely require new and interesting techniques. When the numerical values are completely uncorrelated, it is of course impossible to form good approximations from only ordinal information, so this work will involve looking at different kinds of correlations (e.g., lying in a metric space, symmetric values, values from a common distribution, etc), and determining how much power this structure gives to the ordinal information, as compared to the true numerical information. The PI will also consider optimization problems with other interesting constraints which deserve further study, focusing especially on computing good solutions in the presence of self-interested agents, in the contexts of social choice, matching, and envy-free pricing. This work should lead to basic understanding of the fundamental power of ordinal information, by determining under which settings and conditions ordinal information is enough to approximate the numerical truth, and when such an approximation is impossible."
"1816372","AF: Small: Parallels in Approximability of Discrete and Continuous Optimization Problems","CCF","ALGORITHMIC FOUNDATIONS","10/01/2018","05/22/2018","Madhur Tulsiani","IL","Toyota Technological Institute at Chicago","Standard Grant","Rahul Shah","09/30/2021","$497,239.00","","madhurt@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372803","7738340409","CSE","7796","7923, 7926","$0.00","Optimization problems arise naturally in many areas such as scheduling, artificial intelligence, software engineering, control of robotic systems, statistics and machine learning. Many of these problems require too long to solve exactly - a common approach for dealing with this has been to design techniques which can efficiently find approximate solutions that are 'good enough' for the task at hand. The study of what approximations are best possible, as well as methods for achieving them, has also led to many new ideas in theoretical computer science, leading to a rich mathematical theory. This project considers several such problems (arising in different areas) which represent challenges to our current understanding. The goal of the project is to develop unified techniques for solving and analyzing them. The project includes several opportunities for training and mentoring of graduate and undergraduate students. Another aim of the project is to develop a collaborative forum for theoretical computer science students in the Chicago area, which can be used to discuss technical ideas and develop expository material.<br/><br/>This project considers various problems in discrete and continuous optimization, which represent bottlenecks for algorithmic techniques for designing approximation algorithms, as well as for techniques proving hardness of approximation. The difficulty of understanding many of these problems arises from the fact that many of them only impose a relatively weak global constraint on the solutions, which is hard to exploit algorithmically and also not amenable to techniques for proving inapproximability. The project considers several continuous optimization problems which offer an ideal testbed for the development of new algorithmic techniques, while still capturing the bottlenecks in proving inapproximability of related discrete problems. The aim of this project is to examine such problems from the following perspectives: (1) average-case hardness and lower bounds for the Sum-of-Squares hierarchy of convex relaxations; (2) techniques and barriers for proving inapproximability; and (3) conditions under which good approximations are achievable.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1704656","AF: Large: Collaborative Research: Nonconvex Methods and Models for Learning: Towards Algorithms with Provable and Interpretable Guarantees","CCF","ALGORITHMIC FOUNDATIONS","06/01/2017","04/20/2018","Rong Ge","NC","Duke University","Continuing grant","Rahul Shah","05/31/2022","$202,246.00","","rongge@cs.duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7796","7925, 7926, 9251","$0.00","Artificial Intelligence along with Machine Learning are perhaps the most dominant research themes of our times - with far reaching implications for society and our current life style. While the possibilities are many, there are also doubts about how far these methods will go - and what new theoretical foundations may be required to take them to the next level overcoming possible hurdles. Recently, machine learning has undergone a paradigm shift with increasing reliance on  stochastic optimization to train highly non-convex models -- including but not limited to deep nets. Theoretical understanding has lagged behind, primarily because most problems in question are provably intractable on worst-case instances. Furthermore, traditional machine learning theory is mostly concerned with classification, whereas much practical success is driven by unsupervised learning and representation learning. Most past theory of representation learning was focused on simple models such as k-means clustering and PCA, whereas  practical work uses vastly more complicated models like autoencoders, restricted Boltzmann machines and deep generative models. The proposal presents an ambitious agenda for extending theory to embrace and support these practical trends, with hope of influencing practice. Theoretical foundations will be provided for the next generation of machine learning methods and optimization algorithms. <br/><br/>The project may end up having significant impact on  practical machine learning, and even cause a cultural change in the field -- theory as well as practice -- with long-term ramifications. Given the ubiquity as well as  economic and scientific implications of machine learning today, such impact will extend into other disciplines, especially in (ongoing) collaborations with researchers in neuroscience. The project will train a new generation of machine learning researchers, through an active teaching and mentoring plan at all levels, from undergrad to postdoc. This new generation will be at ease combining cutting edge theory and applications. There is a pressing need for such people today, and the senior PIs played a role in training/mentoring several existing ones.<br/> <br/>Technical contributions will include new theoretical models of knowledge representation and semantics, and also frameworks for proving convergence of nonconvex optimization routines. Theory will be developed to explain and exploit the interplay between representation learning and supervised learning that has proved so empirically successful in deep learning, and seems to underlie new learning paradigms such as domain adaptation, transfer learning, and interactive learning. Attempts will be made to replace neural models with models with more ""interpretable""  attributes and performance curves.  All PIs have a track record of combining theory with practice. They  are also devoted to a heterodox research approach, borrowing from all the past phases of machine learning: interpretable representations from the earlier phases (which relied on logical representations, or probabilistic models), provable guarantees from the middle phase (convex optimization, kernels etc.), and an embrace of nonconvex methods from the latest deep net phase. Such eclecticism is uncommon in machine learning, and may give rise to new paradigms and new kinds of science."
"1826506","Designing Materials to Revolutionize and Engineer our Future March 26th & 27th 2018 Meeting","DMR","DMREF","02/15/2018","02/13/2018","William Bentley","MD","University of Maryland College Park","Standard Grant","John Schlueter","01/31/2019","$99,997.00","Gregory Payne","bentley@eng.umd.edu","3112 LEE BLDG 7809 Regents Drive","COLLEGE PARK","MD","207425141","3014056269","MPS","8292","054Z, 7556, 8400","$0.00","Non-technical description: This grant funds a workshop to bring together Materials Genome Initiative (MGI) grantees and program managers from the National Science Foundation (NSF) and the Department of Energy (DOE), along with those from other federal agencies including the National Institute of Standards and Technology (NIST) and the Department of Defense (DoD). As NSF's response to the President's Materials Genome Initiative, the Designing Materials to Revolutionize and Engineer our Future (DMREF) program seeks to foster tight collaborations between materials researchers in experiment, theory, and computation. These collaborations are founded on highly iterative feedback loops in which experimental results directly inform theory and computation, and vice versa, with the goal of accelerating the discovery and development of new materials. The workshop provides researchers a forum to share their research results and discuss cross-cutting topics related to establishing and sustaining research collaborations, managing digital data, and supporting long-term simulation software development. <br/><br/>Technical description: Researchers that are participating in Material Genome Initiative projects provide leadership to the broader materials research community by implementing strategies to achieve the goals set out by this Initiative, including reducing both the cost and time it takes to bring a new material to market. The goals of the workshop are to: 1) Identify successes of the MGI, 2) Promote data-driven research, artificial intelligence, and machine learning for materials discovery and development, 3) Transition fundamental research along the Materials Development Continuum toward eventual deployment, and 4) Identify mechanisms for MGI principal investigators (PIs) to partner with those at other laboratories. Overarching themes identified through presentations, break-out sessions, and discussions will be presented in a report for dissemination to the broader materials research community. MGI projects are developing tools that are made available to aid research of the larger community and this workshop presents the most effective ways to implement this task. The workshop, which will be held in College Park, Maryland on March 26-27, 2018, follows in a series of successful workshops, the latest being held in Bethesda, Maryland January 11-12, 2016."
"1758684","SBIR Phase II:  Predicting Healthcare Fraud, Waste and Abuse by Automatically Discovering Social Networks in Health Insurance Claims Data through Machine Learning","IIP","SMALL BUSINESS PHASE II","04/01/2018","04/04/2018","PARTHA DATTA RAY","CA","Albeado, Inc","Standard Grant","Nancy Kamei","03/31/2020","$749,897.00","","partha.dattaray@albeado.com","5201 Great America Parkway","Santa Clara","CA","950541157","4083167831","ENG","5373","5373, 8018, 8023, 8032, 8042","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will usher new Artificial Intelligence/Machine Learning (AI/ML) products delivering high accuracy with explainability. Without rationale behind predictions, decision makers can't trust and effectively use AI/ML solutions.  Outcome of R&D through this project would lead to more accurate and faster detection with appropriate explanation of anomalous interactions and recommend effective controls to 1) eliminate billions of dollars of fraud, waste and abuse (FWA) in Health Insurance  markets;  2) lower costs, improve quality and speed of Health Care delivery to consumers; and 3) promote new markets in Personalized Health and Smart Health sector for  emerging Medical Internet-of-Things (IOT) devices and systems, enabling economic growth.  The results of this research are expected to enable the discovery of medical anomaly together with advancing the detection of new types of FWA. The boost in detection accuracy with explanation will save hundreds of millions of dollars. Societal impact includes reduced costs to consumers and taxpayers through better FWA control and advance health outcome through early medical IOT anomaly detection. More broadly, the system is expected to detect possible opioid or substance abuse epidemic cohorts, under/over-medication, advanced alerts for community health anomalies.<br/><br/>The proposed project will extend and generalize a novel machine learning method to solve the Fraud, Waste, and Abuse (FWA) problem in health insurance, coupled with explanatory capability providing rational behind predictions and operationalized in a distributed parallel computing framework for scaling. The technical problem is how to combine relations between entities (e.g., doctors) with their attribute (e.g., a doctor's prescription history). This project advances the state of the art by combining relations between rows in the training data (e.g. doctors) with standard machine learning to improve prediction accuracy while facilitating local explanation. The result is vastly improved prediction accuracy with explainability. Thus, the method uses network information to fill in the gaps of entity information alone and vice versa while facilitating explanation for a test case. This method is expected to significantly improve the ability to detect FWA and pave ways for multi Billion dollars savings, call out IOT-based medical anomaly in advance to improve health outcome and build trust in the predictions for the decision makers through the explanations provided. The team intends to deliver not only the accuracy boost with explainability, but a fully operational system with automated data pipeline, parallel and distributed algorithmic processing framework which can be deployed on a SaaS basis or an enterprise solution.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1812478","RUI: Compressive Sensing and Neuronal Network Structure-Function Relationships","DMS","MATHEMATICAL BIOLOGY","06/15/2018","05/16/2018","Victor Barranca","PA","Swarthmore College","Standard Grant","Junping Wang","05/31/2021","$140,301.00","","vbarran1@swarthmore.edu","500 COLLEGE AVE","Swarthmore","PA","190811390","6103288000","MPS","7334","8091, 9229","$0.00","The human brain is a complex network of billions of neurons whose intricate connectivity largely determines perception and behavior. To understand brain function, it is therefore paramount to efficiently measure and analyze neuronal network architecture. However, measuring the connectivity of large neuronal networks remains a challenge both experimentally and theoretically. An often more tractable approach to reconstructing connectivity in complex networks is to instead measure the dynamics of neurons of interest, and then use mathematical approaches to infer the network connectivity. This project will utilize the widespread sparsity found in brain networks to develop an efficient mathematical framework for reconstructing neuronal connectivity from limited measurements of neuronal dynamics. Upon accurately recovering the architecture of neuronal networks, this project will investigate how the sparse structure of natural stimuli impacts the early development of neuronal connectivity and what functional implication this has in the encoding of diverse classes of sensory signals. Analyzing the neuronal dynamics that optimally encode network connectivity and stimulus information, this project will provide new insights into sensory processing and abnormal brain function. In formulating novel methodologies for processing dynamic network data, this project will inform advances in artificial intelligence and prosthetics. This work will actively involve undergraduate students in all phases of research, promoting interdisciplinary scientific collaboration and deepening the scope of applied mathematics education for a diverse spectrum of students.<br/><br/>With the increasing prevalence of network models in the mathematical sciences, accurately measuring network structure and understanding its relationship with network function is of broad scientific importance. In neuroscience in particular, efficiently measuring large-scale brain connectivity and determining its impact on cognitive function is inherently challenging yet fundamental in characterizing the nature of computation in the brain. This project will formulate a novel framework for the reconstruction and characterization of neuronal connectivity by taking advantage of the widespread network sparsity found in the brain and utilizing recent advances in compressive-sensing (CS) theory.  Key facets of the project are to: (1) develop a novel CS-based mean-field approach for efficiently reconstructing sparse connections in physiological neuronal networks based on underlying input-output mappings embedded in the nonlinear network dynamics; (2) analyze the role of the balanced network operating regime in CS reconstruction of recurrent network connectivity; (3) investigate the basis for structural motifs in the visual system through supervised learning of neuronal connectivity aimed at optimized compressive encoding of sparse visual stimuli; and (4) characterize the functional role of  receptive field structure in the encoding of natural scenes through compressive network dynamics and the manifestation of related deficiencies in processing non-natural scenes, such as illusory images. This work will underline how the network dynamical regime impacts the inference of structural connectivity and network inputs from neuronal dynamics, improving the scale over which neuronal connectivity can be determined and providing novel insights into abnormal information processing in the brain.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816512","SHF: Small: Fault Model Evaluation and Discovery","CCF","SOFTWARE & HARDWARE FOUNDATION","06/01/2018","05/16/2018","Ronald Blanton","PA","Carnegie-Mellon University","Standard Grant","Sankar Basu","05/31/2021","$446,330.00","","blanton@ece.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7798","7923, 7945, 9102","$0.00","Integrated electronic circuits (ICs) today are ubiquitous in that they affect every aspect of our daily lives, ranging from use within all forms of mobile devices (smart phones, laptops, etc.) to all modes of transportation (cars, aircraft, etc.). Advances in electronics also form the foundation for the recent and forthcoming advances in machine learning, artificial intelligence, autonomous vehicles, etc.  The research work stemming from the project will aid the continued advancement of the electronic semiconductor industry by helping leading companies ensure that electronics work properly and reliably over long time periods. Additionally, the research conducted will include undergraduate student researchers, and the results will be disseminated to the research community, and incorporated into post-secondary curriculum.<br/><br/>The research will specifically examine how electronic failures are modeled, and for any shortcomings discovered, new models that are more accurate will be developed. While it is widely known that model effectiveness greatly depends on the IC and its fabrication, it is not known which models will be proven ineffective beforehand. In addition, especially for cutting-edge technologies, it is expected that there also will be a need for new, more accurate fault models for state-of-the-art ICs. Therefore, the objective of this research is to develop a comprehensive data-driven methodology for the continuous evaluation and development of fault models. Data from failed ICs will be analyzed to understand the likelihood and types of failures. For the expected mismatch between existing models and measured data, new models will be proposed and evaluated. Successfully meeting the objective of this research would will enable IC manufacturers to produce more reliable ICs at much lower cost.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1662731","Collaborative Research: Computational Design of Metal-Organic Framework Materials","CMMI","Design of Eng Materials (DEMS)","06/15/2017","06/13/2017","Matthew Campbell","OR","Oregon State University","Standard Grant","Richard Malak","05/31/2020","$274,135.00","","matt.campbell@oregonstate.edu","OREGON STATE UNIVERSITY","Corvallis","OR","973318507","5417374933","ENG","8086","024E, 067E, 073E","$0.00","This award supports research in computational methods for the automatic exploration of the search space of metal-organic frameworks to obtain desired combinations of mechanical, thermal and chemical properties. A metal-organic framework is a repeating three-dimensional crystal lattice with a large open space-frame structure composed of organic linking molecules bonded to inorganic nodal units. The interconnected pore-spaces in these materials endow them with a rich variety of unusual properties that can be exploited for gas storage, gas separation, and catalysis. Given the constraints of chemical bonds and bond angles, one cannot easily customize the lattice for a particular size and shape. Thankfully there is an astronomically large number of permutations for combining various atomic elements together. However, human designers are confounded on how to find one for their particular problem domain. What is needed is a computational process to search the space for a best solution. By formalizing the molecular design as a decision tree, the developed computer algorithms will invent new materials whose functional behavior is defined by its chemical makeup and the resulting geometry and movement of the lattice structure. As part of testing the design approach, the project will address two technologically important problems:  designing new metal organic frameworks optimized for gas storage, and materials for separating isomers in industrially important chemical feed stocks. STEM outreach activities to high school students and teachers will also be performed.<br/><br/>Specifically, the project seeks materials that exhibit highly chemically selective adsorption or permeability of gases through mechanisms that arise from chemical, steric, and vibrational behavior of the frameworks. The computational search for this incorporates a unique graph transformation approach that mimics correct stoichiometric reactions and leads to a large search tree that is amenable to recent advances in artificial intelligence planning algorithms. Furthermore, machine learning methods will establish a link between the structure and function of organic frameworks by leveraging data from complex molecular simulations. This will lead to more efficient search of the decision tree so that meaningful results can be obtained. Through detailed simulations of the resulting metal organic frameworks, the researchers will publish how their new materials can be used to tackle challenging problems in energy storage, high-tech manufacturing, and the creation of new sensitive sensor equipment."
"1724753","Inductive learning of nonlocal phonological interactions","BCS","LINGUISTICS","08/01/2017","08/08/2017","Gillian Gallagher","NY","New York University","Standard Grant","William J. Badecker","01/31/2021","$214,541.00","Maria Gouskova","geg4@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","SBE","1311","1311, 9179","$0.00","Language is a fundamental and universal aspect of human cognition. Linguistic research over the past five decades has established that language structure is governed by detailed rules. These rules constrain meanings, sentences, words, and sound patterns--the focus of the proposed research. For many years, sound structure was investigated primarily by theorizing. More recently, linguists have begun to test these theories using experiments and computational models. Computational models are valuable because they can only be created based on a complete and explicit understanding of the underlying rules. If the model succeeds in learning human-like rules when given the same data that is available to human learners, then it can shed some light on the rules that constitute the human knowledge of language and how humans learn these rules. In addition to helping scientists understand the human mind, computational models and the datasets they use are invaluable in developing applied computational tools for machine language translation, language identification, and artificial intelligence.<br/><br/>The rules that govern sound patterns differ in nuanced ways between languages, and they can be divided into two kinds. First, all languages have rules that restrict how sounds interact with sounds that immediately precede or follow them: for example, in English, words can begin in ""pr"" but not ""pn"", whereas in Greek, words can begin in either sequence. But some languages also have rules that restrict the interactions of sounds that are not adjacent (nonlocal). Languages such as Hungarian and Turkish have vowel harmony, which means that all the vowels in a word tend to share certain features of their pronunciation. Navajo (Southwestern United States) has consonant harmony--consonants have to match in certain features. In languages such as Quechua (spoken in South America) and Amharic (Africa), certain features of consonants have to mismatch. Linguists have known about these patterns for a long time, and there are many theories of how they are cognitively represented. But these nonlocal rules continue to stymie computational models, because in order to notice them, the computer has to consider many more possibilities than it would for rules on adjacent sounds. This is similar to how much more difficult it is for a computer to crack a password the longer it gets. The proposed research builds a computational model of nonlocal rules that identifies certain clues to their existence in a language. The project will compile corpora to test the model's ability to find nonlocal rules (Quechua, Shona, Hungarian, Russian, Aymara, Sundanese). The model's performance will be compared with experiments with native speakers of several languages. The model, the corpora, and the experimental data will be made freely available to the scientific community and the public. Workshops will disseminate the research in Bolivia. The project will provide training for students in computational analysis and corpus building."
"1663360","Collaborative Research: Computational Design of Metal-Organic Framework Materials","CMMI","Design of Eng Materials (DEMS)","06/15/2017","06/13/2017","Peter Greaney","CA","University of California-Riverside","Standard Grant","Richard Malak","05/31/2020","$269,245.00","","agreaney@engr.ucr.edu","Research & Economic Development","RIVERSIDE","CA","925210217","9518275535","ENG","8086","024E, 067E, 073E","$0.00","This award supports research in computational methods for the automatic exploration of the search space of metal-organic frameworks to obtain desired combinations of mechanical, thermal and chemical properties. A metal-organic framework is a repeating three-dimensional crystal lattice with a large open space-frame structure composed of organic linking molecules bonded to inorganic nodal units. The interconnected pore-spaces in these materials endow them with a rich variety of unusual properties that can be exploited for gas storage, gas separation, and catalysis. Given the constraints of chemical bonds and bond angles, one cannot easily customize the lattice for a particular size and shape. Thankfully there is an astronomically large number of permutations for combining various atomic elements together. However, human designers are confounded on how to find one for their particular problem domain. What is needed is a computational process to search the space for a best solution. By formalizing the molecular design as a decision tree, the developed computer algorithms will invent new materials whose functional behavior is defined by its chemical makeup and the resulting geometry and movement of the lattice structure. As part of testing the design approach, the project will address two technologically important problems:  designing new metal organic frameworks optimized for gas storage, and materials for separating isomers in industrially important chemical feed stocks. STEM outreach activities to high school students and teachers will also be performed.<br/><br/>Specifically, the project seeks materials that exhibit highly chemically selective adsorption or permeability of gases through mechanisms that arise from chemical, steric, and vibrational behavior of the frameworks. The computational search for this incorporates a unique graph transformation approach that mimics correct stoichiometric reactions and leads to a large search tree that is amenable to recent advances in artificial intelligence planning algorithms. Furthermore, machine learning methods will establish a link between the structure and function of organic frameworks by leveraging data from complex molecular simulations. This will lead to more efficient search of the decision tree so that meaningful results can be obtained. Through detailed simulations of the resulting metal organic frameworks, the researchers will publish how their new materials can be used to tackle challenging problems in energy storage, high-tech manufacturing, and the creation of new sensitive sensor equipment."
"1454190","CAREER: Automated scientific discovery and the philosophical problem of natural kinds","SES","CROSS-DIRECTORATE  ACTIV PROGR, SCIENCE, TECH & SOCIETY","04/01/2015","08/03/2017","Benjamin Jantzen","VA","Virginia Polytechnic Institute and State University","Continuing grant","Frederick M Kronz","03/31/2020","$386,618.00","","bjantzen@vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","SBE","1397, 7603","1045, 1353, 9179","$0.00","General Audience Summary <br/><br/>This is a Faculty Early Career Development (CAREER) award, the NSF's most prestigious awards in support of junior faculty who exemplify the role of teacher-scholars through outstanding research, excellent education and the integration of education and research within the context of the mission of their organizations. This award supports an integrated research and education project that addresses a fundamental scientific question:  Out of countless number of empirical quantities related to some phenomenon of interest, to which quantities should attention be directed in order to successfully discover the regularities or laws behind the phenomenon? Only a special few facilitate accurate generalization from a few particular facts to a great many that are not in evidence, and yet in the course of their work scientists efficiently choose variables that support generalization. That scientists are able to do this is both fascinating and perplexing. This project will clarify and test a new approach to solving this puzzle by constructing a series of computer algorithms that automatically carry out a process of variable choice in the service of autonomous scientific discovery. The inductive success of these algorithms when applied to genuine problems in current scientific settings will serve as tangible validation of the theory underlying these algorithms. The automated discovery algorithms produced will be leveraged to introduce a generation of graduate students in philosophy and science to the deep connections between physical computing and formal epistemology. A recurring summer school will train graduate students in basic programming and formal methods, with hands on development of automated discovery systems.<br/><br/>Technical Summary <br/><br/>This project connects the philosophical problem of natural kinds with computational problems of automated discovery in artificial intelligence. It tests a new approach, a dynamical natural kinds theory, denoted the Dynamical Kinds Theory, by deriving discovery algorithms from that theory's normative content and then applying these algorithms to real-world phenomena. The inductive success of these algorithms when applied to genuine problems in current scientific settings will serve as tangible validation of the philosophical theory. More dramatically, these discovery algorithms have the potential to produce more than one equally effective but inconsistent classification of phenomena into kinds. The existence of such alternatives plays a central role in debates over scientific realism. Outside of philosophy, the application of the discovery algorithms to open problems in areas of ecology, evolution, metagenomics, metabolomics, and systems biology has the potential to suggest previously unconceived theories of the fundamental ontology in these fields. In particular, the algorithms will be applied to agent-based models of evolutionary dynamics to search for population-level laws, and to publicly available long-term ecological data to search for stable dynamical kinds outside the standard set of ecological categories."
"1561655","Collaborative Research: Big Data from Small Groups: Learning Analytics and Adaptive Support in Game-based Collaborative Learning","DRL","Core R&D Programs","10/01/2016","08/24/2017","James Lester","NC","North Carolina State University","Continuing grant","John Cherniavsky","09/30/2021","$739,564.00","","lester@csc.ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","EHR","7980","8244","$0.00","This is a research project supporting a new model of Computer Supported Collaborative Learning (CSCL) that combines the advantages of game based learning with problem based learning. Good game based learning environments combine rich scenarios with engaging activities to serendipitously provide student learning. These learning environments also provide an opportunity for players to collaborate in reaching their game goals. Good problem based learning environments provide support for the solution of complex and ill-structured problems. The combination of these two types of learning environments promise to provide the engagement and richness of game based learning with the support environment to engage students in authentic science. Both of these environments are computer based so the actions and interactions of the students and teachers are captured for analysis. Applying learning analytics to the captured data provides information on student learning for the teacher, provides learning information to the student for self-reflection and improved learning, and provides information for the system designer to improve the effectiveness of the new CSCL environment.<br/><br/>The scientific problem domain is environmental science for middle school students. The CSCL environment is a  game based learning environment that incorporates problem based learning. The interaction between the CSCL environment and the student is enhanced by the collection of data on the student based on cognitive, affective, and metacognitive states that are inferred using artificial intelligence technologies. Specific strategies are employed to help students construct explanagions, reason effectively, and become self-directed learners. Key outcomes of the project include a model of collaborative scaffolding for game based learning that is usable in classrooms to help students learn STEM content and learning analytics designed to support the teacher in the roles of guide and collaborator. A goal of the project is wide dissemination of the CSCL system."
"1561486","Collaborative Research:  Big Data from Small Groups: Learning Analytics and Adaptive Support in Game-based Collaborative Learning","DUE","Core R&D Programs","10/01/2016","09/13/2017","Cindy Hmelo-Silver","IN","Indiana University","Continuing grant","John Cherniavsky","09/30/2021","$700,560.00","Krista Glazewski","chmelosi@indiana.edu","509 E 3RD ST","Bloomington","IN","474013654","8128550516","EHR","7980","8244","$0.00","This is a research project supporting a new model of Computer Supported Collaborative Learning (CSCL) that combines the advantages of game based learning with problem based learning. Good game based learning environments combine rich scenarios with engaging activities to serendipitously provide student learning. These learning environments also provide an opportunity for players to collaborate in reaching their game goals. Good problem based learning environments provide support for the solution of complex and ill-structured problems. The combination of these two types of learning environments promises to provide the engagement and richness of game based learning with the support environment to engage students in authentic science. Both of these environments are computer based so the actions and interactions of the students and teachers are captured for analysis. Applying learning analytics to the captured data provides information on student learning for the teacher, provides learning information to the student for self-reflection and improved learning, and provides information for the system designer to improve the effectiveness of the new CSCL environment.<br/><br/>The scientific problem domain is environmental science for middle school students. The CSCL environment is a  game based learning environment that incorporates problem based learning. The interaction between the CSCL environment and the student is enhanced by the collection of data on the student based on cognitive, affective, and metacognitive states that are inferred using artificial intelligence technologies. Specific strategies are employed to help students construct explanagions, reason effectively, and become self-directed learners. Key outcomes of the project include a model of collaborative scaffolding for game based learning that is usable in classrooms to help students learn STEM content and learning analytics designed to support the teacher in the roles of guide and collaborator. A goal of the project is wide dissemination of the CSCL system."
"1351892","CAREER: Characterizing Object Recognition Machinery in a Newborn Visual System","BCS","DS - Developmental Sciences","04/15/2014","08/14/2017","Justin Wood","CA","University of Southern California","Continuing grant","Chalandra Bryant","03/31/2019","$559,086.00","","justin.wood@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","SBE","1698","1045, 1698","$0.00","How does early experience shape how we process and interpret visual information? Two major limitations have made this question difficult to answer. First, researchers can typically collect only a few data points from newborns, which prevents precise measurement of the infants' visual cognitive abilities. Second, human infants cannot ethically be raised in controlled environments from birth, which prevents researchers from studying how specific experiences shape the newborn mind. <br/><br/>To overcome these limitations, Dr. Wood has developed a new controlled-rearing method using a non-human animal model. This method can be used to measure all of a newborn's behavior (24 hours/day, 7 days/week) with high precision (9 samples/second) within strictly controlled environments. With support from this NSF CAREER award, Dr. Wood will use the new controlled-rearing method to characterize how newborns recognize objects at the onset of visual object experience. <br/><br/>Dr. Wood's laboratory will use a two-pronged approach. First, the lab will perform a series of controlled-rearing experiments with newborn chickens. Studies of chickens can inform human cognitive development because chickens and humans have similar neural processing systems for sensory information. These controlled-rearing experiments will reveal how specific visual experiences shape newborns' object recognition abilities. The findings will provide the foundation for a new, publicly-accessible database that describes how specific sensory experiences relate to specific behaviors in a newborn organism. <br/><br/>Second, the lab will build biologically-inspired computational models of newborns' object recognition behavior, using state-of-the-art techniques from artificial intelligence. These models will make predictions that can be compared to the data from the controlled-rearing experiments. This will help identify how the visual system processes objects. This approach integrates ideas from developmental psychology, vision science, and computational neuroscience, providing a unified framework for studying the origins of object recognition and other visual cognitive abilities."
"1629564","XPS: FULL: Collaborative Research: Parallel and Distributed Circuit Programming for Structured Prediction","CCF","Exploiting Parallel&Scalabilty","08/15/2016","08/11/2016","Jason Eisner","MD","Johns Hopkins University","Standard Grant","Anindya Banerjee","07/31/2019","$415,000.00","","jason@cs.jhu.edu","1101 E 33rd St","Baltimore","MD","212182686","4439971898","CSE","8283","","$0.00","This project develops a system for ""circuit programming,"" which allows a programmer to focus on the high-level solution to a problem rather than on the details of how the computation is organized. Circuit programming consists of writing rules that describe how data items depend on one another. The intellectual merits lie in the design of a new programming language for specifying these rules, along with the algorithms whereby the computer automatically finds efficient strategies for managing the necessary computations on available parallel hardware.  The project's broader significance and importance lie in its potential to streamline work in areas such as artificial intelligence and machine learning.  With the growing complexity of systems in these areas and their need to process big data in depth, research and teaching typically get bogged down in programming details, especially for parallel platforms; this project aims to delegate those details to automatic methods.<br/><br/>The research develops a programming system for Dyna, a circuit programming language that enables concise specification of large function graphs that may be cyclic and/or infinite. Dyna employs (1) a pattern-matching notation that augments pure Prolog with evaluation and aggregation and (2) an object-like mechanism for dynamically defining new sub-circuits as modifications of old ones.  This project is building an adaptive system that can mix forward and backward chaining to seek a fixpoint of the circuit and to update this fixpoint as the inputs change.  The system will perform compile-time and runtime analysis of the Dyna program and will map it to Habanero, a system for scheduling parallel computations on multicore processors, with extensions for task priorities, task cancellation, GPU execution, and distributed execution."
"1456382","SBIR Phase II:  A Question of Numbers: Numeracy, Learning, and Learning about Learning","IIP","SMALL BUSINESS PHASE II","03/01/2015","06/28/2017","Brent Milne","CO","Simbulus Inc","Standard Grant","Rajesh Mehta","08/31/2019","$1,275,000.00","","brent.milne@simbulus.com","2017 10TH ST STE B","Boulder","CO","803025186","3034496284","ENG","5373","115E, 165E, 5373, 7218, 8031, 8032, 9102, 9177","$0.00","This Small Business Innovation Research (SBIR) Phase II project aims to answer the presidential call to ""create digital tutors that are as effective as personal tutors."" More than any other subject, mathematical learning is cumulative, and as students fall behind their classmates, new material becomes less comprehensible and they can face an ever-widening gap to their peers. Formative assessment (FA) practices have been well established as effective in closing these gaps and informing teacher decision-making. While the influx of mobile computing devices has enormous potential to help facilitate change in education, the potential is heavily dependent on the availability of proven, research-backed software and services. This project will help close achievement gaps by providing students with adaptive, personalized instruction and also providing teachers with valuable FA techniques, data, and suggestions. More broadly, the data will yield opportunities to research and model student understanding and to analyze the learning process, enabling additional research into effective practices for the teaching and learning of mathematics. With its strong customer value propositions and innovations that will enable new forms of software-enhanced teaching and learning, this project will also create significant commercial value within the educational market. <br/><br/>This project will create digital learning environments that go beyond current state-of-the-art systems to deliver adaptively selected instructional video segments and highly interactive problems, and do so while maintaining a flow of content that feels natural - as if the learning was occurring in the presence of an actual tutor. The ability of the system to adapt to the needs of an individual student is based upon a real-time assessment of student understanding and leverages cutting edge research from the fields of formative assessment, machine learning, artificial intelligence and big data. The ability to model student understanding and analyze the learning process will lead to the creation of new learning analytics tools and enable additional research into effective practices for the teaching and learning of mathematics. The proposed research will seek to demonstrate, in a randomized crossover trial, the effectiveness of the adaptive, online system over a control treatment. The researched solutions will also employ novel FA implementations such as collaborative review and white-boarding (via wireless communication), record and playback of teacher work, use of student sentiment, groupings of peers for collaborative work, and models of student understanding that incorporate teacher input (teacher plus software in the FA loop)."
"1718970","CCF-BSF:  AF:  Small:  Convex and Non-Convex Distributed Learning","CCF","ALGORITHMIC FOUNDATIONS","01/01/2018","07/10/2017","Nathan Srebro","IL","Toyota Technological Institute at Chicago","Standard Grant","Tracy J. Kimbrel","12/31/2020","$249,978.00","","nati@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372803","7738340409","CSE","7796","7923, 7926, 7934","$0.00","Machine learning is an increasingly important approach in tackling many difficult scientific, engineering and artificial intelligence tasks, ranging from machine translation and speech recognition, through control of self driving cars, to protein structure prediction and drug design. The core idea of machine learning is to use examples and data to automatically train a system to perform some task. Accordingly, the success of machine learning is tied to availability of large amounts of training data and our ability to process it. Much of the recent success of machine learning is fueled by the large amounts of data (text, images, videos, etc) that can now be collected.  But all this data also needs to be processed and learned from---indeed this data flood has shifted the bottleneck, to a large extent, from availability of data to our ability to process it.  In particular, the amounts of data involved can no longer be stored and handled on single computers. Consequently, distributed machine learning, where data is processed and learned from on many computers that communicate with each other, is a crucial element of modern large scale machine learning.<br/><br/>The goal of this project is to provide a rigorous framework for studying distributed machine learning, and through it develop efficient methods for distributed learning and a theoretical understanding of the benefits of these methods, as well as the inherent limitations of distributed learning. A central component in the PIs' approach is to model distributed learning as a stochastic optimization problem, where different machines receive samples drawn from the same source distribution, thus allowing methods and analysis that specifically leverage the relatedness between data on different machines. This is crucial for studying how availability of multiple computers can aid in reducing the computational cost of learning.  Furthermore, the project also encompasses the more challenging case where there are significant differences between the nature of the data on different machines (for instance, when different machines serve different geographical regions, or when each machine is a personal device, collecting data from a single user). In such a situation, the proposed approach to be studied is to integrate distributed learning with personalization or adaptation, which the PIs argue can not only improve learning performance, but also better leverage distributed computation.<br/><br/>This is an international collaboration, made possible through joint funding with the US-Israel Binational Science Foundation (BSF).  The project brings together two PIs that have worked together extensively on related topics in machine learning and optimization."
"1657039","CRII: CSR: Rethinking the FTL in SSDs -- a file translation layer instead of a flash translation layer","CNS","CRII CISE Research Initiation","03/15/2017","03/20/2017","Hung-Wei Tseng","NC","North Carolina State University","Standard Grant","M. Mimi McClure","02/28/2019","$174,998.00","","htseng3@ncsu.edu","CAMPUS BOX 7514","RALEIGH","NC","276957514","9195152444","CSE","026Y","7354, 8228","$0.00","As data sets for artificial intelligence, network services, and cloud storage grows, so does the demand of quickly and efficiently serving data from the storage device. Using solid state drives (SSDs) based on non-volatile, flash memory technologies is an effective approach to improve the performance of storage devices. However, as the rest parts of the computer system leverage the entrenched interface to communicate with SSDs, the overhead of supporting these abstractions buries the real potential of SSDs. Specifically, the different addressing modes for different system layers result in multiple address translations when accessing a single file and require additional system resource to maintain the mapping. This address translation overhead takes time and limits the bandwidth of SSDs. This project is addressing this problem by proposing an innovative storage interface that minimizes the system overhead but better fits the behaviors of applications in accessing data. The proposed interface will simplify the design of operating systems. This interface will require no modifications to existing applications. <br/><br/>As most file accessing overhead coming from the operating system, simplifying operating systems with the proposed interface will significantly boost the latency and bandwidth when applications access SSDs. This project will implement the proposed design in real SSDs without changes to existing hardware, meaning that the result of this project can immediately facilitate existing computer systems hosting big data applications without additional hardware costs. This project will also encourage researchers to revisit existing hardware/software interfaces for achieving better performance on emerging peripheral devices as well as exploring other benefits, including enhanced security and reduced energy consumption of pursuing this research direction."
"1757632","REU Site: Undergraduate Research in Smart Environments","CNS","RSCH EXPER FOR UNDERGRAD SITES","03/01/2018","01/23/2018","Lawrence Holder","WA","Washington State University","Standard Grant","Jonathan Sprinkle","02/28/2021","$360,000.00","","holder@eecs.wsu.edu","280 Lighty","PULLMAN","WA","991641060","5093359661","CSE","1139","9250","$0.00","This Research Experiences for Undergraduates site will enable 10 undergraduates each year to conduct hands-on research in the field of smart environments for a period of 10 weeks each summer. Research participants from a wide variety of institutions and demographic backgrounds will explore the links between multiple applications including artificial intelligence, machine learning, data mining, high-performance computing, pervasive computing, networking, distributed systems, health, medicine, psychology, gerontechnology, and energy sustainability. Within this context, participants will gain an appreciation for how to collect large amounts of data from these environments, analyze the data for new knowledge, and take actions to effect changes in the environments in order to improve health, security, efficiency and sustainability. <br/><br/>This REU site facilitates research and training in multiple complementary disciplines including computer science, electrical engineering, psychology, and health care. The team partners with other REU programs on campus, and participants will interact regularly with other REU students from around the country, with faculty from multiple REU programs, and with graduate students from the related ongoing research programs in smart environments. The program will enable interdisciplinary research that links design of technology with health-based sustainable energy applications, and creates new opportunities for undergraduates to study health, energy and human behavior using the technology. Results of this program, including descriptions of student projects, lessons learned, and quantitative and qualitative feedback, will be disseminated via the program website. This program will also make a contribution to a generation whose workforce is trained in multiple, complementary disciplines. Finally, our planned recruitment effort and strong mentoring component will spread knowledge of the benefits of the REU program among the targeted populations, resulting in broadening participation in engineering and related disciplines.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1659585","REU Site: Language, Cognition and Computation","SMA","","06/15/2017","06/13/2017","Michael Frank","CA","Stanford University","Standard Grant","Josie S. Welkom","05/31/2020","$283,231.00","Christopher Potts","mcfrank@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","SBE","Q170","7736, 9250","$0.00","This site is supported by the Department of Defense in partnership with the NSF's Research Experiences for Undergraduates (REU) Sites program. The REU program has both scientific and societal benefits integrating research and education. Recent developments in cognitive science have led to breakthrough new scientific results and are providing the basis for exciting new applications in areas like social computing and assistive technologies. These developments present a challenge for education, however. Even at top research universities, students are hard-pressed to receive the appropriate training; the situation is even more difficult at institutions that do not provide extensive research training. This REU addresses this challenge. Based at Stanford's Center for the Study of Language and Information (CSLI), a top institution for interdisciplinary cognitive science, the program provides talented undergraduates from diverse backgrounds with both an opportunity to do mentored research in a top laboratory and a supportive program framework that includes technical training, professional development, and academic discussion.<br/><br/>The scientific and technological innovations motivating this REU derive from a convergence within the core disciplines of cognitive science -- psychology, linguistics, and computer science -- around themes of uncertainty, approximation, and learning. As psychology and linguistics are becoming more computational, computation is returning to its cognitive roots. Artificial intelligence techniques developed in psychology are undergoing a resurgence in machine learning, and natural language processing models of syntactic structure are becoming the standard cognitive modeling frameworks in psycholinguistics. The prerequisites for research in this new intellectual environment include an understanding of how the mind works, familiarity with the nature of human language and communication, proficiency in statistical analysis, and advanced programming skills. Yet a classic psychology or linguistics degree provides almost no programming or technical experience, and a standard computer science education doesn't include any content on how the mind works. This REU fills such gaps in the training of undergraduates and helps to foster a new, more diverse generation of researchers entering cognitive science."
"1723440","SaTC: EDU: Learning Moving Target Defense Concepts: Teaching and Training Curricula Development Based on Software Defined Networking and Network Function Virtualization","DGE","Secure &Trustworthy Cyberspace","09/01/2017","08/11/2017","Dijiang Huang","AZ","Arizona State University","Standard Grant","Victor P. Piotrowski","08/31/2019","$299,756.00","","dijiang@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","EHR","8060","7254, 7434, 9178, 9179, SMET","$0.00","Moving Target Defense (MTD) is a new security concept to increase uncertainty and complexity for attackers, reduce their window of opportunity and increase the costs of their attack efforts. MTD solutions involve a wide-range of advanced technical expertise, which current education models lack. The project from Arizona State University proposes to develop an MTD courseware for both senior undergraduate level and graduate level in computer science focusing on network-based MTD technologies. Additionally, a cloud-based hands-on laboratory will be established to support MTD labs, which will increase access to students and educators in lab environments with limited computer networking and system security capabilities. The proposed MTD curricula will be published as a textbook associating with a MTD lab repository allowing instructors to build a new MTD course or pick part of the teaching materials to incorporate them into their current curricula. The project team will also work with industry partners to develop the course content and provide a Teacher Training workshop to disseminate the course materials. All the created course content and labs will be freely downloadable by instructors and students.<br/><br/>MTD solutions involve technologies in machine learning, artificial intelligence, and big data analysis models, and current education resources in this realm should address these fields. The proposed project will address the research challenge on how to build-out a much-needed hands-on learning module that can be easily deployed on existing cloud service platforms to learn and experiment with new computer networking and security technologies such as Software Defined Networking (SDN), Network Function Virtualization (NFV), and MTD. This project will focus on four interdependent tasks: (a) building the MTD education capability by creating software components to support SDN, NFV, and MTD, and establishing MTD lab repository and APIs to enhance MTD learning outcomes; (b) developing both long-term semester-based course curriculum, and short-term training oriented MTD teaching contents; (c) conducting a comprehensive evaluation plan by involving both internal and external independent evaluators to use the developed course content and labs; and (d) working with industry partners and hosting a Teacher Training workshop to maximally disseminate developed MTD learning contents and hands-on exercises."
"1755419","Systematizing Connective Labor","SES","SOCIOLOGY","02/15/2018","02/13/2018","Allison Pugh","VA","University of Virginia Main Campus","Standard Grant","Toby Parcel","01/31/2020","$205,000.00","","apugh@virginia.edu","P.O.  BOX 400195","CHARLOTTESVILLE","VA","229044195","4349244270","SBE","1331","1331","$0.00","This research investigates connective labor, a novel concept of service work, and examines the impact of contemporary trends in standardization and automation. Some jobs have relationships with people at the core of their work where these relationships require an emotional connection between workers and their charges.  Teachers, therapists, primary care physicians, even prison guards each depend on relationships in service to a larger goal: children learning, patients healing, prisons secure. Connective labor captures the relational work between practitioner and recipient, using their emotional connection to produce an outcome.  Existing research documents the importance of work involving relationships for valuable outcomes in arenas from schools to hospitals; these proven impacts of connective labor make its scarcity, uneven distribution or unreliable performance a social problem. Yet its emotional nature resists efforts to make it more systematic or automated. This research will provide new information to policymakers and the public about connective labor: its variation, its value, and the costs and benefits of making it more systematic, scaling it up, or delivering it by non-human agents. The project will also contribute to ongoing public debates and policy deliberations about automation and work involving relationships, by providing a new visibility for connective labor and the kind of standards and technology that support its excellence. <br/><br/>The goals of the project are: to distill the common practices and principles that comprise connective labor, for practitioners as well as the program administrators and artificial intelligence (AI) engineers who would systematize their work; investigate how workers experience different kinds of systematization, from checklists to robotics; and evaluate how such systematization affects connective labor. Research includes 95 in-depth interviews and ethnographic observations with connective laborers in fields focused on security and/or control, e.g. police; with low-wage workers in home health care; and with what might be called systematizers, e.g., administrators. The results of the study will document characteristics of different kinds of connective labor, outline the risks and rewards of the various ways these are systematized, and explain differing stances towards this work."
"1629395","XPS: EXPL: Hippogriff: Efficient Heterogeneous Servers for Data Centers and Cloud Services","CCF","Exploiting Parallel&Scalabilty","10/01/2016","09/08/2016","Steven Swanson","CA","University of California-San Diego","Standard Grant","M. Mimi McClure","09/30/2019","$300,000.00","","swanson@cs.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","CSE","8283","","$0.00","The growing importance of artificial intelligence, network services, and cloud storage drives the demand of building powerful computer systems that can perform many operation at once.  Building computers with different kinds of computing processors (i.e., heterogeneous processing) is an effective way to achieve this goal. However, this approach also creates new problems that can negate some of the benefits it provides.  In particular, using different processors for different tasks requires moving data between those processors.  This movement takes time and can cancel out saving heterogeneous processing provides. This project is addressing this problem in heterogeneous computing systems by making the movement of data between different processors more efficient.  This improved efficiency leads directly to benefits for applications of scientific and commercial importance.<br/><br/>Much of the cost of data movement heterogeneous computing systems stems from the entrenched central processing unit (CPU)-centric programming model.  This project is revisiting the design of the application interface, system software and hardware components to remove CPUs and main memory from the critical path of moving data.  The project provides an efficient programming model that allows the system software stack to automatically and efficiently setup the data movements between heterogeneous processors. We are applying the system to large-scale database systems, massive parallel programming systems like Spark and MapReduce as well as scientific computing that power important daily applications and research projects."
"1759934","ABI Innovation:  Deep learning methods for protein bioinformatics","DBI","ADVANCES IN BIO INFORMATICS","07/01/2018","03/12/2018","Jianlin Cheng","MO","University of Missouri-Columbia","Standard Grant","Peter H. McCartney","06/30/2021","$624,247.00","","chengji@missouri.edu","115 Business Loop 70 W","COLUMBIA","MO","652110001","5738827560","BIO","1165","9150","$0.00","Protein sequence is a language of a living system, which encodes protein structure and function critical for the survival of any organism. Therefore, understanding how protein sequence describes function and structure is a fundamental problem in biological research. Yet, the traditional interpretation of protein sequences is 3ased on either manual identification of sub-sequence patterns or some arbitrary dissection of a sequence into subsequences of fixed size; neither approach can accurately recognize all of the semantic components in a protein sequence that are relevant to its structure and function. In this project, powerful artificial intelligence methods, based on deep learning, will be designed such that they can automatically map protein sequences into high-level semantic features that are meaningful when related to protein structure and function. This will not only improve the accuracy of predicting protein structural and functional properties, but also provide a new way of representing and interpreting proteins biological function, transforming how protein data are interpreted. The impact of the basic research will be broadened through open source software dissemination to other researchers, seminars on deep learning and bioinformatics, student training, involvement of minority and female students, publications, presentations, workshops, and outreach activities for high school students, as well as thoughtfully crafted communication with the Missouri state legislature, and other members of the general public.<br/><br/>During the research, novel deep one-dimensional (1D), 2D, and 3D convolutional neural networks will be developed to translate protein sequences or structures of arbitrary size into high-level features under the guidance of improving the prediction of multiple residue-wise local structural/functional properties (secondary structures, solvent accessibility, torsion angle, disorder, contact map, disulfide bonds, beta-sheet pairings, and protein functional sites) as well as global properties such as folds. The 1D convolutional neural network for interpreting protein sequence data will also be supplemented by the long- and short-term memory networks. The comprehensive deep learning models will be trained by innovative multi-task learning and transfer learning to enhance prediction performance. The 1D, 2D and 3D convolutional networks will be further integrated to improve the accuracy of analyzing protein sequence, structure and function. The 1D and 3D convolutional neural networks are completely original, and the new 2D convolutional architecture is more comprehensive and versatile than existing approaches. In addition to advancing the classic protein prediction tasks through the novel deep learning architectures, the hidden features automatically extracted by the deep learning models will provide a new semantic representation of proteins, which will likely transform various protein bioinformatics tasks such as classification, clustering, comparison, and ranking. The URL of this project is: http://calla.rnet.missouri.edu/cheng/nsf_deepbioinfo.html .<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1756013","CRII: SHF: Optimizing Deep Learning Training through Modeling and Scheduling Support","CCF","SOFTWARE & HARDWARE FOUNDATION","06/01/2018","01/23/2018","Feng Yan","NV","Board of Regents, NSHE, obo University of Nevada, Reno","Standard Grant","Almadena Y. Chtchelkanova","05/31/2020","$174,990.00","","fyan@unr.edu","1664 North Virginia Street","Reno","NV","895570001","7757844040","CSE","7798","7942, 8228, 9150","$0.00","Deep learning models trained on large amounts of data using lots of computing resources have recently achieved state-of-the-art training performance on important yet challenging artificial intelligence tasks. The success of deep learning has attracted significant research interest from hardware and software communities to improve training speed and efficiency. Despite the great efforts and rapid progress made, one important bridge to connect software and hardware support with deep learning domain knowledge is still missing: efficient configuration exploration and runtime scheduling. Both the quality of deep learning models and the training time are very sensitive to many adjustable parameters that are set before and during the training process, including the hyperparameter configurations (such as learning rate, momentum, number and size of hidden layers) and system configurations (such as thread parallelism, model parallelism, and data parallelism). Efficient exploration of hyperparameter configurations and judicious selection of system configurations is of great importance to find high-quality models with affordable time and cost. This is however a challenging problem due to a huge search space, expensive training runtime, sparsity of good configurations, and scarcity of time and resources.<br/><br/>The objective of this research work is to systematically study the unique properties of deep learning systems and workloads, and establish new modeling and scheduling methodologies for improving deep learning training. The PI aims to improve the efficiency of discovering high performing models through a dynamic scheduling methodology driven by a novel hyperparameter configuration classification approach. The PI aims at developing an accuracy- and efficiency-aware hybrid scheduling methodology that makes judicious scheduling decisions based on a global view of both the time dimension (accuracy potential) and spatial dimension (efficiency potential) information. This research work integrates techniques in workload characterization, performance modeling, resource management, and scheduling to dramatically speedup the training process while significantly reducing the cost in time and resources. More broadly, this project will gain foundational knowledge about the interaction between software-hardware support and deep learning domain knowledge. This knowledge can help design next generation deep learning systems and frameworks, making deep learning training handy for researchers and practitioners with limited system and machine learning domain expertise. This research will help enhance curriculum and provide research topics for both undergraduate and graduate students, especially students from underrepresented groups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1746511","STTR Phase I:  Microscope-based Technology For Automatic Brain Cell Counts Using Unbiased Methods","IIP","STTR PHASE I","01/01/2018","12/27/2017","Peter Mouton","FL","Stereology Resource Center, Inc.","Standard Grant","Ruth M. Shuman","12/31/2018","$224,417.00","Dmitry Goldgof","peter@disector.com","6260 Kipps Colony Court","Gulfport","FL","337073992","4107391667","ENG","1505","124E, 1505, 7236, 8042","$0.00","The broader impact/commercial potential of this Small Business Technology Transfer (STTR) Phase I project is in automating the process of unbiased stereology, the state-of-the-method used in the life sciences for counting stained cells on tissue sections.  Unbiased stereology allows neuroscientists to accurately analyze the size and number of brain cells, which are altered in many neurological disorders and mental illnesses. For reasons that are currently unknown, Alzheimer's disease, Parkinson's disease and Amyotrophic Lateral Sclerosis are all associated with a progressive loss of brain cells. In contrast, children with autism are born with too many brain cells, which leads to life-long problems in processing complex streams of information.  Stereology plays an important role in investigating many conditions affecting the brain and assessing the efficacy and safety of possible treatments. Though the proposed technology will initially target research studies to understand and treat all neurological conditions, it can be useful for automatic assessments of cells in all tissues, including cancer screening and diagnosis from biopsies. <br/><br/><br/>The proposed project will develop and optimize an algorithm to help brain scientists identify causes and treatments for neurological disease and mental illness. The proposed technology will use deep learning (artificial intelligence) systems to automatically recognize, count and size brain cells on tissue sections. An important use of this technology will be to analyze brains and nerve tissue from mice and rats treated to show similar neurological diseases as those found in humans. These animal models provide a powerful tool for testing treatments to cure brain disease in humans. Currently stereology studies of tissues from these animals require a trained technician to sit before a computer screen making tedious manual counts of hundreds and thousands of microscopic cells. This outdated approach fails to take advantage of powerful deep learning methods proposed for the proposed software that could complete these tasks 10 times faster and with fewer errors and human biases. Therefore, the proposed technology will use deep learning technology to accelerate basic research and drug development in the U.S., thereby establishing a long-term economic engine and bringing significant benefits to society through scientific breakthroughs and medical discoveries."
"1661456","Collaborative Research: ABI Innovation: Enabling machine-actionable semantics for comparative analyses of trait evolution","DBI","ADVANCES IN BIO INFORMATICS","09/01/2017","08/30/2017","Hilmar Lapp","NC","Duke University","Standard Grant","Peter H. McCartney","08/31/2020","$569,764.00","","hilmar.lapp@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","BIO","1165","9150","$0.00","The millions of species that inhabit the planet all have distinct biological traits that enable them to successfully compete in or adapt to their ecological niches. Determining accurately how these traits evolved is thus fundamental to understanding earth's biodiversity, and to predicting how it might change in the future in response to changes in ecosystems. Although sophisticated analytical methods and tools exist for analyzing traits comparatively, applying their full power to the myriad of trait observations recorded in the form of natural language descriptions has been hindered by the difficulty of allowing these tools to understand even the most basic facts implied by an unstructured free-text statement made by a human observer. The technological arsenal needed to overcome this challenge is now in principle available, thanks to a number of recent breakthroughs in the areas of knowledge representation and machine reasoning, but these technologies are challenging enough to deploy, orchestrate, and use that the barriers to effectively exploit them remains far too high for most tools. This project will create infrastructure that will dramatically reduce this barrier, with the goal of providing comparative trait analysis tools easy access to algorithms powered by machines reasoning with and making inferences from the meaning of trait descriptions. Similar to how Google, IBM Watson, and others have enabled developers of smartphone apps to incorporate, with only a few lines of code, complex machine-learning and artificial intelligence capabilities such as sentiment analysis, this project will demonstrate how easy access to knowledge computing opens up new opportunities for analysis, tools, and research. It will do this by addressing three long-standing limitations in comparative studies of trait evolution: recombining trait data, modeling trait evolution, and generating testable hypotheses for the drivers of trait adaptation.<br/><br/>The treasure trove of morphological data published in the literature holds one of the keys to understanding the biodiversity of phenotypes, but exploiting the data in full through modern computational data science analytics remains severely hampered by the steep barriers to connecting the data with the accumulated body of morphological knowledge in a form that machines can readily act on. This project aims to address this barrier by creating a centralized computational infrastructure that affords comparative analysis tools the ability to compute with morphological knowledge through scalable online application programming interfaces (APIs), enabling developers of comparative analysis tools, and therefore their users, to tap into machine reasoning-powered capabilities and data with machine-actionable semantics. By shifting all the heavy-lifting to this infrastructure, tools can programmatically obtain answers to knowledge-based questions that would otherwise require careful study by a human export, such as objectively and reproducibly assessing the relatedness, independence, and distinctness of characters and character states, with only a few lines of code. To accomplish this, the project will adapt key products and know-how developed by the Phenoscape project, including an integrative knowledgebase of ontology-linked phenotype data, metrics for quantifying the semantic similarity of phenotype descriptions, and algorithms for synthesizing morphological data from published trait descriptions. To drive development of the computational infrastructure and to demonstrate its enabling value, the project's objectives focus on addressing three concrete long-standing needs for which the difficulty of computing with domain knowledge is the major impediment: (1) computationally synthesizing, calibrating, and assessing morphological trait matrices from across studies; (2) objectively and reproducibly incorporating morphological domain knowledge provided by ontologies into evolutionary models of trait evolution; and (3) generating testable hypotheses for adaptive diversification by incorporating semantic phenotypes into ancestral state reconstruction and identifying domain ontology concepts linked to evolutionary changes in a branch or clade more frequently than expected by chance. In addition, to better prepare evolutionary biologist users and developers of comparative analysis tools for adopting these new capabilities, a domain-tailored short-course on requisite knowledge representation and computational inference technologies will be developed and taught. More information on this project can be found at http://cate.phenoscape.org/."
"1652735","CAREER: Urban Transport Network Design with Privacy-Aware Agent Learning","CMMI","CAREER: FACULTY EARLY CAR DEV, CIVIL INFRASTRUCTURE SYSTEMS","03/15/2017","03/14/2017","Joseph Chow","NY","New York University","Standard Grant","Cynthia Chen","02/28/2022","$500,000.00","","joseph.chow@nyu.edu","70 WASHINGTON SQUARE S","NEW YORK","NY","100121019","2129982121","ENG","1045, 1631","029E, 036E, 039E, 1045","$0.00","Technological advances for transportation systems are quickly evolving from their roots in highway materials and traffic control 70 years ago to technologies that support ""smart cities"": autonomous vehicles, on-demand mobility services, and traffic control with machine learning, among others. In 2016, the U.S. Department of Transportation proposed spending $4 billion on autonomous vehicles, and pledged $40 million in tackling smart cities as a grand challenge. However, successful operation of these technologies in a large scale, highly congested city remains prone to operational pitfalls and obstacles. For example, how should a service operator best deploy their vehicles or inform their travelers in real time to optimize service and learning potential simultaneously, while acknowledging their privacy? Some high profile failures include the on-demand transit service Kutsuplus in Helsinki and the Car2Go car share service in San Diego. These systems are highly dynamic, but methods in machine learning and dynamic optimization are not designed for the unique intricacies of urban transport networks. This Faculty Early Career Development (CAREER) Program project is for integrated research and advanced education to create new technologies for these dynamic systems, train students and professionals in these technologies, and engage with private operators and incubators in New York City to operationalize them. The project will use real data from industry partners in ridesharing and autonomous vehicle systems operations, and drive innovation and entrepreneurship by defining new functional roles that mix transportation, computer science, and economics. This will culminate in a test bed in New York City that is expected to shape a next-generation national interdisciplinary research center on ""smart transit"" over the next decade. The PI will recruit local high school students to work with his PhD students each summer; the high school students will be identified through the university's ARISE (Applied Research Innovations in Science and Engineering) program which creates STEM education experiences for women, minorities, and students from low-income backgrounds.  <br/><br/>The research marries three theories together in order to address these new mobility problems in smart cities: dynamic resource allocation under uncertainty, agent-based machine learning, and privacy optimization in a network context. All three are necessary because transportation systems need to be optimized holistically, but data is typically obtained from multiple travelers or vehicles in operation. As such, agent learning and minimization of privacy concerns in the system optimization is needed. The methodology expands the science of inverse optimization by integrating it with dynamic network optimization with privacy control as constraints on the estimated parameters. The research benefits all types of dynamic mobility systems: it will make shared autonomous vehicle fleet operations viable and on-demand service fleets more sustainable and resilient. Data privacy and security in a transport system design context will also be advanced, allowing data from travelers to be more accessible. This research will benefit smart cities, sensor deployment, artificial intelligence, collective behavior, differential privacy, service systems, public policy, and network economics."
"1637585","AitF: Collaborative Research: Algorithms for Probabilistic Inference in the Real World","CCF","Algorithms in the Field","09/01/2016","08/30/2016","Aravindan Vijayaraghavan","IL","Northwestern University","Standard Grant","Tracy J. Kimbrel","08/31/2020","$399,939.00","","aravindv@northwestern.edu","1801 Maple Ave.","Evanston","IL","602013149","8474913003","CSE","7239","","$0.00","Statistical models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data.  The process of using a model to answer specific questions, such as inferring the state of several random variables given evidence observed about others, is called probabilistic inference.  Probabilistic graphical models, a type of statistical model, are often used in diverse applications such as medical diagnosis, understanding protein and gene regulatory networks, computer vision, and language understanding.  On account of the central role played by probabilistic graphical models in a wide range of automated reasoning applications, designing efficient algorithms for probabilistic inference is a fundamental problem in artificial intelligence and machine learning.<br/> <br/>Probabilistic inference in many of these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve.  However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently.  This project focuses on bridging the gap between theory and practice for probabilistic inference problems in large-scale machine learning systems.  The PIs will identify structural properties and methods of analysis that differentiate real-world instances from worst-case instances used to show NP-hardness, and will design efficient algorithms with provable guarantees that would apply to most real-world instances.  The project will also study why heuristics like linear programming and other convex relaxations are so successful on real-world instances.  The efficient algorithms for probabilistic inference developed as part of this project have the potential to be transformative in machine learning, statistics, and more applied areas like computer vision, social networks and computational biology.  To help disseminate the research and foster new collaborations, a series of workshops will be organized bringing together the theoretical computer science and machine learning communities.  Additionally, undergraduate curricula will be developed that use machine learning to introduce students to concepts in theoretical computer science."
"1733686","AitF: Collaborative Research: Efficient High-Dimensional Integration using Error-Correcting Codes","CCF","Algorithms in the Field","09/01/2017","08/11/2017","Stefano Ermon","CA","Stanford University","Standard Grant","Tracy J. Kimbrel","08/31/2021","$360,000.00","","ermon@cs.stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","CSE","7239","","$0.00","Efficiently estimating integrals of high-dimensional functions is a fundamental and largely unsolved computational problem, manifesting in scientific areas from biology and physics to economics. In particular, in Artificial Intelligence and Machine Learning, a wide array of methods are computationally limited precisely because they require the computation of high-dimensional integrals. While computing such integrals exactly is highly intractable, approximations suffice for many applications. Currently, approximation is attempted using two main classes of algorithms: Markov Chain Monte Carlo (MCMC) sampling methods and variational inference techniques. The former are asymptotically accurate, but their computational budget is inflexible and often prohibitive. The latter have manageable computational budget, but typically come with no accuracy guarantees. This project will investigate a new family of computationally efficient approximation methods which reduce the task of integration to the much better studied task of optimization, thus leveraging decades of research and engineering in combinatorial optimization methods and technology. A key goal of the project is to develop an open-source software library of efficient tools for high-dimensional integration.<br/><br/>The reduction of integration to optimization builds on the probabilistic reduction of decision problems to uniqueness promise problems developed in the mid-80s. Specifically, the idea is to use systems of random parity equations in order to specify random subsets of the function's domain, and relate integration to the task of optimization over these subsets. In general, the capacity for efficient optimization fundamentally stems from the capacity to summarily dispense large parts of the domain as uninteresting. The key question to be addressed by the project is whether it is possible to define random subsets over which optimization is both tractable and informative for integration. To that end, the project will employ random systems of linear equations corresponding to Low Density Parity Check (LDPC) matrices for error-correcting codes. The energy landscape, i.e., the number of violated equations, of such systems is far smoother than that of the generic (dense) random systems of linear equations that underlie the original mid-80s technique, thus being far more amenable to optimization. The project will also build upon the deep understanding gained in the last two decades for LDPC codes in the field of communications, with the goal of integrating a priori knowledge about the energy landscape in the optimization strategy. This will provide a fundamentally new use for error-correcting codes, creating a bridge between the areas of optimization and information theory."
"1554783","CAREER: Phase Transitions in Some Discrete Random Models and Mixing of Markov Chains","DMS","PROBABILITY, Division Co-Funding: CAREER, EPSCoR Co-Funding","07/01/2016","04/01/2016","Nayantara Bhatnagar","DE","University of Delaware","Continuing grant","Tomek Bartoszynski","06/30/2021","$253,761.00","","nayantara.bhatnagar@gmail.com","210 Hullihen Hall","Newark","DE","197162553","3028312136","MPS","1263, 8048, 9150","1045, 9150","$0.00","Water turning into ice at its freezing point or the magnetization of iron are examples of phase transitions in physical systems. At the transition point, the properties of the system such as the volume or heat capacity may change discontinuously. The aim of our research is to study phase transitions in mathematical models using probabilistic tools in the following three directions. (1) The longest increasing subsequence (LIS) of a permutation is the length of a maximal subsequence of the permutation in which the elements increase. How long is the LIS for a uniformly random permutation? This question has been studied in connection with practical applications such as sorting sequences, disk drive scheduling and airplane boarding times. The mathematical study of the LIS has revealed deep and unexpected connections of the problem with areas such as the theory of random matrices, analytic combinatorics and random polymer models.  The proposed research aims to study the LIS when the permutation is drawn from certain non-uniform distributions and associated phase transitions. (2) Many computational problems can be phrased as constraint satisfaction problems (CSPs) where one wants to find a solution to a number of variables with a set of constraints imposed on them. CSPs were first studied in computer science motivated by applications to artificial intelligence. To study the difficulty of finding solutions in typical rather than worst case scenarios, researchers study random CSPs. Using sophisticated heuristics, physicists have made detailed predictions about the location and nature of phase transitions in random CSPs. The accuracy of these heuristic predictions motivates the importance of discovering the rigorous mathematical foundations of these techniques. (3) Interacting particle processes are used to model large, randomly evolving interacting systems of agents that arise in the natural sciences including in physics and in biology. The exclusion and interchange random walks are examples of such interacting particle processes. In the symmetric case the long term mixing behavior of the random walk and the nature of phase transitions is well studied. The goal of this research is to understand the mixing properties of natural asymmetric and weighted versions of these processes. While achieving these three goals, the principal investigator will create exciting research opportunities for graduate and undergraduate students in probability, mentoring programs with the goal of retention of women in mathematics, and the development of online curricular material.<br/><br/>The main aim of this project is to develop new theory and analysis for phase transitions in certain discrete probabilistic models. The first problem is to study the limiting distribution of the LIS in non-uniformly random permutations by way of analyzing the fluctuations of the LIS as the parameter of the distribution is varied. The distribution is known to be Gaussian in one regime of the parameter and Tracy-Widom in another and we aim to study this transition. The second problem is to study the condensation and clustering transitions in random CSPs such as the hardcore model on random graphs. The research aims to identify the location of the reconstruction threshold more precisely in these models and to explore the connection to the clustering transition. Finally, the proposal will consider Markov processes such as asymmetric exclusion and interchange and attempt to relate the mixing times and spectral gaps of these processes to the corresponding quantities for a single particle and to understand the cutoff phenomenon for these processes."
"1807368","NSF Workshop: New Vistas in Molecular Thermodynamics: Experimentation, Modeling and Inverse Design","CBET","Proc Sys, Reac Eng & Mol Therm","01/01/2018","12/27/2017","Jianzhong Wu","CA","University of California-Riverside","Standard Grant","Triantafillos Mountziaris","12/31/2018","$30,000.00","","jwu@engr.ucr.edu","Research & Economic Development","RIVERSIDE","CA","925210217","9518275535","ENG","1403","7556","$0.00","The project will support a workshop on Molecular Thermodynamics that will be held on the campus of the University of California-Berkeley, from January 7 to 9, 2018. The workshop will bring together technology leaders and junior researchers to develop a roadmap for basic research in response to emerging opportunities and challenges in the Chemical Process Industries. The workshop will foster debate and discussion among scholars from different areas of the Molecular Thermodynamics community to uncover fundamental research questions whose answers will enable overcoming current technological challenges. It will also will also cover topics related to modernizing Engineering Education. Successful development and implementation of new tools for process design and optimization will ensure sustained competitiveness of the U.S. chemical industry while also addressing environmental challenges and promoting energy efficiency.<br/><br/>Recent trends emphasizing environmental sustainability and improved energy efficiency in the chemical process industries have created new research opportunities in the field of Molecular Thermodynamics. By connecting the physicochemical properties of matter at all length scales, Molecular Thermodynamics has been an enabling tool to accelerate scientific innovations, catalyze emerging technologies, and provide core knowledge for design and optimization of diverse industrial systems, ranging from energy production, materials synthesis, and chemical processing to pharmaceutical and environmental applications. The rapid emergence of new methods in computational algorithms, data science and artificial intelligence provide a unique opportunity for innovation and interdisciplinary collaboration by integrating experimental and computational methods into powerful tools for process design and optimization. In addition to defining new research frontiers in the field of Molecular Thermodynamics, the workshop will also address curriculum development and workforce training issues to ensure continued world-wide competitiveness of the U.S. chemical industry."
"1755876","CRII: SHF: Enabling Neuroevolution in Hardware","CCF","SOFTWARE & HARDWARE FOUNDATION","01/15/2018","01/11/2018","Tushar Krishna","GA","Georgia Tech Research Corporation","Standard Grant","Almadena Y. Chtchelkanova","12/31/2019","$175,000.00","","tushar@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","7798","7945, 8228","$0.00","Over the past few years, machine learning algorithms, especially neural networks (NN) have seen a surge of popularity owing to their potential in solving a wide variety of complex problems across image classification and speech recognition. Unfortunately, in order to be effective, NNs need to have the appropriate topology (connections between neurons) for the task at hand and have the right weights on the connections. This is known as supervised learning and requires training the NN by running it through terabytes to petabytes of data. This form of machine learning is infeasible for the emerging domain of autonomous systems (robots/drones/cars) which will often operate in environments where the right topology for the task may be unknown or keep changing, and robust training data is not available. Autonomous systems need the ability to mirror human-like learning, where we are continuously learning, and often from experiences rather than being explicitly trained. This is known as reinforcement learning (RL). The goal of this project will be on enabling RL in energy-constrained autonomous devices. If successful, this research will enable mass proliferation of automated robots or drones to assist human society. The learnings will also be used to develop new courses on cross-layer support for machine learning. <br/><br/>The focus of the research will be on neuroevolution (NE), a class of RL algorithms that evolve NN topologies and weights using evolutionary algorithms.  The idea is to run multiple ""parent"" NNs in parallel, have the environment provide a reward (score) to the actions of all NNs, and create a population of new ""child"" NNs that preserve those nodes and connections from the parents that lead to actions producing the maximum reward. Running NE algorithms over multiple iterations has been shown to evolve complex behaviors in NNs. Unfortunately, NEs are computationally very expensive and have required large scale compute clusters running for hours before converging. A characterization of the computation and memory behavior of NE algorithms will be performed, and opportunities to massively parallelize these algorithms across genes (i.e., nodes and connections in the NN) will be explored. The evolutionary learning steps of crossover and mutation will be performed over specialized hardware engines, and a low-power architectural platform running NE algorithms at the edge will be demonstrated. Furthermore, the proposed research will serve as the foundation for further research in fast and energy-efficient RL algorithms to help realize general-purpose artificial intelligence."
"1747341","SBIR Phase I:  High Fidelity EUV PhotoMasks","IIP","SMALL BUSINESS PHASE I","01/01/2018","12/18/2017","Supriya Jaiswal","CA","Astrileux Corporation","Standard Grant","Richard Schwerdtfeger","12/31/2018","$225,000.00","","supriya@astrileux.com","4225 Executive Sq Ste 490","La Jolla","CA","920378411","8585312432","ENG","5371","5371, 8034","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to drive the next generation of advanced computing power and performance, by manufacturing integrated circuits, the fundamental units of electronic systems, at length scales of 7 nm and smaller. Today?s central processing units (CPUs) each contain 7.2 Bn chips and over 1.2 sextillion chips are manufactured per year to meet computing demands. Next generation technology is expected to enable artificial intelligence and machine learning through both conventional computing and potentially neuromorphic paradigms, bringing to reality transformative applications such as self-driving cars and smart buildings. As Moore?s law continues to set the pace of technological advancement, chipmakers will deploy new EUV (Extreme Ultraviolet) lithography tools, using light of 13.5 nm to pattern integrated circuits or chip architecture into silicon wafers, for the next three generations of technology. Chipmakers strive to bring about the readiness of EUV technology in 2019. The global demand for next generation electronics is forever increasing as the population grows above 7 Bn. However, the global supply of electronics constantly faces challenges to reduce costs and deliver technology beyond Moore?s Law.<br/><br/>The proposed project addresses the challenges related to high volume manufacturing at the 7 nm node for lithography tools and its components. For example, an EUV photomask, a high commodity component, patterns and replicates integrated circuit design into silicon wafers. Current EUV photomasks have a sub-optimal manufacturing yield of ~60% and suffer from defectivity which arises during fabrication of its architecture. During operational use the photomask sustains damage from the debris generated by the EUV plasma light source that implants in the mask and inevitably replicates in the wafer, destroying the integrated chip pattern. In high volume manufacturing, these issues manifest in the wafer yield, the reusability of a mask, and drive the need for high cost real-time inspection and metrology. A new EUV photomask which promises greater robustness to defects, a higher manufacturing yield, more reusability of masks in operations and a longer lifetime is presented. The goals of the project are to evaluate new integrated architecture for the EUV mask design, develop a higher yield fabrication process and characterize the EUV performance. More robust photomasks reduce the capital outlay required for in-situ metrology and inspection and ultimately bring down the cost of next generation electronics."
"1837369","CPS: Small: Multi-Human Assisted Learning for Multi-Agent Systems using Intrinsically Generated Event-Related EEG Potentials","CNS","SPECIAL PROJECTS - CISE","01/01/2019","09/10/2018","Raghupathy Sivakumar","GA","Georgia Tech Research Corporation","Standard Grant","Jonathan Sprinkle","12/31/2021","$500,000.00","Faramarz Fekri","siva@ece.gatech.edu","Office of Sponsored Programs","Atlanta","GA","303320420","4048944819","CSE","1714","075Z, 7918, 7923","$0.00","The goal of this project is to allow humans to assist machine learning algorithms in a Cyber-Physical System. The approach involves the use of electroencephalogram (EEG) based brain waves of the human-in-the-loop to generate feedback for the learning algorithms. Machine learning solutions are particularly useful for the monitoring, instrumenting, and optimization of complex cyber physical systems (CPS). However, several important problems spanning domains such as natural language processing, automated language translation, and understanding what is in a scene or image remain beyond the scope of true machine learning algorithms, and require human participation. The project involves collaboration with Georgia Tech's Create-X and Venture Lab programs to commercialize the outcomes of the proposed research.<br/> <br/>This project considers recognizing the erroneous behavior of the machine intrinsically by the error related negativity (ERN) in the human EEG signals, which are then used as the reward function for the reinforcement learning (RL) algorithm of the machine to improve its intelligence. Another novel aspect of the research is the consideration of multiple humans-in-the-loop providing feedback that is used as a reward function by the learning algorithms embedded within the CPS. Finally, the project also is exploring the benefits of convergence time acceleration and deep learning techniques to extract features from EEG that are independent of canonical ERN component peaks. The research is evaluated using both a game proxy based analysis and experimental analysis within the context of real-world CPS.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815699","SHF: Small: Collaborative Research: LDPD-Net: A Framework for Accelerated Architectures for Low-Density Permuted-Diagonal Deep Neural Networks","CCF","SOFTWARE & HARDWARE FOUNDATION","10/01/2018","06/22/2018","Bo Yuan","NY","CUNY City College","Standard Grant","Sankar Basu","09/30/2021","$224,997.00","","bo.yuan@soe.rutgers.edu","Convent Ave at 138th St","New York","NY","100319101","2126505418","CSE","7798","075Z, 7923, 7945","$0.00","Deep learning has emerged as an important form of machine-learning where multiple layers of neural networks can learn the system function from available input-output data. Deep learning has outperformed traditional machine-learning algorithms based on feature engineering in fields such as image recognition, healthcare, and autonomous vehicles. These are widely used in cloud computing where large amount of computational resources are available. Deep neural networks are typically trained using graphic processing units (GPUs) or tensor processing units (TPUs). The training time and energy consumption grow with the complexity of the neural network. This project attempts to impose sparsity and regularity as constraints on the structure of the deep neural networks to reduce complexity and energy consumption by orders of magnitude, possibly at the expense of a slight degradation in the performance. The impacts lie in the formulation of a new family of structures for neural networks referred to as Low-Density Permuted Diagonal Network or LDPD-Net. The approach will enable the deployment of deep neural networks in energy-constrained and resource-constrained embedded platforms for inference tasks, including, but not limited to, unmanned vehicles/aerial systems, personalized healthcare, wearable and implantable devices, and mobile intelligent systems. In addition, the design methodology/techniques developed in this project can facilitate investigation of efficient computing of other matrix/tensor-based big data processing and analysis approaches. These approaches may also find applications in data-driven neuroscience and data-driven signal processing. In addition to graduate students, the project will involve undergraduates via senior design projects and research experiences for undergraduates. The results of the project will be disseminated to the broader community by publications, presentations, talks at various industries and other academic institutions. <br/><br/>The main barriers to wide adoption of deep learning networks include computational resource constraints and energy consumption constraints. These barriers can be relaxed by imposing sparsity and regularity among different layers of the deep neural network. The proposed low-density permuted-diagonal (LDPD) network can lead to orders of magnitude reduction in computation complexity, storage space and energy consumption. The LDPD-Net will not be retrained by first training a regular network and then only retaining the weights corresponding to the LDPD-Net. Instead, the proposed network will be trained from scratch. The proposed LDPD-Net can enable scaling of the network for a specified computational platform. The proposed research has three thrusts: 1) develop novel resource-constrained and energy-constrained inference and training systems;  2) develop novel efficient hardware architectures that can fully exploit the advantages of the LDPD-Net to achieve high performance; and 3) perform novel software and hardware co-design and co-optimization to explore the design space of the LDPD-Net. Using these, the efficacy of the proposed LDPD-net will be validated and evaluated, via software implementations on high-performance systems, low-power embedded systems, and a hardware prototype on FPGA development boards.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1761548","Discovering and Demonstrating Linguistic Features for Language Documentation","BCS","IIS SPECIAL PROJECTS, ROBUST INTELLIGENCE, DEL","08/15/2018","08/21/2018","Graham Neubig","PA","Carnegie-Mellon University","Standard Grant","Colleen Fitzgerald","01/31/2022","$450,000.00","","gneubig@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","SBE","7484, 7495, 7719","075Z, 1311, 7484, 7495, 7719","$0.00","Documenting endangered languages is matter of great urgency, but is also a time-consuming process.  Annotation and curation of speech and text data, searching for interesting, prototypical, or atypical entries, and marshalling examples for pedagogy or publication are still mostly manual processes.  This project aims to speed these processes by (1) creating better tools for the automated analysis of<br/>smaller and partially-annotated corpora, which have potential to reduce the amount of time required by linguists to manually annotate these corpora, and (2) creating better methods for linguists to browse their collected data and answer questions about the characteristics of the language at hand. The intellectual contribution of this proposal will lie in the development of new computational methods for natural language processing (NLP) for endangered languages, and their evaluation, both in controlled environments and as a tool for linguists in the field. It will also have broader impact in the creation of new tools and standards for linguistic documentation,increased collaboration between linguists and computer scientists, and training of a graduate student in the technologies and practices necessary to move this collaboration forward. The training component will increase the STEM workforce capacity in computational linguistics, important given the need for more advanced tools in working on languages that are underdocumented and spoken in countries that are key to national interests. <br/><br/>As a specific methodology to realize this vision, this project focuses on recent development of massively multilingual NLP models based on neural networks. These methods work by creating NLP using data from a large number of languages, then using the information gleaned from these languages to improve the accuracy of processing on a new language with a paucity of training data. Within this framework, three major research questions will be examined: (1) How can these techniques be efficiently applied to very-low-resource languages,especially those in the early stages of text collection? (2) What methods can be used to move beyond sentence-by-sentence analyses, and synthesize information about the entirety of the language to propose a simple grammatical specification? (3) Is it possible to provide examples that support typological predictions for a linguist to read and learn more about the nuances of the language they are analyzing? All three of these research questions will be examined in a rigorous process of devising methods, testing on existing data sets for well-resourced languages, and finally deployment to field linguists to examine how they improve the efficiency or accuracy of the language documentation process.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1824737","CompCog: A Machine Learning Approach to Human Perceptual Similarity","BCS","INFORMATION TECHNOLOGY RESEARC, PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE","10/01/2018","08/15/2018","Robert Jacobs","NY","University of Rochester","Standard Grant","Lawrence Gottlob","09/30/2021","$400,000.00","","robbie@bcs.rochester.edu","518 HYLAN, RC BOX 270140","Rochester","NY","146270140","5852754031","SBE","1640, 7252, 7495","075Z, 7252, 7495","$0.00","Similarity is fundamental to nearly all aspects of human cognition. Perception uses similarity: when viewing a person's face, we (unconsciously) calculate its similarity to the faces of people we know in order to recognize who we are looking at. Categorization uses similarity: when judging whether a building was designed by the architect Frank Lloyd Wright, we calculate its similarity to buildings known to have been designed by Wright in order to make our best estimate. Reasoning and problem solving use similarity: when attempting to solve a calculus problem, we calculate its similarity to previous problems that we have encountered in order to determine a good solution strategy. However, how people calculate the similarity of two items is not yet understood. Which features of items do people use to calculate similarity? And how are the feature values of items compared in order to calculate similarity? This research project will use human experimentation and computational modeling to address these questions when items are viewed or grasped. A long-term benefit of the project is that a greater understanding of people's perceptual similarity judgments will provide a foundation for understanding how people calculate and use similarity in other areas of cognition. While conducting the research, undergraduate and graduate students will be mentored in the cross-disciplinary approach embodied in our investigation through participation in both experimental and computational aspects of the research project. <br/> <br/>This project focuses on developing a new empirical and theoretical foundation for understanding people's notions of similarity, particularly in the domain of perceptual similarity.  The field of cognitive science is well aware that understanding similarity is essential to understanding human cognition. Despite this, the primary motivation for this project is the belief that, to date, cognitive science's approach to the study of similarity judgments is much too simple---the restricted class of similarity metrics considered by cognitive scientists is unlikely to scale to large, realistic settings. The primary hypothesis of this project is that the field of machine learning---especially the study of metric learning---can supply cognitive science with a rich array of complex and sophisticated models, models that will be necessary to accurately characterize people's similarity notions in large, realistic domains. Machine learning has pioneered the study of mathematically rigorous linear and nonlinear similarity metrics. We believe that the time is ripe for the field of cognitive science to make use of machine learning's recent advances. Machine learning's metric learning framework extends and elaborates the cognitive science approach in principled and innovative new directions. Indeed, this framework presents an unparalleled opportunity for cognitive science with the potential for transforming this field. Using the empirical and theoretical findings from machine learning, cognitive scientists can now begin to explore human notions of similarity in more complex and sophisticated ways---and in more realistic domains---than has ever been possible. We regard the research project as an early step for cognitive science towards a more sophisticated understanding of people's notions of similarity. Because the project cannot study similarity in all domains of human cognition, it concentrates on perception. Future work will need to develop further the models proposed and evaluated here. If successful, the program will establish an empirical and theoretical foundation that can subsequently be extended to many other areas of human cognition.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816851","SaTC: CORE: Small: Adversarial ML in Traffic Analysis","CNS","SPECIAL PROJECTS - CISE, Secure &Trustworthy Cyberspace","08/15/2018","08/09/2018","Matthew Wright","NY","Rochester Institute of Tech","Standard Grant","Dan Cosley","07/31/2021","$500,000.00","","matthew.wright@rit.edu","1 LOMB MEMORIAL DR","ROCHESTER","NY","146235603","5854757987","CSE","1714, 8060","025Z, 075Z, 7434, 7923","$0.00","Surveillance and tracking on the Internet are growing more pervasive and threaten privacy and freedom of expression. The Tor anonymity system protects the privacy of millions of users, including ordinary citizens, journalists, whistle-blowers, military intelligence, police, businesses, and people living under censorship and surveillance. Unfortunately, Tor is vulnerable to website fingerprinting (WF) attacks in which an eavesdropper uses a machine learning (ML) classifier to identify which website the user is visiting from its traffic patterns. The research team's state-of-the-art WF attack using a deep learning classifier reaches 98% accuracy, which is deeply concerning to Tor and its users. The goal of this project is to explore the new landscape of WF attacks and defenses in light of the team's findings with deep learning. A key aspect of the work is to build upon recent advances in fooling deep learning classifiers and apply these new findings to the context of anonymity systems. Based on this focus on adversarial machine learning, the project will create a new course and an accessible summer camp module on the topic, as well as launch a podcast on Cybersecurity Research featuring interviews with top researchers in the fields of adversarial machine learning and anonymity.<br/><br/>The research has three thrusts. First, the team is exploring the impact that these attacks can have for Tor users by addressing how the attacks can generalize to different network conditions and Tor versions, how they can be better adapted to realistic settings, and how they are impacted by real-world user behaviors in Tor. Second, since recent work has shown that it is possible to reliably fool deep learning classifiers, the team is studying how to adapt these techniques for robust and efficient defense. Prior work has primarily been in the image classification domain, whereas network traffic is more challenging to manipulate, so the team is designing new methods that account for this difference. In the third thrust, recognizing that researchers are actively seeking robust classifiers that are harder to fool, the team aims to understand new ways to build robust classifiers and explore their properties. While this aspect of the project means potentially finding stronger WF attacks against Tor, robust classifiers would be helpful for the myriad applications of deep learning, such as self-driving cars, stylometry, malware detection, processing drone and satellite imagery, and more.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1814759","SHF: Small: Collaborative Research: LDPD-Net: A Framework for Accelerated Architectures for Low-Density Permuted-Diagonal Deep Neural Networks","CCF","SOFTWARE & HARDWARE FOUNDATION","10/01/2018","06/22/2018","Keshab Parhi","MN","University of Minnesota-Twin Cities","Standard Grant","Sankar Basu","09/30/2021","$275,000.00","","parhi@umn.edu","200 OAK ST SE","Minneapolis","MN","554552070","6126245599","CSE","7798","075Z, 7923, 7945","$0.00","Deep learning has emerged as an important form of machine-learning where multiple layers of neural networks can learn the system function from available input-output data. Deep learning has outperformed traditional machine-learning algorithms based on feature engineering in fields such as image recognition, healthcare, and autonomous vehicles. These are widely used in cloud computing where large amount of computational resources are available. Deep neural networks are typically trained using graphic processing units (GPUs) or tensor processing units (TPUs). The training time and energy consumption grow with the complexity of the neural network. This project attempts to impose sparsity and regularity as constraints on the structure of the deep neural networks to reduce complexity and energy consumption by orders of magnitude, possibly at the expense of a slight degradation in the performance. The impacts lie in the formulation of a new family of structures for neural networks referred to as Low-Density Permuted Diagonal Network or LDPD-Net. The approach will enable the deployment of deep neural networks in energy-constrained and resource-constrained embedded platforms for inference tasks, including, but not limited to, unmanned vehicles/aerial systems, personalized healthcare, wearable and implantable devices, and mobile intelligent systems. In addition, the design methodology/techniques developed in this project can facilitate investigation of efficient computing of other matrix/tensor-based big data processing and analysis approaches. These approaches may also find applications in data-driven neuroscience and data-driven signal processing. In addition to graduate students, the project will involve undergraduates via senior design projects and research experiences for undergraduates. The results of the project will be disseminated to the broader community by publications, presentations, talks at various industries and other academic institutions. <br/><br/>The main barriers to wide adoption of deep learning networks include computational resource constraints and energy consumption constraints. These barriers can be relaxed by imposing sparsity and regularity among different layers of the deep neural network. The proposed low-density permuted-diagonal (LDPD) network can lead to orders of magnitude reduction in computation complexity, storage space and energy consumption. The LDPD-Net will not be retrained by first training a regular network and then only retaining the weights corresponding to the LDPD-Net. Instead, the proposed network will be trained from scratch. The proposed LDPD-Net can enable scaling of the network for a specified computational platform. The proposed research has three thrusts: 1) develop novel resource-constrained and energy-constrained inference and training systems;  2) develop novel efficient hardware architectures that can fully exploit the advantages of the LDPD-Net to achieve high performance; and 3) perform novel software and hardware co-design and co-optimization to explore the design space of the LDPD-Net. Using these, the efficacy of the proposed LDPD-net will be validated and evaluated, via software implementations on high-performance systems, low-power embedded systems, and a hardware prototype on FPGA development boards.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813567","SHF: Small: Fast Sign-Off of Machine Learning Systems: From Circuit-Level Modeling to Statistical System Validation","CCF","SOFTWARE & HARDWARE FOUNDATION","10/01/2018","06/18/2018","Xin Li","NC","Duke University","Standard Grant","Sankar Basu","09/30/2021","$400,000.00","","xinli.ece@duke.edu","2200 W. Main St, Suite 710","Durham","NC","277054010","9196843030","CSE","7798","075Z, 7923, 7945","$0.00","Machine learning has been adopted by a broad range of emerging applications, including health monitoring, autonomous driving, advanced manufacturing, etc. However, any machine learning system cannot be 100% accurate due to the accuracy limitation posed by machine learning algorithms and the circuit-level non-ideal features associated with its hardware implementation. This project investigates a radically new framework for efficient validation of machine learning systems implemented with nano-scale integrated circuits. It aims to identify and synthesize the critical corner cases for which a machine learning system is likely to fail. The project is expected to initialize a paradigm shift in today's design methodology for complex machine learning systems, thereby leading to an immediate impact on a broad range of industrial sectors relying on machine intelligence. In addition, the proposed education activities create a large number of unique training opportunities for both academic and industrial participants, substantially improving the education infrastructure and generate high-quality researchers and practitioners for the society. <br/><br/>Today, validating a machine learning system with high throughout, low power and complex functionality is an extremely challenging task. This project attacks the grand challenge by developing a novel validation framework composed of two major components: (1) corner-case generation and (2) rare-failure rate estimation. Both physical circuit models and statistical generative models are proposed to synthesize a large amount of test cases, reducing the experimental cost to physically record the corner-cases that are difficult to observe. Furthermore, a novel formulation, based on subset partition and graph embedding, is developed to efficiently inspect the likely-failed test cases and consequently estimate the rare- failure rate that is expensive to capture by random sampling. Built upon these mathematical tools, the project's framework offers a fundamental infrastructure that could facilitate radical breakthroughs over numerous machine learning applications.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1838745","SCH: INT: Collaborative Research: Data-driven Stratification and Prognosis for Traumatic Brain Injury","IIS","Smart and Connected Health","09/15/2018","09/06/2018","Vignesh Subbian","AZ","University of Arizona","Standard Grant","Wendy Nilsen","08/31/2022","$503,567.00","Jonathan Ratcliff","vsubbian@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","CSE","8018","075Z, 8018","$0.00","Traumatic Brain Injury (TBI) is a global health problem affecting over 10 million people worldwide and is a leading cause of death and disability among children and young adults in the United States. While the understanding of biological mechanisms related to acquired brain injuries has improved significantly in the past two decades, none of these advances have translated to a successful clinical trial and therefore, there has been no substantial improvement in treating such critical conditions. The heterogeneity of TBI and the ability to reliably stratify critically-ill patients who will likely have better outcomes for a certain intervention are amongst the major challenges in clinical research. To address these challenges, this project develops a comprehensive set of machine learning methods that can be broadly applied to a variety of problems. Data sources include both in-patient bedside data as well as remotely monitored telemedicine data, thus connecting data at multiple levels for specific patient populations. This research is crucial to support the development of pilot computational models for stratification of critical care patients and potentially inform ways to reduce the overall healthcare and societal costs for this patient population.<br/><br/>The project aims to develop novel computational algorithms for reliably stratifying brain injury patients and predicting their short-term and long-term outcomes from multi-modal physiologic and clinical data. Specifically, the research objectives of this project are: (i) Develop a scalable and effective algorithm for personalized subgroup identification for any given patient using an efficient subcluster model that groups patients using only a subset of coherently relevant variables. Discriminative subspace models will also be built to distinguish subgroups of patients. (ii) Propose a new machine learning paradigm called 'Label-Bag learning' to identify and predict changes in TBI Patients. The goal of label-bag learning is to learn a group of labels and their corresponding outcome variable in the data. The project includes a new framework based on Bayesian correlations that can adaptively transform any existing machine learning algorithm and implicitly handle this label-bag problem formulation through constrained modeling. (iii) Develop a novel approach to long-term outcome prediction through differential subset modeling framework. Through outreach and educational activities, the project will promote computational and systems thinking among high school, undergraduate, and graduate students along with clinical trainees. Methods developed in this project will be integrated into courses and tutorials that have both computational and biomedical emphases.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1838730","SCH: INT: Collaborative Research: Data-driven Stratification and  Prognosis for Traumatic Brain Injury","IIS","Smart and Connected Health","09/15/2018","09/06/2018","Chandan Reddy","VA","Virginia Polytechnic Institute and State University","Standard Grant","Wendy Nilsen","08/31/2022","$695,600.00","Brandon Foreman","reddy@cs.vt.edu","Sponsored Programs 0170","BLACKSBURG","VA","240610001","5402315281","CSE","8018","075Z, 8018","$0.00","Traumatic Brain Injury (TBI) is a global health problem affecting over 10 million people worldwide and is a leading cause of death and disability among children and young adults in the United States. While the understanding of biological mechanisms related to acquired brain injuries has improved significantly in the past two decades, none of these advances have translated to a successful clinical trial and therefore, there has been no substantial improvement in treating such critical conditions. The heterogeneity of TBI and the ability to reliably stratify critically-ill patients who will likely have better outcomes for a certain intervention are amongst the major challenges in clinical research. To address these challenges, this project develops a comprehensive set of machine learning methods that can be broadly applied to a variety of problems. Data sources include both in-patient bedside data as well as remotely monitored telemedicine data, thus connecting data at multiple levels for specific patient populations. This research is crucial to support the development of pilot computational models for stratification of critical care patients and potentially inform ways to reduce the overall healthcare and societal costs for this patient population.<br/><br/>The project aims to develop novel computational algorithms for reliably stratifying brain injury patients and predicting their short-term and long-term outcomes from multi-modal physiologic and clinical data. Specifically, the research objectives of this project are: (i) Develop a scalable and effective algorithm for personalized subgroup identification for any given patient using an efficient subcluster model that groups patients using only a subset of coherently relevant variables. Discriminative subspace models will also be built to distinguish subgroups of patients. (ii) Propose a new machine learning paradigm called 'Label-Bag learning' to identify and predict changes in TBI Patients. The goal of label-bag learning is to learn a group of labels and their corresponding outcome variable in the data. The project includes a new framework based on Bayesian correlations that can adaptively transform any existing machine learning algorithm and implicitly handle this label-bag problem formulation through constrained modeling. (iii) Develop a novel approach to long-term outcome prediction through differential subset modeling framework. Through outreach and educational activities, the project will promote computational and systems thinking among high school, undergraduate, and graduate students along with clinical trainees. Methods developed in this project will be integrated into courses and tutorials that have both computational and biomedical emphases.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816701","III: Small: Towards Speech-Driven Multimodal Querying","IIS","INFO INTEGRATION & INFORMATICS","10/01/2018","07/31/2018","Arun Kumar","CA","University of California-San Diego","Standard Grant","James French","09/30/2021","$500,000.00","Lawrence Saul, Ndapandula Nakashole","arunkk@eng.ucsd.edu","Office of Contract & Grant Admin","La Jolla","CA","920930621","8585344896","CSE","7364","075Z, 7364, 7923","$0.00","Modern automatic speech recognition (ASR) tools offer near-human accuracy in many scenarios. This has increased the popularity of speech-driven input in many applications on modern device environments such as tablets and smartphones, while also enabling personal conversational assistants. In this context, this project will study a seemingly simple but important fundamental question: how should one design a speech-driven system to query structured data? Structured data querying is ubiquitous in the enterprise, healthcare, and other domains. Typing queries in the Structured Query Language (SQL) is the gold standard for such querying. But typing SQL is painful or impossible in the above environments, which restricts when and how users can consume their data. SQL also has a learning curve. Existing alternatives such as typed natural language interfaces help improve usability but sacrifice query sophistication substantially. For instance, conversational assistants today support queries mainly over curated vendor-specific datasets, not arbitrary database schemas, and they often fail to understand query intent. This has widened the gap with SQL's high query sophistication and unambiguity. This project will bridge this gap by enabling users to interact with structured data using spoken queries over arbitrary database schemas. It will lead to prototype systems on popular tablet, smartphone, and conversational assistant environments. This could help many data professionals such as data analysts, business reporters, and database administrators, as well as non-technical data enthusiasts. For instance, nurse informaticists can retrieve patient details more easily and unambiguously to assist doctors, while analysts can slice and dice their data even on the move. The research will be disseminated as publications in database and natural language processing conferences. The research and artifacts produced will be integrated into graduate and undergraduate courses on database systems. The PIs will continue supporting students from under-represented groups as part of this project.<br/><br/>This project will create three new systems for spoken querying at three levels of ""naturalness."" The first level targets a tractable and meaningful subset of SQL. This research will exploit three powerful properties of SQL that regular English speech lacks--unambiguous context-free grammar, knowledge of the database schema queried, and knowledge of tokens from the database instance queried--to support arbitrary database schemas and tokens not present in the ASR vocabulary. The PIs will synthesize and innovate upon ideas from information retrieval, natural language processing, and database indexing and combine them with human-in-the-loop query correction to improve accuracy and efficiency. The second version will make SQL querying even more natural and stateful by changing its grammar. This will lead to the first speech-oriented dialect of SQL. The third version will apply the lessons from the previous versions to two state-of-the-art typed natural language interfaces for databases. This will lead to a redesign of such interfaces that exploits both the properties of speech and the database instance queried.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815948","III: Small: Collaborative Research: Explainable Natural Language Inference","IIS","INFO INTEGRATION & INFORMATICS","09/01/2018","07/27/2018","Peter Jansen","AZ","University of Arizona","Standard Grant","Maria Zemankova","08/31/2021","$254,463.00","Mihai Surdeanu","pajansen@email.arizona.edu","888 N Euclid Ave","Tucson","AZ","857194824","5206266000","CSE","7364","075Z, 7364, 7923","$0.00","Natural language inference (NLI) can support decision-making using information contained in natural language texts (e.g, detecting undiagnosed medical conditions in medical records, finding alternate treatments from scientific literature). This requires gathering facts extracted from text and reasoning over them. Current automated solutions for NLI are largely incapable of producing explanations for their inferences, but this capacity is essential for users to trust their reasoning in domains such as scientific discovery and medicine where the cost of making errors is high. This project develops natural language inference methods that are both accurate and explainable. They are accurate because they build on state-of-the-art deep learning frameworks which use powerful, automatically learned, representations of text. They are explainable because they aggregate information in units that can be represented in both a human readable explanation and a machine-usable vector representation. This project will advance methods in explainable natural language inference to enable the application of automated inference methods in critical domains such as medical knowledge extraction. The project will also evaluate the explainability of the inference decisions in collaboration with domain experts.<br/><br/>This project reframes natural language inference as the task of constructing and reasoning over explanations. In particular, inference assembles smaller component facts into a graph (explanation graph) that it reasons over to make decisions. In this view, generating explanations is an integral part of the inference process and not a separate post-hoc mechanism. The project has three main goals: (a) Develop multiagent reinforcement learning models that can effectively and efficiently explore the space of explanation graphs, (b) Develop deep learning based aggregation mechanisms that can prevent inference from combining semantically incompatible evidence, and (c) Build a continuum of hypergraph based text representations that combine discrete forms of structured knowledge with their continuous embedding based representations. The techniques will be evaluated on three application domains: complex question answering, medical relation extraction, and clinical event detection from medical records. The results of the project will be disseminated through the project website, scholarly venues, and the software and datasets will be made available to the public.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815358","III: Small: Collaborative Research: Explainable Natural Language Inference","IIS","INFO INTEGRATION & INFORMATICS","09/01/2018","07/27/2018","Niranjan Balasubramanian","NY","SUNY at Stony Brook","Standard Grant","Maria Zemankova","08/31/2021","$244,537.00","","niranjan@cs.stonybrook.edu","WEST 5510 FRK MEL LIB","Stony Brook","NY","117940001","6316329949","CSE","7364","075Z, 7364, 7923","$0.00","Natural language inference (NLI) can support decision-making using information contained in natural language texts (e.g, detecting undiagnosed medical conditions in medical records, finding alternate treatments from scientific literature). This requires gathering facts extracted from text and reasoning over them. Current automated solutions for NLI are largely incapable of producing explanations for their inferences, but this capacity is essential for users to trust their reasoning in domains such as scientific discovery and medicine where the cost of making errors is high. This project develops natural language inference methods that are both accurate and explainable. They are accurate because they build on state-of-the-art deep learning frameworks which use powerful, automatically learned, representations of text. They are explainable because they aggregate information in units that can be represented in both a human readable explanation and a machine-usable vector representation. This project will advance methods in explainable natural language inference to enable the application of automated inference methods in critical domains such as medical knowledge extraction. The project will also evaluate the explainability of the inference decisions in collaboration with domain experts.<br/><br/>This project reframes natural language inference as the task of constructing and reasoning over explanations. In particular, inference assembles smaller component facts into a graph (explanation graph) that it reasons over to make decisions. In this view, generating explanations is an integral part of the inference process and not a separate post-hoc mechanism. The project has three main goals: (a) Develop multiagent reinforcement learning models that can effectively and efficiently explore the space of explanation graphs, (b) Develop deep learning based aggregation mechanisms that can prevent inference from combining semantically incompatible evidence, and (c) Build a continuum of hypergraph based text representations that combine discrete forms of structured knowledge with their continuous embedding based representations. The techniques will be evaluated on three application domains: complex question answering, medical relation extraction, and clinical event detection from medical records. The results of the project will be disseminated through the project website, scholarly venues, and the software and datasets will be made available to the public.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1837131","FMitF: A Novel Framework for Learning Formal Abstractions and Causal Relations from Temporal Behaviors","CCF","FMitF: Formal Methods in the F, SPECIAL PROJECTS - CCF","11/01/2018","09/07/2018","Jyotirmoy Deshmukh","CA","University of Southern California","Standard Grant","Nina Amla","10/31/2022","$1,000,000.00","Yan Liu, Paul Bogdan","jdeshmuk@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","094Y, 2878","062Z, 071Z, 075Z, 8206","$0.00","Formal methods consist of a collection of techniques that help developers rigorously reason about the behaviors of software and hardware systems with the help of mathematical logic. While formal logic has been used for articulating system specifications for the purpose of verification or software synthesis, this project introduces a logic-based framework to address machine-learning problems such as classification (which category should a new datum be put into?), clustering (how should a collection of data points be grouped together into categories?) and discovery of causal relations (when should an earlier data observation be deemed to cause the appearance of a later data observation?) for time-series data, in which repeated observations are made over time. The use of formal logic opens new avenues such as enhancing the interpretability of machine-learning models, the explainability of learning results, and articulation of formal guarantees on the behavior of learning algorithms. The societal impact of this work targets discovery of latent information in time-series data in diverse domains such as healthcare, autonomous systems, and security. The research impacts education by providing cross-disciplinary training of undergraduate and graduates students in areas of data science, machine learning, formal methods, and introducing students to methods from statistical physics on a number of real-world systems.<br/><br/>This project explores the intersection between the logical inference based on real-time temporal logics and statistical inference prevalent in machine learning. The algorithms developed in this project allow users to express domain knowledge in the form of signal predicates or chance constraints, and output the results of classification, clustering or causal discovery as formulas in specific real-time temporal logics. This allows the results of the machine-learning algorithms to be human-interpretable, and also improves the explainability of learning algorithms by answering the question of why a particular time-series datum is classified or clustered in a specific fashion.  These techniques are able to model uncertainty in time-series data by creating a new class of non-parametric learning methods that combine concepts from statistical physics, information theory, and statistical inference. The use of a logic-based framework allows providing formal guarantees on the learning process itself by applying ideas such as probably-approximately-correct learning (from computational learning theory) to the inference of real-time temporal logic formulas from data.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1814557","SaTC: CORE: Small: FIRMA: Personalized Cross-Layer Continuous Authentication","CNS","SPECIAL PROJECTS - CISE, Secure &Trustworthy Cyberspace","09/15/2018","09/06/2018","Daniela Oliveira","FL","University of Florida","Standard Grant","Dan Cosley","08/31/2020","$500,000.00","Dapeng Wu, Natalie Ebner","daniela@ece.ufl.edu","1 UNIVERSITY OF FLORIDA","GAINESVILLE","FL","326112002","3523923516","CSE","1714, 8060","025Z, 075Z, 7434, 7923, 9102","$0.00","An important problem in computer security is verifying that people using computing devices are authorized to use them, not just when they first sign on to the device but during the whole time they are using them.  Most existing continuous authentication schemes impose burdens on users, for instance, when systems quickly log users out and require frequent re-entry of passwords.  This project will build and evaluate FIRMA, a user-transparent, continuous authentication software framework that collects usage data, targeted at corporate security contexts where such monitoring can be done.  To the extent that people have unique but recurrent patterns of use -- itself an interesting research question -- FIRMA can estimate the likelihood that the current user is still an authorized, authenticated user based on how current use patterns compare to historical ones.  Doing this might both reduce the burden of frequent re-authentication and provide early warning signs of malicious activity by malware or insider attacks.  Further, by leveraging the unique way people use computers, FIRMA will be diverse by design -- adversaries will not be able to predict how specific individuals use their devices and their attacks will fail in many devices -- thereby ""herd-protecting"" security by making it difficult for malware to automatically spread across many devices.  If successful, the project could have real impact on corporate security, reducing data breaches and downtime while improving the usability of these systems.  The work will also have educational and training impacts through interdisciplinary collaboration and education between computer engineering and psychology, involvement of undergraduate researchers, and efforts to recruit female and minority students to participate in the project. <br/><br/>FIRMA will be composed of a kernel module, which will continuously record at the operating system level all events related to user activities: user events (mouse clicks, keystrokes, and timestamps), processes, and the files and network events created as a consequence of user-driven activity. These events, recorded during a training period that represents a user's typical computer usage, will be applied to create a user profile using a novel Generative Adversarial Network (GAN)-based deep learning approach called AttenGAN/P-GAN, which will be composed of a user profile generator and a runtime classifier.  AttenGAN/P-GAN will both provide new deep learning tools for processing sequences of unknown length as well as improved ability to train classifiers for anomaly detection without negative samples. The runtime classifier will continuously observe events generated by FIRMA's extractor, leverage the user profile to classify the current window of events being observed as normal or anomalous, and update the current user confidence score. This classifier will be resilient to benign profile changes caused by fluctuations in a user's activity pattern caused by external factors, such as travel (change of time zone) or change of groups or projects. FIRMA's evaluation will comprise four-week captures of natural computer usage data from recruited computer users. This evaluation will consider usability, classification accuracy, and false positives in the presence of various types of anomalies.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815011","AF: Small: Foundations for Collaborative and Information-Limited Machine Learning","CCF","SPECIAL PROJECTS - CCF, ALGORITHMIC FOUNDATIONS","10/01/2018","08/28/2018","Avrim Blum","IL","Toyota Technological Institute at Chicago","Standard Grant","Rahul Shah","09/30/2021","$324,884.00","","avrim@ttic.edu","6045 S. Kenwood Avenue","Chicago","IL","606372803","7738340409","CSE","2878, 7796","075Z, 7923, 7926","$0.00","Machine learning increasingly is being used throughout society, and in a wide range of applications.  Businesses use machine learning systems for decision support, internet sites use machine learning to better interact with users, our personal devices use machine learning to adapt to our needs, and our cars are beginning to use data-trained systems to improve safety.  These applications bring up new opportunities as well as new concerns. Opportunities include the potential for systems to more rapidly learn and adapt through collaboration, and concerns include privacy and the fairness of algorithmically-made decisions.  This project is aimed at developing new foundational understanding of these opportunities and concerns, to help guide the development of more efficient, more adaptive, and fairer, machine learning methods.  This project additionally will support educational workshops on these issues, and more broadly will support the education and training of young scientists on these topics.<br/><br/>Specifically, this project has the following four main thrusts: (1) Collaborative Machine Learning. How can devices with related learning tasks best collaborate to learn efficiently from only a modest amount of data, and how can privacy and related concerns be addressed?  (2) Property Testing and Error Extrapolation.  This thrust aims to develop methods that, from a small amount of labeled data, can reliably estimate how well a given learning algorithm or representation class would perform if given a much larger labeled data sample.  (3) Semi-Supervised Learning. Semi-supervised learning refers to methods that combine labeled and unlabeled data, to learn well even when labeled data is limited. This work aims to develop theoretical foundations for an approach based on explicitly learning regularities within the unlabeled data and then using these to guide how learning is performed over the labeled data. (4)  Fairness in Learning. There has recently been substantial concern about algorithmic decisions (such as whether to offer an applicant a loan) that could unfairly discriminate against certain classes of people. This work aims to develop improved theoretical understanding, tools, and guarantees for tackling these kinds of problems.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1824257","Learning Depends on Knowledge: Using Interaction Designs and Machine Learning to Contrast the Testing and Worked Example Effects","BCS","Science of Learning, IIS SPECIAL PROJECTS","08/15/2018","08/27/2018","Ken Koedinger","PA","Carnegie-Mellon University","Standard Grant","Soo-Siang Lim","07/31/2021","$712,416.00"," Paulo Carvalho","Koedinger@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","SBE","004Y, 7484","059Z, 075Z","$0.00","A distinctive characteristic of human learning is its capability to flexibly acquire a wide range of rich and complex forms of knowledge (e.g., first and second languages) and acquiring new and accumulated knowledge (e.g., learning physics is easier after having learned algebra). An adequate explanation of human learning must address how existing knowledge changes the way we learn so that we achieve knowledge goals and in specific contexts. This project aims to discover and specify how human learning processes operate differently under different contexts, depending upon what content is being learned. This research contributes to improved educational practices by specifying how learning processes are influenced by knowledge acquisition in a systematic and replicable way. This research will enhance our understanding of successful learning and optimal performance.<br/><br/>The project explores learning processes by contrasting learning from retrieval practice and learning from studying examples. The goal of this project is to resolve and clarify how these processes compete for cognitive resources, including attention and working memory, in ways that depend on the knowledge content to be learned. This research examines (1) the learning processes involved in learning from retrieval practice and from worked examples, (2) how these learning processes work differently when applied to different knowledge content, and (3) the computational mechanisms of learning that give rise to learning different content. The researchers use a combination of experiments in which the learning approach is varied along with the materials being studied and machine learning models. It will demonstrate knowledge-learning dependence by showing that one learning process (e.g., retrieval practice) produces better learning outcomes than another (e.g., example encoding) in some knowledge contexts but the reverse occurs in other knowledge contexts. By implementing the studies as part of a machine learning architecture, this research will provide computational evidence and theoretical insight into the hypothesized knowledge-learning dependence framework. The machine learning architecture developed may be used as an educational and research tool in learning sciences, and the project involves training new learning scientists.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1830478","LEAP-HI/GOALI: Engineering Crops for Genetic Adaptation to Changing Enviroments","CMMI","LEAP-HI Leading Engineering fo","09/01/2018","08/23/2018","Lizhi Wang","IA","Iowa State University","Standard Grant","Bruce M. Kramer","08/31/2023","$1,999,999.00","William Beavis, Sotirios Archontoulis, Guiping Hu, Jack Kloeber","lzwang@iastate.edu","1138 Pearson","AMES","IA","500112207","5152945225","ENG","068Y","062Z, 068Z, 075Z, 1504, 5514, 8024","$0.00","This Leading Engineering for America's Prosperity, Health, and Infrastructure (LEAP-HI) Grant Opportunities for Academic Liaison with Industry (GOALI) project addresses the NSF Big Ideas of Understanding the Rules of Life and Harnessing the Data Revolution in targeting the need to provide food, fiber and fuel for a growing population using fewer resources (land, water, pesticides and fertilizers) in uncertain and rapidly changing environments. It is widely recognized that current agricultural technologies, from crop genetic improvement to field crop production, will not meet future agricultural demands, due to their heavy reliance on expensive, time-consuming, trail and error field trials to develop improved plant breeds. Emerging mathematical optimization and machine learning methods for analyzing high-dimensional data provide opportunities to speed up plant breeding to achieve rapid and efficient adaptation of crops to changing environments. The approaches in this project will take advantage of engineering techniques that have been used to remarkably improve the efficiency and resiliency of communication, manufacturing, transportation and energy systems.  The research requires the synthesis of multiple disciplines, including agronomy, crop modeling, machine learning, operations research, optimization and plant breeding and aims to demonstrate the leadership role of engineering in addressing agricultural challenges.<br/><br/>Three technical issues, which represent a small but highly visible subset of agronomic systems, will be addressed: (1) accurately predicting plant phenotypes based on genetic, agronomic management and environmental data and their interactions; (2) design of genetic improvement systems to efficiently develop cultivars with superior phenotypes; and (3) design of crop management strategies to assure that crops achieve superior phenotypes under changing environments, while balancing reward, time, and risk in the decision-making process. The research team will first translate the technical issues into engineering objectives and then identify existing methods and design new ones to achieve the objectives. The corresponding engineering objectives are: (1) identify a small subset of variables associated with synergistic effects in addition to their additive effects; (2) design a set of algorithms for genomic selection, which is a special type of nonlinear, non-convex, high-dimensional, and dynamic optimization problem constrained by resource availability and laws of reproductive biology; and (3) create a set of multi-objective and multi-level optimization models and algorithms for balancing reward, time, and risk, subject to genetic, environmental, and logistical constraints. Achieving these objectives will demonstrate the power of engineering approaches in improving the efficiency and resiliency of agronomic systems, with the aim of establishing plant breeding as an engineering discipline.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1748897","Assessing the changes in the brain representations of individual STEM concepts in the course of learning","BCS","Science of Learning, INFORMATION TECHNOLOGY RESEARC","09/01/2018","08/22/2018","Robert Mason","PA","Carnegie-Mellon University","Standard Grant","Soo-Siang Lim","08/31/2021","$549,377.00","Marcel Just","rmason@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","SBE","004Y, 1640","059Z, 075Z, 8089","$0.00","Discovering how STEM concepts are represented in the brain will allow us to both assess student learning of science and to teach STEM concepts more effectively. This project makes use of previous work by the investigators that demonstrated the remarkable new ability to determine the neural correlates (brain signature) of an individual concept, using fMRI brain imaging. Knowing the brain signature of physics concepts like gravity and velocity makes it possible to observe how the brain representations develop in a learner's brain, how they are organized, and how they depend on that person's learning background and on the teaching method. If we know the brain's way of organizing STEM concept knowledge, we can design curricula that teach to that organizational system and measure student learning at the brain level. This approach will not replace conventional tests, but it will provide a new type of basis for those tests such that they can assess alternative instructional methods. <br/><br/> The investigators had previously shown that neural signatures can be decomposed into meaningful underlying dimensions that are remarkably similar across people, making it possible to precisely compare the neural representations of student learners to the representations of instructors or of other successful learners. What has not been attempted before, and is the major goal of this project, is relating the neural signatures of concept learning to various learning outcomes.  Behavioral tests will assess the students? acquisition of the concepts and fMRI scans will assess the acquisition of the concomitant brain representations of the individual concepts.  The students' neural representations will be analyzed for their intrinsic integrity, measured by a machine learning classifier's accuracy in identifying a concept from its fMRI signature.  These will be compared to the neural representations of people with demonstrated mastery of the concepts (such as advanced students and the class instructors). Additionally, the project will assess changes in brain tissues (gray and white matter) that co-occur with concept learning, as well as changes in synchronization (functional connectivity) between brain regions involved in the concept representations. A central contribution of this project will be a brain-based understanding of how individual scientific concepts are learned and how this learning can be related to behavioral measures and individual differences.  The long-term goal is to build the foundation for neuroscience findings to inform teaching techniques and assessments, and as inspiration for additional strategies to promote successful learning in both the general student population and students at risk for failure.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1801494","SaTC: CORE: Medium: Collaborative: Using Machine Learning to Build More Resilient and Transparent Computer Systems","CNS","SPECIAL PROJECTS - CISE","09/01/2018","08/20/2018","Michael Reiter","NC","University of North Carolina at Chapel Hill","Standard Grant","Dan Cosley","08/31/2022","$333,320.00","","reiter@cs.unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275991350","9199663411","CSE","1714","025Z, 075Z, 7924","$0.00","Machine learning algorithms are increasingly part of everyday life: they help power the ads that we see while browsing the web, self-driving aids in modern cars, and even weather prediction and critical infrastructure. We rely on these algorithms in part because they perform better than alternatives and they can be easy to customize to new applications. Many machine learning algorithms also have a big weakness: it is difficult to understand how and why they compute the answers they provide. This opaqueness means that the answers we get from a machine learning algorithm could be subtly biased or even completely wrong, and yet we might not realize it. This project's goal is to make machine learning algorithms easier to understand, as well as to leverage some of the techniques used by attackers to trick machine learning algorithms into making mistakes to build computer systems that are more resistant to attack. In addition to making fundamental contributions to how machine learning algorithms are designed and used, the project includes outreach efforts that will entice students to gain hands-on experience with machine learning tools.<br/><br/>This project focuses on deep neural networks (DNNs).  A groundswell of research within the past five years has demonstrated the propensity of these models to being evaded by inputs created to fool them -- so called ""adversarial examples."" These types of attacks leverage DNNs' opacity: while DNNs can perform remarkably well on some classification tasks, they often defy simple explanations of how they do so, and indeed can leverage features for doing so that humans might find surprising. This project leverages DNNs and the attacks against them to gain insights into how to build more resilient computer systems. Specifically, the project will use DNNs to model adversaries trying to attack computer systems and then ""attack"" these DNNs to learn how to improve these systems' resilience to attack. This modeling will be done using Generative Adversarial Nets (GANs), in which ""generator"" and ""discriminator"" models compete. Central to this vision are the abilities to evade DNNs under constraints and to extract explanations from them about how they perform classification. Consequently, this project will make fundamental advances both in developing better methods to deceive DNNs and in improving this important machine-learning tool.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1801391","SaTC: CORE: Medium: Collaborative: Using Machine Learning to Build More Resilient and Transparent Computer Systems","CNS","SPECIAL PROJECTS - CISE, Secure &Trustworthy Cyberspace","09/01/2018","08/20/2018","Ljudevit Bauer","PA","Carnegie-Mellon University","Standard Grant","Dan Cosley","08/31/2022","$691,625.00","Matthew Fredrikson","lbauer@cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","1714, 8060","025Z, 075Z, 7434, 7924","$0.00","Machine learning algorithms are increasingly part of everyday life: they help power the ads that we see while browsing the web, self-driving aids in modern cars, and even weather prediction and critical infrastructure. We rely on these algorithms in part because they perform better than alternatives and they can be easy to customize to new applications. Many machine learning algorithms also have a big weakness: it is difficult to understand how and why they compute the answers they provide. This opaqueness means that the answers we get from a machine learning algorithm could be subtly biased or even completely wrong, and yet we might not realize it. This project's goal is to make machine learning algorithms easier to understand, as well as to leverage some of the techniques used by attackers to trick machine learning algorithms into making mistakes to build computer systems that are more resistant to attack. In addition to making fundamental contributions to how machine learning algorithms are designed and used, the project includes outreach efforts that will entice students to gain hands-on experience with machine learning tools.<br/><br/>This project focuses on deep neural networks (DNNs). A groundswell of research within the past five years has demonstrated the propensity of these models to being evaded by inputs created to fool them -- so called ""adversarial examples."" These types of attacks leverage DNNs' opacity: while DNNs can perform remarkably well on some classification tasks, they often defy simple explanations of how they do so, and indeed can leverage features for doing so that humans might find surprising. This project leverages DNNs and the attacks against them to gain insights into how to build more resilient computer systems. Specifically, the project will use DNNs to model adversaries trying to attack computer systems and then ""attack"" these DNNs to learn how to improve these systems' resilience to attack. This modeling will be done using Generative Adversarial Nets (GANs), in which ""generator"" and ""discriminator"" models compete. Central to this vision are the abilities to evade DNNs under constraints and to extract explanations from them about how they perform classification. Consequently, this project will make fundamental advances both in developing better methods to deceive DNNs and in improving this important machine-learning tool.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1814105","NeTS: Small: Collaborative Research: Protocol Validation using Minimally Supervised Semantic Interpretation of Text","CNS","SPECIAL PROJECTS - CISE","10/01/2018","08/15/2018","Dan Goldwasser","IN","Purdue University","Standard Grant","Ann Von Lehmen","09/30/2021","$250,000.00","","dgoldwas@purdue.edu","Young Hall","West Lafayette","IN","479072114","7654941055","CSE","1714","075Z, 7923","$0.00","The networks that comprise the Internet are fundamental to our society, facilitating access to medical and financial services, supporting critical infrastructure such as the power grid, and enabling emergent services such as those provided by autonomous cars and IoT (Internet of Things) devices. Network behavior is dictated by a set of instructions, or protocols, developed and tested over time.  Such protocols must operate correctly and comply with requirements that are usually described in a document(s), i.e., in a textual representation.  If they do not operate properly, the performance and security of a network could be compromised.  The goal of this project is to increase assurance in network protocols, specifically in their compliance to specified rules, in their inter-operability and in their functionality.  This project will accomplish this via a novel scheme to perform protocol testing through automated extraction of protocol requirements from their textual specification.  This would mark a significant advance in the field, towards automated mechanisms that assure that network protocols are behaving as we expect them to, making networks more reliable and secure.    <br/><br/>This multidisciplinary project combines expertise from natural language processing and computer networks to create methodologies, frameworks, a knowledge base, and tools for protocol validation for (1) compliance checking, (2) bug finding, and (3) interoperability testing.   The general approach is to apply machine learning, semantic parsing and information extraction  techniques to structured text (RFCs, internet-drafts) and unstructured text (blogs, forums, and bug reports), and create a knowledge base about the protocols, containing formal information such as  message formats, protocol state machine, constraints,  and semi-formal information such as temporal properties, tuning conditions and parameters, changes from one version to another, or known bugs. This information is organized into a knowledge base and used to validate protocol implementations through protocol fuzzying, program analysis, software model checking, and measurement methods, to check whether protocols are compliant with their specifications, to detect semantic bugs dependent on intrinsic protocol properties, or check for interoperability issues between different versions, or protocol stacks.  This work is guided by protocols from three representative domains -- TCP variants, the SDN ecosystem, and IoT smart home environment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815219","NeTS: Small: Collaborative Research: Protocol Validation using Minimally Supervised Semantic Interpretation of Text","CNS","SPECIAL PROJECTS - CISE, Networking Technology and Syst","10/01/2018","08/15/2018","Cristina Nita-Rotaru","MA","Northeastern University","Standard Grant","Ann Von Lehmen","09/30/2021","$249,914.00","","c.nitarotaru@neu.edu","360 HUNTINGTON AVE","BOSTON","MA","021155005","6173733004","CSE","1714, 7363","075Z, 7923, 9102","$0.00","The networks that comprise the Internet are fundamental to our society, facilitating access to medical and financial services, supporting critical infrastructure such as the power grid, and enabling emergent services such as those provided by autonomous cars and IoT (Internet of Things) devices. Network behavior is dictated by a set of instructions, or protocols, developed and tested over time.  Such protocols must operate correctly and comply with requirements that are usually described in a document(s), i.e., in a textual representation.  If they do not operate properly, the performance and security of a network could be compromised.  The goal of this project is to increase assurance in network protocols, specifically in their compliance to specified rules, in their inter-operability and in their functionality.  This project will accomplish this via a novel scheme to perform protocol testing through automated extraction of protocol requirements from their textual specification.  This would mark a significant advance in the field, towards automated mechanisms that assure that network protocols are behaving as we expect them to, making networks more reliable and secure.    <br/><br/>This multidisciplinary project combines expertise from natural language processing and computer networks to create methodologies, frameworks, a knowledge base, and tools for protocol validation for (1) compliance checking, (2) bug finding, and (3) interoperability testing.   The general approach is to apply machine learning, semantic parsing and information extraction  techniques to structured text (RFCs, internet-drafts) and unstructured text (blogs, forums, and bug reports), and create a knowledge base about the protocols, containing formal information such as  message formats, protocol state machine, constraints,  and semi-formal information such as temporal properties, tuning conditions and parameters, changes from one version to another, or known bugs. This information is organized into a knowledge base and used to validate protocol implementations through protocol fuzzying, program analysis, software model checking, and measurement methods, to check whether protocols are compliant with their specifications, to detect semantic bugs dependent on intrinsic protocol properties, or check for interoperability issues between different versions, or protocol stacks.  This work is guided by protocols from three representative domains -- TCP variants, the SDN ecosystem, and IoT smart home environment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1827993","Standard Grant: Productive Ambiguity in Classification","SES","INFORMATION TECHNOLOGY RESEARC, IIS SPECIAL PROJECTS, SCIENCE, TECH & SOCIETY","08/01/2018","08/10/2018","Beckett Sterner","AZ","Arizona State University","Standard Grant","Frederick M Kronz","07/31/2021","$158,162.00","Liz Lerman, Nico Franz, Manfred Laubichler, Joeri Witteveen","beckett.sterner@asu.edu","ORSPA","TEMPE","AZ","852816011","4809655479","SBE","1640, 7484, 7603","075Z, 1353","$0.00","This is a project in the history and philosophy of biology that has very substantial ramifications for data-intensive science. The PI will investigate how the history of taxonomy can shed new light on the value of ambiguity for science in the domain of data-intensive science. The project focuses on detecting trade-offs in the value of ambiguity for scientific language as a function of changing social contexts. Accurate disambiguation relies on a shared background of knowledge and abilities, which may prove inadequate as concepts spread into new contexts or a community grows larger and more heterogeneous. The project will fund graduate and undergraduate research assistants to analyze a text corpus drawn from two centuries of history in biological taxonomy. It will also support public events and the creation of educational materials addressing the theme of productive ambiguity in naming and classification.<br/><br/>This project will implement an integrative conceptual framework enabling empirical investigation of ambiguity in linguistic settings. It will use an information-theoretic framework from cognitive pragmatics to quantify ambiguity in a way that is open-ended enough to accommodate a wide range of phenomena shaping human language and communication while also reflecting the specific constraints required by computers. It will provide novel tools for tracking changes in language at the level of populations rather than individuals while remaining sensitive to underlying social institutions and individual differences. Results from this project will open new perspectives on the history of types and subspecies in systematics, and it will inform contemporary debates about the virtues of maximal determinacy in the computational representation of human language and meaning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1834323","EAGER: Toward a General Framework for Optimal Experimentation in Computational Cognition","BCS","METHOD, MEASURE & STATS, CROSS-DIRECTORATE  ACTIV PROGR, PERCEPTION, ACTION & COGNITION, ANIMAL BEHAVIOR","09/15/2018","08/09/2018","Woojae Kim","DC","Howard University","Standard Grant","Lawrence Gottlob","08/31/2020","$299,794.00","","woojae.kim@howard.edu","2400 Sixth Street N W","Washington","DC","200599000","2028064759","SBE","1333, 1397, 7252, 7659","041Z, 075Z, 1333, 7252, 7659","$0.00","Cognitive science aims to gain detailed insight into the underlying mechanisms of cognitive tasks. To achieve this, researchers change factors affecting a task in an experiment and observe responses. One way to learn from such an experiment is to build and test a computational model of stimulus-response relationships. However, the level of detail with which a model describes a task requires as much detail in supporting data. As observations from experiments are often expensive (e.g., child subject), this is a rather significant barrier. The method of optimal experiments can be a solution. It can optimize the selection of stimuli to maximize inference from responses. Nonetheless, the difficulty in applying the method to each new experiment has been a stumbling block. This project proposes to lay the foundation for a general framework for optimal experiments. The goal is to make it applicable to a wide range of modeling problems in cognitive science. This will help cognitive scientists to develop quantitative accounts of cognitive tasks effectively. Further, the method has the potential to accelerate scientific discovery broadly in social and behavioral research.<br/><br/>Conducting cognitive science experiments guided by optimal interaction with subjects toward a clear, quantified inference goal is a powerful idea. Such a method is particularly enticing for behavioral experiments in which the amount of noise in response is so great as to require many repeated measurements. Despite its groundbreaking potential for cognitive modeling research, the method of optimal experimentation is out of reach for most researchers in the field. The formidable task of implementing it for each unique experimental paradigm has been an obstacle to the realization of the methodology's promising power. The project focuses on establishing the technical feasibility of optimal experiments in arbitrary cognitive modeling contexts. The proposed research will define the need for the methodology in the field clearly, identify suitable computational strategies, and test alternative algorithms in simulation studies. The performance of algorithms under consideration will be evaluated on a testbed of modeling paradigms whose successful treatment would transfer to a wide range of similar problems. The project aims to create a tangible blueprint for a general-purpose methodology for optimal experimentation in computational cognition.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1763307","AF: Medium: Collaborative Research: Foundations of Fair Data Analysis","CCF","SPECIAL PROJECTS - CCF","07/01/2018","06/12/2018","AARON ROTH","PA","University of Pennsylvania","Continuing grant","Tracy J. Kimbrel","06/30/2022","$439,621.00","Rakesh Vohra, Sampath Kannan","aaroth@cis.upenn.edu","Research Services","Philadelphia","PA","191046205","2158987293","CSE","2878","075Z, 7924, 7926","$0.00","Machine learning algorithms increasingly make or inform critical decisions that affect peoples' every day lives.  For instance, algorithms make decisions pertaining to hiring, college admissions, credit card and mortgage approvals, sentencing and parole of the incarcerated, first-responder deployment, and what advertisements and search results a user sees on the internet.  An attractive feature is that these algorithms can efficiently process large amounts of data in making these decisions, thus hopefully improving economic and social efficiency.  Because such decisions are so consequential, their fairness has become a matter of increasing concern.  It has been argued that automation, by removing the human element, guarantees fairness, but this is not so -- several empirical studies have demonstrated that automation is no panacea.  Further, the reasons for unfairness and discrimination can be complex and non-obvious.  This project will study the frictions that may cause unfairness in algorithmic decision making, and the costs of mitigating unfairness -- that is, quantitative trade-offs between fairness and other desiderata, including accuracy, computational efficiency, and economic efficiency.<br/><br/>Specifically, this project will study frictions to fairness arising from several factors.  There may not be sufficient data about minority populations.  There can be feedback loops arising from the fact that observations can only be made on an individual if a risky action is taken, e.g., the person is granted a loan, or hired.  Decision makers can be myopic, choosing to maximize short-term gains rather than exploring riskier options that may pay off in the long run.  Economic frictions include self-confirming equilibria---differing subjective perceptions of opportunities leading to choices by individuals and communities which sustain those perceptions, and competition among classifiers (for example, credit agencies) leading to less accurate qualifiers in equilibrium.  Finally, the problem of finding fair and accurate classifiers can be computationally intractable.  This project will seek ways to mitigate the unfairness arising from these frictions.  It will study the cost of incentivizing myopic agents to explore and examine the short-term costs of such incentives, and their long-term impact on fairness.  It will also seek to design computationally tractable classifiers that achieve provably good approximations for fairness and accuracy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1826540","Statistical Learning for Innovative Assessment","SES","METHOD, MEASURE & STATS, IIS SPECIAL PROJECTS","09/01/2018","08/07/2018","Jingchen Liu","NY","Columbia University","Standard Grant","Cheryl L. Eavey","08/31/2021","$358,991.00","Zhiliang Ying","jcliu@stat.columbia.edu","2960 Broadway","NEW YORK","NY","100276902","2128546851","SBE","1333, 7484","075Z","$0.00","This research project will develop statistical methods for modern cognitive assessment. With the increasing use of computer-based testing, a variety of high-dimensional and complex structured data sets have been collected. The project will focus on statistical modeling and inference for large-scale data sets of complex structures. Specific topics to be addressed include the analysis of process data, adaptive learning through a reinforcement learning framework, and the development of computational methods for the models to be developed. The results of this research will provide a deeper understanding of the complex data structures collected in technology-rich interactive tasks. The project will shed light on items in learning and assessment environments that are delivered online both in client-server constellations and in stand-alone applications. The project will provide guidelines to improve item quality with a focus on more innovative item types, such as those in scenario-based and simulation-based environments for the assessment of students' knowledge and skills in the STEM fields. Educational researchers will be provided with tools to identify patterns in high-dimensional data and sequence data. Students in instructional and interventional programs will benefit from this research, especially in the STEM fields that are increasingly defined by digital media and technology-based interaction and communication.<br/><br/>Recent large-scale computer-based assessments have developed a number of interactive problem-solving items and collaborative problem-solving items. The investigators will develop statistical methods for the analysis of these new items. The investigators will concentrate on several aspects that are very challenging in the analysis of modern computer-based assessment; specifically, they will focus on: 1) predicting human behavior by means of modern machine learning techniques; 2) extracting latent structure and graphical structure for process data collected by interactive problem-solving items through event history analyses; 3) providing personalized learning material through a reinforcement learning framework; and 4) developing numerical methods to optimize high-dimensional functions either stochastically or deterministically. The models to be developed will combine latent variable and graphical approaches as well as deep-learning techniques for high-dimensional data. For modeling process data, the investigators will employ recent advances in modeling and segmenting techniques for natural language processing. For computation, the investigators will develop adaptive Robbins-Monro stochastic approximation. Optimization algorithms will be developed using recent advances in numerical methods.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816887","CSR: Small: Deconstructing Distributed Deep Learning","CNS","SPECIAL PROJECTS - CISE, Computer Systems Research (CSR","10/01/2018","08/04/2018","Leana Golubchik","CA","University of Southern California","Standard Grant","Samee Khan","09/30/2021","$516,000.00","","leana@cs.usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","1714, 7354","075Z, 7923","$0.00","Deep learning has made substantial strides in computer vision, speech recognition, natural language processing, and other applications. New algorithms, larger datasets, increased compute power, and machine learning frameworks all contribute to this success. An important missing piece is that it is still challenging for users to effectively provision and integrate deep learning applications into existing datacenters. This project develops novel solutions that enable effective use of cloud resources, which in turn will aid in broadening the population of users capable of discovering new and better deep learning models and applying them in novel settings and applications.<br/><br/>When developing new applications, users experiment with many deep neural networks (DNNs), but have limited knowledge of their computational demand. Due to non-linear scaling, predicting throughput improvements is challenging. Techniques developed in thrust 1 of this project quickly guide provisioning and resource allocation. In such environments, efficient inter-job resource sharing (particularly for similar DNNs) is an open problem, addressed in thrust 2 of the project by developing effective scheduling techniques. The diversity of datacenter workloads (DNNs, web), with different resource ""affinity"", creates opportunities to embrace cloud federations. While promising, there is a lack of techniques to support their sustainable deployment; these are developed in thrust 3 of the project.<br/><br/>This project is committed to diversity in research and education, involving undergraduate and graduate students, coupled with an existing extensive K-12 outreach effort. The developed experimental testbed is utilized for both, research and education. All algorithms, designs, software, and data are made publicly available so that researchers and educators are able to replicate and improve on developed technologies. Solutions to the fundamental problems that are the focus of this project enable the development of new deep learning models and increase the adoption rate of these technologies in novel application domains.<br/><br/>All reports and code are stored in an SVN-based repository. Software and related documents are publicly available on GitHub. All data is kept for at least 7 years beyond the life of the project. Research products are available promptly after publication, including supplemental information, through http://qed.usc.edu. These records are durable, accessible through standard web protocols, and made secure. Appropriate storage media is used, to keep data access current, as needed. Data that supports patents resulting from the project is retained for the duration of the patents. The URL to the repository is http://qed.usc.edu/D3/repository.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1829240","Collaborative Research: Modeling the Invention, Dissemination, and Translation of Scientific Concepts","SMA","INFORMATION TECHNOLOGY RESEARC, CYBERINFRASTRUCTURE, SCIENCE OF SCIENCE POLICY","09/01/2018","08/02/2018","Daniel McFarland","CA","Stanford University","Standard Grant","Mark K. Fiegener","08/31/2020","$313,486.00","","mcfarland@stanford.edu","3160 Porter Drive","Palo Alto","CA","943041212","6507232300","SBE","1640, 7231, 7626","075Z, 7626","$0.00","Scientific advance rests on discovery, dissemination, and translation. And yet, most discoveries fail to get noticed and have practical relevance. Nearly every university, discipline, foundation, government and company would like to know not just how to facilitate the creation of new scientific ideas, but how to get those ideas to spread and relate to practical issues in the world. To address such challenges, this research follows leading philosophers of science who argue that scientific concepts are the basic unit of knowledge, and it is there people observe scientific revolutions and advance. This research identifies scientific concepts using natural language processing techniques. With concepts in hand, it intends to model their interrelation in documents as forming an accumulated knowledge network to which every new publication's conceptual relations can be compared. Through comparison one will identify conceptual discoveries as the arrival of new concepts and conceptual relations. Results from this project will inform a variety of stakeholders concerned with intellectual innovation. The findings will have practical relevance by identifying where and when scholars make creative intellectual contributions, contributions that garner wider attention and reception in fields and domains far afield from academe. It will also identify levers for facilitating more rapid forms of discovery, dissemination and translation. Findings from this research will thus have direct relevance to decisions by academics, government agencies, and non-governmental organizations trying to accelerate scientific advance.  <br/><br/>Specifically, this research conducts three interrelated projects that identify the social conditions giving rise to concept discovery, dissemination, and translation. The first study asks what are the conditions that give rise to scientific discoveries like new concepts and new conceptual relations? Here the project identifies ecological conditions, resources, and demographic compositions that enable forms of conceptual creativity. The second study follows concepts over time and seeks to understand how they garner attention. Notably, only some conceptual discoveries actually spread and get repeatedly used. What are the initial conditions surrounding a concept's creation that predicts its entire career? Here, the project intends to study new concepts and new concept linkages, and it will look at their staging (start) and implementation (preceding moment) practices so as to determine what drives the heightened usage of some concepts over others. The third study will follow concepts as they spread beyond their discipline and to domains outside of academia. There the project analyzes how concepts translate across fields, or how they move from basic research applications to applied ones such as those found in patents. It also asks how scientific concepts get archived as accepted knowledge in encyclopedia such as Wikipedia. What leads an idea to go from theory, to applied use, to public acceptance? Again, are there ecological conditions and socio-cultural resources that enable an idea to move across social domains? This research will generate and share unique linked data, and it will create new empirical models and extensions of theory that will shift the way scholars conceive of scientific advance.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815971","CIF: Small: Learning on Graphs","CCF","SPECIAL PROJECTS - CCF","06/15/2018","06/11/2018","Francois Meyer","CO","University of Colorado at Boulder","Standard Grant","Phillip Regalia","05/31/2021","$426,527.00","","fmeyer@colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","CSE","2878","075Z, 7923, 7935, 8089, 8091","$0.00","Not unlike road networks, significant disruptions in the pattern of connections between brain regions have profound effect on brain function. International projects, such as the Human Connectome Project and the Autism Brain Imaging Data Exchange initiative, provide open access to massive datasets that can be used to learn the association between brain connectivity and psychiatric or neurological diseases. This award responds to the current lack of analytical and computational methods to quantify changes in the organization of brain functional networks. This project proposes to design novel machine learning algorithms that will lead the way toward precision medicine in psychiatry and neurology. The award will train several graduate students to work on big-data challenges in precision medicine. The source code that will implement the algorithms will be made publicly available in the form of open source toolboxes.<br/><br/>The availability of large datasets composed of graphs creates an unprecedented need to invent tools in statistical learning to study ""graph-valued random variables"". The first goal of this project is to develop theory and algorithms to estimate the mean and variance of a set of graphs. This basic problem is at the core of several statistical inference problems about population of graph ensembles. The second aim is to develop statistical methods that can detect significant structural changes (e.g., alteration of the topology and connectivity, etc.) in a time series of graphs. The third aim is concerned with the question of learning functions defined on a graph ensemble. The proposed approach relies on the ability to equip a graph ensemble with a metric, effectively turning the learning problem into the question of extending functions defined on a metric space.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1813877","CIF: Small: Precise Computational and Statistical Tradeoffs for Iterative Signal Estimation and Supervised Learning","CCF","SPECIAL PROJECTS - CCF, COMM & INFORMATION FOUNDATIONS","07/01/2018","06/18/2018","Mahdi Soltanolkotabi","CA","University of Southern California","Standard Grant","Phillip Regalia","06/30/2021","$490,691.00","","soltanol@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","2878, 7797","075Z, 7923, 7935","$0.00","Due to the proliferation of new sensors and acquisition devices, massive data sets are gathered in many modern applications ranging from medical imaging to online advertisement. Conventional statistical signal estimation and machine learning theory aims to understand how the predictive ability or accuracy of data analysis algorithms scales with data sizes. However, given the sheer size of modern data sets, these classical statistical theories are insufficient as algorithms have to operate effectively under a variety of new constraints such as, limited processing time, fixed computational budget and communication constraints. This project aims to develop the fundamental limits of how statistical accuracy tradeoffs with these resource constraints together with algorithms that nearly achieve such performance limits. The resulting signal estimation and learning algorithms are deployed in novel applications aimed at decreasing the acquisition time in medical imaging devices and speeding up parallelized algorithms in other data processing domains. Parts of this project are integrated into an advanced graduate class and select results will serve to motivate K-12 students to pursue careers in STEM (Science, Technology, Engineering and Math).<br/> <br/>In this project, the team of researchers study a family of convex optimization algorithms used for signal estimation and unsupervised learning. The main goal of this project is to understand how the statistical performance of iterative convex optimization algorithms tradeoffs with various statistical and computational resources such as run time, data size, communication, etc. The theoretical investigations utilizes techniques from convex analysis, probability, and information theory. The theoretical analysis can be used to establish fundamental performance bounds for popular convex optimization problems and guide the design of new algorithms that achieve optimal trade-offs between competing resource constraints.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1829268","Collaborative Research: Modeling the Invention, Dissemination, and Translation of Scientific Concepts","SMA","INFORMATION TECHNOLOGY RESEARC, CYBERINFRASTRUCTURE, SCIENCE OF SCIENCE POLICY","09/01/2018","08/02/2018","Xiang Ren","CA","University of Southern California","Standard Grant","Mark K. Fiegener","08/31/2020","$239,988.00","","xiangren@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","SBE","1640, 7231, 7626","075Z, 7626","$0.00","Scientific advance rests on discovery, dissemination, and translation. And yet, most discoveries fail to get noticed and have practical relevance. Nearly every university, discipline, foundation, government and company would like to know not just how to facilitate the creation of new scientific ideas, but how to get those ideas to spread and relate to practical issues in the world. To address such challenges, this research follows leading philosophers of science who argue that scientific concepts are the basic unit of knowledge, and it is there people observe scientific revolutions and advance. This research identifies scientific concepts using natural language processing techniques. With concepts in hand, it intends to model their interrelation in documents as forming an accumulated knowledge network to which every new publication's conceptual relations can be compared. Through comparison one will identify conceptual discoveries as the arrival of new concepts and conceptual relations. Results from this project will inform a variety of stakeholders concerned with intellectual innovation. The findings will have practical relevance by identifying where and when scholars make creative intellectual contributions, contributions that garner wider attention and reception in fields and domains far afield from academe. It will also identify levers for facilitating more rapid forms of discovery, dissemination and translation. Findings from this research will thus have direct relevance to decisions by academics, government agencies, and non-governmental organizations trying to accelerate scientific advance.  <br/><br/>Specifically, this research conducts three interrelated projects that identify the social conditions giving rise to concept discovery, dissemination, and translation. The first study asks what are the conditions that give rise to scientific discoveries like new concepts and new conceptual relations? Here the project identifies ecological conditions, resources, and demographic compositions that enable forms of conceptual creativity. The second study follows concepts over time and seeks to understand how they garner attention. Notably, only some conceptual discoveries actually spread and get repeatedly used. What are the initial conditions surrounding a concept's creation that predicts its entire career? Here, the project intends to study new concepts and new concept linkages, and it will look at their staging (start) and implementation (preceding moment) practices so as to determine what drives the heightened usage of some concepts over others. The third study will follow concepts as they spread beyond their discipline and to domains outside of academia. There the project analyzes how concepts translate across fields, or how they move from basic research applications to applied ones such as those found in patents. It also asks how scientific concepts get archived as accepted knowledge in encyclopedia such as Wikipedia. What leads an idea to go from theory, to applied use, to public acceptance? Again, are there ecological conditions and socio-cultural resources that enable an idea to move across social domains? This research will generate and share unique linked data, and it will create new empirical models and extensions of theory that will shift the way scholars conceive of scientific advance.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1763747","SHF: Medium: Training Sparse Neural Networks with Co-Designed Hardware Accelerators: Enabling Model Optimization and Scientific Exploration","CCF","SPECIAL PROJECTS - CCF","07/01/2018","07/02/2018","Keith Chugg","CA","University of Southern California","Continuing grant","Almadena Y. Chtchelkanova","06/30/2021","$758,600.00","Leana Golubchik, Peter Beerel, Panayiotis Georgiou","chugg@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","2878","075Z, 7924, 7942","$0.00","Machine learning systems are critical drivers of new technologies such as near-perfect automatic speech recognition, autonomous vehicles, computer vision, and natural language understanding.  The underlying inference engine for many of these systems is based on neural networks.  Before a neural network can be used for these inference tasks, it must be trained using a data corpus of known input-output pairs.  This training process is very computationally intensive with current systems requiring weeks to months of time on graphic processing units (GPUs) or central processing units in the cloud.  As more data becomes available, this problem of long training time is further exacerbated because larger, more effective network models become desirable.  The theoretical understanding of neural networks is limited, so experimentation and empirical optimization remains the primary tool for understanding deep neural networks and innovating in the field.   However, the ability to conduct larger scale experiments is becoming concentrated with a few large entities with the necessary financial and computational resources.  Even for those with such resources, the painfully long experimental cycle for training neural networks means that large-scale searches and optimizations over the neural network model structure are not performed.  The ultimate goal of this research project is to democratize and distribute the ability to conduct large scale neural network training and model optimizations at high speed, using hardware accelerators.  Reducing the training time from weeks to hours will allow researchers to run many more experiments, gaining knowledge into the fundamental inner workings of deep learning systems.  The hardware accelerators are also much more energy efficient than the existing GPU-based training paradigm, so advances made in this project can significantly reduce the energy consumption required for neural network training tasks.<br/><br/>This project comprises an interdisciplinary research plan that spans theory, hardware architecture and design, software control, and system integration.  A new class of neural networks that have pre-defined sparsity is being explored.  These sparse neural networks are co-designed with a very flexible, high-speed, energy-efficient hardware architecture that maximizes circuit speed for any model size in a given Field Programmable Gate Array (FPGA) chip.  This algorithm-hardware co-design is a key research theme that differentiates this approach from previous research that enforces some sparsity during the training process in a manner incompatible with parallel hardware acceleration. In particular, the proposed architecture operates on each network layer simultaneously, executing the forward- and back-propagation in parallel and pipelined fully across layers.  With high precision arithmetic, a speed-up of about 5X relative to GPUs is expected.  Using log-domain arithmetic, these gains are expected to increase to 100X or larger. Software and algorithms are being developed to manage multiple FPGA boards, simplifying and automating the model search and training process. These algorithms exploit the ability to reconfigure the FPGAs to trade speed for accuracy, a capability lacking in GPUs.  These software tools will also serve as a bridge to popular Python libraries used by the machine learning community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1763702","CIF: Medium: Collaborative Research: Coded Computing for Large-Scale Machine Learning","CCF","SPECIAL PROJECTS - CCF","09/01/2018","06/28/2018","Georgios-Alex Dimakis","TX","University of Texas at Austin","Continuing grant","Phillip Regalia","08/31/2022","$71,994.00","","dimakis@austin.utexas.edu","3925 W Braker Lane, Ste 3.340","Austin","TX","787595316","5124716424","CSE","2878","075Z, 7924, 7935","$0.00","Deep learning models are breaking new ground in data science tasks including image recognition, automatic translation and autonomous driving. This is achieved by neural networks that can be hundreds of layers deep and involve hundreds of millions of parameters. Training such large models requires distributed computations, very long training times and expensive hardware. This project studies coding theoretic techniques that can accelerate distributed machine learning and allow training with cheaper commodity hardware. Beyond the development of theoretical foundations, this project develops new algorithms for providing fault tolerance over unreliable cloud infrastructure that can significantly reduce the cost of large-scale machine learning. The research outcomes of the project will be broadly disseminated and integrated into education. <br/><br/>The specific focus of this research program is on mitigating the bottlenecks of distributed machine learning. Currently, scaling benefits are limited because of two reasons: first, communication is typically the bottleneck and second, straggler effects limit performance. Both problems can be mitigated using coding theoretic methods. This work proposes ""coded computing"", a transformative framework that combines coding theory with distributed computing to inject computational redundancy in a novel coded form. This framework is then used to develop three research thrusts: a) Coding for Linear Algebraic Computations b) Coding for Iterative Computations and c) Coding for General Distributed Computations. Each of the thrusts operates on a different layer of a machine learning pipeline but all rely on coding theoretic tools and distributed information processing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1763657","CIF: Medium: Collaborative Research: Coded Computing for Large-Scale Machine Learning","CCF","SPECIAL PROJECTS - CCF","09/01/2018","06/28/2018","Viveck Cadambe","PA","Pennsylvania State Univ University Park","Continuing grant","Phillip Regalia","08/31/2022","$75,777.00","","VXC12@psu.edu","110 Technology Center Building","UNIVERSITY PARK","PA","168027000","8148651372","CSE","2878","075Z, 7924, 7935","$0.00","Deep learning models are breaking new ground in data science tasks including image recognition, automatic translation and autonomous driving. This is achieved by neural networks that can be hundreds of layers deep and involve hundreds of millions of parameters. Training such large models requires distributed computations, very long training times and expensive hardware. This project studies coding theoretic techniques that can accelerate distributed machine learning and allow training with cheaper commodity hardware. Beyond the development of theoretical foundations, this project develops new algorithms for providing fault tolerance over unreliable cloud infrastructure that can significantly reduce the cost of large-scale machine learning. The research outcomes of the project will be broadly disseminated and integrated into education. <br/><br/>The specific focus of this research program is on mitigating the bottlenecks of distributed machine learning. Currently, scaling benefits are limited because of two reasons: first, communication is typically the bottleneck and second, straggler effects limit performance. Both problems can be mitigated using coding theoretic methods. This work proposes ""coded computing"", a transformative framework that combines coding theory with distributed computing to inject computational redundancy in a novel coded form. This framework is then used to develop three research thrusts: a) Coding for Linear Algebraic Computations b) Coding for Iterative Computations and c) Coding for General Distributed Computations. Each of the thrusts operates on a different layer of a machine learning pipeline but all rely on coding theoretic tools and distributed information processing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1763561","CIF: Medium: Collaborative Research: Coded Computing for Large-Scale Machine Learning","CCF","SPECIAL PROJECTS - CCF","09/01/2018","06/28/2018","Pulkit Grover","PA","Carnegie-Mellon University","Continuing grant","Phillip Regalia","08/31/2022","$97,696.00","","pgrover@andrew.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","2878","075Z, 7924, 7935","$0.00","Deep learning models are breaking new ground in data science tasks including image recognition, automatic translation and autonomous driving. This is achieved by neural networks that can be hundreds of layers deep and involve hundreds of millions of parameters. Training such large models requires distributed computations, very long training times and expensive hardware. This project studies coding theoretic techniques that can accelerate distributed machine learning and allow training with cheaper commodity hardware. Beyond the development of theoretical foundations, this project develops new algorithms for providing fault tolerance over unreliable cloud infrastructure that can significantly reduce the cost of large-scale machine learning. The research outcomes of the project will be broadly disseminated and integrated into education. <br/><br/>The specific focus of this research program is on mitigating the bottlenecks of distributed machine learning. Currently, scaling benefits are limited because of two reasons: first, communication is typically the bottleneck and second, straggler effects limit performance. Both problems can be mitigated using coding theoretic methods. This work proposes ""coded computing"", a transformative framework that combines coding theory with distributed computing to inject computational redundancy in a novel coded form. This framework is then used to develop three research thrusts: a) Coding for Linear Algebraic Computations b) Coding for Iterative Computations and c) Coding for General Distributed Computations. Each of the thrusts operates on a different layer of a machine learning pipeline but all rely on coding theoretic tools and distributed information processing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1763673","CIF: Medium: Collaborative Research: Coded Computing for Large-Scale Machine Learning","CCF","SPECIAL PROJECTS - CCF","09/01/2018","06/28/2018","Amir Avestimehr","CA","University of Southern California","Continuing grant","Phillip Regalia","08/31/2022","$71,244.00","","avestime@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","CSE","2878","075Z, 7924, 7935","$0.00","Deep learning models are breaking new ground in data science tasks including image recognition, automatic translation and autonomous driving. This is achieved by neural networks that can be hundreds of layers deep and involve hundreds of millions of parameters. Training such large models requires distributed computations, very long training times and expensive hardware. This project studies coding theoretic techniques that can accelerate distributed machine learning and allow training with cheaper commodity hardware. Beyond the development of theoretical foundations, this project develops new algorithms for providing fault tolerance over unreliable cloud infrastructure that can significantly reduce the cost of large-scale machine learning. The research outcomes of the project will be broadly disseminated and integrated into education. <br/><br/>The specific focus of this research program is on mitigating the bottlenecks of distributed machine learning. Currently, scaling benefits are limited because of two reasons: first, communication is typically the bottleneck and second, straggler effects limit performance. Both problems can be mitigated using coding theoretic methods. This work proposes ""coded computing"", a transformative framework that combines coding theory with distributed computing to inject computational redundancy in a novel coded form. This framework is then used to develop three research thrusts: a) Coding for Linear Algebraic Computations b) Coding for Iterative Computations and c) Coding for General Distributed Computations. Each of the thrusts operates on a different layer of a machine learning pipeline but all rely on coding theoretic tools and distributed information processing.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816936","SHF: Small: SMT Reasoning for Tensors and Data","CCF","SPECIAL PROJECTS - CCF","10/01/2018","06/21/2018","Dejan Jovanovic","CA","SRI International","Standard Grant","Nina Amla","09/30/2021","$499,452.00","","dejan@csl.sri.com","333 RAVENSWOOD AVE","Menlo Park","CA","940253493","6508592651","CSE","2878","075Z, 7923, 8206","$0.00","Our society is increasingly more dependent on computing systems that include components built from tensor models and rely on them to make critical decisions, like for example airplane controllers built from MATLAB code, or neural networks in self-driving cars. The surge in size and complexity of these systems has made their development, testing, and verification extremely costly and time consuming. To address this challenge, this project develops novel automated reasoning techniques that can support the development cycle of tensor-based systems, at scale, from design to verification, with the potential to increase both performance and reliability of the resulting systems, while broadening the applicability of symbolic reasoning to new domains.<br/><br/>The goal of the project is to develop new automated reasoning and symbolic optimization techniques needed for reasoning about complex systems that rely on tensors and data as the underlying model of<br/>computation. The current generation of automated reasoning techniques focuses solely on scalar domains, and they are inadequate for reasoning about large tensor systems with data. This project develops new reasoning techniques, in the context of satisfiability modulo theories, that can operate at the level of tensors. The key novel ideas explored in this project include high-level modeling and representation of tensor models, data-aware reasoning and optimization techniques for both linear and non-linear tensor models, and combination of numerical optimization and symbolic reasoning techniques. The project integrates the new techniques into machine learning and software analysis tools and evaluates their effectiveness.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1815899","SHF: Small: Energy Efficient Learning on Chip with Quantized Representations","CCF","SOFTWARE & HARDWARE FOUNDATION","10/01/2018","06/19/2018","Diana Marculescu","PA","Carnegie-Mellon University","Standard Grant","Sankar Basu","09/30/2021","$450,000.00","Ronald Blanton","dianam@ece.cmu.edu","5000 Forbes Avenue","PITTSBURGH","PA","152133815","4122689527","CSE","7798","075Z, 7923, 7945, 9102","$0.00","Machine learning models, especially deep neural networks, have been adopted in many real-time applications, such as speech and image recognition or object detection. These applications typically must be fast and energy efficient so they are usable in the field. This project develops quantized representations and algorithmic transformations for neural networks that represent large models with significantly less storage, energy and area, and with little or no accuracy degradation - in other words, enabling the use of efficient neural networks on mobile devices. The results of this project are poised to change how designers approach modeling, analysis, and optimization methodologies for large-scale deep neural networks, and more generally, any statistical learning applications that rely on expensive compute operations, with large memory footprint. The project will have not only a technical impact, but also an important educational and mentoring component by potentially changing how engineers are trained in a multidisciplinary fashion for dealing with next generation technological advances in general, and the problem of energy efficient machine learning in silicon in particular. The extensive experience of the Carnegie Mellon team in outreach to underrepresented groups involving training a diverse student body will be leveraged in this work, while further expanding the project's outreach to high-school and middle-school students.<br/><br/>This project exploits the fact that using a quantized representation for on-chip training and inference can reduce the energy consumption and storage requirements of the associated hardware implementation. This is a crucial feature in achieving higher throughput and lower latency for real-time learning systems. This project addresses these challenges by developing novel quantization approaches for machine learning models that reduce both data movement and computation, and therefore reduce overall energy consumption. Furthermore, the research pursued herein relies on new algorithmic approaches for training quantized learning models so as to accelerate their training process without harming their accuracy, and learning quantized models on hardware (i.e., field programmable gate arrays) to verify their benefits and accelerate their adoption.  To demonstrate feasibility, the project features a hardware accelerator-based testbed for inference and training models in a quantized fashion.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1817037","SHF:Small: Tensor-Based Algorithm and Hardware Co-Optimization for Neural Network Architecture","CCF","SPECIAL PROJECTS - CCF","10/01/2018","06/19/2018","Zheng Zhang","CA","University of California-Santa Barbara","Standard Grant","Sankar Basu","09/30/2021","$499,998.00","Yuan Xie","zhengzhang@ece.ucsb.edu","Office of Research","Santa Barbara","CA","931062050","8058934188","CSE","2878","075Z, 7923, 7945","$0.00","Machine learning plays an important role in our daily life, including medical data analysis, finance, autonomous driving and computer vision. Many popular machine learning models are both data-intensive and computationally expensive. In order to address this challenge, algorithm and architecture co-design and co-optimizations are required to achieve better performance and energy efficiency. This project aims to develop a more powerful learning architecture by simultaneously optimizing the neural network algorithm and its hardware implementation. The project will have a broad impact. The AI applications will gain a significant performance boost if the computational and storage cost of its algorithm can be reduced significantly.  It will improve many applications such as data mining, medical imaging analysis, computational biology, and financial analysis.  The project will greatly enrich the undergraduate and graduate course curriculum and attract graduate and undergraduate students to participate in this project and related workshops. Finally, this project will develop new AI, VLSI and computer architecture workforce with solid background in several areas including computational math, machine learning, and hardware design.<br/><br/>Tensors are a generalization of vectors and matrices, and they are promising tools to represent and numerically process high-dimensional data arrays. Leveraging the high effectiveness of tensor computation in big-data analysis, this project will investigate three specific topics towards designing high-performance and energy-efficient machine learning hardware. First, theoretically sound and novel tensor numerical algorithms will be developed to significantly reduce the training and inference cost of deep learning. Second, the algorithm framework will be optimized on existing hardware (e.g., GPU and FPGA) to achieve better performance, and to examine the main challenges when running on hardware platforms. Finally, emerging design technologies (e.g., 3-D process-in-memory) will be investigated to design specific hardware libraries to perform fundamental tensor computation and to further boost the performance and energy efficiency of the whole machine learning architecture.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1763349","AF: Medium: Collaborative Research: Foundations of Fair Data Analysis","CCF","SPECIAL PROJECTS - CCF, ALGORITHMIC FOUNDATIONS","07/01/2018","06/12/2018","Mallesh Pai","TX","William Marsh Rice University","Continuing grant","Tracy J. Kimbrel","06/30/2022","$63,168.00","","Mallesh.Pai@rice.edu","6100 MAIN ST","Houston","TX","770051827","7133484820","CSE","2878, 7796","075Z, 7924, 7926, 7932","$0.00","Machine learning algorithms increasingly make or inform critical decisions that affect peoples' every day lives. For instance, algorithms make decisions pertaining to hiring, college admissions, credit card and mortgage approvals, sentencing and parole of the incarcerated, first-responder deployment, and what advertisements and search results a user sees on the internet. An attractive feature is that these algorithms can efficiently process large amounts of data in making these decisions, thus hopefully improving economic and social efficiency. Because such decisions are so consequential, their fairness has become a matter of increasing concern. It has been argued that automation, by removing the human element, guarantees fairness, but this is not so -- several empirical studies have demonstrated that automation is no panacea. Further, the reasons for unfairness and discrimination can be complex and non-obvious. This project will study the frictions that may cause unfairness in algorithmic decision making, and the costs of mitigating unfairness -- that is, quantitative trade-offs between fairness and other desiderata, including accuracy, computational efficiency, and economic efficiency. <br/><br/>Specifically, this project will study frictions to fairness arising from several factors. There may not be sufficient data about minority populations. There can be feedback loops arising from the fact that observations can only be made on an individual if a risky action is taken, e.g., the person is granted a loan, or hired. Decision makers can be myopic, choosing to maximize short-term gains rather than exploring riskier options that may pay off in the long run. Economic frictions include self-confirming equilibria---differing subjective perceptions of opportunities leading to choices by individuals and communities which sustain those perceptions, and competition among classifiers (for example, credit agencies) leading to less accurate qualifiers in equilibrium. Finally, the problem of finding fair and accurate classifiers can be computationally intractable. This project will seek ways to mitigate the unfairness arising from these frictions. It will study the cost of incentivizing myopic agents to explore and examine the short-term costs of such incentives, and their long-term impact on fairness. It will also seek to design computationally tractable classifiers that achieve provably good approximations for fairness and accuracy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1816874","AF: Small: Foundations for Data-driven Algorithmics","CCF","SPECIAL PROJECTS - CCF","06/15/2018","06/04/2018","Yaron Singer","MA","Harvard University","Standard Grant","Rahul Shah","05/31/2021","$499,947.00","","yaron@seas.harvard.edu","1033 MASSACHUSETTS AVE","Cambridge","MA","021385369","6174955501","CSE","2878","075Z, 7923, 7926","$0.00","The traditional approach in optimization assumes that the underlying objective is known, but in many real-life applications, the true objectives are not known and learned from data. This gap between theory and practice turns out to be quite dramatic, and leaves us without guarantees on the performance of optimization algorithms in such applications. The goal of this project is to develop a theory for algorithms whose input (i.e., the objective) is learned from data, and design algorithms that perform well in these settings. The technical challenges in this space are highly non-trivial, but their solution would dramatically impact our thinking in computer science and result in major advancements in AI. The project develops courses in optimization and data science that foster an interdisciplinary approach. The project will involve mentoring undergraduate and graduate students from underrepresented groups and promote an open access research culture. The investigator will develop new interdisciplinary connections through courses, seminars, and workshops with the goal of promoting a discipline of researchers working on algorithms for the information age.<br/><br/>In light of a recent line of impossibility results initiated by the investigator, the goal of this project is to investigate alternative notions of optimization that can facilitate desirable guarantees for data-driven optimization. The first direction in this project considers optimization from adaptive samples. The general notion of adaptivity is surprisingly under-explored, and advancement on this front can have a tremendous impact both on theory and applications. A complementary direction is to consider algorithms that are given samples on a training datasets, and seek to approximate the optimal solution of the testing dataset, drawn from the same distribution. Finally, the last direction considered is that of optimization from pairwise comparisons.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
